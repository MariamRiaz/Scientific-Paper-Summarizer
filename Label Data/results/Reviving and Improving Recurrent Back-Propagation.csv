0,1,label2,summary_sentences
"Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex.",1. Introduction,[0],[0]
"While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another.",1. Introduction,[0],[0]
"Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).
",1. Introduction,[0.9565458478302308],"['We adopt graph neural networks (GNNs) (Scarselli et al., 2009) model and employ the GRU as the update function similarly as (Li et al., 2016).']"
"*Equal contribution 1University of Hong Kong, Hong Kong.",1. Introduction,[0],[0]
2This research was partially supported by the Hong Kong RGC under the grant 17200214.,1. Introduction,[0],[0]
"Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
"In this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger.",1. Introduction,[0],[0]
"This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).
",1. Introduction,[0],[0]
"However, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph.",1. Introduction,[0],[0]
"For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve.",1. Introduction,[0],[0]
"Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003).",1. Introduction,[0],[0]
"By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:
min Φold(f) := 1
2 ∑ e∈E we ∑
{u,v}∈(e2)
(fu − fv)2
subject to fu ∈",1. Introduction,[0],[0]
"[−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈",1. Introduction,[0],[0]
"L.
On the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:
Φnew(f) := 1
2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.
",1. Introduction,[0],[0]
"Indeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).
",1. Introduction,[0],[0]
Loss Function.,1. Introduction,[0],[0]
"In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function Φnew(f) + µ ‖f − f∗‖22 on f ∈",1. Introduction,[0],[0]
"[−1, 1]V , where µ > 0 is a parameter to be tuned, f∗L is given by the labeled vertices L, and for the unlabeled vertices f∗N = 0.
",1. Introduction,[0],[0]
"The loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique.",1. Introduction,[0],[0]
"However, as a result, unlabeled vertices have a tendency to acquire f values close to 0.",1. Introduction,[0],[0]
"This might remove useful information as illustrated in the following example.
",1. Introduction,[0],[0]
Example.,1. Introduction,[0],[0]
"In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1.",1. Introduction,[0],[0]
"Vertices x, y ∈ N are unlabeled.",1. Introduction,[0],[0]
"There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.
",1. Introduction,[0],[0]
"By choosing µ = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0.",1. Introduction,[0],[0]
"Hence, this solution gives no useful information regarding the label for vertex y.
On the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval",1. Introduction,[0],[0]
"[−1, 13 ].",1. Introduction,[0],[0]
"Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.
Our Contributions.",1. Introduction,[0],[0]
"In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications.",1. Introduction,[0],[0]
"We summarize our results and give an outline of the paper as follows.
1.",1. Introduction,[0],[0]
Unified Framework for Directed Hypergraphs.,1. Introduction,[0],[0]
"Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships.",1. Introduction,[0],[0]
"This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis.",1. Introduction,[0],[0]
"On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1.",1. Introduction,[0],[0]
"(Equivalently in terms of its contrapositive, a vertex in He labeled −1 implies that a vertex in Te is more likely to be labeled −1.)",1. Introduction,[0],[0]
"In Section 2, we formally define the model and the corresponding potential function Φ. An additional advantage of our potential function is that there is no need to tune any parameters.
2.",1. Introduction,[0],[0]
Confidence Interval for Unlabeled Vertices.,1. Introduction,[0],[0]
Observe that the minimizer for our convex program might not be unique.,1. Introduction,[0],[0]
"In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label.",1. Introduction,[0],[0]
"Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.
3.",1. Introduction,[0],[0]
Simpler Subgradient Method.,1. Introduction,[0],[0]
"Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction.",1. Introduction,[0],[0]
"Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for Φ, which is used to solve the underlying convex program.",1. Introduction,[0],[0]
"We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.
",1. Introduction,[0],[0]
"In contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables.",1. Introduction,[0],[0]
"The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method.",1. Introduction,[0],[0]
"Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013).",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster.",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.
",4. Experimental Results on Real-World Datasets. In,[0],[0]
"Moreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy.",4. Experimental Results on Real-World Datasets. In,[0],[0]
The experiments for directed hypergraphs are described in the full version.,4. Experimental Results on Real-World Datasets. In,[0],[0]
"We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function",2. Preliminaries,[0],[0]
w : E → R+.,2. Preliminaries,[0],[0]
Each hyperedge e ∈ E consists of a tail set Te ⊆ V and a head set He ⊆ V (which are not necessarily disjoint); we use the convention that the direction is from tail to head.,2. Preliminaries,[0],[0]
"For x ∈ R, we denote [x]+ := max{x, 0}.
",2. Preliminaries,[0],[0]
"In our application, each vertex v ∈ V is supposed to have a label in {−1,+1}.",2. Preliminaries,[0],[0]
"Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1.",2. Preliminaries,[0],[0]
"In terms of its contrapositive, if there is a vertex in He having label −1, then it is more likely for vertices in Te to receive label −1.
",2. Preliminaries,[0],[0]
"We use f ∈ RV to denote a vector, where the coordi-
nates are labeled by vertices in V .",2. Preliminaries,[0],[0]
"For U ⊆ V , we use fU ∈ RU to denote the vector restricting f to coordinates inU .",2. Preliminaries,[0],[0]
"In semi-supervised learning, we consider a setL ⊆ V of labeled vertices, which have labels f∗L ∈",2. Preliminaries,[0],[0]
"{−1,+1}L. Typically, |L| |V | and the task is to assign a label in {−1,+1} to each unlabeled vertex in N := V \ L, using information from the directed hypergraph H .
",2. Preliminaries,[0],[0]
"By relaxing labels to be in the interval [−1, 1], we consider the following regularization potential function Φ : RV → R:
Φ(f)",2. Preliminaries,[0],[0]
"= 1
2 ∑ e∈E we · ([∆e(f)]+)2,
where ∆e(f) := max(u,v)∈Te×He(fu − fv) = maxu∈Te fu −minv∈He fv .
",2. Preliminaries,[0],[0]
"In particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He.",2. Preliminaries,[0],[0]
"The convexity of Φ is proved in the full version.
",2. Preliminaries,[0],[0]
Our approach is to consider the following convex program to obtain an estimated minimizer f ∈,2. Preliminaries,[0],[0]
"[−1, 1]V , which can be rounded to an integer solution for labeling all vertices.
min Φ(f) (CP1) subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1], ∀u ∈ V
fu = f ∗ u , ∀u",2. Preliminaries,[0],[0]
"∈ L
Since the f values for the labeled vertices L are fixed in (CP1), we also view Φ : RN → R as a function on the f values of unlabeled vertices N .",2. Preliminaries,[0],[0]
"We use OPT ⊂ RV to denote the set of optimal solutions to (CP1).
",2. Preliminaries,[0],[0]
Trivial Edges.,2. Preliminaries,[0],[0]
An edge e ∈ E is trivial if there exist vertices u ∈ Te ∩ L and v ∈,2. Preliminaries,[0],[0]
He ∩ L such that f∗u = +1 and f∗v = −1.,2. Preliminaries,[0],[0]
"As trivial edges contribute constant towards the objective function Φ, we shall assume that there are no trivial edges in the convex program (CP1).
",2. Preliminaries,[0],[0]
Special Cases.,2. Preliminaries,[0],[0]
"Our directed hypergraph model can capture other graph models as follows.
1.",2. Preliminaries,[0],[0]
Undirected Hypergraphs.,2. Preliminaries,[0],[0]
"For each hyperedge e, we can set Te = He to the corresponding subset of vertices.",2. Preliminaries,[0],[0]
2.,2. Preliminaries,[0],[0]
Undirected Normal Graphs.,2. Preliminaries,[0],[0]
"For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes Φ(f) =∑
(u,v)∈E wuv(fu− fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.
",2. Preliminaries,[0],[0]
Soft Constraints.,2. Preliminaries,[0],[0]
"In (Hein et al., 2013), each labeled vertex u ∈ L can also have some weight µu ∈ R+, which can, for instance, indicate how trustworthy the label
f∗u ∈ {−1,+1} is.",2. Preliminaries,[0],[0]
"The following relaxation is considered.
",2. Preliminaries,[0],[0]
"min Φ̂(f) := Φ(f) + 1
2 ∑ u∈L µu(fu",2. Preliminaries,[0],[0]
"− f∗u)2 (CP2)
subject to fu ∈",2. Preliminaries,[0],[0]
"[−1, 1],∀u ∈ V.
Observe that (CP2) can also be expressed in the framework of (CP1).",2. Preliminaries,[0],[0]
"We simply consider an augmented hypergraph Ĥ such that all vertices V are treated as unlabeled, and for each u ∈ L, we add a new vertex û with label f∗u and a new undirected edge {u, û} with weight µu.",2. Preliminaries,[0],[0]
"Then, it follows that the convex program (CP1) for the augmented instance for Ĥ is exactly the same as (CP2).
",2. Preliminaries,[0],[0]
Challenges Ahead.,2. Preliminaries,[0],[0]
"We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.
",2. Preliminaries,[0],[0]
"• Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1).",2. Preliminaries,[0],[0]
"In Section 3, we prove some structural properties of the convex program, and illustrate that each u ∈ N has some confidence interval from which we can predict its label.",2. Preliminaries,[0],[0]
• The function Φ is not everywhere differentiable.,2. Preliminaries,[0],[0]
"Hence, we use the subgradient method (Shor et al., 1985).",2. Preliminaries,[0],[0]
"In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version.",2. Preliminaries,[0],[0]
"In general, a minimizer for (CP1) might not be unique.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Hence, we introduce the concept of confidence interval.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Definition 3.1 (Confidence Interval),3. Confidence Interval for Semi-supervised Learning,[0],[0]
"For each u ∈ V , we define its confidence interval to be [mu,Mu], where mu := minf∈OPT fu and Mu := maxf∈OPT fu.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M ∈ RV , respectively.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 (Confidence Vectors Give Optimal Solutions),3. Confidence Interval for Semi-supervised Learning,[0],[0]
For any λ ∈,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1], the convex combination λ~m + (1− λ) ~M",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"∈ OPT is optimal for (CP1).
",3. Confidence Interval for Semi-supervised Learning,[0],[0]
Semi-supervised Learning via Confidence Interval.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Specifically, in Algorithm 1, the
average vector 12 (~m + ~M) ∈ OPT can be used for label prediction.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f ∈ OPT, which in turn can be estimated by the subgradient method described in Section 4.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Algorithm 1 Semi-Supervised Learning
1: Input: Directed hypergraph H = (V,E,w), labels f∗L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"RN × RN , either by Algorithm 2 or 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
3: Compute average vector fN ← 12 (~m+ ~M).,3. Confidence Interval for Semi-supervised Learning,[0],[0]
4: Compute threshold θ ← 1|N | ∑ u∈N fu.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"5: for each u ∈ N do 6: if fu ≥ θ then 7: f̂u ← +1; 8: else 9: f̂u ← −1;
10: end if 11: end for 12: return f̂N
Fine-Tuning Parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"In view of Lemma 3.1, one could further optimize the choice of λ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1] in defining fN ← λ~m+ (1−λ) ~M in Line 3.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"Similarly, one could pick the threshold θ to be the ϑ-percentile of the sorted coordinates of fN , for some choice of ϑ ∈",3. Confidence Interval for Semi-supervised Learning,[0],[0]
"[0, 1].",3. Confidence Interval for Semi-supervised Learning,[0],[0]
The parameters λ and ϑ can be tuned using standard techniques like cross-validation.,3. Confidence Interval for Semi-supervised Learning,[0],[0]
"However, to illustrate our concepts, we keep the description simple without introducing too many free parameters.",3. Confidence Interval for Semi-supervised Learning,[0],[0]
We derive some properties of the confidence vectors to prove Lemma 3.1.,3.1. Properties of Confidence Vectors,[0],[0]
"The full proofs of Lemma 3.2 and 3.3 are given in the full version.
",3.1. Properties of Confidence Vectors,[0],[0]
"Given a feasible solution f ∈ RV to (CP1), we define the following:
1. Se(f) := arg maxu∈Te fu ⊆ Te and Ie(f) := arg minv∈He fv ⊆ He.",3.1. Properties of Confidence Vectors,[0],[0]
2. f(Se),3.1. Properties of Confidence Vectors,[0],[0]
:= maxu∈Te fu and f(Ie) := minv∈He fv .,3.1. Properties of Confidence Vectors,[0],[0]
"Hence, we have ∆e(f) = f(Se)− f(Ie).",3.1. Properties of Confidence Vectors,[0],[0]
3.,3.1. Properties of Confidence Vectors,[0],[0]
"The set of active edges with respect to f is E(f) := {e ∈ E : ∆e(f) > 0}.
",3.1. Properties of Confidence Vectors,[0],[0]
"The following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1).,3.1. Properties of Confidence Vectors,[0],[0]
"Then, for all e ∈ E, [∆e(f)]+ = [∆e(g)]+.",3.1. Properties of Confidence Vectors,[0],[0]
"In particular, this implies that the set of active edges E∗",3.1. Properties of Confidence Vectors,[0],[0]
":= E(f) = E(g) in any op-
timal solution is uniquely determined.",3.1. Properties of Confidence Vectors,[0],[0]
"Hence, for e ∈ E∗, we can define the corresponding ∆∗e = ∆e(f).
",3.1. Properties of Confidence Vectors,[0],[0]
"Definition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f ∈ RV if there exist active edges e and e′ ∈ E(f) such that u ∈ Se(f)∩ Ie′(f), in which case we say that the edges e and e′ pin the vertex u under f .
",3.1. Properties of Confidence Vectors,[0],[0]
Lemma 3.3 (Extending an Active Edge),3.1. Properties of Confidence Vectors,[0],[0]
Suppose edge e ∈ E(f) is active in an optimal solution f .,3.1. Properties of Confidence Vectors,[0],[0]
"If He does not contain a vertex labeled with −1, then there exist u ∈ Ie(f) and another active edge e′ ∈ E(f) such that the following holds.
",3.1. Properties of Confidence Vectors,[0],[0]
(a) The edges e and e′,3.1. Properties of Confidence Vectors,[0],[0]
"pin u under f , i.e., u ∈ Se′(f).",3.1. Properties of Confidence Vectors,[0],[0]
(b),3.1. Properties of Confidence Vectors,[0],[0]
"If g is an optimal solution, then Ie(f) ∩ Se′(f) =
Ie(g) ∩ Se′(g) and fu = gu.",3.1. Properties of Confidence Vectors,[0],[0]
vertex labeled with +1.,An analogous result holds when Te does not contain any,[0],[0]
∗(Ie),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
":= minu∈He fu are uniquely determined by any optimal solution f .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Corollary 3.1 (Pinned Vertices),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"In any optimal solution, the set of pinned vertices is uniquely determined.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We use L∗ to denote the set of labeled or pinned vertices in an optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Then, for each u ∈ L∗, its value f∗u in any optimal solution is also uniquely determined.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"From Corollary 3.1, the confidence interval for any u ∈ L∗ contains exactly one value, namely the unique value f∗u in any optimal solution.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following lemma gives a characterization of an optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.4 Characterization of Optimal Solutions,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"A solution f to (CP1) is optimal iff the following conditions hold.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(a) For each u ∈ L∗, fu = f∗u .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"(b) For each active edge e ∈ E∗, both the maximum
maxu∈Te fu and the minimum minv∈He fv are attained by vertices in L∗. (c) For each inactive edge e /∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"E∗,","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
for all u ∈ Te and v ∈,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fu ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Proof: We first observe that Corollary 3.1 states that the values of the vertices in L∗ are uniquely determined in any optimal solution.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any optimal solution must satisfy the three conditions.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next show that the three conditions implies that the objective value is optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Once the values for vertices in L∗ are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E∗ are determined and are the same as any optimal solution.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, condition (c) implies that edges not in E∗ do not have any contribution towards the objective function.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, any solution satisfying the three conditions must be optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Deriving Confidence Vectors.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"To prove Lemma 3.5, we define a procedure that returns a vector ~m ∈ V R such that for any optimal f ∈ OPT, we have f ≥ ~m.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we shall show that ~m ∈ OPT and hence ~m is the lower confidence vector.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The argument for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Lemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1),"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This implies that any of their convex combination is also optimal.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Proof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f ∈ OPT, f ≥ ~m.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The following steps correspond to maintaining the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set mv := f∗v ; for v /∈ L∗, set mv := −1.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This satisfies the invariant, because for any f ∈ OPT and any v ∈ L∗, fv = f∗v .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set mv ← max{mv,maxe∈E∗:v∈He f∗(Ie)}.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that Lemma 3.4(b) implies that for any optimal f ∈ OPT, any e ∈ E∗ and any v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He, fv ≥ f∗(Ie).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant is maintained.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and mu > mv , set mv ← mu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
We argue why each such update preserves the invariant.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Consider any optimal f ∈ OPT.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Before this update, the invariant holds.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, we have mu ≤ fu.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, Lemma 3.4 implies that fu ≤ fv .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, after setting mv ← mu, we still have mv ≤ fv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Finally, observe that after step (b), the coordinates of ~m can take at most n distinct values.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, after each update in step (c), one coordinate of ~m must increase strictly.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, this procedure will terminate.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (a).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Observe that for each v ∈ L∗, mv is initialized to f∗v .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Afterwards the value mv could only be increased.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"However, because the invariant holds when the procedure terminates, it must be the case that mv = f∗v at the end.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
Condition (b).,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The procedure makes sure that at the end of
step (b), for every active edge e ∈ E∗, minv∈He mv can be attained by some vertex in L∗. Since only mv for v /∈ L∗ can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L∗.
Next, consider u ∈ Te, where e ∈ E∗. For any optimal solution f , Lemma 3.3 implies that fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Hence, the invariant implies thatmu ≤ fu ≤ f∗(Se).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Since condition (a) holds, this means that maxv∈Te mv can be attained by some vertex in L∗.
Condition (c).","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"This is clearly satisfied because of the while-termination condition.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Therefore, we have ~m ∈ OPT, as required.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
The proof for the upper confidence vector ~M is similar.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"We omit the detailed proof and just give the corresponding procedure to return ~M .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(a) Initialization.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For v ∈ L∗, set Mv := f∗v ; for v /∈ L∗, set Mv := +1.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(b) Preserving Active Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"For each v /∈ L∗, set Mv ← min{Mv,mine∈E∗:v∈Te f∗(Se)}.
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
(c) Preserving Inactive Edges.,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
While there is an inactive edge e /∈ E∗,"In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"such that u ∈ Te, v ∈","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"He and Mu > Mv , set Mu ←Mv .
","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"The same argument can show that for any optimal f ∈ OPT, we have f ≤ ~M .","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"Moreover, we also have ~M ∈ OPT.","In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",[0],[0]
"As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution.",3.2. Computing the Confidence Interval,[0],[0]
"For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.
",3.2. Computing the Confidence Interval,[0],[0]
"Alternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors.",3.2. Computing the Confidence Interval,[0],[0]
"In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values.",3.2. Computing the Confidence Interval,[0],[0]
Resolving Ties.,4. Subgradient Method via Markov Operator,[0],[0]
Observe that Φ : RN → R is differentiable at fN ∈ RN that has distinct coordinates.,4. Subgradient Method via Markov Operator,[0],[0]
"For the purpose of computing a subgradient, we assume that there is some global ordering π on V to resolve ties among coordinates with the same value.",4. Subgradient Method via Markov Operator,[0],[0]
"In particular, the vertices in L having label +1 are the highest, and those in L labeled −1 are the lowest.",4. Subgradient Method via Markov Operator,[0],[0]
"Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices
Algorithm 2 Confidence Intervals for Undirected Hypergraphs
1: Input: Undirected hypergraph H = (V,E,w), label vector f∗L and tolerance ≥ 0.",4. Subgradient Method via Markov Operator,[0],[0]
"2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v ∈ V , set p(v)← v, mv ← −1, Mv ← +1.",4. Subgradient Method via Markov Operator,[0],[0]
"4: Ê := {e ∈ E : ∆e(f) ≤ } 5: while ∃e1 6= e2 ∈ Ê, e1 ∩ e2 6= ∅",4. Subgradient Method via Markov Operator,[0],[0]
"do 6: Ê ← (Ê \ {e1, e2}) ∪ {e1 ∪ e2} 7: end while 8: for each e ∈ Ê do 9: x← an arbitrary vertex in e
10: for each vertex v ∈ e do 11: p(v)← p(x) 12: end for 13: end for 14: for each vertex v ∈ L do 15: mp(v) ← f∗v , Mp(v) ← f∗v 16: end for 17: for each edge e ∈ E such that ∆e(f) >",4. Subgradient Method via Markov Operator,[0],[0]
do 18: for each vertex v ∈,4. Subgradient Method via Markov Operator,[0],[0]
e,4. Subgradient Method via Markov Operator,[0],[0]
"do 19: mp(v) ← max{mp(v), f(Ie)} 20: Mp(v) ← min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v ∈ V do 24: mv ← mp(v), Mv ←Mp(v) 25: end for 26: return vectors (~m, ~M)
will return a unique vertex.
",4. Subgradient Method via Markov Operator,[0],[0]
"We next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians.",4. Subgradient Method via Markov Operator,[0],[0]
"We denote the projection operator ΠN : RV → RN that takes f ∈ RV and returns the restricted vector fN ∈ RN .
",4. Subgradient Method via Markov Operator,[0],[0]
Lemma 4.1 For f ∈,4. Subgradient Method via Markov Operator,[0],[0]
"[−1, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of Φ : RN → R at fN .
",4. Subgradient Method via Markov Operator,[0],[0]
"Proof: (Sketch) Observe that if fN ∈ RN has distinct coordinates, then Φ is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case).",4. Subgradient Method via Markov Operator,[0],[0]
"Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering π.
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f∗L
for labeled vertices L 2: Construct feasible f (0,+)N ← +1 ∈ RN with all entries
being +1; 3: Construct feasible f (0,−)N ← −1 ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN with all entries
being −1; 4: ~M ← SGM(f (0,+)N ); 5: ~m← SGM(f (0,−)N ); 6: return the vectors (~m, ~M)
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 4 Markov Operator M : RV → RN
1: Input: Directed hypergraph H = (V,E,w), feasible f ∈ RV for (CP1) 2: Construct symmetric matrix A ∈ RV×V ; set A← 0.",4. Subgradient Method via Markov Operator,[0],[0]
3: for each e ∈ E such that ∆e(f) > 0,4. Subgradient Method via Markov Operator,[0],[0]
do 4: u← arg maxu∈Te fu; 5: v ← arg minv∈He fv; 6: Auv ← Auv + we; 7: (The same is done forAvu becauseA is symmetric.),4. Subgradient Method via Markov Operator,[0],[0]
"8: end for 9: Construct diagonal matrix W ∈ RN×N ; set W ← 0.
10: for each u ∈ N",4. Subgradient Method via Markov Operator,[0],[0]
do 11:,4. Subgradient Method via Markov Operator,[0],[0]
"Wuu ← ∑ v∈V Auv; 12: end for 13: return (WΠN −ΠNA)f
Hence, as the magnitude of the perturbation tends to zero, if the global ordering π is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.
",4. Subgradient Method via Markov Operator,[0],[0]
"Using the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).
",4. Subgradient Method via Markov Operator,[0],[0]
"Algorithm 5 Subgradient Method SGM(f (0)N ∈ RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-
bels f∗L for labeled vertices L, initial feasible solution f (0) N ∈",4. Subgradient Method via Markov Operator,[0],[0]
"RN , step size {ηt := 1 t }t≥1
2: t← 1; 3: (Throughout the algorithm, f (t)L = f ∗ L is given by the
labeled vertices.)",4. Subgradient Method via Markov Operator,[0],[0]
4: while Solution f (t)N has not “stabilized” do 5: g(t)N ← Mf (t−1) ∈ RN ; 6: f (t)N = f (t−1) N,4. Subgradient Method via Markov Operator,[0],[0]
"− ηt ·
g (t)",4. Subgradient Method via Markov Operator,[0],[0]
"N∥∥∥g(t)N ∥∥∥
2
;
7: t← t+ 1; 8: end while 9: return f (t)
",4. Subgradient Method via Markov Operator,[0],[0]
Stabilizing Condition.,4. Subgradient Method via Markov Operator,[0],[0]
"Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy.",4. Subgradient Method via Markov Operator,[0],[0]
Our experiments are run on a standard PC.,5. Experimental Results,[0],[0]
"In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean.",5. Experimental Results,[0],[0]
"We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Hypergraph Model.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Each entry in the dataset corresponds to a vertex, which is labeled either +1 or −1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Moreover, each entry has some categorical attributes.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"To summarize, below are the properties of the resulting hypergraphs.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Dataset mushroom covertype45 covertype67
n = |V",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"| 8124 12240 37877 m = |E| 112 104 123 k =∑
e∈E |e| m
1523 1412 3695
Semi-supervised Learning Framework.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Specifically, we compare the prediction accuracy of the following two prediction algorithms.
1.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Confidence Interval (CI).,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.
",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Testing Methodology.,5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"For each size l
of labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or −1) appears in L. For each size",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"l, we perform 100 trials to report the average error rate together with its standard error.
Results.",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"Our experiment can recover the results reported in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
"The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013).",5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods,[0],[0]
Different Solvers.,5.2. Comparing Running Times of Solvers,[0],[0]
"We compare the running times of the following two convex program solvers:
• Subgradient Method (SG), proposed by us.",5.2. Comparing Running Times of Solvers,[0],[0]
"Empirically, the step size ηt := 1
(t+1) min( 0.16t 105 ,1)
gives good
performance.",5.2. Comparing Running Times of Solvers,[0],[0]
"For large t, ηt grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence.",5.2. Comparing Running Times of Solvers,[0],[0]
"• Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013).",5.2. Comparing Running Times of Solvers,[0],[0]
"We choose σ = τ = 1√
1+d ,
where d is the maximum degree.
",5.2. Comparing Running Times of Solvers,[0],[0]
Theoretical Analysis.,5.2. Comparing Running Times of Solvers,[0],[0]
"Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges.",5.2. Comparing Running Times of Solvers,[0],[0]
"For SG, we use a heap-based data structure to maintain the vertices within a hyperedge.",5.2. Comparing Running Times of Solvers,[0],[0]
"Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"In each iteration, at most 2m vertices will have their values updated.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, in each iteration, SG takes time 2m·mkn ·O(log k) = O(m
2k n log k).",5.2. Comparing Running Times of Solvers,[0],[0]
"In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.
",5.2. Comparing Running Times of Solvers,[0],[0]
Testing Methodology.,5.2. Comparing Running Times of Solvers,[0],[0]
"In each experiment, we consider the hypergraph from one of the above three datasets.",5.2. Comparing Running Times of Solvers,[0],[0]
"We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [−1, 1].",5.2. Comparing Running Times of Solvers,[0],[0]
"To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration.",5.2. Comparing Running Times of Solvers,[0],[0]
"According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
"Then, we scan each trajectory, and for each relative gap
∈ {10−i : i = 1, 2, . . .",5.2. Comparing Running Times of Solvers,[0],[0]
", 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT.",5.2. Comparing Running Times of Solvers,[0],[0]
Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )’s and their standard error.,5.2. Comparing Running Times of Solvers,[0],[0]
"For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.
Results.",5.2. Comparing Running Times of Solvers,[0],[0]
Both solvers have similar performance.,5.2. Comparing Running Times of Solvers,[0],[0]
"As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67.",5.2. Comparing Running Times of Solvers,[0],[0]
"Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10−4 has almost no effect on improving the prediction accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
"Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-
tion accuracy.",5.2. Comparing Running Times of Solvers,[0],[0]
DBLP Dataset.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We use the DBLP (Ley, 2009) dataset.",5.3. Directed Hypergraph: More Powerful,[0],[0]
Each paper is represented by a vertex.,5.3. Directed Hypergraph: More Powerful,[0],[0]
"We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:
• 7049 papers from machine learning (ML): NIPS, ICML • 2539 papers from theoretical computer science (TCS): STOC, FOCS • 3374 papers from database (DB): VLDB, SIGMOD
We perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).
",5.3. Directed Hypergraph: More Powerful,[0],[0]
The details of the experiment setup and the results are given in the full version.,5.3. Directed Hypergraph: More Powerful,[0],[0]
We revisit semi-supervised learning on hypergraphs.,abstractText,[0],[0]
"Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable.",abstractText,[0],[0]
"We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution.",abstractText,[0],[0]
"Moreover, we give a much simpler approach for solving the convex program based on the subgradient method.",abstractText,[0],[0]
"Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.",abstractText,[0],[0]
Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method,title,[0],[0]
"The Fisher Information Metric (FIM) I(Θ) = (Iij) of a statistical parametric model p(x |Θ) of order D is defined by a D×D positive semidefinite (psd) matrix (I(Θ) 0) with coefficients Iij = Ep [ ∂l ∂Θi ∂l ∂Θj ] , where l(Θ) denotes the log-density function log p(x |Θ).",1. Fisher Information Metric,[0],[0]
"Under light regularity conditions, FIM can be rewritten equivalently as
Iij = −Ep",1. Fisher Information Metric,[0],[0]
"[ ∂2l
∂Θi∂Θj
] = 4 ∫ ∂ √ p(x |Θ) ∂Θi ∂ √ p(x |Θ) ∂Θj dx.
",1. Fisher Information Metric,[0],[0]
"As its empirical counterpart, the observed FIM (Efron & Hinkley, 1978) with respect to (wrt) a sample set Xn = {xk}nk=1 is Î(Θ |Xn) = −∇2l(Θ",1. Fisher Information Metric,[0],[0]
"|Xn), which is often evaluated at the maximum likelihood estimate Θ = Θ̂(Xn).",1. Fisher Information Metric,[0],[0]
"By the law of large numbers, Î(Θ) converges to the (expected) FIM I(Θ) as n→∞.
1King Abdullah University of Science and Technology (KAUST), Saudi Arabia 2École Polytechnique, France 3Sony Computer Science Laboratories Inc., Japan.",1. Fisher Information Metric,[0],[0]
"Correspondence to: Ke Sun <sunk@ieee.org>, Frank Nielsen <Frank.Nielsen@acm.org>.
",1. Fisher Information Metric,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Fisher Information Metric,[0],[0]
"Copyright 2017 by the author(s).
",1. Fisher Information Metric,[0],[0]
The FIM is not invariant and depends on the parameterization.,1. Fisher Information Metric,[0],[0]
We can optionally write I(Θ) as IΘ(Θ) to emphasize the coordinate system.,1. Fisher Information Metric,[0],[0]
"By definition, IΘ(Θ) = JᵀIΛ(Λ)J where J = (Jij), Jij = ∂Λi∂Θj is the Jacobian matrix.",1. Fisher Information Metric,[0],[0]
"For example, the FIM of regular natural exponential families (NEFs) l(Θ) = Θᵀt(x)",1. Fisher Information Metric,[0],[0]
− F (Θ) (loglinear models with sufficient statistics t(x)) is I(Θ),1. Fisher Information Metric,[0],[0]
"= ∇2F (Θ) 0, the Hessian of the log-normalizer function F (Θ).",1. Fisher Information Metric,[0],[0]
"Although exponential families can approximate arbitrarily any smooth density (Cobb et al., 1983), the lognormalizer function may not be available in closed-form nor computationally tractable (Montanari, 2015).
",1. Fisher Information Metric,[0],[0]
The FIM is an important concept for statistical machine learning.,1. Fisher Information Metric,[0],[0]
"It gives a Riemannian metric (Hotelling, 1929; Rao, 1945) of the learning parameter space which is unique (Čencov, 1982; Dowty, 2017).",1. Fisher Information Metric,[0],[0]
"Hence any learning is in a space that is intrinsically curved based on the FIM, regardless of the choice of the coordinate system.",1. Fisher Information Metric,[0.9536333905540637],"['Since the condition number of the current system is the square of the original one, the system may be slower to converge in practice.']"
"It also gives a bound (Fréchet, 1943; Cramér, 1946; Nielsen, 2013) of learning efficiency saying that the variance of any unbiased learning of Θ is at least I−1(Θ)/n, where n is the i.i.d. sample size.",1. Fisher Information Metric,[0],[0]
"The FIM is applied to neural network optimization (Amari, 1997), metric learning (Lebanon, 2005), reinforcement learning (Thomas, 2014) and manifold learning (Sun & Marchand-Maillet, 2014).
",1. Fisher Information Metric,[0],[0]
However computing the FIM is expensive.,1. Fisher Information Metric,[0],[0]
"Besides the fact that learning machines have often singularities (Watanabe, 2009) (|I(Θ)| = 0, not full rank) characterized by plateaux in gradient learning, computing/estimating the FIM of a large neuron system (e.g. one with millions of parameters, Szegedy, Christian et al. 2015) is very challenging due to the finiteness of data, and the huge number D(D+1)2 of matrix coefficients to evaluate.",1. Fisher Information Metric,[0],[0]
"Furthermore, gradient descent techniques require inverting this large matrix and tuning the learning rate.
",1. Fisher Information Metric,[0],[0]
"To tackle this problem, past works mainly focus on how to approximate the FIM with a block diagonal form (Kurita, 1994; Le Roux et al., 2008; Martens, 2010; Pascanu & Bengio, 2014; Martens & Grosse, 2015) or quasi-diagonal form (Ollivier, 2013; Marceau-Caron & Ollivier, 2016).",1. Fisher Information Metric,[0],[0]
"This global approach faces increasing approximation error and increasing computational cost as the system scales up
and as complex and dynamic structures (Looks et al., 2017) emerge.
",1. Fisher Information Metric,[0],[0]
This work aims at a different local approach.,1. Fisher Information Metric,[0],[0]
"The idea is to accurately describe the information geometry (IG) in a subsystem of the large learning system, which is invariant to the scaling up and structural change of the global system, so that the local machinery, including optimization, can be discussed regardless of the other parts.
",1. Fisher Information Metric,[0],[0]
"For this purpose, a novel concept, the Relative Fisher Information Metric (RFIM), is defined.",1. Fisher Information Metric,[0],[0]
"Unlike the traditional geometric view of a high-dimensional parameter manifold, RFIMs defines multiple projected low-dimensional geometries of subsystems.",1. Fisher Information Metric,[0],[0]
This geometry is correlated to the parameters beyond the subsystem and is therefore considered dynamic.,1. Fisher Information Metric,[0],[0]
It can be used to characterize the efficiency of a local learning process.,1. Fisher Information Metric,[0],[0]
Taking this stance has potential in deep learning because a deep neural network can be decomposed into many local components such as neurons or layers.,1. Fisher Information Metric,[0],[0]
The RFIM is well suited to the compositional block structures of neural networks.,1. Fisher Information Metric,[0],[0]
"The RFIM can be used for out-of-core learning.
",1. Fisher Information Metric,[0],[0]
The paper is organized as follows.,1. Fisher Information Metric,[0],[0]
Sec. 2 reviews natural gradient within the context of Multi-Layer Perceptrons (MLPs).,1. Fisher Information Metric,[0],[0]
"Sec. 3 formally defines the RFIM, and gives a table of RFIMs of several commonly used subsystems.",1. Fisher Information Metric,[0],[0]
Sec. 4 discusses the advantages of using the RFIM as compared to the FIM. Sec. 5 gives an algorithmic framework and proof-of-concept experiments on neural network optimization.,1. Fisher Information Metric,[0],[0]
Sec. 6 presents related works on parameter diagonalization.,1. Fisher Information Metric,[0],[0]
Sec. 7 concludes this work and further hints at perspectives.,1. Fisher Information Metric,[0],[0]
"Consider a MLP x θ1−→ h1 · · ·hL−1 θL−−→ y, whose statistical model is the following conditional distribution
p(y |x,Θ) = ∑
h1,··· ,hL−1
p(h1 |x,θ1) · · · p(y |hL−1,θL).
",2. Natural Gradient: Review and Insights,[0],[0]
"The often intractable sum over h1, · · · ,hL−1 can be get rid off by deteriorating p(h1 |x,θ1), · · · , p(hL−1 |hL−2,θL−1) to Dirac’s deltas δ, and letting merely the last layer p(y |hL−1,θL) be stochastic.",2. Natural Gradient: Review and Insights,[0],[0]
"Other models such as restricted Boltzmann machines (Nair & Hinton, 2010; Montavon & Müller, 2012), deep belief networks (Hinton et al., 2006), dropout (Wager et al., 2013), and variational autoencoders (Kingma & Welling, 2014) do consider the hi’s to be stochastic.
",2. Natural Gradient: Review and Insights,[0],[0]
"The tensor metric of the neuromanifold (Amari, 1995) M, consisting of all MLPs with the same architecture but different parameter values, is locally defined by the FIM.",2. Natural Gradient: Review and Insights,[0],[0]
"Because a MLP corresponds to a con-
ditional distribution, its FIM is a function of the input x. By taking an empirical average over the input samples {xk}nk=1, the FIM of a MLP can be expressed as IΘ(Θ) = 1n",2. Natural Gradient: Review and Insights,[0],[0]
"∑n k=1Ep(y |xk,Θ) [ ∂lk ∂Θ ∂lk ∂Θᵀ ] , where lk(Θ) = log p(y |xk, Θ) denotes the conditional log-likelihood function wrt xk.
",2. Natural Gradient: Review and Insights,[0],[0]
"To understand the meaning of the Riemannian metric IΘ(Θ), it measures the intrinsic difference between two nearby neural networks around Θ ∈ M. A learning step can be regarded as a tiny displacement δΘ",2. Natural Gradient: Review and Insights,[0],[0]
onM.,2. Natural Gradient: Review and Insights,[0],[0]
"According to the FIM, the infinitesimal square distance
〈δΘ, δΘ〉IΘ(Θ) = 1
n n∑ k=1 Ep(y |xk,Θ)
[( δΘᵀ
∂lk ∂Θ )",2. Natural Gradient: Review and Insights,[0],[0]
"2] (1)
measures how much δΘ",2. Natural Gradient: Review and Insights,[0],[0]
"(with a radius constraint) is statistically along ∂l∂Θ , or equivalently how much δΘ affects intrinsically the conditional distribution p(y |x, Θ).
",2. Natural Gradient: Review and Insights,[0.9523965121982981],"['One possible explanation is that the initial meta training loss of small training steps (e.g., (a)) is still very high as you can see from the log y-axis whereas the one with large training step, e.g., (d) is much lower.']"
Consider the negative log-likelihood function L(Θ) =,2. Natural Gradient: Review and Insights,[0],[0]
"− ∑n k=1 log p(yk |xk,Θ) wrt the observed pairs {(xk,yk)}nk=1, we try to minimize the loss while maintaining a small learning step size 〈δΘ, δΘ〉IΘ(Θ) on M. At Θt ∈ M, the target is to minimize wrt δΘ",2. Natural Gradient: Review and Insights,[0],[0]
"the Lagrange function
L(Θt + δΘ)",2. Natural Gradient: Review and Insights,[0],[0]
"+ 1
2γ 〈δΘ, δΘ〉IΘ(Θt)
",2. Natural Gradient: Review and Insights,[0],[0]
"≈ L(Θt) + δΘᵀ 5Θ L(Θt) + 1
2γ δΘᵀIΘ(Θt)δΘ,
where γ > 0 is a learning rate.",2. Natural Gradient: Review and Insights,[0],[0]
"The optimal solution of the above quadratic optimization gives a learning step
δΘt = −γI−1Θ (Θt)5Θ L(Θt).
",2. Natural Gradient: Review and Insights,[0],[0]
"In this update procedure, ∇̃ΘL(Θ) = I−1Θ (Θ)5Θ L(Θ) replaces the role of the usual gradient ∇ΘL(Θ) and is called the natural gradient (Amari, 1997).
",2. Natural Gradient: Review and Insights,[0],[0]
"Although the FIM depends on the chosen parameterization, the natural gradient is invariant to reparameterization.",2. Natural Gradient: Review and Insights,[0],[0]
Let Λ be another coordinate system and J be the Jacobian matrix of the mapping,2. Natural Gradient: Review and Insights,[0],[0]
"Θ→ Λ. Then we have
I−1Θ (Θ)5Θ L(Θ) =",2. Natural Gradient: Review and Insights,[0],[0]
"(J ᵀIΛ(Λ)J)−1 Jᵀ 5Λ L(Λ)
",2. Natural Gradient: Review and Insights,[0],[0]
"= J−1I−1Λ (Λ)5Λ L(Λ),
showing that ∇̃ΘL(Θ) and ∇̃ΛL(Λ) are the same dynamic up to coordinate transformation.",2. Natural Gradient: Review and Insights,[0],[0]
"As the learning rate γ is not infinitesimal in practice, natural gradient descent actually depends on the coordinate system (see e.g. Martens 2014).",2. Natural Gradient: Review and Insights,[0],[0]
"Other intriguing properties of natural gradient optimization lie in being free from getting trapped in plateaux of the error surface, and attaining Fisher efficiency in online learning (see Sec. 4 Amari 1998).
",2. Natural Gradient: Review and Insights,[0],[0]
"MΘ
Θ yx
Mθ1
x
x+ ∆x
θ1x
Mθ2h1
h1 + ∆h1
θ2h1
Mθ3
h2
h2 + ∆h2
θ3h2",2. Natural Gradient: Review and Insights,[0],[0]
"y
Model:
Manifold:
Computational graph:
Metric:
Θ
Θ I(Θ)
θ3 h2
θ3
h2
gy(θ3)
",2. Natural Gradient: Review and Insights,[0],[0]
"θ2 h1
θ2
h1
gh2(θ2)
θ1
θ1 gh1(θ1)
p(y |Θ,x) =",2. Natural Gradient: Review and Insights,[0],[0]
"∑ h1 ∑ h2 p(h1 |θ1,x) p(h2 |θ2,h1) p(y |θ3,h2)
",2. Natural Gradient: Review and Insights,[0],[0]
Figure 1.,2. Natural Gradient: Review and Insights,[0],[0]
(left),2. Natural Gradient: Review and Insights,[0],[0]
The traditional global geometry of a MLP; (right) information geometry of subsystems.,2. Natural Gradient: Review and Insights,[0],[0]
The gray and blue meshes show that the subsystem geometry is dynamic when the reference variable makes a tiny move.,2. Natural Gradient: Review and Insights,[0],[0]
"The square under the (sub-)system means the (R-)FIM is computed by (i) computing the FIM in the traditional way wrt all free parameters that affect the system output; (ii) choosing a sub-block that contains only the internal parameters of the (sub-)system and regarding the remaining variables as the reference.
",2. Natural Gradient: Review and Insights,[0],[0]
"For the sake of simplicity, we do not discuss singular FIMs with a subset of parameters having zero metric.",2. Natural Gradient: Review and Insights,[0],[0]
"This set of parameters forms an analytic variety (Watanabe, 2009), and technically the MLP as a statistical model is said to be non-regular (and the parameter Θ is not identifiable).",2. Natural Gradient: Review and Insights,[0],[0]
"The natural gradient has been extended (Thomas, 2014) to cope with singular FIMs having positive semi-definite matrices by taking the Moore-Penrose pseudo-inverse (that coincides with the inverse matrix for full rank matrices).
",2. Natural Gradient: Review and Insights,[0],[0]
"In the family of 2nd-order optimization methods, a fuzzy line can be drawn from the natural gradient and alternative methods such as the Hessian-free optimization (Martens, 2010).",2. Natural Gradient: Review and Insights,[0],[0]
"By definition, the FIM is a property of the parameter space which is independent or weakly dependent on the input samples.",2. Natural Gradient: Review and Insights,[0],[0]
"For example, the FIM of a MLP is independent of {yi}.",2. Natural Gradient: Review and Insights,[0],[0]
"In contrast, the Hessian (or related concepts such as the Gauss-Newton matrix, Martens 2014) is a property of the learning cost function wrt the input samples.
",2. Natural Gradient: Review and Insights,[0],[0]
"Bonnabel (Bonnabel, 2013) proposed to use the Riemannian exponential map to define a gradient descent step, thus ensuring to stay on the manifold for any chosen learning rate.",2. Natural Gradient: Review and Insights,[0],[0]
Convergence is proven for Hadamard manifolds (of negative curvatures).,2. Natural Gradient: Review and Insights,[0],[0]
"However, it is not mathematically tractable to express the exponential map of hierarchical model manifolds like the neuromanifold.",2. Natural Gradient: Review and Insights,[0],[0]
"In general, for large parametric systems, it is impossible to diagonalize or decorrelate all the parameters, so that we split instead all random variables into three parts θf , θ and h.",3. RFIM: Definition and Expressions,[0],[0]
We examine their intuitive meanings before giving the formal definition.,3. RFIM: Definition and Expressions,[0],[0]
"The reference, θf , consists of the majority of the random variables that are considered fixed (therefore allowing us to simplify the analysis).",3. RFIM: Definition and Expressions,[0],[0]
This is in analogy to the notion of a reference frame in physics.,3. RFIM: Definition and Expressions,[0],[0]
"θ is the
subsystem parameters, resembling the long-term memory adapting slowly to the observations (e.g. neural network weights).",3. RFIM: Definition and Expressions,[0],[0]
The response h is a random variable that reacts to the variations of θ.,3. RFIM: Definition and Expressions,[0],[0]
"Usually, h is the output of the subsystem that is connected to neighbour subsystems (e.g. hidden layer outputs).",3. RFIM: Definition and Expressions,[0],[0]
"Formally, a subsystem which factorizes the learning machine is characterized by the conditional distribution p(h |θ,θf ), where θ can be estimated based on h and θf .",3. RFIM: Definition and Expressions,[0],[0]
We make the following definition.,3. RFIM: Definition and Expressions,[0],[0]
Definition 1 (RFIM).,3. RFIM: Definition and Expressions,[0],[0]
"Given θf , the RFIM 1 of θ wrt h is
gh (θ |θf )",3. RFIM: Definition and Expressions,[0],[0]
"def = Ep(h | θ, θf ) [ ∂
∂θ log p(h |θ, θf )
∂
∂θᵀ log p(h |θ, θf )
] ,
or simply gh (θ), corresponding to the estimation of θ based on observations of h given θf .
",3. RFIM: Definition and Expressions,[0],[0]
"For example, consider a MLP.",3. RFIM: Definition and Expressions,[0],[0]
"If we choose θf to be the input features x, choose h to be the final output y, and choose θ to be all the network weights Θ, then the RFIM becomes the FIM: I(Θ) = gy(Θ |x).
",3. RFIM: Definition and Expressions,[0],[0]
"More generally, we can choose the response h to be other than the observables to compute the Fisher information of subsystems, especially dynamically during the learning of the global machine.",3. RFIM: Definition and Expressions,[0],[0]
"To see the meaning of the RFIM, similar to eq.",3. RFIM: Definition and Expressions,[0],[0]
"(1), the infinitesimal square distance 〈δθ, δθ〉gh(θ) =",3. RFIM: Definition and Expressions,[0],[0]
"Ep(h | θ, θf ) [( δθᵀ ∂∂θ log p(h |θ, θf )
)2] measures how much δθ impacts intrinsically the stochastic mapping θ → h which features the subsystem.",3. RFIM: Definition and Expressions,[0],[0]
"We have the following proposition following definition 1.
",3. RFIM: Definition and Expressions,[0],[0]
Proposition 2 (Relative Geometry Consistency).,3. RFIM: Definition and Expressions,[0],[0]
"If θ1 consists of a subset of θ2 so that θ2 = (θ1, θ̃1), then ∀θ̃1, Mθ1 with the metric gh(θ1 | θ̃1) has exactly the same Rie-
1We use the same term “relative FIM” (Zegers, 2015) with a different definition.
",3. RFIM: Definition and Expressions,[0],[0]
"mannian metric with the sub-manifold {θ2 ∈ Mθ2 : θ̃1 is fixed} induced by the ambient metric gh (θ2).
",3. RFIM: Definition and Expressions,[0],[0]
"When the response h is chosen, then different splits of (θ,θf ) are consistent with the same ambient geometry.
",3. RFIM: Definition and Expressions,[0],[0]
"Figure 1 shows the traditional global geometry of a learning system, where the curvature is defined by the learner’s parameter sensitivity to the external environment (x and y), as compared to the information geometry of subsystems, where the curvature is defined by the parameter sensitivity wrt hidden interface variables h.",3. RFIM: Definition and Expressions,[0],[0]
"The two-colored meshes show that the geometry structure is dynamic and varies with the reference variable θf .
",3. RFIM: Definition and Expressions,[0],[0]
"One should not confuse the RFIM with the diagonal blocks of the FIM (Kurita, 1994).",3. RFIM: Definition and Expressions,[0],[0]
Both their meanings and expressions are different.,3. RFIM: Definition and Expressions,[0],[0]
The RFIM is computed by integrating out the hidden response variables h.,3. RFIM: Definition and Expressions,[0],[0]
The FIM is always computed by integrating out the observables x and y.,3. RFIM: Definition and Expressions,[0],[0]
Hence the RFIM is a more general concept and includes the FIM as a special case.,3. RFIM: Definition and Expressions,[0],[0]
"This highlights a main difference with the backpropagated metric (Ollivier, 2013), which essentially considers parameter sensitivity wrt the final output.",3. RFIM: Definition and Expressions,[0],[0]
"Despite the fact that the FIMs of small parametric structures such as single neurons was studied (Amari, 1997), we are not looking at a small single-component system but a component embedded in a large system, targeting at improving the large system.
",3. RFIM: Definition and Expressions,[0],[0]
"In the following we provide a short table of commonly used RFIMs for future reference (the RFIMs listed are mostly straightforward from definition 1, with detailed derivations given in the supplementary material).",3. RFIM: Definition and Expressions,[0],[0]
This is meaningful since the RFIM is a new concept.,3. RFIM: Definition and Expressions,[0],[0]
We also want to demonstrate these simple closed form expressions without any approximations.,3. RFIM: Definition and Expressions,[0],[0]
We start from the RFIM of single neuron models.,3.1. RFIMs of One Neuron,[0],[0]
"Consider a stochastic neuron with input x and weights w. After a nonlinear activation function f , the output y is randomized surrounding the mean f(wᵀx̃) with a variance.",3.1. RFIMs of One Neuron,[0],[0]
"Throughout this paper x̃ = (xᵀ, 1)ᵀ denotes the augmented vector of x (homogeneous coordinates) so that wᵀx̃ contains a bias term, and a general linear transformation can be written simply asAx̃.
Using x as the reference, the RFIM of w with respect to y has a common form gy(w |x)",3.1. RFIMs of One Neuron,[0],[0]
"= νf (w,x)x̃x̃ᵀ, where νf (w,x) is a positive coefficient with large values in the linear region, or the effective learning zone of the neuron.",3.1. RFIMs of One Neuron,[0],[0]
"This agrees with early studies on single neuron FIMs (Amari, 1997; Kurita, 1994).
",3.1. RFIMs of One Neuron,[0],[0]
"If f(t) = tanh(t) is the hyperbolic tangent func-
tion, then νf (w,x) = sech2(wᵀx̃), where sech(t) = 2 exp(t)+exp(−t) is the hyperbolic secant function.",3.1. RFIMs of One Neuron,[0],[0]
"Similarly, if f(t) = sigm(t) is the sigmoid function, then νf (w,x) = sigm (w ᵀx̃)",3.1. RFIMs of One Neuron,[0],[0]
"[ 1− sigm (wᵀx̃) ] .
",3.1. RFIMs of One Neuron,[0],[0]
"If f is defined by Parametric Rectified Linear Unit (PReLU) (He et al., 2015), which includes Rectified Linear Unit (ReLU) (Nair & Hinton, 2010) as a special case, so that f(t) = t (t ≥ 0), f(t) = ιt (t < 0), 0 ≤ ι < 1, then under certain approximations (see supplementary material)
",3.1. RFIMs of One Neuron,[0],[0]
"νf (w,x) =
[ ι+ (1− ι)sigm",3.1. RFIMs of One Neuron,[0],[0]
"( 1− ι ω wᵀx̃ )]2 ,
where ω > 0 is a hyper-parameter (e.g. ω = 1).
",3.1. RFIMs of One Neuron,[0],[0]
"For the exponential linear unit (ELU) (Clevert et al., 2015), f(t) = t (t ≥ 0), f(t) = α (exp(t)− 1) (t < 0), where α > 0 is a hyper-parameter.",3.1. RFIMs of One Neuron,[0],[0]
"We get
νf (w,x) =",3.1. RFIMs of One Neuron,[0],[0]
{ 1 if wᵀx̃ ≥ 0 α2 exp (2wᵀx̃),3.1. RFIMs of One Neuron,[0],[0]
if wᵀx̃ < 0.,3.1. RFIMs of One Neuron,[0],[0]
Let D denote the dimensionality of the corresponding variable.,3.2. RFIM of One Layer,[0],[0]
"A linear layer with input x, connection weights W =",3.2. RFIM of One Layer,[0],[0]
"[ w1, · · · ,wDy ] , and stochastic output y can be represented by y ∼ G(W ᵀx̃, σ2I), where I is the identity matrix, and σ is the scale of the observation noise, and G(µ,Σ) is a multivariate Gaussian distribution with mean µ and covariance matrix Σ. We vectorize W by stacking its columns {wi}.",3.2. RFIM of One Layer,[0],[0]
"Then gy(W |x) is a tensor of size (Dx + 1)Dy× (Dx + 1)Dy , given by gy(W |x)",3.2. RFIM of One Layer,[0],[0]
"= diag [x̃x̃ᵀ, · · · , x̃x̃ᵀ], where diag(·) means the (block) diagonal matrix constructed by the given matrix entries.
",3.2. RFIM of One Layer,[0],[0]
"A nonlinear layer increments a linear layer by adding an element-wise activation function applied on W ᵀx̃, and then randomized wrt the choice of the neuron.",3.2. RFIM of One Layer,[0],[0]
"By definition 1, its RFIM is given by
gy (",3.2. RFIM of One Layer,[0],[0]
W |x) =,3.2. RFIM of One Layer,[0],[0]
"diag [ νf (w1,x)x̃x̃ ᵀ, · · · , νf (wm,x)x̃x̃ᵀ ] , (2)
where νf (wi,x) is given in Subsec.",3.2. RFIM of One Layer,[0],[0]
"3.1.
",3.2. RFIM of One Layer,[0],[0]
"A softmax layer, which often appears as the last layer of a MLP, is given by y ∈ {1, . . .",3.2. RFIM of One Layer,[0],[0]
",m}, where p(y) = ηy = exp(wyx̃)∑m i=1 exp(wix̃) .",3.2. RFIM of One Layer,[0],[0]
"Its RFIM is a dense matrix given by
gy(W )",3.2. RFIM of One Layer,[0],[0]
=  (η1 − η21)x̃x̃ᵀ · · · −η1ηmx̃x̃ᵀ −η2η1x̃x̃ᵀ · · · −η2ηmx̃x̃ᵀ ... . .,3.2. RFIM of One Layer,[0],[0]
".
...",3.2. RFIM of One Layer,[0],[0]
−ηmη1x̃x̃ᵀ · · · (ηm − η2m)x̃x̃ᵀ  .,3.2. RFIM of One Layer,[0],[0]
Notice that its i’th diagonal block (ηi − η2i ),3.2. RFIM of One Layer,[0],[0]
x̃x̃ᵀ resembles the RFIM of a single sigm neuron.,3.2. RFIM of One Layer,[0],[0]
"By eq. (2), the one-layer RFIM is a product metric (Jost, 2011) and does not consider the inter-neuron correlations, which must be obtained by looking at a larger subsystem.",3.3. RFIM of Two Layers,[0],[0]
"Consider a two-layer model with stochastic output y around the mean vector f(Cᵀh̃), where h = f (W ᵀx̃).",3.3. RFIM of Two Layers,[0],[0]
"For simplicity, we ignore inter-layer correlations between the first layer and the second layer and focus on the interneuron correlations within the first layer.",3.3. RFIM of Two Layers,[0],[0]
"To do this, both x and C are considered as references to compute the RFIM of W .",3.3. RFIM of Two Layers,[0],[0]
"By definition 1, gy(W |x,C) =",3.3. RFIM of Two Layers,[0],[0]
"[Gij ]Dh×Dh and each block has the form
Gij = Dy∑ l=1 cilcjlνf (cl,h)νf (wi,x)νf (wj ,x)x̃x̃ ᵀ.
Now that we have the one-layer and two-layer RFIMs, we can either split a given feed-forward neural network into one-layer subsystems or into two-layer subsystems.",3.3. RFIM of Two Layers,[0],[0]
"A trade-off is that using a larger subsystem entails greater analytical and computational difficulty, although it could more accurately model the global system dynamics.",3.3. RFIM of Two Layers,[0],[0]
"In the extreme case, the FIM is obtained if the whole system is considered as one single subsystem.",3.3. RFIM of Two Layers,[0],[0]
This section discusses the theoretical advantages of the RFIM over the FIM.,4. RFIM: Key Advantages,[0.9627195371231968],['This increases the difficulty of solving the system.']
"Consider wlog a MLP with Bernoulli outputs y ∈ {0, 1}m, whose mean µ is a deterministic function depending on the input x and the network parameters Θ. By Sec. 2, the FIM of the MLP can be computed as (see supplementary for proof)
I(Θ)",4. RFIM: Key Advantages,[0],[0]
= 1 n n∑ i=1,4. RFIM: Key Advantages,[0],[0]
"m∑ j=1
1 µj(xi)(1− µj(xi))",4. RFIM: Key Advantages,[0],[0]
"∂µj(xi) ∂Θ ∂µj(xi) ∂Θᵀ .
",4. RFIM: Key Advantages,[0],[0]
(3) Therefore rank(I(Θ)),4. RFIM: Key Advantages,[0],[0]
≤,4. RFIM: Key Advantages,[0],[0]
nm.,4. RFIM: Key Advantages,[0],[0]
The rank of a diagonal block of I(Θ) corresponding to one layer is even smaller.,4. RFIM: Key Advantages,[0],[0]
"In a deep neural network (e.g. Szegedy, Christian et al. 2015), if the sample size n < dim(Θ)/m, then I(Θ) is doomed to be singular.",4. RFIM: Key Advantages,[0],[0]
All methods trying to approximate the FIM suffer from this problem and therefore rely on proper regularizations.,4. RFIM: Key Advantages,[0],[0]
"If the network is decomposed into layers, the RFIM of each subsystem (layer) is given by eq.",4. RFIM: Key Advantages,[0],[0]
(2).,4. RFIM: Key Advantages,[0],[0]
Each sample can contribute maximally 1 to the rank of the neuron-RFIM and can contribute maximally Dy to the rank of the layer-RFIM.,4. RFIM: Key Advantages,[0],[0]
"It only requires maxi{dim(wi)} (the maximum layer width) observations to have a full rank RFIM, where wi is the weight vector of the i’th neuron.",4. RFIM: Key Advantages,[0],[0]
The RFIM is expected to have a much higher rank than the FIM.,4. RFIM: Key Advantages,[0],[0]
Higher rank means less singularity and more information is captured.,4. RFIM: Key Advantages,[0],[0]
"Models that can
be distinguished by the RFIM may be identical in the sense of the FIM.",4. RFIM: Key Advantages,[0],[0]
"Essentially, the RFIM integrates the internal randomness (Bengio, 2013) of the neural system by considering the output of each layer as a random variable.",4. RFIM: Key Advantages,[0],[0]
"In theory, the FIM should also consider stochastic neurons.",4. RFIM: Key Advantages,[0],[0]
"However it requires marginalizing the joint distribution of h1, h2, · · · , y. This makes the already infeasible computation even more challenging.
",4. RFIM: Key Advantages,[0],[0]
"The RFIM is not an approximation of the FIM but is an accurate metric, defining the geometry of θ wrt to its direct response h in the system, or adjacent nodes in a graphical model.",4. RFIM: Key Advantages,[0],[0]
By the example in fig.,4. RFIM: Key Advantages,[0],[0]
"1, gy(θL) of the last layer is exactly the corresponding block in I(Θ): they both characterize how θL affects the mapping hL−1",4. RFIM: Key Advantages,[0],[0]
→ y. They start to diverge from the second to last layer.,4. RFIM: Key Advantages,[0],[0]
"To compute the geometry of θL−1, the RFIM looks at how θL−1 affects the local mapping hL−2 → hL−1, which can be measured reliably regardless of the rest of the system (think of a “debugging” process to separate and measure a single component).",4. RFIM: Key Advantages,[0],[0]
"In contrast, the FIM examines how θL−1 affects the non-local mapping hL−2 → y.",4. RFIM: Key Advantages,[0],[0]
This is a difficult task because it must consider the correlation between different layers.,4. RFIM: Key Advantages,[0],[0]
"As an approximation, the block diagonalized version of the FIM ignores such correlations and therefore faces the loss of accuracy.
",4. RFIM: Key Advantages,[0],[0]
The RFIM makes it possible to maintain global system stability so that the intrinsic variations of different subsystems are balanced during learning.,4. RFIM: Key Advantages,[0],[0]
Consider a set of interconnected subsystems with internal parameters {θl} and the corresponding response variables {hl}.,4. RFIM: Key Advantages,[0],[0]
The RFIM ghl(θl) measures how much the likelihood surface of hl is curved wrt a small learning step δθl.,4. RFIM: Key Advantages,[0],[0]
"By constraining the squared Riemannian distance δθᵀl g
hl(θl)δθl having similar scales, different subsystems will present similar variations during learning.",4. RFIM: Key Advantages,[0],[0]
"Within one subsystem, the learning along sensitive parameter directions is penalized.",4. RFIM: Key Advantages,[0],[0]
"Among different subsystems, the learning of sensitive subsystems is penalized.",4. RFIM: Key Advantages,[0],[0]
"Globally, the inter-subsystem stochastic connections have similar variance, maintaining a stable reference system and achieving efficient learning.",4. RFIM: Key Advantages,[0],[0]
"This is similar to the idea of batch normalization (BN) (Ioffe & Szegedy, 2015) but has a deeper theoretical foundation.
",4. RFIM: Key Advantages,[0],[0]
"Formally, we have the following theorem.
",4. RFIM: Key Advantages,[0],[0]
Theorem 3.,4. RFIM: Key Advantages,[0],[0]
"Consider a learning system represented by a joint distribution p(x,h) of x (observables) and h (hidden variables which connect subsystems).",4. RFIM: Key Advantages,[0],[0]
"The joint FIM J (Θ) = Ep ( log p(x,h |Θ) ∂Θ",4. RFIM: Key Advantages,[0],[0]
"log p(x,h |Θ) ∂Θᵀ ) has a block diagonal form.",4. RFIM: Key Advantages,[0],[0]
"Each block isEp(gh(θ)), where θ is the parameters within a subsystem and h is its response variables to neighour subsystems.
",4. RFIM: Key Advantages,[0],[0]
"The global correspondence of the local RFIM is the joint
FIM.",4. RFIM: Key Advantages,[0],[0]
"By theorem 3, the square distance dΘᵀJ (Θ)dΘ = Ep( ∑ l dθ ᵀ l g hl(θl)dθl) measures the system variance, including both the observables x and the hidden variables h.",4. RFIM: Key Advantages,[0],[0]
An intrinsic trade-off between the RFIM and the FIM is learning system stability versus efficiency.,4. RFIM: Key Advantages,[0],[0]
"Normalizing the FIM is more efficient because it helps to achieve Fisher efficiency (Amari, 1998).",4. RFIM: Key Advantages,[0],[0]
"Normalizing the RFIM is more stable since the hidden variations are bounded, which only guarantees subsystem Fisher efficiency characterized by the Cramér-Rao lower bound of local parameters.",4. RFIM: Key Advantages,[0],[0]
The traditional non-parametric way of applying natural gradient requires re-calculating the FIM and solving a large linear system in each learning step.,5. Relative Natural Gradient Descent,[0],[0]
"Besides the huge computational cost, it has a large approximation error.",5. Relative Natural Gradient Descent,[0],[0]
"For example during online learning, a mini-batch of samples cannot faithfully reflect the “true” geometry, which has to integrate the risk of sample variations.",5. Relative Natural Gradient Descent,[0],[0]
"That is, the FIM of a mini-batch is likely to be singular or poorly conditioned.
",5. Relative Natural Gradient Descent,[0],[0]
"A recent series of efforts (Montavon & Müller, 2012; Raiko et al., 2012; Desjardins et al., 2015) are gearing towards a parametric approach to applying natural gradient, which memorizes and learns a geometry.",5. Relative Natural Gradient Descent,[0],[0]
"For example, natural neural networks (Desjardins et al., 2015) augment each layer with a redundant linear layer, and let these linear layers parametrize the geometry of the neural manifold.
",5. Relative Natural Gradient Descent,[0],[0]
"By dividing the learning system into subsystems, the RFIM potentially gives a systematical implementation of parametric natural gradient descent.",5. Relative Natural Gradient Descent,[0],[0]
"The memory complexity of storing the Riemannian metric has been reduced from O(D2) to O( ∑ iD 2 i ), where Di = dim(wi) is the size of the i’th neuron.",5. Relative Natural Gradient Descent,[0],[0]
"Consider there are M neurons in total, then the memory cost is reduced by a factor of M .",5. Relative Natural Gradient Descent,[0],[0]
"The computational complexity has been reduced from O(D%) (% ≈ 2.373, Williams 2012) to O( ∑ iD % i ).",5. Relative Natural Gradient Descent,[0],[0]
"Optimization based on RFIM is called Relative Natural Gradient Descent (RNGD).
",5. Relative Natural Gradient Descent,[0],[0]
"The good performance of batch normalization (Ioffe & Szegedy, 2015) provides an empirical support for the RFIM.",5. Relative Natural Gradient Descent,[0],[0]
"Basically, BN uses an inter-sample normalization layer to transform the layer input x to z with zero mean and unit variance and thus reduces “internal covariate shift”.",5. Relative Natural Gradient Descent,[0],[0]
"In a typical case, above this normalization layer is a linear layer given by y = W ᵀz̃.",5. Relative Natural Gradient Descent,[0],[0]
"If each dimension of z is normalized, then the diagonal blocks of the linear layer RFIM gy(W )",5. Relative Natural Gradient Descent,[0],[0]
"= diag[z̃z̃ᵀ, · · · , z̃z̃ᵀ] become a covariance matrix with identity diagonal entries (after taking an empirical average).",5. Relative Natural Gradient Descent,[0],[0]
"This gives the coordinate system W a well conditioned RFIM for efficient learning.
5.1.",5. Relative Natural Gradient Descent,[0],[0]
"RNGD with a relu MLP
",5. Relative Natural Gradient Descent,[0],[0]
This subsection builds a proof-of-concept experiment on MLP optimization.,5. Relative Natural Gradient Descent,[0],[0]
We partition the MLP into layers (one layer consists of a linear layer plus an element-wise nonlinear activation function) as the subsystems.,5. Relative Natural Gradient Descent,[0],[0]
"By eq. (2), the RFIM of layer l (l = 1, · · · , L) with input hl−1 (h0 = x) and weights {wl1, · · · ,wlml} is
diag [ νf (wl1,hl−1)h̃l−1h̃ ᵀ l−1, · · · , νf (wlml ,hl−l)h̃l−1h̃ ᵀ l−1 ] .
",5. Relative Natural Gradient Descent,[0],[0]
The subsystem stability during one learning step δw can be measured geometrically by∑L l=1 ∑ml i=1,5. Relative Natural Gradient Descent,[0],[0]
"νf (wli,hl−1)(δw ᵀ lih̃l−1)
2.",5. Relative Natural Gradient Descent,[0],[0]
"Using this term as the geometric cost (the Lagrange term) in the trust region approach in Sec. 2, we get the following RNGD method.",5. Relative Natural Gradient Descent,[0],[0]
"In a stochastic gradient descent scenario, each neuron i in layer l is updated by
wnewli ← woldli −G−1li ∂E
∂wli ,
where E is the cost function and Gli is a learned metric.",5. Relative Natural Gradient Descent,[0],[0]
"The consideration is that a mini-batch of samples do not contain enough information to compute the RFIM, which should be averaged over all training samples.",5. Relative Natural Gradient Descent,[0],[0]
"Therefore, for the i’th neuron in layer l, Gli is initialized to identity, and is updated based on
Gnewli ← (1− λ)Goldli + λνf (wli,hl−1)h̃l−1h̃ ᵀ",5. Relative Natural Gradient Descent,[0],[0]
l−1,5. Relative Natural Gradient Descent,[0],[0]
+,5. Relative Natural Gradient Descent,[0],[0]
"I,
where > 0 is a hyper-parameter to avoid singularity caused by small sample size, and the average is taken over all samples in a mini-batch, and λ is a learning rate.",5. Relative Natural Gradient Descent,[0],[0]
"In theory, λ should be gradually reduced to zero to guarantee the convergence of this geometry learning.",5. Relative Natural Gradient Descent,[0],[0]
"To avoid solving a linear system in each iteration, every T iterations we recompute and store G−1li based on the most updated Gli.",5. Relative Natural Gradient Descent,[0],[0]
"In the next T iterations, this G−1li will be used as an approximation of the inverse RFIM.",5. Relative Natural Gradient Descent,[0],[0]
"For the input layer which scales with the number of input features, and the final softmax layer, we apply instead the RFIM of the corresponding linear layer to improve the computational efficiency.
",5. Relative Natural Gradient Descent,[0],[0]
We compare different optimizers on classifying MNIST digits.,5. Relative Natural Gradient Descent,[0],[0]
"The network has shape 784-80-80-80-10, with relu activation units, a final soft-max layer, and uses the persample average cross-entropy with L2-regularization as the learning cost function.",5. Relative Natural Gradient Descent,[0],[0]
"We experiment on two different architectures: one is a plain MLP (PLAIN); the other has a batch normalization layer after each hidden layer (BNA), where a rescaling parameter is applied to ensure enough flexibility of the parametric structure (Ioffe & Szegedy, 2015).",5. Relative Natural Gradient Descent,[0],[0]
"For simplicity, the architecture, mini-batch size (50), and L2 regularization strength (10−3) are fixed to be the same for all compared methods.",5. Relative Natural Gradient Descent,[0],[0]
"The observations are consistent when these configurations vary.
",5. Relative Natural Gradient Descent,[0],[0]
Figure 2 shows the learning curves of different methods.,5. Relative Natural Gradient Descent,[0],[0]
SGD is stochastic gradient descent.,5. Relative Natural Gradient Descent,[0],[0]
"ADAM is the Adam optimizer (Kingma & Ba, 2014) with β1 = 0.9, β2 = 0.999 and = 10−8.",5. Relative Natural Gradient Descent,[0],[0]
"Our RNGD is implemented by modifying TensorFlow’s (Abadi, Martı́n",5. Relative Natural Gradient Descent,[0],[0]
"et al., 2015) SGD optimizer.",5. Relative Natural Gradient Descent,[0],[0]
"We set empirically T = 100, λ = 0.005 and ω = 1.
RNGD presents a sharper learning curve and better generalization, especially when it is combined with BN.",5. Relative Natural Gradient Descent,[0],[0]
"In this case, the final tranining error of RNGD is slightly larger than ADAM because by validation it favors a larger learning rate, which is applied on the neural network weights (based on RNGD) and BN parameters (based on SGD).",5. Relative Natural Gradient Descent,[0],[0]
"For the ReLU activation, νf (wi,x) is approximately binary, emphasizing such informative samples with wᵀi x̃ > 0, which are the ones contributing to the learning of wi with non-zero gradient values.",5. Relative Natural Gradient Descent,[0],[0]
Each output neuron has a different subset of informative samples.,5. Relative Natural Gradient Descent,[0],[0]
"RNGD normalizes x differently wrt different output neurons, so that the in-
formative samples for each output neuron are centered and decorrelated.
",5. Relative Natural Gradient Descent,[0],[0]
"In the above experiment, RNGD’s computational time per each epoch is roughly 4 ∼ 10 times more than SGD and ADAM on a modern graphic card.",5. Relative Natural Gradient Descent,[0],[0]
Therefore in terms of wall clock time RNGD does not show advantages.,5. Relative Natural Gradient Descent,[0],[0]
This can be improved by more efficient implementations with low rank approximation techniques and early stopping.,5. Relative Natural Gradient Descent,[0],[0]
Our RNGD prototype hints at a promising direction to develop scalable 2nd-order deep learning optimizers based on the RFIM.,5. Relative Natural Gradient Descent,[0],[0]
One may ponder whether we can always find a suitable parameterization that yields a diagonal FIM that is straightforward to invert.,6. Related Works on FIM Diagonalization,[0],[0]
This fundamental problem of parameter orthogonalization was first investigated by Jeffreys (1998) for decorrelating the parameters of interest from the nuisance parameters.,6. Related Works on FIM Diagonalization,[0],[0]
"Fisher diagonalization yields parameter orthogonalization (Cox & Reid, 1987), and is proved useful when estimating Θ̂ using a maximum likelihood estimator (MLE) that is asymptotically normally distributed, Θ̂n ∼ G(Θ, I−1(Θ)/n), and efficient since the variance of the estimator matches the Cramér-Rao lower bound.",6. Related Works on FIM Diagonalization,[0],[0]
"Using the chain rule, this amounts to find a suitable parameterization Ω = Ω(Θ) satisfying∑
",6. Related Works on FIM Diagonalization,[0],[0]
"i,j
E
[ ∂2l
∂Θi∂Θj ] ∂Θi",6. Related Works on FIM Diagonalization,[0],[0]
"∂Ωk ∂Θj ∂Ωl = 0, ∀k 6=",6. Related Works on FIM Diagonalization,[0],[0]
"l.
Thus in general, we end up with ( D 2 ) = D(D−1)2 (nonlinear) partial differential equations to satisfy (Huzurbazar, 1950).",6. Related Works on FIM Diagonalization,[0],[0]
"Therefore, in general there is no solution when( D 2 )",6. Related Works on FIM Diagonalization,[0],[0]
"> D, that is when D > 3.",6. Related Works on FIM Diagonalization,[0],[0]
"When D = 2, the single differential equation is usually solvable and tractable, and the solution may not be unique: For example, Huzurbazar (1950) reports two orthogonalization schemes for the location-scale families { 1σp0( x−µ σ )} that include the Gaussian family and the Cauchy family.",6. Related Works on FIM Diagonalization,[0],[0]
"Sometimes, the structure of the differential equation system yields a solution: For example, Jeffreys (1998) reported a parameter orthogonalization for Pearson’s distributions of type I which is of orderD = 4.",6. Related Works on FIM Diagonalization,[0],[0]
"Cox and Reid (1987) further investigated this topic with application to conditional inference, and provide examples (including the Weibull distribution).
",6. Related Works on FIM Diagonalization,[0],[0]
"From the viewpoint of geometry, the FIM induces a Riemannian manifold with metric tensor g(Θ) = I(Θ).",6. Related Works on FIM Diagonalization,[0],[0]
"When the FIM may be degenerate, this yields a pseudoRiemannian manifold (Thomas, 2014).",6. Related Works on FIM Diagonalization,[0],[0]
"In differential geometry, orthogonalization amounts to transforming the square length infinitesimal element gijdΘiΘj of a Riemannian geometry into an orthogonal system ω with match-
ing square length infinitesimal element ΩiidΩ2i .",6. Related Works on FIM Diagonalization,[0],[0]
"However, such a global orthogonal metric does not exist (Huzurbazar, 1950)",6. Related Works on FIM Diagonalization,[0],[0]
"when D > 3 for an arbitrary metric tensor, although interesting Riemannian parameterization structures may be derived in Riemannian 4D geometry (Grant & Vickers, 2009).
",6. Related Works on FIM Diagonalization,[0],[0]
"For NEFs, the FIM can be made block-diagonal easily by using the mixed coordinate system (Amari, 2016) (Θ1:k,Hk+1:D), where H = Ep[t(x)] = ∇F (Θ) is the moment parameter, for any k ∈ {1, ..., D − 1}, where vb:e denotes the subvector (vb, ..., ve)ᵀ of v. The geometry of NEFs is a dually flat structure (Amari, 2016) induced by the convex mgf, the potential function.",6. Related Works on FIM Diagonalization,[0],[0]
"It defines a dual affine coordinate systems ei = ∂i = ∂∂Hi and ej = ∂
j = ∂∂Θj that are orthogonal: 〈ei, ej〉 = δij , where δij = 1 iff i = j and δij = 0 otherwise.",6. Related Works on FIM Diagonalization,[0],[0]
Hence the FIM has two diagonal blocks.,6. Related Works on FIM Diagonalization,[0],[0]
"Those dual affine coordinate systems are defined up to an affine invertible transformation: Θ̃ = AΘ + b, H̃ = A−1H + c.",6. Related Works on FIM Diagonalization,[0],[0]
"In particular, for any order-2 NEF (D = 2), we can always obtain two mixed parameterizations (Θ1, H2) or (H1,Θ2).
",6. Related Works on FIM Diagonalization,[0],[0]
The RFIM contributes another line of thought in parameter diagonalization.,6. Related Works on FIM Diagonalization,[0],[0]
"We investigate the Fisher information of hidden variables, or internal interfaces in the learning machine.",6. Related Works on FIM Diagonalization,[0],[0]
"This is novel since the majority of previous works concentrate on the FIM of the observables, or the external interface of the machine.",6. Related Works on FIM Diagonalization,[0],[0]
"From a causality perspective, we factor out the main cause (parameters within the subsystem) of the response variable with a direct action-reaction relationship, and regard the remaining parameters as a reference that can be easily estimated by the empirical distribution.",6. Related Works on FIM Diagonalization,[0],[0]
"This simplification may lead to broader applications of Fisher information in machine learning.
",6. Related Works on FIM Diagonalization,[0],[0]
"The particular case of a mixed coordinate system (that is not an affine coordinate system) induces in information geometry (Amari, 2016) a dual pair of orthogonal e- and morthogonal foliations.",6. Related Works on FIM Diagonalization,[0],[0]
"Our splits in RFIMs consider general non-orthogonal foliations that provide the factorization decompositions of the whole manifold into submanifolds, that are the leaves of the foliation (see section 3.7 of Amari & Nagaoka 2000).",6. Related Works on FIM Diagonalization,[0],[0]
We investigate local structures of large learning systems using the new concept of Relative Fisher Information Metric.,7. Conclusion and Discussions,[0],[0]
The key advantage of this approach is that the local learning dynamics can be analyzed in an accurate way without approximation.,7. Conclusion and Discussions,[0],[0]
"We present a core list of such local structures in neural networks, and give their corresponding RFIMs.",7. Conclusion and Discussions,[0],[0]
"This list of recipes can be used to provide guiding principles to design new optimizers for deep learning.
",7. Conclusion and Discussions,[0],[0]
"Our work applies to mirror descent as well since natural gradient is related to mirror descent (Raskutti & Mukherjee, 2015) as follows:",7. Conclusion and Discussions,[0],[0]
"In mirror descent to minimize a cost function E(Θ), given a strictly convex distance function D(·, ·) in the first argument (playing the role of the proximity function), we express the gradient descent step as:
Θt+1 = arg min Θ
{ Θ>∇E(Θt) + 1
γ D(Θ,Θt)
} .
",7. Conclusion and Discussions,[0],[0]
"When D(Θ,Θ′) is chosen as a Bregman divergence BF (Θ,Θ
′) = F (Θ)− F (Θ′)− (Θ−Θ′)>∇F (Θ′) wrt to a convex function F , it has been proved that the mirror descent on the Θ-parameterization is equivalent (Raskutti & Mukherjee, 2015) to the natural gradient optimization on the induced Riemannian manifold with metric tensor (∇2F (Θ)) parameterized by the dual coordinate system H = ∇F (Θ).
",7. Conclusion and Discussions,[0],[0]
"In general, to perform a Riemannian gradient descent for minimizing a real-valued function f(Θ) on the manifold, one needs to choose a proper metric tensor given in matrix form G(Θ).",7. Conclusion and Discussions,[0],[0]
Thomas (2014) constructed a toy example showing that the natural gradient may diverge while the ordinary gradient (for G = I) converges.,7. Conclusion and Discussions,[0],[0]
"Recently, Thomas et al. (2016) proposed a new kind of descent method based on what they called the Energetic Natural Gradient that generalizes the natural gradient.",7. Conclusion and Discussions,[0],[0]
"The energy distance DE(p(Θ1), p(Θ2))2 = E[2dp(Θ1)(X,Y )",7. Conclusion and Discussions,[0],[0]
"− dp(Θ1)(X,X
′)",7. Conclusion and Discussions,[0],[0]
"− dp(Θ1)(Y, Y ′)] where X,X ′ ∼ p(Θ1) and Y, Y ′ ∼ p(Θ2), where dp(Θ1)(·, ·) is a distance metric over the support.",7. Conclusion and Discussions,[0],[0]
"Using a Taylor’s expansion on their energy distance, they get the Energy Information Matrix (in a way similar to recovering the FIM from a Taylor’s expansion of any f -divergence like the Kullback-Leibler divergence).",7. Conclusion and Discussions,[0],[0]
Their idea is to incorporate prior knowledge on the structure of the support (observation space) to define energy distance.,7. Conclusion and Discussions,[0],[0]
"Twisting the geometry of the support (say, Wasserstein’s optimal transport) with the geometry of the parametric distributions (Fisher-Rao geodesic distances) is indeed important (Chizat et al., 2015).",7. Conclusion and Discussions,[0],[0]
"In information geometry, invariance on the support is provided by a Markov morphism that is a probabilistic mapping of the support to itself (Čencov, 1982).",7. Conclusion and Discussions,[0],[0]
There is no neighbourhood structure on the support in IG.,7. Conclusion and Discussions,[0],[0]
Markov morphism includes deterministic transformation of a random variable by a statistic.,7. Conclusion and Discussions,[0],[0]
It is well-known that IT (Θ) IX(Θ) with equality iff.,7. Conclusion and Discussions,[0],[0]
T = T (X) is a sufficient statistic of X .,7. Conclusion and Discussions,[0],[0]
"Thus to get the same invariance for the energy distance (Thomas et al., 2016), one shall further require dp(Θ)(T (X), T (Y ))",7. Conclusion and Discussions,[0],[0]
"= dp(Θ)(X,Y ).
",7. Conclusion and Discussions,[0],[0]
We believe that RFIMs will provide a sound methodology to build further efficient systems for deep learning.,7. Conclusion and Discussions,[0],[0]
The full source codes to reproduce the experimental results are available at https://www.lix.polytechnique.,7. Conclusion and Discussions,[0],[0]
fr/˜nielsen/RFIM.,7. Conclusion and Discussions,[0],[0]
The authors would like to thank the anonymous reviewers and Yann Ollivier for the helpful comments.,Acknowledgements,[0],[0]
This work was mainly conducted when the first author was a postdoctoral researcher at École Polytechnique.,Acknowledgements,[0],[0]
Fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks.,abstractText,[0],[0]
However related analysis becomes more and more difficult as the learner’s structure turns large and complex.,abstractText,[0],[0]
This paper makes a preliminary step towards a new direction.,abstractText,[0],[0]
"We extract a local component from a large neural system, and define its relative Fisher information metric that describes accurately this small component, and is invariant to the other parts of the system.",abstractText,[0],[0]
This concept is important because the geometry structure is much simplified and it can be easily applied to guide the learning of neural networks.,abstractText,[0],[0]
"We provide an analysis on a list of commonly used components, and demonstrate how to use this concept to further improve optimization.",abstractText,[0],[0]
1.,abstractText,[0],[0]
Fisher Information Metric The Fisher Information Metric (FIM) I(Θ) =,abstractText,[0],[0]
"(Iij) of a statistical parametric model p(x |Θ) of order D is defined by a D×D positive semidefinite (psd) matrix (I(Θ) 0) with coefficients Iij = Ep [ ∂l ∂Θi ∂l ∂Θj ] , where l(Θ) denotes the log-density function log p(x |Θ).",abstractText,[0],[0]
"Under light regularity conditions, FIM can be rewritten equivalently as Iij = −Ep [ ∂l ∂Θi∂Θj ]",abstractText,[0],[0]
Relative Fisher Information and Natural Gradient for Learning Large Modular Models,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 44–54, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
Our model is evaluated both for accuracy in predicting target order, and for its impact on translation quality. We report significant performance gains over phrase reordering, and over two known preordering baselines for English-Japanese.",text,[0],[0]
"Preordering (Collins et al., 2005) aims at permuting the words of a source sentence s into a new order ś, hopefully close to a plausible target word order.",1 Introduction,[0],[0]
"Preordering is often used to bridge long distance reorderings (e.g., in Japanese- or GermanEnglish), before applying phrase-based models (Koehn et al., 2007).",1 Introduction,[0],[0]
"Preordering is often broken down into two steps: finding a suitable tree structure, and then finding a transduction function over it.",1 Introduction,[0],[0]
"A common approach is to use monolingual syntactic trees and focus on finding a transduction function of the sibling subtrees under the nodes (Lerner and Petrov, 2013; Xia and Mccord, 2004).",1 Introduction,[0],[0]
"The (direct correspondence) assumption
underlying this approach is that permuting the siblings of nodes in a source syntactic tree can produce a plausible target order.",1 Introduction,[0],[0]
"An alternative approach creates reordering rules manually and then learns the right structure for applying these rules (Katz-Brown et al., 2011).",1 Introduction,[0],[0]
"Others attempt learning the transduction structure and the transduction function in two separate, consecutive steps (DeNero and Uszkoreit, 2011).",1 Introduction,[0],[0]
"Here we address the challenge of learning both the trees and the transduction functions jointly, in one fell swoop, from word-aligned parallel corpora.
",1 Introduction,[0],[0]
Learning both trees and transductions jointly raises two questions.,1 Introduction,[0],[0]
How to obtain suitable trees for the source sentence and how to learn a distribution over random variables specifically aimed at reordering in a hierarchical model?,1 Introduction,[0],[0]
"In this work we solve both challenges by using the factorizations of permutations into Permutation Trees (PETs) (Zhang and Gildea, 2007).",1 Introduction,[0],[0]
"As we explain next, PETs can be crucial for exposing the hierarchical reordering patterns found in wordalignments.
",1 Introduction,[0],[0]
We obtain permutations in the training data by segmenting every word-aligned source-target pair into minimal phrase pairs; the resulting alignment between minimal phrases is written as a permutation (1:1 and onto) on the source side.,1 Introduction,[0],[0]
"Every permutation can be factorized into a forest of PETs (over the source sentences) which we use as a latent treebank for training a Probabilistic ContextFree Grammar (PCFG) tailor made for preordering as we explain next.
",1 Introduction,[0],[0]
Figure 1 shows two alternative PETs for the same permutation over minimal phrases.,1 Introduction,[0],[0]
"The nodes have labels (like P3142) which stand for local permutations (called prime permutation) over the child nodes; for example, the root label P3142 stands for prime permutation 〈3, 1, 4, 2〉, which says that the first child of the root becomes 3rd on the target side, the second becomes 1st, the third
44
becomes 4th and the fourth becomes 2nd.",1 Introduction,[0],[0]
"The prime permutations are non-factorizable permutations like 〈1, 2〉, 〈2, 1〉 and 〈2, 4, 1, 3〉.
",1 Introduction,[0],[0]
We think PETs are suitable for learning preordering for two reasons.,1 Introduction,[0],[0]
"Firstly, PETs specify exactly the phrase pairs defined by the permutation.",1 Introduction,[0],[0]
"Secondly, every permutation is factorizable into prime permutations only (Albert and Atkinson, 2005).",1 Introduction,[0],[0]
"Therefore, PETs expose maximal sharing between different permutations in terms of both phrases and their reordering.",1 Introduction,[0.9557803950651267],"['The training, validation and difference norm curves of BPTT, TBPTT and all RBPs are shown in Fig.']"
"We expect this to be advantageous for learning hierarchical reordering.
",1 Introduction,[0],[0]
"For learning preordering, we first extract an initial PCFG from the latent treebank of PETs over the source sentences only.",1 Introduction,[0],[0]
We initialize the nonterminal set of this PCFG to the prime permutations decorating the PET nodes.,1 Introduction,[0],[0]
"Subsequently we split these coarse labels in the same way as latent variable splitting is learned for treebank parsing (Matsuzaki et al., 2005; Prescher, 2005; Petrov et al., 2006; Saluja et al., 2014).",1 Introduction,[0],[0]
"Unlike treebank parsing, however, our training treebank is latent because it consists of a whole forest of PETs per training instance (s).
",1 Introduction,[0],[0]
"Learning the splits on a latent treebank of PETs results in a Reordering PCFG which we use to parse input source sentences into split-decorated trees, i.e., the labels are the splits of prime permutations.",1 Introduction,[0],[0]
"After parsing s, we map the splits back on their initial prime permutations, and then retrieve a reordered version ś of s.",1 Introduction,[0],[0]
"In this sense, our latent splits are dedicated to reordering.
",1 Introduction,[0],[0]
We face two technical difficulties alien to work on latent PCFGs in treebank parsing.,1 Introduction,[0],[0]
"Firstly, as mentioned above, permutations may factorize into more than one PET (a forest) leading to a latent training treebank.1",1 Introduction,[0],[0]
"And secondly, after we parse a source string s, we are interested in ś, the permuted version of s, not in the best derivation/PET.",1 Introduction,[0],[0]
"Exact computation is a known NP-Complete problem (Sima’an, 2002).",1 Introduction,[0],[0]
"We solve this by a new Minimum-Bayes Risk decoding approach using Kendall reordering score as loss function, which is an efficient measure over permutations (Birch and Osborne, 2011; Isozaki et al., 2010a).
",1 Introduction,[0],[0]
"In summary, this paper contributes: • A novel latent hierarchical source reordering
model working over all derivations of PETs
1All PETs for the same permutation share the same set of prime permutations but differ only in bracketing structure (Zhang and Gildea, 2007).
•",1 Introduction,[0],[0]
"A label splitting approach based on PCFGs over minimal phrases as terminals, learned from an ambiguous treebank, where the label splits start out from prime permutations.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A fast Minimum Bayes Risk decoding over
Kendall τ reordering score for selecting ś. We report results for extensive experiments on English-Japanese showing that our Reordering PCFG gives substantial improvements when used as preordering for phrase-based models, outperforming two existing baselines for this task.",1 Introduction,[0],[0]
"We aim at learning a PCFG which we will use for parsing source sentences s into synchronous trees, from which we can obtain a reordered source version ś. Since PCFGs are non-synchronous grammars, we will use the nonterminal labels to encode reordering transductions, i.e., this PCFG is implicitly an SCFG.",2 PETs and the Hidden Treebank,[0],[0]
"We can do this because s and ś are over the same alphabet.
",2 PETs and the Hidden Treebank,[0],[0]
"Here, we have access only to a word-aligned parallel corpus, not a treebank.",2 PETs and the Hidden Treebank,[0],[0]
"The following steps summarize our approach for acquiring a latent treebank and how it is used for learning a Reordering PCFG:
1.",2 PETs and the Hidden Treebank,[0],[0]
Obtain a permutation over minimal phrases from every word-alignment.,2 PETs and the Hidden Treebank,[0],[0]
2.,2 PETs and the Hidden Treebank,[0],[0]
Obtain a latent treebank of PETs by factorizing the permutations.,2 PETs and the Hidden Treebank,[0],[0]
3. Extract a PCFG from the PETs with initial nonterminals taken from the PETs.,2 PETs and the Hidden Treebank,[0],[0]
4.,2 PETs and the Hidden Treebank,[0],[0]
"Learn to split the initial nonterminals and estimate rule probabilities.
",2 PETs and the Hidden Treebank,[0],[0]
"These steps are detailed in the next section, but we will start out with an intuitive exposition of PETs, the latent treebank and the Reordering Grammar.
",2 PETs and the Hidden Treebank,[0],[0]
"Figure 1 shows examples of how PETs look like – see (Zhang and Gildea, 2007) for algorithmic details.",2 PETs and the Hidden Treebank,[0],[0]
Here we label the nodes with nonterminals which stand for prime permutations from the operators on the PETs.,2 PETs and the Hidden Treebank,[0],[0]
"For example, nonterminals P12, P21 and P3142 correspond respectively to reordering transducers 〈1, 2〉, 〈2, 1〉 and 〈3, 1, 4, 2〉.",2 PETs and the Hidden Treebank,[0],[0]
"A prime permutation on a source node µ is a transduction dictating how the children of µ are reordered at the target side, e.g., P21 inverts the child order.",2 PETs and the Hidden Treebank,[0],[0]
"We must stress that any similarity with ITG (Wu, 1997) is restricted to the fact that the straight and inverted operators of ITG are the binary case of prime permutations
in PETs (P12 and P21).",2 PETs and the Hidden Treebank,[0],[0]
"ITGs recognize only the binarizable permutations, which is a major restriction when used on the data: there are many nonbinarizable permutations in actual data (Wellington et al., 2006).",2 PETs and the Hidden Treebank,[0],[0]
"In contrast, our PETs are obtained by factorizing permutations obtained from the data, i.e., they exactly fit the range of prime permutations in the parallel corpus.",2 PETs and the Hidden Treebank,[0],[0]
"In practice we limit them to maximum arity 5.
",2 PETs and the Hidden Treebank,[0],[0]
"We can extract PCFG rules from the PETs, e.g., P21 → P12 P2413.",2 PETs and the Hidden Treebank,[0],[0]
"However, these rules are decorated with too coarse labels.",2 PETs and the Hidden Treebank,[0],[0]
"A similar problem was encountered in non-lexicalized monolingual parsing, and one solution was to lexicalize the productions (Collins, 2003) using head words.",2 PETs and the Hidden Treebank,[0],[0]
"But linguistic heads do not make sense for PETs, so we opt for the alternative approach (Matsuzaki et al., 2005), which splits the nonterminals and softly percolates the splits through the trees gradually fitting them to the training data.",2 PETs and the Hidden Treebank,[0],[0]
"Splitting has a shadow side, however, because it leads to combinatorial explosion in grammar size.
",2 PETs and the Hidden Treebank,[0],[0]
Suppose for example node P21 could split into P211 and P212 and similarly P2413 splits into P24131 and 24132.,2 PETs and the Hidden Treebank,[0],[0]
"This means that rule P21 → P12 P2413 will form eight new rules:
P211 → P121 P24131",2 PETs and the Hidden Treebank,[0],[0]
P211 → P121 P24132 P211,2 PETs and the Hidden Treebank,[0],[0]
→ P122 P24131,2 PETs and the Hidden Treebank,[0],[0]
P211 → P122 P24132 P212 → P121 P24131,2 PETs and the Hidden Treebank,[0],[0]
P212 → P121 P24132 P212 → P122 P24131,2 PETs and the Hidden Treebank,[0],[0]
"P212 → P122 P24132
Should we want to split each nonterminal into 30 subcategories, then an n-ary rule will split into 30n+1 new rules, which is prohibitively large.",2 PETs and the Hidden Treebank,[0],[0]
Here we use the “unary trick” as in Figure 2.,2 PETs and the Hidden Treebank,[0],[0]
The superscript on the nonterminals denotes the child position from left to right.,2 PETs and the Hidden Treebank,[0],[0]
"For example P2121 means that this node is a second child, and the
mother nonterminal label is P211.",2 PETs and the Hidden Treebank,[0],[0]
"For the running example rule, this gives the following rules:
P211 → P2111 P2121 P212",2 PETs and the Hidden Treebank,[0],[0]
→ P2112 P2122,2 PETs and the Hidden Treebank,[0],[0]
P2111,2 PETs and the Hidden Treebank,[0],[0]
→ P121 P2121 → P24131,2 PETs and the Hidden Treebank,[0],[0]
P2111,2 PETs and the Hidden Treebank,[0],[0]
→ P122 P2121 → P24132 P2112 → P121 P2122 → P24131,2 PETs and the Hidden Treebank,[0],[0]
P2112 → P122 P2122,2 PETs and the Hidden Treebank,[0],[0]
"→ P24132
",2 PETs and the Hidden Treebank,[0],[0]
"The unary trick leads to substantial reduction in grammar size, e.g., for arity 5 rules and 30 splits we could have had 306 = 729000000 split-rules, but with the unary trick we only have 30+302∗5 = 4530 split rules.",2 PETs and the Hidden Treebank,[0],[0]
"The unary trick was used in early lexicalized parsing work (Carroll and Rooth, 1998).2 This split PCFG constitutes a latent PCFG because the splits cannot be read of a treebank.",2 PETs and the Hidden Treebank,[0],[0]
"It must be learned from the latent treebank of PETs, as described next.",2 PETs and the Hidden Treebank,[0],[0]
"Obtaining permutations Given a source sentence s and its alignment a to a target sentence
2After applying the unary trick, we add a constraint on splitting: all nonterminals on an n-ary branching rule must be split simultaneously.
",3 Details of Latent Reordering PCFG,[0],[0]
"t in the training corpus, we segment 〈s,a, t〉 into a sequence of minimal phrases sm (maximal sequence) such that the reordering between these minimal phrases constitutes a permutation πm.",3 Details of Latent Reordering PCFG,[0],[0]
"We do not extract non-contiguous or non-minimal phrases because reordering them often involves complicated transductions which could hamper the performance of our learning algorithm.3
Unaligned words Next we describe the use of the factorization of permutations into PET forests for training a PCFG model.",3 Details of Latent Reordering PCFG,[0],[0]
But first we need to extend the PETs to allow for unaligned words.,3 Details of Latent Reordering PCFG,[0],[0]
"An unaligned word is joined with a neighboring phrase to the left or the right, depending on the source language properties (e.g., whether the language is head-initial or -final (Chomsky, 1970)).",3 Details of Latent Reordering PCFG,[0],[0]
"Our experiments use English as source language (head-initial), so the unaligned words are joined to phrases to their right.",3 Details of Latent Reordering PCFG,[0],[0]
This modifies a PET by adding a new binary branching node µ (dominating the unaligned word and the phrase it is joined to) which is labeled with a dedicated nonterminal: P01 if the unaligned word joins to the right and P10 if it joins to the left.,3 Details of Latent Reordering PCFG,[0],[0]
"We decompose the permutation πm into a forest of permutation trees PEF (πm) in O(n3), following algorithms in (Zhang et al., 2008; Zhang and Gildea, 2007) with trivial modifications.",3.1 Probability model,[0],[0]
Each PET ∆ ∈ PEF (πm) is a different bracketing (differing in binary branching structure only).,3.1 Probability model,[0],[0]
"We consider the bracketing hidden in the latent treebank, and apply unsupervised learning to induce a distribution over possible bracketings.",3.1 Probability model,[0],[0]
Our probability model starts from the joint probability of a sequence of minimal phrases sm and a permutation πm over it.,3.1 Probability model,[0],[0]
"This demands summing over all PETs ∆ in the forest PEF (πm), and for every PET also over all its label splits, which are given by the grammar derivations",3.1 Probability model,[0],[0]
"d:
P (sm, πm) = ∑
∆∈PEF (πm) ∑ d∈∆ P (d, sm) (1)
",3.1 Probability model,[0],[0]
"The probability of a derivation d is a product of probabilities of all the rules r that build it:
P (sm, πm) = ∑
∆∈PEF (πm) ∑ d∈∆ ∏ r∈d P (r) (2)
3Which differs from (Quirk and Menezes, 2006).
",3.1 Probability model,[0],[0]
"As usual, the parameters of this model are the PCFG rule probabilities which are estimated from the latent treebank using EM as explained next.",3.1 Probability model,[0],[0]
"For training the latent PCFG over the latent treebank, we resort to EM (Dempster et al., 1977) which estimates PCFG rule probabilities to maximize the likelihood of the parallel corpus instances.",3.2 Learning Splits on Latent Treebank,[0],[0]
"Computing expectations for EM is done efficiently using Inside-Outside (Lari and Young, 1990).",3.2 Learning Splits on Latent Treebank,[0],[0]
"As in other state splitting models (Matsuzaki et al., 2005), after splitting the nonterminals, we distribute the probability uniformly over the new rules, and we add to each new rule some random noise to break the symmetry.",3.2 Learning Splits on Latent Treebank,[0],[0]
"We split the non-terminals only once as in (Matsuzaki et al., 2005) (unlike (Petrov et al., 2006)).",3.2 Learning Splits on Latent Treebank,[0],[0]
For estimating the distribution for unknown words we replace all words that appear ≤ 3 times with the “UNKNOWN” token.,3.2 Learning Splits on Latent Treebank,[0],[0]
"We use CKY+ (Chappelier and Rajman, 1998) to parse a source sentence s into a forest using the learned split PCFG.",3.3 Inference,[0],[0]
"Unfortunately, computing the most-likely permutation (or alternatively ś) as in
argmax π∈Π ∑ ∆∈PEF (π) ∑ d∈∆ P (d, πm)
from a lattice of permutations Π using a PCFG is NP-complete (Sima’an, 2002).",3.3 Inference,[0],[0]
"Existing techniques, like variational decoding or MinimumBayes Risk (MBR), used for minimizing loss over trees as in (Petrov and Klein, 2007), are not directly applicable here.",3.3 Inference,[0],[0]
"Hence, we opt for minimizing the risk of making an error under a loss function over permutations using the MBR decision rule (Kumar and Byrne, 2004):
π̂ = argmin π ∑ πr Loss(π, πr)P (πr) (3)
",3.3 Inference,[0],[0]
The loss function we minimize is Kendall τ,3.3 Inference,[0],[0]
"(Birch and Osborne, 2011; Isozaki et al., 2010a) which is a ratio of wrongly ordered pairs of words (including gapped pairs) to the total number of pairs.",3.3 Inference,[0],[0]
We do Monte Carlo sampling of 10000 derivations from the chart of the s and then find the least risky permutation in terms of this loss.,3.3 Inference,[0],[0]
"We sample from the true distribution by sampling edges recursively
using their inside probabilities.",3.3 Inference,[0],[0]
"An empirical distribution over permutations P (π) is given by the relative frequency of π in the sample.
",3.3 Inference,[0],[0]
With large samples it is hard to efficiently compute expected Kendall τ loss for each sampled hypothesis.,3.3 Inference,[0],[0]
For sentence of length k and sample of size n the complexity of a naive algorithm is O(n2k2).,3.3 Inference,[0],[0]
Computing Kendall τ alone takes O(k2).,3.3 Inference,[0],[0]
"We use the fact that Kendall τ decomposes as a linear function over all skip-bigrams b that could be built for any permutation of length k:
Kendall(π, πr) = ∑ b 1− δ(π, b) k(k−1) 2 δ(πr, b) (4)
",3.3 Inference,[0],[0]
"Here δ returns 1 if permutation π contains the skip bigram b, otherwise it returns 0.",3.3 Inference,[0],[0]
"With this decomposition we can use the method from (DeNero et al., 2009) to efficiently compute the MBR hypothesis.",3.3 Inference,[0],[0]
"Combining Equations 3 and 4 we get:
π̂ = argmin π ∑ πr ∑ b 1− δ(π, b) k(k−1) 2 δ(πr, b)P (πr) (5)
",3.3 Inference,[0],[0]
"We can move the summation inside and reformulate the expected Kendall τ loss as expectation over the skip-bigrams of the permutation.
",3.3 Inference,[0],[0]
= argmin π ∑ b,3.3 Inference,[0],[0]
"(1− δ(π, b))",3.3 Inference,[0],[0]
"[∑ πr δ(πr, b)P (πr) ] (6)
= argmin π ∑ b (1− δ(π, b))EP (πr)δ(πr, b) (7)
= argmax π ∑ b δ(π, b)EP (πr)δ(πr, b) (8)
This means we need to pass through the sampled list only twice: (1) to compute expectations over skip bigrams and (2) to compute expected loss of each sampled permutation.",3.3 Inference,[0],[0]
The time complexity is O(nk2) which is quite fast in practice.,3.3 Inference,[0],[0]
We conduct experiments with three baselines:,4 Experiments,[0],[0]
• Baseline A: No preordering.,4 Experiments,[0],[0]
"• Baseline B: Rule based preordering (Isozaki
et al., 2010b), which first obtains an HPSG parse tree using Enju parser 4 and after that swaps the children by moving the syntactic head to the final position to account for different head orientation in English and Japanese.
",4 Experiments,[0],[0]
"4http://www.nactem.ac.uk/enju/
• Baseline C: LADER (Neubig et al., 2012): latent variable preordering that is based on ITG and large-margin training with latent variables.",4 Experiments,[0],[0]
"We used LADER in standard settings without any linguistic features (POS tags or syntactic trees).
",4 Experiments,[0],[0]
And we test four variants of our model:,4 Experiments,[0],[0]
• RGleft - only canonical left branching PET •,4 Experiments,[0],[0]
"RGright - only canonical right branching PET • RGITG-forest - all PETs that are binary (ITG) • RGPET-forest - all PETs.
",4 Experiments,[0],[0]
We test these models on English-Japanese NTCIR-8 Patent Translation (PATMT) Task.,4 Experiments,[0],[0]
For tuning we use all NTCIR-7 dev sets and for testing the test set from NTCIR-9 from both directions.,4 Experiments,[0],[0]
All used data was tokenized (English with Moses tokenizer and Japanese with KyTea 5) and filtered for sentences between 4 and 50 words.,4 Experiments,[0],[0]
"A subset of this data is used for training the Reordering Grammar, obtained by filtering out sentences that have prime permutations of arity > 5, and for the ITG version arity > 2.",4 Experiments,[0],[0]
Baseline C was trained on 600 sentences because training is prohibitively slow.,4 Experiments,[0],[0]
"Table 1 shows the sizes of data used.
",4 Experiments,[0],[0]
The Reordering Grammar was trained for 10 iterations of EM on train RG data.,4 Experiments,[0],[0]
We use 30 splits for binary non-terminals and 3 for non-binary.,4 Experiments,[0],[0]
Training on this dataset takes 2 days and parsing tuning and testing set without any pruning takes 11 and 18 hours respectively.,4 Experiments,[0],[0]
We test how well our model predicts gold reorderings before translation by training the alignment model using MGIZA++ 6 on the training corpus and using it to align the test corpus.,4.1 Intrinsic evaluation,[0],[0]
"Gold reorderings for the test corpus are obtained by sorting words by their average target position and (unaligned words follow their right neighboring
5http://www.phontron.com/kytea/ 6http://www.kyloo.net/software/doku.php/mgiza:overview
word).",4.1 Intrinsic evaluation,[0],[0]
"We use Kendall τ score for evaluation (note the difference with Section 3.3 where we defined it as a loss function).
",4.1 Intrinsic evaluation,[0],[0]
Table 2 shows that our models outperform all baselines on this task.,4.1 Intrinsic evaluation,[0],[0]
"The only strange result here is that rule-based preordering obtains a lower score than no preordering, which might be an artifact of the Enju parser changing the tokenization of its input, so the Kendall τ of this system might not really reflect the real quality of the preordering.",4.1 Intrinsic evaluation,[0],[0]
All other systems use the same tokenization.,4.1 Intrinsic evaluation,[0],[0]
"The reordered output of all the mentioned baselines and versions of our model are translated with phrase-based MT system (Koehn et al., 2007) (distortion limit set to 6 with distance based reordering model) that is trained on gold preordering of the training data 7 ś − t.",4.2 Extrinsic evaluation in MT,[0],[0]
"The only exception is Baseline A which is trained on original s− t.
We use a 5-gram language model trained with KenLM 8, tune 3 times with kb-mira (Cherry and Foster, 2012) to account for tuner instability and evaluated using Multeval 9 for statistical significance on 3 metrics: BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and TER (Snover et al., 2006).",4.2 Extrinsic evaluation in MT,[0],[0]
"We additionally report RIBES score (Isozaki et al., 2010a) that concentrates on word order more than other metrics.
",4.2 Extrinsic evaluation in MT,[0],[0]
Single or all PETs?,4.2 Extrinsic evaluation in MT,[0],[0]
In Table 3 we see that using all PETs during training makes a big impact on performance.,4.2 Extrinsic evaluation in MT,[0],[0]
"Only the all PETs variants
7Earlier work on preordering applies the preordering model to the training data to obtain a parallel corpus of guessed ś − t pairs, which are the word re-aligned and then used for training the back-end MT system (Khalilov and Sima’an, 2011).",4.2 Extrinsic evaluation in MT,[0],[0]
"We skip this, we take the risk of mismatch between the preordering and the back-end system, but this simplifies training and saves a good amount of training time.
8http://kheafield.com/code/kenlm/ 9https://github.com/jhclark/multeval
(RGITG-forest and RGPET-forest) significantly outperform all baselines.",4.2 Extrinsic evaluation in MT,[0],[0]
"If we are to choose a single PET per training instance, then learning RG from only left-branching PETs (the one usually chosen in other work, e.g. (Saluja et al., 2014)) performs slightly worse than the right-branching PET.",4.2 Extrinsic evaluation in MT,[0],[0]
This is possibly because English is mostly rightbranching.,4.2 Extrinsic evaluation in MT,[0],[0]
"So even though both PETs describe the same reordering, RGright captures reordering over English input better than RGleft.
",4.2 Extrinsic evaluation in MT,[0],[0]
All PETs or binary only?,4.2 Extrinsic evaluation in MT,[0],[0]
RGPET-forest performs significantly better than RGITG-forest (p < 0.05).,4.2 Extrinsic evaluation in MT,[0],[0]
"Non-ITG reordering operators are predicted rarely (in only 99 sentences of the test set), but they make a difference, because these operators often appear high in the predicted PET.",4.2 Extrinsic evaluation in MT,[0],[0]
"Furthermore, having these operators during training might allow for better fit to the data.
",4.2 Extrinsic evaluation in MT,[0],[0]
How much reordering is resolved by the Reordering Grammar?,4.2 Extrinsic evaluation in MT,[0],[0]
"Obviously, completely factorizing out the reordering from the translation process is impossible because reordering depends to a certain degree on target lexical choice.",4.2 Extrinsic evaluation in MT,[0],[0]
"To quantify the contribution of Reordering Grammar, we tested decoding with different distortion limit values in the SMT system.",4.2 Extrinsic evaluation in MT,[0],[0]
"We compare the phrase-based (PB) system with distance based cost function for reordering (Koehn et al., 2007) with and without preordering.
",4.2 Extrinsic evaluation in MT,[0],[0]
Figure 3 shows that Reordering Grammar gives substantial performance improvements at all distortion limits (both BLEU and RIBES).,4.2 Extrinsic evaluation in MT,[0],[0]
RGPET-forest is less sensitive to changes in decoder distortion limit than standard PBSMT.,4.2 Extrinsic evaluation in MT,[0],[0]
"The perfor-
mance of RGPET-forest varies only by 1.1 BLEU points while standard PBSMT by 4.3 BLEU points.",4.2 Extrinsic evaluation in MT,[0],[0]
Some local reordering in the decoder seems to help RGPET-forest but large distortion limits seem to degrade the preordering choice.,4.2 Extrinsic evaluation in MT,[0],[0]
"This shows also that the improved performance of RGPET-forest is not only a result of efficiently exploring the full space of permutations, but also a result of improved scoring of permutations.
",4.2 Extrinsic evaluation in MT,[0],[0]
Does the improvement remain for a decoder with MSD reordering model?,4.2 Extrinsic evaluation in MT,[0],[0]
"We compare the RGPET-forest preordered model against a decoder that uses the strong MSD model (Tillmann, 2004; Koehn et al., 2007).",4.2 Extrinsic evaluation in MT,[0],[0]
Table 4 shows that using Reordering Grammar as front-end to MSD reordering (full Moses) improves performance by 2.8 BLEU points.,4.2 Extrinsic evaluation in MT,[0],[0]
"The improvement is confirmed by METEOR, TER and RIBES.",4.2 Extrinsic evaluation in MT,[0],[0]
"Our preordering model and MSD are complementary – the Reordering Grammar captures long distance reordering, while MSD possibly does better local reorderings, especially reorderings conditioned on the lexical part of translation units.
",4.2 Extrinsic evaluation in MT,[0],[0]
"Interestingly, the MSD model (BLEU 29.6) improves over distance-based reordering (BLEU 27.8) by (BLEU 1.8), whereas the difference between these systems as back-ends to Reordering Grammar (respectively BLEU 32.4 and 32.0) is
far smaller (0.4 BLEU).",4.2 Extrinsic evaluation in MT,[0],[0]
This suggests that a major share of reorderings can be handled well by preordering without conditioning on target lexical choice.,4.2 Extrinsic evaluation in MT,[0],[0]
"Furthermore, this shows that RGPET-forest preordering is not very sensitive to the decoder’s reordering model.
",4.2 Extrinsic evaluation in MT,[0],[0]
Comparison to a Hierarchical model (Hiero).,4.2 Extrinsic evaluation in MT,[0],[0]
"Hierarchical preordering is not intended for a hierarchical model as Hiero (Chiang, 2005).",4.2 Extrinsic evaluation in MT,[0],[0]
"Yet, here we compare our preordering system (PB MSD+RG) to Hiero for completeness, while we should keep in mind that Hiero’s reordering model has access to much richer training data.",4.2 Extrinsic evaluation in MT,[0],[0]
"We will discuss these differences shortly.
",4.2 Extrinsic evaluation in MT,[0],[0]
"Table 4 shows that the difference in BLEU is not statistically significant, but there is more difference in METEOR and TER. RIBES, which concentrates more on reordering, prefers Reordering Grammar over Hiero.",4.2 Extrinsic evaluation in MT,[0],[0]
It is somewhat surprising that a preordering model combined with a phrase-based model succeeds to rival Hiero’s performance on English-Japanese.,4.2 Extrinsic evaluation in MT,[0],[0]
"Especially when looking at the differences between the two:
1.",4.2 Extrinsic evaluation in MT,[0],[0]
"Reordering Grammar uses only minimal phrases, while Hiero uses composite (longer) phrases which encapsulate internal reorderings, but also non-contiguous phrases.",4.2 Extrinsic evaluation in MT,[0],[0]
2.,4.2 Extrinsic evaluation in MT,[0],[0]
"Hiero conditions its reordering on the lexical target side, whereas the Reordering Grammar does not (by definition).",4.2 Extrinsic evaluation in MT,[0],[0]
3.,4.2 Extrinsic evaluation in MT,[0],[0]
"Hiero uses a range of features, e.g., a language model, while Reordering Grammar is a mere generative PCFG.",4.2 Extrinsic evaluation in MT,[0],[0]
"The advantages of Hiero can be brought to bear upon Reordering Grammar by reformulating it as a discriminative model.
",4.2 Extrinsic evaluation in MT,[0],[0]
Which structure is learned?,4.2 Extrinsic evaluation in MT,[0],[0]
"Figure 4 shows an example PET output showing how our model learns: (1) that the article “the” has no equivalent in Japanese, (2) that verbs go after their object, (3) to use postpositions instead of prepositions, and (4) to correctly group certain syntactic units, e.g. NPs and VPs.",4.2 Extrinsic evaluation in MT,[0],[0]
"The majority of work on preordering is based on syntactic parse trees, e.g., (Lerner and Petrov, 2013; Khalilov and Sima’an, 2011; Xia and Mccord, 2004).",5 Related work,[0],[0]
Here we concentrate on work that has common aspects with this work.,5 Related work,[0],[0]
"Neubig et
al (2012) trains a latent non-probabilistic discriminative model for preordering as an ITG-like grammar limited to binarizable permutations.",5 Related work,[0],[0]
Tromble and Eisner (2009) use ITG but do not train the grammar.,5 Related work,[0],[0]
They only use it to constrain the local search.,5 Related work,[0],[0]
DeNero and Uszkoreit (2011) present two separate consecutive steps for unsupervised induction of hierarchical structure (ITG) and the induction of a reordering function over it.,5 Related work,[0],[0]
"In contrast, here we learn both the structure and the reordering function simultaneously.",5 Related work,[0],[0]
"Furthermore, at test time, our inference with MBR over a measure of permutation (Kendall) allows exploiting both structure and reordering weights for inference, whereas test-time inference in (DeNero and Uszkoreit, 2011) is also a two step process – the parser forwards to the next stage the best parse.
",5 Related work,[0],[0]
Dyer and Resnik (2010) treat reordering as a latent variable and try to sum over all derivations that lead not only to the same reordering but also to the same translation.,5 Related work,[0],[0]
"In their work they consider all permutations allowed by a given syntactic tree.
",5 Related work,[0],[0]
"Saers et al (2012) induce synchronous grammar for translation by splitting the non-terminals, but unlike our approach they split generic nonterminals and not operators.",5 Related work,[0],[0]
Their most expressive grammar covers only binarizable permutations.,5 Related work,[0],[0]
The decoder that uses this model does not try to sum over many derivations that have the same yield.,5 Related work,[0],[0]
They do not make independence assumption like our “unary trick” which is probably the reason they do not split more than 8 times.,5 Related work,[0],[0]
"They do not compare their results to any other SMT system and test on a very small dataset.
",5 Related work,[0],[0]
"Saluja et al (2014) attempts inducing a refined Hiero grammar (latent synchronous CFG) from Normalized Decomposition Trees (NDT) (Zhang et al., 2008).",5 Related work,[0],[0]
"While there are similarities with
the present work, there are major differences.",5 Related work,[0],[0]
"On the similarity side, NDTs are decomposing alignments in ways similar to PETs, and both Saluja’s and our models refine the labels on the nodes of these decompositions.",5 Related work,[0],[0]
"However, there are major differences between the two:
• Our model is completely monolingual and unlexicalized (does not condition its reordering on the translation) in contrast with the Latent SCFG used in (Saluja et al., 2014), • Our Latent PCFG label splits are defined
as refinements of prime permutations, i.e., specifically designed for learning reordering, whereas (Saluja et al., 2014) aims at learning label splitting that helps predicting NDTs from source sentences, • Our model exploits all PETs and all deriva-
tions, both during training (latent treebank) and during inferences.",5 Related work,[0],[0]
"In (Saluja et al., 2014) only left branching NDT derivations are used for learning the model.",5 Related work,[0],[0]
•,5 Related work,[0],[0]
"The training data used by (Saluja et al., 2014)
is about 60 times smaller in number of words than the data used here; the test set of (Saluja et al., 2014) also consists of far shorter sentences where reordering could be less crucial.
",5 Related work,[0],[0]
"A related work with a similar intuition is presented in (Maillette de Buy Wenniger and Sima’an, 2014), where nodes of a tree structure similar to PETs are labeled with reordering patterns obtained by factorizing word alignments into Hierarchical Alignment Trees.",5 Related work,[0],[0]
These patterns are used for labeling the standard Hiero grammar.,5 Related work,[0],[0]
"Unlike this work, the labels extracted by (Maillette de Buy Wenniger and Sima’an, 2014) are clustered manually into less than a dozen labels without the possibility of fitting the labels to the training data.",5 Related work,[0],[0]
We present a generative Reordering PCFG model learned from latent treebanks over PETs obtained by factorizing permutations over minimal phrase pairs.,6 Conclusion,[0],[0]
Our Reordering PCFG handles non-ITG reordering patterns (up to 5-ary branching) and it works with all PETs that factorize a permutation (rather than a single PET).,6 Conclusion,[0],[0]
To the best of our knowledge this is the first time both extensions are shown to improve performance.,6 Conclusion,[0],[0]
"The empirical results on English-Japanese show that (1) when used for preordering, the Reordering PCFG helps particularly with relieving the phrase-based model from long range reorderings, (2) combined with a state-of-the-art phrase model, Reordering PCFG shows performance not too different from Hiero, supporting the common wisdom of factorizing long range reordering outside the decoder, (3) Reordering PCFG generates derivations that seem to coincide well with linguistically-motivated reordering patterns for English-Japanese.",6 Conclusion,[0],[0]
"There are various direction we would like to explore, the most obvious of which are integrating the learned reordering with other feature functions in a discriminative setting, and extending the model to deal with non-contiguous minimal phrases.",6 Conclusion,[0],[0]
This work is supported by STW grant nr. 12271 and NWO VICI grant nr. 277-89-002.,Acknowledgments,[0],[0]
We thank Wilker Aziz for comments on earlier version of the paper and discussions about MBR and sampling.,Acknowledgments,[0],[0]
"We present a novel approach for unsupervised induction of a Reordering Grammar using a modified form of permutation trees (Zhang and Gildea, 2007), which we apply to preordering in phrase-based machine translation.",abstractText,[0],[0]
"Unlike previous approaches, we induce in one step both the hierarchical structure and the transduction function over it from word-aligned parallel corpora.",abstractText,[0],[0]
"Furthermore, our model (1) handles non-ITG reordering patterns (up to 5-ary branching), (2) is learned from all derivations by treating not only labeling but also bracketing as latent variable, (3) is entirely unlexicalized at the level of reordering rules, and (4) requires no linguistic annotation.",abstractText,[0],[0]
"Our model is evaluated both for accuracy in predicting target order, and for its impact on translation quality.",abstractText,[0],[0]
"We report significant performance gains over phrase reordering, and over two known preordering baselines for English-Japanese.",abstractText,[0],[0]
Reordering Grammar Induction,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2401–2410 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Deep neural models are known to be computationally expensive to train even with fast hardware (Sutskever et al., 2014; Wu et al., 2016).",1 Introduction,[0],[0]
"For example, it takes three weeks to train a deep neural machine translation system on 100 Graphics Processing Units (GPUs) (Wu et al., 2016).",1 Introduction,[0],[0]
"Furthermore, a large amount of data is usually required to train effective neural models (Goodfellow et al., 2016; Hirschberg and Manning, 2015).
",1 Introduction,[0],[0]
Bengio et al. (2009) and Kumar et al. (2010) developed training paradigms which are inspired by the learning principle that humans can learn more effectively when training starts with easier concepts and gradually proceeds with more difficult concepts.,1 Introduction,[0],[0]
"Since these approaches are motivated by
1Our code is available at scholar.harvard.edu/ hadi/RbF/
a “starting small” strategy they are called curriculum or self-paced learning.
",1 Introduction,[0],[0]
"In this paper, we present a novel training paradigm which is inspired by the broad evidence in psychology that shows human ability to retain information improves with repeated exposure and exponentially decays with delay since last exposure (Cepeda et al., 2006; Averell and Heathcote, 2011).",1 Introduction,[0],[0]
"Spaced repetition was presented in psychology (Dempster, 1989) and forms the building block of many educational devices, including flashcards, in which small pieces of information are repeatedly presented to a learner on a schedule determined by a spaced repetition algorithm.",1 Introduction,[0],[0]
"Such algorithms show that human learners can learn efficiently and effectively by increasing intervals of time between subsequent reviews of previously learned materials (Dempster, 1989; Novikoff et al., 2012).
",1 Introduction,[0],[0]
"We investigate the analogy between training neural models and findings in psychology about human memory model and develop a spaced repetition algorithm (named Repeat before Forgetting, RbF) to efficiently and effectively train neural models.",1 Introduction,[0],[0]
The core part of our algorithm is a scheduler that ensures a given neural network spends more time working on difficult training instances and less time on easier ones.,1 Introduction,[0],[0]
"Our scheduler is inspired by factors that affect human memory retention, namely, difficulty of learning materials, delay since their last review, and strength of memory.",1 Introduction,[0],[0]
The scheduler uses these factors to lengthen or shorten review intervals with respect to individual learners and training instances.,1 Introduction,[0],[0]
"We evaluate schedulers based on their scheduling accuracy, i.e., accuracy in estimating network memory retention with respect to previously-seen instances, as well as their effect on the efficiency and effectiveness of downstream neural networks.2
2 In this paper, we use the terms memory retention, recall, and learning interchangeably.
2401
The contributions of this paper are: (1) we show that memory retention in neural networks is affected by the same (known) factors that affect memory retention in humans, (2) we present a novel training paradigm for neural networks based on spaced repetition, and (3) our approach can be applied without modification to any neural network.
",1 Introduction,[0],[0]
"Our best RbF algorithm uses 34-50% of training data per epoch while producing similar results to state-of-the-art systems on three tasks, namely sentiment classification, image categorization, and arithmetic addition.3",1 Introduction,[0],[0]
"It also runs 2.9-4.8 times faster than standard training, and outperforms competing state-of-the-art baselines.",1 Introduction,[0],[0]
"Research in psychology describes the following memory model for human learning: the probability that a human recalls a previously-seen item (e.g., the Korean translation of a given English word) depends on the difficulty of the item, delay since last review of the item, and the strength of the human memory.",2 Neural and Brain Memory Models,[0],[0]
"The relation between these indicators and memory retention has the following functional form (Reddy et al., 2016; Ebbinghaus, 1913):
Pr(recall) = exp(−difficulty × delay strength ).",2 Neural and Brain Memory Models,[0],[0]
"(1)
An accurate memory model enables estimating the time by which an item might be forgotten by a learner so that a review can be scheduled for the learner before that time.
",2 Neural and Brain Memory Models,[0],[0]
We investigate the analogy between the above memory model and memory model of artificial neural networks.,2 Neural and Brain Memory Models,[0],[0]
"Our intuition is that if the probability that a network recalls an item (e.g., correctly predicts its category) depends on the same factors (difficulty of the item, delay since last review of the item, or strength of the network), then we can develop spaced repetition algorithms to efficiently and effectively train neural networks.",2 Neural and Brain Memory Models,[0],[0]
We design a set of preliminarily experiments to directly evaluate the effect of the aforementioned factors (recall indicators) on memory retention in neural networks.,2.1 Recall Indicators,[0],[0]
"For this purpose, we use a set of training instances that are partially made available to the network during training.",2.1 Recall Indicators,[0],[0]
"This scheme
3We obtained similar results on QA tasks (Weston et al., 2016) but they are excluded due to space limit.
will allow us to intrinsically examine the effect of recall indicators on memory retention in isolation from external effects such as size of training data, number of training epochs, etc.
",2.1 Recall Indicators,[0],[0]
"We first define the following concepts to ease understanding the experiments (see Figure 1):
• First and Last review points (fRev and lRev) of a training instance are the first and last epochs in which the instance is used to train the network respectively,
• Recall point (Rec) is the epoch in which network retention is computed against some training instances; network retention is the probability that a neural network recalls (i.e. correctly classifies) a previously-seen training instance, and
• Delay since last review of a training instance is the difference between the recall point and the last review point of the training instance.
",2.1 Recall Indicators,[0],[0]
"Given training data and a neural network, we uniformly at random divide the data into three disjoint sets: a base set A, a review set B, and a replacement set C that respectively contain 80%, 10%, and 10% of the data.",2.1 Recall Indicators,[0],[0]
"As depicted in Figure 1, instances of A are used for training at every epoch, while those in B and C are partially used for training.",2.1 Recall Indicators,[0],[0]
The network initially starts to train with {A ∪ C} instances.,2.1 Recall Indicators,[0],[0]
"Then, starting from the first review point, we inject the review set B and remove C, training with {A ∪ B} instances at every epoch until the last review point.",2.1 Recall Indicators,[0],[0]
The network will then continue training with {A ∪ C} instances until the recall point.,2.1 Recall Indicators,[0],[0]
"At this point, network retention is computed against set B instances, with delay defined as the number of epochs since last review point.",2.1 Recall Indicators,[0],[0]
"The intuition behind using review and replacement sets, B and C respectively, is to avoid external effects (e.g.
size of data or network generalization and learning capability) for our intrinsic evaluation purpose.
",2.1 Recall Indicators,[0],[0]
"To conduct these experiments, we identify different neural models designed for different tasks.4 For each network, we fix the recall point to either the epoch in which the network is fully trained (i.e., obtains its best performance based on standard or “rote” training in which all instances are used for training at every iteration), or partially trained (i.e., obtains half of its best performance based on rote training).",2.1 Recall Indicators,[0],[0]
We report average results across these networks for each experiment.,2.1 Recall Indicators,[0],[0]
"As aforementioned, delay since last review of a training instance is the difference between the recall point (Rec) and the last review point (lRev) of the training instance.",2.1.1 Delay since Last Review,[0],[0]
We evaluate the effect of delay on network retention (against set B instances) by keeping the recall point fixed while moving the sliding window in Figure 1.,2.1.1 Delay since Last Review,[0],[0]
Figures 2(a) and 2(b) show average network retention across networks for the fully and partially trained recall points respectively.,2.1.1 Delay since Last Review,[0],[0]
The results show an inverse relationship between network retention and delay since last review in neural networks.,2.1.1 Delay since Last Review,[0],[0]
We define difficulty of training instances by the loss values generated by a network for the instances.,2.1.2 Item Difficulty,[0],[0]
Figure 2(c) shows the difficulty of set B instances at the last review point against average network retention on these instances at recall point.,2.1.2 Item Difficulty,[0],[0]
"We normalize loss values to unit vectors (to make them com-
4See section 4, we use Addition and CIFAR10 datasets and their corresponding neural networks for these experiments.
",2.1.2 Item Difficulty,[0],[0]
parable across networks) and then average them across networks for both fully and partially trained recall points.,2.1.2 Item Difficulty,[0],[0]
"As the results show, network retention decreases as item difficulty increases.",2.1.2 Item Difficulty,[0],[0]
We define strength of a network by its performance on validation data.,2.1.3 Network Strength,[0],[0]
"To understand the effect of network strength on its retention, we use the same experimental setup as before except that we keep the delay (difference between recall point and last review point) fixed while gradually increasing the recall point; this will make the networks stronger by training them for more epochs.",2.1.3 Network Strength,[0],[0]
"Then, at every recall point, we record network retention on set B instances and network accuracy on validation data.",2.1.3 Network Strength,[0],[0]
Average results across networks for two sets of 10 consecutive recall points (before fully and partially trained recall points) are shown in Figure 2(d).,2.1.3 Network Strength,[0],[0]
"As the results show, network retention increases as memory strength increases.
",2.1.3 Network Strength,[0],[0]
"The above experiments show that memory retention in neural networks is affected by the same factors that affect memory retention in humans: (a) neural networks forget training examples after a certain period of intervening training data (b): the period of recall is shorter for more difficult examples, and (c): recall improves as networks achieve better overall performance.",2.1.3 Network Strength,[0],[0]
"We conclude that delay since last review, item difficulty (loss values of training instances), and memory strength (network performance on validation data) are key indicators that affect network retention and propose to design spaced repetition algorithms that take such indicators into account in training neural networks.",2.1.3 Network Strength,[0],[0]
"We present two spaced repetition-based algorithms: a modified version of the Leitner system developed in (Reddy et al., 2016) and our Repeat before Forgetting (RbF) model respectively.",3 Spaced Repetition,[0],[0]
"Suppose we have n queues {q0, q1, . . .",3.1 Leitner System,[0],[0]
", qn−1}.",3.1 Leitner System,[0],[0]
"The Leitner system initially places all training instances in the first queue, q0.",3.1 Leitner System,[0],[0]
"As Algorithm 1 shows, at each training iteration, the Leitner scheduler chooses some queues to train a downstream neural network.",3.1 Leitner System,[0],[0]
Only instances in the selected queues will be used for training the network.,3.1 Leitner System,[0],[0]
"During training, if an instance from qi is recalled (e.g. correctly classified) by the network, the instance will be “promoted” to qi+1, otherwise it will be “demoted” to the first queue, q0.5
The Leitner scheduler reviews instances of qi at every 2i iterations.",3.1 Leitner System,[0],[0]
"Therefore, instance in lower queues (difficult/forgotten instances) are reviewed more frequently than those in higher queues (easy/recalled ones).",3.1 Leitner System,[0],[0]
Figure 3 (bottom) provides examples of queues and their processing epochs.,3.1 Leitner System,[0],[0]
"Note that the overhead imposed on training by
5 Note that in (Reddy et al., 2016) demoted instances are moved to qi−1.",3.1 Leitner System,[0],[0]
"We observed significant improvement in Leitner system by moving such instances to q0 instead of qi−1.
the Leitner system is O(|current batch|) at every epoch for moving instances between queues.",3.1 Leitner System,[0],[0]
The challenge in developing memory models is to estimate the time by which a training instance should be reviewed before it is forgotten by the network.,3.2.1 RbF Memory Models,[0],[0]
Accurate estimation of the review time leads to efficient and effective training.,3.2.1 RbF Memory Models,[0],[0]
"However, a heuristic scheduler such as Leitner system is suboptimal as its hard review schedules (i.e. only 2iiteration delays) may lead to early or late reviews.
",3.2.1 RbF Memory Models,[0],[0]
We develop flexible schedulers that take recall indicators into account in the scheduling process.,3.2.1 RbF Memory Models,[0],[0]
Our schedulers lengthen or shorten inter-repetition intervals with respect to individual training instances.,3.2.1 RbF Memory Models,[0],[0]
"In particular, we propose using density kernel functions to estimate the latest epoch in which a given training instance can be recalled.",3.2.1 RbF Memory Models,[0],[0]
"We aim to investigate how much improvement (in terms of efficiency and effectiveness) can be achieved using more flexible schedulers that utilize the recall indicators.
",3.2.1 RbF Memory Models,[0],[0]
"We propose considering density kernels as schedulers that favor (i.e., more confidently delay) less difficult training instances in stronger networks.",3.2.1 RbF Memory Models,[0],[0]
"As a kernel we can use any non-increasing function of the following quantity:
xi = di × ti se , (2)
where di indicates the loss of network for a training instance hi ∈ H, ti indicates the number of epochs to next review of hi, and se indicates the performance of network— on validation data— at epoch e. We investigate the Gaussian, Laplace, Linear, Cosine, Quadratic, and Secant kernels as described below respectively:
fgau(x, τ) = exp(−τx2), (3) flap(x, τ) = exp(−τx), (4)
flin(x, τ) = { 1− τx x < 1τ 0",3.2.1 RbF Memory Models,[0],[0]
"otherwise , (5)
fcos(x, τ) =
{ 1 2 cos(τπx)",3.2.1 RbF Memory Models,[0],[0]
"+ 1 x < 1 τ
0 otherwise ,
(6)
fqua(x, τ) = { 1− τx2",3.2.1 RbF Memory Models,[0],[0]
x2 < 1τ 0,3.2.1 RbF Memory Models,[0],[0]
"otherwise , (7)
fsec(x, τ) = 2
exp(−τx2) + exp(τx2) , (8)
where τ is a learning parameter.",3.2.1 RbF Memory Models,[0],[0]
Figure 4 depicts these kernels with τ = 1.,3.2.1 RbF Memory Models,[0],[0]
"As we will discuss in the next section, we use these kernels to optimize delay with respect to item difficulty and network strength for each training instance.",3.2.1 RbF Memory Models,[0.9553878925935979],"['For example, we show how RBP can be used to back propagate thorough the optimization of deep neural networks in order to tune hyperparameters.']"
"Our Repeat before Forgetting (RbF) model is a spaced repetition algorithm that takes into account the previously validated recall indicators to train neural networks, see Algorithm 2.",3.2.2 RbF Algorithm,[0],[0]
RbF divides training instances into current and delayed batches based on their delay values at each iteration.,3.2.2 RbF Algorithm,[0],[0]
Instances in the current batch are those that RbF is less confident about their recall and therefore are reviewed (used to re-train the network) at current iteration.,3.2.2 RbF Algorithm,[0],[0]
"On the other hand, instances in the delayed batch are those that are likely to be recalled by the network in the future and therefore are not reviewed at current epoch.",3.2.2 RbF Algorithm,[0],[0]
"At each iteration, the RbF scheduler estimates the optimum delay (number of epochs to next review) for each training instance in the current batch.",3.2.2 RbF Algorithm,[0],[0]
"RbF makes such item-specific estimations as follows:
Given the difficulty of a training instance di, the memory strength of the neural network at epoch e, se, and an RbF memory model f (see section 3.2.1), RbF scheduler estimates the maximum delay t̂i for the instance such that it can be recalled with a confidence greater than the given threshold η ∈",3.2.2 RbF Algorithm,[0],[0]
"(0, 1) at time e+ t̂i.",3.2.2 RbF Algorithm,[0],[0]
"As described before, di and se can be represented by the current loss of the network for the instance and the current performance of the network on validation data respectively.",3.2.2 RbF Algorithm,[0],[0]
"Therefore, the maximum delay between the current (epoch e) and next reviews of the instance can be estimated as follows:
t̂i = arg min ti
( f(xi, τ̂)− η )2 , (9)
",3.2.2 RbF Algorithm,[0],[0]
s.t 1 ≤,3.2.2 RbF Algorithm,[0],[0]
ti ≤ k,3.2.2 RbF Algorithm,[0],[0]
"− e
where τ̂ is the optimum value for the learning parameter obtained from validation data, see Equation (10).",3.2.2 RbF Algorithm,[0],[0]
"In principle, reviewing instances could be delayed for any number of epochs; in practice however, delay is bounded both below and above (e.g., by queues in the Leitner system).",3.2.2 RbF Algorithm,[0],[0]
"Thus, we assume that, at each epoch e, instances could be delayed for at least one iteration and at most k − e iterations where k is the total number of training epochs.",3.2.2 RbF Algorithm,[0],[0]
"We also note that ti is a lower bound of the maximum delay as se is expected to increase and di is expected to decrease as the network trains in next iterations.
",3.2.2 RbF Algorithm,[0],[0]
Algorithm 2 shows the outline of the proposed RbF model.,3.2.2 RbF Algorithm,[0],[0]
We estimate the optimum value of τ (line 5 of Algorithm 2) for RbF memory models using validation data.,3.2.2 RbF Algorithm,[0],[0]
"In particular, RbF uses the loss values of validation instances and strength of the network obtained at the previous epoch to estimate network retention for validation instances at the current epoch (therefore ti = 1 for every validation instance).",3.2.2 RbF Algorithm,[0],[0]
"The parameter τ for each memory model is computed as follows:
τ̂ = arg min τ
( f(xj , τ)− aj )2 ,∀hj ∈ V, aj ≥ η,
(10) where aj ∈ (0, 1) is the current accuracy of the model for the validation instance hj .",3.2.2 RbF Algorithm,[0],[0]
RbF then predicts the delay for current batch instances and reduces the delay for those in the delayed batch by one epoch.,3.2.2 RbF Algorithm,[0],[0]
The overhead of RbF is O(|H|) to compute delays and O(|V|) to compute τ̂ .,3.2.2 RbF Algorithm,[0],[0]
Note that (9) and (10) have closed form solutions.,3.2.2 RbF Algorithm,[0],[0]
"Table 1 describes the tasks, datasets, and models that we consider in our experiments.",4 Experiments,[0],[0]
It also reports the training epochs for which the models produce their best performance on validation data (based on rote training).,4 Experiments,[0],[0]
"We note that the Addition dataset is randomly generated and contains numbers with at most 4 digits.6
We consider three schedulers as baselines: a slightly modified version of the Leitner scheduler (Lit) developed in Reddy et al. (2016) for human learners (see Footnote 5), curriculum learning (CL) in which training instances are scheduled with respect to their easiness (Jiang et al., 2015), and the uniform scheduler of rote training (Rote) in which all instances are used for training at every epoch.",4 Experiments,[0],[0]
"For Lit, we experimented with different queue lengths, n = {3, 5, 7}, and set n = 5 in the experiments as this value led to the best performance of this scheduler across all datasets.
",4 Experiments,[0],[0]
Curriculum learning starts training with easy instances and gradually introduces more complex instances for training.,4 Experiments,[0],[0]
"Since easiness information is not readily available in most datasets, previous approaches have used heuristic techniques (Spitkovsky et al., 2010; Basu and Christensen, 2013) or optimization algorithms (Jiang et al., 2015, 2014) to quantify easiness of training instances.",4 Experiments,[0],[0]
These approaches consider an instance as easy if its loss is smaller than a threshold (λ).,4 Experiments,[0],[0]
"We adopt this technique as follows: at each iteration e, we divide the entire training data into easy and hard sets using iteration-specific λe and the loss values of instances, obtained from the current partially-trained network.",4 Experiments,[0],[0]
All easy instances in conjunction with αe ∈,4 Experiments,[0],[0]
"[0, 1] fraction of easiest hard instances (those with smallest loss values greater than λe) are used for training at",4 Experiments,[0],[0]
"iteration e. We set
6https://github.com/fchollet/keras/ blob/master/examples/addition_rnn.py
each λe to the average loss of training instances that are correctly classified by the current partiallytrained network.",4 Experiments,[0],[0]
"Furthermore, at each iteration e, we set αe = e/k to gradually introduce complex instances at every new iteration.7 Note that we treat all instances as easy at e = 0.
",4 Experiments,[0],[0]
Performance values reported in experiments are averaged over 10 runs of systems and the confidence parameter η is always set to 0.5 unless otherwise stated.,4 Experiments,[0],[0]
"In these experiments, we evaluate memory schedulers with respect to their accuracy in predicting network retention for delayed instances.",4.1 Evaluation of Memory Models,[0],[0]
"Since curriculum learning does not estimate delay for training instances, we only consider Leitner and RbF schedulers in these experiments.
",4.1 Evaluation of Memory Models,[0],[0]
"For this evaluation, if a scheduler predicts a delay t for a training instance h at epoch e, we evaluate network retention with respect to h at epoch e+ t. If the network recalls (correctly classifies) the instance at epoch e+ t, the scheduler has correctly predicted network retention for h, and otherwise, it has made a wrong prediction.",4.1 Evaluation of Memory Models,[0],[0]
We use this binary outcome to evaluate the accuracy of each scheduler.,4.1 Evaluation of Memory Models,[0],[0]
Note that the performance of schedulers on instances that have not been delayed is not a major concern.,4.1 Evaluation of Memory Models,[0],[0]
"Although failing to delay an item inversely affects efficiency, it makes the network stronger by providing more instances to train from.",4.1 Evaluation of Memory Models,[0],[0]
"Therefore, we consider a good scheduler as the one that accurately delays more items.
",4.1 Evaluation of Memory Models,[0],[0]
Figure 6 depicts the average accuracy of schedulers in predicting networks’ retention versus the average fraction of training instances that they delayed per epoch.,4.1 Evaluation of Memory Models,[0],[0]
"As the results show, all schedulers
7k is the total number of iterations.
",4.1 Evaluation of Memory Models,[0],[0]
delay substantial amount of instances per epoch.,4.1 Evaluation of Memory Models,[0],[0]
"In particular, Cos and Qua outperform Lit in both predicting network retention and delaying items, delaying around 50% of training instances per epoch.",4.1 Evaluation of Memory Models,[0],[0]
This is while Gau and Sec show comparable accuracy to Lit but delay more instances.,4.1 Evaluation of Memory Models,[0],[0]
"On the other hand, Lap, which has been found effective in Psychology, and Lin are less accurate in predicting network retention.",4.1 Evaluation of Memory Models,[0],[0]
This is because of the tradeoff between delaying more instances and creating stronger networks.,4.1 Evaluation of Memory Models,[0],[0]
"Since these schedulers are more flexible in delaying greater amount of instances, they might not provide networks with enough data to fully train.
",4.1 Evaluation of Memory Models,[0],[0]
"Figure 7 shows the performance of RbF schedulers with respect to the recall confidence parameter η, see Equation (9).",4.1 Evaluation of Memory Models,[0],[0]
"As the results show, schedulers have poor performance with smaller values of η.",4.1 Evaluation of Memory Models,[0],[0]
This is because smaller values of η make schedulers very flexible in delaying instances.,4.1 Evaluation of Memory Models,[0],[0]
"However, the performance of schedulers are not dramatically low even with very small ηs.",4.1 Evaluation of Memory Models,[0],[0]
"Our further analyses on the delay patterns show that although a smaller η leads to more delayed instances, the delays are significantly shorter.",4.1 Evaluation of Memory Models,[0],[0]
"Therefore, most delayed instances will be “reviewed” shortly in next epochs.",4.1 Evaluation of Memory Models,[0],[0]
"These bulk reviews make the network stronger and help it to recall most delayed instance in future iterations.
",4.1 Evaluation of Memory Models,[0],[0]
"On the other hand, greater ηs lead to more accurate schedulers at the cost of using more training data.",4.1 Evaluation of Memory Models,[0],[0]
"In fact, we found that larger ηs do not delay most training instances in the first few iterations.",4.1 Evaluation of Memory Models,[0],[0]
"However, once the network obtains a reasonably high performance, schedulers start delaying instances for longer durations.",4.1 Evaluation of Memory Models,[0],[0]
We will further study this effect in the next section.,4.1 Evaluation of Memory Models,[0],[0]
We compare RbF against Leitner and curriculum learning in terms of efficiency of training and effectiveness of trained models.,4.2 Efficiency and Effectiveness,[0],[0]
"We define effectiveness as the accuracy of a trained network on balanced test data, and efficiency as (a): fraction of instances used for training per epoch, and (b): required time for training the networks.",4.2 Efficiency and Effectiveness,[0],[0]
"For RbF schedulers, we set η to 0.5 and consider the best performing kernel Cosine with η = 0.9 based on results in Figure 7.
",4.2 Efficiency and Effectiveness,[0],[0]
The results in Table 2 show that all training paradigms have comparable effectiveness (Accuracy) to that of rote training (Rote).,4.2 Efficiency and Effectiveness,[0],[0]
Our RbF schedulers use less data per epoch (34-50% of data) and run considerably faster than Rote (2.90-4.78 times faster for η = 0.5).,4.2 Efficiency and Effectiveness,[0],[0]
"The results also show that Lit is slightly less accurate but runs 2.87 time faster than Rote; note that, as a scheduler, Lit is less accurate than RbF models, see Figures 6 and 7.
",4.2 Efficiency and Effectiveness,[0],[0]
"In addition, CL leads to comparable performance to RbF but is considerably slower than other schedulers.",4.2 Efficiency and Effectiveness,[0],[0]
This is because this scheduler has to identify easier instances and sort the harder ones to sample training data at each iteration.,4.2 Efficiency and Effectiveness,[0],[0]
"Overall, the performance of Lit, CL, Cos η = .5 and Cos η = .9 are only 2.76, 1.90, 1.88, and 0.67 absolute values lower than that of Rote respectively.",4.2 Efficiency and Effectiveness,[0],[0]
"Considering the achieved efficiency, these differences are negligible (see the overall gain in Table 2).
",4.2 Efficiency and Effectiveness,[0],[0]
Figure 8 reports detailed efficiency and effectiveness results across datasets and networks.,4.2 Efficiency and Effectiveness,[0],[0]
"For clear illustration, we report accuracy at iterations 2i ∀i in which Lit is trained on the entire data, and consider Cos η = .5",4.2 Efficiency and Effectiveness,[0],[0]
as RbF scheduler.,4.2 Efficiency and Effectiveness,[0],[0]
"In terms of efficiency (first row of Figure 8), CL starts with (small set of)
easier instances and gradually increases the amount of training data by adding slightly harder instances into its training set.",4.2 Efficiency and Effectiveness,[0],[0]
"On the other hand, Lit and RbF start big and gradually delay reviewing (easy) instances that the networks have learned.",4.2 Efficiency and Effectiveness,[0],[0]
"The difference between these two training paradigms is apparent in Figures 8(a)-8(c).
",4.2 Efficiency and Effectiveness,[0],[0]
The results also show that the efficiency of a training paradigm depends on the initial effectiveness of the downstream neural network.,4.2 Efficiency and Effectiveness,[0],[0]
"For CL to be efficient, the neural network need to initially have low performance (accuracy) so that the scheduler works on smaller set of easy instances.",4.2 Efficiency and Effectiveness,[0],[0]
"For example, in case of Addition, Figures 8(b) and 8(e), the initial network accuracy is only 35%, therefore most instances are expected to be initially treated as hard instances and don’t be used for training.",4.2 Efficiency and Effectiveness,[0],[0]
"On the other hand, CL shows a considerably lower efficiency for networks with slightly high initial accuracy, e.g. in case of IMDb or CIFAR10 where the initial network accuracy is above 56%, see Figures 8(a) and 8(d), and 8(c) and 8(f) respectively.
",4.2 Efficiency and Effectiveness,[0],[0]
"In contrast to CL, Lit and RbF are more efficient when the network has a relatively higher initial performance.",4.2 Efficiency and Effectiveness,[0],[0]
"A higher initial performance helps the
schedulers to more confidently delay “reviewing” most instances and therefore train with a much smaller set of instances.",4.2 Efficiency and Effectiveness,[0],[0]
"For example, since the initial network accuracy in IMDb or CIFAR10 is above 56%, Lit and RbF are considerably more efficient from the beginning of the training process.",4.2 Efficiency and Effectiveness,[0],[0]
"However, in case of low initial performance, Lit and RbF tend to avoid delaying instances at lower iterations which leads to poor efficiency at the beginning.",4.2 Efficiency and Effectiveness,[0],[0]
"This is the case for the Addition dataset in which instances are gradually delayed by these two schedulers even at epoch 8 when the performance of the network reaches above 65%, see Figures 8(e) and 8(b).",4.2 Efficiency and Effectiveness,[0],[0]
"However, Lit gains its true efficiency after iteration 12, see Figure 8(b), while RbF still gradually improves the efficiency.",4.2 Efficiency and Effectiveness,[0],[0]
"This might be because of the lower bound delays that RbF estimates, see Equation (9).
",4.2 Efficiency and Effectiveness,[0],[0]
"Furthermore, the effectiveness results in Figure 8 (bottom) show that all schedulers produce comparable accuracy to the Rote scheduler throughout the training process, not just at specific iterations.",4.2 Efficiency and Effectiveness,[0],[0]
"This indicates that these training paradigms can much faster achieve the same generalizability as standard training, see Figures 8(b) and 8(e).",4.2 Efficiency and Effectiveness,[0],[0]
We investigate the effect of spaced repetition on overtraining.,4.3 Robustness against Overtraining,[0],[0]
The optimal number of training epochs required to train fastText on the IMDb dataset is 8 epochs (see Table 1).,4.3 Robustness against Overtraining,[0],[0]
"In this experiment, we run fastText on IMDb for greater number of iterations to investigate the robustness of different schedulers against overtraining.",4.3 Robustness against Overtraining,[0],[0]
The results in Figure 9 show that Lit and RbF (Cos η = 0.5) are more robust against overtraining.,4.3 Robustness against Overtraining,[0],[0]
"In fact, the performance of Lit and RbF further improve at epoch 16 while CL and Rote overfit at epoch 16 (note that CL and Rote also require considerably more amount of time to reach to higher iterations).",4.3 Robustness against Overtraining,[0],[0]
We attribute the robustness of Lit and RbF to the scheduling mechanism which helps the networks to avoid retraining with easy instances.,4.3 Robustness against Overtraining,[0],[0]
"On the other hand, overtraining affects Lit and RbF at higher training iterations, compare performance of each scheduler at epochs 8 and 32.",4.3 Robustness against Overtraining,[0],[0]
This might be because these training paradigms overfit the network by paying too much training attention to very hard instances which might introduce noise to the model.,4.3 Robustness against Overtraining,[0],[0]
"Ebbinghaus (1913, 2013), and recently Murre and Dros (2015), studied the hypothesis of the exponential nature of forgetting, i.e. how information is lost over time when there is no attempt to retain it.",5 Related Work,[0],[0]
"Previous research identified three critical indicators that affect the probability of recall: repeated exposure to learning materials, elapsed time since their last review (Ebbinghaus, 1913; Wixted, 1990; Dempster, 1989), and more recently item difficulty (Reddy et al., 2016).",5 Related Work,[0],[0]
We based our investigation on these findings and validated that these indicators indeed affect memory retention in neural networks.,5 Related Work,[0],[0]
"We then developed training paradigms that utilize the above indicators to train networks.
",5 Related Work,[0],[0]
Bengio et al. (2009) and Kumar et al. (2010) also developed cognitively-motivated training paradigms which are inspired by the principle that learning can be more effective when training starts with easier concepts and gradually proceeds with more difficult ones.,5 Related Work,[0],[0]
"Our idea is motivated by the spaced repetition principle which indicates learning improves with repeated exposure and decays with delay since last exposure (Ebbinghaus, 1913; Dempster, 1989).",5 Related Work,[0],[0]
"Based on this principle, we developed schedulers that space the reviews of training instances over time for efficient and effective training of neural networks.",5 Related Work,[0],[0]
We developed a cognitively-motivated training paradigm (scheduler) that space instances over time for efficient and effective training of neural networks.,6 Conclusion and Future Work,[0],[0]
Our scheduler only uses a small fraction of training data per epoch but still effectively train neural networks.,6 Conclusion and Future Work,[0],[0]
It achieves this by estimating the time (number of epochs) by which training could be delayed for each instance.,6 Conclusion and Future Work,[0],[0]
"Our work was inspired by three recall indicators that affect memory retention in humans, namely difficulty of learning materials, delay since their last review, and memory strength of the learner, which we validated in the context of neural networks.
",6 Conclusion and Future Work,[0],[0]
There are several avenues for future work including the extent to which our RbF model and its kernels could be combined with curriculum learning or Leitner system to either predict easiness of novel training instances to inform curriculum learning or incorporate Leitner’s queueing mechanism to the RbF model.,6 Conclusion and Future Work,[0],[0]
"Other directions include extending RbF to dynamically learn the recall confidence parameter with respect to network behavior, or developing more flexible delay functions with theoretical analysis on their lower and upper bounds.",6 Conclusion and Future Work,[0],[0]
We thank Mitra Mohtarami for her constructive feedback during the development of this paper and anonymous reviewers for their thoughtful comments.,Acknowledgments,[0],[0]
This work was supported by National Institutes of Health (NIH) grant R01GM114355 from the National Institute of General Medical Sciences (NIGMS).,Acknowledgments,[0],[0]
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.,Acknowledgments,[0],[0]
We present a novel approach for training artificial neural networks.,abstractText,[0],[0]
Our approach is inspired by broad evidence in psychology that shows human learners can learn efficiently and effectively by increasing intervals of time between subsequent reviews of previously learned materials (spaced repetition).,abstractText,[0],[0]
We investigate the analogy between training neural models and findings in psychology about human memory model and develop an efficient and effective algorithm to train neural models.,abstractText,[0],[0]
The core part of our algorithm is a cognitively-motivated scheduler according to which training instances and their “reviews” are spaced over time.,abstractText,[0],[0]
"Our algorithm uses only 34-50% of data per epoch, is 2.9-4.8 times faster than standard training, and outperforms competing state-of-the-art baselines.1",abstractText,[0],[0]
Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks,title,[0],[0]
"With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction. 1",text,[0.9506955749474737],"['In practice, we can obtain further memory efficiency by performing updates within the for loops in-place (please refer to the example code in appendix), so that memory usage need not scale with the number of truncation steps.']"
The field of Natural Language Processing (NLP) is going through the data revolution.,1 Introduction,[0],[0]
"With the persistent increase of the heterogeneous web, for the first time in human history, written language from multiple languages, domains, and genres is now abundant.",1 Introduction,[0],[0]
"Naturally, the expectations from NLP algorithms also grow and evaluating a new algorithm on as many languages, domains, and genres as possible is becoming a de-facto standard.
",1 Introduction,[0],[0]
"1Our code is at: https://github.com/rtmdrr/replicabilityanalysis-NLP .
",1 Introduction,[0],[0]
"For example, the phrase structure parsers of Charniak (2000) and Collins (2003) were mostly evaluated on the Wall Street Journal Penn Treebank (Marcus et al., 1993), consisting of written, edited English text of economic news.",1 Introduction,[0],[0]
"In contrast, modern dependency parsers are expected to excel on the 19 languages of the CoNLL 2006-2007 shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007), and additional challenges, such as the shared task on parsing multiple English Web domains (Petrov and McDonald, 2012), are continuously proposed.
",1 Introduction,[0],[0]
"Despite the growing number of evaluation tasks, the analysis toolbox employed by NLP researchers has remained quite stable.",1 Introduction,[0],[0]
"Indeed, in most experimental NLP papers, several algorithms are compared on a number of datasets where the performance of each algorithm is reported together with per-dataset statistical significance figures.",1 Introduction,[0],[0]
"However, with the growing number of evaluation datasets, it becomes more challenging to draw comprehensive conclusions from such comparisons.",1 Introduction,[0],[0]
"This is because although the probability of drawing an erroneous conclusion from a single comparison is small, with multiple comparisons the probability of making one or more false claims may be very high.
",1 Introduction,[0],[0]
"The goal of this paper is to provide the NLP community with a statistical analysis framework, which we term Replicability Analysis, which will allow us to draw statistically sound conclusions in evaluation setups that involve multiple comparisons.",1 Introduction,[0],[0]
"The classical goal of replicability analysis is to examine the consistency of findings across studies in order to address the basic dogma of science, that a find-
471
Transactions of the Association for Computational Linguistics, vol. 5, pp.",1 Introduction,[0],[0]
"471–486, 2017.",1 Introduction,[0],[0]
Action Editor: Brian Roark.,1 Introduction,[0],[0]
"Submission batch: 3/2017; Revision batch: 7/2017; Published 11/2017.
",1 Introduction,[0],[0]
c©2017 Association for Computational Linguistics.,1 Introduction,[0],[0]
"Distributed under a CC-BY 4.0 license.
",1 Introduction,[0],[0]
"ing is more convincingly true if it is replicated in at least one more study (Heller et al., 2014; Patil et al., 2016).",1 Introduction,[0],[0]
"We adapt this goal to NLP, where we wish to ascertain the superiority of one algorithm over another across multiple datasets, which may come from different languages, domains, and genres.",1 Introduction,[0],[0]
"Finding that one algorithm outperforms another across domains gives a sense of consistency to the results and positive evidence that the better performance is not specific to a selected setup.2
In this work we address two questions: (1) Counting: For how many datasets does a given algorithm outperform another?",1 Introduction,[0],[0]
"and (2) Identification: What are these datasets?
",1 Introduction,[0],[0]
"When comparing two algorithms on multiple datasets, NLP papers often answer informally the questions we address in this work.",1 Introduction,[0],[0]
"In some cases this is done without any statistical analysis, by simply declaring better performance of a given algorithm for datasets where its performance measure is better than that of another algorithm, and counting these datasets.",1 Introduction,[0],[0]
In other cases answers are based on the p-values from statistical tests performed for each dataset: declaring better performance for datasets with p-value below the significance level (e.g. 0.05) and counting these datasets.,1 Introduction,[0],[0]
"While it is clear that the first approach is not statistically valid, it seems that our community is not aware of the fact that the second approach, which may seem statistically sound, is not valid as well.",1 Introduction,[0],[0]
"This may lead to erroneous conclusions, which result in adopting new (and probably complicated) algorithms, while they are not better than previous (probably more simple) ones.
",1 Introduction,[0],[0]
"In this work, we demonstrate this problem and show that it becomes more severe as the number of evaluation sets grows, which seems to be the current trend in NLP.",1 Introduction,[0],[0]
"We adopt a known general statistical methodology for addressing the counting (question (1)) and identification (question (2)) problems, by choosing the tests and procedures which are valid for
2“Replicability” is sometimes referred to as “reproducibility”.",1 Introduction,[0],[0]
"In recent NLP work the term reproducibility was used when trying to get identical results on the same data (Névéol et al., 2016; Marrese-Taylor and Matsuo, 2017).",1 Introduction,[0],[0]
"In this paper, we adopt the meaning of “replicability” and its distinction from “reproducibility” from Peng (2011) and Leek and Peng (2015) and refer to replicability analysis as the effort to show that a finding is consistent over different datasets from different domains or languages, and is not idiosyncratic to a specific scenario.
situations encountered in NLP problems, and giving specific recommendations for such situations.
",1 Introduction,[0],[0]
"Particularly, we first demonstrate (Section 3) that the current prominent approach in the NLP literature, identifying the datasets for which the difference between the performance of the algorithms reaches a predefined significance level according to some statistical significance test, does not guarantee to bound the probability to make at least one erroneous claim.",1 Introduction,[0],[0]
Hence this approach is error-prone when the number of participating datasets is large.,1 Introduction,[0],[0]
We thus propose an alternative approach (Section 4).,1 Introduction,[0],[0]
"For question (1), we adopt the approach of Benjamini et al. (2009) to replicability analysis of multiple studies, based on the partial conjunction framework of Benjamini and Heller (2008).",1 Introduction,[0],[0]
This analysis comes with a guarantee that the probability of overestimating the true number of datasets with effect is upper bounded by a predefined constant.,1 Introduction,[0],[0]
"For question (2), we motivate a multiple testing procedure which guarantees that the probability of making at least one erroneous claim on the superiority of one algorithm over another is upper bounded by a predefined constant.
",1 Introduction,[0],[0]
"In Sections 5 and 6 we demonstrate how to apply the proposed frameworks to two synthetic data toy examples and four NLP applications: multidomain dependency parsing, multilingual POS tagging, cross-domain sentiment classification, and word similarity prediction with word embedding models.",1 Introduction,[0],[0]
"Our results demonstrate that the current practice in NLP for addressing our questions is error-prone, and illustrate the differences between it and the proposed statistically sound approach.
",1 Introduction,[0],[0]
"We hope that this work will encourage our community to increase the number of standard evaluation setups per task when appropriate (e.g. including additional languages and domains), possibly paving the way to hundreds of comparisons per study.",1 Introduction,[0],[0]
This is due to two main reasons.,1 Introduction,[0],[0]
"First, replicability analysis is a statistically sound framework that allows a researcher to safely draw valid conclusions with well defined statistical guarantees.",1 Introduction,[0],[0]
"Moreover, this framework provides a means of summarizing a large number of experiments with a handful of easily interpretable numbers (e.g., see Table 1).",1 Introduction,[0],[0]
"This allows researchers to report results over a large number of comparisons in a concise manner, delving into details of particular comparisons when necessary.",1 Introduction,[0],[0]
"Our work recognizes the current trend in the NLP community where, for many tasks and applications, the number of evaluation datasets constantly increases.",2 Previous Work,[0],[0]
We believe this trend is inherent to language processing technology due to the multiplicity of languages and of linguistic genres and domains.,2 Previous Work,[0],[0]
"In order to extend the reach of NLP algorithms, they have to be designed so that they can deal with many languages and with the various domains of each.",2 Previous Work,[0],[0]
"Having a sound statistical framework that can deal with multiple comparisons is hence crucial for the field.
",2 Previous Work,[0],[0]
This section is hence divided into two.,2 Previous Work,[0],[0]
"We start by discussing representative examples for multiple comparisons in NLP, focusing on evaluations across multiple languages and multiple domains.",2 Previous Work,[0],[0]
"We then discuss existing analysis frameworks for multiple comparisons, both in the NLP and in the machine learning literatures, pointing to the need for establishing new standards for our community.
",2 Previous Work,[0],[0]
"Multiple Comparisons in NLP Multiple comparisons of algorithms over datasets from different languages, domains and genres have become a de-facto standard in many areas of NLP.",2 Previous Work,[0],[0]
Here we survey a number of representative examples.,2 Previous Work,[0],[0]
"A full list of NLP tasks is beyond the scope of this paper.
",2 Previous Work,[0],[0]
"A common multilingual example is, naturally, machine translation, where it is customary to compare algorithms across a large number of sourcetarget language pairs.",2 Previous Work,[0],[0]
"This is done, for example, with the Europarl corpus consisting of 21 European languages (Koehn, 2005; Koehn and Schroeder, 2007) and with the datasets of the WMT workshop series with its multiple domains (e.g. news and biomedical in 2017), each consisting of several language pairs (7 and 14, respectively, in 2017).
",2 Previous Work,[0.9554106975726716],"['(9) in the derivation of original RBP, one would naturally think of the most common iterative solver, i.e., conjugate gradient method (Hestenes & Stiefel, 1952).']"
Multiple dataset comparisons are also abundant in domain adaptation work.,2 Previous Work,[0],[0]
"Representative tasks include named entity recognition (Guo et al., 2009), POS tagging (Daumé III, 2007), dependency parsing (Petrov and McDonald, 2012), word sense disambiguation (Chan and Ng, 2007) and sentiment classification (Blitzer et al., 2006; Blitzer et al., 2007).
",2 Previous Work,[0],[0]
"More recently, with the emergence of crowdsourcing that makes data collection cheap and fast (Snow et al., 2008), an ever growing number of datasets is being created.",2 Previous Work,[0],[0]
"This is particularly notice-
able in lexical semantics tasks that have become central in NLP research due to the prominence of neural networks.",2 Previous Work,[0],[0]
"For example, it is customary to compare word embedding models (Mikolov et al., 2013; Pennington et al., 2014; Ó",2 Previous Work,[0],[0]
"Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014; Schwartz et al., 2015) on multiple datasets where word pairs are scored according to the degree to which different semantic relations, such as similarity and association, hold between the members of the pair (Finkelstein et al., 2001a; Bruni et al., 2014; Silberer and Lapata, 2014; Hill et al., 2015).",2 Previous Work,[0],[0]
"In some works (e.g., Baroni et al. (2014))",2 Previous Work,[0],[0]
"these embedding models are compared across a large number of simple tasks.
",2 Previous Work,[0],[0]
"As discussed in Section 1, the outcomes of such comparisons are often summarized in a table that presents numerical performance values, usually accompanied by statistical significance figures and sometimes also with cross-comparison statistics such as average performance figures.",2 Previous Work,[0],[0]
"Here, we analyze the conclusions that can be drawn from this information and suggest that with the growing number of comparisons, a more intricate analysis is required.
",2 Previous Work,[0],[0]
"Existing Analysis Frameworks Machine learning work on multiple dataset comparisons dates back to Dietterich (1998) who raised the question: “given two learning algorithms and datasets from several domains, which algorithm will produce more accurate classifiers when trained on examples from new domains?”.",2 Previous Work,[0],[0]
The seminal work that proposed practical means for this problem is that of Demšar (2006).,2 Previous Work,[0],[0]
"Given performance measures for two algorithms on multiple datasets, the authors test whether there is at least one dataset on which the difference between the algorithms is statistically significant.",2 Previous Work,[0],[0]
"For this goal they propose methods such as a paired t-test, a nonparametric sign-rank test and a wins/losses/ties count, all computed across the results collected from all participating datasets.",2 Previous Work,[0],[0]
"In contrast, our goal is to count and identify the datasets for which one algorithm significantly outperforms the other, which provides more intricate information, especially when the datasets come from different sources.
",2 Previous Work,[0],[0]
"In NLP, several studies addressed the problem of measuring the statistical significance of results on a single dataset (e.g., Berg-Kirkpatrick et al. (2012); Søgaard (2013); Søgaard et al. (2014)).",2 Previous Work,[0],[0]
"Søgaard
(2013) is, to the best of our knowledge, the only work that addressed the statistical properties of evaluation with multiple datasets.",2 Previous Work,[0],[0]
"For this aim he modified the statistical tests proposed in Demšar (2006) to use a Gumbel distribution assumption on the test statistics, which he considered to suit NLP better than the original Gaussian assumption.",2 Previous Work,[0],[0]
"However, while this procedure aims to estimate the effect size across datasets, it answers neither the counting nor the identification question of Section 1.
",2 Previous Work,[0],[0]
In the next section we provide the preliminary knowledge from the field of statistics that forms the basis for the proposed framework and then proceed with its description.,2 Previous Work,[0],[0]
We start by formulating a general hypothesis testing framework for a comparison between two algorithms.,3 Preliminaries,[0],[0]
"This is a common type of hypothesis testing framework applied in NLP, its detailed formulation will help us develop our ideas.",3 Preliminaries,[0],[0]
"We wish to compare between two algorithms, A and B. Let X be a collection of datasets X = {X1, X2, . . .",3.1 Hypothesis Testing,[0],[0]
", XN}, where for all i ∈ {1, . . .",3.1 Hypothesis Testing,[0],[0]
", N}, Xi = {xi,1, . . .",3.1 Hypothesis Testing,[0],[0]
", xi,ni} .",3.1 Hypothesis Testing,[0],[0]
Each dataset Xi can be of a different language or a different domain.,3.1 Hypothesis Testing,[0],[0]
"We denote by xi,k the granular unit on which results are being measured, that, in most NLP tasks, is a word or a sequence of words.",3.1 Hypothesis Testing,[0],[0]
"The difference in performance between the two algorithms is measured using one or more of the evaluation measures in the setM = {M1, . . .",3.1 Hypothesis Testing,[0],[0]
",Mm}.3
Let us denoteMj(ALG,Xi) as the value of the measureMj when algorithmALG is applied on the dataset Xi.",3.1 Hypothesis Testing,[0],[0]
"Without loss of generality, we assume that higher values of the measure are better.",3.1 Hypothesis Testing,[0],[0]
"We define the difference in performance between two algorithms, A and B, according to the measure",3.1 Hypothesis Testing,[0],[0]
"Mj on the dataset Xi as:
δj(X i) =Mj(A,Xi)−Mj(B,Xi).
",3.1 Hypothesis Testing,[0],[0]
"3To keep the discussion concise, throughout this paper we assume that only one evaluation measure is used.",3.1 Hypothesis Testing,[0],[0]
"Our framework can be easily extended to deal with multiple measures.
",3.1 Hypothesis Testing,[0],[0]
"Finally, using this notation we formulate the following statistical hypothesis testing problem:
H0i(j) :δj(X i) ≤ 0
H1i(j) :δj(X i) > 0.
(1)
The null hypothesis, stating that there is no difference between the performance of algorithm A and algorithmB, or thatB performs better, is tested versus the alternative statement thatA is superior.",3.1 Hypothesis Testing,[0],[0]
"If the statistical test results in rejecting the null hypothesis, one concludes that A outperforms B in this setup.",3.1 Hypothesis Testing,[0],[0]
"Otherwise, there is not enough evidence in the data to make this conclusion.
",3.1 Hypothesis Testing,[0],[0]
"Rejection of the null hypothesis when it is true is termed type I error, and non-rejection of the null hypothesis when the alternative is true is termed type II error.",3.1 Hypothesis Testing,[0],[0]
"The classical approach to hypothesis testing is to find a test that guarantees that the probability of making a type I error is upper bounded by a predefined constant α, the test significance level, while achieving as low probability of type II error as possible, a.k.a “achieving as high power as possible”.
",3.1 Hypothesis Testing,[0],[0]
We next turn to the case where the difference between two algorithms is tested across multiple datasets.,3.1 Hypothesis Testing,[0],[0]
Equation 1 defines a multiple hypothesis testing problem when considering the formulation for all N datasets.,3.2 The Multiplicity Problem,[0],[0]
"If N is large, testing each hypothesis separately at the nominal significance level may result in a high number of erroneously rejected null hypotheses.",3.2 The Multiplicity Problem,[0],[0]
"In our context, when the performance of algorithm A is compared to that of algorithm B across multiple datasets, and for each dataset algorithm A is declared as superior, based on a statistical test at the nominal significance level α, the expected number of erroneous claims may grow as N grows.
",3.2 The Multiplicity Problem,[0],[0]
"For example, if a single test is performed with a significance level of α = 0.05, there is only a 5% chance of incorrectly rejecting the null hypothesis.",3.2 The Multiplicity Problem,[0],[0]
"On the other hand, for 100 tests where all null hypotheses are true, the expected number of incorrect rejections is 100 · 0.05 = 5.",3.2 The Multiplicity Problem,[0],[0]
"Denoting the total number of type I errors as V , we can see below that if the test statistics are independent then the probability of
making at least one incorrect rejection is 0.994:
P(V > 0)",3.2 The Multiplicity Problem,[0],[0]
"= 1− P(V = 0) =
1− 100∏
i=1
P(no type I error in i)",3.2 The Multiplicity Problem,[0],[0]
"=1− (1− 0.05)100.
",3.2 The Multiplicity Problem,[0],[0]
This demonstrates that the naive method of counting the datasets for which significance was reached at the nominal level is error-prone.,3.2 The Multiplicity Problem,[0],[0]
"Similar examples can be constructed for situations where some of the null hypotheses are false.
",3.2 The Multiplicity Problem,[0],[0]
"The multiple testing literature proposes various procedures for bounding the probability of making at least one type I error, as well as other, less restrictive error criteria (see a survey in Farcomeni (2007)).",3.2 The Multiplicity Problem,[0],[0]
"In this paper, we address the questions of counting and identifying the datasets for which algorithm A outperforms B, with certain statistical guarantees regarding erroneous claims.",3.2 The Multiplicity Problem,[0],[0]
"While identifying the datasets gives more information when compared to just declaring their number, we consider these two questions separately.",3.2 The Multiplicity Problem,[0],[0]
"As our experiments show, according to the statistical analysis we propose the estimated number of datasets with effect (question 1) may be higher than the number of identified datasets (question 2).",3.2 The Multiplicity Problem,[0],[0]
We next present the fundamentals of the partial conjunction framework which is at the heart of our proposed methods.,3.2 The Multiplicity Problem,[0],[0]
We start by reformulating the set of hypothesis testing problems of Equation 1 as a unified hypothesis testing problem.,3.3 Partial Conjunction Hypotheses,[0],[0]
This problem aims to identify whether algorithm A is superior to B across all datasets.,3.3 Partial Conjunction Hypotheses,[0],[0]
"The notation for the null hypothesis in this problem is HN/N0 since we test if N out of N alternative hypotheses are true:
H N/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
":
N⋃
i=1
H0i is true vs. H N/N 1 :
N⋂
i=1
H1i is true.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"Requiring the rejection of the disjunction of all null hypotheses is often too restrictive for it involves observing a significant effect on all datasets, i ∈ {1, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
", N}.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Instead, one can require a rejection of the global null hypothesis stating that all individual null hypotheses are true, i.e., evidence that
at least one alternative hypothesis is true.",3.3 Partial Conjunction Hypotheses,[0],[0]
"This hypothesis testing problem is formulated as follows:
H 1/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
":
N⋂
i=1
H0i is true vs. H 1/N 1 :
N⋃
i=1
H1i is true.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"Obviously, rejecting the global null may not provide enough information: it only indicates that algorithm A outperforms B on at least one dataset.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Hence, this claim does not give any evidence for the consistency of the results across multiple datasets.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"A natural compromise between the above two formulations is to test the partial conjunction null, which states that the number of false null hypotheses is lower than u, where 1 ≤ u ≤ N is a pre-specified integer constant.",3.3 Partial Conjunction Hypotheses,[0],[0]
"The partial conjunction test contrasts this statement with the alternative statement that at least u out of the N null hypotheses are false.
",3.3 Partial Conjunction Hypotheses,[0],[0]
Definition 1 (Benjamini and Heller (2008)).,3.3 Partial Conjunction Hypotheses,[0],[0]
"Consider N ≥ 2 null hypotheses: H01, H02, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
",H0N , and let p1, . . .",3.3 Partial Conjunction Hypotheses,[0],[0]
", pN be their associated p−values.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Let k be the true unknown number of false null hypotheses, then our question “Are at least u out of N null hypotheses false?” can be formulated as follows:
H u/N 0",3.3 Partial Conjunction Hypotheses,[0],[0]
:,3.3 Partial Conjunction Hypotheses,[0],[0]
"k < u vs. H u/N 1 : k ≥ u.
",3.3 Partial Conjunction Hypotheses,[0],[0]
"In our context, k is the number of datasets where algorithm A is truly better, and the partial conjunction test examines whether algorithmA outperforms algorithm B in at least u of N cases.
",3.3 Partial Conjunction Hypotheses,[0],[0]
Benjamini and Heller (2008) developed a general method for testing the above hypothesis for a given u. They also showed how to extend their method in order to answer our counting question.,3.3 Partial Conjunction Hypotheses,[0],[0]
"We next describe their framework and advocate a different, yet related method for dataset identification.",3.3 Partial Conjunction Hypotheses,[0],[0]
"Referred to as the cornerstone of science (Moonesinghe et al., 2007), replicability analysis is of predominant importance in many scientific fields including psychology (Collaboration, 2012), genomics (Heller et al., 2014), economics (Herndon et al., 2014) and medicine (Begley and Ellis, 2012), among others.",4 Replicability Analysis for NLP,[0],[0]
"Findings are usually considered as replicated if they are obtained in two or more
studies that differ from each other in some aspects (e.g. language, domain or genre in NLP).
",4 Replicability Analysis for NLP,[0],[0]
"The replicability analysis framework we employ (Benjamini and Heller, 2008; Benjamini et al., 2009) is based on partial conjunction testing.",4 Replicability Analysis for NLP,[0],[0]
"Particularly, these authors have shown that a lower bound on the number of false null hypotheses with a confidence level of 1 − α can be obtained by finding the largest u for which we can reject the partial conjunction null hypothesis Hu/N0 along with H
1/N 0 , . . .",4 Replicability Analysis for NLP,[0],[0]
",H (u−1)/N 0 at a significance levelα.",4 Replicability Analysis for NLP,[0],[0]
"Since rejecting Hu/N0 means that we see evidence in at least u out of N datasets, algorithm",4 Replicability Analysis for NLP,[0],[0]
"A is superior to B. This lower bound on k is taken as our answer to the Counting question of Section 1.
",4 Replicability Analysis for NLP,[0],[0]
"In line with the hypothesis testing framework of Section 3, the partial conjunction null, Hu/N0 , is rejected at level α if pu/N ≤ α, where pu/N is the partial conjunction p-value.",4 Replicability Analysis for NLP,[0],[0]
"Based on the known methods for testing the global null hypothesis (see, e.g., Loughin (2004)), Benjamini and Heller (2008) proposed methods for combining the p−values p1, . . .",4 Replicability Analysis for NLP,[0],[0]
", pN of H01, H02, . . .",4 Replicability Analysis for NLP,[0],[0]
",H0N in order to obtain pu/N .",4 Replicability Analysis for NLP,[0],[0]
"Below, we describe two such methods and their properties.",4 Replicability Analysis for NLP,[0],[0]
"The methods we focus on were developed by Benjamini and Heller (2008), and are based on Fisher’s and Bonferroni’s methods for testing the global null hypothesis.",4.1 The Partial Conjunction p−value,[0],[0]
"For brevity, we name them Bonferroni and Fisher.",4.1 The Partial Conjunction p−value,[0],[0]
"We choose them because they are valid in different setups that are frequently encountered in NLP (Section 6): Bonferroni for dependent datasets and both Fisher and Bonferroni for independent datasets.4
Bonferroni’s method does not make any assumptions about the dependencies between the participating datasets and it is hence applicable in NLP tasks, since in NLP it is most often hard to determine the type of dependence between the datasets.",4.1 The Partial Conjunction p−value,[0],[0]
"Fisher’s method, while assuming independence across the
4For simplicity we refer to dependent/independent datasets as those for which the test statistics are dependent/independent.",4.1 The Partial Conjunction p−value,[0],[0]
"We assume the test statistics are independent if the corresponding datasets do not have mutual samples, and one dataset is not a transformation of the other.
participating datasets, is often more powerful than Bonferroni’s method (see Loughin (2004) and Benjamini and Heller (2008) for other methods and a comparison between them).",4.1 The Partial Conjunction p−value,[0],[0]
"Our recommendation is hence to use the Bonferroni’s method when the datasets are dependent and to use the more powerful Fisher’s method when the datasets are independent.
",4.1 The Partial Conjunction p−value,[0],[0]
"Let p(i) be the i-th smallest p−value among p1, . . .",4.1 The Partial Conjunction p−value,[0],[0]
", pN .",4.1 The Partial Conjunction p−value,[0],[0]
"The partial conjunction p−values are:
p u/N Bonferroni = (N − u+ 1)p(u) (2)
p u/N Fisher = P ( χ22(N−u+1) ≥ −2",4.1 The Partial Conjunction p−value,[0],[0]
"N∑
i=u
ln p(i)
) (3)
where χ22(N−u+1) denotes a chi-squared random variable with 2(N − u+ 1) degrees of freedom.
",4.1 The Partial Conjunction p−value,[0],[0]
"To understand the reasoning behind these methods, let us consider first the above p−values for testing the global null, i.e., for the case of u = 1.",4.1 The Partial Conjunction p−value,[0],[0]
Rejecting the global null hypothesis requires evidence that at least one null hypothesis is false.,4.1 The Partial Conjunction p−value,[0],[0]
"Intuitively, we would like to see one or more small p−values.
",4.1 The Partial Conjunction p−value,[0],[0]
Both of the methods above agree with this intuition.,4.1 The Partial Conjunction p−value,[0],[0]
"Bonferroni’s method rejects the global null if p(1) ≤ α/N , i.e. if the minimum p−value is small enough, where the threshold guarantees that the significance level of the test is α for any dependency among the p−values p1, . . .",4.1 The Partial Conjunction p−value,[0],[0]
", pN .",4.1 The Partial Conjunction p−value,[0],[0]
"Fisher’s method rejects the global null for large values of −2∑Ni=1 ln p(i), or equivalently for small values of∏N i=1",4.1 The Partial Conjunction p−value,[0],[0]
pi.,4.1 The Partial Conjunction p−value,[0],[0]
"That is, while both these methods are intuitive, they are different.",4.1 The Partial Conjunction p−value,[0],[0]
Fisher’s method requires a small enough product of p−values as evidence that at least one null hypothesis is false.,4.1 The Partial Conjunction p−value,[0],[0]
"Bonferroni’s method, on the other hand, requires as evidence at least one small enough p−value.
",4.1 The Partial Conjunction p−value,[0],[0]
"For the case u = N , i.e., when the alternative states that all null hypotheses are false, both methods require that the maximal p−value is small enough for rejection of HN/N0 .",4.1 The Partial Conjunction p−value,[0],[0]
This is also intuitive because we expect that all the p−values will be small when all the null hypotheses are false.,4.1 The Partial Conjunction p−value,[0],[0]
"For other cases, where 1 < u < N , the reasoning is more complicated and is beyond the scope of this paper.
",4.1 The Partial Conjunction p−value,[0],[0]
The partial conjunction test for a specific u answers the question “Does algorithm A perform better than B on at least u datasets?”,4.1 The Partial Conjunction p−value,[0],[0]
"The next step is
the estimation of the number of datasets for which algorithm A performs better than B.",4.1 The Partial Conjunction p−value,[0],[0]
Recall that the number of datasets where algorithm A outperforms algorithm B (denoted with k in Definition 1) is the true number of false null hypotheses in our problem.,4.2 Dataset Counting (Question 1),[0],[0]
"Benjamini and Heller (2008) proposed to estimate k to be the largest u for which H u/N 0 , along with H 1/N 0 , . . .",4.2 Dataset Counting (Question 1),[0],[0]
",H (u−1)/N 0 is rejected.",4.2 Dataset Counting (Question 1),[0],[0]
"Specifically, the estimator k̂ is defined as follows:
k̂ = max{u : pu/N∗ ≤",4.2 Dataset Counting (Question 1),[0],[0]
"α}, (4)
where pu/N∗ = max{p(u−1)/N∗ , pu/N}, p1/N = p1/N∗",4.2 Dataset Counting (Question 1),[0],[0]
and α is the desired upper bound on the probability to overestimate the true k.,4.2 Dataset Counting (Question 1),[0],[0]
"It is guaranteed that P(k̂ > k) ≤ α as long as the p−value combination method used for constructing pu/N is valid for the given dependency across the test statistics.5 When k̂ is based on pu/NBonferroni it is denoted with k̂Bonferroni; when it is based on p u/N Fisher, it is denoted with k̂Fisher.",4.2 Dataset Counting (Question 1),[0],[0]
"A crucial practical consideration, when choosing between k̂Bonferroni and k̂Fisher, is the assumed dependency between the datasets.",4.2 Dataset Counting (Question 1),[0],[0]
"As discussed in Section 4.1, pu/NFisher is recommended when the participating datasets are assumed to be independent; when this assumption cannot be made, only pu/NBonferroni is appropriate.",4.2 Dataset Counting (Question 1),[0],[0]
"As the k̂ estimators are based on the respective pu/N s, the same considerations hold when choosing between them.
",4.2 Dataset Counting (Question 1),[0],[0]
"With the k̂ estimators, one can answer the counting question of Section 1, reporting that algorithm",4.2 Dataset Counting (Question 1),[0],[0]
A is better than algorithm B in at least k̂ out of N datasets with a confidence level of 1 − α.,4.2 Dataset Counting (Question 1),[0],[0]
"Regarding the identification question, a natural approach would be to declare the k̂ datasets with the smallest p−values as those for which the effect holds.",4.2 Dataset Counting (Question 1),[0],[0]
"However, with k̂Fisher this approach does not guarantee control over type I errors.",4.2 Dataset Counting (Question 1),[0],[0]
"In contrast, for k̂Bonferroni, the above approach comes with such guarantees, as described in the next section.
",4.2 Dataset Counting (Question 1),[0],[0]
5This result is a special case of Theorem 4 in Benjamini and Heller (2008).,4.2 Dataset Counting (Question 1),[0],[0]
"As demonstrated in Section 3.2, identifying the datasets with p−value below the nominal significance level and declaring them as those where algorithm A is better than B may lead to a very high number of erroneous claims.",4.3 Dataset Identification (Question 2),[0],[0]
A variety of methods exist for addressing this problem.,4.3 Dataset Identification (Question 2),[0],[0]
"A classical and very simple method for addressing this problem is named the Bonferroni’s procedure, which compensates for the increased probability of making at least one type I error by testing each individual hypothesis at a significance level of α′ = α/N , where α is the predefined bound on this probability and N is the number of hypotheses tested.6 While Bonferroni’s procedure is valid for any dependency among the p−values, the probability of detecting a true effect using this procedure is often very low, because of its strict p−value threshold.
",4.3 Dataset Identification (Question 2),[0],[0]
"Many other procedures controlling the above or other error criteria, and having less strict p−value thresholds, have been proposed.",4.3 Dataset Identification (Question 2),[0],[0]
"Below we advocate one of these methods: the Holm procedure (Holm, 1979).",4.3 Dataset Identification (Question 2),[0],[0]
This is a simple p−value based procedure that is concordant with the partial conjunction analysis when pu/NBonferroni is used in that analysis.,4.3 Dataset Identification (Question 2),[0],[0]
"Importantly for NLP applications, Holm controls the probability of making at least one type I error for any type of dependency between the participating datasets (see a demonstration in Section 6).
",4.3 Dataset Identification (Question 2),[0],[0]
"Let α be the desired upper bound on the probability that at least one false rejection occurs, let p(1) ≤",4.3 Dataset Identification (Question 2),[0],[0]
p(2) ≤ . . .,4.3 Dataset Identification (Question 2),[0],[0]
≤,4.3 Dataset Identification (Question 2),[0],[0]
p(N) be the ordered p−values and let the associated hypotheses be H(1) . . .,4.3 Dataset Identification (Question 2),[0],[0]
H(N).,4.3 Dataset Identification (Question 2),[0],[0]
"The Holm procedure for identifying the datasets with a significant effect is given below.
",4.3 Dataset Identification (Question 2),[0],[0]
Procedure Holm 1),4.3 Dataset Identification (Question 2),[0],[0]
"Let k be the minimal index such that
p(k)",4.3 Dataset Identification (Question 2),[0],[0]
> α N+1−k . 2) Reject the null hypotheses H(1) . . .,4.3 Dataset Identification (Question 2),[0],[0]
H(k−1),4.3 Dataset Identification (Question 2),[0],[0]
"and
do not reject H(k) . . .",4.3 Dataset Identification (Question 2),[0],[0]
H(N).,4.3 Dataset Identification (Question 2),[0],[0]
"If no such k exists, then reject all null hypotheses.
",4.3 Dataset Identification (Question 2),[0],[0]
The output of the Holm procedure is a rejection 6Bonferroni’s correction is based on similar considerations as pu/NBonferroni for u = 1 (Eq. 2).,4.3 Dataset Identification (Question 2),[0],[0]
"The partial conjunction framework (Sec. 4.1) extends this idea for other values of u.
list of null hypotheses; the corresponding datasets are those we return in response to the identification question of Section 1.",4.3 Dataset Identification (Question 2),[0],[0]
Note that the Holm procedure rejects a subset of hypotheses with p-value below α.,4.3 Dataset Identification (Question 2),[0],[0]
Each p-value is compared to a threshold which is smaller or equal to α and depends on the number of evaluation datasets N.,4.3 Dataset Identification (Question 2),[0],[0]
"The dependence of the thresholds on N can be intuitively explained as follows: the probability of making one or more erroneous claims may increase with N, as demonstrated in Section 3.2.",4.3 Dataset Identification (Question 2),[0],[0]
"Therefore, in order to bound this probability by a pre-specified level α, the thresholds for p-values should depend on N.
It can be shown that the Holm procedure at level α always rejects the k̂Bonferroni hypotheses with the smallest p−values, where k̂Bonferroni is the lower bound for k with a confidence level of 1 − α.",4.3 Dataset Identification (Question 2),[0],[0]
"Therefore, k̂Bonferroni corresponding to a confidence level of 1 − α is always smaller or equal to the number of datasets for which the difference between the compared algorithms is significant at level α.",4.3 Dataset Identification (Question 2),[0],[0]
"This is not surprising in view of the fact that, without making any assumptions on the dependencies among the datasets, k̂Bonferroni guarantees that the probability of making a too optimistic claim (k̂ > k) is bounded by α, when simply counting the number of datasets with p-value below α, the probability of making a too optimistic claim may be close to 1, as demonstrated in Section 5.
",4.3 Dataset Identification (Question 2),[0],[0]
Framework Summary Following Section 4.2 we answer the counting question of Section 1 by reporting either k̂Fisher (when all datasets can be assumed to be independent) or k̂Bonferroni (when such an independence assumption cannot be made).,4.3 Dataset Identification (Question 2),[0],[0]
"Based on Section 4.3 we suggest to answer the identification question of Section 1 by reporting the rejection list returned by the Holm procedure.
",4.3 Dataset Identification (Question 2),[0],[0]
Our proposed framework is based on certain assumptions regarding the experiments conducted in NLP setups.,4.3 Dataset Identification (Question 2),[0],[0]
The most prominent of these assumptions states that for dependent datasets the type of dependency cannot be determined.,4.3 Dataset Identification (Question 2),[0],[0]
"Indeed, to the best of our knowledge, the nature of the dependency between dependent test sets in NLP work has not been analyzed before.",4.3 Dataset Identification (Question 2),[0],[0]
In Section 7 we revisit our assumptions and point to alternative methods for answering our questions.,4.3 Dataset Identification (Question 2),[0],[0]
"These methods may be ap-
propriate under other assumptions that may become relevant in future.
",4.3 Dataset Identification (Question 2),[0],[0]
We next demonstrate the value of the proposed replicability analysis through toy examples with synthetic data (Section 5) as well as analysis of state-of-the-art algorithms for four major NLP applications (Section 6).,4.3 Dataset Identification (Question 2),[0],[0]
"Our point of reference is the standard, yet statistically unjustified, counting method that sets its estimator, k̂count, to the number of datasets for which the difference between the compared algorithms is significant with p−value ≤ α (i.e. k̂count = #{i : pi ≤ α}).7",4.3 Dataset Identification (Question 2),[0],[0]
"For the examples of this section we synthesize p−values to emulate a test with N = 100 hypotheses (domains), and set α to 0.05.",5 Toy Examples,[0],[0]
"We start with a simulation of a scenario where algorithmA is equivalent to B for each domain, and the datasets representing these domains are independent.",5 Toy Examples,[0],[0]
"We sample the 100 p−values from a standard uniform distribution, which is the p−value distribution under the null hypothesis, repeating the simulation 1,000 times.
",5 Toy Examples,[0],[0]
"Since all the null hypotheses are true then k, the number of false null hypotheses, is 0.",5 Toy Examples,[0],[0]
"Figure 1 presents the histogram of k̂ values from all 1,000 iterations according to k̂Bonferroni, k̂Fisher and k̂count.
",5 Toy Examples,[0],[0]
The figure clearly demonstrates that k̂count provides an overestimation of k while k̂Bonferroni and k̂Fisher do much better.,5 Toy Examples,[0],[0]
"Indeed, the histogram yields the following probability estimates: P̂ (k̂count >
7We use α in two different contexts: the significance level of an individual test and the bound on the probability to overestimate k.",5 Toy Examples,[0],[0]
"This is the standard notation in the statistical literature.
",5 Toy Examples,[0],[0]
"k) = 0.963, P̂ (k̂Bonferroni > k) = 0.001 and P̂ (k̂Fisher > k) = 0.021 (only the latter two are lower than 0.05).",5 Toy Examples,[0],[0]
"This simulation strongly supports the theoretical results of Section 4.2.
",5 Toy Examples,[0],[0]
"To consider a scenario where a dependency between the participating datasets does exist, we consider a second toy example.",5 Toy Examples,[0],[0]
"In this example we generate N = 100 p−values corresponding to 34 independent normal test statistics, and two other groups of 33 positively correlated normal test statistics with ρ = 0.2 and ρ = 0.5, respectively.",5 Toy Examples,[0],[0]
"We again assume that all null hypotheses are true and thus all the p−values are distributed uniformly, repeating the simulation 1,000 times.",5 Toy Examples,[0],[0]
"To generate positively dependent p−values, we followed the process described in Section 6.1 of Benjamini et al. (2006).
",5 Toy Examples,[0],[0]
We estimate the probability that k̂ > k,5 Toy Examples,[0],[0]
= 0,5 Toy Examples,[0],[0]
"for the three k̂ estimators based on the 1000 repetitions and get the values of: P̂ (k̂count > k) = 0.943, P̂ (k̂Bonferroni > k) = 0.046 and P̂ (k̂Fisher > k) = 0.234.",5 Toy Examples,[0],[0]
"This simulation demonstrates the importance of using Bonferroni’s method rather than Fisher’s method when the datasets are dependent, even if some of the datasets are independent.",5 Toy Examples,[0],[0]
In this section we demonstrate the potential impact of replicability analysis on the way experimental results are analyzed in NLP setups.,6 NLP Applications,[0],[0]
We explore four NLP applications: (a) two where the datasets are independent: multi-domain dependency parsing and multilingual POS tagging; and (b) two where dependency between the datasets does exist: cross-domain sentiment classification and word similarity prediction with word embedding models.,6 NLP Applications,[0],[0]
"Dependency Parsing We consider a multidomain setup, analyzing the results reported in Choi et al. (2015).",6.1 Data,[0],[0]
"The authors compared ten state-of-the-art parsers from which we pick three: (a) Mate (Bohnet, 2010)8 that performed best on the majority of datasets; (b) Redshift (Honnibal et al., 2013)9 which demonstrated comparable, still somewhat lower, performance compared to Mate;
8code.google.com/p/mate-tools.",6.1 Data,[0],[0]
"9github.com/syllog1sm/Redshift.
",6.1 Data,[0],[0]
"and (c) SpaCy (Honnibal and Johnson, 2015) that was substantially outperformed by Mate.
",6.1 Data,[0],[0]
"All parsers were trained and tested on the English portion of the OntoNotes 5 corpus (Weischedel et al., 2011; Pradhan et al., 2013), a large multigenre corpus consisting of the following 7 genres: broadcasting conversations (BC), broadcasting news (BN), news magazine (MZ), newswire (NW), pivot text (PT), telephone conversations (TC) and web text (WB).",6.1 Data,[0],[0]
"Train and test set size (in sentences) range from 6672 to 34,492 and from 280 to 2327, respectively (see Table 1 of Choi et al. (2015)).",6.1 Data,[0],[0]
"We copy the test set UAS results of Choi et al. (2015) and compute p−values using the data downloaded from http://amandastent.com/dependable/.
POS Tagging We consider a multilingual setup, analyzing the results reported in (Pinter et al., 2017).",6.1 Data,[0],[0]
"The authors compare their MIMICK model with the model of Ling et al. (2015), denoted with CHAR→TAG.",6.1 Data,[0],[0]
"Evaluation is performed on 23 of the 44 languages shared by the Polyglot word embedding dataset (Al-Rfou et al., 2013) and the universal dependencies (UD) dataset (De Marneffe et al., 2014).",6.1 Data,[0],[0]
"Pinter et al. (2017) choose their languages so that they reflect a variety of typological, and particularly morphological, properties.",6.1 Data,[0],[0]
The training/test split is the standard UD split.,6.1 Data,[0],[0]
"We copy the word level accuracy figures of Pinter et al. (2017) for the low resource training set setup, the focus setup of that paper.",6.1 Data,[0],[0]
"The authors kindly sent us their p-values.
",6.1 Data,[0],[0]
"Sentiment Classification In this task, an algorithm is trained on reviews from one domain and should classify the sentiment of reviews from another domain to the positive and negative classes.",6.1 Data,[0],[0]
For replicability analysis we explore the results of Ziser and Reichart (2017) for the cross-domain sentiment classification task of Blitzer et al. (2007).,6.1 Data,[0],[0]
"The data in this task consists of Amazon product reviews from 4 domains: books (B), DVDs (D), electronic items (E), and kitchen appliances (K), for the total of 12 domain pairs, each domain having a 2000 review test set.10 Ziser and Reichart (2017) compared the accuracy of their AE-SCL-SR model to MSDA (Chen et al., 2011), a well known domain adaptation
10http://www.cs.jhu.edu/˜mdredze/ datasets/sentiment
method, and kindly sent us the required p-values.
",6.1 Data,[0],[0]
Word Similarity We compare two state-of-the-art word embedding collections: (a) word2vec,6.1 Data,[0],[0]
"CBOW (Mikolov et al., 2013) vectors, generated by the model titled the best “predict” model in Baroni et al. (2014);11 and (b) GloVe (Pennington et al., 2014) vectors generated by a model trained on a 42B token common web crawl.12 We employed the demo of Faruqui and Dyer (2014) to perform a Spearman correlation evaluation of these vector collections on 12 English word pair datasets: WS-353 (Finkelstein et al., 2001b), WS-353-SIM (Agirre et al., 2009), WS-353-REL (Agirre et al., 2009), MC-30 (Miller and Charles, 1991), RG-65 (Rubenstein and Goodenough, 1965), Rare-Word (Luong et al., 2013), MEN (Bruni et al., 2012), MTurk-287 (Radinsky et al., 2011), MTurk-771",6.1 Data,[0],[0]
"(Halawi et al., 2012), YP-130 (Yang and Powers, ), SimLex-999 (Hill et al., 2016), and Verb-143 (Baker et al., 2014).",6.1 Data,[0],[0]
"We first calculate the p−values for each task and dataset according to the principals of p−values computation for NLP as discussed in Yeh (2000), BergKirkpatrick et al. (2012) and Søgaard et al. (2014).
",6.2 Statistical Significance Tests,[0],[0]
"For dependency parsing, we employ the aparametric paired bootstrap test (Efron and Tibshirani, 1994) that does not assume any distribution on the test statistics.",6.2 Statistical Significance Tests,[0],[0]
We chose this test because the distribution of the values for the measures commonly applied in this task is unknown.,6.2 Statistical Significance Tests,[0],[0]
"We implemented the test as in (Berg-Kirkpatrick et al., 2012) with a bootstrap size of 500 and with 105 repetitions.
",6.2 Statistical Significance Tests,[0],[0]
"For multilingual POS tagging, we employ the Wilcoxon signed-rank test (Wilcoxon, 1945) on the differences of the sentence level accuracy scores of the two compared models.",6.2 Statistical Significance Tests,[0],[0]
"This test is a nonparametric test for differences in measure, testing the null hypothesis that the difference has a symmetric distribution around zero.",6.2 Statistical Significance Tests,[0],[0]
"It is appropriate for tasks with paired continuous measures for each observation, which is the case when comparing sentence level accuracies.
",6.2 Statistical Significance Tests,[0],[0]
11http://clic.cimec.unitn.it/composes/ semantic-vectors.html.,6.2 Statistical Significance Tests,[0],[0]
"Parameters: 5-word context window, 10 negative samples, subsampling, 400 dimensions.
",6.2 Statistical Significance Tests,[0],[0]
"12http://nlp.stanford.edu/projects/glove/. 300 dimensions.
",6.2 Statistical Significance Tests,[0],[0]
"For sentiment classification we employ the McNemar test for paired nominal data (McNemar, 1947).",6.2 Statistical Significance Tests,[0],[0]
"This test is appropriate for binary classification tasks and since we compare the results of the algorithms when applied on the same datasets, we employ its paired version.",6.2 Statistical Significance Tests,[0],[0]
"Finally, for word similarity with its Spearman correlation evaluation, we choose the Steiger test (Steiger, 1980) for comparing elements in a correlation matrix.
",6.2 Statistical Significance Tests,[0],[0]
We consider the case of α = 0.05 for all four applications.,6.2 Statistical Significance Tests,[0],[0]
"For the dependent datasets experiments (sentiment classification and word similarity prediction) with their generally lower p−values (see below), we also consider the case where α = 0.01.",6.2 Statistical Significance Tests,[0],[0]
"Table 1 summarizes the replicability analysis results while Table 2 – 5 present task specific performance measures and p−values.
",6.3 Results,[0],[0]
"Independent Datasets Dependency parsing (Table 2) and multilingual POS tagging (Table 3) are our example tasks for this setup, where k̂Fisher is our recommended valid estimator for the number of cases where one algorithm outperforms another.
",6.3 Results,[0],[0]
"For dependency parsing, we compare two scenarios: (a) where in most domains the differences between the compared algorithms are quite large and the p−values are small (Mate vs. SpaCy); and (b)
where in most domains the differences between the compared algorithms are smaller and the p−values are higher (Mate vs. Redshift).",6.3 Results,[0],[0]
"Our multilingual POS tagging scenario (MIMICK vs. Char→Tag) is more similar to scenario (b) in terms of the differences between the participating algorithms.
",6.3 Results,[0],[0]
Table 1 demonstrates the k̂ estimators for the various tasks and scenarios.,6.3 Results,[0],[0]
"For dependency parsing, as expected, in scenario (a) where all the p−values are small, all estimators, even the error-prone k̂count, provide the same information.",6.3 Results,[0],[0]
"In case (b) of dependency parsing, however, k̂Fisher estimates the number of domains where Mate outperforms Redshift to be 5, while k̂count estimates this number to be 2.",6.3 Results,[0],[0]
This is a substantial difference given that the number of domains is 7.,6.3 Results,[0],[0]
"The k̂Bonferroni estimator, that is valid under arbitrary dependencies, is even more conservative than k̂count and its estimation is only 1.
",6.3 Results,[0],[0]
"Perhaps not surprisingly, the multilingual POS
tagging results are similar to case (b) of dependency parsing.",6.3 Results,[0],[0]
"Here, again, k̂count is too conservative, estimating the number of languages with effect to be 11 (out of 23) while k̂Fisher estimates this number to be 16 (an increase of 5/23 in the estimated number of languages with effect).",6.3 Results,[0],[0]
"k̂Bonferroni is again more conservative, estimating the number of languages with effect to be only 6, which is not very surprising given that it does not exploit the independence between the datasets.",6.3 Results,[0],[0]
"These two examples of case (b) demonstrate that when the differences between the algorithms are quite small, k̂Fisher may be more sensitive than the current practice in NLP for discovering the number of datasets with effect.
",6.3 Results,[0],[0]
"To complete the analysis, we would like to name the datasets with effect.",6.3 Results,[0],[0]
"As discussed in Section 4.2, while this can be straightforwardly done by naming the datasets with the k̂ smallest p−values, in general, this approach does not control the probability of identifying at least one dataset erroneously.",6.3 Results,[0],[0]
"We thus employ the Holm procedure for the identification task, noticing that the number of datasets it identifies should be equal to the value of the k̂Bonferroni estimator (Section 4.3).
",6.3 Results,[0],[0]
"Indeed, for dependency parsing in case (a), the Holm procedure identifies all seven domains as cases where Mate outperforms SpaCy, while in case (b) it identifies only the MZ domain as a case where Mate outperforms Redshift.",6.3 Results,[0],[0]
"For multilingual POS
tagging the Holm procedure identifies Tamil, Hungarian, Basque, Indonesian, Chinese and Czech as languages where MIMICK outperforms Char→Tag.",6.3 Results,[0],[0]
"This analysis demonstrates that when the performance gap between two algorithms becomes narrower, inquiring for more information (i.e. identifying the domains with effect rather than just estimating their number), may result in weaker results.13
Dependent Datasets In cross-domain sentiment classification (Table 4) and word similarity prediction (Table 5), the involved datasets manifest mutual dependence.",6.3 Results,[0],[0]
"Particularly, each sentiment setup shares its test dataset with 2 other setups, while in word similarity WS-353 is the union of WS-353REL and WS-353-SIM.",6.3 Results,[0],[0]
"As discussed in Section 4, k̂Bonferroni is the appropriate estimator of the number of cases one algorithm outperforms another.
",6.3 Results,[0],[0]
"The results in Table 1 manifest the phenomenon demonstrated by the second toy example in Section 5, which shows that when the datasets are dependent, k̂Fisher as well as the error-prone k̂count may be too optimistic regarding the number of datasets with effect.",6.3 Results,[0],[0]
"This stands in contrast to k̂Bonferroni which controls the probability to overestimate the number of such datasets.
",6.3 Results,[0],[0]
"Indeed, k̂Bonferroni is much more conservative, yielding values of 6 (α = 0.05) and 2 (α = 0.01) for sentiment, and of 6 (α = 0.05) and 4 (α = 0.01) for word similarity.",6.3 Results,[0],[0]
The differences from the conclusions that might have been drawn by k̂count are again quite substantial.,6.3 Results,[0],[0]
"The difference between k̂Bonferroni and k̂count in sentiment classification is 4, which accounts to 1/3 of the 12 test setups.",6.3 Results,[0],[0]
"Even for word similarity, the difference between the two methods, which account to 2 for both α values, represents 1/6 of the 12 test setups.",6.3 Results,[0],[0]
"The domains identified by the Holm procedure are marked in the tables.
",6.3 Results,[0],[0]
"Results Overview Our goal in this section is to demonstrate that the approach of simply looking at the number of datasets for which the difference between the performance of the algorithms reaches a predefined significance level, gives different results
13For completeness, we also performed the analysis for the independent dataset setups with α = 0.01.",6.3 Results,[0],[0]
"The results are (k̂count, k̂Bonferroni, k̂Fisher): Mate vs. SpaCy: (7,7,7); Mate vs. Redshift (1,0,2); MIMICK vs. Char→Tag: (7,5,13).",6.3 Results,[0],[0]
"The patterns are very similar to those discussed in the text.
from our suggested statistically sound analysis.",6.3 Results,[0],[0]
This approach is denoted here with k̂count and shown to be statistically not valid in Sections 3.2 and 5.,6.3 Results,[0],[0]
We observe that this happens especially in evaluation setups where the differences between the algorithms are small for most datasets.,6.3 Results,[0],[0]
"In some cases, when the datasets are independent, our analysis has the power to declare a larger number of datasets with effect than the number of individual significant test values (k̂count).",6.3 Results,[0],[0]
"In other cases, when the datasets are interdependent, k̂count is much too optimistic.
",6.3 Results,[0],[0]
Our proposed analysis changes the observations that might have been made based on the papers where the results analyzed here were originally reported.,6.3 Results,[0],[0]
"For example, for the Mate-Redshift comparison (independent evaluation sets), we show that there is evidence that the number of datasets with effect is much higher than one would assume based on counting the significant sets (5 vs. 2 out of 7 evaluation sets), giving a stronger claim regarding the superiority of Mate.",6.3 Results,[0],[0]
"In multilingual POS tagging (again, a setup of independent evaluation sets) our analysis shows evidence for 16 sets with effect compared to only 11 of the erroneous count method - a difference in 5 out of 23 evaluation sets (21.7%).",6.3 Results,[0],[0]
"Finally, in the cross-domain sentiment classification and the word similarity judgment tasks (dependent evaluation sets), the unjustified counting method may be too optimistic (e.g. 10 vs. 6 out of 12 evaluation sets, for α = 0.05 in the sentiment task), in favor of the new algorithms.",6.3 Results,[0],[0]
We proposed a statistically sound replicability analysis framework for cases where algorithms are compared across multiple datasets.,7 Discussion and Future Directions,[0],[0]
"Our main contributions are: (a) analyzing the limitations of the current practice in NLP work; and (b) proposing a framework that addresses both the estimation of the number of datasets with effect and their identification.
",7 Discussion and Future Directions,[0],[0]
The framework we propose addresses two different situations encountered in NLP: independent and dependent datasets.,7 Discussion and Future Directions,[0],[0]
"For dependent datasets, we assumed that the type of dependency cannot be determined.",7 Discussion and Future Directions,[0],[0]
One could use more powerful methods if certain assumptions on the dependency between the test statistics could be made.,7 Discussion and Future Directions,[0],[0]
"For example, one could use
the partial conjunction p-value based on Simes test for the global null hypothesis (Simes, 1986), which was proposed by Benjamini and Heller (2008) for the case where the test statistics satisfy certain positive dependency properties (see Theorem 1 in (Benjamini and Heller, 2008)).",7 Discussion and Future Directions,[0],[0]
"Using this partial conjunction p-value rather than the one based on Bonferroni, one may obtain higher values of k̂ with the same statistical guarantee.",7 Discussion and Future Directions,[0],[0]
"Similarly, for the identification question, if certain positive dependency properties hold, Holm’s procedure could be replaced by Hochberg’s or Hommel’s procedures (Hochberg, 1988; Hommel, 1988) which are more powerful.
",7 Discussion and Future Directions,[0],[0]
"An alternative, more powerful multiple testing procedure for identification of datasets with effect, is the method in Benjamini and Hochberg (1995), that controls the false discovery rate (FDR), a less strict error criterion than the one considered here.",7 Discussion and Future Directions,[0],[0]
"This method is more appropriate in cases where one may tolerate some errors as long as the proportion of errors among all the claims made is small, as expected to happen when the number of datasets grows.
",7 Discussion and Future Directions,[0],[0]
We note that the increase in the number of evaluation datasets may have positive and negative aspects.,7 Discussion and Future Directions,[0],[0]
"As noted in Section 2, we believe that multiple comparisons are integral to NLP research when aiming to develop algorithms that perform well across languages and domains.",7 Discussion and Future Directions,[0],[0]
"On the other hand, experimenting with multiple evaluation sets that reflect very similar linguistic phenomena may only complicate the comparison between alternative algorithms.
",7 Discussion and Future Directions,[0],[0]
"In fact, our analysis is useful mostly where the datasets are heterogeneous, coming from different languages or domains.",7 Discussion and Future Directions,[0],[0]
"When they are just technically different but could potentially be just combined into a one big dataset, then we believe the question of Demšar (2006), whether at least one dataset shows evidence for effect, is more appropriate.",7 Discussion and Future Directions,[0],[0]
The research of M. Bogomolov was supported by the Israel Science Foundation grant No. 1112/14.,Acknowledgement,[0],[0]
We thank Yuval Pinter for his great help with the multilingual experiments and for his useful feedback.,Acknowledgement,[0],[0]
"We also thank Ruth Heller, Marten van Schijndel, Oren Tsur, Or Zuk and the ie@technion NLP group members for their useful comments.",Acknowledgement,[0],[0]
"With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups.",abstractText,[0],[0]
"However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions.",abstractText,[0],[0]
In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks.,abstractText,[0],[0]
"We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.",abstractText,[0],[0]
1,abstractText,[0],[0]
Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets,title,[0],[0]
Graphs are a ubiquitous structure that widely occurs in data analysis problems.,1. Introduction,[0],[0]
"Real-world graphs such as social networks, financial networks, biological networks and citation networks represent important rich information which is not seen from the individual entities alone, for example, the communities a person is in, the functional role of a molecule, and the sensitivity of the assets of an enterprise to external shocks.",1. Introduction,[0],[0]
"Therefore, representation learning of nodes in graphs aims to extract high-level features from a node as well as its neighborhood, and has proved extremely useful for many applications, such as node classification, clustering, and link prediction (Perozzi et al., 2014; Monti et al.,
1Massachusetts Institute of Technology (MIT) 2National Institute of Informatics, Tokyo.",1. Introduction,[0],[0]
Correspondence to: Keyulu Xu,1. Introduction,[0],[0]
"<keyulu@mit.edu>, Stefanie Jegelka <stefje@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
2017; Grover & Leskovec, 2016; Tang et al., 2015).
",1. Introduction,[0],[0]
Recent works focus on deep learning approaches to node representation.,1. Introduction,[0],[0]
"Many of these approaches broadly follow a neighborhood aggregation (or “message passing” scheme), and those have been very promising (Kipf & Welling, 2017; Hamilton et al., 2017; Gilmer et al., 2017; Veličković",1. Introduction,[0],[0]
"et al., 2018; Kearnes et al., 2016).",1. Introduction,[0],[0]
"These models learn to iteratively aggregate the hidden features of every node in the graph with its adjacent nodes’ as its new hidden features, where an iteration is parametrized by a layer of the neural network.",1. Introduction,[0],[0]
"Theoretically, an aggregation process of k iterations makes use of the subtree structures of height k rooted at every node.",1. Introduction,[0],[0]
"Such schemes have been shown to generalize the Weisfeiler-Lehman graph isomorphism test (Weisfeiler & Lehman, 1968) enabling to simultaneously learn the topology as well as the distribution of node features in the neighborhood (Shervashidze et al., 2011; Kipf & Welling, 2017; Hamilton et al., 2017).
",1. Introduction,[0],[0]
"Yet, such aggregation schemes sometimes lead to surprises.",1. Introduction,[0],[0]
"For example, it has been observed that the best performance with one of the state-of-the-art models, Graph Convolutional Networks (GCN), is achieved with a 2-layer model.",1. Introduction,[0],[0]
"Deeper versions of the model that, in principle, have access to more information, perform worse (Kipf & Welling, 2017).",1. Introduction,[0],[0]
"A similar degradation of learning for computer vision problems is resolved by residual connections (He et al., 2016a) that greatly aid the training of deep models.",1. Introduction,[0],[0]
"But, even with residual connections, GCNs with more layers do not perform as well as the 2-layer GCN on many datasets, e.g. citation networks.
",1. Introduction,[0],[0]
"Motivated by observations like the above, in this paper, we address two questions.",1. Introduction,[0],[0]
"First, we study properties and resulting limitations of neighborhood aggregation schemes.",1. Introduction,[0],[0]
"Second, based on this analysis, we propose an architecture that, as opposed to existing models, enables adaptive, structure-aware representations.",1. Introduction,[0],[0]
"Such representations are particularly interesting for representation learning on large complex graphs with diverse subgraph structures.
",1. Introduction,[0],[0]
Model analysis.,1. Introduction,[0],[0]
"To better understand the behavior of different neighborhood aggregation schemes, we analyze the effective range of nodes that any given node’s representation draws from.",1. Introduction,[0],[0]
"We summarize this sensitivity analysis by what
we name the influence distribution of a node.",1. Introduction,[0],[0]
This effective range implicitly encodes prior assumptions on what are the “nearest neighbors” that a node should draw information from.,1. Introduction,[0],[0]
"In particular, we will see that this influence is heavily affected by the graph structure, raising the question whether “one size fits all”, in particular in graphs whose subgraphs have varying properties (such as more tree-like or more expander-like).
",1. Introduction,[0],[0]
"In particular, our more formal analysis connects influence distributions with the spread of a random walk at a given node, a well-understood phenomenon as a function of the graph structure and eigenvalues (Lovász, 1993).",1. Introduction,[0],[0]
"For instance, in some cases and applications, a 2-step random walk influence that focuses on local neighborhoods can be more informative than higher-order features where some of the information may be “washed out” via averaging.
",1. Introduction,[0],[0]
Changing locality.,1. Introduction,[0],[0]
"To illustrate the effect and importance of graph structure, recall that many real-world graphs possess locally strongly varying structure.",1. Introduction,[0],[0]
"In biological and citation networks, the majority of the nodes have few connections, whereas some nodes (hubs) are connected to many other nodes.",1. Introduction,[0],[0]
"Social and web networks usually consist of an expander-like core part and an almost-tree (bounded treewidth) part, which represent well-connected entities and the small communities respectively (Leskovec et al., 2009; Maehara et al., 2014; Tsonis et al., 2006).
",1. Introduction,[0],[0]
"Besides node features, this subgraph structure has great impact on the result of neighborhood aggregation.",1. Introduction,[0],[0]
"The speed of expansion or, equivalently, growth of the influence radius, is characterized by the random walk’s mixing time, which changes dramatically on subgraphs with different structures (Lovász, 1993).",1. Introduction,[0],[0]
"Thus, the same number of iterations (layers) can lead to influence distributions of very different locality.",1. Introduction,[0],[0]
"As an example, consider the social network in Figure 1 from GooglePlus (Leskovec & Mcauley, 2012).",1. Introduction,[0],[0]
The figure illustrates the expansions of a random walk starting at the square node.,1. Introduction,[0],[0]
The walk (a) from a node within the core rapidly includes almost the entire graph.,1. Introduction,[0],[0]
"In contrast, the walk (b) starting at a node in the tree part includes only a very small fraction of all nodes.",1. Introduction,[0],[0]
"After 5 steps, the same walk has reached the core and, suddenly, spreads quickly.",1. Introduction,[0],[0]
"Translated to graph representation models, these spreads become the influence distributions or, in other words, the averaged features yield the new feature of the walk’s starting node.",1. Introduction,[0],[0]
"This shows that in the same graph, the same number of steps can lead to very different effects.",1. Introduction,[0],[0]
"Depending on the application, wide-range or smallrange feature combinations may be more desirable.",1. Introduction,[0],[0]
"A too rapid expansion may average too broadly and thereby lose information, while in other parts of the graph, a sufficient neighborhood may be needed for stabilizing predictions.
",1. Introduction,[0],[0]
JK networks.,1. Introduction,[0],[0]
"The above observations raise the question
whether it is possible to adaptively adjust (i.e., learn) the influence radii for each node and task.",1. Introduction,[0],[0]
"To achieve this, we explore an architecture that learns to selectively exploit information from neighborhoods of differing locality.",1. Introduction,[0],[0]
"This architecture selectively combines different aggregations at the last layer, i.e., the representations “jump” to the last layer.",1. Introduction,[0],[0]
"Hence, we name the resulting networks Jumping Knowledge Networks (JK-Nets).",1. Introduction,[0],[0]
"We will see that empirically, when adaptation is an option, the networks indeed learn representations of different orders for different graph substructures.",1. Introduction,[0],[0]
"Moreover, in Section 6, we show that applying our framework to various state-of-the-art neighborhood-aggregation models consistently improves their performance.",1. Introduction,[0],[0]
"We begin by summarizing some of the most common neighborhood aggregation schemes and, along the way, introduce our notation.",2. Background and Neighborhood aggregation schemes,[0],[0]
"Let G = (V,E) be a simple graph with node features Xv ∈",2. Background and Neighborhood aggregation schemes,[0],[0]
Rdi for v ∈ V .,2. Background and Neighborhood aggregation schemes,[0],[0]
Let G̃ be the graph obtained by adding a self-loop to every v ∈ V .,2. Background and Neighborhood aggregation schemes,[0],[0]
The hidden feature of node v learned by the l-th layer of the model is denoted by h (l) v ∈,2. Background and Neighborhood aggregation schemes,[0],[0]
Rdh .,2. Background and Neighborhood aggregation schemes,[0],[0]
"Here, di is the dimension of the input features and dh is the dimension of the hidden features, which, for simplicity of exposition, we assume to be the same across layers.",2. Background and Neighborhood aggregation schemes,[0],[0]
We also use h(0)v = Xv for the node feature.,2. Background and Neighborhood aggregation schemes,[0],[0]
"The neighborhood N(v) = {u ∈ V | (v, u) ∈ E} of node v is the set of adjacent nodes of v. The analogous neighborhood Ñ(v) = {v} ∪ {u ∈ V | (v, u) ∈ E} on G̃ includes v.
A typical neighborhood aggregation scheme can generically be written as follows: for a k-layer model, the l-th layer (l = 1..k) updates h(l)v for every v ∈ V simultaneously as
h(l)v = σ",2. Background and Neighborhood aggregation schemes,[0],[0]
"( Wl · AGGREGATE ({ h(l−1)u ,∀u ∈ Ñ(v) }))",2. Background and Neighborhood aggregation schemes,[0],[0]
"(1)
where AGGREGATE is an aggregation function defined by the specific model, Wl is a trainable weight matrix on the lth layer shared by all nodes, and σ is a non-linear activation function, e.g. a ReLU.
",2. Background and Neighborhood aggregation schemes,[0],[0]
Graph Convolutional Networks (GCN).,2. Background and Neighborhood aggregation schemes,[0],[0]
"Graph Convolutional Networks (GCN) (Kipf & Welling, 2017), initially motivated by spectral graph convolutions (Hammond et al., 2011; Defferrard et al., 2016), are a specific instantiation of this framework (Gilmer et al., 2017), of the form
h(l)v = ReLU ( Wl · ∑ u∈Ñ(v) (deg(v)deg(u))−1/2 h(l−1)u ) (2)
where deg(v) is the degree of node v in G. Hamilton et al. (2017) derived a variant of GCN that also works in inductive settings (previously unseen nodes), by using a different normalization to average:
h(l)v",2. Background and Neighborhood aggregation schemes,[0],[0]
"= ReLU ( Wl · 1
d̃eg(v) ∑ u∈Ñ(v) h(l−1)u ) (3)
where d̃eg(v) is the degree of node v in G̃.
Neighborhood Aggregation with Skip Connections.",2. Background and Neighborhood aggregation schemes,[0],[0]
Instead of aggregating a node and its neighbors at the same time as in Eqn.,2. Background and Neighborhood aggregation schemes,[0],[0]
"(1), a number of recent approaches aggregate the neighbors first and then combine the resulting neighborhood representation with the node’s representation from the last iteration.",2. Background and Neighborhood aggregation schemes,[0],[0]
"More formally, each node is updated as
h (l) N(v) = σ",2. Background and Neighborhood aggregation schemes,[0],[0]
"( Wl · AGGREGATEN ( {h(l−1)u ,∀u ∈ N(v)} )) h(l)v =",2. Background and Neighborhood aggregation schemes,[0],[0]
"COMBINE ( h(l−1)v , h (l) N(v)
) where AGGREGATEN and COMBINE are defined by the specific model.",2. Background and Neighborhood aggregation schemes,[0],[0]
The COMBINE step is key to this paradigm and can be viewed as a form of a ”skip connection” between different layers.,2. Background and Neighborhood aggregation schemes,[0],[0]
"For COMBINE, GraphSAGE (Hamilton et al., 2017) uses concatenation after a feature transform.",2. Background and Neighborhood aggregation schemes,[0],[0]
"Column Networks (Pham et al., 2017) interpolate the neighborhood representation and the node’s previous representation, and Gated GNN (Li et al., 2016) uses the Gated Recurrent Unit (GRU) (Cho et al., 2014).",2. Background and Neighborhood aggregation schemes,[0],[0]
"Another wellknown variant of skip connections, residual connections, use the identity mapping to help signals propagate (He et al., 2016a;b).
",2. Background and Neighborhood aggregation schemes,[0],[0]
"These skip connections are input- but not output-unit specific: If we ”skip” a layer for h(l)v (do not aggregate) or use a certain COMBINE, all subsequent units using this representation will be using this skip implicitly.",2. Background and Neighborhood aggregation schemes,[0],[0]
It is impossible that a certain higher-up representation h(l+j)u uses the skip and another one does not.,2. Background and Neighborhood aggregation schemes,[0],[0]
"As a result, skip connections cannot adaptively adjust the neighborhood sizes of the final-layer representations independently.
",2. Background and Neighborhood aggregation schemes,[0],[0]
Neighborhood Aggregation with Directional Biases.,2. Background and Neighborhood aggregation schemes,[0],[0]
"Some recent models, rather than treating the features of
adjacent nodes equally, weigh “important” neighbors more.",2. Background and Neighborhood aggregation schemes,[0],[0]
"This paradigm can be viewed as neighborhood-aggregation with directional biases because a node will be influenced by some directions of expansion more than the others.
",2. Background and Neighborhood aggregation schemes,[0],[0]
"Graph Attention Networks (GAT) (Veličković et al., 2018) and VAIN (Hoshen, 2017) learn to select the important neighbors via an attention mechanism.",2. Background and Neighborhood aggregation schemes,[0],[0]
"The max-pooling operation in GraphSAGE (Hamilton et al., 2017) implicitly selects the important nodes.",2. Background and Neighborhood aggregation schemes,[0],[0]
"This line of work is orthogonal to ours, because it modifies the direction of expansion whereas our model operates on the locality of expansion.",2. Background and Neighborhood aggregation schemes,[0],[0]
Our model can be combined with these models to add representational power.,2. Background and Neighborhood aggregation schemes,[0],[0]
"In Section 6, we demonstrate that our framework works with not only simple neighborhood-aggregation models (GCN), but also with skip connections (GraphSAGE) and directional biases (GAT).",2. Background and Neighborhood aggregation schemes,[0],[0]
"Next, we explore some important properties of the above aggregation schemes.",3. Influence Distribution and Random Walks,[0],[0]
"Related to ideas of sensitivity analysis and influence functions in statistics (Koh & Liang, 2017) that measure the influence of a training point on parameters, we study the range of nodes whose features affect a given node’s representation.",3. Influence Distribution and Random Walks,[0],[0]
"This range gives insight into how large a neighborhood a node is drawing information from.
",3. Influence Distribution and Random Walks,[0],[0]
"We measure the sensitivity of node x to node y, or the influence of y on x, by measuring how much a change in the input feature of y affects the representation of x in the last layer.",3. Influence Distribution and Random Walks,[0],[0]
"For any node x, the influence distribution captures the relative influences of all other nodes.
",3. Influence Distribution and Random Walks,[0],[0]
Definition 3.1 (Influence score and distribution).,3. Influence Distribution and Random Walks,[0],[0]
"For a simple graph G = (V,E), let h(0)x be the input feature and h
(k) x be the learned hidden feature of node x ∈ V at the k-th (last) layer of the model.",3. Influence Distribution and Random Walks,[0],[0]
"The influence score I(x, y) of node x by any node y ∈ V is the sum of the absolute values
of the entries of the Jacobian matrix [ ∂h(k)x ∂h (0) y ] .",3. Influence Distribution and Random Walks,[0],[0]
"We define the influence distribution Ix of x ∈ V by normalizing the influence scores: Ix(y) = I(x, y)/ ∑ z I(x, z), or
Ix(y) = e T
[ ∂h (k) x
∂h (0) y
] e /(∑
z∈V eT
[ ∂h (k) x
∂h (0) z
] e )
where e is the all-ones vector.
",3. Influence Distribution and Random Walks,[0],[0]
"Later, we will see connections of influence distributions with random walks.",3. Influence Distribution and Random Walks,[0],[0]
"For completeness, we also define random walk distributions.
",3. Influence Distribution and Random Walks,[0],[0]
Definition 3.2.,3. Influence Distribution and Random Walks,[0],[0]
"Consider a random walk on G̃ starting at a node v0; if at the t-th step we are at a node vt, we move to any neighbor of vt (including vt) with equal probability.
",3. Influence Distribution and Random Walks,[0],[0]
"The t-step random walk distribution Pt of v0 is
Pt (i) =",3. Influence Distribution and Random Walks,[0],[0]
Prob (vt = i) .,3. Influence Distribution and Random Walks,[0],[0]
"(4)
Analogous definitions apply for random walks with nonuniform transition probabilities.
",3. Influence Distribution and Random Walks,[0],[0]
An important property of the random walk distribution is that it becomes more spread out as t increases and converges to the limit distribution if the graph is non-bipartite.,3. Influence Distribution and Random Walks,[0],[0]
"The rate of convergence depends on the structure of the subgraph and can be bounded by the spectral gap (or the conductance) of the random walk’s transition matrix (Lovász, 1993).",3. Influence Distribution and Random Walks,[0],[0]
The influence distribution for different aggregation models and nodes can give insights into the information captured by the respective representations.,3.1. Model Analysis,[0],[0]
The following results show that the influence distributions of common aggregation schemes are closely connected to random walk distributions.,3.1. Model Analysis,[0],[0]
"This observation hints at specific implications – strengths and weaknesses – that we will discuss.
",3.1. Model Analysis,[0],[0]
"With a randomization assumption of the ReLU activations similar to that in (Kawaguchi, 2016; Choromanska et al., 2015), we can draw connections between GCNs and random walks:
Theorem 1.",3.1. Model Analysis,[0],[0]
"Given a k-layer GCN with averaging as in Equation (3), assume that all paths in the computation graph of the model are activated with the same probability of success ρ.",3.1. Model Analysis,[0],[0]
"Then the influence distribution Ix for any node
x ∈ V is equivalent, in expectation, to the k-step random walk distribution on G̃ starting at node x.
We prove Theorem 1 in the appendix.
",3.1. Model Analysis,[0],[0]
It is straightforward to modify the proof of Theorem 1 to show a nearly equivalent result for the version of GCN in Equation (2).,3.1. Model Analysis,[0],[0]
"The only difference is that each random walk path v0p, v 1 p, ..., v k p from node x (v 0 p) to y (v k p), in-
stead of probability ρ ∏k l=1 1
d̃eg(vlp) , now has probability
ρ Q ∏k−1 l=1 1
d̃eg(vlp) · (d̃eg(x)d̃eg(y))−1/2, where Q is a nor-
malizing factor.",3.1. Model Analysis,[0],[0]
"Thus, the difference in probability is small, especially when the degree of x and y are close.
",3.1. Model Analysis,[0],[0]
"Similarly, we can show that neighborhood aggregation schemes with directional biases resemble biased random walk distributions.",3.1. Model Analysis,[0],[0]
"This follows by substituting the corresponding probabilities into the proof of Theorem 1.
",3.1. Model Analysis,[0],[0]
"Empirically, we observe that, despite somewhat simplifying assumptions, our theory is close to what happens in practice.",3.1. Model Analysis,[0],[0]
"We visualize the heat maps of the influence distributions for a node (labeled square) for trained GCNs, and compare with the random walk distributions starting at the same node.",3.1. Model Analysis,[0],[0]
Figure 2 shows example results.,3.1. Model Analysis,[0],[0]
Darker colors correspond to higher influence probabilities.,3.1. Model Analysis,[0],[0]
"To show the effect of skip connections, Figure 3 visualizes the analogous heat maps for one example—GCN with residual connections.",3.1. Model Analysis,[0],[0]
"Indeed, we observe that the influence distributions of networks with residual connections approximately correspond to lazy random walks: each step has a higher probability of staying at
the current node.",3.1. Model Analysis,[0],[0]
Local information is retained with similar probabilities for all nodes in each iteration; this cannot adapt to diverse needs of specific upper-layer nodes.,3.1. Model Analysis,[0],[0]
"Further visualizations may be found in the appendix.
",3.1. Model Analysis,[0],[0]
Fast Collapse on Expanders.,3.1. Model Analysis,[0],[0]
"To better understand the implication of Theorem 1 and the limitations of the corresponding neighborhood aggregation algorithms, we revisit the scenario of learning on a social network shown in Figure 1.",3.1. Model Analysis,[0],[0]
"Random walks starting inside an expander converge rapidly in O(log |V |) steps to an almost-uniform distribution (Hoory et al., 2006).",3.1. Model Analysis,[0],[0]
"After O(log |V |) iterations of neighborhood aggregation, by Theorem 1 the representation of every node is influenced almost equally by any other node in the expander.",3.1. Model Analysis,[0],[0]
"Thus, the node representations will be representative of the global graph and carry limited information about individual nodes.",3.1. Model Analysis,[0],[0]
"In contrast, random walks starting at the bounded tree-width (almost-tree) part converge slowly, i.e., the features retain more local information.",3.1. Model Analysis,[0],[0]
"Models that impose a fixed random walk distribution inherit these discrepancies in the speed of expansion and influence neighborhoods, which may not lead to the best representations for all nodes.",3.1. Model Analysis,[0],[0]
"The above observations raise the question whether the fixed but structure-dependent influence radius size induced by
common aggregation schemes really achieves the best representations for all nodes and tasks.",4. Jumping Knowledge Networks,[0],[0]
"Large radii may lead to too much averaging, while small radii may lead to instabilities or insufficient information aggregation.",4. Jumping Knowledge Networks,[0],[0]
"Hence, we propose two simple yet powerful architectural changes – jump connections and a subsequent selective but adaptive aggregation mechanism.
",4. Jumping Knowledge Networks,[0],[0]
"Figure 4 illustrates the main idea: as in common neighborhood aggregation networks, each layer increases the size of the influence distribution by aggregating neighborhoods from the previous layer.",4. Jumping Knowledge Networks,[0],[0]
"At the last layer, for each node, we carefully select from all of those itermediate representations (which “jump” to the last layer), potentially combining a few.",4. Jumping Knowledge Networks,[0],[0]
"If this is done independently for each node, then the model can adapt the effective neighborhood size for each node as needed, resulting in exactly the desired adaptivity.
",4. Jumping Knowledge Networks,[0],[0]
Our model permits general layer-aggregation mechanisms.,4. Jumping Knowledge Networks,[0],[0]
We explore three approaches; others are possible too.,4. Jumping Knowledge Networks,[0],[0]
"Let h (1) v , ..., h (k) v be the jumping representations of node v (from k layers) that are to be aggregated.
",4. Jumping Knowledge Networks,[0],[0]
Concatenation.,4. Jumping Knowledge Networks,[0],[0]
"A concatenation [ h (1) v , ..., h (k) v ] is the
most straightforward way to combine the layers, after which we may perform a linear transformation.",4. Jumping Knowledge Networks,[0],[0]
"If the transformation weights are shared across graph nodes, this approach is not node-adaptive.",4. Jumping Knowledge Networks,[0],[0]
"Instead, it optimizes the weights to combine the subgraph features in a way that works best for the dataset overall.",4. Jumping Knowledge Networks,[0],[0]
"One may expect concatenation to be suitable for small graphs and graphs with regular structure that require less adaptivity; also because weight-sharing helps reduce overfitting.
",4. Jumping Knowledge Networks,[0],[0]
Max-pooling.,4. Jumping Knowledge Networks,[0],[0]
"An element-wise max ( h (1) v , ..., h (k) v ) selects the most informative layer for each feature coordinate.",4. Jumping Knowledge Networks,[0],[0]
"For example, feature coordinates that represent more local properties can use the feature coordinates learned from the close neighbors and those representing global status would favor features from the higher-up layers.",4. Jumping Knowledge Networks,[0],[0]
"Max-pooling is adaptive and has the advantage that it does not introduce any additional parameters to learn.
",4. Jumping Knowledge Networks,[0],[0]
LSTM-attention.,4. Jumping Knowledge Networks,[0],[0]
"An attention mechanism identifies the most useful neighborhood ranges for each node v by computing an attention score s(l)v for each layer l (∑ l s (l) v = 1 ) , which represents the importance of the feature learned on the l-th layer for node v. The aggregated representation for node v is a weighted average of the layer features∑ l s (l) v · h(l)v .",4. Jumping Knowledge Networks,[0],[0]
"For LSTM attention, we input h(1)v , ..., h(k)v into a bi-directional LSTM (Hochreiter & Schmidhuber, 1997) and generate the forward-LSTM and backward-LSTM",4. Jumping Knowledge Networks,[0],[0]
hidden features f (l)v and b (l) v for each layer l.,4. Jumping Knowledge Networks,[0],[0]
A linear mapping of the concatenated features [f (l)v ||b(l)v ] yields the scalar importance score s(l)v .,4. Jumping Knowledge Networks,[0],[0]
"A Softmax layer applied to {s(l)v }kl=1
yields the attention of node v on its neighborhood in different ranges.",4. Jumping Knowledge Networks,[0],[0]
Finally we take the sum of [f (l)v ||b(l)v ] weighted by SoftMax({s(l)v }kl=1) to get the final layer representation.,4. Jumping Knowledge Networks,[0],[0]
Another possible implementation combines LSTM with max-pooling.,4. Jumping Knowledge Networks,[0],[0]
LSTM-attention is node adaptive because the attention scores are different for each node.,4. Jumping Knowledge Networks,[0],[0]
"We shall see that the this approach shines on large complex graphs, although it may overfit on small graphs (fewer training nodes) due to its relatively higher complexity.",4. Jumping Knowledge Networks,[0],[0]
"The key idea for the design of layer-aggregation functions is to determine the importance of a node’s subgraph features at different ranges after looking at the learned features on all layers, rather than to optimize and fix the same weights for all nodes.",4.1. JK-Net Learns to Adapt,[0],[0]
"Under the same assumption on the ReLU activation distribution as in Theorem 1, we show below that layer-wise max-pooling implicitly learns the influence locality adaptively for different nodes.",4.1. JK-Net Learns to Adapt,[0],[0]
"The proof for layerwise attention follows similarly.
",4.1. JK-Net Learns to Adapt,[0],[0]
Proposition 1.,4.1. JK-Net Learns to Adapt,[0],[0]
Assume that paths of the same length in the computation graph are activated with the same probability.,4.1. JK-Net Learns to Adapt,[0],[0]
"The influence score I(x, y) for any x, y ∈ V under a k-layer JK-Net with layer-wise max-pooling is equivalent in expectation to a mixture of 0, .., k-step random walk distributions on G̃ at y starting at x, the coefficients of which depend on the values of the layer features h(l)x .
",4.1. JK-Net Learns to Adapt,[0],[0]
We prove Proposition 1 in the appendix.,4.1. JK-Net Learns to Adapt,[0],[0]
"Contrasting this result with the influence distributions of other aggregation mechanisms, we see that JK-networks indeed differ in their node-wise adaptivity of neighborhood ranges.
",4.1. JK-Net Learns to Adapt,[0],[0]
Figure 5 illustrates how a 6-layer JK-Net with max-pooling aggregation learns to adapt to different subgraph structures on a citation network.,4.1. JK-Net Learns to Adapt,[0],[0]
"Within a tree-like structure, the influence stays in the “small community” the node belongs to.",4.1. JK-Net Learns to Adapt,[0],[0]
"In contrast, 6-layer models whose influence distributions follow random walks, e.g. GCNs, would reach out too far into irrelevant parts of the graph, and models with few layers may not be able to cover the entire “community”, as illustrated in Figure 1, and Figures 7, 8 in the appendix.",4.1. JK-Net Learns to Adapt,[0],[0]
"For
a node affiliated to a “hub”, which presumably plays the role of connecting different types of nodes, JK-Net learns to put most influence on the node itself and otherwise spreads out the influence.",4.1. JK-Net Learns to Adapt,[0],[0]
"GCNs, however, would not capture the importance of the node’s own features in such a structure because the probability at an affiliate node is small after a few random walk steps.",4.1. JK-Net Learns to Adapt,[0],[0]
"For hubs, JK-Net spreads out the influence across the neighboring nodes in a reasonable range, which makes sense because the nodes connected to the hubs are presumably as informative as the hubs’ own features.",4.1. JK-Net Learns to Adapt,[0],[0]
"For comparison, Table 6 in the appendix includes more visualizations of how models with random walk priors behave.",4.1. JK-Net Learns to Adapt,[0],[0]
"Looking at Figure 4, one may wonder whether the same inter-layer connections could be drawn between all layers.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"The resulting architecture is approximately a graph correspondent of DenseNets, which were introduced for computer vision problems (Huang et al., 2017), if the layer-wise concatenation aggregation is applied.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"This version, however, would require many more features to learn.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Viewing the DenseNet setting (images) from a graph-theoretic perspective, images correspond to regular, in fact, near-planar graphs.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Such graphs are far from being expanders, and do not pose the challenges of graphs with varying subgraph structures.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Indeed, as we shall see, models with concatenation aggregation perform well on graphs with more regular structures such as images and well-structured communities.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"As a more general framework, JK-Net admits general layerwise aggregation models and enables better structure-aware representations on graphs with complex structures.",4.2. Intermediate Layer Aggregation and Structures,[0],[0]
"Spectral graph convolutional neural networks apply convolution on graphs by using the graph Laplacian eigenvectors as the Fourier atoms (Bruna et al., 2014; Shuman et al., 2013; Defferrard et al., 2016).",5. Other Related Work,[0],[0]
"A major drawback of the spectral methods, compared to spatial approaches like neighborhoodaggregation, is that the graph Laplacian needs to be known in advance.",5. Other Related Work,[0],[0]
"Hence, they cannot generalize to unseen graphs.",5. Other Related Work,[0],[0]
We evaluate JK-Nets on four benchmark datasets.,6. Experiments,[0],[0]
(I),6. Experiments,[0],[0]
"The task on citation networks (Citeseer, Cora) (Sen et al., 2008) is to classify academic papers into different subjects.",6. Experiments,[0],[0]
The dataset contains bag-of-words features for each document (node) and citation links (edges) between documents.,6. Experiments,[0],[0]
"(II) On Reddit (Hamilton et al., 2017), the task is to predict the community to which different Reddit posts belong.",6. Experiments,[0],[0]
Reddit is an online discussion forum where users comment in different topical communities.,6. Experiments,[0],[0]
Two posts (nodes) are connected if some user commented on both posts.,6. Experiments,[0],[0]
The dataset contains word vectors as node features.,6. Experiments,[0],[0]
"(III) For protein-protein interaction networks (PPI) (Hamilton et al., 2017), the task is to classify protein functions.",6. Experiments,[0],[0]
"PPI consists of 24 graphs, each corresponds to a human tissue.",6. Experiments,[0],[0]
"Each node has positional gene sets, motif gene sets and immunological signatures as features and gene ontology sets as labels.",6. Experiments,[0],[0]
"20 graphs are used for training, 2 graphs are used for validation and the rest for testing.",6. Experiments,[0],[0]
"Statistics of the datasets are summarized in Table 1.
",6. Experiments,[0],[0]
Settings.,6. Experiments,[0],[0]
"In the transductive setting, we are only allowed to access a subset of nodes in one graph as training data, and validate/test on others.",6. Experiments,[0],[0]
"Our experiments on Citeseer, Cora and Reddit are transductive.",6. Experiments,[0],[0]
"In the inductive setting, we use a number of full graphs as training data and use other completely unseen graphs as validation/testing data.",6. Experiments,[0],[0]
"Our experiments on PPI are inductive.
",6. Experiments,[0],[0]
"We compare against three baselines: Graph Convolutional Networks (GCN) (Kipf & Welling, 2017), GraphSAGE (Hamilton et al., 2017) and Graph Attention Networks (GAT) (Veličković et al., 2018).",6. Experiments,[0],[0]
"For experiments on Citeseer and Cora, we choose GCN as the base model since on our data split, it is outperforming GAT.",6.1. Citeseer & Cora,[0],[0]
"We construct JK-Nets by choosing MaxPooling (JKMaxPool), Concatenation (JK-Concat), or LSTM-attention (JK-LSTM) as final aggregation layer.",6.1. Citeseer & Cora,[0],[0]
"When taking the final aggregation, besides normal graph convolutional layers, we also take the first linear-transformed representation into account.",6.1. Citeseer & Cora,[0],[0]
The final prediction is done via a fully connected layer on top of the final aggregated representation.,6.1. Citeseer & Cora,[0],[0]
"We split nodes in each graph into 60%, 20% and 20% for training, validation and testing.",6.1. Citeseer & Cora,[0],[0]
"We vary the number of layers from 1
to 6 for each model and choose the best performing model with respect to the validation set.",6.1. Citeseer & Cora,[0],[0]
"Throughout the experiments, we use the Adam optimizer (Kingma & Ba, 2014) with learning rate 0.005.",6.1. Citeseer & Cora,[0],[0]
"We fix the dropout rate to be 0.5, the dimension of hidden features to be within {16, 32}, and add an L2 regularization of 0.0005 on model parameters.",6.1. Citeseer & Cora,[0],[0]
"The results are shown in Table 2.
Results.",6.1. Citeseer & Cora,[0],[0]
We observe in Table 2 that JK-Nets outperform both GCN and GAT baselines in terms of prediction accuracy.,6.1. Citeseer & Cora,[0],[0]
"Though JK-Nets perform well in general, there is no consistent winner and performance varies slightly across datasets.
",6.1. Citeseer & Cora,[0],[0]
"Taking a closer look at results on Cora, both GCN and GAT achieve their best accuracies with only 2 or 3 layers, suggesting that local information is a stronger signal for classification than global ones.",6.1. Citeseer & Cora,[0],[0]
"However, the fact that JKNets achieve the best performance with 6 layers indicates that global together with local information will help boost performance.",6.1. Citeseer & Cora,[0],[0]
This is where models like JK-Nets can be particularly beneficial.,6.1. Citeseer & Cora,[0],[0]
LSTM-attention may not be suitable for such small graphs because of its relatively high complexity.,6.1. Citeseer & Cora,[0],[0]
The Reddit data is too large to be handled well by current implementations of GCN or GAT.,6.2. Reddit,[0],[0]
"Hence, we use the more scalable GraphSAGE as the base model for JK-Net.",6.2. Reddit,[0],[0]
It has skip connections and different modes of node aggregation.,6.2. Reddit,[0],[0]
"We experiment with Mean and MaxPool node aggregators, which take mean and max-pooling of a linear transformation of representations of the sampled neighbors.",6.2. Reddit,[0],[0]
"Combining each of GraphSAGE modes with MaxPooling, Concatenation or LSTM-attention as the last aggregation layer gives 6 JK-Net variants.",6.2. Reddit,[0],[0]
"We follow exactly the same setting of GraphSAGE as in the original paper (Hamilton et al., 2017), where the model consists of 2 hidden layers, each with 128 hidden units and is trained with Adam with learning rate of 0.01 and no weight decay.",6.2. Reddit,[0],[0]
"Results are shown in Table 3.
Results.",6.2. Reddit,[0],[0]
"With MaxPool as node aggregator and Concat as layer aggregator, JK-Net achieves the best Micro-F1 score
among GarphSAGE and JK-Net variants.",6.2. Reddit,[0],[0]
Note that the original GraphSAGE already performs fairly well with a Micro-F1 of 0.95.,6.2. Reddit,[0],[0]
JK-Net reduces the error by 30%.,6.2. Reddit,[0],[0]
"The communities in the Reddit dataset were explicitly chosen from the well-behaved middle-sized communities to avoid the noisy cores and tree-like small communities (Hamilton et al., 2017).",6.2. Reddit,[0],[0]
"As a result, this graph is more regular than the original Reddit data, and hence not exhibit the problems of varying subgraph structures.",6.2. Reddit,[0],[0]
"In such a case, the added flexibility of the node-specific neighborhood choices may not be as relevant, and the stabilizing properties of concatenation instead come into play.",6.2. Reddit,[0],[0]
"We demonstrate the power of adaptive JK-Nets, e.g., JKLSTM, with experiments on the PPI data, where the subgraphs have more diverse and complex structures than those in the Reddit community detection dataset.",6.3. PPI,[0],[0]
We use both GraphSAGE and GAT as base models for JK-Net.,6.3. PPI,[0],[0]
"The implementation of GraphSAGE and GAT are quite different: GraphSAGE is sample-based, where neighbors of a node are sampled to be a fixed number, while GAT considers all neighbors.",6.3. PPI,[0],[0]
Such differences cause large gaps in terms of both scalability and performances.,6.3. PPI,[0],[0]
"Given that GraphSAGE scales to much larger graphs, it appears particularly valuable to evaluate how much JK-Net can improve upon GraphSAGE.
",6.3. PPI,[0],[0]
"For GraphSAGE we follow the setup as in the Reddit experiments, except that we use 3 layers when possible, and compare the performance after 10 and 30 epochs of training.",6.3. PPI,[0],[0]
The results are shown in Table 4.,6.3. PPI,[0],[0]
"For GAT and its JK-Net variants we stack two hidden layers with 4 attention heads computing 256 features (for a total of 1024 features), and a final prediction layer with 6 attention heads computing 121 features each.",6.3. PPI,[0],[0]
They are further averaged and input into sigmoid activations.,6.3. PPI,[0],[0]
We employ skip connections across intermediate attentional layers.,6.3. PPI,[0],[0]
These models are trained with Batch-size 2 and Adam optimizer with learning rate of 0.005.,6.3. PPI,[0],[0]
"The results are shown in Table 5.
Results.",6.3. PPI,[0],[0]
"JK-Nets with the LSTM-attention aggregators outperform the non-adaptive models GraphSAGE, GAT and JK-Nets with concatenation aggregators.",6.3. PPI,[0],[0]
"In particular, JKLSTM outperforms GraphSAGE by 0.128 in terms of micro-
F1 score after 30 epochs of training.",6.3. PPI,[0],[0]
Structure-aware node adaptive models are especially beneficial on such complex graphs with diverse structures.,6.3. PPI,[0],[0]
"Motivated by observations that reveal great differences in neighborhood information ranges for graph node embeddings, we propose a new aggregation scheme for node representation learning that can adapt neigborhood ranges to nodes individually.",7. Conclusion,[0],[0]
"This JK-network can improve representations in particular for graphs that have subgraphs of diverse local structure, and may hence not be well captured by fixed numbers of neighborhood aggregations.",7. Conclusion,[0],[0]
Interesting directions for future work include exploring other layer aggregators and studying the effect of the combination of various layer-wise and node-wise aggregators on different types of graph structures.,7. Conclusion,[0],[0]
"This research was supported by NSF CAREER award 1553284, and JST ERATO Kawarabayashi Large Graph Project, Grant Number JPMJER1201, Japan.",Acknowledgements,[0],[0]
Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure.,abstractText,[0],[0]
"We analyze some important properties of these models, and propose a strategy to overcome those.",abstractText,[0],[0]
"In particular, the range of “neighboring” nodes that a node’s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk.",abstractText,[0],[0]
"To adapt to local neighborhood properties and tasks, we explore an architecture – jumping knowledge (JK) networks – that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation.",abstractText,[0],[0]
"In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance.",abstractText,[0],[0]
"Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models’ performance.",abstractText,[0],[0]
Representation Learning on Graphs with Jumping Knowledge Networks ,title,[0],[0]
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 912–921, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics
Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks. However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data. We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains. Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.",text,[0],[0]
"Recent advances in deep neural networks (DNNs) have demonstrated the importance of learning vector-space representations of text, e.g., words and sentences, for a number of natural language processing tasks.",1 Introduction,[0],[0]
"For example, the study reported in (Collobert et al., 2011) demonstrated significant accuracy gains in tagging, named entity recognition, and semantic role labeling when using vector space word
∗This research was conducted during the author’s internship at Microsoft Research.
representations learned from large corpora.",1 Introduction,[0],[0]
"Further, since these representations are usually in a lowdimensional vector space, they result in more compact models than those built from surface-form features.",1 Introduction,[0],[0]
"A recent successful example is the parser by (Chen and Manning, 2014), which is not only accurate but also fast.
",1 Introduction,[0],[0]
"However, existing vector-space representation learning methods are far from optimal.",1 Introduction,[0],[0]
"Most previous methods are based on unsupervised objectives such as word prediction for training (Mikolov et al., 2013c; Pennington et al., 2014).",1 Introduction,[0],[0]
"Other methods use supervised training objectives on a single task, e.g. (Socher et al., 2013), and thus are often constrained by limited amounts of training data.",1 Introduction,[0],[0]
"Motivated by the success of multi-task learning (Caruana, 1997), we propose in this paper a multi-task DNN approach for representation learning that leverages supervised data from many tasks.",1 Introduction,[0],[0]
"In addition to the benefit of having more data for training, the use of multi-task also profits from a regularization effect, i.e., reducing overfitting to a specific task, thus making the learned representations universal across tasks.
",1 Introduction,[0],[0]
"Our contributions are of two-folds: First, we propose a multi-task deep neural network for representation learning, in particular focusing on semantic classification (query classification) and semantic information retrieval (ranking for web search) tasks.",1 Introduction,[0],[0]
Our model learns to map arbitrary text queries and documents into semantic vector representations in a low dimensional latent space.,1 Introduction,[0],[0]
"While the general concept of multi-task neural nets is not new, our model is novel in that it successfully combines tasks as disparate as operations necessary for classifica-
912
tion or ranking.",1 Introduction,[0.9540470562923534],"['This RNN formulation differs from the one commonly used in language modeling, as the input is not time-dependent.']"
"Second, we demonstrate strong results on query classification and web search.",1 Introduction,[0],[0]
Our multi-task representation learning consistently outperforms stateof-the-art baselines.,1 Introduction,[0],[0]
"Meanwhile, we show that our model is not only compact but it also enables agile deployment into new domains.",1 Introduction,[0],[0]
This is because the learned representations allow domain adaptation with substantially fewer in-domain labels.,1 Introduction,[0],[0]
Our multi-task model combines classification and ranking tasks.,2.1 Preliminaries,[0],[0]
"For concreteness, throughout this paper we will use query classification as the classification task and web search as the ranking task.",2.1 Preliminaries,[0],[0]
"These are important tasks in commercial search engines:
Query Classification:",2.1 Preliminaries,[0],[0]
"Given a search query Q, the model classifies in the binary fashion as to whether it belongs to one of the domains of interest.",2.1 Preliminaries,[0],[0]
"For example, if the query Q is “Denver sushi”, the classifier should decide that it belongs to the “Restaurant” domain.",2.1 Preliminaries,[0],[0]
"Accurate query classification enables a richer personalized user experience, since the search engine can tailor the interface and results.",2.1 Preliminaries,[0],[0]
"It is however challenging because queries tend to be short (Shen et al., 2006).",2.1 Preliminaries,[0],[0]
"Surface-form word features that are common in traditional document classification problems tend to be too sparse for query classification, so representation learning is a promising solution.",2.1 Preliminaries,[0],[0]
"In this study, we classify queries into four domains of interest: (“Restaurant”, “Hotel”, “Flight”, “Nightlife”).",2.1 Preliminaries,[0],[0]
Note that one query can belong to multiple domains.,2.1 Preliminaries,[0],[0]
"Therefore, a set of binary classifiers are built, one for each domain, to perform the classification.",2.1 Preliminaries,[0],[0]
We frame the problem as four binary classification tasks.,2.1 Preliminaries,[0],[0]
"Thus, for domain Ct, our goal is binary classification based on P (Ct| Q) (Ct = {0, 1} ).",2.1 Preliminaries,[0],[0]
"For each domain t, we assume supervised data (Q, yt = {0, 1} with yt as binary labels.1
Web Search:",2.1 Preliminaries,[0],[0]
"Given a search queryQ and a document list L, the model ranks documents in the order
1One could frame the problem as a a single multi-class classification task, but our formulation is more practical as it allows adding new domains without retraining existing classifiers.",2.1 Preliminaries,[0],[0]
"This will be relevant in domain adaptation (§3.3).
of relevance.",2.1 Preliminaries,[0],[0]
"For example, if the queryQ is ”Denver sushi”, model returns a list of documents that satisfies such information need.",2.1 Preliminaries,[0],[0]
"Formally, we estimate P (D1|Q), P (D2|Q), . . .",2.1 Preliminaries,[0],[0]
for each document Dn and rank according to these probabilities.,2.1 Preliminaries,[0],[0]
"We assume that supervised data exist; I.e., there is at least one relevant document Dn for each query Q.",2.1 Preliminaries,[0],[0]
"Briefly, our proposed model maps any arbitrary queries Q or documents D into fixed lowdimensional vector representations using DNNs.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
These vectors can then be used to perform query classification or web search.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In contrast to existing representation learning methods which employ either unsupervised or single-task supervised objectives, our model learns these representations using multi-task objectives.
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
The architecture of our multi-task DNN model is shown in Figure 1.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"The lower layers are shared across different tasks, whereas the top layers represent task-specific outputs.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Importantly, the input X (either a query or document), initially represented as a bag of words, is mapped to a vector (l2) of dimension 300.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
This is the shared semantic representation that is trained by our multi-task objectives.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In the following, we elaborate the model in detail:
Word Hash Layer (l1): Traditionally, each word is represented by a one-hot word vector, where the dimensionality of the vector is the vocabulary size.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"However, due to the large size of vocabulary in realworld tasks, it is very expensive to learn such kind of models.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"To alleviate this problem, we adopt the word hashing method (Huang et al., 2013).",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"We map a one-hot word vector, with an extremely high dimensionality, into a limited letter-trigram space (e.g., with the dimensionality as low as 50k).",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For example, word cat is hashed as the bag of letter trigram {#-c-a, c-a-t, a-t-#}, where # is a boundary symbol.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Word hashing complements the one-hot vector representation in two aspects: 1) out of vocabulary words can be represented by letter-trigram vectors; 2) spelling variations of the same word can be mapped to the points that are close to each other in the letter-trigram space.
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Semantic-Representation Layer (l2):,2.2 The Proposed Multi-Task DNN Model,[0],[0]
This is a shared representation learned across different tasks.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"this layer maps the letter-trigram inputs into a 300-
1
dimensional vector by
l2 = f(W1 · l1) (1)
where f(·) is the tanh nonlinear activation f(z) = 1−e−2z 1+e−2z .",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"This 50k-by-300 matrix W1 is responsible for generating the cross-task semantic representation for arbitrary text inputs (e.g., Q or D).
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Task-Specific Representation (l3): For each task, a nonlinear transformation maps the 300- dimension semantic representation l2 into the 128- dimension task-specific representation by
l3 = f(Wt2 · l2) (2)
where, t denotes different tasks (query classification or web search).
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Query Classification Output: Suppose QC1 ≡ l3 = f(Wt=C12 · l2) is the 128-dimension taskspecific representation for a query Q.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"The probability that Q belongs to class C1 is predicted by a logistic regression, with sigmoid g(z)",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"= 1
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"1+e−z :
",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"P (C1|Q) = g(Wt=C13 ·QC1) (3)
Web Search Output: For the web search task, both the query Q and the document D are mapped into 128-dimension task-specific representations QSq and DSd .",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Then, the relevance score is
Algorithm 1: Training a Multi-task DNN Initialize model Θ : {W1,Wt2,Wt3} randomly for iteration in 0...∞ do
1.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Pick a task t randomly 2.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Pick sample(s) from task t
(Q, yt = {0, 1}) for query classification (Q,L) for web search
3.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
Compute loss: L(Θ) L(Θ)=Eq.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
5 for query classification L(Θ)=Eq.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
6 for web search 4.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
Compute gradient: ∇(Θ) 5.,2.2 The Proposed Multi-Task DNN Model,[0],[0]
"Update model: Θ = Θ− ∇(Θ)
end The task t is one of the query classification tasks or web search task, as shown in Figure 1.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For query classification, each training sample includes one query and its category label.",2.2 The Proposed Multi-Task DNN Model,[0],[0]
"For web search, each training sample includes query and document list.
computed by cosine similarity as:
R(Q,D) = cos(QSq , DSd)",2.2 The Proposed Multi-Task DNN Model,[0],[0]
= QSq ·DSd ||QSq,2.2 The Proposed Multi-Task DNN Model,[0],[0]
||||DSd || (4),2.2 The Proposed Multi-Task DNN Model,[0],[0]
"In order to learn the parameters of our model, we use mini-batch-based stochastic gradient descent (SGD) as shown in Algorithm 1.",2.3 The Training Procedure,[0],[0]
"In each iteration, a task t is selected randomly, and the model is updated ac-
cording to the task-specific objective.",2.3 The Training Procedure,[0],[0]
This approximately optimizes the sum of all multi-task objectives.,2.3 The Training Procedure,[0],[0]
"For query classification of class Ct, we use the cross-entropy loss as the objective: −{yt lnP (Ct|Q)+(1−yt) ln(1−P (Ct|Q))}",2.3 The Training Procedure,[0],[0]
"(5)
where yt = {0, 1} is the label and the loss is summed over all samples in the mini-batch (1024 samples in experiments).
",2.3 The Training Procedure,[0],[0]
"The objective for web search used in this paper follows the pair-wise learning-to-rank paradigm outlined in (Burges et al., 2005).",2.3 The Training Procedure,[0],[0]
"Given a query Q, we obtain a list of documents L that includes a clicked document D+ (positive sample), and J randomlysampled non-clicked documents {D−j }j=1,.,J .",2.3 The Training Procedure,[0],[0]
"We then minimize the negative log likelihood of the clicked document (defined in Eq. 7) given queries across the training data
− log ∏
(Q,D+)
P (D+|Q) (6)
where the probability of a given document D+ is computed
P (D+|Q) =",2.3 The Training Procedure,[0],[0]
"exp(γR(Q,D +))",2.3 The Training Procedure,[0],[0]
"∑
D′∈L exp(γR(Q,D′)) (7)
",2.3 The Training Procedure,[0],[0]
"here, γ is a tuning factor determined on held-out data.",2.3 The Training Procedure,[0],[0]
"Additional training details: (1) Model parameters are initialized with uniform distribution in the range (−√6/(fanin + fanout),√6/(fanin + fanout))",2.3 The Training Procedure,[0],[0]
"(Montavon et al., 2012).",2.3 The Training Procedure,[0],[0]
"Empirically, we have not observed better performance by initialization with layer-wise pre-training.",2.3 The Training Procedure,[0],[0]
"(2) Moment methods and AdaGrad training (Duchi et al., 2011) speed up the convergence speed but gave similar results as plain SGD.",2.3 The Training Procedure,[0],[0]
The SGD learning rate is fixed at = 0.1/1024.,2.3 The Training Procedure,[0],[0]
"(3) We run Algorithm 1 for 800K iterations, taking 13 hours on an NVidia K20 GPU.",2.3 The Training Procedure,[0],[0]
"Our proposed multi-task DNN (Figure 1) can be viewed as a combination of a standard DNN for classification and a Deep Structured Semantic Model (DSSM) for ranking, shown in Figure 2.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
Other ways to merge the models are possible.,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"Figure 3 shows an alternative multi-task architecture, where only the query part is shared among all tasks and the DSSM
retains independent parameters for computing the document representations.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
This is more similar to the original DSSM.,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"We have attempted training this model using Algorithm 1, but it achieves good results on query classification at the expense of web search.",2.4 An Alternative View of the Multi-Task Model,[0],[0]
"This is likely due to unbalanced updates (i.e. parameters for queries are updated more often than that of documents), and implying that the amount of sharing is an important design choice in multi-task models.
",2.4 An Alternative View of the Multi-Task Model,[0],[0]
3,2.4 An Alternative View of the Multi-Task Model,[0],[0]
"We employ large-scale, real data sets in our evaluation.",3.1 Data Sets and Evaluation Metrics,[0],[0]
See Table 1 for statistics.,3.1 Data Sets and Evaluation Metrics,[0],[0]
The test data for query classification were sampled from one-year log files of a commercial search engine with labels (yes or no) judged by humans.,3.1 Data Sets and Evaluation Metrics,[0],[0]
"The test data for web search contains 12,071 English queries, where each query-document pair has a relevance label manually annotated on a 5-level relevance scale: bad, fair,
good, excellent and perfect.",3.1 Data Sets and Evaluation Metrics,[0],[0]
"The evaluation metric for query classification is the Area under of Receiver Operating Characteristic (ROC) curve (AUC) score (Bradley, 1997).",3.1 Data Sets and Evaluation Metrics,[0],[0]
"For web search, we employ the Normalized Discounted Cumulative Gain (NDCG) (Järvelin and Kekäläinen, 2000).",3.1 Data Sets and Evaluation Metrics,[0],[0]
"First, we evaluate whether our model can robustly improve performance, measured as accuracy across multiple tasks.
",3.2 Results on Accuracy,[0],[0]
"Table 2 summarizes the AUC scores for query classification, comparing the following classifiers: • SVM-Word: a SVM model2 with unigram, bi-
gram and trigram surface-form word features.
",3.2 Results on Accuracy,[0],[0]
• SVM-Letter: a SVM model with letter trigram features (i.e. l1 in Figure 1 as input to SVM).,3.2 Results on Accuracy,[0],[0]
• DNN:,3.2 Results on Accuracy,[0],[0]
single-task deep neural net (Figure 2).,3.2 Results on Accuracy,[0],[0]
• MT-DNN: our multi-task proposal (Figure 1).,3.2 Results on Accuracy,[0],[0]
The results show that the proposed MT-DNN performs best in all four domains.,3.2 Results on Accuracy,[0],[0]
"Further, we observe:
1.",3.2 Results on Accuracy,[0],[0]
"MT-DNN outperforms DNN, indicating the usefulness of the multi-task objective (that includes web search) over the single-task objective of query classification.
2.",3.2 Results on Accuracy,[0],[0]
"Both DNN and MT-DNN outperform SVMLetter, which initially uses the same input features (l1).",3.2 Results on Accuracy,[0],[0]
"This indicates the importance of learning a semantic representation l2 on top of these letter trigrams.
3.",3.2 Results on Accuracy,[0],[0]
"Both DNN and MT-DNN outperform a strong SVM-Word baseline, which has a large feature set that consists of 3 billion features.
",3.2 Results on Accuracy,[0],[0]
"Table 3 summarizes the NDCG results on web search, comparing the following models:",3.2 Results on Accuracy,[0],[0]
"2In this paper, we use the liblinear to build SVM classifiers and optimize the corresponding parameter C by using 5-fold cross-validation in training data.",3.2 Results on Accuracy,[0],[0]
"http://www.csie.ntu.edu.tw/ cjlin/liblinear/
• Popular baselines in the web search literature, e.g. BM25, Language Model, PLSA
• DSSM: single-task ranking model (Figure 2) • MT-DNN:",3.2 Results on Accuracy,[0],[0]
"our multi-task proposal (Figure 1)
",3.2 Results on Accuracy,[0],[0]
"Again, we observe that MT-DNN performs best.",3.2 Results on Accuracy,[0],[0]
"For example, MT-DNN achieves NDCG@1=0.334, outperforming the current state-of-the-art single-task DSSM (0.327) and the classic methods like PLSA (0.308) and BM25 (0.305).",3.2 Results on Accuracy,[0],[0]
"This is a statistically significant improvement (p < 0.05) over DSSM and other baselines.
",3.2 Results on Accuracy,[0],[0]
"To recap, our MT-DNN robustly outperforms strong baselines across all web search and query classification tasks.",3.2 Results on Accuracy,[0],[0]
"Further, due to the use of larger training data (from different domains) and the regularization effort as we discussed in Section 1, we confirm the advantage of multi-task models over than single-task ones.3",3.2 Results on Accuracy,[0],[0]
Important criteria for building practical systems are agility of deployment and small memory footprint and fast run-time.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Our model satisfies both with 3We have also trained SVM using Word2Vec (Mikolov et al., 2013b; Mikolov et al., 2013a) features.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Unfortunately, the results are poor at 60-70 AUC, indicating the sub-optimality of unsupervised representation learning objectives for actual prediction tasks.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"We optimized the Word2Vec features in the SVM baseline by scaling and normalizing as well, but did not observe much improvement.
high model compactness.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The key to the compactness is the aggressive compression from the 500kdimensional bag-of-words input to 300-dimensional semantic representation l2.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
This significantly reduces the memory/run-time requirements compared to systems that rely on surface-form features.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"The most expensive portion of the model is storage of the 50k-by-300 W1 and its matrix multiplication with l1, which is sparse: this is trivial on modern hardware.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Our multi-task DNN takes < 150KB in memory whereas e.g. SVM-Word takes about 200MB.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Compactness is particularly important for query classification, since one may desire to add new domains after discovering new needs from the query logs of an operational system.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"On the other hand, it is prohibitively expensive to collect labeled training data for new domains.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Very often, we only have very small training data or even no training data.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"To evaluate the models using the above criteria, we perform domain adaptation experiments on query classification using the following procedure: (1) Select one query classification task t∗.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Train MTDNN on the remaining tasks (including Web Search
task) to obtain a semantic representation (l2); (2) Given a fixed l2, train an SVM on the training data t∗, using varying amounts of labels; (3) Evaluate the AUC on the test data of t∗
We compare three SVM classifiers trained using different feature representations: (1) SemanticRepresentation uses the l2 features generated according to the above procedure.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"(2) Word3gram uses unigram, bigram and trigram word features.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
(3) Letter3gram uses letter-trigrams.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Note that Word3gram and Letter3gram correspond to SVMWord and SVM-Letter respectively in Table 2.
",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The AUC results for different amounts of t∗ training data are shown in Figure 4.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"In the Hotel, Flight and Restaurant domains, we observe that our semantic representation dominated the other two feature representations (Word3gram and Letter3gram) in all cases except the extremely large-data regime (more than 1 million training samples in domain t∗).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Given sufficient labels, SVM is able to train well on Word3gram sparse features, but for most cases Se-
manticRepresentation is recommended.4
In a further experiment, we compare the following two DNNs using the same domain adaptation procedure: (1) DNN1: DNN where W1 is randomly initialized and parameters W1,W2,Wt ∗ 3 are trained on varying amounts of data in t∗;",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"(2) DNN2: DNN where W1 is obtained from other tasks (i.e. SemanticRepresentation) and fixed, while parameters W2,Wt ∗ 3 are trained on varying amounts of data in t∗.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
The purpose is to see whether shared semantic representation is useful even under a DNN architecture.,3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Figure 5 show the AUC results of DNN1 vs. DNN2 (the results SVM denotes the same system as SemanticRepresentation in Figure 4, plotted here for reference).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"We observe that when the training data is extremely large (millions of samples), one does best by training all parameters from scratch (DNN1).",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Otherwise, one is better off using a shared semantic representation trained by multitask objectives.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"Comparing DNN2 and SVM with SemanticRepresentation, we note that SVM works best for training data of several thousand samples; DNN2 works best in the medium data range.",3.3 Results on Model Compactness and Domain Adaptation,[0],[0]
"There is a large body of work on representation learning for natural language processing, sometimes using different terminologies for similar concepts; e.g., feature generation, dimensionality reduction, and vector space models.",4 Related Work,[0],[0]
"The main motivation is similar: to abstract away from surface forms in words, sentences, or documents, in order to alleviate sparsity and approximate semantics.",4 Related Work,[0],[0]
"Traditional techniques include LSA (Deerwester et al., 1990), ESA (Gabrilovich and Markovitch, 2007), PCA (Karhunen, 1998), and non-linear kernel variants (Schölkopf et al., 1998).",4 Related Work,[0],[0]
"Recently, learningbased approaches inspired by neural networks, especially DNNs, have gained in prominence, due to their favorable performance (Huang et al., 2013; Baroni et al., 2014; Milajevs et al., 2014).
",4 Related Work,[0],[0]
"Popular methods for learning word representations include (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013; Pennington et al., 2014): all are based on unsupervised objec-
4The trends differ slightly in the Nightlife domain.",4 Related Work,[0],[0]
"We believe this may be due to data bias on test data (only 298 samples).
tives of predicting words or word frequencies from raw text.",4 Related Work,[0],[0]
"End-to-end neural network models for specific tasks (e.g. parsing) often use these word representations as initialization, which are then iteratively improved by optimizing a supervised objective (e.g. parsing accuracy).",4 Related Work,[0],[0]
"A selection of successful applications of this approach include sequence labeling (Turian et al., 2010), parsing (Chen and Manning, 2014), sentiment (Socher et al., 2013), question answering (Iyyer et al., 2014) and translation modeling (Gao et al., 2014a).
",4 Related Work,[0],[0]
"Our model takes queries and documents as input, so it learns sentence/document representations.",4 Related Work,[0],[0]
"This is currently an open research question, the challenge being how to properly model semantic compositionality of words in vector space (Huang et al., 2013; M. Baroni and Zamparelli, 2013; Socher et al., 2013).",4 Related Work,[0],[0]
"While we adopt a bag-of-words approach for practical reasons (memory and run-time), our multi-task framework is extensible to other methods for sentence/document representations, such as those based on convolutional networks (Kalchbrenner et al., 2014; Shen et al., 2014; Gao et al., 2014b), parse tree structure (Irsoy and Cardie, 2014), and run-time inference (Le and Mikolov, 2014).
",4 Related Work,[0],[0]
"The synergy between multi-task learning and neural nets is quite natural; the general idea dates back to (Caruana, 1997).",4 Related Work,[0],[0]
The main challenge is in designing the tasks and the network structure.,4 Related Work,[0],[0]
"For example, (Collobert et al., 2011) defined part-of-speech tagging, chunking, and named entity recognition as multiple tasks in a single sequence labeler; (Bordes et al., 2012) defined multiple data sources as tasks in their relation extraction system.",4 Related Work,[0],[0]
"While conceptually similar, our model is novel in that it combines tasks as disparate as classification and ranking.",4 Related Work,[0],[0]
"Further, considering that multi-task models often exhibit mixed results (i.e. gains in some tasks but degradation in others), our accuracy improvements across all tasks is a very satisfactory result.",4 Related Work,[0],[0]
"In this work, we propose a robust and practical representation learning algorithm based on multi-task objectives.",5 Conclusion,[0],[0]
"Our multi-task DNN model successfully combines tasks as disparate as classification and ranking, and the experimental results demon-
strate that the model consistently outperforms strong baselines in various query classification and web search tasks.",5 Conclusion,[0],[0]
"Meanwhile, we demonstrated compactness of the model and the utility of the learned query/document representation for domain adaptation.
",5 Conclusion,[0],[0]
Our model can be viewed as a general method for learning semantic representations beyond the word level.,5 Conclusion,[0],[0]
"Beyond query classification and web search, we believe there are many other knowledge sources (e.g. sentiment, paraphrase) that can be incorporated either as classification or ranking tasks.",5 Conclusion,[0],[0]
A comprehensive exploration will be pursued as future work.,5 Conclusion,[0],[0]
"We thank Xiaolong Li, Yelong Shen, Xinying Song, Jianshu Chen, Byungki Byun, Bin Cao and the anonymous reviewers for valuable discussions and comments.",Acknowledgments,[0],[0]
Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks.,abstractText,[0],[0]
"However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data.",abstractText,[0],[0]
"We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains.",abstractText,[0],[0]
"Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.",abstractText,[0],[0]
Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval,title,[0],[0]
"Recently, hyperbolic embeddings have been proposed as a way to capture hierarchy information for network and natural language processing tasks (Nickel & Kiela, 2017; Chamberlain et al., 2017).",1. Introduction,[0],[0]
"This approach is an exciting way to fuse structural information (for example, from knowledge graphs or synonym hierarchies) with the continuous representations favored by modern machine learning methods.
",1. Introduction,[0],[0]
"To understand the intuition behind hyperbolic embeddings’ superior capacity, note that trees can be embedded with arbitrarily low distortion into the Poincaré disk, a twodimensional model of hyperbolic space (Sarkar, 2011).",1. Introduction,[0],[0]
"In contrast, Bourgain’s theorem (Linial et al., 1995) shows that Euclidean space cannot achieve comparably low distortion
1Department of Computer Science, Stanford University 2Department of Computer Science, Cornell University.",1. Introduction,[0],[0]
"Correspondence to: Frederic Sala <fredsala@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
for trees—even using an unbounded number of dimensions.
",1. Introduction,[0],[0]
"Many graphs, such as complex networks (Krioukov et al., 2010), the Internet (Krioukov et al., 2009), and social networks (Verbeek & Suri, 2016), are known to have tree-like or hyperbolic structure and thus befit hyperbolic embeddings.",1. Introduction,[0],[0]
"Indeed, recent works show that hyperbolic representations are suitable for many hierarchies (e.g. the question answering (Q/A) system HyperQA in Tay et al. (2018), vertex classifiers in Chamberlain et al. (2017), and link prediction (Nickel & Kiela, 2017)).",1. Introduction,[0],[0]
"However, the optimization problems underlying the embedding techniques in these works are challenging, motivating us to seek fundamental insights and to understand the subtle tradeoffs involved.
",1. Introduction,[0],[0]
"We begin by considering the case where we are given an input graph that is a tree or nearly tree-like, and our goal is to produce a low-dimensional hyperbolic embedding that preserves all distances.",1. Introduction,[0],[0]
This leads to a simple combinatorial strategy that directly places points instead of minimizing a surrogate loss function.,1. Introduction,[0],[0]
It is both fast (nearly linear time) and has formal quality guarantees.,1. Introduction,[0],[0]
"The approach proceeds in two phases: we (1) produce an embedding of a graph into a weighted tree, and (2) embed that tree into the hyperbolic disk.",1. Introduction,[0],[0]
"In particular, we consider an extension of an elegant embedding of trees into the Poincaré disk by Sarkar (2011) and work on low-distortion graph embeddings into tree metrics (Abraham et al., 2007).",1. Introduction,[0],[0]
"For trees, this approach has nearly perfect quality.",1. Introduction,[0],[0]
"On the WordNet hypernym graph reconstruction, it obtains a nearly perfect mean average precision (MAP) of 0.989 using just 2 dimensions.",1. Introduction,[0],[0]
"The best published numbers for WordNet in Nickel & Kiela (2017) range between 0.823 and 0.87 for 5 to 200 dimensions.
",1. Introduction,[0],[0]
We analyze this construction to extract fundamental tradeoffs.,1. Introduction,[0],[0]
"One tradeoff involves the embedding dimension, the properties of the graph, and the number of bits of precision used to represent components of embedded points—an important hidden cost.",1. Introduction,[0],[0]
"We show that for a fixed precision, the dimension required scales linearly with the length of the longest path.",1. Introduction,[0],[0]
"On the other hand, the dimension scales logarithmically with the maximum degree of the tree.",1. Introduction,[0],[0]
"This suggests that hyperbolic embeddings should have high quality on hierarchies like WordNet but require large dimensions or high precision on graphs with long chains.
",1. Introduction,[0],[0]
"To understand how hyperbolic embeddings perform for met-
rics that are far from tree-like, we consider a more general problem: given a matrix of distances that arise from points that are embeddable in hyperbolic space of dimension d (not necessarily from a graph), find a set of points that produces these distances.",1. Introduction,[0],[0]
"In Euclidean space, the problem is known as multidimensional scaling (MDS) and is solvable using PCA.",1. Introduction,[0],[0]
"A key step is a transformation that effectively centers the points, without knowledge of their exact coordinates.",1. Introduction,[0],[0]
"It is not obvious how to center points in hyperbolic space, which is curved.",1. Introduction,[0],[0]
"We show that in hyperbolic space, a centering operation is still possible with respect to a non-standard mean.",1. Introduction,[0],[0]
"In turn, this allows us to reduce the hyperbolic MDS problem (h-MDS) to a standard eigenvalue problem that can be solved with power methods.",1. Introduction,[0],[0]
"We also extend classical PCA perturbation analysis (Sibson, 1978; 1979).",1. Introduction,[0],[0]
"When applied to distances from graphs induced by real data, h-MDS obtains low distortion on far from tree-like graphs.",1. Introduction,[0],[0]
"However, we observe that these solutions may require high precision, which is not surprising in light of our previous analysis.
",1. Introduction,[0],[0]
"Finally, we handle increasing amounts of noise in the model, leading naturally into new SGD-based formulations.",1. Introduction,[0],[0]
"Like in traditional PCA, the underlying problem is nonconvex.",1. Introduction,[0],[0]
"In contrast to PCA, there are local minima that are not global minima—an additional challenge.",1. Introduction,[0],[0]
Our main technical result is that an SGD-based algorithm initialized with an h-MDS solution can recover the submanifold the data is on—even in some cases in which the data is perturbed by noise that can be full dimensional.,1. Introduction,[0],[0]
Our algorithm essentially provides new recovery results for convergence of Principal Geodesic Analysis (PGA) in hyperbolic space.,1. Introduction,[0],[0]
We implemented the resulting SGD-based algorithm using PyTorch.,1. Introduction,[0],[0]
"Finally, we note that all of our algorithms can handle incomplete distance information through standard techniques.",1. Introduction,[0],[0]
"We provide intuition connecting hyperbolic space and tree distances, discuss the metrics used to measure embedding fidelity, and discuss the relationship between the reconstruction and learning problems for graph embeddings.
",2. Background,[0],[0]
"Hyperbolic spaces The Poincaré disk H2 is a twodimensional model of hyperbolic geometry with points located in the interior of the unit disk, as shown in Figure 1.",2. Background,[0],[0]
"A natural generalization of H2 is the Poincaré ball Hr, with elements inside the unit ball.",2. Background,[0],[0]
"The Poincaré models offer several useful properties, chief among which is mapping conformally to Euclidean space.",2. Background,[0],[0]
"That is, angles are preserved between hyperbolic and Euclidean space.",2. Background,[0],[0]
"Distances, on the other hand, are not preserved, but are given by
dH(x, y) = acosh ( 1 + 2 ‖x− y‖2
(1− ‖x‖2)(1− ‖y‖2)
) .
",2. Background,[0],[0]
"There are some potentially unexpected consequences of this formula, and a simple example gives intuition about a key technical property that allows hyperbolic space to embed trees.",2. Background,[0],[0]
"Consider three points inside the unit disk: the origin 0, and points x and y with ‖x‖ = ‖y‖ = t for some t > 0.",2. Background,[0],[0]
"As shown on the right of Figure 1, as t → 1 (i.e., the points move towards the outside of the disk), in flat Euclidean space, the ratio dE(x,y)dE(x,0)+dE(0,y) is constant with respect to t (blue curve).",2. Background,[0],[0]
"In contrast, the ratio
dH(x,y) dH(x,0)+dH(0,y) approaches 1, or, equivalently, the distance dH(x, y) approaches dH(x, 0) +",2. Background,[0],[0]
"dH(0, y) (red and pink curves).",2. Background,[0],[0]
"That is, the shortest path between x and y is almost the same as the path through the origin.",2. Background,[0],[0]
This is analogous to the property of trees in which the shortest path between two sibling nodes is the path through their parent.,2. Background,[0],[0]
This tree-like nature of hyperbolic space is the key property exploited by embeddings.,2. Background,[0],[0]
"Moreover, this property holds for arbitrarily small angles between x and y.
Lines and geodesics There are two types of geodesics (shortest paths) in the Poincaré disk model: segments of circles that are orthogonal to the disk surface, and disk diameters (Brannan et al., 2012).",2. Background,[0],[0]
"Our algorithms and proofs make use of a simple geometric fact: isometric reflection across geodesics (preserving hyperbolic distances) is represented in this Euclidean model as a circle inversion.
",2. Background,[0],[0]
Embeddings and fidelity measures An embedding is a mapping f :,2. Background,[0],[0]
"U → V for spaces U, V with distances dU , dV .",2. Background,[0],[0]
"We measure the quality of embeddings with several fidelity measures, presented here from most local to most global.
",2. Background,[0],[0]
"Recent work (Nickel & Kiela, 2017) proposes using the mean average precision (MAP).",2. Background,[0],[0]
"For a graph G = (V,E), let a ∈ V have neighborhood Na = {b1, b2, . . .",2. Background,[0],[0]
", bdeg(a)}, where deg(a) denotes the degree of a.",2. Background,[0],[0]
"In the embedding f , consider the points closest to f(a), and define Ra,bi to be the smallest set of such points that contains bi (that is, Ra,bi is the smallest set of nearest points required to retrieve the ith neighbor of a in f ).",2. Background,[0],[0]
"Then, the MAP is defined to be
MAP(f) = 1 |V | ∑ a∈V
1
deg(a) |Na|∑ i=1",2. Background,[0],[0]
"|Na ∩Ra,bi | |Ra,bi | .
",2. Background,[0],[0]
"We have MAP(f) ≤ 1, with 1 as the best case.",2. Background,[0],[0]
"MAP is not concerned with explicit distances, but only ranks between the distances of immediate neighbors.",2. Background,[0],[0]
"It is a local metric.
",2. Background,[0],[0]
"The standard metric for graph embeddings is distortion D. For an n point embedding,
D(f)",2. Background,[0],[0]
"= 1( n 2 )  ∑ u,v∈U :u6=v |dV",2. Background,[0],[0]
"(f(u),",2. Background,[0],[0]
"f(v))− dU (u, v)| dU (u, v)  .
",2. Background,[0],[0]
"The best distortion isD(f) = 0, preserving the edge lengths exactly.",2. Background,[0],[0]
"This is a global metric, as it depends directly on the underlying distances rather than the local relationships between distances.",2. Background,[0],[0]
"A variant is the worst-case distortion Dwc, defined by
Dwc(f) =",2. Background,[0],[0]
"maxu,v∈U :u6=v dV (f(u), f(v))/dU (u, v)
minu,v∈U :u6=v dV (f(u), f(v))/dU (u, v) .
",2. Background,[0],[0]
"That is, the wost-case distortion is the ratio of the maximal expansion and the minimal contraction of distances.",2. Background,[0],[0]
Note that scaling the unit distance does not affect Dwc.,2. Background,[0],[0]
"The best worst-case distortion is Dwc(f) = 1.
",2. Background,[0],[0]
"Reconstruction and learning If we lack a full set of distances, we can either use the triangle inequality to recover the missing distances, or we can access the scaled Euclidean distances (the inside of the acosh in dH(x, y)), and apply standard matrix completion techniques (Candes & Tao, 2010).",2. Background,[0],[0]
Then we compute an embedding using any of the approaches discussed in this paper.,2. Background,[0],[0]
We quantify the error introduced by this process experimentally in Section 5.,2. Background,[0],[0]
We first focus on hyperbolic tree embeddings—a natural approach considering the tree-like behavior of hyperbolic space.,3. Combinatorial Constructions,[0],[0]
We review the embedding of Sarkar (2011).,3. Combinatorial Constructions,[0],[0]
"We then provide novel analysis on the precision, revealing fundamental limits of hyperbolic embeddings.",3. Combinatorial Constructions,[0],[0]
"In particular, we characterize the bits of precision needed for hyperbolic representations.",3. Combinatorial Constructions,[0],[0]
"We extend the construction to r dimensions, and propose to use Steiner nodes to better embed general graphs as trees, building on Abraham et al. (2007).
",3. Combinatorial Constructions,[0],[0]
Embedding trees The nature of hyperbolic space lends itself towards excellent tree embeddings.,3. Combinatorial Constructions,[0],[0]
"In fact, it is possible to embed trees into the Poincaré disk H2 with arbitrarily low distortion (Sarkar, 2011).",3. Combinatorial Constructions,[0],[0]
"Remarkably, trees cannot be embedded into Euclidean space with arbitrarily low distortion for any number of dimensions.",3. Combinatorial Constructions,[0],[0]
"These notions motivate the following two-step process for embedding hierarchies
into hyperbolic space: (1) embed the graphG = (V,E) into a tree T , and (2) embed T into the Poincaré ball",3. Combinatorial Constructions,[0],[0]
Hd.,3. Combinatorial Constructions,[0],[0]
We refer to this process as the combinatorial construction.,3. Combinatorial Constructions,[0],[0]
Note that we are not required to minimize a loss function.,3. Combinatorial Constructions,[0],[0]
"We begin by describing the second stage, where we extend an elegant construction from Sarkar (2011).",3. Combinatorial Constructions,[0],[0]
Algorithm 1 performs an embedding of trees into H2.,3.1. Sarkar’s Construction,[0],[0]
The inputs are a scaling factor τ and a node a (of degree deg(a)) from the tree with parent node b. Say a and b have already been embedded into f(a) and f(b) in H2.,3.1. Sarkar’s Construction,[0],[0]
"The algorithm places the children c1, c2, . . .",3.1. Sarkar’s Construction,[0],[0]
", cdeg(a)−1 into H2.
",3.1. Sarkar’s Construction,[0],[0]
A two-step process is used.,3.1. Sarkar’s Construction,[0],[0]
"First, f(a) and f(b) are reflected across a geodesic (using circle inversion) so that f(a) is mapped onto the origin 0 and f(b) is mapped onto some point",3.1. Sarkar’s Construction,[0],[0]
"z. Next, we place the children nodes to vectors y1, . . .",3.1. Sarkar’s Construction,[0],[0]
", yd−1 equally spaced around a circle with radius eτ−1 eτ+1 (which is a circle of radius τ in the hyperbolic metric), and maximally separated from the reflected parent node embedding z.",3.1. Sarkar’s Construction,[0],[0]
"Lastly, we reflect all of the points back across the geodesic.",3.1. Sarkar’s Construction,[0],[0]
The isometric properties of reflections imply that all children are now at hyperbolic distance exactly τ from f(a).,3.1. Sarkar’s Construction,[0],[0]
"To embed the entire tree, we place the root at the origin O and its children in a circle around it (as in Step 5 of Algorithm 1), then recursively place their children until all nodes have been placed.",3.1. Sarkar’s Construction,[0],[0]
This process runs in linear time.,3.1. Sarkar’s Construction,[0],[0]
Sarkar’s construction works by separating children sufficiently in hyperbolic space.,3.2. Analyzing Sarkar’s Construction,[0],[0]
A key technical idea is to scale all the edges by a factor τ before embedding.,3.2. Analyzing Sarkar’s Construction,[0],[0]
We can then recover the original distances by dividing by τ .,3.2. Analyzing Sarkar’s Construction,[0],[0]
This transformation exploits the fact that hyperbolic space is not scale invariant.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"Sarkar’s construction always captures neighbors perfectly, but Figure 1 implies that increasing the scale preserves the distances between farther nodes better.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Indeed, if one sets τ = 1+εε ( 2 log degmaxπ/2 ) , then the worst-case distortion D of the resulting embedding is no more than
Algorithm 1 Sarkar’s Construction 1: Input: Node a with parent b, children to place c1, c2, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", cdeg(a)−1, partial embedding f containing an embedding for a and b, scaling factor τ
2: (0, z)← reflectf(a)→0(f(a), f(b))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"3: θ ← arg(z) {angle of z from x-axis in the plane} 4: for i ∈ {1, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
",deg(a)− 1} do 5: yi ← e τ−1 eτ+1 · ( cos ( θ + 2πideg(a) ) , sin ( θ + 2πideg(a)
))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"6: (f(a), f(b), f(c1), . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", f(cdeg(a)−1))",3.2. Analyzing Sarkar’s Construction,[0],[0]
"←
reflect0→f(a)(0, z, y1, . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", ydeg(x)−1) 7: Output: Embedded H2 vectors f(c1), f(c2), . . .",3.2. Analyzing Sarkar’s Construction,[0],[0]
", f(cdeg(a)−1)
1 + ε.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"For trees, Sarkar’s construction has arbitrarily high fidelity.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"However, this comes at a cost: the scaling τ affects the bits of precision required.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"In fact, we will show that the precision scales logarithmically with the degree of the tree—but linearly with the maximum path length.
",3.2. Analyzing Sarkar’s Construction,[0],[0]
How many bits of precision do we need to represent points in H2?,3.2. Analyzing Sarkar’s Construction,[0],[0]
"If x ∈ H2, then ‖x‖ < 1, so we need sufficiently many bits so that 1− ‖x‖ will not be rounded to zero.",3.2. Analyzing Sarkar’s Construction,[0],[0]
This requires roughly − log(1− ‖x‖) = log 11−‖x‖ bits.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"Say we are embedding two points x, y at distance d. As described in the background, there is an isometric reflection that takes a pair of points (x, y) in H2 to (0, z) while preserving their distance, so without loss of generality we have that
d = dH(x, y) = dH(0, z) = acosh
( 1 + 2 ‖z‖2
1− ‖z‖2
) .
",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Rearranging the terms, we have (cosh(d) + 1)/2 = (1 − ‖z‖2)−1 ≥ (1 − ‖z‖)−1/2.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Thus, the number of bits we want so that 1 − ‖z‖ will not be rounded to zero is log(cosh(d)+1).",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Since cosh(d) = (exp(d)+exp(−d))/2, this is roughly d bits.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"That is, in hyperbolic space, we need about d bits to express distances of d (rather than log d in Euclidean space).1 This result will be of use below.
",3.2. Analyzing Sarkar’s Construction,[0],[0]
Consider the largest distance in the embeddings produced by Algorithm 1.,3.2. Analyzing Sarkar’s Construction,[0],[0]
"If the longest path length in the tree is `, and each edge has length τ = 1ε ( 2 log degmax π/2 ) , the largest distance is O( `ε log degmax), and we require this number of bits for the representation.
Let us interpret this expression.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Note that degmax is inside the log term, so that a bushy tree is not penalized much in precision.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"On the other hand, the longest path length ` is not, so that hyperbolic embeddings struggle with long paths.",3.2. Analyzing Sarkar’s Construction,[0],[0]
"Moreover, by selecting an explicit graph, we derive a matching lower bound, concluding that to achieve a dis-
1Although it is particularly easy to bound precision in the Poincaré model, this fact holds generally for hyperbolic space independent of model (shown in the appendix).
",3.2. Analyzing Sarkar’s Construction,[0],[0]
"tortion ε, any construction requires Ω ( ` ε log(degmax) ) bits.",3.2. Analyzing Sarkar’s Construction,[0],[0]
The argument follows from selecting a graph consisting of m(degmax+1) nodes in a tree with a single root and degmax chains each of length m (shown in the appendix).,3.2. Analyzing Sarkar’s Construction,[0],[0]
Our next contribution is a generalization of the construction from the disk H2 to the ball Hr.,3.3. Improving the Construction,[0],[0]
"Our construction follows the same line as Algorithm 1, but since we have r dimensions, the step where we place children spaced out on a circle around their parent now uses a hypersphere.
",3.3. Improving the Construction,[0],[0]
"Spacing out points on the hypersphere is a classic problem known as spherical coding (Conway & Sloane, 1999).",3.3. Improving the Construction,[0],[0]
"As we shall see, the number of children that we can place for a particular angle grows with the dimension.",3.3. Improving the Construction,[0],[0]
"Since the required scaling factor τ gets larger as the angle decreases, we can reduce τ for a particular embedding by increasing the dimension.",3.3. Improving the Construction,[0],[0]
"Note that increasing the dimension helps with bushy trees (large degmax), but has limited effect on tall trees with small degmax.",3.3. Improving the Construction,[0],[0]
"We show
Proposition 3.1.",3.3. Improving the Construction,[0],[0]
"The generalized Hr combinatorial construction has distortion at most 1 + ε and requires at most O( 1ε ` r log degmax) bits to represent a node component for r ≤ (log degmax) + 1, and O( 1ε `) bits for r > (log degmax) + 1.
To generalize to Hr, we replace Step 5 in Algorithm 1 with a node placement step based on coding theory.",3.3. Improving the Construction,[0],[0]
The children are placed at the vertices of a hypercube inscribed into the unit hypersphere (and then scaled by τ ).,3.3. Improving the Construction,[0],[0]
"Each component of a hypercube vertex has the form ±1√
r .",3.3. Improving the Construction,[0],[0]
"We index these
points using binary sequences a ∈ {0, 1}r in the following way: xa = ( (−1)a1√ r , (−1) a2 √ r , . . .",3.3. Improving the Construction,[0],[0]
", (−1) ar √ r ) .",3.3. Improving the Construction,[0],[0]
We space out the children by controlling the distances by selecting a set of binary sequences a with a prescribed minimum Hamming distance—a binary error-correcting code—and placing the children at the resulting hypercube vertices.,3.3. Improving the Construction,[0],[0]
"We provide more details, including our choice of code in the appendix.",3.3. Improving the Construction,[0],[0]
We revisit the first step of the construction: embedding graphs into trees.,3.4. Embedding into Trees,[0],[0]
"There are fundamental limits to how well graphs can be embedded into trees; in general, breaking long cycles inevitably adds distortion, as shown in Figure 2.",3.4. Embedding into Trees,[0],[0]
"We are inspired by a measure of this limit, the δ-4 points condition introduced in Abraham et al. (2007).",3.4. Embedding into Trees,[0],[0]
A graph on n nodes that satisfies the δ-4 points condition has distortion at most (1 + δ)c1 logn for some constant c1.,3.4. Embedding into Trees,[0],[0]
"This result enables our end-to-end embedding to achieve a distortion of at most D(f) ≤ (1 + δ)c1 logn(1 + ε).
",3.4. Embedding into Trees,[0],[0]
"The result in Abraham et al. (2007) builds a tree with Steiner
nodes.",3.4. Embedding into Trees,[0],[0]
These additional nodes can help control the distances in the resulting weighted tree (Figure 2).,3.4. Embedding into Trees,[0],[0]
"Note that Algorithm 1 readily extends to the case of weighted trees.
",3.4. Embedding into Trees,[0],[0]
"In summary, the key takeaways of our analysis are:
•",3.4. Embedding into Trees,[0],[0]
"There is a fundamental tension between precision and quality in hyperbolic embeddings.
",3.4. Embedding into Trees,[0],[0]
"• Hyperbolic embeddings have an exponential advantage in space compared to Euclidean embeddings for short, bushy hierarchies, but will have less of an advantage for graphs that contain long paths.
",3.4. Embedding into Trees,[0],[0]
• Choosing an appropriate scaling factor τ is critical for quality.,3.4. Embedding into Trees,[0],[0]
"Later, we will propose to learn this scale factor automatically for computing embeddings in PyTorch.
",3.4. Embedding into Trees,[0],[0]
• Steiner nodes can help improve embeddings of graphs.,3.4. Embedding into Trees,[0],[0]
"In this section, we explore a fundamental and more general question than we did in the previous section: if we are given the pairwise distances arising from a set of points in hyperbolic space, can we recover the points?",4. Hyperbolic Multidimensional Scaling,[0],[0]
This enables us to produce an embedding for a desired distance metric.,4. Hyperbolic Multidimensional Scaling,[0],[0]
The equivalent problem for Euclidean distances is solved with multidimensional scaling (MDS).,4. Hyperbolic Multidimensional Scaling,[0],[0]
The goal of this section is to analyze the hyperbolic MDS (h-MDS) problem.,4. Hyperbolic Multidimensional Scaling,[0],[0]
"We describe and overcome the additional technical challenges imposed by hyperbolic distances, and show that exact recovery is possible and interpretable.",4. Hyperbolic Multidimensional Scaling,[0],[0]
Afterwards we propose a technique for dimensionality reduction using principal geodesics analysis (PGA) that provides optimization guarantees.,4. Hyperbolic Multidimensional Scaling,[0],[0]
"In particular, this addresses the shortcomings of h-MDS when recovering points that do not exactly lie on a hyperbolic manifold.",4. Hyperbolic Multidimensional Scaling,[0],[0]
"Suppose that there is a set of hyperbolic points x1, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn ∈ Hr, embedded in the Poincaré ball and written X ∈ Rn×r in matrix form.",4.1. Exact Hyperbolic MDS,[0],[0]
"We observe all the pairwise distances di,j = dH(xi, xj), but do not observe X: our goal is to use the observed di,j’s to recover X (or some other set of points with the same pairwise distances di,j).
",4.1. Exact Hyperbolic MDS,[0],[0]
The MDS algorithm in the Euclidean setting makes an important centering2 assumption: the points have mean 0.,4.1. Exact Hyperbolic MDS,[0],[0]
"If an exact embedding for the distances exists, it can be recovered from a matrix factorization.",4.1. Exact Hyperbolic MDS,[0],[0]
"In other words, Euclidean MDS always recovers a centered embedding.
",4.1. Exact Hyperbolic MDS,[0],[0]
"In hyperbolic space, the same algorithm does not work, but we show that it is possible to find an embedding centered at a different mean.",4.1. Exact Hyperbolic MDS,[0],[0]
"More precisely, we introduce a new mean which we call the pseudo-Euclidean mean, that behaves like the Euclidean mean in that it enables recovery through matrix factorization.",4.1. Exact Hyperbolic MDS,[0],[0]
"Once the points are recovered in hyperbolic space, they can be recentered around a more canonical mean by translating it to the origin.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Algorithm 2 is our complete algorithm, and for the remainder of this section we will describe how and why it works.",4.1. Exact Hyperbolic MDS,[0],[0]
"We first describe the hyperboloid model, an alternate but equivalent model of hyperbolic geometry in which h-MDS is simpler.",4.1. Exact Hyperbolic MDS,[0],[0]
"Of course, we can easily convert between the hyperboloid model and the Poincaré ball model.",4.1. Exact Hyperbolic MDS,[0],[0]
"Next, we show how to reduce the problem to a standard PCA problem, which recovers an embedding centered at the points’ pseudo-Euclidean mean.",4.1. Exact Hyperbolic MDS,[0],[0]
"Finally, we discuss the meaning and implications of centering and prove that the algorithm preserves submanifolds as well—that is, if there is an exact embedding in k < r dimensions centered at their canonical mean, then our algorithm will recover it.
",4.1. Exact Hyperbolic MDS,[0],[0]
The hyperboloid model Define Q to be the diagonal matrix in Rr+1 where Q00 = 1 and Qii = −1 for i > 0.,4.1. Exact Hyperbolic MDS,[0],[0]
"For a vector x ∈ Rr+1, xTQx is called the Minkowski quadratic form.",4.1. Exact Hyperbolic MDS,[0],[0]
"The hyperboloid model is defined as
Mr = { x ∈ Rr+1 ∣∣xTQx = 1 ∧ x0 > 0} , which is endowed with a distance measure dH(x, y) = acosh(xTQy).",4.1. Exact Hyperbolic MDS,[0],[0]
"For convenience, for x ∈Mr let x0 denote 0th coordinate eT0 x, and ~x ∈",4.1. Exact Hyperbolic MDS,[0],[0]
Rr denote the rest of the coordinates3.,4.1. Exact Hyperbolic MDS,[0],[0]
"With this notation, the Minkowski bilinear form can be written xTQy =",4.1. Exact Hyperbolic MDS,[0],[0]
x0y0,4.1. Exact Hyperbolic MDS,[0],[0]
"− ~xT~y.
2We say that points are centered at a particular mean if this mean is at 0.",4.1. Exact Hyperbolic MDS,[0],[0]
"The act of centering refers to applying an isometry that makes the mean of the points 0.
",4.1. Exact Hyperbolic MDS,[0],[0]
"3Since x0 = √
1 + ‖~x‖2 is just a function of ~x, we can equivalently consider just ~x as being a member of a model of hyperbolic space: This representation is sometimes known as the Gans model.
",4.1. Exact Hyperbolic MDS,[0],[0]
"A new mean Given points x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn",4.1. Exact Hyperbolic MDS,[0],[0]
"∈Mr in hyperbolic space, define a variance term
Ψ(z;x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn) = n∑ i=1",4.1. Exact Hyperbolic MDS,[0],[0]
"sinh2(dH(xi, z)).
",4.1. Exact Hyperbolic MDS,[0],[0]
We define a pseudo-Euclidean mean to be any local minimum of this expression.,4.1. Exact Hyperbolic MDS,[0],[0]
"Notice that this is independent of any particular model of hyperbolic space, since it is defined only through the hyperbolic distance function dH .",4.1. Exact Hyperbolic MDS,[0],[0]
Lemma 4.1.,4.1. Exact Hyperbolic MDS,[0],[0]
Define X ∈ Rn×r such that XT ei = ~xi and u ∈,4.1. Exact Hyperbolic MDS,[0],[0]
"Rn such that ui = x0,i.",4.1. Exact Hyperbolic MDS,[0],[0]
"Then
∇~zΨ(z;x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn)|~z=0 = −2 n∑ i=1",4.1. Exact Hyperbolic MDS,[0],[0]
"x0,i~xi = −2XTu.
",4.1. Exact Hyperbolic MDS,[0],[0]
This means that 0 is a pseudo-Euclidean mean if and only if 0 = XTu.,4.1. Exact Hyperbolic MDS,[0],[0]
"Call some hyperbolic points x1, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn pseudoEuclidean centered if their average is 0 in this sense: i.e. if XTu = 0.",4.1. Exact Hyperbolic MDS,[0],[0]
"We can always center a set of points without affecting their pairwise distances by simply finding their average, and then sending it to 0 through an isometry.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Recovery via matrix factorization Suppose we observe the pairwise distances dH(xi, xj) of points x1, x2, . . .",4.1. Exact Hyperbolic MDS,[0],[0]
", xn ∈Mr.",4.1. Exact Hyperbolic MDS,[0],[0]
"This gives the matrix Y such that
Yi,j = cosh (dH(xi, xj))",4.1. Exact Hyperbolic MDS,[0],[0]
"= x0,ix0,j",4.1. Exact Hyperbolic MDS,[0],[0]
− ~xiT ~xj .,4.1. Exact Hyperbolic MDS,[0],[0]
"(1)
DefiningX and u as in Lemma 4.1, then in matrix form Y = uuT−XXT .",4.1. Exact Hyperbolic MDS,[0],[0]
"Without loss of generality, suppose that the xi are centered at their pseudo-Euclidean mean, so thatXTu = 0 by Lemma 4.1.",4.1. Exact Hyperbolic MDS,[0],[0]
"This implies that u is an eigenvector of Y with positive eigenvalue, and the rest of Y ’s eigenvalues are negative.",4.1. Exact Hyperbolic MDS,[0],[0]
"Therefore an eigendecomposition of Y will find u, X̂ such that Y = uuT − X̂X̂T , i.e. it will directly recover X up to rotation.
",4.1. Exact Hyperbolic MDS,[0],[0]
"In fact, running PCA on −Y = XTX − uuT to find the n most significant non-negative eigenvectors will recover X up to rotation, and then u can be found by leveraging the fact that x0 = √ 1 + ‖~x‖2.",4.1. Exact Hyperbolic MDS,[0],[0]
"This leads to Algorithm 2, with optional post-processing steps for converting the embedding to the Poincaré ball model and for re-centering the points.
",4.1. Exact Hyperbolic MDS,[0],[0]
"A word on centering The MDS algorithm in Euclidean geometry returns points centered at their Karcher mean z, which is a point minimizing ∑ d2(z, xi) (where d is the distance metric).",4.1. Exact Hyperbolic MDS,[0],[0]
"The Karcher center is important for interpreting dimensionality reduction; we use the analogous hyperbolic Karcher mean for PGA in Section 4.2.
",4.1. Exact Hyperbolic MDS,[0],[0]
"Although Algorithm 2 returns points centered at their pseudo-Euclidean mean instead of their Karcher mean, they can be easily recentered by finding their Karcher mean and
Algorithm 2 1: Input: Distance matrix di,j and rank r 2: Compute scaled distance matrix Yi,j = cosh(di,j) 3: X → PCA(−Y, r) 4: Project X from hyperboloid model to Poincaré model: x→ x
1+ √ 1+‖x‖2
5:",4.1. Exact Hyperbolic MDS,[0],[0]
"If desired, centerX at a different mean (e.g. the Karcher mean) 6: return X
reflecting it onto the origin.",4.1. Exact Hyperbolic MDS,[0],[0]
"Furthermore, Algorithm 2 preserves the dimension of the embedding:
Lemma 4.2.",4.1. Exact Hyperbolic MDS,[0],[0]
"If a set of points lie in a dimension-k geodesic submanifold, then both their Karcher mean and their pseudo-Euclidean mean lie in the same submanifold.
",4.1. Exact Hyperbolic MDS,[0],[0]
"This implies that centering with the pseudo-Euclidean mean preserves geodesic submanifolds: If it is possible to embed distances in a dimension-k geodesic submanifold centered and rooted at a Karcher mean, then it is also possible to embed the distances in a dimension-k submanifold centered and rooted at a pseudo-Euclidean mean, and vice versa.",4.1. Exact Hyperbolic MDS,[0],[0]
"Given a high-rank embedding (resulting from h-MDS, for example), we may wish to find a lower-rank version.",4.2. Reducing Dimensionality with PGA,[0],[0]
"In Euclidean space, one can get the optimal lower rank embedding by simply discarding components.",4.2. Reducing Dimensionality with PGA,[0],[0]
"However, this may not be the case in hyperbolic space.",4.2. Reducing Dimensionality with PGA,[0],[0]
"Motivated by this, we study dimensionality reduction in hyperbolic space.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"As hyperbolic space does not have a linear subspace structure like Euclidean space, we need to define what we mean by lower-dimensional.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We follow Principal Geodesic Analysis (Fletcher et al., 2004), (Huckemann et al., 2010).",4.2. Reducing Dimensionality with PGA,[0],[0]
"Consider an initial embedding with points x1, . . .",4.2. Reducing Dimensionality with PGA,[0],[0]
", xn ∈ H2 and let dH :",4.2. Reducing Dimensionality with PGA,[0],[0]
H2 × H2 → R+ be the hyperbolic distance.,4.2. Reducing Dimensionality with PGA,[0],[0]
Suppose we want to map this embedding onto a one-dimensional subspace.,4.2. Reducing Dimensionality with PGA,[0],[0]
"(Note that we are considering a two-dimensional embedding and one-dimensional subspace here for simplicity, and these results immediately extend to higher dimensions.)",4.2. Reducing Dimensionality with PGA,[0],[0]
"In this case, the goal of PGA is to find a geodesic γ :",4.2. Reducing Dimensionality with PGA,[0],[0]
"[0, 1] → H2 that passes through the mean of the points and that minimizes the squared error (or variance): f(γ) = ∑n i=1 mint∈[0,1] dH(γ(t), xi) 2.
",4.2. Reducing Dimensionality with PGA,[0],[0]
This expression can be simplified significantly and reduced to a minimization in Euclidean space.,4.2. Reducing Dimensionality with PGA,[0],[0]
"First, we find the mean of the points, the point x̄ which minimizes∑n i=1",4.2. Reducing Dimensionality with PGA,[0],[0]
"dH(x̄, xi)
2.4",4.2. Reducing Dimensionality with PGA,[0],[0]
"Next, we reflect all the points xi so that their mean is 0 in the Poincaré disk model; we can
4The derivative of the hyperbolic distance has a singularity, that is, limy→x ∂x|dH(x, y)| → ∞ for any x ∈ H.",4.2. Reducing Dimensionality with PGA,[0],[0]
"This issue can
do this using a circle inversion that maps x̄ onto 0",4.2. Reducing Dimensionality with PGA,[0],[0]
"Since reflections are isometric, if γ is a line through 0 and Rγ is the reflection across γ, we have that dH(γ, x) = mint∈[0,1] dH(γ(t), x) = 1 2dH(Rlx, x).
",4.2. Reducing Dimensionality with PGA,[0],[0]
"Combining this with the Euclidean reflection formula and the hyperbolic metric produces
f(γ) = 1
4 n∑ i=1 acosh2",4.2. Reducing Dimensionality with PGA,[0],[0]
"( 1 + 8dE(γ, xi) 2 (1− ‖xi‖2)2 ) ,
in which dE is the Euclidean distance from a point to a line.",4.2. Reducing Dimensionality with PGA,[0],[0]
If we define wi = √ 8xi/(1,4.2. Reducing Dimensionality with PGA,[0],[0]
− ‖xi‖2),4.2. Reducing Dimensionality with PGA,[0],[0]
this reduces to the simplified expression f(γ),4.2. Reducing Dimensionality with PGA,[0],[0]
"= 1 4 ∑n i=1 acosh 2 ( 1 + dE(γ,wi) 2 ) .
",4.2. Reducing Dimensionality with PGA,[0],[0]
Notice that the loss function is not convex.,4.2. Reducing Dimensionality with PGA,[0],[0]
"We observe that there can be multiple local minima that are attractive and stable, in contrast to PCA.",4.2. Reducing Dimensionality with PGA,[0],[0]
Figure 3 illustrates this nonconvexity on a simple dataset in H2 with only four examples.,4.2. Reducing Dimensionality with PGA,[0],[0]
"This makes globally optimizing the objective difficult.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"Nevertheless, there will always be a region Ω containing a global optimum γ∗ that is convex and admits an efficient projection, and where f is convex when restricted to Ω.",4.2. Reducing Dimensionality with PGA,[0],[0]
"Thus it is possible to build a gradient descent-based algorithm to recover lower-dimensional subspaces: for example, we built a simple optimizer in PyTorch.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We also give a sufficient condition on the data for f above to be convex.
",4.2. Reducing Dimensionality with PGA,[0],[0]
Lemma 4.3.,4.2. Reducing Dimensionality with PGA,[0],[0]
"For hyperbolic PGA if for all i,
acosh2 ( 1 + dE(γ,wi) 2 ) < min ( 1, 1
3 ‖wi‖2 ) then f is locally convex at γ.
be mitigated by minimizing d2H , which does have a continuous derivative throughout H. The use of dH(x, y) is a minor instability in Nickel & Kiela (2017); Chamberlain et al. (2017)’s formulation, necessitating guarding against NANs.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We discuss this further in the appendix.
",4.2. Reducing Dimensionality with PGA,[0],[0]
"As a result, if we initialize in and optimize over a region that contains γ∗ and where the condition of Lemma 4.3 holds, then gradient descent will be guaranteed to converge to γ∗.",4.2. Reducing Dimensionality with PGA,[0],[0]
"We can turn this result around and read it as a recovery result: if the noise is bounded in this regime, then we are able to provably recover the correct low-dimensional embedding.",4.2. Reducing Dimensionality with PGA,[0],[0]
We evaluate the proposed approaches and compare against existing methods.,5. Experiments,[0],[0]
"We hypothesize that for tree-like data, the combinatorial construction offers the best performance.",5. Experiments,[0],[0]
"For general data, we expect h-MDS to produce the lowest distortion, while it may have low MAP due to precision limitations.",5. Experiments,[0],[0]
We anticipate that dimension is a critical factor (outside of the combinatorial construction).,5. Experiments,[0],[0]
"In the appendix, we report on additional datasets, combinatorial construction parameters, and the effect of hyperparameters.
",5. Experiments,[0],[0]
"Datasets We consider trees, tree-like hierarchies, and graphs that are not tree-like.",5. Experiments,[0],[0]
"Trees include fully-balanced and phylogenetic trees expressing genetic heritage (Hofbauer et al., 2016), available at Sanderson et al. (1994).",5. Experiments,[0],[0]
"Nearly tree-like hierarchies include the WordNet hypernym graph (the largest connected component from Nickel & Kiela (2017)) and a graph of Ph.D. advisor-advisee relationships (De Nooy et al., 2011).",5. Experiments,[0],[0]
"Also included are datasets
that vary in their tree nearness, such as disease relationships (Goh et al., 2007) and protein interactions (Jeong et al., 2001), both available from Rossi & Ahmed (2015).",5. Experiments,[0],[0]
"We also include the general relativity and quantum cosmology (GrQC) arXiv collaboration network (Leskovec et al., 2007).
",5. Experiments,[0],[0]
Approaches Combinatorial embeddings into H2 use the ε = 0.1 precision setting; others are considered in the Appendix.,5. Experiments,[0],[0]
We performed h-MDS in floating point precision.,5. Experiments,[0],[0]
"We include results for our PyTorch implementation (PT) of an SGD-based algorithm (described later), and a warm start version (PWS) initialized with the high-dimensional combinatorial construction.",5. Experiments,[0],[0]
"We compare against classical MDS (i.e., PCA), and the optimization-based approach Nickel & Kiela (2017), which we call FB.",5. Experiments,[0],[0]
"The experiments for h-MDS, PyTorch SGD, PCA, and FB used dimensions of 2,5,10,50,100,200; we recorded the best resulting MAP and distortion.",5. Experiments,[0],[0]
"Due to the large scale, we did not replicate the best FB numbers on large graphs (i.e., Gr-QC and WordNet); we report their best published MAP numbers (their work does not report distortion).",5. Experiments,[0],[0]
These entries are marked with an asterisk.,5. Experiments,[0],[0]
"For the WordNet graph, FB uses the transitive closure; a weighted version of the graph captures the ancestor relationships.",5. Experiments,[0],[0]
"The full details are in appendix.
",5. Experiments,[0],[0]
"Quality In Table 3 (left), we report the distortion.",5. Experiments,[0],[0]
"As expected, for tree or tree-like graphs, the combinatorial construction has exceedingly low distortion.",5. Experiments,[0],[0]
"Because h-MDS is meant to recover points exactly, we hypothesized that h-MDS would offer very low distortion on these datasets.",5. Experiments,[0],[0]
"Table 3 confirms this: among h-MDS, PCA, and FB, hMDS consistently offers the lowest distortion, producing, for example, a distortion of 0.039 on the phylogenetic tree.",5. Experiments,[0],[0]
We observe that floating point h-MDS struggles with MAP.,5. Experiments,[0],[0]
"We separately confirmed that this is due to precision (by
using a high-precision solver).",5. Experiments,[0],[0]
"The optimization-based approach is bolstered by appropriate initialization from the combinatorial construction.
",5. Experiments,[0],[0]
"Table 3 (right) reports the MAP measure (we additionally include WordNet results in Table 2), which is a local measure.",5. Experiments,[0],[0]
"We confirm that the combinatorial construction performs well for tree-like hierarchies, where MAP is close to 1.",5. Experiments,[0],[0]
The construction improves on approaches such as FB that rely on optimization.,5. Experiments,[0],[0]
"On larger graphs like WordNet, our approach yields a MAP of 0.989—while their WordNet MAP result is 0.870 at 200 dimensions.",5. Experiments,[0],[0]
"This is exciting, as our approach is deterministic and linear-time.
",5. Experiments,[0],[0]
A refined understanding of hyperbolic embeddings may be used to improve the quality and runtime of extant algorithms.,5. Experiments,[0],[0]
"Indeed, we embedded WordNet entity-relationship-entity triples (Socher et al., 2013) using the combinatorial construction in 10 dimensions, accurately preserving relationship knowledge (Table 4).",5. Experiments,[0],[0]
"This suggests that hyperbolic embeddings are effective at compressing knowledge and may useful for knowledge base completion and Q/A tasks.
SGD-Based Algorithm We built an SGD-based algorithm implemented in PyTorch.",5. Experiments,[0],[0]
"The loss function is equivalent to the PGA loss, and so is continuously differentiable.
",5. Experiments,[0],[0]
"To evaluate our algorithm’s ability to deal with incomplete information, we sample the distance matrix at a ratio of nonedges to edges at 10 : 1 following Nickel & Kiela (2017).",5. Experiments,[0],[0]
"In Figure 4, we recover a good solution for the phylogenetic tree with a small fraction of the entries; for example, we sampled approximately 4% of the graph for a MAP of 0.74 and distortion of 0.6.",5. Experiments,[0],[0]
We also considered learning the scale of the embedding (details in the appendix).,5. Experiments,[0],[0]
"Finally, all of our techniques scale to graphs with millions of nodes.",5. Experiments,[0],[0]
Hyperbolic embeddings embed hierarchical information with high fidelity and few dimensions.,6. Conclusion and Future Work,[0],[0]
"We explored the limits of this approach by describing scalable, high quality algorithms.",6. Conclusion and Future Work,[0],[0]
We hope the techniques here encourage more follow-on work on the exciting techniques of Nickel & Kiela (2017); Chamberlain et al. (2017).,6. Conclusion and Future Work,[0],[0]
Thanks to Alex Ratner and Avner May for helpful discussion and to Beliz Gunel and Sen Wu for assistance with experiments.,Acknowledgements,[0],[0]
"We gratefully acknowledge the support of DARPA under No. FA87501720095 and FA87501320039, ONR under No. N000141712266, the Moore Foundation, Okawa Research Grant, American Family Insurance, Accenture, Toshiba, the Secure Internet of Things Project, Google, VMware, Qualcomm, Ericsson, Analog Devices, and members of the Stanford DAWN project: Intel, Microsoft, Teradata, and VMware.",Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgements,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, DOE, NIH, ONR, or the U.S. Government.",Acknowledgements,[0],[0]
Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures.,abstractText,[0],[0]
We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization.,abstractText,[0],[0]
"On WordNet, this algorithm obtains a meanaverage-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points.",abstractText,[0],[0]
We provide bounds characterizing the precisiondimensionality tradeoff inherent in any hyperbolic embedding.,abstractText,[0],[0]
"To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS).",abstractText,[0],[0]
"We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality.",abstractText,[0],[0]
"Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.",abstractText,[0],[0]
Representation Tradeoffs for Hyperbolic Embeddings,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 613–622 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1057",text,[0],[0]
Speech recognition is one of the success stories of language technology.,1 Introduction,[0],[0]
It works remarkably well in a range of practical settings.,1 Introduction,[0],[0]
"However, this success relies on the use of very heavy supervision where the machine is fed thousands of hours of painstakingly transcribed audio speech signal.",1 Introduction,[0],[0]
Humans are able to learn to recognize and understand speech from notably weaker and noisier supervision: they manage to learn to extract structure and meaning from speech by simply being exposed to utterances situated and grounded in their daily sensory experience.,1 Introduction,[0],[0]
"Modeling and emulating this remarkable skill has been the goal of numerous studies; however in the overwhelming majority of cases researchers used severely simplified settings where either the language input or the extralinguistic sensory input, or both, are small scale and symbolically represented.",1 Introduction,[0],[0]
"Section 2 provides a brief overview of this research.
",1 Introduction,[0],[0]
More recently several lines of work have moved towards more realistic inputs while modeling or emulating language acquisition in a grounded setting.,1 Introduction,[0],[0]
"Gelderloos and Chrupała (2016) use the image captioning dataset MS COCO (Lin et al., 2014) to mimic the setting of grounded language learning: the sensory input consists of images of natural scenes, while the language input are phonetically transcribed descriptions of these scenes.",1 Introduction,[0],[0]
"The use of such moderately large and low-level data allows the authors to train a multi-layer recurrent neural network model, and to explore the nature and localization of the emerging hierarchy of linguistic representations learned in the process.",1 Introduction,[0],[0]
"Furthermore, in a series of recent studies Harwath and Glass (2015); Harwath et al. (2016); Harwath and Glass (2017) use image captioning datasets to model learning to understand spoken language from visual context with convolutional neural network models.",1 Introduction,[0],[0]
"Finally, there is a small but growing body of work dedicated to elucidating the nature of representations learned by neural networks from language data (see Section 2.2 for a brief overview).",1 Introduction,[0],[0]
"In the current work we build on these three strands of research and contribute the following advances:
• We use a multi-layer gated recurrent neural network to properly model the temporal nature of speech signal and substantially improve performance compared to the convolutional architecture from Harwath and Glass (2015); • We carry out an in-depth analysis of the representations used by different components of the trained model and correlate them to representations learned by a text-based model and to human patterns of judgment on linguistic stimuli.",1 Introduction,[0],[0]
"This analysis is especially novel for a model with speech signal as input.
",1 Introduction,[0],[0]
"The general pattern of findings in our analysis is
613
as follows:",1 Introduction,[0],[0]
"The model learns to extract from the acoustic input both form-related and semanticsrelated information, and encodes it in the activations of the hidden layers.",1 Introduction,[0],[0]
Encoding of semantic aspects tends to become richer as we go up the hierarchy of layers.,1 Introduction,[0],[0]
"Meanwhile, encoding of formrelated aspects of the language input, such as utterance length or the presence of specific words, tends to initially increase and then decay.
",1 Introduction,[0],[0]
"We release the code for our models and analyses as open source, available at https://github.com/gchrupala/visually-groundedspeech.",1 Introduction,[0],[0]
"We also release a dataset of synthetically spoken image captions based on MS COCO, available at https://doi.org/10.5281/zenodo.400926.",1 Introduction,[0],[0]
Children learn to recognize and assign meaning to words from continuous perceptual data in extremely noisy context.,2 Related work,[0],[0]
"While there have been many computational studies of human word meaning acquisition, they typically make strong simplifying assumptions about the nature of the input.",2 Related work,[0],[0]
"Often language input is given in the form of word symbols, and the context consists of a set of symbols representing possible referents (e.g. Siskind, 1996; Frank et al., 2007; Fazly et al., 2010).",2 Related work,[0],[0]
"In contrast, several studies presented models that learn from sensory rather than symbolic input, which is rich with regards to the signal itself, but very limited in scale and variation (e.g. Roy and Pentland, 2002; Yu and Ballard, 2004; Lazaridou et al., 2016).",2 Related work,[0],[0]
Chrupała et al. (2015) introduce a model that learns to predict the visual context from image captions.,2.1 Multimodal language acquisition,[0],[0]
"The model is trained on image-caption pairs from MSCOCO (Lin et al., 2014), capturing both rich visual input as well as larger scale input, but the language input still consists of word symbols.",2.1 Multimodal language acquisition,[0],[0]
"Gelderloos and Chrupała (2016) propose a similar architecture that instead takes phonemelevel transcriptions as language input, thereby incorporating the word segmentation problem into the learning task.",2.1 Multimodal language acquisition,[0],[0]
"In this work, we introduce an architecture that learns from continuous speech and images directly.
",2.1 Multimodal language acquisition,[0],[0]
This work is related to research on visual grounding of language.,2.1 Multimodal language acquisition,[0],[0]
"The field is large and growing, with most work dedicated to the ground-
ing of written text, particularly in image captioning tasks (see Bernardi et al. (2016) for an overview).",2.1 Multimodal language acquisition,[0],[0]
"However, learning to ground language to visual information is also interesting from an automatic speech recognition point of view.",2.1 Multimodal language acquisition,[0],[0]
"Potentially, ASR systems could be trained from naturally co-occurring visual context information, without the need for extensive manual annotation – a particularly promising prospect for speech recognition in low-resource languages.",2.1 Multimodal language acquisition,[0],[0]
There have been several attempts along these lines.,2.1 Multimodal language acquisition,[0],[0]
Synnaeve et al. (2014) present a method of learning to recognize spoken words in isolation from cooccurrence with image fragments.,2.1 Multimodal language acquisition,[0],[0]
"Harwath and Glass (2015) present a model that learns to map pre-segmented spoken words in sequence to aspects of the visual context, while in Harwath and Glass (2017)",2.1 Multimodal language acquisition,[0],[0]
"the model also learns to recognize words in the unsegmented signal.
",2.1 Multimodal language acquisition,[0],[0]
"Most closely related to our work is that of Harwath et al. (2016), as it presents an architecture that learns to project images and unsegmented spoken captions to the same embedding space.",2.1 Multimodal language acquisition,[0],[0]
The sentence representation is obtained by feeding the spectrogram to a convolutional network.,2.1 Multimodal language acquisition,[0],[0]
"The architecture is trained on crowd-sourced spoken captions for images from the Places dataset (Zhou et al., 2014), and evaluated on image search and caption retrieval.",2.1 Multimodal language acquisition,[0],[0]
Unfortunately this dataset is not currently available and we were thus unable to directly compare the performance of our model to Harwath et al. (2016).,2.1 Multimodal language acquisition,[0],[0]
We do compare to Harwath and Glass (2015) which was tested on a public dataset.,2.1 Multimodal language acquisition,[0],[0]
"We make different architectural choices, as our models are based on recurrent highway networks (Zilly et al., 2016).",2.1 Multimodal language acquisition,[0],[0]
"As in human cognition, speech is processed incrementally.",2.1 Multimodal language acquisition,[0],[0]
This also allows our architecture to integrate information sequentially from speech of arbitrary duration.,2.1 Multimodal language acquisition,[0],[0]
"While analysis of neural methods in NLP is often limited to evaluation of the performance on the training task, recently methods have been introduced to peek inside the black box and explore what it is that enables the model to perform the task.",2.2 Analysis of neural representations,[0],[0]
"One approach is to look at the contribution of specific parts of the input, or specific units in the model, to final representations or decisions.",2.2 Analysis of neural representations,[0],[0]
"Kádár et al. (2016) propose omission scores, a method to estimate the contribution of input tokens to the fi-
nal representation by removing them from the input and comparing the resulting representations to the ones generated by the original input.",2.2 Analysis of neural representations,[0],[0]
"In a similar approach, Li et al. (2016) study the contribution of individual input tokens as well as hidden units and word embedding dimensions by erasing them from the representation and analyzing how this affects the model.
",2.2 Analysis of neural representations,[0],[0]
Miao et al. (2016) and Tang et al. (2016) use visualization techniques for fine-grained analysis of GRU and LSTM models for ASR.,2.2 Analysis of neural representations,[0],[0]
"Visualization of input and forget gate states allows Miao et al. (2016) to make informed adaptations to gated recurrent architectures, resulting in more efficiently trainable models.",2.2 Analysis of neural representations,[0],[0]
"Tang et al. (2016) visualize qualitative differences between LSTM- and GRUbased architectures, regarding the encoding of information, as well as how it is processed through time.
",2.2 Analysis of neural representations,[0],[0]
We specifically study linguistic properties of the information encoded in the trained model.,2.2 Analysis of neural representations,[0],[0]
"Adi et al. (2016) introduce prediction tasks to analyze information encoded in sentence embeddings about word order, sentence length, and the presence of individual words.",2.2 Analysis of neural representations,[0],[0]
We use related techniques to explore encoding of aspects of form and meaning within components of our stacked architecture.,2.2 Analysis of neural representations,[0],[0]
"We use a multi-layer, gated recurrent neural network (RHN) to model the temporal nature of speech signal.",3 Models,[0],[0]
"Recurrent neural networks are designed for modeling sequential data, and gated variants (GRUs, LSTMs) are widely used with speech and text in both cognitive modeling and engineering contexts.",3 Models,[0],[0]
"RHNs are a simple generalization of GRU networks such that the transform between time points can consist of several steps.
",3 Models,[0],[0]
Our multimodal model projects spoken utterances and images to a joint semantic space.,3 Models,[0],[0]
The idea of projecting different modalities to a shared semantic space via a pair of encoders has been used in work on language and vision (among them Vendrov et al. (2015)).,3 Models,[0],[0]
"The core idea is to encourage inputs representing the same meaning in different modalities to end up nearby, while maintaining a distance from unrelated inputs.
",3 Models,[0],[0]
"The model consists of two parts: an utterance encoder, and an image encoder.",3 Models,[0],[0]
"The utterance encoder starts from MFCC speech features, while
the image encoder starts from features extracted with a VGG-16 pre-trained on ImageNet.",3 Models,[0],[0]
"Our loss function attempts to make the cosine distance between encodings of matching utterances and images greater than the distance between encodings of mismatching utterance/image pairs, by a margin:
(1)
∑
u,i
(∑
u′ max[0, α+d(u, i)−d(u′, i)]
+ ∑
i′ max[0, α+ d(u, i)− d(u, i′)]
)
where d(u, i) is the cosine distance between the encoded utterance u and encoded image i. Here (u, i) is the matching utterance-image pair, u′ ranges over utterances not describing i and i′ ranges over images not described by u.",3 Models,[0],[0]
"The image encoder enci is a simple linear projection, followed by normalization to unit L2 norm:
enci(i) = unit(Ai+ b) (2)
where unit(x) = x (xT x)0.5 and with (A, b) as learned parameters.",3 Models,[0],[0]
"The utterance encoder encu consists of a 1-dimensional convolutional layer of length s, size d and stride z, whose output feeds into a Recurrent Highway Network with k layers and L microsteps, whose output in turn goes through an attention-like lookback operator, and finally L2 normalization:
encu(u) = unit(Attn(RHNk,L(Convs,d,z(u))))",3 Models,[0],[0]
"(3)
The main function of the convolutional layer Convs,d,z is to subsample the input along the temporal dimension.",3 Models,[0],[0]
We use a 1-dimensional convolution with full border mode padding.,3 Models,[0],[0]
"The attention operator simply computes a weighted sum of the RHN activation at all timesteps:
Attn(x) = ∑
t
αtxt (4)
where the weights αt are determined by learned parameters U and W, and passed through the timewise softmax function:
αt = exp(U tanh(Wxt))∑ t′ exp(U tanh(Wxt′))
(5)
",3 Models,[0],[0]
"The main component of the utterance encoder is a recurrent network, specifically a Recurrent Highway Network (Zilly et al., 2016).",3 Models,[0],[0]
"The idea behind
RHN is to increase the depth of the transform between timesteps, or the recurrence depth.",3 Models,[0],[0]
Otherwise they are a type of gated recurrent networks.,3 Models,[0],[0]
"The transition from timestep t − 1 to t is then defined as:
rhn(xt, s (L) t−1) = s (L) t (6)
where xt stands for input at time t, and s (l) t denotes the state at time t at recurrence layer l, with L being the top layer of recurrence.",3 Models,[0],[0]
"Furthermore,
s (l) t = h (l) t t (l) t + s (l−1) t ( 1− t(l)t ) (7)
where is elementwise multiplication, and
h (l) t = tanh ( I[l = 1]WHxt +UHls (l−1) t ) (8)
t (l) t = σ",3 Models,[0],[0]
"( I[l = 1]WTxt +UTls (l−1) )
(9)
",3 Models,[0],[0]
Here I is the indicator function: input is only included in the computation for the first layer of recurrence l = 1.,3 Models,[0],[0]
"By applying the rhn function repeatedly, an RHN layer maps a sequence of inputs to a sequence of states:
(10) RHN(X, s0)
= rhn(xn, . . .",3 Models,[0],[0]
", rhn(x2, rhn(x1, s (L) 0 )))
",3 Models,[0],[0]
"Two or more RHN layers can be composed into a stack:
RHN2(RHN1(X, s1 (L) 0 ), s2 (L) 0 ), (11)
where sn (l) t stands for the state vector of layer n of the stack, at layer l of recurrence, at time t.",3 Models,[0],[0]
"In our version of the Stacked RHN architecture we use residualized layers:
RHNres(X, s0) = RHN(X, s0) +X (12)
",3 Models,[0],[0]
This formulation tends to ease optimization in multi-layer models (cf.,3 Models,[0],[0]
"He et al., 2015; Oord et al., 2016).
",3 Models,[0],[0]
"In addition to the speech model described above, we also define a comparable text model.",3 Models,[0],[0]
"As it takes a sequence of words as input, we replace the convolutional layer with a word embedding lookup table.",3 Models,[0],[0]
"We found the text model did not benefit from the use of the attention mechanism, and thus the sentence embedding is simply the L2-normalized activation vector of the topmost layer, at the last timestep.",3 Models,[0],[0]
Our main goal is to analyze the emerging representations from different components of the model and to examine the linguistic knowledge they encode.,4 Experiments,[0],[0]
"For this purpose, we employ a number of tasks that cover the spectrum from fully formbased to fully semantic.
",4 Experiments,[0],[0]
In Section 4.2 we assess the effectiveness of our architecture by evaluating it on the task of ranking images given an utterance.,4 Experiments,[0],[0]
Sections 4.3 to 4.6 present our analyses.,4 Experiments,[0],[0]
In Sections 4.3 and 4.4 we define auxiliary tasks to investigate to what extent the network encodes information about the surface form of an utterance from the speech input.,4 Experiments,[0],[0]
In Section 4.5 and 4.6 we focus on where semantic information is encoded in the model.,4 Experiments,[0],[0]
"In the analyses, we use the following features: Utterance embeddings: the weighted sum of the
unit activations on the last layer, as calculated by Equation (3).
",4 Experiments,[0],[0]
Average unit activations: hidden layer activations averaged over time and L2-normalized for each hidden layer.,4 Experiments,[0],[0]
Average input vectors: the MFCC vectors averaged over time.,4 Experiments,[0],[0]
We use this feature to examine how much information can be extracted from the input signal only.,4 Experiments,[0],[0]
For the experiments reported in the remainder of the paper we use two datasets of images with spoken captions.,4.1 Data,[0],[0]
"The Flickr8k Audio Caption Corpus was constructed by having crowdsource workers read aloud the captions in the original Flickr8K corpus (Hodosh et al., 2013).",4.1.1 Flickr8K,[0],[0]
For details of the data collection procedure refer to Harwath and Glass (2015).,4.1.1 Flickr8K,[0],[0]
"The datasets consist of 8,000 images, each image with five descriptions.",4.1.1 Flickr8K,[0],[0]
"One thousand images are held out for validation, and another one thousand for the final test set.",4.1.1 Flickr8K,[0],[0]
"We use the splits provided by (Karpathy and Fei-Fei, 2015).",4.1.1 Flickr8K,[0],[0]
"The image features come from the final fully connect layer of VGG-16 (Simonyan and Zisserman, 2014) pre-trained on Imagenet (Russakovsky et al., 2014).
",4.1.1 Flickr8K,[0],[0]
We generate the input signal as follows: we extract 12-dimensional mel-frequency cepstral coefficients (MFCC) plus log of the total energy.,4.1.1 Flickr8K,[0],[0]
"We
then compute and add first order and second order differences (deltas) for a total of 37 dimensions.",4.1.1 Flickr8K,[0],[0]
"We use 25 milisecond windows, sampled every 10 miliseconds.1",4.1.1 Flickr8K,[0],[0]
"We generated synthetic speech for the captions in the MS COCO dataset (Lin et al., 2014) via the Google Text-to-Speech API.2 The audio and the corresponding MFCC features are released as Chrupała et al. (2017)3.",4.1.2 Synthetically spoken COCO,[0],[0]
This TTS system we used produces high-quality realistic-sounding speech.,4.1.2 Synthetically spoken COCO,[0],[0]
"It is nevertheless much simpler than real human speech as it uses a single voice, and lacks tempo variation or ambient noise.",4.1.2 Synthetically spoken COCO,[0],[0]
"The data consists of over 300,000 images, each with five spoken captions.",4.1.2 Synthetically spoken COCO,[0],[0]
Five thousand images each are held out for validation and test.,4.1.2 Synthetically spoken COCO,[0],[0]
"We use the splits and image features provided by Vendrov et al. (2015).4 The image features also come from the VGG-16 network, but are averages of feature vectors for ten crops of each image.",4.1.2 Synthetically spoken COCO,[0],[0]
"For the MS COCO captions we extracted only plain MFCC and total energy features, and did not add deltas in order to keep the amount of computation manageable given the size of the dataset.",4.1.2 Synthetically spoken COCO,[0],[0]
"We evaluate our model on the task of ranking images given a spoken utterance, such that highly ranked images contain scenes described by the utterance.",4.2 Image retrieval,[0],[0]
The performance on this task on validation data is also used to choose the best variant of the model architecture and to tune the hyperparameters.,4.2 Image retrieval,[0],[0]
We compare the speech models to models trained on written sentences split into words.,4.2 Image retrieval,[0],[0]
"The best settings found for the four models were the following: Flickr8K Text RHN 300-dimensional word em-
beddings, 1 hidden layer with 1024 dimensions, 1 microstep, initial learning rate 0.001.
",4.2 Image retrieval,[0],[0]
"Flick8K Speech RHN convolutional layer with length 6, size 64, stride 2, 4 hidden layers with 1024 dimensions, 2 microsteps, atten-
1We noticed that for a number of utterances the audio signal was very long: on inspection it turned out that most of these involved failure to switch off the microphone on the part of the workers, and the audio contained ambient noise or unrelated speech.",4.2 Image retrieval,[0],[0]
"We thus trucated all audio for this dataset at 10,000 miliseconds.
2Available at https://github.com/pndurette/gTTS.",4.2 Image retrieval,[0],[0]
3Available at https://doi.org/10.5281/zenodo.400926.,4.2 Image retrieval,[0],[0]
"4See https://github.com/ivendrov/order-embedding.
tion MLP with 128 hidden units, initial learning rate 0.0002
COCO Text RHN 300-dimensional word embeddings, 1 hidden layer with 1024 dimensions, 1 microstep, initial learning rate 0.001 COCO Speech RHN convolutional layer with length 6, size 64, stride 3, 5 hidden layers with 512 dimensions, 2 microsteps, attention MLP with 512 hidden units, initial learning rate 0.0002
All models were optimized with Adam (Kingma and Ba, 2014) with early stopping: we kept the parameters for the epoch which showed the best recall@10 on validation data.
",4.2 Image retrieval,[0],[0]
Table 1 shows the results for the human speech from the Flickr8K dataset.,4.2 Image retrieval,[0],[0]
The Speech RHN model scores substantially higher than model of Harwath and Glass (2015) on the same data.,4.2 Image retrieval,[0],[0]
However the large gap between its perfomance and the scores of the text model suggests that Flickr8K is rather small for the speech task.,4.2 Image retrieval,[0],[0]
In Table 2 we present the results on the dataset of synthetic speech from MS COCO.,4.2 Image retrieval,[0],[0]
"Here the text model is still better, but the gap is much smaller than for Flickr8K. We attribute this to the much larger size of dataset, and to the less noisy and less variable synthetic speech.
",4.2 Image retrieval,[0],[0]
"While the MS COCO text model is overall better than the speech model, there are cases where it outperforms the text model.",4.2 Image retrieval,[0],[0]
"We listed the top hundred cases where the ratio of the ranks of the correct image according to the two models was the smallest, as well as another hundred cases where it was the largest.",4.2 Image retrieval,[0],[0]
"Manual inspection did not turn
up any obvious patterns for the cases of text being better than speech.",4.2 Image retrieval,[0],[0]
"For the cases where speech outperformed text, two patterns stood out: (i) sentences with spelling mistakes, (ii) unusually long sentences.",4.2 Image retrieval,[0],[0]
"For example for the sentence a yellow
and white birtd is in flight the text model misses the misspelled word birtd and returns an irrelevant image, while the speech model seems robust to some degree of variation in pronunciation and returns the target image at rank 1 (see Figure 1).",4.2 Image retrieval,[0],[0]
"In an attempt to quantify this effect we counted the number of unique words with training set frequencies below 5 in the top 100 utterances with lowest and highest rank ratio: for the utterances where text was better there were 16 such words; for utterances where speech was better there were 28, among them misspellings such as streeet, scears (for skiers), contryside, scull, birtd, devise.
",4.2 Image retrieval,[0],[0]
The distribution of utterance lengths in Figure 2 confirms pattern (ii): the set of 100 sentences where speech beats text by a large margin are longer on average and there are extremely long outliers among them.,4.2 Image retrieval,[0],[0]
"One of them is the 36-word-
long utterance depicted in Figure 3, with ranks 470 and 2 for text and speech respectively.",4.2 Image retrieval,[0],[0]
"We suspect that the speech model’s attention mechanism enables it to cherry pick key fragments of such monster utterances, while the text model lacking this mechanism may struggle.",4.2 Image retrieval,[0],[0]
"Figure 3 shows the plot of the attention weights for this utterance from the
speech model.",4.2 Image retrieval,[0],[0]
"Our first auxiliary task is to predict the length of the utterance, using the features explained at the beginning of Section 4.",4.3 Predicting utterance length,[0],[0]
"Since the length of an utterance directly corresponds to how long it takes to articulate, we also use the number of time steps5 as a feature and expect it to provide the upper bound for our task, especially for synthetic speech.",4.3 Predicting utterance length,[0],[0]
We use a Ridge Regression model for predicting utterance length using each set of features.,4.3 Predicting utterance length,[0],[0]
"The model is trained on 80% of the sentences in the validation set, and tested on the remaining 20%.",4.3 Predicting utterance length,[0],[0]
"For all features regularization penalty α = 1.0 gave the best results.
",4.3 Predicting utterance length,[0],[0]
Figure 4 shows the results for this task on human speech from Flickr8K and synthetic speech from COCO.,4.3 Predicting utterance length,[0],[0]
"With the exception of the average input vectors for Flickr8K, all features can explain a high proportion of variance in the predicted utterance length.",4.3 Predicting utterance length,[0],[0]
"The pattern observed for the two datasets is slightly different: due to the systematic conversion of words to synthetic speech in COCO, using the number of time steps for this dataset yields the highest R2.",4.3 Predicting utterance length,[0],[0]
"However, this feature is not as informative for predicting the utterance length in Flickr8K due to noise and variation in human speech, and is in fact outperformed by some of the features extracted from the model.",4.3 Predicting utterance length,[0],[0]
"Also, the input vectors from COCO are much more informative than Flickr8K due to larger quantity and simpler structure of the speech signal.",4.3 Predicting utterance length,[0],[0]
"However, in both datasets the best (non-ceiling) performance is obtained by using average unit activations from the hidden layers (layer 2 for COCO, and layers 3 and 4 for Flickr8K).",4.3 Predicting utterance length,[0],[0]
"These features outperform utterance embeddings, which are optimized according to the visual grounding objective of the model and most probably learn to ignore the superficial characteristics of the utterance that do not contribute to matching the corresponding image.
",4.3 Predicting utterance length,[0],[0]
"Note that the performance on COCO plateaus after the second layer, which might suggest that form-based knowledge is learned by lower layers.",4.3 Predicting utterance length,[0],[0]
"Since Flickr8K is much smaller in size, the stabilising happens later in layer 3.
",4.3 Predicting utterance length,[0],[0]
5This is approximately duration in milliseconds 10×stride .,4.3 Predicting utterance length,[0],[0]
Results from the previous experiment suggest that our model acquires information about higher level building blocks (words) in the continuous speech signal.,4.4 Predicting word presence,[0],[0]
Here we explore whether it can detect the presence or absence of individual words in an utterance.,4.4 Predicting word presence,[0],[0]
"We formulate detecting a word in an utterance as a binary classification task, for which we use a multi-layer perceptron with a single hidden layer of size 1024, optimized by Adam.",4.4 Predicting word presence,[0],[0]
The input to the model is a concatenation of the feature vector representing an utterance and the one representing a target word.,4.4 Predicting word presence,[0],[0]
"We again use utterance embeddings, average unit activations on each layer, and average input vectors as features, and represent each target word as a vector of MFCC features extracted from the audio signal synthetically produced for that word.
",4.4 Predicting word presence,[0],[0]
"For each utterance in the validation set, we randomly pick one positive and one negative target (i.e., one word that does and one that does not appear in the utterance) that is not a stop word.",4.4 Predicting word presence,[0],[0]
"To balance the probability of a word being positive or negative, we use each positive target as a negative target for another utterance in the validation
set.",4.4 Predicting word presence,[0],[0]
"The MLP model is trained on the positive and negative examples corresponding to 80% of the utterances in the validation set of each dataset, and evaluated on the remaining 20%.
",4.4 Predicting word presence,[0],[0]
Figure 5 shows the mean accuracy of the MLP on Flickr8K and COCO.,4.4 Predicting word presence,[0],[0]
"All results using features extracted from the model are above chance (0.5), with the average unit activations of the hidden layers yielding the best results (0.65 for Flickr8K on layer 3, and 0.79 for COCO on layer 4).",4.4 Predicting word presence,[0],[0]
These numbers show that the speech model infers reliable information about word-level blocks from the low-level audio features it receives as input.,4.4 Predicting word presence,[0],[0]
"The observed trend is similar to the previous task: average unit activations on the higher-level hidden layers are more informative for this task than the utterance embeddings, but the performance plateaus before the topmost layer.",4.4 Predicting word presence,[0],[0]
Next we explore to what extent the model’s representations correspond to those of humans.,4.5 Sentence similarity,[0],[0]
"We employ the Sentences Involving Compositional Knowledge (SICK) dataset (Marelli et al., 2014).",4.5 Sentence similarity,[0],[0]
"SICK consists of image descriptions taken from
Flickr8K and video captions from the SemEval 2012 STS MSRVideo Description data set (STS) (Agirre et al., 2012).",4.5 Sentence similarity,[0],[0]
"Captions were paired at random, as well as modified to obtain semantically similar and contrasting counterparts, and the resulting pairs were rated for semantic similarity.
",4.5 Sentence similarity,[0],[0]
"For all sentence pairs in SICK, we generate synthetic spoken sentences and feed them to the COCO Speech RHN, and calculate the cosine similarity between the averaged MFCC input vectors, the averaged hidden layer activation vectors, and the sentence embeddings.",4.5 Sentence similarity,[0],[0]
Z-score transformation was applied before calculating the cosine similarities.,4.5 Sentence similarity,[0],[0]
"We then correlate these cosine similarities with
• semantic relatedness according to human ratings • cosine similarities according to z-score transformed embeddings from COCO Text RHN • edit similarities, a measure of how similar the sentences are in form, specifically, 1−normalized Levenshtein distance over character sequences
Figure 6 shows a boxplot over 10,000 bootstrap samples for all correlations.",4.5 Sentence similarity,[0],[0]
"We observe that (i) correlation with edit similarity initially increases, then decreases; (ii) correlation with human relatedness scores and text model embeddings increases until layer 4, but decreases for hidden layer 5.",4.5 Sentence similarity,[0],[0]
The initially increasing and then decreasing correlation with edit similarity is consistent with the findings that information about form is encoded by lower layers.,4.5 Sentence similarity,[0],[0]
"The overall growing correlation with both human semantic similarity ratings and
the COCO Text RHN indicate that higher layers learn to represent semantic knowledge.",4.5 Sentence similarity,[0],[0]
We were somewhat surprised by the pattern for the correlation with human ratings and the Text model similarities which drops for layer 5.,4.5 Sentence similarity,[0],[0]
We suspect it may be caused by the model at this point in the layer hierarchy being strongly tuned to the specifics of the COCO dataset.,4.5 Sentence similarity,[0],[0]
"To test this, we checked the correlations with COCO Text embeddings on validation sentences from the COCO dataset instead of SICK.",4.5 Sentence similarity,[0],[0]
"These increased monotonically, in support of our conjecture.",4.5 Sentence similarity,[0],[0]
"Next we simulate the task of distinguishing between pairs of homonyms, i.e. words with the same acoustic form but different meaning.",4.6 Homonym disambiguation,[0],[0]
We group the words in the union of the training and validation data of the COCO dataset by their phonetic transcription.,4.6 Homonym disambiguation,[0],[0]
"We then pick pairs of words which have the same pronunciation but different spelling, for example suite/sweet.",4.6 Homonym disambiguation,[0],[0]
"We impose the following conditions: (a) both forms appear more than 20 times, (b) the two forms have different meaning (i.e. they are not simply variant spellings like theater/theatre), (c) neither form is a function word, and (d) the more frequent form constitutes less than 95% of the occurrences.",4.6 Homonym disambiguation,[0],[0]
"This
gives us 34 word pairs.",4.6 Homonym disambiguation,[0],[0]
"For each pair we generate a binary classification task by taking all the utterances where either form appears, using average input vectors, utterance embeddings, and average unit activations as features.",4.6 Homonym disambiguation,[0],[0]
"Instances for all feature sets are normalized to unit L2 norm.
",4.6 Homonym disambiguation,[0],[0]
For each task and feature set we run stratified 10-fold cross validation using Logistic Regression to predict which of the two words the utterance contains.,4.6 Homonym disambiguation,[0],[0]
"Figure 7 shows, for each pair, the relative error reduction of each feature set with respect to the majority baseline.",4.6 Homonym disambiguation,[0],[0]
"There is substantial variation across word pairs, but overall the task becomes easier as the features come from higher layers in the network.",4.6 Homonym disambiguation,[0],[0]
"Some forms can be disambiguated with very high accuracy (e.g. sale/sail, cole/coal, pairs/pears), while some others cannot be distinguished at all (peaking/peeking, great/grate, mantle/mantel).",4.6 Homonym disambiguation,[0],[0]
"We examined the sentences containing the failing forms, and found out that almost all occurrences of peaking and mantle were misspellings of peeking and mantel, which explains the impossibility of disambiguating these cases.",4.6 Homonym disambiguation,[0],[0]
We present a multi-layer recurrent highway network model of language acquisition from visually grounded speech signal.,5 Conclusion,[0],[0]
"Through detailed analysis we uncover how information in the input signal is transformed as it flows through the network: formal aspects of language such as word identities that not directly present in the input are discovered and encoded low in the layer hierarchy, while semantic information is most strongly expressed in the topmost layers.
",5 Conclusion,[0],[0]
Going forward we would like to compare the representations learned by our model to the brain activity of people listening to speech in order to determine to what extent the patterns we found correspond to localized processing in the human cortex.,5 Conclusion,[0],[0]
This will hopefully lead to a better understanding of language learning and processing by both artificial and neural networks.,5 Conclusion,[0],[0]
We would like to thank David Harwath for making the Flickr8k Audio Caption Corpus publicly available.,Acknowledgements,[0],[0]
We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space.,abstractText,[0],[0]
"We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaningbased linguistic knowledge from the input signal.",abstractText,[0],[0]
"We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of formrelated aspects of the language input tends to initially increase and then plateau or decrease.",abstractText,[0],[0]
Representations of language in a model of visually grounded speech signal,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications.,1 Introduction,[0],[0]
"Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete.",1 Introduction,[0],[0]
"This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015).
",1 Introduction,[0],[0]
"In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations.",1 Introduction,[0],[0]
"This common representation in the same vector space can serve as a kind of “universal schema” which admits joint inferences among
∗This research was conducted during the author’s internship at Microsoft Research.
KBs and text.",1 Introduction,[0],[0]
The textual relations represent the relationships between entities expressed in individual sentences (see Figure 1 for an example).,1 Introduction,[0],[0]
Riedel et al. (2013) represented each textual mention of an entity pair by the lexicalized dependency path between the two entities (see Figure 2).,1 Introduction,[0],[0]
Each such path is treated as a separate relation in a combined knowledge graph including both KB and textual relations.,1 Introduction,[0],[0]
"Following prior work in latent feature models for knowledge base completion, every textual relation receives its own continuous representation, learned from the pattern of its co-occurrences in the knowledge graph.
",1 Introduction,[0],[0]
"However, largely synonymous textual relations often share common sub-structure, and are composed of similar words and dependency arcs.",1 Introduction,[0],[0]
"For example, Table 1 shows a collection of dependency paths co-occurring with the person/organizations founded relation.
",1 Introduction,[0],[0]
"In this paper we model this sub-structure and share parameters among related dependency paths, using a unified loss function learning entity and relation representations to maximize performance on the knowledge base link prediction task.
",1 Introduction,[0],[0]
"We evaluate our approach on the FB15k-237 dataset, a knowledge base derived from the Free-
1499
base subset FB15k (Bordes et al., 2013) and filtered to remove highly redundant relations (Toutanova and Chen, 2015).",1 Introduction,[0],[0]
"The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb121 with Freebase entity mention annotations (Gabrilovich et al., 2013).
",1 Introduction,[0],[0]
"We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions.",1 Introduction,[0],[0]
There has been a growing body of work on learning to predict relations between entities without requiring sentence-level annotations of textual mentions at training time.,2 Related Work,[0],[0]
"We group such related work into three groups based on whether KB, text, or both sources of information are used.",2 Related Work,[0],[0]
"Additionally, we discuss related work in the area of supervised relation extraction using continuous representations of text, even though we do not use supervision at the level of textual mentions.",2 Related Work,[0],[0]
"Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014).",Knowledge base completion,[0],[0]
"These models predict new facts in a given knowledge base, based on information from existing entities and relations.",Knowledge base completion,[0],[0]
"From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset.",Knowledge base completion,[0],[0]
"Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset.",Knowledge base completion,[0],[0]
"We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations.
",Knowledge base completion,[0],[0]
"1http://lemurproject.org/clueweb12/ FACC1/
Relation extraction using distant supervision
A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base.",Knowledge base completion,[0],[0]
"Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context.",Knowledge base completion,[0],[0]
"Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia.",Knowledge base completion,[0],[0]
"Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases.
",Knowledge base completion,[0],[0]
"Combining knowledge base and text information
A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012).",Knowledge base completion,[0],[0]
"To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations.",Knowledge base completion,[0],[0]
Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure.,Knowledge base completion,[0],[0]
"Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015).",Knowledge base completion,[0],[0]
"Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations.",Knowledge base completion,[0],[0]
Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations.,Knowledge base completion,[0],[0]
"The two representations were trained independently of each other and using different loss functions, and were only combined at inference time.",Knowledge base completion,[0],[0]
"Additionally, the employed representations of text were non-compositional.
",Knowledge base completion,[0],[0]
"In this work we train continuous representations of knowledge base and textual relations jointly, which allows for deeper interactions between the
sources of information.",Knowledge base completion,[0],[0]
"We directly build on the universal schema approach of Riedel et al. (2013) as well as the universal schema extension of the DISTMULT model mentioned previously, to improve the representations of textual relations by capturing their compositional structure.",Knowledge base completion,[0],[0]
"Additionally, we evaluate the approach on a dataset that contains rich prior information from the training knowledge base, as well as a wealth of textual information from a large document collection.
",Knowledge base completion,[0],[0]
"Continuous representations for supervised relation extraction
In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence context.",Knowledge base completion,[0],[0]
"Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015).",Knowledge base completion,[0],[0]
"Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple.",Knowledge base completion,[0],[0]
"However, even such a simple approach has been shown to be very competitive (Kim, 2014).",Knowledge base completion,[0],[0]
"We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015).",3 Models for knowledge base completion,[0],[0]
"We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, object), where the subject and object are entities and the predicate is the type of relation.",3 Models for knowledge base completion,[0],[0]
"For example, the KB fragment shown in Figure 1 is shown as a knowledge graph, where the entities are the nodes, and the relations are shown as directed labeled edges: we see three entities participating in three relation instances indicated by the edges.",3 Models for knowledge base completion,[0],[0]
"For brevity, we will denote triples by (es, r, eo), where es and eo denote the subject and object entities, respectively.
",3 Models for knowledge base completion,[0],[0]
"The task is, given a training KB consisting of entities with some relations between them, to predict new relations (links) that do not appear in the training KB.",3 Models for knowledge base completion,[0],[0]
"More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object
1
or subject of a given relation.",3 Models for knowledge base completion,[0],[0]
"This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013).",3 Models for knowledge base completion,[0],[0]
"The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, e′o) will be present.",3 Models for knowledge base completion,[0],[0]
"Such an assumption is particularly justified for nearly functional relations.
",3 Models for knowledge base completion,[0],[0]
"To incorporate textual information, we follow prior work (Lao et al., 2012; Riedel et al., 2013) and represent both textual and knowledge base relations in a single graph of “universal” relations.",3 Models for knowledge base completion,[0],[0]
"The textual relations are represented as full lexicalized dependency paths, as illustrated in Figure 2.",3 Models for knowledge base completion,[0],[0]
"An instance of the textual relation SUBJECT nsubj←−−− president prep−−→ of obj−→OBJECT connecting the entities BARACK OBAMA and UNITED STATES, is added to the knowledge graph based on this sentential occurrence.
",3 Models for knowledge base completion,[0],[0]
"To present the models for knowledge base completion based on such combined knowledge graphs, we first introduce some notation.",3 Models for knowledge base completion,[0],[0]
Let E denote the set of entities in the knowledge graph and let R denote the set of relation types.,3 Models for knowledge base completion,[0],[0]
"We denote each possible triple as T = (es, r, eo) where es, eo ∈ E , r ∈ R, and model its presence with a binary random variable yT ∈ {0, 1} which indicates whether the triple exists.",3 Models for knowledge base completion,[0],[0]
"The models we build score possible triples (es, r, eo) using continuous representations (latent features) of the three elements of the triple.",3 Models for knowledge base completion,[0],[0]
"The models use scoring function f(es, r, eo) to represent the model’s confidence in the existence of the triple.",3 Models for knowledge base completion,[0],[0]
"We present the models and then the loss function used to train
1
their parameters.",3 Models for knowledge base completion,[0],[0]
We begin with presenting the three models from prior work that this research builds upon.,3.1 Basic Models,[0],[0]
"They all learn latent continuous representations of relations and entities or entity pairs, and score possible triples based on the learned continuous representations.",3.1 Basic Models,[0],[0]
"Each of the models can be defined on a knowledge graph containing entities and KB relations only, or on a knowledge graph additionally containing textual relations.",3.1 Basic Models,[0],[0]
"We use models F and E from (Riedel et al., 2013) where they were used for a combined KB+text graph, and model DISTMULT from (Yang et al., 2015), which was originally used for a knowledge graph containing only KB relations.
",3.1 Basic Models,[0],[0]
"As shown in Figure 3, model F learns a Kdimensional latent feature vector for each candidate entity pair (es, eo), as well as a samedimensional vector for each relation r, and the scoring function is simply defined as their inner product: f(es, r, eo) = v(r)ᵀv(es, eo).",3.1 Basic Models,[0],[0]
"Therefore, different pairs sharing the same entity would not share parameters in this model.
",3.1 Basic Models,[0],[0]
"Model E does not have parameters for entity pairs, and instead has parameters for individual entities.",3.1 Basic Models,[0],[0]
"It aims to capture the compatibility be-
tween entities and the subject and object positions of relations.",3.1 Basic Models,[0],[0]
"For each relation type r, the model learns two latent feature vectors v(rs) and v(ro) of dimension K. For each entity (node) ei, the model also learns a latent feature vector of the same dimensionality.",3.1 Basic Models,[0],[0]
"The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(rs)ᵀv(es) + v(ro)ᵀv(eo).",3.1 Basic Models,[0],[0]
"It can be seen that when a subject entity is fixed in a query (es, r, ?), the ranking of candidate object entity fillers according to f does not depend on the subject entity but only on the relation type r.
The third model DISTMULT, is a special form of a bilinear model like RESCAL (Nickel et al., 2011), where the non-diagonal entries in the relation matrices are assumed to be zero.",3.1 Basic Models,[0],[0]
This model was proposed in Yang et al. (2015) and was shown to outperform prior work on the FB15k dataset.,3.1 Basic Models,[0],[0]
"In this model, each entity ei and each relation r is assigned a latent feature vector of dimensionK. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo)",3.1 Basic Models,[0],[0]
"= v(r)ᵀ (v(es) ◦ v(eo)), where ◦ denotes the element-wise vector product.",3.1 Basic Models,[0],[0]
"In this model, entity pairs which share an entity also share parameters, and the ranking of candidate objects for queries (es, r, ?) depends on the subject entity.
",3.1 Basic Models,[0],[0]
"Denote Ne = |E|, Nr = |R|, and K = dimension of latent feature vectors, then model E has KNe +",3.1 Basic Models,[0],[0]
2KNr parameters and model DISTMULT has KNe + KNr parameters.,3.1 Basic Models,[0],[0]
"Model F has KN2e + KNr parameters, although most entity pairs will not co-occur in the knowledge base or text.
",3.1 Basic Models,[0],[0]
"In the basic models, knowledge base and textual relations are treated uniformly, and each textual relation receives its own latent representation of dimensionality K. When textual relations are added to the training knowledge graph, the total number of relations |R| grows substantially (it increases from 237 to more than 2.7 million for the dataset in this study), resulting in a substantial increase in the total number of independent parameters.
",3.1 Basic Models,[0],[0]
"Note that in all of these models queries about the arguments of knowledge base relations (es, r, ?) are answered by scoring functions looking only at the entity and KB relation representations, without using representations of textual mentions.",3.1 Basic Models,[0],[0]
The textual mention information and representations are only used at training time to improve the learned representations of KB relations and entities.,3.1 Basic Models,[0],[0]
"In the standard latent feature models discussed above, each textual relation is treated as an atomic unit receiving its own set of latent features.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"However, many textual relations differ only slightly in the words or dependency arcs used to express the relation.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"For example, Table 1 shows several textual patterns that co-occurr with the relation person/organizations founded in the training KB.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"While some dependency paths occur frequently, many very closely related ones have been observed only once.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The statistical strength of the model could be improved if similar dependency paths have a shared parameterization.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"We build on work using similar intuitions for other tasks and learn compositional representations of textual relations based on their internal structure, so that the derived representations are accurate for the task of predicting knowledge base relations.
",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
We use a convolutional neural network applied to the lexicalized dependency paths treated as a sequence of words and dependency arcs with direction.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
Figure 4 depicts the neural network architecture.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"In the first layer, each word or directed labeled arc is mapped to a continuous representation using an embedding matrix V. In the hidden layer, every window of three elements is mapped to a hidden vector using position-specific maps W, a bias vector b, and a tanh activation function.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"A max-pooling operation over the sequence is applied to derive the final continuous representation for the dependency path.
",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The CONV representation of textual relations can be used to augment any of the three basic models.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
The difference between a basic model and its CONV-augmented variant is in the parameterization of textual mentions.,3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
"The basic models learn distinct latent feature vectors of dimensionality K for all textual relation types, whereas the CONV models derive the K-dimensional latent feature vectors for textual relation types as the activation at the top layer of the convolutional network in Figure 4, given the corresponding lexicalized dependency path as input.",3.2 CONV: Compositional Representations of Textual Relations,[0],[0]
All basic and CONV-augmented models use the same training loss function.,3.3 Training loss function,[0],[0]
Our loss function is motivated by the link prediction task and the performance measures used.,3.3 Training loss function,[0],[0]
"As previously men-
tioned, the task is to predict the subject or object entity for given held-out triples (es, r, eo), i.e., to rank all entities with respect to their likelihood of filling the respective position in the triple2.",3.3 Training loss function,[0],[0]
"We would thus like the model to score correct triples (es, r, eo) higher than incorrect triples (e′, r, eo) and (es, r, e′) which differ from the correct triple by one entity.",3.3 Training loss function,[0],[0]
"Several approaches (Nickel et al., 2015) use a margin-based loss function.",3.3 Training loss function,[0],[0]
We use an approximation to the negative loglikelihood of the correct entity filler instead3.,3.3 Training loss function,[0],[0]
"We define the conditional probabilities p(eo|es, r) and p(es|r, eo) for object and subject entities given the relation and the other argument as follows:
p(eo|es, r; Θ) = e f(es,r,eo;Θ)∑
e′∈Neg(es,r,?)",3.3 Training loss function,[0],[0]
"e f(es,r,e′;Θ)
",3.3 Training loss function,[0],[0]
"Conditional probabilities for subject entities p(es|eo, r; Θ) are defined analogously.",3.3 Training loss function,[0],[0]
Here Θ denotes all the parameters of latent features.,3.3 Training loss function,[0],[0]
"The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the training knowledge graph.",3.3 Training loss function,[0],[0]
"Since the number of such entities is impractically large, we sample negative triples from the full set.",3.3 Training loss function,[0],[0]
"We also limit the candidate entities to ones that have types consistent with the position in the relation triple (Chang et al., 2014; Yang et al., 2015), where the types are approximated following Toutanova and Chen (2015).",3.3 Training loss function,[0],[0]
"Additionally, since the task of predicting textual relations is auxiliary to the main task, we use a weighting factor τ for the loss on predicting the arguments of textual relations (Toutanova and Chen, 2015).
",3.3 Training loss function,[0],[0]
"Denote T as a set of triples, we define the loss L(T ; Θ) as:
L(T ; Θ) =",3.3 Training loss function,[0],[0]
"− ∑
(es,r,eo)∈T log p(eo|es, r; Θ)
− ∑
(es,r,eo)∈T log p(es|eo, r; Θ)
Let TKB and Ttext represent the set of knowledge base triples and textual relation triples respectively.",3.3 Training loss function,[0],[0]
"The final training loss function is de-
2Our experimental comparison focuses on predicting object entities only, but we consider both argument types in the training loss function.
3Note that both margin-based and likelihood-based loss functions are susceptible to noise from potential selection of false negative examples.",3.3 Training loss function,[0],[0]
"An empirical comparison of training loss functions would be interesting.
fined as:
L(TKB; Θ) + τL(Ttext; Θ) + λ‖Θ‖2,
where λ is the regularization parameter, and τ is the weighing factor of the textual relations.
",3.3 Training loss function,[0],[0]
The parameters of all models are trained using a batch training algorithm.,3.3 Training loss function,[0],[0]
"The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation.",3.3 Training loss function,[0],[0]
"We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015).",Dataset and Evaluation Protocol,[0],[0]
"The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015).",Dataset and Evaluation Protocol,[0],[0]
"Textual relations for
4Check the first author’s website for a release of the dataset.
1504
FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set.",Dataset and Evaluation Protocol,[0],[0]
"After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph.",Dataset and Evaluation Protocol,[0],[0]
"The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance.
",Dataset and Evaluation Protocol,[0],[0]
"The number of relations and triples in the training, validation and test portions of the data are given in Table 2.",Dataset and Evaluation Protocol,[0],[0]
The two rows list statistics for the KB and text portions of the data separately.,Dataset and Evaluation Protocol,[0],[0]
The 2.7 million textual relations occur in 3.9 million text triples.,Dataset and Evaluation Protocol,[0],[0]
"Almost all entities occur in textual relations (13,937 out of 14,541).",Dataset and Evaluation Protocol,[0],[0]
The numbers of triples for textual relations are shown as zero for the validation and test sets because we don’t evaluate on prediction of textual relations (all text triples are used in training).,Dataset and Evaluation Protocol,[0],[0]
"The percentage of KB triples that have textual relations for their pair of entities is 40.5% for the training, 26.6% for the validation, and 28.1% for the test set.",Dataset and Evaluation Protocol,[0],[0]
"While 26.6% of the validation set triples have textual mentions, the percentage with textual relations that have been seen in the training set is 18.4%.",Dataset and Evaluation Protocol,[0],[0]
"Having a mention increases the chance that a random entity pair has a relation from 0.1% to 5.0% — a fifty-fold increase.
",Dataset and Evaluation Protocol,[0],[0]
"Given a set of triples in a set disjoint from a training knowledge graph, we test models on predicting the object of each triple, given the subject and relation type.",Dataset and Evaluation Protocol,[0],[0]
We rank all entities in the training knowledge base in order of their likelihood of filling the argument position.,Dataset and Evaluation Protocol,[0],[0]
"We report the mean reciprocal rank (MRR) of the correct entity, as well as HITS@10 — the percentage of test triples for which the correct entity is ranked in the top 10.",Dataset and Evaluation Protocol,[0],[0]
"We use filtered measures following the protocol proposed in Bordes et al. (2013) — that is, when we rank entities for a given position, we remove all other entities that are known to be part of an existing triple in the training, validation, or test set.",Dataset and Evaluation Protocol,[0],[0]
"This avoids penalizing the model for ranking other correct fillers higher than the tested entity.
",Dataset and Evaluation Protocol,[0],[0]
"5The full set of 37 million textual patterns connecting the entity pairs of interest was pruned based on the count of patterns and their tri-grams, and their precision in indicating that entity pairs have KB relations.",Dataset and Evaluation Protocol,[0],[0]
"We used a value of λ = 1 for the weight of the L2 penalty for the main results in Table 3, and present some results on the impact of λ at the end of this section.",Implementation details,[0],[0]
We used batch optimization after initial experiments with AdaGrad showed inferior performance.,Implementation details,[0],[0]
"L-BFGS (Liu and Nocedal, 1989) and RProp (Riedmiller and Braun, 1993) were found to converge to similar function values, with RProp converging significantly faster.",Implementation details,[0],[0]
We thus used RProp for optimization.,Implementation details,[0],[0]
"We initialized the KB+text models from the KB-only models and also from random initial values (sampled from a Gaussian distribution), and stopped optimization when the overall MRR on the validation set decreased.",Implementation details,[0],[0]
"For each model type, we chose the better of random and KB-only initialization.",Implementation details,[0],[0]
"The word embeddings in the CONV models were initialized using the 50-dimensional vectors from Turian et al. (2010) in the main experiments, with a slight positive impact.",Implementation details,[0],[0]
"The effect of initialization is discussed at the end of the section.
",Implementation details,[0],[0]
The number of negative examples for each triple was set to 200.,Implementation details,[0],[0]
Performance improved substantially when the number of negative examples was increased and reached a plateau around 200.,Implementation details,[0],[0]
"We chose the optimal number of latent feature dimensions via a grid search to optimize MRR on the validation set, testing the values 5, 10, 15, 35, 50, 100, 200 and 500.",Implementation details,[0],[0]
"We also performed a grid search over the values of the parameter τ , testing values in the set {0.01, 0.1, 0.25, 0.5, 1}.",Implementation details,[0],[0]
"The best dimension for latent feature vectors was 10 for most KBonly models (not including model F), and 5 for the two model configurations including F. We used K = 10 for all KB+text models, as higher dimension was also not helpful for them.",Implementation details,[0],[0]
"In Table 3 we show the performance of different models and their combinations6, both when using textual mentions (KB+text), and when using only knowledge base relations (KB only).",Experimental results,[0],[0]
"In the KB+text setting, we evaluate the contribution of the CONV representations of the textual relations.",Experimental results,[0],[0]
"The upper portion of the Table shows the performance of models that have been trained using knowledge graphs including only knowledge
6Different models are combined by simply defining a combined scoring function which adds the scores from individual models.",Experimental results,[0],[0]
"Combined models are trained jointly.
base relations, and are not using any information from textual mentions.",Experimental results,[0],[0]
The lower portion of the Table shows the performance when textual relations are added to the training knowledge graph and the corresponding training loss function.,Experimental results,[0],[0]
"Note that all models predict based on the learned knowledge base relation and entity representations, and the textual relations are only used at training time when they can impact these representations.
",Experimental results,[0],[0]
"The performance of all models is shown as an overall MRR (scaled by 100) and HITS@10, as well as performance on the subset of triples that have textual mentions (column With mentions), and ones that do not (column Without mentions).",Experimental results,[0],[0]
"Around 28% of the test triples have mentions and contribute toward the measures in the With mentions column, and the other 72% of the test triples contribute to the Without mentions column.
",Experimental results,[0],[0]
"For the KB-only models, we see the performance of each individual model F, E, and DISTMULT.",Experimental results,[0],[0]
"Model F was the best performing single model from (Riedel et al., 2013), but it does not perform well when textual mentions are not used.",Experimental results,[0],[0]
"In our implementation of model F, we created entity pair parameters only for entity pairs that cooccur in the text data (Riedel et al. (2013) also trained pairwise vectors for co-occuring entities
only, but all of the training and test tuples in their study were co-occurring)7.",Experimental results,[0],[0]
"Without textual information, model F is performing essentially randomly, because entity pairs in the test sets do not occur in training set relations (by construction of the dataset).",Experimental results,[0],[0]
"Model E is able to do surprisingly well, given that it is making predictions for each object position of a relation without considering the given subject of the relation.",Experimental results,[0],[0]
DISTMULT is the best performing single model.,Experimental results,[0],[0]
"Unlike model F, it is able to share parameters among entity pairs with common subject or object entities, and, unlike model E, it captures some dependencies between the subject and object entities of a relation.",Experimental results,[0],[0]
"The combination of models E+DISTMULT improves performance, but combining model F with the other two is not helpful.
",Experimental results,[0],[0]
The lower portion of Table 3 shows results when textual relations are added to the training knowledge graph.,Experimental results,[0],[0]
The basic models treat the textual relations as atomic and learn a separate latent feature vector for each textual relation.,Experimental results,[0],[0]
"The CONV- models use the compositional representations of tex-
7Learning entity pair parameters for all entity pairs would result in 2.2 billion parameters for vectors with dimensionality 10 for our dataset.",Experimental results,[0],[0]
"This was infeasible and was also not found useful based on experiments with vectors of lower dimensionality.
",Experimental results,[0],[0]
tual relations learned using the convolutional neural network architecture shown in Figure 4.,Experimental results,[0],[0]
We show the performance of each individual model and its corresponding variant with a CONV parameterization.,Experimental results,[0],[0]
"For each model, we also show the optimal value of τ , the weight of the textual relations loss.",Experimental results,[0],[0]
"Model F is able to benefit from textual relations and its performance increases by 2.5 points in MRR, with the gain in performance being particularly large on test triples with textual mentions.",Experimental results,[0],[0]
Model F is essentially limiting its space of considered argument fillers to ones that have cooccurred with the given subject entity.,Experimental results,[0],[0]
"This gives it an advantage on test triples with textual mentions, but model F still does relatively very poorly overall when taking into account the much more numerous test triples without textual mentions.",Experimental results,[0],[0]
"The CONV parameterization performs slightly worse in MRR, but slightly better in HITS@10, compared to the atomic parameterization.",Experimental results,[0],[0]
"For model E and its CONV variant, we see that text does not help as its performance using text is the same as that when not using text and the optimal weight of the text is zero.",Experimental results,[0],[0]
"Model DISTMULT benefits from text, and its convolutional text variant CONVDISTMULT outperforms the basic model, with the gain being larger on test triples with mentions.
",Experimental results,[0],[0]
"The best model overall, as in the KB-only case, is E+DISTMULT.",Experimental results,[0],[0]
"The basic model benefits from text slightly and the model with compositional representations of textual patterns CONVE+CONV-DISTMULT, improves the performance further, by 2.4 MRR overall, and by 5 MRR on triples with textual mentions.",Experimental results,[0],[0]
It is interesting that the text and the compositional representations helped most for this combined model.,Experimental results,[0],[0]
"One hypothesis is that model E, which provides a prior over relation arguments, is needed in combination with DISTMULT to prevent the prediction of unlikely arguments based on noisy inference from textual patterns and their individual words and dependency links.",Experimental results,[0],[0]
"To gain insight into the sensitivity of the model to hyper-parameters and initialization, we report on experiments starting with the best model CONVE + CONV-DISTMULT from Table 3 and varying one parameter at a time.",Hyperparameter Sensitivity,[0],[0]
"This model has weight of the textual relations loss τ = 0.25, weight of the L2 penalty λ = 1, convolution window size of
three, and is initialized randomly for the entity and KB relation vectors, and from pre-trained embeddings for word vectors (Turian et al., 2010).",Hyperparameter Sensitivity,[0],[0]
"The overall MRR of the model is 40.4 on the validation set (test results are shown in the Table).
",Hyperparameter Sensitivity,[0],[0]
"When the weight of τ is changed to 1 (i.e., equal contribution of textual and KB relations), the overall MRR goes down to 39.6 from 40.4, indicating the usefulness of weighting the two kinds of relations non-uniformly.",Hyperparameter Sensitivity,[0],[0]
"When λ is reduced to 0.04, MRR is 40.0 and when λ is increased to 25, MRR goes down to 38.9.",Hyperparameter Sensitivity,[0],[0]
This indicates the L2 penalty hyper-parameter has a large impact on performance.,Hyperparameter Sensitivity,[0],[0]
"When we initialize the word embeddings randomly instead of using pre-trained word vectors, performance drops only slightly to 40.3.",Hyperparameter Sensitivity,[0],[0]
"If we initialize from a model trained using KBonly information, performance goes down substantially to 38.7.",Hyperparameter Sensitivity,[0],[0]
This indicates that initialization is important and there is a small gain from using pre-trained word embeddings.,Hyperparameter Sensitivity,[0],[0]
"There was a drop in performance to MRR 40.2 when using a window size of one for the convolutional architecture in Figure 4, and an increase to 40.6 when using a window size of five.",Hyperparameter Sensitivity,[0],[0]
Here we explored an alternative representation of textual relations for latent feature models that learn to represent knowledge base and textual relations in the same vector space.,5 Conclusion and Future Work,[0],[0]
"We showed that given the large degree of sharing of sub-structure in the textual relations, it was beneficial to compose their continuous representations out of the representations of their component words and dependency arc links.",5 Conclusion and Future Work,[0],[0]
"We applied a convolutional neural network model and trained it jointly with a model mapping entities and knowledge base relations to the same vector space, obtaining substantial improvements over an approach that treats the textual relations as atomic units having independent parameterization.",5 Conclusion and Future Work,[0],[0]
"We would like to thank the anonymous reviewers for their suggestions, and Jianfeng Gao, Scott Wen-tau Yih, and Wei Xu for useful discussions.",Acknowledgements,[0],[0]
"Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013).",abstractText,[0],[0]
"In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations.",abstractText,[0],[0]
The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure.,abstractText,[0],[0]
Representing Text for Joint Embedding of Text and Knowledge Bases,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1257–1266 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
1257",text,[0],[0]
"The construction of large-scale Knowledge Bases (KBs) like Freebase (Bollacker et al., 2008) and Wikidata (Vrandečić and Krötzsch, 2014) has proven to be useful in many natural language processing (NLP) tasks like question-answering, web search, etc.",1 Introduction,[0],[0]
"However, these KBs are not exhaustive.",1 Introduction,[0],[0]
Relation Extraction (RE) attempts to fill this gap by extracting semantic relationships between entity pairs from plain text.,1 Introduction,[0],[0]
This task can be modeled as a simple classification problem after the entity pairs are specified.,1 Introduction,[0],[0]
"Formally, given an entity pair (e1,e2) from the KB and an entity annotated sentence (or instance), we aim to predict the
∗Research internship at Indian Institute of Science.
relation r, from a predefined relation set, that exists between e1 and e2.",1 Introduction,[0],[0]
"If no relation exists, we simply label it NA.
",1 Introduction,[0],[0]
Most supervised relation extraction methods require large labeled training data which is expensive to construct.,1 Introduction,[0],[0]
"Distant Supervision (DS) (Mintz et al., 2009) helps with the construction of this dataset automatically, under the assumption that if two entities have a relationship in a KB, then all sentences mentioning those entities express the same relation.",1 Introduction,[0],[0]
"While this approach works well in generating large amounts of training instances, the DS assumption does not hold in all cases.",1 Introduction,[0],[0]
Riedel et al. (2010); Hoffmann et al. (2011); Surdeanu et al. (2012) propose multi-instance based learning to relax this assumption.,1 Introduction,[0],[0]
"However, they use NLP tools to extract features, which can be noisy.
",1 Introduction,[0],[0]
"Recently, neural models have demonstrated promising performance on RE.",1 Introduction,[0],[0]
"Zeng et al. (2014, 2015) employ Convolutional Neural Networks (CNN) to learn representations of instances.",1 Introduction,[0],[0]
"For alleviating noise in distant supervised datasets, attention has been utilized by (Lin et al., 2016; Jat et al., 2018).",1 Introduction,[0],[0]
"Syntactic information from dependency parses has been used by (Mintz et al., 2009; He et al., 2018) for capturing long-range dependencies between tokens.",1 Introduction,[0],[0]
"Recently proposed Graph Convolution Networks (GCN) (Defferrard et al., 2016) have been effectively employed for encoding this information (Marcheggiani and Titov, 2017; Bastings et al., 2017).",1 Introduction,[0],[0]
"However, all the above models rely only on the noisy instances from distant supervision for RE.
",1 Introduction,[0],[0]
Relevant side information can be effective for improving RE.,1 Introduction,[0],[0]
"For instance, in the sentence, Microsoft was started by Bill Gates., the type information of Bill Gates (person) and Microsoft (organization) can be helpful in predicting the correct relation founderOfCompany.",1 Introduction,[0],[0]
"This is because every relation constrains the type of its target en-
tities.",1 Introduction,[0],[0]
"Similarly, relation phrase “was started by” extracted using Open Information Extraction (Open IE) methods can be useful, given that the aliases of relation founderOfCompany, e.g., founded, co-founded, etc., are available.",1 Introduction,[0],[0]
"KBs used for DS readily provide such information which has not been completely exploited by current models.
",1 Introduction,[0],[0]
"In this paper, we propose RESIDE, a novel distant supervised relation extraction method which utilizes additional supervision from KB through its neural network based architecture.",1 Introduction,[0],[0]
"RESIDE makes principled use of entity type and relation alias information from KBs, to impose soft constraints while predicting the relation.",1 Introduction,[0],[0]
"It uses encoded syntactic information obtained from Graph Convolution Networks (GCN), along with embedded side information, to improve neural relation extraction.",1 Introduction,[0],[0]
"Our contributions can be summarized as follows:
• We propose RESIDE, a novel neural method which utilizes additional supervision from KB in a principled manner for improving distant supervised RE.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"RESIDE uses Graph Convolution Networks
(GCN) for modeling syntactic information and has been shown to perform competitively even with limited side information.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Through extensive experiments on benchmark
datasets, we demonstrate RESIDE’s effectiveness over state-of-the-art baselines.
RESIDE’s source code and datasets used in the paper are available at http://github.com/ malllabiisc/RESIDE.",1 Introduction,[0],[0]
Distant supervision: Relation extraction is the task of identifying the relationship between two entity mentions in a sentence.,2 Related Work,[0],[0]
"In supervised paradigm, the task is considered as a multi-class classification problem but suffers from lack of large labeled training data.",2 Related Work,[0],[0]
"To address this limitation, (Mintz et al., 2009) propose distant supervision (DS) assumption for creating large datasets, by heuristically aligning text to a given Knowledge Base (KB).",2 Related Work,[0],[0]
"As this assumption does not always hold true, some of the sentences might be wrongly labeled.",2 Related Work,[0],[0]
"To alleviate this shortcoming, Riedel et al. (2010) relax distant supervision for multi-instance single-label learning.",2 Related Work,[0],[0]
"Subsequently, for handling overlapping relations between entities (Hoffmann et al., 2011; Surdeanu et al., 2012) propose multi-instance multi-label learning paradigm.
",2 Related Work,[0],[0]
Neural Relation Extraction: The performance of the above methods strongly rely on the quality of hand engineered features.,2 Related Work,[0],[0]
"Zeng et al. (2014)
propose an end-to-end CNN based method which could automatically capture relevant lexical and sentence level features.",2 Related Work,[0],[0]
"This method is further improved through piecewise max-pooling by (Zeng et al., 2015).",2 Related Work,[0],[0]
"Lin et al. (2016); Nagarajan et al. (2017) use attention (Bahdanau et al., 2014) for learning from multiple valid sentences.",2 Related Work,[0],[0]
"We also make use of attention for learning sentence and bag representations.
",2 Related Work,[0],[0]
"Dependency tree based features have been found to be relevant for relation extraction (Mintz et al., 2009).",2 Related Work,[0],[0]
He et al. (2018) use them for getting promising results through a recursive tree-GRU based model.,2 Related Work,[0],[0]
"In RESIDE, we make use of recently proposed Graph Convolution Networks (Defferrard et al., 2016; Kipf and Welling, 2017), which have been found to be quite effective for modelling syntactic information (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Vashishth et al., 2018a).
",2 Related Work,[0],[0]
"Side Information in RE: Entity description from KB has been utilized for RE (Ji et al., 2017), but such information is not available for all entities.",2 Related Work,[0],[0]
Type information of entities has been used by Ling and Weld (2012); Liu et al. (2014) as features in their model.,2 Related Work,[0],[0]
Yaghoobzadeh et al. (2017) also attempt to mitigate noise in DS through their joint entity typing and relation extraction model.,2 Related Work,[0],[0]
"However, KBs like Freebase readily provide reliable type information which could be directly utilized.",2 Related Work,[0],[0]
"In our work, we make principled use of entity type and relation alias information obtained from KB.",2 Related Work,[0],[0]
"We also use unsupervised Open Information Extraction (Open IE) methods (Mausam et al., 2012; Angeli et al., 2015), which automatically discover possible relations without the need of any predefined ontology, which is used as a side information as defined in Section 5.2.",2 Related Work,[0],[0]
"In this section, we provide a brief overview of Graph Convolution Networks (GCN) for graphs with directed and labeled edges, as used in (Marcheggiani and Titov, 2017).",3 Background: Graph Convolution Networks (GCN),[0],[0]
"For a directed graph, G = (V, E), where V and E represent the set of vertices and edges respectively, an edge from node u to node v with label luv is represented as (u, v, luv).",3.1 GCN on Labeled Directed Graph,[0],[0]
"Since, informa-
tion in directed edge does not necessarily propagate along its direction, following (Marcheggiani and Titov, 2017) we define an updated edge set E ′ which includes inverse edges (v, u, l−1uv ) and",3.1 GCN on Labeled Directed Graph,[0],[0]
"selfloops (u, u,>) along with the original edge set E , where > is a special symbol to denote self-loops.",3.1 GCN on Labeled Directed Graph,[0],[0]
"For each node v in G, we have an initial representation",3.1 GCN on Labeled Directed Graph,[0],[0]
"xv ∈ Rd, ∀v ∈ V .",3.1 GCN on Labeled Directed Graph,[0],[0]
"On employing GCN, we get an updated d-dimensional hidden representation hv ∈ Rd, ∀v ∈ V , by considering only its immediate neighbors (Kipf and Welling, 2017).",3.1 GCN on Labeled Directed Graph,[0],[0]
"This can be formulated as:
hv = f  ∑ u∈N (v) (Wluvxu + bluv)  .",3.1 GCN on Labeled Directed Graph,[0],[0]
"Here, Wluv ∈ Rd×d and bluv ∈ Rd are label dependent model parameters which are trained based on the downstream task.",3.1 GCN on Labeled Directed Graph,[0],[0]
N (v) refers to the set of neighbors of v based on E ′,3.1 GCN on Labeled Directed Graph,[0],[0]
and f is any non-linear activation function.,3.1 GCN on Labeled Directed Graph,[0],[0]
"In order to capture multihop neighborhood, multiple GCN layers can be stacked.",3.1 GCN on Labeled Directed Graph,[0],[0]
"Hidden representation of node v in this case after kth GCN layer is given as:
hk+1v = f  ∑ u∈N (v) ( W kluvh k u + b k luv ) .",3.1 GCN on Labeled Directed Graph,[0],[0]
"In automatically constructed graphs, some edges might be erroneous and hence need to be discarded.",3.2 Integrating Edge Importance,[0],[0]
"Edgewise gating in GCN by (Bastings et al., 2017; Marcheggiani and Titov, 2017) allows us to alleviate this problem by subduing the noisy edges.",3.2 Integrating Edge Importance,[0],[0]
This is achieved by assigning a relevance score to each edge in the graph.,3.2 Integrating Edge Importance,[0],[0]
"At kth layer, the importance of an edge (u, v, luv) is computed as:
gkuv = σ",3.2 Integrating Edge Importance,[0],[0]
"( hku · ŵkluv + b̂ k luv ) , (1)
Here, ŵkluv ∈ R m and b̂kluv ∈ R are parameters which are trained and σ(·) is the sigmoid function.",3.2 Integrating Edge Importance,[0],[0]
"With edgewise gating, the final GCN embedding for a node v after kth layer is given as:
hk+1v = f  ∑ u∈N (v) gkuv × ( W kluvh k u + b k luv ) .",3.2 Integrating Edge Importance,[0],[0]
(2),3.2 Integrating Edge Importance,[0],[0]
"In multi-instance learning paradigm, we are given a bag of sentences (or instances) {s1, s2, ...sn} for a given entity pair, the task is to predict the relation between them.",4 RESIDE Overview,[0],[0]
"RESIDE consists of three components for learning a representation of a given bag, which is fed to a softmax classifier.",4 RESIDE Overview,[0],[0]
We briefly present the components of RESIDE below.,4 RESIDE Overview,[0],[0]
Each component will be described in detail in the subsequent sections.,4 RESIDE Overview,[0],[0]
"The overall architecture of RESIDE is shown in Figure 1.
1.",4 RESIDE Overview,[0],[0]
Syntactic Sentence Encoding: RESIDE uses a Bi-GRU over the concatenated positional and word embedding for encoding the local context of each token.,4 RESIDE Overview,[0],[0]
"For capturing long-range dependencies, GCN over dependency tree is employed and its encoding is appended to the representation of each token.",4 RESIDE Overview,[0],[0]
"Finally, attention over tokens is used to subdue irrelevant tokens and get an embedding for the entire sentence.",4 RESIDE Overview,[0],[0]
"More details in Section 5.1.
2.",4 RESIDE Overview,[0],[0]
Side Information Acquisition:,4 RESIDE Overview,[0],[0]
"In this module, we use additional supervision from KBs and utilize Open IE methods for getting relevant side information.",4 RESIDE Overview,[0],[0]
"This information is later utilized by the model as described in Section 5.2.
3.",4 RESIDE Overview,[0],[0]
Instance Set Aggregation:,4 RESIDE Overview,[0],[0]
"In this part, sentence representation from syntactic sentence encoder is concatenated with the matched relation embedding obtained from the previous step.",4 RESIDE Overview,[0],[0]
"Then, using attention over sentences, a representation for the entire bag is learned.",4 RESIDE Overview,[0],[0]
This is then concatenated with entity type embedding before feeding into the softmax classifier for relation prediction.,4 RESIDE Overview,[0],[0]
Please refer to Section 5.3 for more details.,4 RESIDE Overview,[0],[0]
"In this section, we provide the detailed description of the components of RESIDE.",5 RESIDE Details,[0],[0]
"For each sentence in the bag si with m tokens {w1, w2, ...wm}, we first represent each token by k-dimensional GloVe embedding (Pennington et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
"For incorporating relative position of tokens with respect to target entities, we use p-dimensional position embeddings, as used by
(Zeng et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
The combined token embeddings are stacked together to get the sentence representationH ∈ Rm×(k+2p).,5.1 Syntactic Sentence Encoding,[0],[0]
"Then, using Bi-GRU (Cho et al., 2014) over H, we get the new sentence representationHgru ∈ Rm×dgru , where dgru is the hidden state dimension.",5.1 Syntactic Sentence Encoding,[0],[0]
"Bi-GRUs have been found to be quite effective in encoding the context of tokens in several tasks (Sutskever et al., 2014; Graves et al., 2013).
",5.1 Syntactic Sentence Encoding,[0],[0]
"Although Bi-GRU is capable of capturing local context, it fails to capture long-range dependencies which can be captured through dependency edges.",5.1 Syntactic Sentence Encoding,[0],[0]
"Prior works (Mintz et al., 2009; He et al., 2018) have exploited features from syntactic dependency trees for improving relation extraction.",5.1 Syntactic Sentence Encoding,[0],[0]
"Motivated by their work, we employ Syntactic Graph Convolution Networks for encoding this information.",5.1 Syntactic Sentence Encoding,[0],[0]
"For a given sentence, we generate its dependency tree using Stanford CoreNLP",5.1 Syntactic Sentence Encoding,[0],[0]
"(Manning et al., 2014).",5.1 Syntactic Sentence Encoding,[0],[0]
"We then run GCN over the dependency graph and use Equation 2 for updating the embeddings, taking Hgru as the input.",5.1 Syntactic Sentence Encoding,[0],[0]
"Since dependency graph has 55 different edge labels, incorporating all of them overparameterizes the model significantly.",5.1 Syntactic Sentence Encoding,[0],[0]
"Therefore, following (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Vashishth et al., 2018a) we use only three edge labels based on the direction of the edge {forward (→), backward (←), selfloop (>)}.",5.1 Syntactic Sentence Encoding,[0],[0]
"We define the new edge label Luv for an edge (u, v, luv) as follows:
",5.1 Syntactic Sentence Encoding,[0],[0]
"Luv =  → if edge exists in dependency parse ← if edge is an inverse edge > if edge is a self-loop
For each token wi, GCN embedding h gcn ik+1 ∈",5.1 Syntactic Sentence Encoding,[0],[0]
"Rdgcn after kth layer is defined as:
hgcnik+1 =",5.1 Syntactic Sentence Encoding,[0],[0]
f,5.1 Syntactic Sentence Encoding,[0],[0]
"( ∑ u∈N (i) gkiu × ( W kLiuh gcn uk + bkLiu )) .
",5.1 Syntactic Sentence Encoding,[0],[0]
"Here, gkiu denotes edgewise gating as defined in Equation 1 and Liu refers to the edge label defined above.",5.1 Syntactic Sentence Encoding,[0],[0]
"We use ReLU as activation function f , throughout our experiments.",5.1 Syntactic Sentence Encoding,[0],[0]
"The syntactic graph encoding from GCN is appended to Bi-GRU output to get the final token representation, hconcati as [hgrui ;h gcn ik+1
].",5.1 Syntactic Sentence Encoding,[0],[0]
"Since, not all tokens are equally relevant for RE task, we calculate the degree of relevance of each token using attention as used in
(Jat et al., 2018).",5.1 Syntactic Sentence Encoding,[0],[0]
"For token wi in the sentence, attention weight αi is calculated as:
αi = exp(ui)∑m j=1 exp(uj) where, ui = hconcati ·",5.1 Syntactic Sentence Encoding,[0],[0]
"r.
where r is a random query vector and ui is the relevance score assigned to each token.",5.1 Syntactic Sentence Encoding,[0],[0]
Attention values {αi} are calculated by taking softmax over {ui}.,5.1 Syntactic Sentence Encoding,[0],[0]
"The representation of a sentence is given as a weighted sum of its tokens, s =∑m
j=1 αih concat i .",5.1 Syntactic Sentence Encoding,[0],[0]
"Relevant side information has been found to improve performance on several tasks (Ling and Weld, 2012; Vashishth et al., 2018b).",5.2 Side Information Acquisition,[0],[0]
"In distant supervision based relation extraction, since the entities are from a KB, knowledge about them can be utilized to improve relation extraction.",5.2 Side Information Acquisition,[0],[0]
"Moreover, several unsupervised relation extraction methods (Open IE) (Angeli et al., 2015; Mausam et al., 2012) allow extracting relation phrases between target entities without any predefined ontology and thus can be used to obtain relevant side information.",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we employ Open IE methods and additional supervision from KB for improving neural relation extraction.
",5.2 Side Information Acquisition,[0],[0]
"Relation Alias Side Information RESIDE uses Stanford Open IE (Angeli et al., 2015) for extracting relation phrases between target entities, which we denote by P .",5.2 Side Information Acquisition,[0],[0]
"As shown in Figure 2, for the sentence Matt Coffin, executive of
lowermybills, a company.., Open IE methods extract “executive of” between Matt Coffin and lowermybills.",5.2 Side Information Acquisition,[0],[0]
"Further, we extend P by including tokens at one hop distance in dependency path from target entities.",5.2 Side Information Acquisition,[0],[0]
"Such features from dependency parse have been exploited in the past by (Mintz et al., 2009; He et al., 2018).",5.2 Side Information Acquisition,[0],[0]
The degree of match between the extracted phrases in P and aliases of a relation can give important clues about the relevance of that relation for the sentence.,5.2 Side Information Acquisition,[0],[0]
"Several KBs like Wikidata provide such relation aliases, which can be readily exploited.",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we further expand the relation alias set using Paraphrase database (PPDB) (Pavlick et al., 2015).",5.2 Side Information Acquisition,[0],[0]
"We note that even for cases when aliases for relations are not available, providing only the names of relations give competitive performance.",5.2 Side Information Acquisition,[0],[0]
"We shall explore this point further in Section 7.3.
",5.2 Side Information Acquisition,[0],[0]
"For matching P with the PPDB expanded relation alias setR, we project both in a d-dimensional space using GloVe embeddings (Pennington et al., 2014).",5.2 Side Information Acquisition,[0],[0]
"Projecting phrases using word embeddings helps to further expand these sets, as semantically similar words are closer in embedding space (Mikolov et al., 2013; Pennington et al., 2014).",5.2 Side Information Acquisition,[0],[0]
"Then, for each phrase p ∈ P , we calculate its cosine distance from all relation aliases inR and take the relation corresponding to the closest relation alias as a matched relation for the sentence.",5.2 Side Information Acquisition,[0],[0]
We use a threshold on cosine distance to remove noisy aliases.,5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we define a kr-dimensional embedding for each relation which we call as matched relation embedding (hrel).",5.2 Side Information Acquisition,[0],[0]
"For a given sentence, hrel is concatenated with its representa-
tion s, obtained from syntactic sentence encoder (Section 5.1) as shown in Figure 1.",5.2 Side Information Acquisition,[0],[0]
"For sentences with |P| > 1, we might get multiple matched relations.",5.2 Side Information Acquisition,[0],[0]
"In such cases, we take the average of their embeddings.",5.2 Side Information Acquisition,[0],[0]
"We hypothesize that this helps in improving the performance and find it to be true as shown in Section 7.
Entity Type Side Information Type information of target entities has been shown to give promising results on relation extraction (Ling and Weld, 2012; Yaghoobzadeh et al., 2017).",5.2 Side Information Acquisition,[0],[0]
Every relation puts some constraint on the type of entities which can be its subject and object.,5.2 Side Information Acquisition,[0],[0]
"For example, the relation person/place of birth can only occur between a person and a location.",5.2 Side Information Acquisition,[0],[0]
"Sentences in distance supervision are based on entities in KBs, where the type information is readily available.
",5.2 Side Information Acquisition,[0],[0]
"In RESIDE, we use types defined by FIGER (Ling and Weld, 2012) for entities in Freebase.",5.2 Side Information Acquisition,[0],[0]
"For each type, we define a kt-dimensional embedding which we call as entity type embedding (htype).",5.2 Side Information Acquisition,[0],[0]
"For cases when an entity has multiple types in different contexts, for instance, Paris may have types government and location, we take the average over the embeddings of each type.",5.2 Side Information Acquisition,[0],[0]
We concatenate the entity type embedding of target entities to the final bag representation before using it for relation classification.,5.2 Side Information Acquisition,[0],[0]
"To avoid over-parameterization, instead of using all fine-grained 112 entity types, we use 38 coarse types which form the first hierarchy of FIGER types.",5.2 Side Information Acquisition,[0],[0]
"For utilizing all valid sentences, following (Lin et al., 2016; Jat et al., 2018), we use attention over sentences to obtain a representation for the entire bag.",5.3 Instance Set Aggregation,[0],[0]
"Instead of directly using the sentence representation si from Section 5.1, we concatenate the embedding of each sentence with matched relation embedding hreli as obtained from Section 5.2.",5.3 Instance Set Aggregation,[0],[0]
"The attention score αi for ith sentence is formulated as:
αi = exp(ŝi · q)∑n j=1 exp(ŝj · q) where, ŝi =",5.3 Instance Set Aggregation,[0],[0]
"[si;hreli ].
here q denotes a random query vector.",5.3 Instance Set Aggregation,[0],[0]
"The bag representation B, which is the weighted sum of its sentences, is then concatenated with the entity type embeddings of the subject (htypesub ) and object
(htypeobj ) from Section 5.2 to obtain B̂.
B̂ = [B;htypesub ;h type obj ] where, B = n∑ i=1 αiŝi.
",5.3 Instance Set Aggregation,[0],[0]
"Finally, B̂ is fed to a softmax classifier to get the probability distribution over the relations.
p(y) =",5.3 Instance Set Aggregation,[0],[0]
Softmax(W · B̂ + b).,5.3 Instance Set Aggregation,[0],[0]
"In our experiments, we evaluate the models on Riedel and Google Distant Supervision (GIDS) dataset.",6.1 Datasets,[0],[0]
Statistics of the datasets is summarized in Table 1.,6.1 Datasets,[0],[0]
"Below we described each in detail1.
1.",6.1 Datasets,[0],[0]
Riedel:,6.1 Datasets,[0],[0]
"The dataset is developed by (Riedel et al., 2010) by aligning Freebase relations with New York Times (NYT) corpus, where sentences from the year 2005-2006 are used for creating the training set and from the year 2007 for the test set.",6.1 Datasets,[0],[0]
"The entity mentions are annotated using Stanford NER (Finkel et al., 2005) and are linked to Freebase.",6.1 Datasets,[0],[0]
"The dataset has been widely used for RE by (Hoffmann et al., 2011; Surdeanu et al., 2012) and more recently by (Lin et al., 2016; Feng et al.;",6.1 Datasets,[0],[0]
"He et al., 2018).
2.",6.1 Datasets,[0],[0]
GIDS:,6.1 Datasets,[0],[0]
Jat et al. (2018) created Google Distant Supervision (GIDS) dataset by extending the Google relation extraction corpus2 with additional instances for each entity pair.,6.1 Datasets,[0],[0]
"The dataset assures that the at-least-one assumption of multi-instance learning, holds.",6.1 Datasets,[0],[0]
"This makes automatic evaluation more reliable and thus removes the need for manual verification.
",6.1 Datasets,[0],[0]
1Data splits and hyperparameters are in supplementary.,6.1 Datasets,[0],[0]
"2https://research.googleblog.com/2013/04/50000-
lessons-on-how-to-read-relation.html",6.1 Datasets,[0],[0]
"For evaluating RESIDE, we compare against the following baselines:
• Mintz: Multi-class logistic regression model proposed by (Mintz et al., 2009) for distant supervision paradigm.",6.2 Baselines,[0],[0]
"• MultiR: Probabilistic graphical model for multi
instance learning by (Hoffmann et al., 2011)",6.2 Baselines,[0],[0]
"• MIMLRE: A graphical model which jointly
models multiple instances and multiple labels.",6.2 Baselines,[0],[0]
"More details in (Surdeanu et al., 2012).",6.2 Baselines,[0],[0]
• PCNN:,6.2 Baselines,[0],[0]
"A CNN based relation extraction model
by (Zeng et al., 2015) which uses piecewise max-pooling for sentence representation.",6.2 Baselines,[0],[0]
• PCNN+ATT,6.2 Baselines,[0],[0]
": A piecewise max-pooling over
CNN based model which is used by (Lin et al., 2016) to get sentence representation followed by attention over sentences.",6.2 Baselines,[0],[0]
"• BGWA: Bi-GRU based relation extraction
model with word and sentence level attention (Jat et al., 2018).",6.2 Baselines,[0],[0]
•,6.2 Baselines,[0],[0]
RESIDE:,6.2 Baselines,[0],[0]
"The method proposed in this paper,
please refer Section 5 for more details.",6.2 Baselines,[0],[0]
"Following the prior works (Lin et al., 2016; Feng et al.), we evaluate the models using held-out evaluation scheme.",6.3 Evaluation Criteria,[0],[0]
This is done by comparing the relations discovered from test articles with those in Freebase.,6.3 Evaluation Criteria,[0],[0]
We evaluate the performance of models with Precision-Recall curve and top-N precision (P@N) metric in our experiments.,6.3 Evaluation Criteria,[0],[0]
"In this section we attempt to answer the following questions:
Q1.",7 Results,[0],[0]
Is RESIDE more effective than existing approaches for distant supervised RE?,7 Results,[0],[0]
"(7.1)
Q2.",7 Results,[0],[0]
What is the effect of ablating different components on RESIDE’s performance?,7 Results,[0],[0]
"(7.2)
Q3.",7 Results,[0],[0]
How is the performance affected in the absence of relation alias information?,7 Results,[0],[0]
(7.3),7 Results,[0],[0]
"For evaluating the effectiveness of our proposed method, RESIDE, we compare it against the baselines stated in Section 6.2.",7.1 Performance Comparison,[0],[0]
We use only the neural baselines on GIDS dataset.,7.1 Performance Comparison,[0],[0]
The Precision-Recall curves on Riedel and GIDS are presented in Figure 3.,7.1 Performance Comparison,[0],[0]
"Overall, we find that RESIDE achieves higher precision over the entire recall range on both the datasets.",7.1 Performance Comparison,[0],[0]
All the non-neural baselines could not perform well as the features used by them are mostly derived from NLP tools which can be erroneous.,7.1 Performance Comparison,[0],[0]
RESIDE outperforms PCNN+ATT and BGWA which indicates that incorporating side information helps in improving the performance of the model.,7.1 Performance Comparison,[0],[0]
The higher performance of BGWA and PCNN+ATT over PCNN shows that attention helps in distant supervised RE.,7.1 Performance Comparison,[0],[0]
"Following (Lin et al., 2016; Liu et al., 2017), we also evaluate our method with different number of sentences.",7.1 Performance Comparison,[0],[0]
"Results summarized in Table 2, show the improved precision of RESIDE in all test settings, as compared to the neural baselines, which demonstrates
the efficacy of our model.",7.1 Performance Comparison,[0],[0]
"In this section, we analyze the effect of various components of RESIDE on its performance.",7.2 Ablation Results,[0],[0]
"For this, we evaluate various versions of our model with cumulatively removed components.",7.2 Ablation Results,[0],[0]
The experimental results are presented in Figure 4.,7.2 Ablation Results,[0],[0]
"We observe that on removing different components from RESIDE, the performance of the model degrades drastically.",7.2 Ablation Results,[0],[0]
The results validate that GCNs are effective at encoding syntactic information.,7.2 Ablation Results,[0],[0]
"Further, the improvement from side information shows that it is complementary to the features extracted from text, thus validating the central thesis of this paper, that inducing side information leads to improved relation extraction.",7.2 Ablation Results,[0],[0]
"In this section, we test the performance of the model in setting where relation alias information is not readily available.",7.3 Effect of Relation Alias Side Information,[0],[0]
"For this, we evaluate the performance of the model on four different settings:",7.3 Effect of Relation Alias Side Information,[0],[0]
"• None: Relation aliases are not available.
",7.3 Effect of Relation Alias Side Information,[0],[0]
• One: The name of relation is used as its alias.,7.3 Effect of Relation Alias Side Information,[0],[0]
"• One+PPDB: Relation name extended using
Paraphrase Database (PPDB).",7.3 Effect of Relation Alias Side Information,[0],[0]
•,7.3 Effect of Relation Alias Side Information,[0],[0]
"All: Relation aliases from Knowledge Base3
The overall results are summarized in Figure 5.",7.3 Effect of Relation Alias Side Information,[0],[0]
We find that the model performs best when aliases are provided by the KB itself.,7.3 Effect of Relation Alias Side Information,[0],[0]
"Overall, we find that RESIDE gives competitive performance even when very limited amount of relation alias information is available.",7.3 Effect of Relation Alias Side Information,[0],[0]
We observe that performance improves further with the availability of more alias information.,7.3 Effect of Relation Alias Side Information,[0],[0]
"In this paper, we propose RESIDE, a novel neural network based model which makes principled use of relevant side information, such as entity type and relation alias, from Knowledge Base, for improving distant supervised relation extraction.",8 Conclusion,[0],[0]
"RESIDE employs Graph Convolution Networks for
3Each relation in Riedel dataset is manually mapped to corresponding Wikidata property for getting relation aliases.",8 Conclusion,[0],[0]
"Few examples are presented in supplementary material.
encoding syntactic information of sentences and is robust to limited side information.",8 Conclusion,[0],[0]
"Through extensive experiments on benchmark datasets, we demonstrate RESIDE’s effectiveness over stateof-the-art baselines.",8 Conclusion,[0],[0]
We have made RESIDE’s source code publicly available to promote reproducible research.,8 Conclusion,[0],[0]
We thank the anonymous reviewers for their constructive comments.,Acknowledgements,[0],[0]
"This work is supported in part by the Ministry of Human Resource Development (Government of India), CAIR (DRDO) and by a gift from Google.",Acknowledgements,[0],[0]
Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text.,abstractText,[0],[0]
"In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany).",abstractText,[0],[0]
RE models usually ignore such readily available side information.,abstractText,[0],[0]
"In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction.",abstractText,[0],[0]
It uses entity type and relation alias information for imposing soft constraints while predicting relations.,abstractText,[0],[0]
RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available.,abstractText,[0],[0]
"Through extensive experiments on benchmark datasets, we demonstrate RESIDE’s effectiveness.",abstractText,[0],[0]
We have made RESIDE’s source code available to encourage reproducible research.,abstractText,[0],[0]
RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information,title,[0],[0]
"The spread of data-driven decision making to civic institutions, spurred by the empirical success of machine learning and the growing availability of individual-level data, raises
This material is based upon work supported by the National Science Foundation under Grant No. 1656996.",1. Introduction,[0],[0]
Angela Zhou is supported through the National Defense Science & Engineering Graduate Fellowship Program.,1. Introduction,[0],[0]
"1Cornell University, and Cornell Tech, New York 2Cornell University, Ithaca, New York.",1. Introduction,[0],[0]
Correspondence to: Angela Zhou,1. Introduction,[0],[0]
"<az434@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
new questions about the possible harms of learning from data which is subject to historical bias.,1. Introduction,[0],[0]
"Unlike clean-cut prediction problems in other domains, datasets of individuals and their historical outcomes may reflect systematic bias due to previously prejudiced decisions (Barocas & Selbst, 2014).",1. Introduction,[0],[0]
"Recent work on fairness in machine learning proposes and analyzes competing criteria for assessing the fairness of machine learning algorithms, where some adjustments attempt to equalize accuracy metrics across groups (Corbett-Davies et al., 2017; Kleinberg et al., 2017; Hardt et al., 2016).",1. Introduction,[0],[0]
"Other work studies how historical prejudices may be reflected in training data such that algorithmic systems might replicate historical biases (Angwin et al., 2016; Lum & Isaac, 2016; Kilbertus et al., 2017).",1. Introduction,[0],[0]
We consider a model of biased data where systematic censoring affects whether or not entire observations appear in the training dataset.,1. Introduction,[0],[0]
"In such cases, the available data are not representative of the eventual realworld “test” population to which any resulting learned policy will be applied.",1. Introduction,[0],[0]
"Our paper formalizes and characterizes how systematic under- or over-representation of groups in the dataset can hamper attempts to correct for fairness, leading to residual unfairness on the target population of interest.
",1. Introduction,[0],[0]
"This important issue arises in almost all settings where fair machine learning has been studied:
(1) Data on loan default can only be collected on those loan applicants who were historically approved but is used to learn approval policies applied to all applicants.",1. Introduction,[0],[0]
"(2) Arrest data help build predictive policing models but these data are disproportionately collected on individuals in highly patrolled areas and may be subject to further prejudice at the individual level, including racial (Lum & Isaac, 2016).",1. Introduction,[0],[0]
"(3) Risk assessment and intervention tools in child welfare agencies are trained on cases which have been “screened in” by caseworkers based on external reports (Chouldechova et al., 2018).",1. Introduction,[0],[0]
"(4) Defendants may only flee and fail to appear if not detained, so any flight risk score used for setting bail can only be learned from data on defendants who were not detained.",1. Introduction,[0],[0]
"(5) Convict recidivism is impacted by sentence applied but learned risk scores are applied to all convicts.
",1. Introduction,[0],[0]
"In these applications, systematic censoring screens out ob-
servations of individuals and their outcomes from a training dataset.",1. Introduction,[0],[0]
"Such censoring may reflect historical decisions made with limited access to information, heterogeneous decision-makers, or the application of statistically discriminatory rules (Arrow, 1973).",1. Introduction,[0],[0]
"Despite the intermediate screening, domain-level restrictions may require ensuring fairness of any decision or prediction policy with respect to the original population.",1. Introduction,[0],[0]
"We formalize this mechanism as a data setting (Fig. 1) where a historical decision policy Z 2 {0, 1} specifies whether an instance will be included in the dataset.",1. Introduction,[0],[0]
"Systematic censoring may induce covariate shift on population-level estimands, such as true positive rate, as outcomes are observed in the training data only where Z = 1.",1. Introduction,[0],[0]
"Notably, predictive tools built on these censored datasets are actively being deployed: there is an opportunity to improve upon standards of practice, but the structural implications of systematically censored data ought to be accounted for (Angwin et al., 2016; Capatosto, 2017; LJAF, 2015).",1. Introduction,[0],[0]
"Our contributions are as follows:
• We characterize when systematic censoring induces residual unfairness in terms of the distributions of the conditional Bayes-optimal risk score across censored and target groups.",1. Introduction,[0],[0]
"• When benchmark data is available, we show how to use sample re-weighting techniques to estimate accuracy metrics to adjust for fairness on the target population.",1. Introduction,[0],[0]
We show how the sample weights indicate what groups remain disadvantaged by residual unfairness.,1. Introduction,[0],[0]
•,1. Introduction,[0],[0]
"We demonstrate how systematic inclusion can affect fairness adjustments on an empirical example with data from the application of the Stop, Question, and Frisk (SQF) policy of the City of New York Police Department (NYPD).
",1. Introduction,[0],[0]
"In settings where datasets can be subject to historical prejudice and decision policies ought to be truly fair on the general population, we argue it is paramount to carefully consider and account for the sampling process to ensure fairness on the true population.",1. Introduction,[0],[0]
"We consider the problem of learning a fair decision policy (classifier or threshold rule on a regressor) from a dataset
where each decision instance is characterized by observed covariates X 2 X (e.g., predictors of creditworthiness, criminality, etc), protected class A 2 [m] = {1, . . .",2. Problem Setting,[0],[0]
",m} (e.g., sex, race, etc), and label Y 2 {0, 1} (where Y = 1 is generally interpreted as the favorable label, e.g., “will pay back loan” or “will not reoffend”).
",2. Problem Setting,[0],[0]
Fig. 1 illustrates the construction of a biased training dataset in this setting.,2. Problem Setting,[0],[0]
"The indicator Z 2 {0, 1} specifies whether an instance is included in the post-censoring training data (e.g., “approved for a loan”) and another indicator T 2 {0, 1} specifying whether an instance belongs to the population to which the learned policy will be applied.",2. Problem Setting,[0],[0]
"For example, if T is the constant 1, the target population is that of all loan applicants.",2. Problem Setting,[0],[0]
"We sometimes call Z = 1 the logging policy in analogy to logged-bandit learning (Kallus, 2017; Swaminathan & Joachims, 2015), where the implementation of a (often unknown) historical policy resulted in limited bandit feedback on outcomes.",2. Problem Setting,[0],[0]
"Because a random sample from the target population is generally not available, the target population is different from the notion of a held-out “test” dataset used to evaluate predictive accuracy .
",2. Problem Setting,[0],[0]
"We consider the problem of determining a policy assigning labels Ŷ 2 {0, 1} that depends only on X,A but may be randomized (so Ŷ ?",2. Problem Setting,[0],[0]
"(Y, Z, T )",2. Problem Setting,[0],[0]
"| X,A).",2. Problem Setting,[0],[0]
"Labeled training data (X,A, Y ) is available from the Z = 1 population, so that only the conditional joint distribution of X,A, Y | Z",2. Problem Setting,[0],[0]
= 1 is characterized by this data.,2. Problem Setting,[0],[0]
"We may or may not also have unlabeled data from the T = 1 population, X,A | T = 1.
",2. Problem Setting,[0],[0]
"For concreteness, when discussing fairness criteria, we consider the specific fairness criterion of equality of opportunity or equalized odds introduced by Hardt et al. (2016).",2. Problem Setting,[0],[0]
The adjustment determines a fair policy Ŷ from a (possibly discriminatory) black-box binary predictor or score R̂ without access to the original training data.,2. Problem Setting,[0],[0]
"They identify two particular types of fairness, equal opportunity and equalized odds, which require that a fairness-adjusted policy Ŷ be independent of class A given a positive label Y = 1 or given any label Y , respectively.",2. Problem Setting,[0],[0]
"For loan approval, equality of opportunity requires that the policy treat truly creditworthy individuals the same, independent of protected class membership.",2. Problem Setting,[0],[0]
"Equalized odds prohibits abusing class membership as an unfair proxy for Y (e.g., via stereotyping or racial profiling).",2. Problem Setting,[0],[0]
"For our setting, to be explicit, we define these relative to an event: Definition 1.",2. Problem Setting,[0],[0]
"A policy Ŷ satisfies equalized odds with respect to (wrt) class variable A and event E if
Ŷ ?",2. Problem Setting,[0],[0]
"A | Y = y,E (1)
holds for y 2 {0, 1}.",2. Problem Setting,[0],[0]
"A policy satisfies equal opportunity wrt A and E if eq. (1) holds for y = 1.
",2. Problem Setting,[0],[0]
"For brevity, we will say a policy is simply fair to mean either equal opportunity or equalized odds.",2. Problem Setting,[0],[0]
"Hardt et al.
(2016) determine such a policy by a post-processing step given a score R̂ using a constrained optimization problem over group-specific thresholds (potentially randomized), enforcing the constraints in eq. (1) on the true positive rate and/or false positive rate across groups while optimizing a given classification loss.",2. Problem Setting,[0],[0]
"Specifically, define F E
a (✓) =",2. Problem Setting,[0],[0]
"Pr[R̂  ✓ | Y = 1, A = a,E] as the conditional CDF (cumulative distribution function) of the score given the event E and Y = 1.",2. Problem Setting,[0],[0]
"For a given true positive rate ⇢, the corresponding derived equal opportunity classifier at rate ⇢ is given by Ŷ = I[R̂ >",2. Problem Setting,[0],[0]
"✓
A ], where ✓ a = (F a ) 1(1 ⇢) is the threshold corresponding to group a so that it has true positive rate ⇢.",2. Problem Setting,[0],[0]
"Note that FZ=1
a
, F T=1 a are the false negative rates for a threshold classifier as evaluated on the censored and target population, respectively.",2. Problem Setting,[0],[0]
"Naturally, a policy is actually fair if it is fair on the population to which it is applied (here, T = 1).",2. Problem Setting,[0],[0]
"So, in seeking a fair policy per these definitions, we seek a policy that satisfies equal opportunity or equalized odds on the target population wrt class variable A and the event T = 1, while the approach of Hardt et al. (2016) applied directly to training data achieves fairness wrt A and the event Z = 1.",2. Problem Setting,[0],[0]
"Throughout, we assume R̂ 2 [0, 1].",2. Problem Setting,[0],[0]
Fairness and Missing Data.,3. Related Work,[0],[0]
Research on fairness and machine learning has considered some subcomponents of the overall problem we study of learning fair policies from biased datasets.,3. Related Work,[0],[0]
Hardt et al. (2016) formalize the criteria of equal opportunity and equalized odds.,3. Related Work,[0],[0]
"Lum & Isaac (2016) show that a predictive policing algorithm for drug enforcement in Oakland, trained on police records, will perpetuate disparate enforcement.",3. Related Work,[0],[0]
"Ensign et al. (2017) consider a discrete model of how beliefs of crime rates in different areas adjust after observing arrest rates, and propose implementing the Horvitz-Thompson estimator via rejection sampling of arrest observations in an “online” fashion.",3. Related Work,[0],[0]
Lakkaraju et al. (2017) identify a similar structural setting with “selective labels” where they learn a decision rule for pre-trial risk assessment from the decisions made from judges (which affect whether or not the outcome of interest will be observed).,3. Related Work,[0],[0]
"They leverage the heterogeneity of heterogeneous decision makers using different decision thresholds to identify subpopulations for comparison but do not consider the subsequent fairness of the learned policy.
",3. Related Work,[0],[0]
Sampling Adjustment and Superpopulations.,3. Related Work,[0],[0]
"Sampling adjustment and re-weighting is commonly used in the social sciences, medicine, and epidemiology for ensuring the validity of population-level inference where there is population mismatch between studies and the population of interest (Thompson, 2012; Freedman & Berk, 2008).",3. Related Work,[0],[0]
"The classic Horvitz-Thompson estimator uses the inverse probability of sampling probability weights and is unbiased for
population level estimates (Horvitz & Thompson, 1952).",3. Related Work,[0],[0]
"Much of the work on fairness in machine learning has used population-level statistics such as accuracy metrics (true positive rate, false negative rate) as metrics for identifying disparate impact.",3. Related Work,[0],[0]
"The case of sample selection bias was studied in Zadrozny (2004) for classifier evaluation, without regard for fairness impacts.",3. Related Work,[0],[0]
"We study how prejudicial biases in a dataset can lead to residual unfairness, which persists even after fairness adjustment if error parity metrics assessed from the censored dataset are used.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We show that the residual unfairness that remains even after adjustment will disadvantage the same group that was prejudiced against before, in the training data.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"This proves that even after fairness adjustment, fair machine learning still has a “bias in, bias out” property.
","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
An Illustrative Synthetic Example:,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Loan Application To illustrate the potential impact of population mismatch on fairness adjustments in a controlled setting, we consider a synthetic example for loan approval.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Suppose there are two classes, with half of the population of loan applicants in class 0 and the other half in class 1.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We let T = 1 be constant as we wish to consider the impact of our policy on the whole population of loan applicants.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We denote by X1 the (normalized) number of bank accounts and by X2 the (normalized) number of delinquent payments on record, including those for subprime loans.1
Suppose X is distributed as a standard bivariate normal conditioned on class, with a mean of (1, 0) among individuals
1The setting is motivated by systematic associations found in studies of the credit scores suggesting disadvantages for younger applicants and recent immigrants due to policies incorporating number of accounts (Board of Governors of the Federal Reserve System, 1997; Rice & Swesnik, 2014).
in the class A = 0 and a mean of (0, 1) among individuals in the underprivileged class A = 1.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Consider Y 2 {0, 1} indicating whether the individual will pay back the loan if it were approved.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Suppose Y is logistic in X conditioned on class with P (Y = 1 | X,A) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"( T
A X), where (t) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"1/(1 + e t) and 0 = (1, 1), 1 = (1.25, 1) so that X2 is predictive of creditworthiness in both classes but X1 is slightly more predictive in class A = 1 than in A = 0.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
Suppose the training data comes from historically approved loans where loans were approved based on X in such a way that P (Z = 1 | X) =,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"( T
a
X).
","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"In Figs. 2a–2b we consider deriving a fair classifier for loan approval from the class-blind Bayes optimal score R̂ = P (Y = 1 | X,T = 1) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"P (Y = 1 | X,Z = 1), which is the same in training and target populations by construction and which we assume is given (e.g., it can be identified from the training data regardless of any covariate shift between Z = 1 and T = 1; see Sec. 4.2).","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We simulate n = 100000 data points and censor the outcome for those with Z
i = 0.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
First we consider deriving an adjusted predictor from the Bayes-optimal classifier Ŷ = I[R̂ 0.5] by naı̈vely applying the method of Hardt et al. (2016).,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
Fig.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"2a shows the space of achievable FPR-TPR in the training (censored) and target (full) populations along with the optimal equalized odds and equal opportunity rates corresponding to the symmetric loss `(y, y0) =","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
I[y 6= y0].,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"As can be seen, there is a significant discrepancy between the regions in the censored vs. full population.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"Next, we consider deriving optimal equal opportunity policies from the score","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
R̂. Fig.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"2b shows the range of optimal policies, which is given by class-based thresholds, as we range the exchange rate between typeI and -II errors (false positives vs. false negatives).","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We also show the result from using a reweighting approach that we discuss in Sec. 5.,"4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
"We note that a naı̈ve application of fairness adjustment provides insufficient compensation for the unfairness toward the underprivileged class A = 1: for every threshold on class A = 0, the corresponding threshold on class A = 1 is always higher for the policy derived in the naı̈ve manner compared to that derived either using the full data or using our reweighting approach, such that the spuriously fair policy is systematically and uniformly harsher than necessary on the disadvantaged class.","4. Residual Unfairness Under Disparate Benefit of the Doubt: Bias In, Bias Out",[0],[0]
We now formalize the phenomenon illustrated in the example as residual unfairness and study why and when it arises in terms of the biases in training data due to existing prejudiced policies.,4.1. Disparate Benefit of the Doubt,[0],[0]
"For concreteness, we focus on the equality of opportunity criterion.",4.1. Disparate Benefit of the Doubt,[0],[0]
Many of our results can be easily extended to other observational fairness criteria.,4.1. Disparate Benefit of the Doubt,[0],[0]
"To quantify the extent to which the criterion is satisfied or violated, and in which direction, we define the inequity of opportunity.",4.1. Disparate Benefit of the Doubt,[0],[0]
Definition 2 (Inequity of Opportunity).,4.1. Disparate Benefit of the Doubt,[0],[0]
"The inequity of
opportunity between classes A = a and A = b wrt to event E under policy Ŷ is defined as
✏
E
a,b = P(Ŷ = 1 | E,A=a, Y=1 )",4.1. Disparate Benefit of the Doubt,[0],[0]
"P(Ŷ = 1 | E,A=b, Y=1 )
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Positive values in the target population, ✏T=1 a,b > 0, indicate unfairness against group b. Zero inequity between all groups corresponds to equality of opportunity.",4.1. Disparate Benefit of the Doubt,[0],[0]
"A policy that is adjusted to be equal-opportunity or equalized-odds fair on the training data has ✏Z=1
a,b = 0.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, any nonzero value of ✏T=1
a,b for such a policy constitutes a residual unfairness corresponding to the additional unadjusted-for inequity introduced by going from the Z = 1 to the T = 1 population.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Intuitively, if censoring induces a spuriously higher or lower overall distribution of scores than in the true population, we might learn a higher or lower threshold from the training data.",4.1. Disparate Benefit of the Doubt,[0],[0]
"If the true distribution will have more people with comparatively lower scores, the rate of false negatives will increase in the true population.",4.1. Disparate Benefit of the Doubt,[0],[0]
"This is to be expected if the censoring decision Z = 1 has itself an associated risk or cost, such as giving a loan.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Differences in the extent and effects of this censoring between groups, which is what we will define as disparate benefit of the doubt, can then give rise to non-zero residual inequity.",4.1. Disparate Benefit of the Doubt,[0],[0]
"This may occur if the censoring mechanism subjects the disadvantaged group to harsher screening than the advantaged group, so that disadvantaged screened-in individuals have higher probabilities of being positive (e.g., innocent or creditworthy) given the observables X,A.
We next derive three sufficient conditions for residual unfairness.",4.1. Disparate Benefit of the Doubt,[0],[0]
We explain how these can be interpreted in terms of the logging policy Z = 1 bestowing disparate benefit of the doubt with respect to the positive outcome Y,4.1. Disparate Benefit of the Doubt,[0],[0]
= 1 on the different groups.,4.1. Disparate Benefit of the Doubt,[0],[0]
"This disparate benefit of the doubt would be directly reflected in the distribution of risk scores in the training and target populations, which we will show necessarily leads to residual unfairness that disadvantages the same group that received comparatively lesser benefit of the doubt (or comparatively heightened suspicion), thus perpetuating historical prejudices.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We first state a simple rephrasing of the residual inequity of opportunity left by a fairness adjustment.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Recall that F
Z=1 a (✓), FT=1 a (✓) correspond to the false negative rate (FNR) when thresholding at ✓ on the training (censored) and test populations, respectively.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Let
a (✓) = FZ=1 a
(✓) F
T=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a (✓) denote the difference between true positive rates in the test population and training (censored) population.,4.1. Disparate Benefit of the Doubt,[0],[0]
Recall that Ŷ is an optimal derived equal opportunity classifier based on the training data if Ŷ = I[R̂ >,4.1. Disparate Benefit of the Doubt,[0],[0]
"✓
A ] and F
Z=1 a (✓ a ) = FZ=1 b",4.1. Disparate Benefit of the Doubt,[0],[0]
"(✓ b ) for every two groups a, b.2",4.1. Disparate Benefit of the Doubt,[0],[0]
"For short we refer to such a classifier as a derived equal oppor-
2Specifically, that the set of derived equal opportunity classi-
tunity classifier.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 1.,4.1. Disparate Benefit of the Doubt,[0],[0]
Let Ŷ = I[R̂,4.1. Disparate Benefit of the Doubt,[0],[0]
>,4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Then ✏T=1
a,b
= a (✓ a ) b (✓ b ).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Next, we define first-order stochastic dominance, which we use to express our first characterization of disparate benefit of the doubt.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Definition 3 (First-order stochastic dominance).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Let F , G be two CDFs.",4.1. Disparate Benefit of the Doubt,[0],[0]
"We write F G whenever F (✓) G(✓) 8✓.
CDFs describe the distribution of a population of real values.",4.1. Disparate Benefit of the Doubt,[0],[0]
"The stochastic dominance F G means that the population described by F has overall smaller values than the population described by G. Specifically, F G is equivalent to saying that for each unit in the population described by F we can find a nonnegative number such that, when added to each unit, the whole population looks like that described by G (Mas-Colell et al., 1997).",4.1. Disparate Benefit of the Doubt,[0],[0]
"That is, each unit from F can be uniquely paired with a unit from G such that the former has a smaller or equal value than the latter (allowing fractional or infinitesimal “units”).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Alternatively, F G holds if and only if the average of every increasing function in the F population is smaller than or equal to the corresponding average in the G population (Fishburn, 1980).",4.1. Disparate Benefit of the Doubt,[0],[0]
"This says that any rational actor with an increasing utility function would gain utility in choosing G over F and lose utility in choosing F over G (or get the same utility).
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 2 (Strong disparate benefit of the doubt).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Suppose that
F Z=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a FT=1 a and FZ=1 b ⌫ FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(2)
while not both are equalities, i.e., either FZ=1",4.1. Disparate Benefit of the Doubt,[0],[0]
a 6= FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
a or FZ=1 b 6= FT=1,4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(or both).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then every derived equal opportunity classifier has nonnegative inequity of opportunity for group b relative to group a (✏T=1
a,b 0) and at least one derived equal opportunity classifier will have a strictly positive inequity of opportunity disadvantaging group b relative to group a (✏T=1
a,b
> 0).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The condition in eq. (2) requires that the distribution of scores among positive group-a members is overall smaller in the training data than in the target population, while the opposite is true for group b. Recall that scores represent the probability of having the positive, favorable label (more on this in Sec. 4.2).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, the condition says that positive group-a members received more benefit of the doubt when
fiers that are optimal with respect to some trade off between type-I and -II errors is exactly equal to the set of all such thresholding classifiers requires only that we assume that, in each group A = a, R̂ is not worse than random guessing and that the ROC is convex.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Neither is without loss of generality as seen by only improving R̂ by conditionally (on A) negating R̂ and/or randomizing its value in nonconvex intervals between the endpoints.
being screened-in into the training data than positive groupb members.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Prop. 2 shows that this will necessarily lead to group-b being further disadvantaged in the future even after correcting for equality of opportunity.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"In the context of loan application, where we can think about the score as a credit score, eq. (2) means that the logging policy (i.e., historical loan approval practice) effectively dug deeper into the pile of creditworthy group-a applicants than for group-b applicants, giving the former more benefit of the doubt as to their creditworthiness based on their credit scores than it gave the latter.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Seen via the equivalent utility-based interpretation of stochastic dominance, given any increasing utility function, if eq. (2) holds then the logging policy is losing utility on group-a via lax screening while gaining utility on group-b by being less lax.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The complement (or, negative) of the score can be thought of as a risk score: the probability of the unfavorable label.",4.1. Disparate Benefit of the Doubt,[0],[0]
Eq. (2) can equivalently be written as the opposite ordering on risk scores rather than positivity scores.,4.1. Disparate Benefit of the Doubt,[0],[0]
"Thus, in either a judicial bail- or sentence-setting context or in a predictive policing context, eq. (2) means that the logging policy (i.e., historical criminal justice or policing practice) was harsher on group b than on group a, screening-in lower risk scores for innocent group-b members compared to the group-b population while screening-in only higher risk scores for group-a members, giving them more benefit of the doubt as to their innocence based on observables.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"If the CDFs are nowhere equal except for at 0 and 1 (where they are always equal) then a strict version of Prop. 2 shows that every derived equal opportunity classifier will be unfair.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"Proposition 3 (Strong disparate benefit of the doubt, strict).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Suppose eq. (2) holds and that FZ=1
a (✓) 6=",4.1. Disparate Benefit of the Doubt,[0],[0]
"F
T=1 a (✓), FZ=1 b (✓) 6=",4.1. Disparate Benefit of the Doubt,[0],[0]
"FT=1 b (✓) for all ✓ 2 (0, 1).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then every nontrivial derived equal opportunity classifier will have strictly positive inequity of opportunity disadvantaging group b relative to group a.
A nontrivial classifier is any classifier that is neither the constant Ŷ = 0 nor the constant Ŷ = 1.
",4.1. Disparate Benefit of the Doubt,[0],[0]
The conditions in Props.,4.1. Disparate Benefit of the Doubt,[0],[0]
2 and 3 are easy to interpret via stochastic dominance but may be too strong to hold in practice.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In particular, suppose the decision Z = 1 itself has a benefit or risk related to whether Y = 1, as in the case of giving a loan (benefit of earning the full interest over loan term compared to risk of a default) or a police stop (benefit of curtailing crime compared to costs, including societal, of aggressive policing).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Then, if the decision Z = 1 is exercised rationally, then we would expect that the distribution of scores is either overall higher (e.g., for loans) or overall lower (e.g., for police stops) in the training population regardless of group, i.e., both FZ=1
a
⌫ FT=1 a and FZ=1 b ⌫ F
T=1 b or both FZ=1 a
FT=1 a and FZ=1 b
FT=1 b .",4.1. Disparate Benefit of the Doubt,[0],[0]
"(Al-
though, prejudice in Z = 1 can be so overt and/or irrational for this not to hold.)",4.1. Disparate Benefit of the Doubt,[0],[0]
"If this is the case, then the conditions of Props.",4.1. Disparate Benefit of the Doubt,[0],[0]
"2 and 3 cannot hold and we must relax them.
",4.1. Disparate Benefit of the Doubt,[0],[0]
"The next result shows that even if the stochastic dominance holds in the same direction for both groups, if the magnitude of the dominance is overall larger in one group compared to the other for a large swath of thresholds then most derived equal opportunity classifiers will actually be unfair and disadvantage the historically disadvantaged.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Proposition 4 (Weak disparate benefit of the doubt, strict).",4.1. Disparate Benefit of the Doubt,[0],[0]
"Let ✓, ✓ be such that
a (✓) >",4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(✓0) 8✓, ✓0 2 (✓, ✓).",4.1. Disparate Benefit of the Doubt,[0],[0]
"(3)
Let Ŷ = I[R̂ >",4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"If ✓
a
, ✓
b 2 (✓, ✓), then Ŷ induces a strictly positive inequality of opportunity disadvantaging group b relative to group a.
Note that, since A (0) =",4.1. Disparate Benefit of the Doubt,[0],[0]
"A (1) = 0, we have that eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(3) holds for (✓, ✓) = (0, 1) if and only if the conditions of Prop. 3 hold.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Therefore, for general (✓, ✓) the former can be understood as a relaxation of the latter.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We can illustrate the conditions of Prop. 4 in the synthetic loan application example from the beginning of this section.,4.1. Disparate Benefit of the Doubt,[0],[0]
In Fig.,4.1. Disparate Benefit of the Doubt,[0],[0]
"3b, we plot the two
A functions and shade a large interval where eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
(3) holds.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In Fig. 3a, we plot the CDFs F E
A and further shade the corresponding regions of false negative rates for which both ✓0 and ✓1 lie the previously shaded interval.",4.1. Disparate Benefit of the Doubt,[0],[0]
"Taking complements, this shows that any derived equal opportunity classifier adjusted to have equal true positive rates of 0.58–0.95 on the training data will disadvantage the underprivileged class despite one’s attempt to adjust against this situation.
",4.1. Disparate Benefit of the Doubt,[0],[0]
We can slightly relax the condition in eq.,4.1. Disparate Benefit of the Doubt,[0],[0]
"(3) whenever dealing with groups that have disparate endowments of scores, as in the example above where the scores of group 0 are overall larger than those of group 1 in terms of stochastic dominance.
",4.1. Disparate Benefit of the Doubt,[0],[0]
Proposition 5 (Weak disparate benefit of the doubt on disparately endowed groups).,4.1. Disparate Benefit of the Doubt,[0],[0]
"Let ✓, ✓ be such that
a (✓) >",4.1. Disparate Benefit of the Doubt,[0],[0]
"b
(✓0) 8✓, ✓0 2 (✓, ✓) : ✓ ✓0.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(4)
Suppose FZ=1 a ⌫ FZ=1 b .",4.1. Disparate Benefit of the Doubt,[0],[0]
Let Ŷ = I[R̂,4.1. Disparate Benefit of the Doubt,[0],[0]
>,4.1. Disparate Benefit of the Doubt,[0],[0]
✓ A ] be a derived equal opportunity classifier.,4.1. Disparate Benefit of the Doubt,[0],[0]
"If ✓
a
, ✓
b 2 (✓, ✓), then Ŷ induces a strictly positive inequality of opportunity disadvantaging group b relative to group a.
In the supplemental Sec.",4.1. Disparate Benefit of the Doubt,[0],[0]
B we also include an illustration of weak disparate benefit of the doubt in a real dataset of credit card applications and payment defaults.,4.1. Disparate Benefit of the Doubt,[0],[0]
"In addition to making more concrete our crediting example, this also serves to illustrate the weaker condition in eq. (4).
",4.1. Disparate Benefit of the Doubt,[0],[0]
"All of our results in this section can be equivalently stated for true negative rates instead of true positive rates, in which case the corresponding conditions such as that in eq.",4.1. Disparate Benefit of the Doubt,[0],[0]
"(2) can instead be interpreted as disparate suspicion, i.e., the disparate scrutiny of truly criminal or credit-unworthy individuals.",4.1. Disparate Benefit of the Doubt,[0],[0]
"So, whereas our notion of disparate benefit of the doubt corresponds to the phenomenon of “driving while black” (Lamberth, 1998), our notion of disparate suspicion would correspond to the phenomenon of “criming while white” (Goldfarb, 2014).",4.1. Disparate Benefit of the Doubt,[0],[0]
"If either disparate benefit of the doubt or disparate suspicion is present, a derived equalized odds classifier will in fact violate equalized odds in a way that disadvantages the same group that was disadvantaged by the disparate benefit of the doubt or suspicion.",4.1. Disparate Benefit of the Doubt,[0],[0]
In the above we interpreted the conditions in our results as disparities in the distributions of positivity or risk scores among different groups in the training and target populations.,4.2. Interpretation of Scores Under MAR,[0],[0]
"Specifically, we interpreted these scores as corresponding to the probabilities of having a positive or negative label given observables.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In full generality, however, this probability might actually be different in the training and target populations, i.e., P (Y = 1 | X,A,Z = 1) 6=",4.2. Interpretation of Scores Under MAR,[0],[0]
"P (Y = 1 | X,A, T = 1).",4.2. Interpretation of Scores Under MAR,[0],[0]
"Since naturally only the training data is available at training we can consider the trainingpopulation Bayes score R̂ = P (Y = 1 | X,A,Z = 1) and interpret disparities as disparities in benefit of the doubt of positivity given this score.",4.2. Interpretation of Scores Under MAR,[0],[0]
"This is consistent with our interpretation above.
",4.2. Interpretation of Scores Under MAR,[0],[0]
"However, whenever censoring Z = 1 is itself based on observables, the data will be missing conditionally at random (MAR) and these probabilities will actually be the same so that we can interpret the scores as simply the probability of positivity given observables generally.",4.2. Interpretation of Scores Under MAR,[0],[0]
Assumption 1.,4.2. Interpretation of Scores Under MAR,[0],[0]
(MAR) Z ?,4.2. Interpretation of Scores Under MAR,[0],[0]
"Y | X,A and T ?",4.2. Interpretation of Scores Under MAR,[0],[0]
"Y | X,A.
Under MAR, it is immediate that the Bayes score satisfies R̂ = P (Y = 1 | X,A) = P (Y = 1 | X,A,Z = 1) =
P (Y = 1 | X,A, T = 1), which can be consistently estimated from training data.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In fact, under MAR, the optimal (unrestricted) decision function in X,A minimizing the average over Z = 1 of any loss in Y is the same as that minimizing the average loss over T = 1.
MAR requires that the missingness is unrelated to outcome after controlling for the observables.",4.2. Interpretation of Scores Under MAR,[0],[0]
"This assumption is clearly satisfied in the common case when T = 1 is constant and only X,A (or just X) were taken into consideration for a randomized inclusion policy Z. In the examples laid out in Sec. 1, this is an appropriate assumption because the censoring mechanism does not observe outcomes Y a priori, only observable characteristics (including the protected attribute).",4.2. Interpretation of Scores Under MAR,[0],[0]
"However, violations of MAR may occur, for example in the loan case if applicants may choose an outside option, selfcensoring the observation of a default while the availability of these options is related to creditworthiness.",4.2. Interpretation of Scores Under MAR,[0],[0]
"In rare situations, we may have additional information about the target population such as an unlabeled dataset.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"We next show how we can use such data to evaluate accuracy metrics on the target population, as long as data is MAR.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This will allow us to assess the residual unfairness of fairness adjusted classifiers, as we will do in our study of SQF, and to correctly adjust for fairness, as we have done in Fig. 2b.
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Let p(x, a) = P(T=1|X=x,A=a)P(Z=1|X=x,A=a) be the propensity score ratio between the target and training populations.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This ratio is a standard way to adjust for systematic covariate shift for evaluating averages in the target (Horvitz & Thompson, 1952; Bottou et al., 2012).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
We next state how a weighting score that’s equal to it up to proportionality in a can be used for evaluating true positive rates.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
Proposition 6.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Suppose p̃(x, a) = r(a)p(x, a) for some r(a) and Ŷ ?",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"(Y, Z, T )",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"| X,A.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Then, under Assumption 1, P(Ŷ = 1 | Y = y,A = a, T = 1) is equal to
E[I[Ŷ=1,Y=y,A=a]p̃(X,A)|Z=1]P ŷ2{0,1} E[I[Ŷ=ŷ,Y=y,Z=1,A=a]p̃(X,A)|Z=1]
(5)
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Given p̃(x, a), the quantity in eq. (5) involves only the distribution of the training data.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"In practice, the expectations in it can be estimated using empirical averages over the training data.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Therefore, if we can compute an appropriate weighting function p̃(x, a), Prop. 6 provides a remedy to the problem of biased data: we may simply replace the condition in Def. 1, which involves an unknown distribution X,A, Y | T = 1, with the condition that eq. (5) is constant over a (for y 2 {0, 1} or for y = 1).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"In particular, to apply the equality of opportunity adjustment on the target population, we need only compute the TPRs and/or FPRs of
any blackbox predictor using the adjustment of eq.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"(5) and proceed with the adjustment as usual.
",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Next we address when can we find an appropriate reweighting score p̃(x, a).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
We consider two cases.,5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"If Z = 1 is a subpopulation of T = 1 and our data consists of iid draws from the target population population but where, naturally, only the Z = 1 units are labeled, then may simply let p̃(x, a) be the reciprocal of the conditional probability of being labeled, which may be estimated using a probabilistic classification algorithm such as logistic regression.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"This case applies, for example, in the loan approval policy example if the data includes the full loan applications, whether they were approved, and whether the approved loans defaulted or were paid back.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"If, however, our data consists only of the labeled examples, as in the case of arrest and SQF data, which contain only the arrests or stops made and, naturally, never any information on those not made, then this case does not apply.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"But, if we have an unlabeled dataset from the target population, then we can separately estimate the distribution of X,A in the training and target distributions.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"Then we may let p̃(x, a) be either the ratio of densities of X,A in T = 1 and Z = 1 or the ratio of densities of X in T = 1, A = a and Z = 1, A = a.
In supplemental Sec.",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"C we provide additional results characterizing residual unfairness under MAR in terms of p̃(x, a).",5. Fairness Assessment and Adjustment with Biased Data via Sample Reweighting,[0],[0]
"We next study the Stop, Question, and Frisk dataset to illustrate how residual unfairness may occur with real data.","6. Case Study: Stop, Question, and Frisk",[0],[0]
We consider learning a predictor of criminal possession of a weapon from this dataset using logistic regression and then adjusting the policy to be fair on the training population.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"The trained policy will be applied to the target population of New York City at large, where it will be shown to in fact be unfair.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"This residual unfairness can be explained by disparities between the training population (SQF stops) and the target population (NYC), which is evident from the divergent geographic distributions of these two as seen in Fig. 4.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"(Further details about SQF and the dataset are provided in the supplemental Sec. D.)
Table 2: Residual unfairness in SQF predictive targeting
Goel et al. (2016) considered learning predictors from this data as a way to assess the implied decision thresholds used for determining pedestrian stops related to the criteria of “reasonable suspicion.”","6. Case Study: Stop, Question, and Frisk",[0],[0]
"While the authors suggest that a logistic regression predictor of criminal possession of a weapon could be used as a secondary filter applied on those individuals targeted by officers, we instead consider training such a predictive model to guide whom to target for a stop and search and adjusting this targeting policy for fairness.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We consider race to be the protected class A, with values Black, Black Hispanic, White, White Hispanic, and Other.3 Arrest data or SQF data only contain the arrests or stops made and, naturally, never any information on those not made.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Since biases in the demographics of stop data arise from disproportionate policing by location and potential racial biases, we define the target population with respect to demographic data about NYC precincts.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Letting X1 denote the precinct-encoding portion of the covariates and X2 denote all other covariates (which include 30 indicators of reasons for suspicion, sex, and location or stop), we set P(X1, A | T = 1) to be the same distribution as that of the population of NYC.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We further assume that, once we condition on the main sources of bias, (X1, A), the covariates X2 are not disproportionate between the training and target distribution: we set P(X2 | A,X1, T = 1) = P(X2 | A,X1, Z = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
"That is, the main sources of systematic bias with respect to censored data are contained in X1 and A, while ancillary covariates X2 are not proxies for discrimination.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"We then have that p̃(X,A) = P(A,X1|T=1)P(A,X1|Z=1) satisfies the conditions of Prop. 6","6. Case Study: Stop, Question, and Frisk",[0],[0]
"so we need only estimate P(A,X1 | Z = 1), P(A,X1 | T = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
We estimate the former from the SQF data and the latter from the 2010 American Community Survey data by matching census blocks to precincts and using Laplace smoothing.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"We clip the ratio weights at 10.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Using the SQF data as is, we fit a logistic regression R̂ to predict the probability of innocence, that a search would not recover a weapon from those suspected of criminal possess-
3Due to the relative size of the Asian/Pacific Islander and Native American classes included in the original SQF dataset, we combine them with the Other (U) class.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
ing one based on the covariates X .,"6. Case Study: Stop, Question, and Frisk",[0],[0]
Fig. 5 shows the FNR discrepancies between training and target and the ROCs in each.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"We consider deriving both an equal opportunity classifier and an equalized odds classifier for a stop and search based on the SQF data to minimize false negatives and false positives at an exchange rate of 25:1.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"In Table 2, we report the estimated true positive and false positive rates achieved by these classifiers both in the training and in the target population.","6. Case Study: Stop, Question, and Frisk",[0],[0]
The latter is computed using Prop. 6.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
FNRs quantify the percent of innocents wrongly targeted and FPRs quantify the percent of criminals undetected.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"By construction, the adjusted-for rates are equal in the training population (Z = 1).","6. Case Study: Stop, Question, and Frisk",[0],[0]
"However, in practice, residual unfairness remains in the target population even after adjustment, and both of these supposedly fair classifiers will systematically disadvantage the same groups that were previously disparately targeted.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"For the equal-opportunity-adjusted classifier, whereas only 11% of white-non-Hispanic innocents are wrongly targeted, up to 20% of white-Hispanic, 16% of other, and 14–15% of black innocents are wrongly targeted and harassed.","6. Case Study: Stop, Question, and Frisk",[0],[0]
Similar disparities exist for the equalized-odds-adjusted classifier.,"6. Case Study: Stop, Question, and Frisk",[0],[0]
"The equalized odds policy, having been subject to additional constraints that require more randomization and hence less dependence on observables, induces smaller but still significant disparities and Hispanics remain particularly disproportionately burdened.
","6. Case Study: Stop, Question, and Frisk",[0],[0]
"In all cases, after fairness adjustment, non-white individuals were still unfairly disadvantaged in practice relative to white individuals, thus perpetuating the same biases that SQF is notorious for under the guise of a policy adjusted to be fair.","6. Case Study: Stop, Question, and Frisk",[0],[0]
"Our work characterizes the problem of residual unfairness, which arises when policies learned from biased datasets are adjusted for fairness but remain unfair in practice.",7. Conclusion,[0],[0]
"We study a general setting where the dataset is generated under a prejudiced historical policy, which captures the structure of many problem settings where fairness has been considered.",7. Conclusion,[0],[0]
We prove that the same prejudices will be reflected in the supposedly-fairness-adjusted policy.,7. Conclusion,[0],[0]
Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies.,abstractText,[0],[0]
We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies.,abstractText,[0],[0]
This scenario is particularly common in the same applications where fairness is a concern.,abstractText,[0],[0]
We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear.,abstractText,[0],[0]
"We prove that, under certain conditions, fairnessadjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-theart fair machine learning can have a “bias in, bias out” property.",abstractText,[0],[0]
"When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring.",abstractText,[0],[0]
"We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.",abstractText,[0],[0]
Residual Unfairness in Fair Machine Learning from Prejudiced Data,title,[0],[0]
"Objective: This paper develops a novel tree-based algorithm, called Bonsai, which can be trained on a laptop, or the cloud, and can then be shipped onto severely resource constrained Internet of Things (IoT) devices.
",1. Introduction,[0],[0]
"Resource constrained devices: The Arduino Uno board has an 8 bit ATmega328P microcontroller operating at 16 MHz with 2 KB SRAM and 32 KB read-only flash mem-
1Microsoft Research, Bangalore, India 2CSE Department, IIT Delhi, India.",1. Introduction,[0],[0]
"Correspondence to: <manik@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
ory.,1. Introduction,[0],[0]
The BBC Micro:Bit has a 32 bit ARM Cortex M0 microcontroller operating at 16 MHz with 16 KB SRAM and 256 KB read-only flash.,1. Introduction,[0],[0]
Neither provides hardware support for floating point operations.,1. Introduction,[0],[0]
"Billions of such tiny IoT microcontrollers have been deployed in the world (Meunier et al., 2014).",1. Introduction,[0],[0]
"Before deployment, the OS and all application code and data are burnt onto flash, leaving only a few KB for storing the trained ML model, prediction code, feature extraction code and associated data and parameters.",1. Introduction,[0],[0]
"After deployment, the only writable memory available is the 2 KB (Uno) or 16 KB (Micro:Bit) of SRAM which might not be sufficient to hold even a single feature vector.
",1. Introduction,[0],[0]
"The Internet of Things: A number of applications have been developed for consumer, enterprise and societal IoT including predictive maintenance, intelligent healthcare, smart cities and housing, etc.",1. Introduction,[0],[0]
"The dominant paradigm for these applications, given the severe resource constraints of IoT devices, has been that the IoT device is dumb – it just senses its environment and transmits the sensor readings to the cloud where all the decision making happens.
",1. Introduction,[0],[0]
Motivating scenarios: This paper proposes an alternative paradigm where the IoT device can make predictions locally without necessarily connecting to the cloud.,1. Introduction,[0],[0]
"This enables many scenarios, beyond the pale of the traditional paradigm, where it is not possible to transmit data to the cloud due to latency, bandwidth, privacy and energy concerns.",1. Introduction,[0],[0]
"For instance, consider a microcontroller implanted in the brain which warns patients about impending seizures so that they can call for help, pull over if they are driving, etc.",1. Introduction,[0],[0]
Making predictions locally would allow the device to work everywhere irrespective of cloud connectivity.,1. Introduction,[0],[0]
"Furthermore, alerts could be raised more quickly with local predictions than if all the sensor readings had to be first transmitted to the cloud.",1. Introduction,[0],[0]
"In addition, since the energy required for executing an instruction might be much lower than the energy required to transmit a byte, making predictions locally would extend battery life significantly thereby avoiding repeated brain surgery and might also prevent brain tissue damage due to excess heat dissipation from the communicating radio.",1. Introduction,[0],[0]
"Finally, people might not be willing to transmit such sensitive data to the cloud.",1. Introduction,[0],[0]
"These characteristics are shared by many other scenarios including implants in the heart, precision agriculture on disconnected farms, smart spectacles for the visually impaired, etc.
Tree algorithms: Tree algorithms are general and can be used for classification, regression, ranking and other problems commonly found in the IoT setting.",1. Introduction,[0],[0]
"Even more importantly, they are ideally suited to IoT applications as they can achieve good prediction accuracies with prediction times and energies that are logarithmic in the number of training points.",1. Introduction,[0],[0]
"Unfortunately, they do not directly fit on tiny IoT devices as their space complexity is linear rather than logarithmic.",1. Introduction,[0],[0]
"In particular, learning shallow trees, or aggressively pruning deep trees or large ensembles, to fit in just a few KB often leads to poor prediction accuracy.
",1. Introduction,[0],[0]
Bonsai:,1. Introduction,[0],[0]
"This paper develops a novel tree learner, called Bonsai, designed specifically for severely resource constrained IoT devices based on the following contributions.",1. Introduction,[0],[0]
"First, Bonsai learns a single, shallow, sparse tree so as to reduce model size but with powerful nodes for accurate prediction.",1. Introduction,[0],[0]
"Second, both internal and leaf nodes in Bonsai make non-linear predictions.",1. Introduction,[0],[0]
Bonsai’s overall prediction for a point is the sum of the individual node predictions along the path traversed by the point.,1. Introduction,[0],[0]
Path based prediction allows Bonsai to accurately learn non-linear decision boundaries while sharing parameters along paths to further reduce model size.,1. Introduction,[0],[0]
"Third, Bonsai learns a sparse matrix which projects all data points into a low-dimensional space in which the tree is learnt.",1. Introduction,[0],[0]
This allows Bonsai to fit in a few KB of flash.,1. Introduction,[0],[0]
"Furthermore, the sparse projection is implemented in a streaming fashion thereby allowing Bonsai to tackle IoT applications where even a single feature vector might not fit in 2 KB of RAM.",1. Introduction,[0],[0]
"Fourth, rather than learning the Bonsai tree node by node in a greedy fashion, all nodes are learnt jointly, along with the sparse projection matrix, so as to optimally allocate memory budgets to each node while maximising prediction accuracy.
",1. Introduction,[0],[0]
Implementation: Another contribution is an efficient implementation of Bonsai which reduces its prediction costs on the Arduino and Micro:Bit to be even lower than that of an unoptimized linear classifier.,1. Introduction,[0],[0]
This allows Bonsai to enjoy the prediction accuracy of a non-linear classifier while paying less than linear costs.,1. Introduction,[0],[0]
"This paper does not focus on the system and implementation details due to space limitations but the interested reader is referred to the publically available source code (BonsaiCode).
",1. Introduction,[0],[0]
"Results: These contributions allow Bonsai to make predictions in milliseconds even on slow microcontrollers, fit in a few KB of flash and extend battery life beyond all other algorithms.",1. Introduction,[0],[0]
"Furthermore, it is demonstrated on multiple benchmark datasets that Bonsai’s prediction accuracies can approach those of uncompressed kNN classifiers, RBFSVMs, single hidden layer neural networks and gradient boosted decision tree ensembles whose models might take many MB of RAM.",1. Introduction,[0],[0]
"It is also demonstrated that Bonsai’s prediction accuracies for a given model size can be as much
as 30% higher than state-of-the-art methods for resourceefficient machine learning.",1. Introduction,[0],[0]
"Finally, Bonsai is shown to generalize to other resource constrained settings beyond IoT by producing significantly better search results than Bing’s L3 ranker when the model size is restricted to 300 bytes.",1. Introduction,[0],[0]
"The literature on resource-efficient machine learning is vast and specialized solutions have been developed for reducing the prediction costs of kNN algorithms (Kusner et al., 2014b; Wang et al., 2016), SVMs (Hsieh et al., 2014; Jose et al., 2013; Le et al., 2013; Li et al., 2016), deep learning (Iandola et al., 2016; Han et al., 2016; Yang et al., 2015; Denton et al., 2014; Wu et al., 2016; Rastegari et al., 2016; Hubara et al., 2016; Shankar et al., 2016; Ioannou et al., 2016a), model compression (Bucilua et al., 2006; Ba & Caruana, 2014), feature selection (Kusner et al., 2014a; Xu et al., 2013; 2012; Nan et al., 2015; Wang et al., 2015) and applications such as face detection (Viola & Jones, 2004).
",2. Related Work,[0],[0]
Resource-efficient tree classifiers are particularly germane to this paper.,2. Related Work,[0],[0]
The standard approach is to greedily grow the decision tree ensemble node by node until the prediction budget is exhausted.,2. Related Work,[0],[0]
"A popular alternative is to first learn the random forest or gradient boosted decision tree ensemble to maximize prediction accuracy and then use pruning techniques to meet the budget constraints (Duda et al., 2002; Dekel et al., 2016; Nan et al., 2016; Li, 2001; Breiman et al., 1984; Zhang & Huei-chuen, 2005; Sherali et al., 2009; Kulkarni & Sinha, 2012; Rokach & Maimon, 2014; Joly et al., 2012).",2. Related Work,[0],[0]
"Unfortunately, such techniques are fundamentally limited as they attempt to approximate complex non-linear decision boundaries using a small number of axis-aligned hyperplanes.",2. Related Work,[0],[0]
"This can lead to poor prediction accuracies as observed in Section 5.
",2. Related Work,[0],[0]
Tree models have also been developed to learn more complex decision boundaries by moving away from learning axis-aligned hyperplanes at internal nodes and constant predictors at the leaves.,2. Related Work,[0],[0]
"For instance, (Breiman, 2001; Murthy et al., 1994; Kontschieder et al., 2015) learnt more powerful branching functions at internal nodes based on oblique cuts and full hyperplanes while (Utgoff, 1989; Hsieh et al., 2014) learnt more powerful leaf node predictors based on linear classifiers, kernelized SVMs, etc.",2. Related Work,[0],[0]
"Bonsai achieves better budget utilization than such models by learning shorter trees, typically depth 4 or lower, and by sharing the parameters between leaf node predictors.
",2. Related Work,[0],[0]
"The models closest to Bonsai are Decision Jungles (Shotton et al., 2013) and LDKL (Jose et al., 2013).",2. Related Work,[0],[0]
"Bonsai improves upon LDKL by learning its tree in a lowdimensional space, learning sparse branching functions and predictors and generalizing the model to multi-class classi-
fication, ranking, etc.",2. Related Work,[0],[0]
Decision Jungles are similar to Bonsai in that they share node parameters using a DAG structure.,2. Related Work,[0],[0]
"Unfortunately, Decision Jungles need to learn deep tree ensembles with many nodes as they use weak constant classifiers as leaf node predictors.",2. Related Work,[0],[0]
"Bonsai can have lower model size and higher accuracy as it learns a single, shallow tree in a low-dimensional space with non-linear predictors.
",2. Related Work,[0],[0]
"Note that while tree based cost-sensitive feature selection methods are not directly relevant, their performance is nevertheless empirically compared to Bonsai’s in Section 5.",2. Related Work,[0],[0]
Overview:,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Bonsai learns a single, shallow sparse tree whose predictions for a point x are given by
y(x) =",3. The Bonsai Model for Efficient Prediction,[0],[0]
∑ k Ik(x)W > k,3. The Bonsai Model for Efficient Prediction,[0],[0]
Zx ◦,3. The Bonsai Model for Efficient Prediction,[0],[0]
"tanh(σV>k Zx) (1)
where ◦ denotes the elementwise Hadamard product, σ is a user tunable hyper-parameter, Z is a sparse projection matrix and Bonsai’s tree is parameterized by Ik, Wk and Vk where Ik(x) is an indicator function taking the value 1 if node k lies along the path traversed by x and 0 otherwise and Wk and Vk are sparse predictors learnt at node k.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"The prediction function is designed to minimize the model size, prediction time and prediction energy, while maintaining prediction accuracy, even at the expense of increased training costs.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"The function is also designed to minimize the working memory required as the Uno provides only 2 KB of writeable memory for storing the feature vector, programme variables and intermediate computations.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Streaming sparse projection: Bonsai projects each D-dimensional input feature vector x into a low D̂dimensional space using a learnt sparse projection matrix ZD̂×D. Bonsai uses fixed point arithmetic for all math computation, including Zx, when implemented on the IoT device so as to avoid floating point overheads.",3. The Bonsai Model for Efficient Prediction,[0],[0]
Note that D̂ could be as low as 5 for many binary classification applications.,3. The Bonsai Model for Efficient Prediction,[0],[0]
This has the following advantages.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"First, it reduces Bonsai’s model size as all tree parameters are now learnt in the low-dimensional space.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Second, when D̂ is small, Zx could be stored directly in the microcontroller’s registers thereby reducing prediction time and energy.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Third, learning the projection matrix jointly with the tree parameters improves prediction accuracy.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Fourth, since Zx can be computed in a streaming fashion, this allows Bonsai to tackle IoT applications where even a single feature vector cannot fit in 2 KB of SRAM.",3. The Bonsai Model for Efficient Prediction,[0],[0]
This is critical since standard tree implementations are unable to handle a streaming feature vector – the entire feature vector needs to be streamed for the root node to determine whether to pass the point down to the left or right child and therefore the vector is unavailable for processing at subsequent nodes.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Some
implementations work around this limitation by simultaneously evaluating the branching function at all nodes as the vector is streamed but this increases the prediction costs from logarithmic to linear which might not be acceptable.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
Branching function at internal nodes: Bonsai computes Ik by learning a sparse vector θ at each internal node such that the sign of θ>Zx determines whether point x should be branched to the node’s left or right child.,3. The Bonsai Model for Efficient Prediction,[0],[0]
Using more powerful branching functions than the axis-aligned hyperplanes in standard decision trees allows Bonsai to learn shallow trees which can fit in a few KB.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Of course, this is not a novel idea, and is insufficient in itself to allow a single, shallow decision tree to make accurate predictions.
",3. The Bonsai Model for Efficient Prediction,[0],[0]
"Node predictors: Decision trees, random forests and boosted tree ensembles are limited to making constant predictions at just the leaf nodes.",3. The Bonsai Model for Efficient Prediction,[0],[0]
This restricts their prediction accuracy when there are very few leaves.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"In contrast, for a multi-class, multi-label or regression problem with L targets, Bonsai learns matrices WD̂×L and VD̂×L at both leaf and internal nodes so that each node predicts the vector W>Zx◦tanh(σV>Zx).",3. The Bonsai Model for Efficient Prediction,[0],[0]
Note that the functional form of the node predictor was chosen as it was found to work well empirically (other forms could be chosen if found to be more appropriate).,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Further note that W and V will reduce to vectors for binary classification, ranking and singletarget regression.",3. The Bonsai Model for Efficient Prediction,[0],[0]
Bonsai’s overall predicted vector is given by (1) and is the sum of the individual vectors predicted by the nodes lying along the path traversed by x. This allows Bonsai to accurately learn non-linear decision boundaries using shallow trees with just a few nodes.,3. The Bonsai Model for Efficient Prediction,[0],[0]
"Furthermore, path based prediction allows parameter sharing and therefore reduces model size as compared to putting independent classifiers of at least equal complexity in the leaf nodes alone.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"For instance, a depth 4 Bonsai tree with 15 internal and 16 leaf nodes stores 31 W and 31 V matrices with overall predictions being the sum of 4 terms depending on the path taken.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"If parameters were not shared and each leaf node independently learnt 4 W and 4 V matrices to make predictions of at least equal complexity, then a total of 16× 4 = 64 W and 64 V matrices would need to be stored thereby exceeding the memory budget.",3. The Bonsai Model for Efficient Prediction,[0],[0]
"As an implementation detail, note that Bonsai uses the approximation tanh(x)",3. The Bonsai Model for Efficient Prediction,[0],[0]
≈ x,3. The Bonsai Model for Efficient Prediction,[0],[0]
if |x| < 1 and signum(x) otherwise in order to avoid floating point computation.,3. The Bonsai Model for Efficient Prediction,[0],[0]
Notation: Bonsai learns a balanced tree of user specified height h with 2h − 1 internal nodes and 2h leaf nodes.,4. Training Bonsai,[0],[0]
The parameters that need to be learnt include: (a) Z: the sparse projection matrix; (b) θ =,4. Training Bonsai,[0],[0]
"[θ1, . . .",4. Training Bonsai,[0],[0]
",θ2h−1]: the parameters of the branching function at each internal node; and (c) W =",4. Training Bonsai,[0],[0]
"[W1, . . .",4. Training Bonsai,[0],[0]
",W2h+1−1] and V =",4. Training Bonsai,[0],[0]
"[V1, . . .",4. Training Bonsai,[0],[0]
",V2h+1−1]:
the predictor parameters at each node.",4. Training Bonsai,[0],[0]
Let Θ =,4. Training Bonsai,[0],[0]
"[θ,W,V] denote a matrix obtained by stacking all the parameters together except for Z. Finally, it is assumed that N training points {(xi, y
¯i )Ni=1} have been provided and that bud-
get constraints BZ and BΘ on the projection matrix and tree parameters have been specified depending on the flash memory available on the IoT device.
",4. Training Bonsai,[0],[0]
"Optimization problem: Bonsai’s parameters are learnt as
min Z,Θ J (Z,Θ) = λθ 2 Tr(θ>θ) + λW 2 Tr(W>W)
+ λV 2 Tr(V>V) + λZ 2 Tr(ZZ>)
+ 1
N N∑ i=1",4. Training Bonsai,[0],[0]
"L(xi,yi,y(xi);Z,Θ)
s. t. ‖Z‖0 ≤",4. Training Bonsai,[0],[0]
"BZ, ‖Θ‖0 ≤ BΘ
(2)
where y(xi) is Bonsai’s prediction for point xi as given in (1) and L is an appropriately chosen loss function for classification, regression, ranking, etc.",4. Training Bonsai,[0],[0]
"For instance, L = max(0, 1 − yiy(xi))",4. Training Bonsai,[0],[0]
"with yi ∈ {−1,+1} for binary classification and L = maxy∈Y((yi − y)>y(xi) +",4. Training Bonsai,[0],[0]
"1 − y>i y) with Y = {y|y ∈ {0, 1}L,1>y = 1} and yi ∈ Y for multi-class classification.",4. Training Bonsai,[0],[0]
It is worth emphasizing that the optimization problem is formulated such that all parameters are learnt jointly subject to the budget constraints.,4. Training Bonsai,[0],[0]
"This leads to significantly higher prediction accuracies than if Z were first learnt independently, say using sparse PCA, and then Θ was learnt afterwards (see Section 5).
",4. Training Bonsai,[0],[0]
"Algorithm: Optimizing (2) over the space of all balanced trees of height h is a hard, non-convex problem.",4. Training Bonsai,[0],[0]
Tree growing algorithms typically optimize such problems by greedily growing the tree a node at a time starting from the root.,4. Training Bonsai,[0],[0]
"Unfortunately, this leads to a suboptimal utilization of the memory budget in Bonsai’s case as it is not clear a priori how much budget to allocate to each node.",4. Training Bonsai,[0],[0]
"For instance, it is not apparent whether the budget should be distributed equally between all nodes or whether the root node should be allocated more budget and, if so, by how much.
",4. Training Bonsai,[0],[0]
Algorithm - Joint learning of nodes: Bonsai therefore learns all node parameters jointly with the memory budget for each node being determined automatically as part of the optimization.,4. Training Bonsai,[0],[0]
The difficulty with joint learning is that a node’s ancestors need to be learnt before it can be determined which training points will reach the node.,4. Training Bonsai,[0],[0]
"Furthermore, the path traversed by a training point is a sharply discontinuous function of θ and Z thereby rendering gradient based techniques ineffective.",4. Training Bonsai,[0],[0]
"Various approaches have been proposed in the literature for tackling these difficulties (Jose et al., 2013; Kontschieder et al., 2015; Norouzi et al., 2015; Xu et al., 2013; Ioannou et al., 2016b).",4. Training Bonsai,[0],[0]
"Bonsai follows the approach of (Jose et al., 2013)
and smooths the objective function by initially allowing points to traverse multiple paths in the tree.",4. Training Bonsai,[0],[0]
"In particular, the indicator function Ik(x) is relaxed to Ik>1(x) = 1 2Ij(x) ( 1 + (−1)k−2j tanh(σIθ>j Zx) ) where j = ⌊ k 2 ⌋ is k’s parent node in a balanced tree, I1(x)",4. Training Bonsai,[0],[0]
= 1 and the parameter σI controls the fidelity of the approximation.,4. Training Bonsai,[0],[0]
"Gradients can now be computed as
∇θlIk(x) = σIIk(x)P lk(x)Zx (3) ∇ZIk(x) =",4. Training Bonsai,[0],[0]
∑ l σIIk(x)P,4. Training Bonsai,[0],[0]
"l k(x)θlx > (4)
where P lk(x) = δ l k((−1)Ck(l)",4. Training Bonsai,[0],[0]
"− tanh(σIθ>l Zx)), δlk = 1 if node l is an ancestor of node k and 0 otherwise and Ck(l) = 1 if node k is in the right subtree of node l and 0 otherwise.",4. Training Bonsai,[0],[0]
"Of course, allowing a point to traverse multiple paths increases prediction costs.",4. Training Bonsai,[0],[0]
"Some approaches therefore allow multiple paths during training but select a single path during prediction (Xu et al., 2013; Ioannou et al., 2016b).",4. Training Bonsai,[0],[0]
"At each node, a point x is greedily branched to the child node having the greatest Ik(x).",4. Training Bonsai,[0],[0]
"Unfortunately, this can lead to a drop in accuracy as the model learnt during training is different from the one used for prediction.
",4. Training Bonsai,[0],[0]
Bonsai therefore follows an alternative strategy where σI is tuned during training to ensure that points gradually start traversing at most a single path as optimization progresses.,4. Training Bonsai,[0],[0]
"In particular, σI is initialized to a small value, such as 0.01, so as to ensure that tanh values are not saturated.",4. Training Bonsai,[0],[0]
"As optimization progresses, σI is gradually increased so that tanh tends to the signum function and Ik(x) goes back to being an indicator function by the time convergence is reached.",4. Training Bonsai,[0],[0]
"This allows Bonsai to directly use the learnt model for prediction and was found to empirically lead to good results.
",4. Training Bonsai,[0],[0]
"Algorithm - Gradient descent with iterative hard thresholding: Various gradient based approaches, including those based on alternating minimization, were tried for optimizing (2).",4. Training Bonsai,[0],[0]
A gradient descent based algorithm with iterative hard thresholding (IHT) was empirically found to yield the best solutions.,4. Training Bonsai,[0],[0]
"Gradient descent was chosen over stochastic gradient descent as it removed the burden of step size tuning, led to slightly better prediction accuracies while keeping training time acceptable.",4. Training Bonsai,[0],[0]
"For instance, training times range from 2 minutes for USPS-2 to 15 minutes for MNIST-2 on a single core of a laptop with an Intel Core i7-3667U processor at 2 GHz with 8 GB of RAM.",4. Training Bonsai,[0],[0]
Stochastic gradient descent could be utilized for larger datasets or if training costs also needed to be minimized.,4. Training Bonsai,[0],[0]
"The algorithm proceeds iteratively based on the following gradient and IHT steps in each iteration.
",4. Training Bonsai,[0],[0]
Algorithm - Gradient step:,4. Training Bonsai,[0],[0]
"Given feasible Zt and Θt with a feasible allocation of the memory budget to various nodes at time step t, Bonsai applies M updates of gradient descent keeping the support of Z and Θ fixed so that
the budget allocations to nodes remain unchanged and the memory constraints are never violated.",4. Training Bonsai,[0],[0]
"The update equations at each time step are
Zt+1 =",4. Training Bonsai,[0],[0]
"Zt − ηtZ∇ZJ (Zt,Θt)|supp(Zt) (5) Θt+1",4. Training Bonsai,[0],[0]
=,4. Training Bonsai,[0],[0]
Θt − ηtΘ∇ΘJ,4. Training Bonsai,[0],[0]
"(Zt,Θt)|supp(Θt) (6)
with step sizes ηZ and ηΘ being chosen according to the Armijo rule and |supp indicating that the gradient was being computed only for the non-zero entries.",4. Training Bonsai,[0],[0]
M = 5 and M = 15 iterations were found to work well for binary and multi-class classification respectively.,4. Training Bonsai,[0],[0]
"This allows Bonsai to decrease the objective function value without changing the budget allocation of various nodes.
",4. Training Bonsai,[0],[0]
"Algorithm - IHT step: In order to improve the budget allocation, Bonsai performs a single gradient update with unrestricted support.",4. Training Bonsai,[0],[0]
"This violates the memory constraints and Bonsai therefore projects the solution onto the feasible set by retaining the parameters with the largest magnitudes
Zt+M+1 = TBZ(Z t+M − ηt+MZ",4. Training Bonsai,[0],[0]
"∇ZJ (Z t+M ,Θt+M ))",4. Training Bonsai,[0],[0]
"Θt+M+1 = TBΘ(Θ t+M − ηt+MΘ ∇ΘJ (Z t+M ,Θt+M ))
where Tk is an operator returning k of its arguments which have the largest magnitudes while setting the rest to 0.",4. Training Bonsai,[0],[0]
"This allows Bonsai to move to another feasible solution with even lower objective function value by improving the memory budget distribution across nodes.
",4. Training Bonsai,[0],[0]
Algorithm - Convergence:,4. Training Bonsai,[0],[0]
"In general, projected gradient descent based algorithms might oscillate for non-convex problems.",4. Training Bonsai,[0],[0]
"However, (Blumensath & Davies, 2008) prove that for smooth objective functions, gradient descent algorithms with IHT do indeed converge to a saddle point solution.",4. Training Bonsai,[0],[0]
"Furthermore, if the objective function satisfies the Restricted Strong Convexity (RSC) property in a local region, then projected gradient descent with IHT will converge to the local minimum in that region (Jain et al., 2014).",4. Training Bonsai,[0],[0]
"In practice, it was observed that the algorithm generally converged to a good solution soon and therefore was terminated after T = 300 iterations were reached.
",4. Training Bonsai,[0],[0]
Algorithm - Initialization & re-training: Z0 and Θ0 could be set randomly.,4. Training Bonsai,[0],[0]
Prediction accuracy gains of up to 1.5% could be observed if Bonsai was initialized by taking T steps of gradient descent without any budget constraints followed by a hard thresholding step.,4. Training Bonsai,[0],[0]
Further gains of 1.5% could be observed by taking another T steps of gradient descent with fixed support after termination.,4. Training Bonsai,[0],[0]
"This helped in fine-tuning Bonsai’s parameters once the memory budget allocation had been finalized across the tree nodes.
",4. Training Bonsai,[0],[0]
More details about the optimization can be found in the supplementary material by clicking here.,4. Training Bonsai,[0],[0]
"Datasets: Experiments were carried out on a number of publically available binary and multi-class datasets including Chars4K (Campos et al., 2009), CIFAR10 (Krizhevsky, 2009), MNIST (LeCun et al., 1998), WARD (Yang et al., 2009), USPS (Hull, 1994), Eye (Kasprowski & Ober, 2004), RTWhale (RTW), and CUReT (Varma & Zisserman, 2005).",5. Experiments,[0],[0]
"Binary versions of these datasets were downloaded from (Jose et al., 2013).",5. Experiments,[0],[0]
Bing’s L3 Ranking is a proprietary dataset where ground truth annotations specifying the relevance of query-document pairs have been provided on a scale of 0-4.,5. Experiments,[0],[0]
"Table 1 lists these datasets’ statistics.
",5. Experiments,[0],[0]
"Baseline algorithms: Bonsai was compared to stateof-the-art algorithms for resource-efficient ML spanning tree, kNN, SVM and single hidden layer neural network algorithms including Decision Jungles (Shotton et al., 2013; Pohlen), Feature Budgeted Random Forests (BudgetRF) (Nan et al., 2015),",5. Experiments,[0],[0]
"Gradient Boosted Decision Tree Ensemble Pruning (Tree Pruning) (Dekel et al., 2016), Pruned Random Forests (BudgetPrune) (Nan et al., 2016), Local Deep Kernel Learning (LDKL) (Jose et al., 2013), Neural Network Pruning (NeuralNet Pruning) (Han et al., 2016) and Stochastic Neighbor Compression (SNC) (Kusner et al., 2014b).",5. Experiments,[0],[0]
The differences between some of these algorithms and Bonsai is briefly discussed in Section 2.,5. Experiments,[0],[0]
Publically available implementations of all algorithms were used taking care to ensure that published results could be reproduced thereby verifying the code and hyper-parameter settings.,5. Experiments,[0],[0]
Note that Bonsai is not compared to deep convolutional neural networks as they have not yet been demonstrated to fit on such tiny IoT devices.,5. Experiments,[0],[0]
"In particular, convolutions are computationally expensive, drain batteries and produce intermediate results which do not fit in 2 KB RAM.",5. Experiments,[0],[0]
"Implementing them on tiny microcontrollers is still
0 50 100 10
20
30
40
50
60 Chars4K−62
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0 50 100 70
80
90
CUReT−61
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0 50 100 80
85
90
95
MNIST−10
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
BonsaiOpt Bonsai NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
0.2 0.4 0.6 0.8 1 42
44
46
48
50
52
L3 Ranking
Model Size (KB)
nD",5. Experiments,[0],[0]
"C
G @
1
Bonsai FastRank
0 5 10 15 50
Model Size (KB)
0 5 10 15 80
Model Size (KB)
0 5 10 15 90
Model Size (KB)
0 5 10 15 88
Model Size (KB)
0 5 10 15 66
68
70
72
74
76
78 Chars4K−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
0 5 10 15 68
70
72
74
76
CIFAR10−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
0 5 10 15 90
92
94
96
USPS−2
Model Size (KB)
",5. Experiments,[0],[0]
"A cc
ur ac
y (%
)
",5. Experiments,[0],[0]
"Legend
−
−
BonsaiOpt Bonsai GBDT",5. Experiments,[0],[0]
Tree Pruning LDKL LDKL−L1 NeuralNet Pruning SNC,5. Experiments,[0],[0]
"Decision Jungle BudgetPrune BudgetRF
Figure 2: Binary Datasets - Bonsai dominates over state-of-the-art resource-efficient ML algorithms with gains of 8.6% on RTWhale-2 and 8.2% on Eye-2 in the 0-2 KB range.",5. Experiments,[0],[0]
BonsaiOpt’s gains are even higher.,5. Experiments,[0],[0]
"Figure best viewed magnified.
",5. Experiments,[0],[0]
an open research problem.,5. Experiments,[0],[0]
"Bonsai’s performance was however compared to that of uncompressed single hidden layer neural networks without convolutions, Gradient Boosted Decision Trees (GBDT), kNN classifiers and RBF-SVMs.
",5. Experiments,[0],[0]
Hyper-parameters: The publically provided training set for each dataset was subdivided into 80% for training and 20% for validation.,5. Experiments,[0],[0]
The hyper-parameters of all algorithms were tuned on the validation set.,5. Experiments,[0],[0]
"Once the hyperparameters had been fixed, the algorithms were trained on the full training set and results were reported on the publically available test set.
",5. Experiments,[0],[0]
Evaluation: IoT applications would like to maximize their prediction accuracies using the best model that might fit within the available flash memory while minimizing their prediction times and energies.,5. Experiments,[0],[0]
Accuracies of all algorithms are therefore presented for a range of model sizes.,5. Experiments,[0],[0]
"Some
of the algorithms were implemented on the Uno and their prediction times and energies were compared to Bonsai’s.
",5. Experiments,[0],[0]
Implementation: Results are presented throughout for an unoptimized implementation of Bonsai for a fair comparison with the other methods.,5. Experiments,[0],[0]
"For instance, 4 bytes were used to store floating point numbers for all algorithms, all floating point operations were simulated in software, etc.",5. Experiments,[0],[0]
"However, results are also presented for an optimized implementation of Bonsai, called BonsaiOpt, where numbers were stored in a 1 byte fixed point format, tanh was approximated, all floating point operations were avoided, etc.
",5. Experiments,[0],[0]
"Comparison to uncompressed methods: The results in Tables 2 and 3 demonstrate that Bonsai’s prediction accuracies could compete with those of uncompressed kNN, GBDT, RBF-SVM and neural network classifiers with significantly larger model sizes.",5. Experiments,[0],[0]
"On RTWhale-2, Chars4K-62
and Chars4K-2, Bonsai’s accuracies were higher than all other methods by 4.8%, 3.2% and 1.1% while its model size was lower by 977x, 13x and 157x respectively.",5. Experiments,[0],[0]
Bonsai’s accuracies were lower by 1.0% - 5.0% on the other datasets with model size gains varying from 55x to 3996x.,5. Experiments,[0],[0]
"Note that, while BonsaiOpt’s accuracies were similar to Bonsai’s, its model sizes would be even lower.
",5. Experiments,[0],[0]
Comparison to resource-efficient ML algorithms: The results in Figures 2 and 3 demonstrate that Bonsai’s prediction accuracies dominate those of state-of-the-art resourceefficient ML algorithms for all model sizes.,5. Experiments,[0],[0]
"In fact, Bonsai could outperform all other algorithms, including tree algorithms by as much as 30.7% on Char4K-62 and 28.9% on CUReT-61 for a given model size.",5. Experiments,[0],[0]
"For binary datasets, the largest gains were observed in the 0-2 KB regime including 8.6% on RTWhale-2 and 8.2% on Eye-2.",5. Experiments,[0],[0]
"Of course, BonsaiOpt’s gains were even higher on both binary and
multi-class datasets.",5. Experiments,[0],[0]
"These results validate Bonsai’s model, showing it to be accurate and compact and demonstrate that Bonsai’s optimization algorithm yields good solutions.
L3 ranking: Bonsai was shown to generalise to other resource-constrained scenarios beyond IoT by ranking documents in response to queries on Bing.",5. Experiments,[0],[0]
"Bonsai was trained by replacing the classification gradients with rank-sensitive gradients approximating nDCG (Burges, 2010).",5. Experiments,[0],[0]
"As can be seen in Figure 1, using a 300 byte model, Bonsai could outperform Bing’s FastRank L3 ranker by 8.3%.",5. Experiments,[0],[0]
"In fact, Bonsai could achieve almost the same ranking accuracy as FastRank but with a 660x smaller model.
",5. Experiments,[0],[0]
Prediction on the Arduino Uno: Table 5 presents the prediction costs per test point for the highest accuracy models with size less than 2 KB for a few methods that were implemented on the Arduino Uno.,5. Experiments,[0],[0]
The BonsaiOpt model was a more efficient implementation of the chosen Bonsai model.,5. Experiments,[0],[0]
"The results indicate that BonsaiOpt could be significantly more accurate, faster and energy-efficient as compared to other algorithms including an unoptimized linear classifier.",5. Experiments,[0],[0]
"Transmitting the test feature vector to the cloud, whenever possible, and running uncompressed GBDT might sometimes yield higher accuracies but would also consume 47x497x more energy which might not be feasible.
Bonsai’s components: The contribution of Bonsai’s components on the Chars4K-2 dataset is presented in Table 4.",5. Experiments,[0],[0]
Modest reductions in accuracy were observed without proper initialization or re-training.,5. Experiments,[0],[0]
Learning a projection matrix independently via sparse PCA before training reduced accuracy significantly as compared to Bonsai’s joint training of the projection matrix and tree parameters.,5. Experiments,[0],[0]
Other tree and uncompressed methods also did not benefit much by training in the sparse PCA space.,5. Experiments,[0],[0]
"This paper proposed an alternative IoT paradigm, centric to the device rather than the cloud, where ML models run on tiny IoT devices without necessarily connecting to the cloud thereby engendering local decision making capabilities.",6. Conclusions,[0],[0]
"The Bonsai tree learner was developed towards this end and demonstrated to be fast, accurate, compact and energy-efficient at prediction time.",6. Conclusions,[0],[0]
"Bonsai was deployed on the Arduino Uno board as it could fit in a few KB of flash, required only 70 bytes of writable memory for binary classification and 500 bytes for a 62 class problem, handled streaming features and made predictions in milliseconds taking only milliJoules of energy.",6. Conclusions,[0],[0]
"Bonsai’s prediction accuracies could be as much as 30% higher as com-
pared to state-of-the-art resource-efficient ML algorithms for a fixed model size and could even approach and outperform those of uncompressed models taking many MB of RAM.",6. Conclusions,[0],[0]
"Bonsai achieved these gains by developing a novel model based on a single, shallow, sparse tree learnt in a low-dimensional space.",6. Conclusions,[0],[0]
Predictions made by both internal and leaf nodes and the sharing of parameters along paths allowed Bonsai to learn complex non-linear decision boundaries using a compact representation.,6. Conclusions,[0],[0]
Bonsai’s code is available from (BonsaiCode) and is part of Microsoft’s ELL machine learning compiler for IoT devices.,6. Conclusions,[0],[0]
"We are grateful to Yeshwanth Cherapanamjeri, Ofer Dekel, Chirag Gupta, Prateek Jain, Ajay Manchepalli, Nagarajan Natarajan, Praneeth Netrapalli, Bhargavi Paranjape, Suresh Parthasarathy, Vivek Seshadri, Rahul Sharma, Harsha Vardhan Simhadri, Manish Singh and Raghavendra Udupa for many helpful discussions and feedback.",Acknowledgements,[0],[0]
"This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices – such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash.",abstractText,[0],[0]
"Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters.",abstractText,[0],[0]
"Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30% higher than stateof-the-art methods for resource-efficient machine learning.",abstractText,[0],[0]
Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing’s L3 ranker when the model size is restricted to 300 bytes.,abstractText,[0],[0]
Bonsai’s code can be downloaded from (BonsaiCode).,abstractText,[0],[0]
Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 925–930 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
925",text,[0],[0]
"Natural language to code generation, a subtask of semantic parsing, is the problem of converting natural language (NL) descriptions to code (Ling et al., 2016; Yin and Neubig, 2017; Rabinovich et al., 2017).",1 Introduction,[0],[0]
"This task is challenging because it has a well-defined structured output and the input structure and output structure are in different forms.
",1 Introduction,[0],[0]
A number of neural network approaches have been proposed to solve this task.,1 Introduction,[0],[0]
"Sequential approaches (Ling et al., 2016; Jia and Liang, 2016; Locascio et al., 2016) convert the target code into a sequence of symbols and apply a sequence-tosequence model, but this approach does not ensure that the output will be syntactically correct.
",1 Introduction,[0.9502823898754794],"['Condition I requires the derivative of F to be continuous, a condition satisfied by many RNNs, like LSTM and GRU (Cho et al., 2014).']"
"1Code available at https://github.com/ sweetpeach/ReCode
Tree-based approaches (Yin and Neubig, 2017; Rabinovich et al., 2017) represent code as Abstract Syntax Trees (ASTs), which has proven effective in improving accuracy as it enforces the well-formedness of the output code.",1 Introduction,[0],[0]
"However, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly exceeds the length of the NL description.",1 Introduction,[0],[0]
"As a result, tree-based approaches are often incapable of generating correct code for phrases in the corresponding NL description that have low frequency in the training data.
",1 Introduction,[0],[0]
"In machine translation (MT) problems (Zhang et al., 2018; Gu et al., 2018; Amin Farajian et al., 2017; Li et al., 2018), hybrid methods combining retrieval of salient examples and neural models have proven successful in dealing with rare words.",1 Introduction,[0],[0]
"Following the intuition of these models, we hypothesize that our model can benefit from querying pairs of NL descriptions and AST structures from training data.
",1 Introduction,[0],[0]
"In this paper, we propose RECODE, and adaptation of Zhang et al. (2018)’s retrieval-based approach neural MT method to the code generation problem by expanding it to apply to generation of tree structures.",1 Introduction,[0],[0]
Our main contribution is to introduce the use of retrieval methods in neural code generation models.,1 Introduction,[0],[0]
We also propose a dynamic programming-based sentence-tosentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches.,1 Introduction,[0],[0]
These contributions allow us to improve on previous stateof-the-art results.,1 Introduction,[0],[0]
"Given an NL description q, our purpose is to generate code (e.g. Python) represented as an AST a.",2 Syntactic Code Generation,[0],[0]
"In this work, we start with the syntactic code gen-
eration model by Yin and Neubig (2017), which uses sequences of actions to generate the AST before converting it to surface code.",2 Syntactic Code Generation,[0],[0]
"Formally, we want to find the best generated AST â given by:
â = argmax a
p(a|q)
p(a|q) = T∏ t=1 p(yt|y<t, q)
where yt is the action taken at time step t and y<t = y1...",2 Syntactic Code Generation,[0],[0]
"yt−1 and T is the number of total time steps of the whole action sequence resulting in AST a.
We have two types of actions to build an AST: APPLYRULE and GENTOKEN.",2 Syntactic Code Generation,[0],[0]
APPLYRULE(r) expands the current node in the tree by applying production rule r from the abstract syntax grammar2 to the current node.,2 Syntactic Code Generation,[0],[0]
GENTOKEN(v) populates terminal nodes with the variable v which can be generated from vocabulary or by COPYing variable names or values from the NL description.,2 Syntactic Code Generation,[0],[0]
The generation process follows a preorder traversal starting with the root node.,2 Syntactic Code Generation,[0],[0]
"Figure 1 shows an action tree for the example code: the nodes correspond to actions per time step in the construction of the AST.
",2 Syntactic Code Generation,[0],[0]
"Interested readers can reference Yin and Neubig (2017) for more detail of the neural model, which consists of a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) encoder-decoder with action embeddings, context vectors, parent feeding, and a copy mechanism using pointer networks.",2 Syntactic Code Generation,[0],[0]
"We propose RECODE, a method for retrievalbased neural syntactic code generation, using retrieved action subtrees.",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"Following Zhang et al. (2018)’s method for neural machine translation, these retrieved subtrees act as templates that bias the generation of output code.",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"Our pipeline at test time is as follows: • retrieve from the training set NL descriptions
that are most similar with our input sentence (§3.1), • extract n-gram action subtrees from these
retrieved sentences’ corresponding target ASTs (§3.2),
2https://docs.python.org/2/library/ ast.html
• alter the copying actions in these subtrees, by substituting words of the retrieved sentence with corresponding words in the input sentence (§3.3), and • at every decoding step, increase the probabil-
ity of actions that would lead to having these subtrees in the produced tree (§3.4).",3 RECODE: Retrieval-Based Neural Code Generation,[0],[0]
"For every retrieved NL description qm from training set (or retrieved sentence for short), we compute its similarity with input q, using a sentence similarity formula (Gu et al., 2016; Zhang et al., 2018):
sim(q, qm) = 1−",3.1 Retrieval of Training Instances,[0],[0]
"d(q, qm)
max(|q| ,|qm|)
where d is the edit distance.",3.1 Retrieval of Training Instances,[0],[0]
We retrieve only the top M sentences according to this metric where M is a hyperparameter.,3.1 Retrieval of Training Instances,[0],[0]
These scores will later be used to increase action probabilities accordingly.,3.1 Retrieval of Training Instances,[0],[0]
"In Zhang et al. (2018), they collect n-grams from the output side of the retrieved sentences and encourage the model to generate these n-grams.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Word n-grams are obvious candidates when generating a sequence of words as output, as in NMT.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"However, in syntax-based code generation, the generation target is ASTs with no obvious linear structure.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"To resolve this problem, we instead use retrieved pieces of n-gram subtrees from the target code corresponding to the retrieved NL descriptions.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Though we could select successive nodes in the AST as retrieved pieces, such as [assign; expr*(targets); expr] from Figure 1, we would miss important structural information from the rules that are used.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"Thus, we choose to exploit actions in the generation model rather than AST nodes themselves to be candidates for our retrieved pieces.
",3.2 Extracting N -gram Action Subtrees,[0],[0]
"In the action tree (Figure 1), we considered only successive actions, such as subtrees where each node has one or no children, to avoid overly rigid structures or combinatorial explosion of the number of retrieved pieces the model has to consider.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"For example, such an action subtree would be given by [assign → expr*(targets), expr(value) ; expr(value) → List; List → epsilon].
",3.2 Extracting N -gram Action Subtrees,[0],[0]
"As the node in the action tree holds structural information about its children, we set the subtrees
to have a fixed depth, linear in the size of the tree.",3.2 Extracting N -gram Action Subtrees,[0],[0]
"These can be considered “n-grams of actions”, emphasizing the comparison with machine translation which uses n-grams of words.",3.2 Extracting N -gram Action Subtrees,[0],[0]
n is a hyperparameter to be tuned.,3.2 Extracting N -gram Action Subtrees,[0],[0]
Using the retrieved subtree without modification is problematic if it contains at least one node corresponding to a COPY action because copied tokens from the retrieved sentence may be different from those in the input.,3.3 Word Substitution in Copy Actions,[0],[0]
"Figure 1 shows an example when the input and retrieved sentence have four common words, but the object names are different.",3.3 Word Substitution in Copy Actions,[0],[0]
"The extracted action n-gram would contain the rule that copies the second word (“lst”) of the retrieved sentence while we want to copy the first word (“params”) from the input.
",3.3 Word Substitution in Copy Actions,[0],[0]
"By computing word-based edit distance between the input description and the retrieved sentence, we implement a one-to-one sentence alignment method that infers correspondences between uncommon words.",3.3 Word Substitution in Copy Actions,[0],[0]
"For unaligned words, we alter all COPY rules in the extracted n-grams to copy tokens by their aligned counterpart, such as replace “params” with “lst”, and delete the n-gram subtree, as it is not likely to be relevant in the predicted tree.",3.3 Word Substitution in Copy Actions,[0],[0]
"Thus, in the example in Figure 1, the GENTOKEN(LST) action in t5 will not be executed.",3.3 Word Substitution in Copy Actions,[0],[0]
"N -gram subtrees from all retrieved sentences are assigned a score, based on the best similarity score
of all instances where they appeared.",3.4 Retrieval-Guided Code Generation,[0],[0]
"We normalize the scores for each input sentence by subtracting the average over the training dataset.
",3.4 Retrieval-Guided Code Generation,[0],[0]
"At decoding time, incorporate these retrievalderived scores into beam search: for a given time step, all actions that would result in one of the retrieved n-grams u to be in the prediction tree has its log probability log(p(yt | yt−11 )) increased by λ ∗ score(u) where λ is a hyperparameter, and score(u) is the maximal sim(q, qm) from which u is extracted.",3.4 Retrieval-Guided Code Generation,[0],[0]
The probability distribution is then renormalized.,3.4 Retrieval-Guided Code Generation,[0],[0]
"We evaluate RECODE with the Hearthstone (HS) (Ling et al., 2016) and Django (Oda et al., 2015) datasets, as preprocessed by Yin and Neubig (2017).",4 Datasets and Evaluation Metrics,[0],[0]
HS consists of Python classes that implement Hearthstone card descriptions while Django contains pairs of Python source code and English pseudo-code from Django web framework.,4 Datasets and Evaluation Metrics,[0],[0]
"Table 1 summarizes dataset statistics.
",4 Datasets and Evaluation Metrics,[0],[0]
"For evaluation metrics, we use accuracy of exact match and the BLEU score following Yin and Neubig (2017).",4 Datasets and Evaluation Metrics,[0],[0]
"For the neural code generation model, we use the settings explained in Yin and Neubig (2017).",5 Experiments,[0],[0]
"For the retrieval method, we tuned hyperparameters and achieved best result when we set nmax = 4 and λ = 3 for both datasets3.",5 Experiments,[0],[0]
"For HS, we set M = 3 and M = 10 for Django.
",5 Experiments,[0],[0]
"We compare our model with Yin and Neubig (2017)’s model that we call YN17 for brevity, and a sequence-to-sequence (SEQ2SEQ) model that we implemented.",5 Experiments,[0],[0]
"SEQ2SEQ is an attentionenabled encoder-decoder model (Bahdanau et al., 2015).",5 Experiments,[0],[0]
The encoder is a bidirectional LSTM and the decoder is an LSTM.,5 Experiments,[0],[0]
"Table 2 shows that RECODE outperforms the baselines in both BLEU and accuracy, providing ev-
3n-gram subtrees are collected up to nmax-gram
idence for the effectiveness of incorporating retrieval methods into tree-based approaches.
.
",5.1 Results,[0],[0]
"We ran statistical significance tests for RECODE and YN17, using bootstrap resampling with N = 10,000.",5.1 Results,[0],[0]
"For the BLEU scores of both datasets, p < 0.001.",5.1 Results,[0],[0]
"For the exact match accuracy, p < 0.001 for Django dataset, but for Hearthstone, p > 0.3, showing that the retrieval-based model is on par with YN17.",5.1 Results,[0],[0]
"It is worth noting, though, that HS consists of long and complex code, and that generating exact matches is very difficult, making exact match accuracy a less reliable metric.
",5.1 Results,[0],[0]
We also compare RECODE with Rabinovich et al. (2017)’s Abstract Syntax Networks with supervision (ASN+SUPATT) which is the state-of-the-art system for HS.,5.1 Results,[0],[0]
RECODE exceeds ASN without extra supervision though ASN+SUPATT has a slightly better result.,5.1 Results,[0],[0]
"However, ASN+SUPATT is trained with supervised attention extracted through heuristic exact word matches while our attention is unsupervised.",5.1 Results,[0],[0]
"From our observation and as mentioned in Rabinovich et al. (2017), HS contains classes with similar structure, so the code generation task could be simply matching the tree structure and filling the terminal tokens with correct variables and values.",5.2 Discussion and Analysis,[0],[0]
"However, when the code consists of complex logic, partial implementation errors occur, leading to low exact match accuracy (Yin and Neubig, 2017).",5.2 Discussion and Analysis,[0],[0]
"Analyzing our result, we find this intuition to be true not only for HS but also for Django.
",5.2 Discussion and Analysis,[0],[0]
"Examining the generated output for the Django dataset in Table 3, we can see that in the first example, our retrieval model can successfully generate the correct code when YN17 fails.",5.2 Discussion and Analysis,[0],[0]
This difference suggests that our retrieval model benefits from the action subtrees from the retrieved sentences.,5.2 Discussion and Analysis,[0],[0]
"In the second example, although our generated code does not perfectly match the reference code, it has a higher BLEU score compared
to the output of YN17 because our model can predict part of the code (timesince(d, now, reversed)) correctly.",5.2 Discussion and Analysis,[0],[0]
The third example shows where our method fails to apply the correct action as it cannot cast s to str type while YN17 can at least cast s into a type (bool).,5.2 Discussion and Analysis,[0],[0]
"Another common type of error that we found RECODE’s generated outputs is incorrect variable copying, similarly to what is discussed in Yin and Neubig (2017) and Rabinovich et al. (2017).
",5.2 Discussion and Analysis,[0],[0]
Table 4 presents a result on the HS dataset4.,5.2 Discussion and Analysis,[0],[0]
We can see that our retrieval model can handle complex code more effectively.,5.2 Discussion and Analysis,[0],[0]
"Several works on code generation focus on domain specific languages (Raza et al., 2015; Kushman and Barzilay, 2013).",6 Related Work,[0],[0]
"For general purpose code generation, some data-driven work has been
4More example of HS code is provided in the supplementary material.
done for predicting input parsers (Lei et al., 2013) or a set of relevant methods (Raghothaman et al., 2016).",6 Related Work,[0],[0]
"Some attempts using neural networks have used sequence-to-sequence models (Ling et al., 2016) or tree-based architectures (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017).",6 Related Work,[0],[0]
Ling et al. (2016); Jia and Liang (2016); Locascio et al. (2016) treat semantic parsing as a sequence generation task by linearizing trees.,6 Related Work,[0],[0]
The closest work to ours are Yin and Neubig (2017) and Rabinovich et al. (2017) which represent code as an AST.,6 Related Work,[0],[0]
"Another close work is Dong and Lapata (2018), which uses a two-staged structure-aware neural architecture.",6 Related Work,[0],[0]
"They initially generate a lowlevel sketch and then fill in the missing information using the NL and the sketch.
",6 Related Work,[0],[0]
Recent works on retrieval-guided neural machine translation have been presented by Gu et al. (2018); Amin Farajian et al. (2017); Li et al. (2018); Zhang et al. (2018).,6 Related Work,[0],[0]
Gu et al. (2018) use the retrieved sentence pairs as extra inputs to the NMT model.,6 Related Work,[0],[0]
Zhang et al. (2018) employ a simpler and faster retrieval method to guide neural MT where translation pieces are n-grams from retrieved target sentences.,6 Related Work,[0],[0]
"We modify Zhang et al. (2018)’s method from textual n-grams to n-grams over subtrees to exploit the code structural similarity, and propose methods to deal with complex statements and rare words.
",6 Related Work,[0],[0]
"In addition, some previous works have used subtrees in structured prediction tasks.",6 Related Work,[0],[0]
"For example, Galley et al. (2006) used them in syntaxbased translation models.",6 Related Work,[0],[0]
"In Galley et al. (2006), subtrees of the input sentence’s parse tree are associated with corresponding words in the output sentence.",6 Related Work,[0],[0]
We proposed an action subtree retrieval method at test time on top of an AST-driven neural model for generating general-purpose code.,7 Conclusion,[0],[0]
"The predicted surface code is syntactically correct, and the retrieval component improves the performance of a previously state-of-the-art model.",7 Conclusion,[0],[0]
Our successful result suggests that our idea of retrieval-based generation can be potentially applied to other treestructured prediction tasks.,7 Conclusion,[0],[0]
"We are grateful to Lucile Callebert for insightful discussions, Aldrian Obaja Muis for helpful
input on early version writing, and anonymous reviewers for useful feedback.",Acknowledgements,[0],[0]
This material is based upon work supported by the National Science Foundation under Grant No. 1815287.,Acknowledgements,[0],[0]
"In models to generate program source code from natural language, representing this code in a tree structure has been a common approach.",abstractText,[0],[0]
"However, existing methods often fail to generate complex code correctly due to a lack of ability to memorize large and complex structures.",abstractText,[0],[0]
"We introduce RECODE, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model.",abstractText,[0],[0]
"First, we retrieve sentences that are similar to input sentences using a dynamicprogramming-based sentence similarity scoring method.",abstractText,[0],[0]
"Next, we extract n-grams of action sequences that build the associated abstract syntax tree.",abstractText,[0],[0]
"Finally, we increase the probability of actions that cause the retrieved n-gram action subtree to be in the predicted code.",abstractText,[0],[0]
We show that our approach improves the performance on two code generation tasks by up to +2.6 BLEU.1,abstractText,[0],[0]
Retrieval-Based Neural Code Generation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 152–161 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
152",text,[0],[0]
The exponentially growing online information has necessitated the development of effective automatic summarization systems.,1 Introduction,[0],[0]
"In this paper, we focus on an increasingly intriguing task, i.e., abstractive sentence summarization (Rush et al., 2015a), which generates a shorter version of a given sentence while attempting to preserve its original meaning.",1 Introduction,[0],[0]
It can be used to design or refine appealing headlines.,1 Introduction,[0],[0]
"Recently, the application of the attentional sequence-to-sequence (seq2seq) framework has attracted growing attention and achieved state-of-the-art performance on this task (Rush et al., 2015a; Chopra et al., 2016; Nallapati et al., 2016).
",1 Introduction,[0],[0]
Most previous seq2seq models purely depend on the source text to generate summaries.,1 Introduction,[0],[0]
"However, as reported in many studies (Koehn and Knowles, 2017), the performance of a seq2seq model deteriorates quickly with the increase of the length of generation.",1 Introduction,[0],[0]
Our experiments also show that seq2seq models tend to “lose control” sometimes.,1 Introduction,[0],[0]
"For example, 3% of summaries contain less than 3 words, while there are 4 summaries repeating a word for even 99 times.",1 Introduction,[0],[0]
These results largely reduce the informativeness and readability of the generated summaries.,1 Introduction,[0],[0]
"In addition, we find seq2seq models usually focus on copying source words in order, without any actual “summarization”.",1 Introduction,[0],[0]
"Therefore, we argue that, the free generation based on the source sentence is not enough for a seq2seq model.
",1 Introduction,[0],[0]
"Template based summarization (e.g., Zhou and Hovy (2004)) is a traditional approach to abstractive summarization.",1 Introduction,[0],[0]
"In general, a template is an incomplete sentence which can be filled with the input text using the manually defined rules.",1 Introduction,[0],[0]
"For instance, a concise template to conclude the stock market quotation is: [REGION] shares [open/close]",1 Introduction,[0],[0]
"[NUMBER] percent [lower/higher], e.g., “hong kong shares close #.",1 Introduction,[0],[0]
# percent lower”.,1 Introduction,[0],[0]
"Since the templates are written by humans, the produced summaries are usually fluent and informative.",1 Introduction,[0],[0]
"However, the construction of templates is extremely time-consuming and requires a plenty of domain knowledge.",1 Introduction,[0],[0]
"Moreover, it is impossible to develop all templates for summaries in various domains.
",1 Introduction,[0],[0]
"Inspired by retrieve-based conversation systems (Ji et al., 2014), we assume the golden summaries of the similar sentences can provide a reference point to guide the input sentence summarization process.",1 Introduction,[0],[0]
"We call these existing summaries soft templates since no actual rules are nee-
ded to build new summaries from them.",1 Introduction,[0],[0]
"Due to the strong rewriting ability of the seq2seq framework (Cao et al., 2017a), in this paper, we propose to combine the seq2seq and template based summarization approaches.",1 Introduction,[0],[0]
"We call our summarization system Re3Sum, which consists of three modules: Retrieve, Rerank and Rewrite.",1 Introduction,[0],[0]
We utilize a widely-used Information Retrieval (IR) platform to find out candidate soft templates from the training corpus.,1 Introduction,[0],[0]
"Then, we extend the seq2seq model to jointly learn template saliency measurement (Rerank) and final summary generation (Rewrite).",1 Introduction,[0],[0]
"Specifically, a Recurrent Neural Network (RNN) encoder is applied to convert the input sentence and each candidate template into hidden states.",1 Introduction,[0],[0]
"In Rerank, we measure the informativeness of a candidate template according to its hidden state relevance to the input sentence.",1 Introduction,[0],[0]
The candidate template with the highest predicted informativeness is regarded as the actual soft template.,1 Introduction,[0],[0]
"In Rewrite, the summary is generated according to the hidden states of both the sentence and template.
",1 Introduction,[0],[0]
"We conduct extensive experiments on the popular Gigaword dataset (Rush et al., 2015b).",1 Introduction,[0],[0]
"Experiments show that, in terms of informativeness, Re3Sum significantly outperforms the state-ofthe-art seq2seq models, and even soft templates themselves demonstrate high competitiveness.",1 Introduction,[0],[0]
"In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.
",1 Introduction,[0],[0]
"The contributions of this work are summarized as follows:
• We propose to introduce soft templates as additional input to improve the readability and stability of seq2seq summarization systems.",1 Introduction,[0],[0]
Code and results can be found at http://www4.comp.polyu.,1 Introduction,[0],[0]
"edu.hk/˜cszqcao/
• We extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously.
",1 Introduction,[0],[0]
"• We fuse the popular IR-based and seq2seqbased summarization systems, which fully utilize the supervisions from both sides.",1 Introduction,[0],[0]
"As shown in Fig. 1, our summarization system consists of three modules, i.e., Retrieve, Rerank
and Rewrite.",2 Method,[0],[0]
"Given the input sentence x, the Retrieve module filters candidate soft templates C = {ri} from the training corpus.",2 Method,[0],[0]
"For validation and test, we regard the candidate template with the highest predicted saliency (a.k.a informativeness) score as the actual soft template r. For training, we choose the one with the maximal actual saliency score in C, which speeds up convergence and shows no obvious side effect in the experiments.
",2 Method,[0],[0]
"Then, we jointly conduct reranking and rewriting through a shared encoder.",2 Method,[0],[0]
"Specifically, both the sentence x and the soft template r are converted into hidden states with a RNN encoder.",2 Method,[0],[0]
"In the Rerank module, we measure the saliency of r according to its hidden state relevance to x.",2 Method,[0],[0]
"In the Rewrite module, a RNN decoder combines the hidden states of x and r to generate a summary y. More details will be described in the rest of this section",2 Method,[0],[0]
The purpose of this module is to find out candidate templates from the training corpus.,2.1 Retrieve,[0],[0]
We assume that similar sentences should hold similar summary patterns.,2.1 Retrieve,[0],[0]
"Therefore, given a sentence x, we find out its analogies in the corpus and pick their summaries as the candidate templates.",2.1 Retrieve,[0],[0]
"Since the size of our dataset is quite large (over 3M), we leverage the widely-used Information Retrieve (IR) system Lucene1 to index and search efficiently.",2.1 Retrieve,[0],[0]
We keep the default settings of Lucene2 to build the IR system.,2.1 Retrieve,[0],[0]
"For each input sentence, we select top 30 searching results as candidate templates.",2.1 Retrieve,[0],[0]
"To conduct template-aware seq2seq generation (rewriting), it is a necessary step to encode both the source sentence x and soft template r into hidden states.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Considering that the matching networks based on hidden states have demonstrated the strong ability to measure the relevance of two pieces of texts (e.g., Chen et al. (2016)), we propose to jointly conduct reranking and rewriting through a shared encoding step.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Specifically, we employ a bidirectional Recurrent Neural Network (BiRNN) encoder (Cho et al., 2014) to read x and r. Take the sentence x as an example.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Its hidden state of the forward RNN at timestamp i can be
1https://lucene.apache.org/ 2TextField with EnglishAnalyzer
represented by:
−→ h xi = RNN(xi, −→ h xi−1) (1)
The BiRNN consists of a forward RNN and a backward RNN.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Suppose the corresponding outputs are [ −→ h x1 ; · · · ; −→ h x−1] and [ ←− h x1 ; · · · ; ←− h x−1], respectively, where the index “−1” stands for the last element.",2.2 Jointly Rerank and Rewrite,[0],[0]
"Then, the composite hidden state of a word is the concatenation of the two RNN representations, i.e., hxi =",2.2 Jointly Rerank and Rewrite,[0],[0]
[ −→ h xi ; ←− h xi ].,2.2 Jointly Rerank and Rewrite,[0],[0]
The entire representation for the source sentence is [hx1 ; · · · ;hx−1].,2.2 Jointly Rerank and Rewrite,[0],[0]
"Since a soft template r can also be regarded as a readable concise sentence, we use the same BiRNN encoder to convert it into hidden states [hr1; · · · ;hr−1].",2.2 Jointly Rerank and Rewrite,[0],[0]
"In Retrieve, the template candidates are ranked according to the text similarity between the corresponding indexed sentences and the input sentence.",2.2.1 Rerank,[0],[0]
"However, for the summarization task, we expect the soft template r resembles the actual summary y∗ as much as possible.",2.2.1 Rerank,[0],[0]
"Here we use the widely-used summarization evaluation metrics ROUGE (Lin, 2004) to measure the actual saliency s∗(r,y∗) (see Section 3.2).",2.2.1 Rerank,[0],[0]
We utilize the hidden states of x and r to predict the saliency s of the template.,2.2.1 Rerank,[0],[0]
"Specifically, we regard the output of the BiRNN as the representation of the sentence or template:
hx =",2.2.1 Rerank,[0],[0]
[ ←− h x1 ; −→ h x−1] (2) hr =,2.2.1 Rerank,[0],[0]
[ ←− h r1; −→ h r−1],2.2.1 Rerank,[0],[0]
"(3)
Next, we use Bilinear network to predict the saliency of the template for the input sentence.
",2.2.1 Rerank,[0],[0]
"s(r,x) = sigmoid(hrWshTx + bs), (4)
where Ws and bs are parameters of the Bilinear network, and we add the sigmoid activation function to make the range of s consistent with the actual saliency s∗.",2.2.1 Rerank,[0],[0]
"According to Chen et al. (2016), Bilinear outperforms multi-layer forward
neural networks in relevance measurement.",2.2.1 Rerank,[0],[0]
"As shown later, the difference of s and s∗ will provide additional supervisions for the seq2seq framework.",2.2.1 Rerank,[0],[0]
The soft template r selected by the Rerank module has already competed with the state-of-the-art method in terms of ROUGE evaluation (see Table 4).,2.2.2 Rewrite,[0],[0]
"However, r usually contains a lot of named entities that does not appear in the source (see Table 5).",2.2.2 Rewrite,[0],[0]
"Consequently, it is hard to ensure that the soft templates are faithful to the input sentences.",2.2.2 Rewrite,[0],[0]
"Therefore, we leverage the strong rewriting ability of the seq2seq model to generate more faithful and informative summaries.",2.2.2 Rewrite,[0],[0]
"Specifically, since the input of our system consists of both the sentence and soft template, we use the concatenation function3 to combine the hidden states of the sentence and template:
Hc =",2.2.2 Rewrite,[0],[0]
"[h x 1 ; · · · ;hx−1;hr1; · · · ;hr−1] (5)
",2.2.2 Rewrite,[0],[0]
"The combined hidden states are fed into the prevailing attentional RNN decoder (Bahdanau et al., 2014) to generate the decoding hidden state at the position t:
st = Att-RNN(st−1, yt−1,Hc), (6)
where yt−1 is the previous output summary word.",2.2.2 Rewrite,[0],[0]
"Finally, a softmax layer is introduced to predict the current summary word:
ot = softmax(stWo), (7)
where Wo is a parameter matrix.",2.2.2 Rewrite,[0],[0]
There are two types of costs in our system.,2.3 Learning,[0],[0]
"For Rerank, we expect the predicted saliency s(r,x) close to the actual saliency s∗(r,y∗).",2.3 Learning,[0],[0]
"Therefore,
3We also attempted complex combination approaches such as the gate network Cao et al. (2017b) but failed to achieve obvious improvement.",2.3 Learning,[0],[0]
"We assume the Rerank module has partially played the role of the gate network.
",2.3 Learning,[0],[0]
"we use the cross entropy (CE) between s and s∗ as the loss function:
JR(θ) = CE(s(r,x), s ∗(r,y∗)) (8)
= −s∗ log s− (1− s∗) log(1− s),
where θ stands for the model parameters.",2.3 Learning,[0],[0]
"For Rewrite, the learning goal is to maximize the estimated probability of the actual summary y∗.",2.3 Learning,[0],[0]
"We adopt the common negative log-likelihood (NLL) as the loss function:
JG(θ)",2.3 Learning,[0],[0]
=,2.3 Learning,[0],[0]
"− log(p(y∗|x, r))",2.3 Learning,[0],[0]
(9) =,2.3 Learning,[0],[0]
"− ∑
t log(ot[y
∗ t ])
To make full use of supervisions from both sides, we combine the above two costs as the final loss function:
J(θ) = JR(θ)",2.3 Learning,[0],[0]
+ JG(θ),2.3 Learning,[0],[0]
"(10)
We use mini-batch Stochastic Gradient Descent (SGD) to tune model parameters.",2.3 Learning,[0],[0]
The batch size is 64.,2.3 Learning,[0],[0]
"To enhance generalization, we introduce dropout (Srivastava et al., 2014) with probability p = 0.3 for the RNN layers.",2.3 Learning,[0],[0]
"The initial learning rate is 1, and it will decay by 50% if the generation loss does not decrease on the validation set.",2.3 Learning,[0],[0]
"We conduct experiments on the Annotated English Gigaword corpus, as with (Rush et al., 2015b).",3.1 Datasets,[0],[0]
This parallel corpus is produced by pairing the first sentence in the news article and its headline as the summary with heuristic rules.,3.1 Datasets,[0],[0]
"All the training, development and test datasets can be downloaded at https://github.",3.1 Datasets,[0],[0]
com/harvardnlp/sent-summary.,3.1 Datasets,[0],[0]
The statistics of the Gigaword corpus is presented in Table 1.,3.1 Datasets,[0],[0]
"We adopt ROUGE (Lin, 2004) for automatic evaluation.",3.2 Evaluation Metrics,[0],[0]
ROUGE has been the standard evaluation metric for DUC shared tasks since 2004.,3.2 Evaluation Metrics,[0],[0]
"It measures the quality of summary by computing the overlapping lexical units between the candidate summary and actual summaries, such as unigram, bi-gram and longest common subsequence (LCS).",3.2 Evaluation Metrics,[0],[0]
"Following the common practice, we report ROUGE-1 (uni-gram), ROUGE-2 (bi-gram) and ROUGE-L (LCS) F1 scores4 in the following experiments.",3.2 Evaluation Metrics,[0],[0]
"We also measure the actual saliency of a candidate template r with its combined ROUGE scores given the actual summary y∗:
s∗(r,y∗) = RG(r,y∗) +",3.2 Evaluation Metrics,[0],[0]
"RG(r,y∗), (11)
where “RG” stands for ROUGE for short.",3.2 Evaluation Metrics,[0],[0]
ROUGE mainly evaluates informativeness.,3.2 Evaluation Metrics,[0],[0]
"We also introduce a series of metrics to measure the summary quality from the following aspects: LEN DIF The absolute value of the length diffe-
rence between the generated summaries and the actual summaries.",3.2 Evaluation Metrics,[0],[0]
We use mean value ± standard deviation to illustrate this item.,3.2 Evaluation Metrics,[0],[0]
"The average value partially reflects the readability and informativeness, while the standard deviation links to stability.
",3.2 Evaluation Metrics,[0],[0]
"4We use the ROUGE evaluation option: -m -n 2 -w 1.2
LESS 3",3.2 Evaluation Metrics,[0],[0]
"The number of the generated summaries, which contains less than three tokens.",3.2 Evaluation Metrics,[0],[0]
These extremely short summaries are usually unreadable.,3.2 Evaluation Metrics,[0],[0]
COPY,3.2 Evaluation Metrics,[0],[0]
The proportion of the summary words (without stopwords) copied from the source sentence.,3.2 Evaluation Metrics,[0],[0]
A seriously large copy ratio indicates that the summarization system pays more attention to compression rather than required abstraction.,3.2 Evaluation Metrics,[0],[0]
NEW NE,3.2 Evaluation Metrics,[0],[0]
The number of the named entities that do not appear in the source sentence or actual summary.,3.2 Evaluation Metrics,[0],[0]
"Intuitively, the appearance of new named entities in the summary is likely to bring unfaithfulness.",3.2 Evaluation Metrics,[0],[0]
We use Stanford CoreNLP,3.2 Evaluation Metrics,[0],[0]
"(Manning et al., 2014) to recognize named entities.",3.2 Evaluation Metrics,[0],[0]
We use the popular seq2seq framework OpenNMT5 as the starting point.,3.3 Implementation Details,[0],[0]
"To make our model more general, we retain the default settings of OpenNMT to build the network architecture.",3.3 Implementation Details,[0],[0]
"Specifically, the dimensions of word embeddings and RNN are both 500, and the encoder and decoder structures are two-layer bidirectional Long Short Term Memory Networks (LSTMs).",3.3 Implementation Details,[0],[0]
The only difference is that we add the argument “- share embeddings” to share the word embeddings between the encoder and decoder.,3.3 Implementation Details,[0],[0]
This practice largely reduces model parameters for the monolingual task.,3.3 Implementation Details,[0],[0]
"On our computer (GPU: GTX 1080, Memory: 16G, CPU: i7-7700K), the training spends about 2 days.
",3.3 Implementation Details,[0],[0]
"During test, we use beam search of size 5 to generate summaries.",3.3 Implementation Details,[0],[0]
We add the argument “- replace unk” to replace the generated unknown words with the source word that holds the highest attention weight.,3.3 Implementation Details,[0],[0]
"Since the generated summaries are often shorter than the actual ones, we introduce an additional length penalty argument “- alpha 1” to encourage longer generation, like Wu et al. (2016).",3.3 Implementation Details,[0],[0]
"We compare our proposed model with the following state-of-the-art neural summarization systems: ABS Rush et al. (2015a) used an attentive CNN
encoder and a NNLM decoder to summarize 5https://github.com/OpenNMT/OpenNMT-py
the sentence.",3.4 Baselines,[0],[0]
ABS+,3.4 Baselines,[0],[0]
"Rush et al. (2015a) further tuned the ABS
model with additional hand-crafted features to balance between abstraction and extraction.
",3.4 Baselines,[0],[0]
"RAS-Elman As the extension of the ABS model, it used a convolutional attention-based encoder and a RNN decoder (Chopra et al., 2016).",3.4 Baselines,[0],[0]
"Featseq2seq Nallapati et al. (2016) used a complete seq2seq RNN model and added the hand-crafted features such as POS tag and NER, to enhance the encoder representation.",3.4 Baselines,[0],[0]
Luong-NMT Chopra et al. (2016) implemented the neural machine translation model of Luong et al. (2015) for summarization.,3.4 Baselines,[0],[0]
This model contained two-layer LSTMs with 500 hidden units in each layer.,3.4 Baselines,[0],[0]
OpenNMT,3.4 Baselines,[0],[0]
We also implement the standard attentional seq2seq model with OpenNMT.,3.4 Baselines,[0],[0]
All the settings are the same as our system.,3.4 Baselines,[0],[0]
It is noted that OpenNMT officially examined the Gigaword dataset.,3.4 Baselines,[0],[0]
We distinguish the official result6 and our experimental result with suffixes “O” and “I” respectively.,3.4 Baselines,[0],[0]
"FTSum Cao et al. (2017b) encoded the facts extracted from the source sentence to improve both the faithfulness and informativeness of generated summaries.
",3.4 Baselines,[0],[0]
"In addition, to evaluate the effectiveness of our joint learning framework, we develop a baseline named “PIPELINE”.",3.4 Baselines,[0],[0]
Its architecture is identical to Re3Sum.,3.4 Baselines,[0],[0]
"However, it trains the Rerank module and Rewrite module in pipeline.",3.4 Baselines,[0],[0]
Let’s first look at the final cost values (Eq. 9) on the development set.,3.5 Informativeness Evaluation,[0],[0]
"From Table 2, we can
6http://opennmt.net/Models/
see that our model achieves much lower perplexity compared against the state-of-the-art systems.",3.5 Informativeness Evaluation,[0],[0]
It is also noted that PIPELINE slightly outperforms Re3Sum.,3.5 Informativeness Evaluation,[0],[0]
"One possible reason is that Re3Sum additionally considers the cost derived from the Rerank module.
",3.5 Informativeness Evaluation,[0],[0]
The ROUGE F1 scores of different methods are then reported in Table 3.,3.5 Informativeness Evaluation,[0],[0]
"As can be seen, our model significantly outperforms most other approaches.",3.5 Informativeness Evaluation,[0],[0]
"Note that, ABS+ and Featseq2seq have utilized a series of hand-crafted features, but our model is completely data-driven.",3.5 Informativeness Evaluation,[0],[0]
"Even though, our model surpasses Featseq2seq by 22% and ABS+ by 60% on ROUGE-2.",3.5 Informativeness Evaluation,[0],[0]
"When soft templates are ignored, our model is equivalent to the standard at-
tentional seq2seq model OpenNMTI .",3.5 Informativeness Evaluation,[0],[0]
"Therefore, it is safe to conclude that soft templates have great contribute to guide the generation of summaries.
",3.5 Informativeness Evaluation,[0],[0]
We also examine the performance of directly regarding soft templates as output summaries.,3.5 Informativeness Evaluation,[0],[0]
We introduce five types of different soft templates:,3.5 Informativeness Evaluation,[0],[0]
Random An existing summary randomly selected from the training corpus.,3.5 Informativeness Evaluation,[0],[0]
First The top-ranked candidate template given by the Retrieve module.,3.5 Informativeness Evaluation,[0],[0]
"Max The template with the maximal actual
ROUGE scores among the 30 candidate templates.
",3.5 Informativeness Evaluation,[0],[0]
Optimal An existing summary in the training corpus which holds the maximal ROUGE scores.,3.5 Informativeness Evaluation,[0],[0]
Rerank The template with the maximal predicted ROUGE scores among the 30 candidate templates.,3.5 Informativeness Evaluation,[0],[0]
"It is the actual soft template we adopt.
",3.5 Informativeness Evaluation,[0],[0]
"As shown in Table 4, the performance of Random is terrible, indicating it is impossible to use one summary template to fit various actual summaries.",3.5 Informativeness Evaluation,[0],[0]
"Rerank largely outperforms First, which verifies the effectiveness of the Rerank module.",3.5 Informativeness Evaluation,[0],[0]
"However, according to Max and Rerank, we find the Rerank performance of Re3Sum is far from perfect.",3.5 Informativeness Evaluation,[0],[0]
"Likewise, comparing Max and First, we observe that the improving capacity of the Retrieve module is high.",3.5 Informativeness Evaluation,[0],[0]
Notice that Optimal greatly exceeds all the state-of-the-art approaches.,3.5 Informativeness Evaluation,[0],[0]
This finding strongly supports our practice of using existing summaries to guide the seq2seq models.,3.5 Informativeness Evaluation,[0],[0]
"We also measure the linguistic quality of generated summaries from various aspects, and the results are present in Table 5.",3.6 Linguistic Quality Evaluation,[0],[0]
"As can be seen from the rows “LEN DIF” and “LESS 3”, the performance of Re3Sum is almost the same as that of soft templates.",3.6 Linguistic Quality Evaluation,[0],[0]
The soft templates indeed well guide the summary generation.,3.6 Linguistic Quality Evaluation,[0],[0]
"Compared with
Re3Sum, the standard deviation of LEN DF is 0.7 times larger in OpenNMT, indicating that OpenNMT works quite unstably.",3.6 Linguistic Quality Evaluation,[0],[0]
"Moreover, OpenNMT generates 53 extreme short summaries, which seriously reduces readability.",3.6 Linguistic Quality Evaluation,[0],[0]
"Meanwhile, the copy ratio of actual summaries is 36%.",3.6 Linguistic Quality Evaluation,[0],[0]
"Therefore, the copy mechanism is severely overweighted in OpenNMT.",3.6 Linguistic Quality Evaluation,[0],[0]
"Our model is encouraged to generate according to human-written soft templates, which relatively diminishes copying from the source sentences.",3.6 Linguistic Quality Evaluation,[0],[0]
Look at the last row “NEW NE”.,3.6 Linguistic Quality Evaluation,[0],[0]
"A number of new named entities appear in the soft templates, which makes them quite unfaithful to source sentences.",3.6 Linguistic Quality Evaluation,[0],[0]
"By contrast, this index in Re3Sum is close to the OpenNMT’s.",3.6 Linguistic Quality Evaluation,[0],[0]
It highlights the rewriting ability of our seq2seq framework.,3.6 Linguistic Quality Evaluation,[0],[0]
"In this section, we investigate how soft templates affect our model.",3.7 Effect of Templates,[0],[0]
"At the beginning, we feed different types of soft templates (refer to Table 4) into the Rewriting module of Re3Sum.",3.7 Effect of Templates,[0],[0]
"As illustrated in Table 6, the more high-quality templates are provided, the higher ROUGE scores are achieved.",3.7 Effect of Templates,[0],[0]
"It is interesting to see that,while the ROUGE-2 score of Random templates is zero, our model can still generate acceptable summaries with Random templates.",3.7 Effect of Templates,[0],[0]
It seems that Re3Sum can automatically judge whether the soft templates are trustworthy and ignore the seriously irrelevant ones.,3.7 Effect of Templates,[0],[0]
"We believe that the joint learning with the Rerank model plays a vital role here.
",3.7 Effect of Templates,[0],[0]
"Next, we manually inspect the summaries generated by different methods.",3.7 Effect of Templates,[0],[0]
"We find the outputs of Re3Sum are usually longer and more flu-
ent than the outputs of OpenNMT.",3.7 Effect of Templates,[0],[0]
Some illustrative examples are shown in Table 7.,3.7 Effect of Templates,[0],[0]
"In Example 1, there is no predicate in the source sentence.",3.7 Effect of Templates,[0],[0]
"Since OpenNMT prefers selecting source words around the predicate to form the summary, it fails on this sentence.",3.7 Effect of Templates,[0],[0]
"By contract, Re3Sum rewrites the template and produces an informative summary.",3.7 Effect of Templates,[0],[0]
"In Example 2, OpenNMT deems the starting part of the sentences are more important, while our model, guided by the template, focuses on the second part to generate the summary.
",3.7 Effect of Templates,[0],[0]
"In the end, we test the ability of our model to generate diverse summaries.",3.7 Effect of Templates,[0],[0]
"In practice, a system that can provide various candidate summaries is probably more welcome.",3.7 Effect of Templates,[0],[0]
"Specifically, two candidate templates with large text dissimilarity are manually fed into the Rewriting module.",3.7 Effect of Templates,[0],[0]
The corresponding generated summaries are shown in Table 8.,3.7 Effect of Templates,[0],[0]
"For the sake of comparison, we also present the 2-best results of OpenNMT with beam search.",3.7 Effect of Templates,[0],[0]
"As can be seen, with different templates given, our model is likely to generate dissimilar summaries.",3.7 Effect of Templates,[0],[0]
"In contrast, the 2-best results of OpenNMT is almost the same, and often a shorter summary is only a piece of the other one.",3.7 Effect of Templates,[0],[0]
"To sum up, our model demonstrates promising prospect in generation diversity.",3.7 Effect of Templates,[0],[0]
"Abstractive sentence summarization aims to produce a shorter version of a given sentence while preserving its meaning (Chopra et al., 2016).",4 Related Work,[0],[0]
"This task is similar to text simplification (Saggion, 2017) and facilitates headline design and refine.",4 Related Work,[0],[0]
"Early studies on sentence summariza-
tion include template-based methods (Zhou and Hovy, 2004), syntactic tree pruning (Knight and Marcu, 2002; Clarke and Lapata, 2008) and statistical machine translation techniques (Banko et al., 2000).",4 Related Work,[0],[0]
"Recently, the application of the attentional seq2seq framework has attracted growing attention and achieved state-of-the-art performance on this task (Rush et al., 2015a; Chopra et al., 2016; Nallapati et al., 2016).
",4 Related Work,[0],[0]
"In addition to the direct application of the general seq2seq framework, researchers attempted to integrate various properties of summarization.",4 Related Work,[0],[0]
"For example, Nallapati et al. (2016) enriched the encoder with hand-crafted features such as named entities and POS tags.",4 Related Work,[0],[0]
These features have played important roles in traditional feature based summarization systems.,4 Related Work,[0],[0]
Gu et al. (2016) found that a large proportion of the words in the summary were copied from the source text.,4 Related Work,[0],[0]
"Therefore, they proposed CopyNet which considered the copying mechanism during generation.",4 Related Work,[0],[0]
"Recently, See et al. (2017) used the coverage mechanism to discourage repetition.",4 Related Work,[0],[0]
Cao et al. (2017b) encoded facts extracted from the source sentence to enhance the summary faithfulness.,4 Related Work,[0],[0]
There were also studies to modify the loss function to fit the evaluation metrics.,4 Related Work,[0],[0]
"For instance, Ayana et al. (2016) applied the Minimum Risk Training strategy to maximize the ROUGE scores of generated sum-
maries.",4 Related Work,[0],[0]
"Paulus et al. (2017) used the reinforcement learning algorithm to optimize a mixed objective function of likelihood and ROUGE scores.
",4 Related Work,[0],[0]
Guu et al. (2017) also proposed to encode human-written sentences to improvement the performance of neural text generation.,4 Related Work,[0],[0]
"However, they handled the task of Language Modeling and randomly picked an existing sentence in the training corpus.",4 Related Work,[0],[0]
"In comparison, we develop an IR system to find proper existing summaries as soft templates.",4 Related Work,[0],[0]
"Moreover, Guu et al. (2017) used a general seq2seq framework while we extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously.",4 Related Work,[0],[0]
This paper proposes to introduce soft templates as additional input to guide the seq2seq summarization.,5 Conclusion and Future Work,[0],[0]
We use the popular IR platform Lucene to retrieve proper existing summaries as candidate soft templates.,5 Conclusion and Future Work,[0],[0]
Then we extend the seq2seq framework to jointly conduct template reranking and template-aware summary generation.,5 Conclusion and Future Work,[0],[0]
"Experiments show that our model can generate informative, readable and stable summaries.",5 Conclusion and Future Work,[0],[0]
"In addition, our model demonstrates promising prospect in generation diversity.
",5 Conclusion and Future Work,[0],[0]
"We believe our work can be extended in vari-
ous aspects.",5 Conclusion and Future Work,[0],[0]
"On the one hand, since the candidate templates are far inferior to the optimal ones, we intend to improve the Retrieve module, e.g., by indexing both the sentence and summary fields.",5 Conclusion and Future Work,[0],[0]
"On the other hand, we plan to test our system on the other tasks such as document-level summarization and short text conversation.
",5 Conclusion and Future Work,[0],[0]
"Acknowledgments
The work described in this paper was supported by Research Grants Council of Hong Kong (PolyU 152036/17E), National Natural Science Foundation of China (61672445 and 61572049) and The Hong Kong Polytechnic University (G-YBP6, 4- BCDV).",5 Conclusion and Future Work,[0],[0]
"Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably.",abstractText,[0],[0]
"Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model.",abstractText,[0],[0]
"To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates.",abstractText,[0],[0]
"Then, we extend the seq2seq framework to jointly conduct template Reranking and templateaware summary generation (Rewriting).",abstractText,[0],[0]
"Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness.",abstractText,[0],[0]
"In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.",abstractText,[0],[0]
"Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization",title,[0],[0]
Revealing common statistical behaviors among a group of subjects is fundamental to neuroscience and bio-medical data analysis.,1. Introduction,[0],[0]
"For example, in functional magnetic resonance imaging (fMRI) research (Bullmore et al., 1996; Smith et al., 2011; Varoquaux & Craddock, 2013), group level analyses are used for detecting brain networks from resting-state recordings (Fox et al., 2005), for detecting activities of specific regions in response to various stimuli (Haxby et al., 2001), for studying the connectivity of a specific brain region to other regions through seed based
1Electrical Engineering Dept., Technion, Israel.",1. Introduction,[0],[0]
"Correspondence to: Andrey Zhitnikov <andreyz@campus.technion.ac.il>, Rotem Mulayoff <smulayof@campus.technion.ac.il>, Tomer Michaeli <tomer.m@ee.technion.ac.il>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"analysis (Hagler et al., 2006), etc.",1. Introduction,[0],[0]
Group analyses often rely on the assumption that all subjects in the group behave according to the same statistical model.,1. Introduction,[0],[0]
"For example, to estimate the covariance (or partial covariance) matrix of several variables, a popular approach is to average the covariance matrices estimated for each of the individual subjects in the group (Power et al., 2011).",1. Introduction,[0],[0]
"This is done using either the Euclidean mean (arithmetic average) or the intrinsic (Riemannian) mean (Förstner & Moonen, 2003), (Fletcher & Joshi, 2007), which respects the geometry of the manifold of positive definite matrices (Varoquaux et al., 2010a).
",1. Introduction,[0],[0]
"Real data, however, rarely conform to this assumption.",1. Introduction,[0],[0]
"Often times, each subject in a group deviates from the common model in a different way.",1. Introduction,[0],[0]
"For example, it has been shown that estimates of connectivity patterns from fMRI scans, tend to vary significantly between subjects (Moussa et al., 2012).",1. Introduction,[0],[0]
Subject-specific deviations may even be more dominant than the common model itself.,1. Introduction,[0],[0]
"Therefore, if ignored, these deviations may severely degrade the quality of the estimate of the common model.",1. Introduction,[0],[0]
This phenomenon is illustrated in Fig. 1 in the context of nonparametric density estimation of two variables (brain regions).,1. Introduction,[0],[0]
"In this example, the deviations from the common model are additive and have a different distribution for each subject.",1. Introduction,[0],[0]
"Thus, as can be seen on the right, kernel density estimation (KDE) applied to the entire group, fails to reveal the common behavior.
",1. Introduction,[0],[0]
Approaches for accounting for subject-specific deviations often make limiting assumptions.,1. Introduction,[0],[0]
"For example, in the context of covariance estimation, (Varoquaux et al., 2010b) assumed that the precision matrices of all subjects in the group have the same sparsity pattern, and proposed a modified graph Lasso technique (Friedman et al., 2008) for simultaneously estimating those matrices.",1. Introduction,[0],[0]
"In (Marrelec et al., 2006), the authors assumed that each subject’s samples follow a Gaussian distribution with a covariance matrix that follows an inverse Wishart distribution around the group covariance.",1. Introduction,[0],[0]
"In the context of regression, a popular strategy is to use a linear mixed-effects model (Friston et al., 2005; Chen et al., 2013), which relies on a Gaussian distribution assumption for the subject specific factors.",1. Introduction,[0],[0]
"Similar lines of work include grouplevel independent component analysis (ICA) (Calhoun et al., 2001; Beckmann & Smith, 2005; Varoquaux et al., 2010c), dictionary learning (Varoquaux et al., 2011; Mensch et al., 2016), and causal structure estimation (Ramsey et al., 2010).
",1. Introduction,[0],[0]
In this paper we present non-parametric methods for estimating a common model in the presence of subject-specific noise factors.,1. Introduction,[0],[0]
"Specifically, we present a common-covariance estimation algorithm and a common probability density function (pdf) estimation method, both of which do not assume any particular form for the underlying distributions.",1. Introduction,[0],[0]
Our only assumption is that the subject-specific noise factors are additive and have diverse distributions (otherwise they could be considered part of the common model).,1. Introduction,[0],[0]
"In this setting, the Euclidean and Riemannian mean estimates do not approach the true covariance matrix as the number of subjects grows.",1. Introduction,[0],[0]
"In contrast, we prove that our estimate does converge to the true covariance under very mild assumptions.",1. Introduction,[0],[0]
We verify the advantages of our approach through extensive experiments on simulated and on real data.,1. Introduction,[0],[0]
"Let u ∈ Rd be a random vector, which represents the common source of variability across a group of subjects.",2. Problem formulation,[0],[0]
"For example, in Fig. 1, u ∈ R2 is distributed according to the ‘ground truth’ density function (top right).",2. Problem formulation,[0],[0]
"Let xj ∈ Rd be a random vector, which represents the jth subject in the group (in Fig. 1, the jth scatter plot shows realizations of xj).",2. Problem formulation,[0],[0]
"We assume the additive model
xj = u+ vj , (1)
where {vj} are random vectors that are independent of u and represent subject-specific factors.",2. Problem formulation,[0],[0]
"Generally, each vj has a different distribution (had they been distributed identically, they would have been part of the common model).
",2. Problem formulation,[0],[0]
"Given realizations of xj , for j = 1 . .",2. Problem formulation,[0],[0]
".m, our goal is to estimate statistical properties of the common component u.
In particular, we are interested in estimating either the covariance matrix Σu or the full pdf pu of u.
Obviously, the performance in those estimation tasks will generally depend on both the number of subjects m and the number of samples per subject.",2. Problem formulation,[0],[0]
"However, here, we are interested in the common situation in which the number of samples per subject suffices to obtain reasonably accurate estimates for Σxj or pxj (e.g., when the dimension d is relatively small).",2. Problem formulation,[0],[0]
Our assumption is thus that the covariances (or pdfs) of the subjects xj are known and our focus is on the problem of recovering the common covariance (or pdf) from them.,2. Problem formulation,[0],[0]
"To apply our algorithms in practice, one has to plug in estimates of the covariances (or pdfs) of the subjects (obtained using, e.g., KDE).",2. Problem formulation,[0],[0]
"Since u and vj are independent, we have from (1) that
Σxj = Σu + Σvj (2)
for every j = 1, . . .",3. Common covariance estimation,[0],[0]
",m. We would like to estimate the covariance matrix Σu of the common component, given the covariance matrices {Σxj} of the subjects.",3. Common covariance estimation,[0],[0]
"To avoid ambiguity, we define the common component Σu to be the largest one satisfying such a decomposition.",3. Common covariance estimation,[0],[0]
"In particular, this means that the smallest eigenvalue of (at least some of) the subject-specific factors {Σvj} must be arbitrarily small.",3. Common covariance estimation,[0],[0]
"Indeed, otherwise there would exist some α > 0",3. Common covariance estimation,[0],[0]
such that Σvj αI for every j so that αI would be common to all {Σvj} and not subject-specific.,3. Common covariance estimation,[0],[0]
"In other words, the common component in this case is in fact Σu + αI and the noise covariances are Σvj − αI .
",3. Common covariance estimation,[0],[0]
"Let us first informally describe the key idea underlying
our method, and then provide a formal “group consistency” result.",3. Common covariance estimation,[0],[0]
Denote the eigenvalues of Σu by λ1 ≤ λ2 ≤ . . .,3. Common covariance estimation,[0],[0]
", λd and the corresponding eigenvectors by q1, q2, . . .",3. Common covariance estimation,[0],[0]
", qd.",3. Common covariance estimation,[0],[0]
"We will begin by estimating the smallest eigenvalue, λ1, and its associated eigenvector, q1.",3. Common covariance estimation,[0],[0]
"By definition,
λ1 = min ‖q‖=1
qTΣuq. (3)
Now, observe that
qTΣuq ≤ qTΣxjq, ∀j,∀q (4)
since qTΣxjq = q TΣuq + q TΣvjq and q TΣvjq ≥ 0.",3. Common covariance estimation,[0],[0]
"Our assumption, which we formalize mathematically below, is that the subject-specific noise covariances Σvj are diverse in the sense that their bottom eigenvectors tend to point in different directions.",3. Common covariance estimation,[0],[0]
"This, together with the fact their smallest eigenvalue can be arbitrarily small, implies that as the number of subjects grows, it becomes increasingly likely that for every direction q, at least one of the values {qTΣvjq}mj=1 be small.",3. Common covariance estimation,[0],[0]
"This motivates us to estimate λ1 and q1 as
q̂1 = arg min ‖q‖=1 min j∈{1,...,m}
qTΣxjq, (5)
λ̂1 = min ‖q‖=1 min j∈{1,...,m}
qTΣxjq. (6)
That is, we minimize over the pointwise minimum of the quadratic functions of the individual subjects.",3. Common covariance estimation,[0],[0]
Figure 2 visualizes this objective for the case of 2× 2 matrices.,3. Common covariance estimation,[0],[0]
"Here, the thick blue curve corresponds to the desired objective function (3), which we cannot directly minimize (as it involves the unknown Σu).",3. Common covariance estimation,[0],[0]
"The thin curves correspond to
Algorithm 1 Common covariance estimation Input: Covariance matrices Σx1 , . . .",3. Common covariance estimation,[0],[0]
",Σxm in Rd×d.",3. Common covariance estimation,[0],[0]
Output: Common covariance estimate Σ̂u.,3. Common covariance estimation,[0],[0]
for k = 1 . . .,3. Common covariance estimation,[0],[0]
"d do
Using (14), compute q̂k and λ̂k as
q̂k = arg min q∈Sk min j∈{1,...,m}
qTΣxjq, (11)
",3. Common covariance estimation,[0],[0]
"λ̂k = min q∈Sk min j∈{1,...,m}
qTΣxjq, (12)
where
Sk = { q : ‖q‖ = 1, q ⊥ span{q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂k−1} } .
(13)
end for Construct Σ̂u from {q̂k}mk=1 and {λ̂k}mk=1 as in (10).
",3. Common covariance estimation,[0],[0]
the quadratic functions of the subjects (involving the known matrices {Σxj}).,3. Common covariance estimation,[0],[0]
"As can be seen, the pointwise minimum of the thin curves (dotted curve) is close to the thick curve when the number of subjects is large.
",3. Common covariance estimation,[0],[0]
"Next, we turn to estimate λ2 and q2.",3. Common covariance estimation,[0],[0]
"Note that
λ2 = min {q:‖q‖=1,q⊥q1}
qTΣuq
≤ min {q:‖q‖=1,q⊥q1} qTΣxjq, ∀j.",3. Common covariance estimation,[0],[0]
"(7)
Therefore, following the logic above, and replacing q1 by its estimate q̂1, we propose to calculate q̂2 and λ̂2 as
q̂2 = arg min {q:‖q‖=1,q⊥q̂1} min j∈{1,...,m}
qTΣxjq, (8)
λ̂2 = min {q:‖q‖=1,q⊥q̂1} min j∈{1,...,m}
qTΣxjq. (9)
",3. Common covariance estimation,[0],[0]
"This process can be repeated, where at the kth step, we constrain the search to the subspace orthogonal to span{q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂k−1}.",3. Common covariance estimation,[0],[0]
"The last eigenvector, q̂d, is completely determined by q̂1, . . .",3. Common covariance estimation,[0],[0]
", q̂d−1 and thus does not involve an optimization problem.",3. Common covariance estimation,[0],[0]
"The associated eigenvalue is estimated as λ̂d = minj∈{1,...,m} q̂ T d Σxj q̂d.
",3. Common covariance estimation,[0],[0]
"Having estimated all the eigenvalues and eigenvectors, we construct our estimate of Σu as
Σ̂u = d∑ k=1 λ̂kq̂kq̂",3. Common covariance estimation,[0],[0]
T k .,3. Common covariance estimation,[0],[0]
"(10)
",3. Common covariance estimation,[0],[0]
This is summarized in Alg. 1.,3. Common covariance estimation,[0],[0]
"The objective in Problems (11),(12) is the pointwise minimum of a finite set of continuous (quadratic) functions over
a compact set.",3.1. Practical implementation,[0],[0]
"Therefore, the minimum is attained at the minimum of one of those functions, each of which has a closed form.",3.1. Practical implementation,[0],[0]
"Specifically, when k = 1, we only have the constraint ‖q‖ = 1, and the minimum of the jth problem is the smallest eigenvalue of Σxj (attained by the corresponding eigenvector).",3.1. Practical implementation,[0],[0]
"When k > 1, we have an additional set of linear constraints, which can be written asQkq = 0, where Qk = ∑k−1 i=1",3.1. Practical implementation,[0],[0]
q̂iq̂ T i .,3.1. Practical implementation,[0],[0]
"In this case, the minimizer is given by the top eigenvector of (I −Qk)(cI −Σxj )(I −Qk), which we denote by vkj , where c is any constant such that cI −Σxj 0",3.1. Practical implementation,[0],[0]
"(Blau & Michaeli, 2017).",3.1. Practical implementation,[0],[0]
"Thus, in summary,
q̂k = v k j∗ , λ̂k = (v k j∗) TΣxjv k j∗ , (14)
where j∗ = arg minj∈{1,...,m}(v k j )",3.1. Practical implementation,[0],[0]
"TΣxjv k j .
",3.1. Practical implementation,[0],[0]
"In the Supplementary Material, we discuss ways to speed up the estimation on parallel platforms.",3.1. Practical implementation,[0],[0]
To analyze the behavior of Alg.,3.2. Group consistency,[0],[0]
"1 as the number of subjects m increases, one must assume something regarding the variability of the subject-specific noise covariances Σvj .",3.2. Group consistency,[0],[0]
"A rather general assumption is that they are independent draws from some distribution over PSD matrices, namely
Σvj ∼ pΣv .",3.2. Group consistency,[0],[0]
"(15)
The next theorem shows that under very mild conditions on pΣv , our estimate Σ̂u converges to Σu almost surely (a.s.).",3.2. Group consistency,[0],[0]
"We refer to this as group consistency.
",3.2. Group consistency,[0],[0]
Theorem 1 (Group consistency).,3.2. Group consistency,[0],[0]
"Assume that
P (λmax(Σv) ≤ α) = 1 (16)
for some α > 0 and that P ( qTΣvq ≤ )",3.2. Group consistency,[0],[0]
"> 0 (17)
for every > 0 and every unit-norm q. Let Σ̂ m
u denote the estimate produced by Alg. 1 using m subjects.",3.2. Group consistency,[0],[0]
"Then
P (
lim m→∞ ∥∥∥Σ̂mu −Σu∥∥∥ = 0) = 1. (18) Assumption (16) merely states that the noise factors are not arbitrarily large.",3.2. Group consistency,[0],[0]
Assumption (17) is a condition on the distribution of the smallest eigenvalue of Σv and its associated eigenvector.,3.2. Group consistency,[0],[0]
"Roughly speaking, it requires that there be a positive probability for the smallest eigenvalue to be arbitrarily small and, simultaneously, for the corresponding eigenvector to point in any direction (i.e., this eigenvector can have any distribution on the unit sphere as long as it does not vanish on a set of nonzero Lebesgue measure).",3.2. Group consistency,[0],[0]
"Recall that the condition on the smallest eigenvalue is actually
part of the definition of the common covariance estimation problem, and therefore not a limiting assumption.
",3.2. Group consistency,[0],[0]
"To prove the theorem, let us denote ψ(q) , qTΣuq, gj(q) , qTΣvjq, and hm(q) , minj∈{1,...,m} gj(q).",3.2. Group consistency,[0],[0]
Note that ψ(q) is a deterministic function (as Σu is deterministic) whereas {gj(q)} and {hm(q)} are sequences of random functions (as {Σvj} are random).,3.2. Group consistency,[0],[0]
"We will need the following lemmas (see proofs in the Supplementary).
",3.2. Group consistency,[0],[0]
Lemma 1.,3.2. Group consistency,[0],[0]
"For every q, the sequence of random variables {hm(q)} converges to zero almost surely.",3.2. Group consistency,[0],[0]
"Furthermore, for any sequence of vectors {qm}∞m=1 that converges to some vector q∗, the sequence of random variables {hm(qm)} converges to zero almost surely.
",3.2. Group consistency,[0],[0]
Lemma 2.,3.2. Group consistency,[0],[0]
"Let φ(q) be a continuous bounded function on a compact set C, which achieves a strict global minimum at q∗ ∈ C. Let {fn(q)}∞n=1 be a sequence of continuous bounded nonnegative functions on C satisfying fn(q∗)→ 0, and let wn(q) = φ(q) + fn(q).",3.2. Group consistency,[0],[0]
"Then any sequence of the form qn ∈ arg minq∈C wn(q) converges to q∗, and the sequence wn(qn) converges to φ(q ∗).
proof of Theorem 1.",3.2. Group consistency,[0],[0]
"For simplicity, we prove the theorem for d = 2.",3.2. Group consistency,[0],[0]
"The extension to higher dimensions is similar.
",3.2. Group consistency,[0],[0]
"Since problem (11) is symmetric, we can divide the unit circle into two disjoint half circles A and B such that A is closed, and restrict the search for the minimum to A. Let us first assume that λ1 6= λ2.",3.2. Group consistency,[0],[0]
"In this case, the minimum of ψ(q) over the unit circle is achieved at the points q1 and −q1.",3.2. Group consistency,[0],[0]
"Without loss of generality, we assume that q1 ∈",3.2. Group consistency,[0],[0]
A and −q1 ∈,3.2. Group consistency,[0],[0]
B.,3.2. Group consistency,[0],[0]
The objective in (11) can be written as ψ(q) + hm(q).,3.2. Group consistency,[0],[0]
"Since hm(q) is continuous for every m and hm(q1)
",3.2. Group consistency,[0],[0]
a.s.→ 0,3.2. Group consistency,[0],[0]
"(Lemma 1), the conditions of Lemma 2 hold a.s.",3.2. Group consistency,[0],[0]
"Therefore, our estimate of the bottom eigenvector, q̂m1 , converges a.s.",3.2. Group consistency,[0],[0]
"to the true eigenvector q1, namely
q̂m1 a.s.→ q1.",3.2. Group consistency,[0],[0]
"(19)
Our estimate (12) of the bottom eigenvalue, λ̂m1 , can be written as ψ(q̂m1 ) +",3.2. Group consistency,[0],[0]
hm(q̂ m 1 ).,3.2. Group consistency,[0],[0]
"Since q̂ m 1
a.s.→ q1, we have from Lemma 1 that hm(q̂ m 1 )",3.2. Group consistency,[0],[0]
"a.s.→ 0, and therefore λ̂m1 a.s.→ ψ(q1)",3.2. Group consistency,[0],[0]
"= λ1 as well.
",3.2. Group consistency,[0],[0]
"The top eigenvector is given by q2 = Rq1, where R is a 90◦ rotation matrix, and our estimate of this eigenvector is simply q̂2 = Rq̂1.",3.2. Group consistency,[0],[0]
"Therefore, (19) implies that also
q̂m2 a.s.→ q2.",3.2. Group consistency,[0],[0]
"(20)
The convergence of λ̂m2 to λ2 follows similarly by Lemma 1.
",3.2. Group consistency,[0],[0]
Let us now treat the case where λ1 = λ2.,3.2. Group consistency,[0],[0]
"In this setting, the vectors q̂m1 , q̂ m 2 do not necessarily converge.",3.2. Group consistency,[0],[0]
"However, for the matrix Σ̂ m
u to converge to Σu, it suffices that only
the eigenvalue estimates λ̂m1 , λ̂ m 2 converge to λ1, λ2 (in that case, the vectors q̂m1 , q̂ m 2 have no effect in (10)).",3.2. Group consistency,[0],[0]
"To see that the eigenvalues converge, note that the solution of (12) is bounded from below by minq∈S1 ψ(q) = λ1, because hm(q) ≥ 0.",3.2. Group consistency,[0],[0]
"Additionally, we have that
λ̂m1 = min q∈S1 min j∈{1,...,m} qTΣxjq
= λ1 + min q∈S1 hm(q) ≤",3.2. Group consistency,[0],[0]
"λ1 + hm(q̄) a.s.→ λ1, (21)
where q̄ is an arbitrary point in S1, and the convergence is due to Lemma 1.",3.2. Group consistency,[0],[0]
Therefore λ̂m1 converges to λ1.,3.2. Group consistency,[0],[0]
"Similar arguments can be invoked to show that λ̂m2 converges to λ2.
",3.2. Group consistency,[0],[0]
"Since the eigenvectors and eigenvalues converge, Σ̂ m
u converges to Σu, and the proof is complete.",3.2. Group consistency,[0],[0]
"Next, we address the problem of estimating the pdf pu of the common component, given the pdfs {pxj} of the subjects in the group.
",4. Common density function estimation,[0],[0]
"Since u and xj are statistically independent, we have that pxj (α) =",4. Common density function estimation,[0],[0]
( pu ∗ pvj ),4. Common density function estimation,[0],[0]
"(α), (22)
where ‘∗’ denotes convolution.",4. Common density function estimation,[0],[0]
"Furthermore,
ϕxj (t) = ϕu(t)ϕvj (t), (23)
where ϕz(t) =",4. Common density function estimation,[0],[0]
"E[ejt T z] denotes the characteristic function of a random vector z. We will focus on estimating ϕu(t), from which pu can be retrieved by a Fourier transform.
",4. Common density function estimation,[0],[0]
"A well known property of characteristic functions is that |ϕz(t)| ≤ 1 for every t. Therefore, we have from (23) that |ϕu(t)| ≥ |ϕxj (t)| for every j and for all t. In particular,
|ϕu(t)|",4. Common density function estimation,[0],[0]
"≥ max j∈{1,...,m} ∣∣ϕxj (t)∣∣ , ∀t. (24) Based on this observation, we propose to take the maximum among the values {|ϕxj (t)|}mj=1 as our estimate of |ϕu(t)|, for every t.",4. Common density function estimation,[0],[0]
"The idea is that if the noise characteristic functions {ϕvj (t)} are diverse, then for every t, it is likely that at least one of them attain a value close to 1 (in absolute value).",4. Common density function estimation,[0],[0]
"Namely, at least one of the values {|ϕxj (t)|} is close to |ϕu(t)|, which justifies our estimator.",4. Common density function estimation,[0],[0]
"To estimate the phase of ϕu(t), we take the phase of the characteristic function ϕxj (t) that attains the maximum.",4. Common density function estimation,[0],[0]
"That is, we construct our estimate as
k(t) = arg max j∈{1,...,m} |ϕxj (t)|,
ϕ̂u(t) = ϕxk(t)(t).",4. Common density function estimation,[0],[0]
"(25)
Algorithm 2 Common density estimation",4. Common density function estimation,[0],[0]
"Input: Density functions px1 , . . .",4. Common density function estimation,[0],[0]
", pxm .",4. Common density function estimation,[0],[0]
Output: Common density estimate p̂u. for j = 1 . .,4. Common density function estimation,[0],[0]
.m,4. Common density function estimation,[0],[0]
"do
Set ϕxj ← IDFT{pxj}.",4. Common density function estimation,[0],[0]
"for all t do
Set k as the index of the largest value in {ϕxj (t)}.",4. Common density function estimation,[0],[0]
"Set ϕ̂u(t)← ϕxk(t).
end for end for Set p̂u ← DFT{ϕ̂u}.",4. Common density function estimation,[0],[0]
"Truncate the negative values of p̂u and normalize it to have unit area.
",4. Common density function estimation,[0],[0]
"Note that our phase estimate is accurate when the pdfs {pvj} are symmetric (e.g., when {vj} are zero-mean Gaussian random vectors).",4. Common density function estimation,[0],[0]
"Indeed, in that case the phase of ϕvj is zero, so that the phase of ϕu equals the phase of ϕxj .",4. Common density function estimation,[0],[0]
"Our common pdf estimation algorithm is summarized in Alg. 2.
",4. Common density function estimation,[0],[0]
"It is interesting to note that Alg. 2 has been proposed in the Image Processing community, as a way of removing blur from several blurry images the of same scene (Delbracio & Sapiro, 2015).",4. Common density function estimation,[0],[0]
The analogy to our setting is quite natural.,4. Common density function estimation,[0],[0]
"The functions pxj in our context can be thought of as “blurry” versions of the function pu, where the “blur kernels” are the functions pvj (see (22)).",4. Common density function estimation,[0],[0]
"In this section we verify the effectiveness of our methods, first on simulated data and then on real data.",5. Experiments,[0],[0]
"In our first experiment, we study the behavior of our common covariance estimator as a function of the number of subjects and the signal to noise ratio (SNR).",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We take the common component u to be a two-dimensional random vector with covariance matrix
Σu =
( 1 0.5
0.5 1
) .",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"(26)
Our goal is to estimate the Pearson correlation coefficient between u(1) and u(2) (which is ρ = 0.5 in this case) from the perturbed versions Σxj = Σu + Σvj .",5.1. Estimation of Pearson correlation coefficient,[0],[0]
This can be done by first estimating Σu and then normalizing the offdiagonal entry by the square-roots of the diagonal entries.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We compare our estimator (Alg. 1) with naive averaging of {Σxj} using either Euclidean or Riemannian mean.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We generate the matrices {Σvj} as
Σvj = M jΛjM T j , (27)
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"whereM j are random rotation matrices whose angles are distributed uniformly in [0, 2π], and Λj are random diagonal matrices",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Λj = diag{βj1, β j 2} with β j 1 ∼ U [0, b] and βj2 ∼ U [b, 2b] for some b > 0.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"We draw {M j}, {β j 1}, {β j 2} independently.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"The SNR, which we define as SNR = Tr{Σu}/E{Tr{Σv}}, is 1/b in this case.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
Figures 3 and 4 visualize the mean and variance of our estimator as well as of the naive Euclidean and Riemanian mean estimators (using 200 trials per setting) as functions of the number of subjects and the SNR.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"As can be seen, while the variance of our estimator is slightly larger than the variances of the naive estimators, its bias is significantly smaller.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Therefore, overall, it attains a substantially lower mean square error.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
Figure 3 also indicates that our estimator is asymptotically (in the number of subjects) unbiased.,5.1. Estimation of Pearson correlation coefficient,[0],[0]
"The naive estimators, on the other hand, have severe biases, which do not decrease with the number of subjects.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"Figure 4 further illustrates that the performance of the naive
estimators degrades rapidly as the SNR decreases, while our estimator remains relatively accurate even at low SNRs.
",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"In this example, the poor performance of the naive estimators is mainly rooted in their over-estimation of the diagonal entries of Σu.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"This happens because the contributions of the noise matrices {Σvj} are only positive on the diagonal, so that averaging does not cancel them out.",5.1. Estimation of Pearson correlation coefficient,[0],[0]
"In most practical cases, the advantage of our approach is not confined to the diagonal elements of Σu.",5.2. Clustered subject-specific noise covariances,[0],[0]
"Specifically, although our algorithm relies on the diversity of the noise covariances, it does not require their eigenvectors to be uniformly distributed on the unit sphere.",5.2. Clustered subject-specific noise covariances,[0],[0]
"Therefore, our technique can even handle cases in which the noise covariances tend to cluster around a certain matrix.",5.2. Clustered subject-specific noise covariances,[0],[0]
"As long as there exists a nonzero probability to encounter matrices away from the cluster, our algorithm is guaranteed to produce an accurate estimate as the number of subjects grows.",5.2. Clustered subject-specific noise covariances,[0],[0]
"This is in contrast to naive averaging, which typically produces estimates with severe bias in all matrix entries.
",5.2. Clustered subject-specific noise covariances,[0],[0]
"To illustrate this, we next perform a 3× 3 common covariance estimation experiment.",5.2. Clustered subject-specific noise covariances,[0],[0]
"We generate Σvj as in (27), where now we construct the unitary matrixM j assin(θ1) cos(θ2) sin(θ1) sin(θ2) cos(θ1)cos(θ1)",5.2. Clustered subject-specific noise covariances,[0],[0]
"cos(θ2) cos(θ1) sin(θ2) − sin(θ1)
− sin(θ2) cos(θ2) 0  , (28) with θ1 and θ2 being two independent random variables with a normal distribution N (1, 1) truncated to [0, π] and
[0, 2π], respectively (Chopin, 2011).
",5.2. Clustered subject-specific noise covariances,[0],[0]
"Figure 5 depicts the estimation results obtained with Alg. 1 and with naive averaging, using 1000 subjects.",5.2. Clustered subject-specific noise covariances,[0],[0]
We show results for three different common covariance matrices.,5.2. Clustered subject-specific noise covariances,[0],[0]
"These include a zero matrix (first row), an identity matrix (second row), and a random PSD matrix (third row).",5.2. Clustered subject-specific noise covariances,[0],[0]
"As can be seen, the Euclidean and Riemannian means produce inaccurate estimates in all entries of the matrix while our estimator produces accurate results.",5.2. Clustered subject-specific noise covariances,[0],[0]
This is despite the preference of the noise covariances towards specific patterns.,5.2. Clustered subject-specific noise covariances,[0],[0]
"Next, we applied our covariance estimation algorithm on the ADHD200-preprocessed dataset (Bellec et al., 2017).",5.3. FMRI data,[0],[0]
We used the Athena pipeline.,5.3. FMRI data,[0],[0]
"In particular, we used preprocessed resting state fMRI data, written into MNI space at
4mm×4mm×4mm voxel resolution.",5.3. FMRI data,[0],[0]
"We removed nuisance variance (Lund, 2001; Fox et al., 2005), applied a temporal bandpass filter (0.009 Hz < f < 0.08 Hz) (Fox et al., 2005; Biswal et al., 1995; Cordes et al., 2001) and a spatial Gaussian filter (6mm FWHM), and removed linear trend from the extracted time-courses.",5.3. FMRI data,[0],[0]
"We took the 458 control subjects from the published training set (for results on 141 subjects with ADHD, please see the Supplementary).",5.3. FMRI data,[0],[0]
"From each subject, we extracted time-courses of 39 regions of interest (ROI) of the MSDL atlas (Varoquaux et al., 2011) and estimated their covariance using the Ledoit-Wolf estimator (Ledoit & Wolf, 2004).",5.3. FMRI data,[0],[0]
This gave us a 39× 39 covariance matrix per subject.,5.3. FMRI data,[0],[0]
"We estimated the common covariance matrix using Alg. 1, using Geometric (Riemannian) mean (Varoquaux et al., 2010a), and using Euclidean mean.",5.3. FMRI data,[0],[0]
"From the estimated covariances, we calculated correlation matrices.",5.3. FMRI data,[0],[0]
"We used the nilearn and scikit-learn python packages
(Abraham et al., 2014; Pedregosa et al., 2011; Buitinck et al., 2013).",5.3. FMRI data,[0],[0]
The running time of Alg. 1 was about 10s on an 8 core Intel i7-6700 with 16GB of RAM working at 3.40GHz.,5.3. FMRI data,[0],[0]
"The results are depicted in Fig. 6.
",5.3. FMRI data,[0],[0]
"It has been shown that estimates of connectivity patterns often vary significantly between subjects (Moussa et al., 2012).",5.3. FMRI data,[0],[0]
"As can be seen in Fig. 6, our estimator detects activity within known networks despite the large variability between subjects.",5.3. FMRI data,[0],[0]
"In particular, our estimator detects stronger correlations than the Euclidean and Riemannian mean estimators within the Default Mode Network, the Right Ventral Attention network, the Left Ventral Attention network, and the Cingulate Insula (connectivity between cingulate cortex and insula) (Moussa et al., 2012).",5.3. FMRI data,[0],[0]
Zoomed versions of those networks are shown in Fig. 7.,5.3. FMRI data,[0],[0]
Note that the Euclidean mean estimator shows very low correlations within some of those regions.,5.3. FMRI data,[0],[0]
"In our last experiment, we used Alg. 2 to estimate the joint density function of arterial blood pressure (ABP) and photoplethysmogram (PPG) recordings.",5.4. Common density of PPG and ABP,[0],[0]
"We used measurements from 25 subjects in critical care taken from the MIMIC 2 dataset (Kachuee et al., 2015).",5.4. Common density of PPG and ABP,[0],[0]
"As a preprocessing step, we normalized the signals to have zero mean and unit variance.
",5.4. Common density of PPG and ABP,[0],[0]
"For each subject, we then estimated the 2D pdf of ABP and PPG using Gaussian KDE with bandwidth 0.08.",5.4. Common density of PPG and ABP,[0],[0]
"From the resulting 25 pdfs, we estimated the common pdf using Alg. 2.",5.4. Common density of PPG and ABP,[0],[0]
"As can be seen in Fig. 8, our algorithm manages to reveal delicate structures in the common pdf, which are not seen when applying KDE on all the data from all the subjects.",5.4. Common density of PPG and ABP,[0],[0]
"In the Supplementary, we show that these structures are not detected with naive KDE with any bandwidth.",5.4. Common density of PPG and ABP,[0],[0]
This illustrates again the ability of our approach to suppress subject-specific noise factors that have different distributions.,5.4. Common density of PPG and ABP,[0],[0]
"We presented algorithms for estimating the covariance and the pdf of the common component of a group of subjects, when noise has a different distribution for each subject.",6. Conclusion,[0],[0]
Our algorithms take advantage of the diversity of the subjectspecific noise distributions in order to efficiently suppress them.,6. Conclusion,[0],[0]
"In contrast to previous approaches, we did not assume any parametric model for the underlying distributions.",6. Conclusion,[0],[0]
"We proved that under rather mild assumptions, our common covariance estimate tends to the covariance of the common component as the number of subjects grows.",6. Conclusion,[0],[0]
"We presented experiments on simulated and on real data, which confirmed the advantages of our methods over alternative approaches.",6. Conclusion,[0],[0]
"In many areas of neuroscience and biological data analysis, it is desired to reveal common patterns among a group of subjects.",abstractText,[0],[0]
"Such analyses play important roles e.g., in detecting functional brain networks from fMRI scans and in identifying brain regions which show increased activity in response to certain stimuli.",abstractText,[0],[0]
"Group level techniques usually assume that all subjects in the group behave according to a single statistical model, or that deviations from the common model have simple parametric forms.",abstractText,[0],[0]
"Therefore, complex subject-specific deviations from the common model severely impair the performance of such methods.",abstractText,[0],[0]
"In this paper, we propose nonparametric algorithms for estimating the common covariance matrix and the common density function of several variables in a heterogeneous group of subjects.",abstractText,[0],[0]
"Our estimates converge to the true model as the number of subjects tends to infinity, under very mild conditions.",abstractText,[0],[0]
We illustrate the effectiveness of our methods through extensive simulations as well as on real-data from fMRI scans and from arterial blood pressure and photoplethysmogram measurements.,abstractText,[0],[0]
Revealing Common Statistical Behaviors in Heterogeneous Populations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4295–4305 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4295",text,[0],[0]
Neural Machine Translation (NMT) has largely replaced the complex pipeline of Phrase-Based MT with a single model that is trained end-to-end.,1 Introduction,[0],[0]
"However, NMT systems still typically rely on preand post-processing operations such as tokenization and word fragmentation through byte-pair encoding (BPE; Sennrich et al., 2016).",1 Introduction,[0],[0]
"Although these are effective, they involve hyperparameters
∗*Equal contributions
that should ideally be tuned for each language pair and corpus, an expensive step that is frequently omitted.",1 Introduction,[0],[0]
"Even when properly tuned, the representation of the corpus generated by pipelined external processing is likely to be sub-optimal.",1 Introduction,[0],[0]
"For instance, it is easy to find examples of word fragmentations, such as fling → fl + ing, that are linguistically implausible.",1 Introduction,[0],[0]
"NMT systems are generally robust to such infelicities—and can be made more robust through subword regularization (Kudo, 2018)—but their effect on performance has not been carefully studied.",1 Introduction,[0],[0]
"The problem of finding optimal segmentations becomes more complex when an NMT system must handle multiple source and target languages, as in multilingual translation or zero-shot approaches (Johnson et al., 2017).
",1 Introduction,[0],[0]
"Translating characters instead of word fragments avoids these problems, and gives the system access to all available information about source and target sequences.",1 Introduction,[0],[0]
"However, it presents significant modeling and computational challenges.",1 Introduction,[0],[0]
"Longer sequences incur linear per-layer cost and quadratic attention cost, and require information to be retained over longer temporal spans.",1 Introduction,[0],[0]
"Finer temporal granularity also creates the potential for attention jitter (Gulcehre et al., 2017).",1 Introduction,[0],[0]
"Perhaps most significantly, since the meaning of a word is not a compositional function of its characters, the system must learn to memorize many character sequences, a different task from the (mostly) compositional operations it performs at higher levels of linguistic abstraction.
",1 Introduction,[0],[0]
"In this paper, we show that a standard LSTM sequence-to-sequence model works very well for characters, and given sufficient depth, consistently outperforms identical models operating over word fragments.",1 Introduction,[0],[0]
"This result suggests that a productive line of research on character-level models is to seek architectures that approximate standard sequence-to-sequence models while being compu-
tationally cheaper.",1 Introduction,[0],[0]
One approach to this problem is temporal compression: reducing the number of state vectors required to represent input or output sequences.,1 Introduction,[0],[0]
"We evaluate various approaches for performing temporal compression, both according to a fixed schedule; and, more ambitiously, learning compression decisions with a Hierarchical Multiscale architecture (Chung et al., 2017).",1 Introduction,[0],[0]
"Following recent work by Lee et al. (2017), we focus on compressing the encoder.
",1 Introduction,[0],[0]
"Our contributions are as follows:
• The first large-scale empirical investigation of the translation quality of standard LSTM sequence-to-sequence architectures operating at the character level, demonstrating improvements in translation quality over word fragments, and quantifying the effect of corpus size and model capacity.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A comparison of techniques to compress
character sequences, assessing their ability to trade translation quality for increased speed.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"A first attempt to learn how to compress the
source sequence during NMT training by using the Hierarchical Multiscale LSTM to dynamically shorten the source sequence as it passes through the encoder.",1 Introduction,[0],[0]
"Early work on modeling characters in NMT focused on solving the out-of-vocabulary and softmax bottleneck problems associated with wordlevel models (Ling et al., 2015; Costa-jussà and Fonollosa, 2016; Luong and Manning, 2016).",2 Related Work,[0],[0]
"These took the form of word-boundary-aware hierarchical models, with word-level models delegating to character-level models to generate representations in the encoder and words in the decoder.",2 Related Work,[0],[0]
"Our work will not assume fixed word boundaries are given in advance.
",2 Related Work,[0],[0]
"With the advent of word-fragment approaches, interest in character-level processing fell off, but has recently been reignited with the work of Lee et al. (2017).",2 Related Work,[0],[0]
"They propose a specialized character-level encoder, connected to an unmodified character-level RNN decoder.",2 Related Work,[0],[0]
"They address the modeling and efficiency challenges of long character sequences using a convolutional layer, max-pooling over time, and highway layers.",2 Related Work,[0],[0]
"We agree with their conclusion that character-level translation is effective, but revisit the question
of whether their specific encoder produces a desirable speed-quality tradeoff in the context of a much stronger baseline translation system.",2 Related Work,[0],[0]
"We draw inspiration from their pooling solution for reducing sequence length, along with similar ideas from the speech community (Chan et al., 2016), when devising fixed-schedule reduction strategies in Section 3.3.
",2 Related Work,[0],[0]
One of our primary contributions is an extensive invesigation of the efficacy of a typical LSTM-based NMT system when operating at the character-level.,2 Related Work,[0],[0]
The vast majority of existing studies compare a specialized character-level architecture to a distinct word-level one.,2 Related Work,[0],[0]
"To the best of our knowledge, only a small number of papers have explored running NMT unmodified on character sequences; these include: Luong and Manning (2016) on WMT’15 English-Czech, Wu et al. (2016) on WMT’14 English-German, and Bradbury et al. (2016) on IWSLT German-English.",2 Related Work,[0],[0]
All report scores that either trail behind or reach parity with word-level models.,2 Related Work,[0],[0]
"Only Wu et al. (2016) compare to word fragment models, which they show to outperform characters by a sizeable margin.",2 Related Work,[0],[0]
"We revisit the question of character- versus fragment-level NMT here, and reach quite different conclusions.",2 Related Work,[0],[0]
We adopt a simplified version of the LSTM architecture of Chen et al. (2018) that achieves state-ofthe-art performance on the competitive WMT14 English-French and English-German benchmarks.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"This incorporates bidirectional LSTM (BiLSTM) layers in the encoder, concatenating the output from forward and backward directions before feeding the next layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
Output from the top encoder layer is projected down to the decoder dimension and used in an additive attention mechanism computed over the bottom decoder layer.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"The decoder consists of unidirectional layers, all of which use the encoder context vectors computed from attention weights over the bottom layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"For both encoder and decoder we use layer normalization (Ba et al., 2016) and residual connections beginning at the third layer.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
We do not apply a non-linearity to LSTM output.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"We regularize with dropout applied to embeddings and to the output of each LSTM layer.
",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"In the interests of simplicity and reproducibil-
ity, we depart from Chen et al. (2018) in several ways: we do not use multi-headed attention, feed encoder context vectors to the softmax, regularize with label smoothing or weight decay, nor apply dropout to the attention mechanism.
",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"Our baseline character models and BPE models both use this architecture, differing only in whether the source and target languages are tokenized into sequences of characters or BPE word fragments.",3.1 Baseline Sequence-to-Sequence Model,[0],[0]
We describe BPE briefly below.,3.1 Baseline Sequence-to-Sequence Model,[0],[0]
"Byte-Pair Encoding (BPE) offers a simple interpolation between word- and character-level representations (Sennrich et al., 2016).",3.2 Byte-Pair Encoding,[0],[0]
It creates a vocabulary of frequent words and word fragments in an iterative greedy merging process that begins with characters and ends when a desired vocabulary size is reached.,3.2 Byte-Pair Encoding,[0],[0]
The source and target language are typically processed together in order to exploit lexical similarities.,3.2 Byte-Pair Encoding,[0],[0]
"Given a vocabulary, BPE re-tokenizes the corpus into word fragments in a greedy left-to-right fashion, selecting the longest possible vocabulary match, and backing off to characters when necessary.
",3.2 Byte-Pair Encoding,[0],[0]
"Since each BPE token consists of one or more characters, BPE-tokenized sequences will be shorter than character sequences.",3.2 Byte-Pair Encoding,[0],[0]
"Viewed as a mechanism to reduce sequence length, BPE differs from the solutions we will discuss subsequently in that it increases the vocabulary size, delegating the task of creating representations for word fragments to the embedding table.",3.2 Byte-Pair Encoding,[0],[0]
"Also, despite being data-driven, its segmentation decisions are fixed before NMT training begins.",3.2 Byte-Pair Encoding,[0],[0]
We explore using fixed stride temporal pooling within the encoder to compress the source character sequence.,3.3 Fixed stride Temporal Pooling,[0],[0]
"These solutions are characterized by pooling the contents of two or more contiguous timesteps to create a single vector that summarizes them, and will replace them to shorten the sequence in the next layer.",3.3 Fixed stride Temporal Pooling,[0],[0]
"These approaches can learn to interpret the raw character sequence in service to their translation objective, but any such interepretation must fit into the pooling schedule that was specified during network construction.",3.3 Fixed stride Temporal Pooling,[0],[0]
"We evaluate two methods in this family: a reimplementation of Lee et al. (2017), and a version of our baseline with interspersed pooling layers.
",3.3 Fixed stride Temporal Pooling,[0],[0]
"As mentioned earlier, Lee et al. (2017) propose a specialized character encoder that combines convolutional layers to accumulate local context, max-pooling layers to reduce sequence lengths, highway layers to increase network capacity, followed by bidirectional GRU layers to generate globally aware contextual source representations.",3.3 Fixed stride Temporal Pooling,[0],[0]
This strategy is particularly efficient because all reductions happen before the first recurrent layer.,3.3 Fixed stride Temporal Pooling,[0],[0]
"We re-implement their approach faithfully, with the exceptions of using LSTMs in place of GRUs,1 and modifying the batch sizes to accomodate our multi-GPU training scheme.
",3.3 Fixed stride Temporal Pooling,[0],[0]
"While pooling based approaches are typically employed in association with convolutional layers, we can also intersperse pooling layers into our high capacity baseline encoder.",3.3 Fixed stride Temporal Pooling,[0],[0]
"This means that after each BiLSTM layer, we have the option to include a fixed-stride pooling layer to compress the sequence before it is processed by the next BiLSTM layer.",3.3 Fixed stride Temporal Pooling,[0],[0]
"This is similar to the pyramidal LSTM encoders used for neural speech recognition (Chan et al., 2016).",3.3 Fixed stride Temporal Pooling,[0],[0]
"This general strategy affords considerable flexibility to the network designer, leaving the type of pooling (concatenation, max, mean), and the strides with which to pool as design decisions that can be tuned to fit the task.",3.3 Fixed stride Temporal Pooling,[0],[0]
"It is unsatisfying to compress a sequence on a fixed schedule; after all, the characters in a sentence do not each carry an identical amount of information.",3.4 Learned Temporal Compression,[0],[0]
"The goal of this section is to explore data-driven reduction methods that are optimized to the NMT system’s objective, and which learn to compress as a part of training.
",3.4 Learned Temporal Compression,[0],[0]
"Any strategy for performing temporal compression will necessarily make discrete decisions, since sentence length is discrete.",3.4 Learned Temporal Compression,[0],[0]
"Examples of such strategies include sparse attention (Raffel et al., 2017) and discrete auto-encoders (Kaiser et al., 2018).",3.4 Learned Temporal Compression,[0],[0]
"For our initial exploration, we chose the hierarchical multiscale (HM) architecture of Chung et al. (2017), which we briefly describe.",3.4 Learned Temporal Compression,[0],[0]
"The HM is a bottom-up temporal subsampling approach, with each layer selecting the timesteps that will survive to the layer above.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"At a given timestep t and layer `, the network makes a binary decision,
1 Development experiments indicated that using LSTMs over GRUs resulted in a slight improvement.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"z`t , to determine whether or not it should send its output up to layer `+ 1.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"The preactivation for this decision, z̃`t , is a function of the current node’s inputs from below and from the previous hidden state, similar to an LSTM gate.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"However, z`t ’s activation is a binary step function in the forward pass, to enable discrete decisions, and a hard sigmoid in the backward pass, to allow gradients to flow through the decision point.2",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"The z`t decision affects both the layer above, and the next timestep of the current layer:
• z`t = 1, flow up: the node above (t, `+1) performs a normal LSTM update; the node to the right (t+1, `) performs a modified update called a flush, which ignores the LSTM internal cell at (t, `), and redirects the incoming LSTM hidden state from (t, `) to (t, `+ 1).
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"• z`t = 0, flow right: the node above (t, `+1) simply copies the cell and hidden state values from (t−1, `+1); the node to the right (t+1, `) performs a normal LSTM update.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Conceptually, when z`t = 0, the node above it becomes a placeholder and is effectively removed from the sequence for that layer.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Shorter upper layers save computation and facilitate the left-toright flow of information for the surviving nodes.
",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"Typically, one uses the top hidden state hLt from a stack of L RNNs to provide the representation for a timestep t. But for the HM, the top layer may be updated much less frequently than the layers below it.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"To enable tasks that need a distinct representation for each timestep, such as language modeling, the HM employs a gated output module to mix hidden states across layers.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
"This learned module combines the states h1t , h 2 t , . .",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
.,3.4.1 Hierarchical Multiscale LSTM,[0],[0]
", h L t using scaling and projection operators to produce a single output ht.",3.4.1 Hierarchical Multiscale LSTM,[0],[0]
We would like sequences to become progressively shorter as we move upward through the layers.,3.4.2 Modifying the HM for NMT,[0],[0]
"As originally specified, the HM calculates z`t independently for every t and `, including copied nodes, meaning that a “removed” timestep could reappear in a higher layer when a copied node (t, `) sets z`t = 1.",3.4.2 Modifying the HM for NMT,[0],[0]
"This is easily addressed by locking z ` t = 0 for copied nodes, creating a hierarchical structure
2This disconnect between forward and backward activations is known as a straight-through estimator (Bengio et al., 2013).
in which upper layers never increase the amount of computation.
",3.4.2 Modifying the HM for NMT,[0],[0]
"We also found that the flush component of the original architecture, which modifies the LSTM update at (t+1, `) to discard the LSTM’s internal cell, provided too much incentive to leave z`t at 0, resulting in degenerate configurations which collapsed to having very few tokens in their upper layers.",3.4.2 Modifying the HM for NMT,[0],[0]
We addressed this by removing the notion of a flush from our architecture.,3.4.2 Modifying the HM for NMT,[0],[0]
"The node to the right (t+1, `) always performs a normal LSTM update, regardless of z`t .",3.4.2 Modifying the HM for NMT,[0],[0]
"This modification is similar to one proposed independently by Kádár et al. (2018), who simplified the flush operation by removing the connection to (t, `+ 1).
",3.4.2 Modifying the HM for NMT,[0],[0]
"We found it useful to change the initial value of the bias term used in the calculation of z̃`t , which we refer to as the z-bias.",3.4.2 Modifying the HM for NMT,[0],[0]
"Setting z-bias to 1, which is the saturation point for the hard sigmoid with slope 1, improves training stability by encouraging the encoder to explore configurations where most timesteps survive through all layers, before starting to discard them.
",3.4.2 Modifying the HM for NMT,[0],[0]
"Even with these modifications, we observed degenerate behavior in some settings.",3.4.2 Modifying the HM for NMT,[0],[0]
"To discourage this, we added a compression loss component similar to that of Ke et al. (2018) to penalize z activation rates outside a specified range α1, α2:",3.4.2 Modifying the HM for NMT,[0],[0]
"Lc = ∑ l max(0, Z
l − α1T, α2T − Z l), where T is source sequence length and Z l = ∑T t=1 z",3.4.2 Modifying the HM for NMT,[0],[0]
"l t.
To incorporate the HM into our NMT encoder, we replace the lowest BiLSTM layer with unidirectional HM",3.4.2 Modifying the HM for NMT,[0],[0]
layers.3 We adapt any remaining BiLSTM layers to copy or update according to the z-values calculated by the top HM layer.,3.4.2 Modifying the HM for NMT,[0],[0]
"We adopt the corpora used by Lee et al (2017), with the exception of WMT15 Russian-English.4 To measure performance on an “easy” language pair, and to calibrate our results against recent benchmarks, we also included WMT14 EnglishFrench.",4.1 Corpora,[0],[0]
Table 1 gives details of the corpora used.,4.1 Corpora,[0],[0]
"All corpora are preprocessed using Moses tools.5
3The flush operation makes the original HM inherently left-to-right.",4.1 Corpora,[0],[0]
"Since we have dropped flushes from our current version, it should be straightforward to devise a bidirectional variant, which we leave to future work.
",4.1 Corpora,[0],[0]
4Due,4.1 Corpora,[0],[0]
to licence restrictions.,4.1 Corpora,[0],[0]
"5 Scripts and arguments:
remove-non-printing-char.perl
Dev and test corpora are tokenized, but not filtered or cleaned.",4.1 Corpora,[0],[0]
"Our character models use only the most frequent 496 characters across both source and target languages; similarly, BPE is run across both languages, with a vocabulary size of 32k.",4.1 Corpora,[0],[0]
"Except where noted below, we used 6 bidirectional layers in the encoder, and 8 unidirectional layers in the decoder.","4.2 Model sizes, training, and inference",[0],[0]
"All vector dimensions were 512.
","4.2 Model sizes, training, and inference",[0],[0]
Models were trained using sentence-level crossentropy loss.,"4.2 Model sizes, training, and inference",[0],[0]
"Batch sizes are capped at 16,384 tokens, and each batch is divided among 16 NVIDIA P100s running synchronously.
","4.2 Model sizes, training, and inference",[0],[0]
Parameters were initialized with a uniform (0.04) distribution.,"4.2 Model sizes, training, and inference",[0],[0]
"We use the Adam optimizer, with β1 = 0.9, β2 = 0.999, and = 10−6 (Kingma and Ba, 2014).","4.2 Model sizes, training, and inference",[0],[0]
Gradient norm is clipped to 5.0.,"4.2 Model sizes, training, and inference",[0],[0]
"The initial learning rate is 0.0004, and we halve it whenever dev set perplexity has not decreased for 2k batches, with at least 2k batches between successive halvings.","4.2 Model sizes, training, and inference",[0],[0]
"Training stops when dev set perplexity has not decreased for 8k batches.
","4.2 Model sizes, training, and inference",[0],[0]
"Inference uses beam search with 8 hypotheses, coverage penalty of 0.2 (Tu et al., 2016), and length normalization of 0.2 (Wu et al., 2016).","4.2 Model sizes, training, and inference",[0],[0]
"When comparing character-level and BPE models, we tuned dropout independently for each setting, greedily exploring increments of 0.1 in the range 0.1–0.5, and selecting based on dev-set BLEU.",4.3 Tuning and Evalution,[0],[0]
"This expensive strategy is crucial to obtaining valid conclusions, since optimal dropout values tend to be lower for character models.
",4.3 Tuning and Evalution,[0],[0]
Our main evaluation metric is Moses-tokenized case-sensitive BLEU score.,4.3 Tuning and Evalution,[0],[0]
We report test-set scores on the checkpoints having highest dev-set BLEU.,4.3 Tuning and Evalution,[0],[0]
"To facilitate comparison with future work
tokenize.perl clean-corpus-n.perl -ratio 9 1 100
we also report SacreBLEU scores (Post, 2018) for key results, using the Moses detokenizer.",4.3 Tuning and Evalution,[0],[0]
"We begin with experiments to compare the standard RNN architecture from Section 3.1 at the character and BPE levels, using our full-scale model with 6 bidirectional encoder layers and 8 decoder layers.",5.1 Character-level translation,[0],[0]
"The primary results of our experiments are presented in Table 2, while Table 3 positions the same results with respect to recent points from the literature.
",5.1 Character-level translation,[0],[0]
There are a number of observations we can draw from this data.,5.1 Character-level translation,[0],[0]
"First, from the EnFr results in Table 3, we are in line with GNMT (Wu et al., 2016), and within 2 BLEU points of the RNN and Transformer models investigated by Chen et al. (2018).",5.1 Character-level translation,[0],[0]
"So, while we are not working at the exact state-ofthe-art, we are definitely in a range that should be relevant to most practitioners.
",5.1 Character-level translation,[0],[0]
"Also from Table 3, we compare quite favorably with Lee et al. (2017), exceeding their reported scores by 3-6 points, which we attribute to having employed much higher model capacity, as they use a single bidirectional layer in the encoder and a two-layer decoder.",5.1 Character-level translation,[0],[0]
"We investigate the impact of model capacity in Section 5.1.1.
",5.1 Character-level translation,[0],[0]
"Finally, Table 2 clearly shows the characterlevel systems outperforming BPE for all language pairs.",5.1 Character-level translation,[0],[0]
"The dominance of character-level methods in Table 2 indicates that RNN-based NMT architectures are not only capable of translating charac-
ter sequences, but actually benefit from them.",5.1 Character-level translation,[0],[0]
"This is in direct contradiction to the few previously reported results on this matter, which can in most cases be explained by our increased model capacity.",5.1 Character-level translation,[0],[0]
"The exception is GNMT (Wu et al., 2016), which had similar depth.",5.1 Character-level translation,[0],[0]
"In this case, possible explanations for the discrepancy include our use of a fully bidirectional encoder, our translating into English instead of German, and our modelspecific tuning of dropout.",5.1 Character-level translation,[0],[0]
"Character-level NMT systems have a more difficult sequence-modeling task, as they need to infer the meaning of words from their constituent characters, where models with larger tokens instead delegate this task to the embedding table.",5.1.1 Effect of model capacity,[0],[0]
"Therefore, we hypothesize that increasing the model’s capacity by adding layers will have a greater impact on character-level models.",5.1.1 Effect of model capacity,[0],[0]
Figure 1 tests this hypothesis by measuring the impact of three model sizes on test BLEU score.,5.1.1 Effect of model capacity,[0],[0]
"For each of our four language pairs, the word-fragment model starts out ahead, and quickly loses ground as architecture size increases.",5.1.1 Effect of model capacity,[0],[0]
"For the languages with greater morphological complexity—German, Czech and Finnish—the slope of the character model’s curve is notably steeper than that of the BPE system, indicating that these systems could benefit from yet more modeling capacity.",5.1.1 Effect of model capacity,[0],[0]
"One of the most compelling arguments for working with characters (and to a lesser extent, wordfragments) is improved generalization.",5.1.2 Effect of corpus size,[0],[0]
"Through morphological generalizations, the system can better handle low-frequency and previously unseen words.",5.1.2 Effect of corpus size,[0],[0]
"It stands to reason that as the training corpus increases in size, the importance of these generalization capabilities will decrease.",5.1.2 Effect of corpus size,[0],[0]
"We test this hypothesis by holding the language pair constant, and varying the training corpus size by downsampling the full training corpus.",5.1.2 Effect of corpus size,[0],[0]
We choose EnFr because it has by far the most available data.,5.1.2 Effect of corpus size,[0],[0]
"We compare four sizes: 2M, 4M, 14M and 40M.
The results are shown in Figure 2.",5.1.2 Effect of corpus size,[0],[0]
"As expected, the gap between character and word-fragment modeling decreases as corpus size increases.",5.1.2 Effect of corpus size,[0],[0]
"From the slopes of the curves, we can infer that the advantage of character-level modeling will disappear completely as we reach 60-70M sentence pairs.",5.1.2 Effect of corpus size,[0],[0]
"However, there is reason to expect this break-even
point to be much higher for more morphologically complex languages.",5.1.2 Effect of corpus size,[0],[0]
It is also important to recall that relatively few language-pairs can assemble parallel corpora of this size.,5.1.2 Effect of corpus size,[0],[0]
The performance advantage of working with characters comes at a significant computational cost.,5.1.3 Speed,[0],[0]
"With our full-sized architecture, character models trained roughly 8x more slowly than BPE models.6 Figure 3 shows that training time grows linearly with number of layers in the model, and that character models have a much higher per-layer cost: roughly 0.38 msec/sentence versus 0.04 for BPE.",5.1.3 Speed,[0],[0]
"We did not directly measure the difference in attention cost, but it cannot be greater than the difference in total cost for the smallest number of layers.",5.1.3 Speed,[0],[0]
"Therefore, we can infer from Figure 3 that processing 5 layers in a character model incurs roughly the same time cost as attention.",5.1.3 Speed,[0],[0]
"This is surprising given the quadratic cost of attention, and indicates that efforts to speed up character models cannot focus exclusively on attention.",5.1.3 Speed,[0],[0]
"To make a qualitative comparison between word fragments (BPE) and characters for NMT, we examined 100 randomly selected sentence pairs from the DeEn test set.",5.1.4 Qualitative comparison,[0],[0]
"One author examined the sentences, using a display that showed the source7 and the reference, along with the output of BPE and character models.",5.1.4 Qualitative comparison,[0],[0]
Any differences between the two outputs were highlighted.,5.1.4 Qualitative comparison,[0],[0]
"They then assigned tags to both system outputs indicating broad error categories, such as lexical choice, word order and German compound handling.8",5.1.4 Qualitative comparison,[0],[0]
"Tags were restricted to cases where one system made a mistake that the other did not.
",5.1.4 Qualitative comparison,[0],[0]
"Of the 100 sentences, 47 were annotated as being identical or of roughly the same quality.",5.1.4 Qualitative comparison,[0],[0]
The remaining 53 exhibited a large variety of differences.,5.1.4 Qualitative comparison,[0],[0]
Table 4 summarizes the errors that were most easily characterized.,5.1.4 Qualitative comparison,[0],[0]
"BPE and character sys-
6Recall that we use batches containing 16,384 tokens— corresponding to a fixed memory budget—for both character and BPE models.",5.1.4 Qualitative comparison,[0],[0]
"Thus character models are slowed not only by having longer sentences, but also by parallelizing across fewer sentences in each batch.
",5.1.4 Qualitative comparison,[0],[0]
7The annotating author does not speak German.,5.1.4 Qualitative comparison,[0],[0]
8Our,5.1.4 Qualitative comparison,[0],[0]
"annotator also looked specifically for agreement and negation errors, as studied by Sennrich (2017) for English-toGerman character-level NMT.",5.1.4 Qualitative comparison,[0],[0]
"However, neither system exhibited these error types with sufficient frequency to draw meaningful conclusions.
tems differ most in the number of lexical choice errors, and in the extent to which they drop content.",5.1.4 Qualitative comparison,[0],[0]
"The latter is surprising, and appears to be a side-effect of a general tendency of the character models to be more faithful to the source, verging on being overly literal.",5.1.4 Qualitative comparison,[0],[0]
"An example of dropped content is shown in Table 5 (top).
",5.1.4 Qualitative comparison,[0],[0]
"Regarding lexical choice, the two systems differ not only in the number of errors, but in the nature of those errors.",5.1.4 Qualitative comparison,[0],[0]
"In particular, the BPE model had more trouble handling German compound nouns.",5.1.4 Qualitative comparison,[0],[0]
"Table 5 (bottom) shows an example which exhibits two compound errors, includ-
ing one where the character system is a strict improvement, translating Bunsenbrenner into bunsen burner instead of bullets.",5.1.4 Qualitative comparison,[0],[0]
"The second error follows another common pattern, where both systems mishandle the German compound (Chemiestunden / chemistry lessons), but the character system fails in a more useful way.
",5.1.4 Qualitative comparison,[0],[0]
We also found that both systems occasionally mistranslate proper names.,5.1.4 Qualitative comparison,[0],[0]
"Both fail by attempting to translate when they should copy over, but the BPE system’s errors are harder to understand as they involve semantic translation, rendering Britta Hermann as Sir Leon, and Esme Nussbaum as smiling walnut.9",5.1.4 Qualitative comparison,[0],[0]
"The character system’s one observed error in this category was phonetic rather than semantic, rendering Schotten as Scottland.
",5.1.4 Qualitative comparison,[0],[0]
"Interestingly, we also observed several instances where the model correctly translates the German 24-hour clock into the English 12-hour clock; for example, 19.30 becomes 7:30 p.m..",5.1.4 Qualitative comparison,[0],[0]
"This deterministic transformation is potentially in reach for both models, but we observed it only for the character system in this sample.
9",5.1.4 Qualitative comparison,[0],[0]
The BPE segmentations for these names were: _Britt a _,5.1.4 Qualitative comparison,[0],[0]
Herr mann and _Es me _,5.1.4 Qualitative comparison,[0],[0]
N uss baum,5.1.4 Qualitative comparison,[0],[0]
"At this point we have established that characterlevel NMT benefits translation quality, but incurs a large computational cost.",5.2 Compressing the Source Sequence,[0],[0]
"In this section, we evaluate the speed-quality tradeoffs of various techniques for reducing the number of state vectors required to represent the source sentence.",5.2 Compressing the Source Sequence,[0],[0]
"All experiments are conducted on our DeEn language pair, chosen for having a good balance of morphological complexity and training corpus size.",5.2 Compressing the Source Sequence,[0],[0]
Recall that BPE interpolates between word- and character-level processing by tokenizing consecutive characters into word fragments; larger BPE vocabulary sizes result in larger fragments and shorter sequences.,5.2.1 Optimizing the BPE vocabulary,[0],[0]
"If character-level models outperform BPE with a vocabulary size of 32k, then is there a smaller BPE vocabulary size that reaps the benefits of character-level processing, while still substantially reducing the sequence length?
",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"To answer this question, we test a number of BPE vocabularies, as shown in Table 6.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"For each vocabulary, we measure BLEU and sequence compression rate, defined as the average size of the source sequence in characters divided by its size in word fragments (the ratio for the target sequence was similar).",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"Unfortunately, even at just 1k vocabulary items, BPE has already lost a BLEU point with respect to the character model.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
"When comparing these results to the other methods in this section, it is important to recall that BPE is compressing both the source and target sequence (by approximately the same amount), doubling its effective compression rate.",5.2.1 Optimizing the BPE vocabulary,[0],[0]
The goal of these experiments is to determine whether using fixed schedule compression is a feasible alternative to BPE.,5.2.2 Fixed Stride Compression,[0],[0]
"We evaluate our reimplementation of the pooling model of Lee et al. (2017) and our pooled BiLSTM encoder, both described in Section 3.3.",5.2.2 Fixed Stride Compression,[0],[0]
"For the pooled BiLSTM encoder, development experiments led us to introduce two mean-pooling layers, a stride 3 layer after the second BiLSTM, and a stride 2 layer after the third.",5.2.2 Fixed Stride Compression,[0],[0]
"Therefore, the final output of the encoder is compressed by a factor of 6.
",5.2.2 Fixed Stride Compression,[0],[0]
The results are also shown in Table 6.,5.2.2 Fixed Stride Compression,[0],[0]
"Note that for the pooled BiLSTM, different encoder layers have different lengths: 2 full length layers, followed by 1 at 13 length and 3 at 1 6 length.",5.2.2 Fixed Stride Compression,[0],[0]
"Therefore, we report the average compression across layers here and for the HM in Section 5.2.3.
",5.2.2 Fixed Stride Compression,[0],[0]
"Our implementation of Lee et al. (2017) outperforms the original results by more than 2 BLEU
points.",5.2.2 Fixed Stride Compression,[0],[0]
We suspect most of these gains result from better optimization of the model with large batch training.,5.2.2 Fixed Stride Compression,[0],[0]
"However, our attempts to scale this encoder to larger depths, and therfore to the level of performance exhibited by our other systems, did not result in any significant improvements.",5.2.2 Fixed Stride Compression,[0],[0]
"This is possibly due to difficulties with optimizing a deeper stack of diverse layers.
",5.2.2 Fixed Stride Compression,[0],[0]
"Comparing the performance of our Pooled BiLSTM model against BPE, we notice that for a comparable level of compression (BPE size of 1k), BPE out-performs the pooled model by around 0.5 BLEU points.",5.2.2 Fixed Stride Compression,[0],[0]
"At a similar level of performance (BPE size of 4k), BPE has significantly shorter sequences.",5.2.2 Fixed Stride Compression,[0],[0]
"Although fixed-stride pooling does not yet match the performance of BPE, we remain optimistic about its potential.",5.2.2 Fixed Stride Compression,[0],[0]
"The appeal of these models derives from their simplicity; they are easy to optimize, perform reasonably well, and remove the complication of BPE preprocessing.",5.2.2 Fixed Stride Compression,[0],[0]
"We experimented with using the Hierarchical Multiscale (HM; Section 3.4.1) architecture to learn compression decisions for the encoder.
",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"For initial exploration, we used a scaled-down architecture consisting of 3 unidirectional HM encoder layers and 2 LSTM decoder layers, attending over the HM’s gated output module.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
Comparisons to an equivalent LSTM are shown in table 7.,5.2.3 Hierarchical Multiscale Compression,[0],[0]
"The first two HM lines justify the no-flush and hierarchical modifications described in Section 3.4.1, yielding incremental gains of 27.3 (the flush variant failed to converge), and 1.2 respectively.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Initializing z-bias to 1 and annealing the slope of the hard binarizer from 1.0 to 5.0 over 80k minibatches gave further small gains, bringing the HM to parity with the LSTM while saving approximately 35% of layer-wise computations.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Interestingly, we found that, over a wide range of training conditions, each layer tended to reduce computa-
tion by roughly 60% relative to the layer below.10
For full-scale experiments, we stacked 5 BiLSTM layers on top of 2 or 3 HM layers, as described in section 3.4.1, using only the top HM layer (rather than the gated output module) as input to the lowest BiLSTM layer.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"To stabilize the 3- HM configuration we used a compression penalty with a weight of 2, and α1 and α2 of 0.1 and 0.9.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Given the tendency of HM layers to reduce computation by a roughly constant proportion, we expect fewer z-gates to be open in the 3-HM configuration, but this is achieved at the cost of one extra layer relative to our standard 12-layer encoder.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"As shown in table 6, the 3-HM configuration achieves much better compression even when this is accounted for, and also gives slightly better performance than 2-HM.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"In general, HM gating results in less compression but better performance than the fixed-stride techniques.
",5.2.3 Hierarchical Multiscale Compression,[0],[0]
"Although these preliminary results are promising, it should be emphasized that the speed gains they demonstrate are conceptual, and that realizing them in practice comes with significant engineering challenges.",5.2.3 Hierarchical Multiscale Compression,[0],[0]
We have demonstrated the translation quality of standard NMT architectures operating at the character-level.,6 Conclusion,[0],[0]
"Our experiments show the surprising result that character NMT can substantially out-perform BPE tokenization for all but the largest training corpora sizes, and the less surprising result that doing so incurs a large computational cost.",6 Conclusion,[0],[0]
"To address this cost, we have explored a number of methods for source-sequence compression, including the first application of the Hierarchical Multiscale LSTM to NMT, which allows us to learn to dynamically compress the source sequence.
",6 Conclusion,[0],[0]
We intend this paper as a call to action.,6 Conclusion,[0],[0]
"Character-level translation is well worth doing, but we do not yet have the necessary techniques to benefit from this quality boost without suffering a disproportionate reduction in speed.",6 Conclusion,[0],[0]
"We hope that these results will spur others to revisit the question of character-level translation as an interesting testbed for methods that can learn to process, summarize or compress long sequences.
",6 Conclusion,[0],[0]
"10For instance, the 2nd and 3rd layer of the best configuration shown had on average 60% and 36% of z gates open, yielding the computation ratio of (1+0.6+0.36)/3 = 0.65.",6 Conclusion,[0],[0]
"Translating characters instead of words or word-fragments has the potential to simplify the processing pipeline for neural machine translation (NMT), and improve results by eliminating hyper-parameters and manual feature engineering.",abstractText,[0],[0]
"However, it results in longer sequences in which each symbol contains less information, creating both modeling and computational challenges.",abstractText,[0],[0]
"In this paper, we show that the modeling problem can be solved by standard sequence-to-sequence architectures of sufficient depth, and that deep models operating at the character level outperform identical models operating over word fragments.",abstractText,[0],[0]
This result implies that alternative architectures for handling character input are better viewed as methods for reducing computation time than as improved ways of modeling longer sequences.,abstractText,[0],[0]
"From this perspective, we evaluate several techniques for characterlevel NMT, verify that they do not match the performance of our deep character baseline model, and evaluate the performance versus computation time tradeoffs they offer.",abstractText,[0],[0]
"Within this framework, we also perform the first evaluation for NMT of conditional computation over time, in which the model learns which timesteps can be skipped, rather than having them be dictated by a fixed schedule specified before training begins.",abstractText,[0],[0]
Revisiting Character-Based Neural Machine Translation with Capacity and Compression,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4743–4751 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4743",text,[0],[0]
"In this paper, we explore the effectiveness of methods designed to improve sentiment classification (positive vs. negative) of sentences that contain complex syntactic structures.",1 Introduction,[0],[0]
"While simple bag-of-words or lexicon-based methods (Pang and Lee, 2005; Wang and Manning, 2012; Iyyer et al., 2015) achieve good performance on this task, they are unequipped to deal with syntactic structures that affect sentiment, such as contrastive conjunctions (i.e., sentences of the form “A-but-B”) or negations.",1 Introduction,[0],[0]
"Neural models that explicitly encode word order (Kim, 2014), syntax (Socher et al., 2013; Tai et al., 2015) and semantic features (Li et al., 2017) have been proposed with the aim of improving performance on these more complicated sentences.",1 Introduction,[0],[0]
"Recently, Hu et al. (2016) incorporate logical rules into a neural model and
show that these rules increase the model’s accuracy on sentences containing contrastive conjunctions, while Peters et al. (2018a) demonstrate increased overall accuracy on sentiment analysis by initializing a model with representations from a language model trained on millions of sentences.
",1 Introduction,[0],[0]
"In this work, we carry out an in-depth study of the effectiveness of the techniques in Hu et al. (2016) and Peters et al. (2018a) for sentiment classification of complex sentences.",1 Introduction,[0],[0]
"Part of our contribution is to identify an important gap in the methodology used in Hu et al. (2016) for performance measurement, which is addressed by averaging the experiments over several executions.",1 Introduction,[0],[0]
"With the averaging in place, we obtain three key findings: (1) the improvements in Hu et al. (2016) can almost entirely be attributed to just one of their two proposed mechanisms and are also less pronounced than previously reported; (2) contextualized word embeddings (Peters et al., 2018a) incorporate the “A-but-B” rules more effectively without explicitly programming for them; and (3) an analysis using crowdsourcing reveals a bigger picture where the errors in the automated systems have a striking correlation with the inherent sentiment-ambiguity in the data.",1 Introduction,[0],[0]
Here we briefly review background from Hu et al. (2016) to provide a foundation for our reanalysis in the next section.,2 Logic Rules in Sentiment Classification,[0],[0]
We focus on a logic rule for sentences containing an “A-but-B” structure (the only rule for which Hu et al. (2016) provide experimental results).,2 Logic Rules in Sentiment Classification,[0],[0]
"Intuitively, the logic rule for such sentences is that the sentiment associated with the whole sentence should be the same as the sentiment associated with phrase “B”.1
1The rule is vacuously true if the sentence does not have this structure.
",2 Logic Rules in Sentiment Classification,[0],[0]
"More formally, let pθ(y|x) denote the probability assigned to the label y ∈ {+,−} for an input x by the baseline model using parameters θ.",2 Logic Rules in Sentiment Classification,[0],[0]
"A logic rule is (softly) encoded as a variable rθ(x, y) ∈",2 Logic Rules in Sentiment Classification,[0],[0]
"[0, 1] indicating how well labeling x with y satisfies the rule.",2 Logic Rules in Sentiment Classification,[0],[0]
"For the case of A-but-B sentences, rθ(x, y) = pθ(y|B) if x has the structure A-but-B (and 1 otherwise).",2 Logic Rules in Sentiment Classification,[0],[0]
"Next, we discuss the two techniques from Hu et al. (2016) for incorporating rules into models: projection, which directly alters a trained model, and distillation, which progressively adjusts the loss function during training.
Projection.",2 Logic Rules in Sentiment Classification,[0],[0]
"The first technique is to project a trained model into a rule-regularized subspace, in a fashion similar to Ganchev et al. (2010).",2 Logic Rules in Sentiment Classification,[0],[0]
"More precisely, a given model pθ is projected to a model qθ defined by the optimum value of q in the following optimization problem:2
min q,ξ≥0 KL(q(X,Y )||pθ(X,Y ))",2 Logic Rules in Sentiment Classification,[0],[0]
+,2 Logic Rules in Sentiment Classification,[0],[0]
C ∑,2 Logic Rules in Sentiment Classification,[0],[0]
"x∈X ξx
s.t.",2 Logic Rules in Sentiment Classification,[0],[0]
"(1− Ey←q(·|x)[rθ(x, y)]) ≤",2 Logic Rules in Sentiment Classification,[0],[0]
"ξx
Here q(X,Y ) denotes the distribution of (x, y) when x is drawn uniformly from the set X and y is drawn according to q(·|x).
",2 Logic Rules in Sentiment Classification,[0],[0]
Iterative Rule Knowledge Distillation.,2 Logic Rules in Sentiment Classification,[0],[0]
The second technique is to transfer the domain knowledge encoded in the logic rules into a neural network’s parameters.,2 Logic Rules in Sentiment Classification,[0],[0]
"Following Hinton et al. (2015), a “student” model pθ can learn from the “teacher” model qθ, by using a loss function πH(pθ, Ptrue)+ (1− π)H(pθ, qθ) during training, where Ptrue denotes the distribution implied by the ground truth, H(·, ·) denotes the cross-entropy function, and π is a hyperparameter.",2 Logic Rules in Sentiment Classification,[0],[0]
"Hu et al. (2016) computes qθ after every gradient update by projecting the current pθ, as described above.",2 Logic Rules in Sentiment Classification,[0],[0]
"Note that both mechanisms can be combined: After fully training pθ using the iterative distillation process above, the projection step can be applied one more time to obtain qθ which is then used as the trained model.
",2 Logic Rules in Sentiment Classification,[0],[0]
Dataset.,2 Logic Rules in Sentiment Classification,[0],[0]
"All of our experiments (as well as those in Hu et al. (2016)) use the SST2 dataset, a
2The formulation in Hu et al. (2016) includes another hyperparameter λ per rule, to control its relative importance; when there is only one rule, as in our case, this parameter can be absorbed into C.
binarized subset of the popular Stanford Sentiment Treebank (SST) (Socher et al., 2013).",2 Logic Rules in Sentiment Classification,[0],[0]
"The dataset includes phrase-level labels in addition to sentence-level labels (see Table 1 for detailed statistics); following Hu et al. (2016), we use both types of labels for the comparisons in Section 3.2.",2 Logic Rules in Sentiment Classification,[0],[0]
"In all other experiments, we use only sentencelevel labels, and our baseline model for all experiments is the CNN architecture from Kim (2014).",2 Logic Rules in Sentiment Classification,[0],[0]
In this section we reanalyze the effectiveness of the techniques of Hu et al. (2016) and find that most of the performance gain is due to projection and not knowledge distillation.,3 A Reanalysis,[0],[0]
The discrepancy with the original analysis can be attributed to the relatively small dataset and the resulting variance across random initializations.,3 A Reanalysis,[0],[0]
We start by analyzing the baseline CNN by Kim (2014) to point out the need for an averaged analysis.,3 A Reanalysis,[0],[0]
"We run the baseline CNN by Kim (2014) across 100 random seeds, training on sentence-level la-
bels.",3.1 Importance of Averaging,[0],[0]
"We observe a large amount of variation from run-to-run, which is unsurprising given the small dataset size.",3.1 Importance of Averaging,[0],[0]
"The inset density plot in Figure 1 shows the range of accuracies (83.47 to 87.20) along with 25, 50 and 75",3.1 Importance of Averaging,[0],[0]
"percentiles.3 The figure also shows how the variance persists even after the average converges: the accuracies of 100 models trained for 20 epochs each are plotted in gray, and their average is shown in red.
",3.1 Importance of Averaging,[0],[0]
"We conclude that, to be reproducible, only averaged accuracies should be reported in this task and dataset.",3.1 Importance of Averaging,[0],[0]
This mirrors the conclusion from a detailed analysis by Reimers and Gurevych (2017) in the context of named entity recognition.,3.1 Importance of Averaging,[0],[0]
We carry out an averaged analysis of the publicly available implementation4 of Hu et al. (2016).,3.2 Performance of Hu et al. (2016),[0],[0]
Our analysis reveals that the reported performance of their two mechanisms (projection and distillation) is in fact affected by the high variability across random seeds.,3.2 Performance of Hu et al. (2016),[0],[0]
"Our more robust averaged analysis yields a somewhat different conclusion of their effectiveness.
",3.2 Performance of Hu et al. (2016),[0],[0]
"In Figure 2, the first two columns show the reported accuracies in Hu et al. (2016) for models trained with and without distillation (corresponding to using values π = 1 and π = 0.95t in the tth epoch, respectively).",3.2 Performance of Hu et al. (2016),[0],[0]
The two rows show the results for models with and without a final projection into the rule-regularized space.,3.2 Performance of Hu et al. (2016),[0],[0]
"We keep our hyper-parameters identical to Hu et al. (2016).5
The baseline system (no-project, no-distill) is identical to the system of Kim (2014).",3.2 Performance of Hu et al. (2016),[0],[0]
"All the systems are trained on the phrase-level SST2 dataset
3We use early stopping based on validation performance for all models in the density plot.
",3.2 Performance of Hu et al. (2016),[0],[0]
"4https://github.com/ZhitingHu/logicnn/ 5In particular, C = 6 for projection.
with early stopping on the development set.",3.2 Performance of Hu et al. (2016),[0],[0]
The number inside each arrow indicates the improvement in accuracy by adding either the projection or the distillation component to the training algorithm.,3.2 Performance of Hu et al. (2016),[0],[0]
"Note that the reported figures suggest that while both components help in improving accuracy, the distillation component is much more helpful than the projection component.
",3.2 Performance of Hu et al. (2016),[0],[0]
"The next two columns, which show the results of repeating the above analysis after averaging over 100 random seeds, contradict this claim.",3.2 Performance of Hu et al. (2016),[0],[0]
"The averaged figures show lower overall accuracy increases, and, more importantly, they attribute these improvements almost entirely to the projection component rather than the distillation component.",3.2 Performance of Hu et al. (2016),[0],[0]
"To confirm this result, we repeat our averaged analysis restricted to only “A-but-B” sentences targeted by the rule (shown in the last two columns).",3.2 Performance of Hu et al. (2016),[0],[0]
"We again observe that the effect of projection is pronounced, while distillation offers little or no advantage in comparison.",3.2 Performance of Hu et al. (2016),[0],[0]
"Traditional context-independent word embeddings like word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014) are fixed vectors for every word in the vocabulary.",4 Contextualized Word Embeddings,[0],[0]
"In contrast, contextualized embeddings are dynamic representations, dependent on the current context of the word.",4 Contextualized Word Embeddings,[0],[0]
We hypothesize that contextualized word embeddings might inherently capture these logic rules due to increasing the effective context size for the CNN layer in Kim (2014).,4 Contextualized Word Embeddings,[0],[0]
"Following the recent success of ELMo (Peters et al., 2018a) in sentiment analysis, we utilize the TensorFlow Hub implementation of ELMo6 and feed these contextualized embeddings into our CNN model.",4 Contextualized Word Embeddings,[0],[0]
"We
6https://tfhub.dev/google/elmo/1
fine-tune the ELMo LSTM weights along with the CNN weights on the downstream CNN task.",4 Contextualized Word Embeddings,[0],[0]
"As in Section 3, we check performance with and without the final projection into the rule-regularized space.",4 Contextualized Word Embeddings,[0],[0]
"We present our results in Table 2.
",4 Contextualized Word Embeddings,[0],[0]
"Switching to ELMo word embeddings improves performance by 2.9 percentage points on an average, corresponding to about 53 test sentences.",4 Contextualized Word Embeddings,[0],[0]
"Of these, about 32 sentences (60% of the improvement) correspond to A-but-B and negation style sentences, which is substantial when considering that only 24.5% of test sentences include these discourse relations (Table 1).",4 Contextualized Word Embeddings,[0],[0]
"As further evidence that ELMo helps on these specific constructions, the non-ELMo baseline model (no-project, no-distill) gets 255 sentences wrong in the test corpus on average, only 89 (34.8%) of which are A-but-B style or negations.
",4 Contextualized Word Embeddings,[0],[0]
"Statistical Significance: Using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001 for the results in Table 2, we find that ELMo and projection each yield statistically significant improvements, but distillation does not.",4 Contextualized Word Embeddings,[0],[0]
"Also, with ELMo, projection is not significant.",4 Contextualized Word Embeddings,[0],[0]
"Specific comparisons have been added in the Appendix, in Table A3.
KL Divergence Analysis: We observe no significant gains by projecting a trained ELMo model into an A-but-B rule-regularized space, unlike the other models.",4 Contextualized Word Embeddings,[0],[0]
"We confirm that ELMo’s predictions are much closer to the A-but-B rule’s manifold than those of the other models by computing KL(qθ||pθ) where pθ and qθ are the original and projected distributions: Averaged across all A-butB sentences and 100 seeds, this gives 0.27, 0.26 and 0.13 for the Kim (2014), Hu et al. (2016) with distillation and ELMo systems respectively.
",4 Contextualized Word Embeddings,[0],[0]
"Intra-sentence Similarity: To understand the information captured by ELMo embeddings for A-but-B sentences, we measure the cosine similarity between the word vectors of every pair of words within the A-but-B sentence (Peters et al., 2018b).",4 Contextualized Word Embeddings,[0],[0]
"We compare the intra-sentence similarity for fine-tuned word2vec embeddings (baseline), ELMo embeddings without fine-tuning and finally fine-tuned ELMo embeddings in Figure 3.",4 Contextualized Word Embeddings,[0],[0]
"In the fine-tuned ELMo embeddings, we notice the words within the A and within the B part of the A-but-B sentence share the same part of the vector space.",4 Contextualized Word Embeddings,[0],[0]
"This pattern is less visible in the
ELMo embeddings without fine-tuning and absent in the word2vec embeddings.",4 Contextualized Word Embeddings,[0],[0]
This observation is indicative of ELMo’s ability to learn specific rules for A-but-B sentences in sentiment classification.,4 Contextualized Word Embeddings,[0],[0]
More intra-sentence similarity heatmaps for A-but-B sentences are in Figure A1.,4 Contextualized Word Embeddings,[0],[0]
We conduct a crowdsourced analysis that reveals that SST2 data has significant levels of ambiguity even for human labelers.,5 Crowdsourced Experiments,[0],[0]
"We discover that ELMo’s performance improvements over the baseline are robust across varying levels of ambiguity, whereas the advantage of Hu et al. (2016) is reversed in sentences of low ambiguity (restricting to A-but-B style sentences).
",5 Crowdsourced Experiments,[0],[0]
"Our crowdsourced experiment was conducted on Figure Eight.8 Nine workers scored the sentiment of each A-but-B and negation sentence in the test SST2 split as 0 (negative), 0.5 (neutral) or 1 (positive).",5 Crowdsourced Experiments,[0],[0]
(SST originally had three crowdworkers choose a sentiment rating from 1 to 25 for every phrase.),5 Crowdsourced Experiments,[0],[0]
More details regarding the crowd experiment’s parameters have been provided in,5 Crowdsourced Experiments,[0],[0]
"Appendix A.
We average the scores across all users for each sentence.",5 Crowdsourced Experiments,[0],[0]
"Sentences with a score in the range (x, 1] are marked as positive (where x ∈",5 Crowdsourced Experiments,[0],[0]
"[0.5, 1)), sentences in [0, 1 − x) marked as negative, and sentences in [1 − x, x] are marked as neutral.",5 Crowdsourced Experiments,[0],[0]
"For instance, “flat , but with a revelatory performance by michelle williams” (score=0.56) is neutral when x",5 Crowdsourced Experiments,[0],[0]
= 0.6.9,5 Crowdsourced Experiments,[0],[0]
We present statistics of our dataset10 in Table 3.,5 Crowdsourced Experiments,[0],[0]
"Inter-annotator agree-
7Trained on sentences and not phrase-level labels for a fair comparison with baseline and ELMo, unlike Section 3.2.
",5 Crowdsourced Experiments,[0],[0]
"8 https://www.figure-eight.com/ 9More examples of neutral sentences have been provided in the Appendix in Table A1, as well as a few “flipped” sentences receiving an average score opposite to their SST2 label (Table A2).
",5 Crowdsourced Experiments,[0],[0]
"10The dataset along with source code can be found in
ment was computed using Fleiss’ Kappa (κ).",5 Crowdsourced Experiments,[0],[0]
"As expected, inter-annotator agreement is higher for higher thresholds (less ambiguous sentences).",5 Crowdsourced Experiments,[0],[0]
"According to Landis and Koch (1977), κ ∈ (0.2, 0.4] corresponds to “fair agreement”, whereas κ ∈ (0.4, 0.6] corresponds to “moderate agreement”.
",5 Crowdsourced Experiments,[0],[0]
We next compute the accuracy of our model for each threshold by removing the corresponding neutral sentences.,5 Crowdsourced Experiments,[0],[0]
Higher thresholds correspond to sets of less ambiguous sentences.,5 Crowdsourced Experiments,[0],[0]
Table 3 shows that ELMo’s performance gains in Table 2 extends across all thresholds.,5 Crowdsourced Experiments,[0],[0]
In Figure 4 we compare all the models on the A-but-B sentences in this set.,5 Crowdsourced Experiments,[0],[0]
"Across all thresholds, we notice trends similar to previous sections: 1) ELMo performs the best among all models on A-but-B style sentences, and projection results in only a slight improvement; 2) models in Hu et al. (2016) (with and without distillation) benefit considerably from projection; but 3) distillation offers little improvement (with or without projection).",5 Crowdsourced Experiments,[0],[0]
"Also, as the ambiguity threshold increases, we see decreasing gains from projection on all models.",5 Crowdsourced Experiments,[0],[0]
"In fact, beyond the 0.85 threshold, projection degrades the average performance, indicating that projection is useful for more ambiguous sentences.",5 Crowdsourced Experiments,[0],[0]
We present an analysis comparing techniques for incorporating logic rules into sentiment classification systems.,6 Conclusion,[0],[0]
"Our analysis included a metastudy highlighting the issue of stochasticity in performance across runs and the inherent ambiguity in the sentiment classification task itself, which was tackled using an averaged analysis and
https://github.com/martiansideofthemoon/ logic-rules-sentiment.
a crowdsourced experiment identifying ambiguous sentences.",6 Conclusion,[0],[0]
"We present evidence that a recently proposed contextualized word embedding model (ELMo) (Peters et al., 2018a) implicitly learns logic rules for sentiment classification of complex sentences like A-but-B sentences.",6 Conclusion,[0],[0]
Future work includes a fine-grained quantitative study of ELMo word vectors for logically complex sentences along the lines of Peters et al. (2018b).,6 Conclusion,[0],[0]
"Crowd workers residing in five English-speaking countries (United States, United Kingdom, New Zealand, Australia and Canada) were hired.",A Crowdsourcing Details,[0],[0]
"Each crowd worker had a Level 2 or higher rating on Figure Eight, which corresponds to a “group of more experienced, higher accuracy contributors”.",A Crowdsourcing Details,[0],[0]
Each contributor had to pass a test questionnaire to be eligible to take part in the experiment.,A Crowdsourcing Details,[0],[0]
Test questions were also hidden throughout the task and untrusted contributions were removed from the final dataset.,A Crowdsourcing Details,[0],[0]
"For greater quality control, an upper limit of 75 judgments per contributor was enforced.",A Crowdsourcing Details,[0],[0]
Crowd workers were paid a total of $1 for 50 judgments.,A Crowdsourcing Details,[0],[0]
"An internal unpaid workforce (including the first and second author of the paper) of 7 contributors was used to speed up data collection.
",A Crowdsourcing Details,[0],[0]
"# Judgments Average Sentence Positive Negative Neutral
1 1 7 0.50 the fight scenes are fun , but it grows tedious
3 2 4 0.56 it ’s not exactly a gourmet meal but the fare is fair , even coming from the drive thru
2 3 4 0.44 propelled not by characters but by caricatures
4 2 3 0.61 not everything works , but the average is higher than in mary and most other recent comedies
Table A1:",A Crowdsourcing Details,[0],[0]
"Examples of neutral sentences for a threshold of 0.66
# Judgments Average Original Sentence Positive Negative Neutral
1 5 3 0.28 Positive de niro and mcdormand give solid performances , but their screen time is sabotaged by the story ’s inability to create interest
6 0 3 0.83 Negative son of the bride may be a good half hour too long but comes replete with a flattering sense of mystery and quietness
0 5 4 0.22 Positive wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of hubert ’s punches ) , but it should go down smoothly enough with popcorn
Table A2: Examples of flipped sentiment sentences, for a threshold of 0.66
Model 1 vs Model 2 Significant
distill no-project distill project",A Crowdsourcing Details,[0],[0]
"Yes no-distill no-project no-distill project Yes
ELMo no-project ELMo project No
no-distill no-project distill no-project No no-distill project distill project",A Crowdsourcing Details,[0],[0]
"No
no-distill no-project ELMo no-project",A Crowdsourcing Details,[0],[0]
Yes distill no-project ELMo no-project,A Crowdsourcing Details,[0],[0]
Yes no-distill project ELMo project,A Crowdsourcing Details,[0],[0]
"Yes distill project ELMo project Yes
Table A3: Statistical significance using a two-sided Kolmogorov-Smirnov statistic (Massey Jr, 1951) with α = 0.001.
",A Crowdsourcing Details,[0],[0]
"al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click 0.1
0.0
0.1
",A Crowdsourcing Details,[0],[0]
"0.2
0.3
0.4
al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click 0.1
0.2
0.3
0.4
0.5
0.6
al l en ds we ll , so rt of , bu t th e fre nz
ie d
co m ic m
om en ts ne ve r cli ck
all ends well
, sort
of ,
but the frenzied comic
moments never click
0.1
0.2
0.3
0.4
0.5
m ar isa to m ei is go od ,",A Crowdsourcing Details,[0],[0]
"bu t ju st a ki ss is ju st a m es s
marisa tomei
is good
, but just
a kiss
is just
a mess 0.1
0.0
0.1
0.2
0.3
0.4
m ar isa to m ei is go od , bu t ju st a ki ss is ju st a m es s marisa tomei
is good
, but just
a kiss
is just
a mess
0.2
0.3
0.4
",A Crowdsourcing Details,[0],[0]
"0.5
0.6
m ar isa to m ei is go",A Crowdsourcing Details,[0],[0]
od,A Crowdsourcing Details,[0],[0]
", bu t ju st a ki ss is ju st a m es s
marisa tomei
is good
, but just
a kiss
is just
a mess 0.0
0.1
0.2
0.3
0.4
0.5
0.6
",A Crowdsourcing Details,[0],[0]
"th e irw in s em
er ge
un sc
at he d ,",A Crowdsourcing Details,[0],[0]
"bu t th e fic tio na l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted
0.1
0.0
0.1
0.2
0.3
th e irw in s em
er ge
un sc
at he d ,",A Crowdsourcing Details,[0],[0]
"bu t th e fic tio na l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted 0.1
0.2
0.3
0.4
0.5
0.6
th e irw in s em
er ge
un sc
at he d , bu t th e fic tio",A Crowdsourcing Details,[0],[0]
na,A Crowdsourcing Details,[0],[0]
"l fo ot ag e is un co nv
in cin g",A Crowdsourcing Details,[0],[0]
an d cr,A Crowdsourcing Details,[0],[0]
"im in al ly ba dl y ac te d
the irwins emerge unscathed
, but the fictional footage
is unconvincing
and criminally
badly acted
0.1
0.2
0.3
0.4
0.5
Figure A1:",A Crowdsourcing Details,[0],[0]
Heat map showing the cosine similarity between pairs of word vectors within a single sentence.,A Crowdsourcing Details,[0],[0]
"The leftmost column has word2vec (Mikolov et al., 2013) embeddings, fine-tuned on the downstream task (SST2).",A Crowdsourcing Details,[0],[0]
"The middle column contains the original ELMo embeddings (Peters et al., 2018a) without any fine-tuning.",A Crowdsourcing Details,[0],[0]
The representations from the three layers (token layer and two LSTM layers) have been averaged.,A Crowdsourcing Details,[0],[0]
The rightmost column contains ELMo embeddings fine-tuned on the downstream task.,A Crowdsourcing Details,[0],[0]
"For better visualization, the cosine similarity between identical words has been set equal to the minimum value in the map.",A Crowdsourcing Details,[0],[0]
We analyze the performance of different sentiment classification models on syntacticallycomplex inputs like A-but-B sentences.,abstractText,[0],[0]
"The first contribution of this analysis addresses reproducible research: to meaningfully compare different models, their accuracies must be averaged over far more random seeds than what has traditionally been reported.",abstractText,[0],[0]
"With proper averaging in place, we notice that the distillation model described in Hu et al. (2016), which incorporates explicit logic rules for sentiment classification, is ineffective.",abstractText,[0],[0]
"In contrast, using contextualized ELMo embeddings (Peters et al., 2018a) instead of logic rules yields significantly better performance.",abstractText,[0],[0]
"Additionally, we provide analysis and visualizations that demonstrate ELMo’s ability to implicitly learn logic rules.",abstractText,[0],[0]
"Finally, a crowdsourced analysis reveals how ELMo outperforms baseline models even on sentences with ambiguous sentiment labels.",abstractText,[0],[0]
Revisiting the Importance of Encoding Logic Rules in Sentiment Classification,title,[0],[0]
"Back-propagation through time (BPTT) (Werbos, 1990) is nowadays the standard approach for training recurrent neural networks (RNNs).",1. Introduction,[0],[0]
"However, the computation and memory cost of BPTT scale linearly with the number of steps which makes BPTT impractical for applications where long sequences are common (Sutskever et al., 2014; Goodfellow
*Equal contribution 1Department of Computer Science, University of Toronto 2Uber ATG Toronto 3Vector Institute 4Department of Electrical and Computer Engineering, Rice University 5Department of Neuroscience, Baylor College of Medicine 6Canadian Institute for Advanced Research.",1. Introduction,[0],[0]
"Correspondence to: Renjie Liao <rjliao@cs.toronto.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"et al., 2016).",1. Introduction,[0],[0]
"Moreover, as the number of unrolling steps increases, the numerical error accumulates which may render the algorithm useless in some applications, e.g., gradientbased hyperparameter optimization (Maclaurin et al., 2015).",1. Introduction,[0],[0]
This issue is often solved in practice by using truncated back-propagation through time (TBPTT),1. Introduction,[0],[0]
"(Williams & Peng, 1990; Sutskever, 2013) which has constant computation and memory cost, is simple to implement, and effective in some applications.",1. Introduction,[0],[0]
"However, the quality of the TBPTT approximate gradient is not well understood.",1. Introduction,[0],[0]
"A natural question to ask is, can we get better gradient approximations while still using the same computational cost as TBPTT?
",1. Introduction,[0],[0]
"Here will show that under certain conditions on the underlying model, the answer is positive.",1. Introduction,[0],[0]
"In particular, we consider a class of RNNs whose hidden state converges to a steady state.",1. Introduction,[0],[0]
"For this class of RNNs, we can bypass BPTT and compute the exact gradient using an algorithm called recurrent back-propagation (RBP) (Almeida, 1987; Pineda, 1987).",1. Introduction,[0],[0]
The key observation exploited by RBP is that the gradient of the steady state w.r.t.,1. Introduction,[1.0],['The key observation exploited by RBP is that the gradient of the steady state w.r.t.']
"the learnable parameters can be directly computed using the implicit function theorem, alleviating the need to unroll the entire forward pass.",1. Introduction,[0],[0]
The main computational cost of RBP is in solving a linear system which has constant memory and computation time w.r.t.,1. Introduction,[0],[0]
the number of unrolling steps.,1. Introduction,[0],[0]
"However, due to the strong assumptions that RBP imposes, TBPTT has become the standard approach used in practice and RBP did not get much attention for many years.
",1. Introduction,[0],[0]
"In this paper, we first revisit RBP in the context of modern deep learning.",1. Introduction,[1.0],"['In this paper, we first revisit RBP in the context of modern deep learning.']"
"We discuss the original algorithm, the assumptions it imposes and how to satisfy them for deep neural networks.",1. Introduction,[0],[0]
"Second, we notice that although the fixed point iteration method used in (Almeida, 1987; Pineda, 1987) is guaranteed to converge if the steady hidden state is achievable, in practice it can fail to do so within a reasonable amount of steps.",1. Introduction,[0],[0]
This may be caused by the fact that there are many fixed points and the algorithm is sensitive to initialization.,1. Introduction,[0],[0]
We try to overcome the instability issue by proposing two variants of RBP based on conjugate gradient on normal equations (CG-RBP) and Neumann series (Neumann-RBP).,1. Introduction,[0],[0]
We show a connection between NeumannRBP and TBPTT which sheds some new light on the approximation quality of TBPTT.,1. Introduction,[0],[0]
"In the experiments, we show
several important applications which are naturally amenable to RBP.",1. Introduction,[0],[0]
"For example, we show how RBP can be used to back propagate thorough the optimization of deep neural networks in order to tune hyperparameters.",1. Introduction,[0],[0]
"Throughout our experiments, we found that Neumann-RBP not only inherits the advantages of original RBP but also remains consistently stable across different applications.",1. Introduction,[0],[0]
"In the context of neural networks, RBP was independently discovered by Almeida (Almeida, 1987) and Pineda (Pineda, 1987) in 1987, which is why this algorithm is sometimes called the Almeida-Pineda algorithm.",2. Related Work,[0],[0]
"Back then, RBP was shown to be useful in learning content-addressable memory (CAM) models (Hopfield, 1982; 1984) and other computational neurodynamic models (Lapedes & Farber, 1986; Haykin, 1993; Chauvin & Rumelhart, 1995).",2. Related Work,[0],[0]
These models are special RNNs in a sense that their inference stage is a convergent dynamic system by design.,2. Related Work,[0],[0]
"For these systems, one can construct a Lyapunov function for the underlying dynamics which further guarantees the asymptotic stability.",2. Related Work,[0],[0]
"We refer readers to chapter 13 of (Haykin, 1993) for more details on neurodynamic models.",2. Related Work,[0],[0]
"The goal of learning in these models is to manipulate the attractors, i.e. steady states, such that they are close to the input data.",2. Related Work,[0],[0]
"Therefore, during inference stage, even if the input data is corrupted, the corresponding correct attractor or “memory“ can still be retrieved.",2. Related Work,[0],[0]
"Instead of computing gradient via BPTT, RBP provides an more efficient alternative for manipulating the attractors.
",2. Related Work,[0],[0]
"RBP was later applied to learning graph neural networks (GNNs) (Scarselli et al., 2009), which are generalizations of RNNs that handle graph-structured input data.",2. Related Work,[0],[0]
"Specifically, the inference of GNNs is essentially a propagation process which spreads information along the graph.",2. Related Work,[0],[0]
"One can force the propagation process to converge by either constructing a contraction map explicitly, or by regularizing the Jacobian of the update function.",2. Related Work,[0],[0]
"Similarly, the goal is to push the converged inference solution close to the target.",2. Related Work,[0],[0]
RBP is naturally applicable here and demonstrated to save both computation time and memory.,2. Related Work,[0],[0]
"A recent investigation (Scellier & Bengio, 2017a) shows that RBP is related to equilibrium propagation (Scellier & Bengio, 2017b) which is motivated from the perspective of biological plausibility.",2. Related Work,[0],[0]
"Another recent related work in deep learning is OptNet (Amos & Kolter, 2017) where the gradient of the optimized solution of a quadratic programming problem w.r.t.",2. Related Work,[0],[0]
"parameters is obtained by analytically differentiating the KKT system.
",2. Related Work,[0],[0]
"In the probabilistic graphical models (PGMs) literature, similar techniques to RBP have been developed as well.",2. Related Work,[0],[0]
"For example, an efficient gradient-based method to learn the hyperparameters of log-linear models is provided in (Foo et al.,
2008) where the core contribution is to use the implicit differentiation trick to compute the gradient of the optimized inference solution w.r.t.",2. Related Work,[0],[0]
the hyperparameters.,2. Related Work,[0],[0]
"A similar implicit differentiation technique is used in (Samuel & Tappen, 2009) to optimize the maximum a posterior (MAP) solution of continuous MRFs, since the MAP solution can be regarded as the steady state of the inference process.",2. Related Work,[0],[0]
"An implicit-differentiation-based optimization method for generic energy models is proposed in (Domke, 2012) where the gradient of the optimal state (steady state) of the energy w.r.t.",2. Related Work,[0],[0]
"the parameters can be efficiently computed given the fast matrix-vector product implementation (Pearlmutter, 1994).",2. Related Work,[0],[0]
"If one regards the inference algorithms from aforementioned applications as unrolled RNNs, the implicit differentiation technique is essentially equivalent to RBP.
",2. Related Work,[0],[0]
Other efforts have been made to develop alternatives to BPTT.,2. Related Work,[0],[0]
"NoBackTrack (Ollivier et al., 2015) maintains an online estimate of the gradient via the random rank-one reduction technique.",2. Related Work,[0],[0]
"ARTBP (Tallec & Ollivier, 2017) introduces a probability distribution over the truncation points in the sequence and compensates the truncated gradient based on the distribution.",2. Related Work,[0],[0]
Both approaches provide an unbiased estimation of the gradient although their variances differ.,2. Related Work,[0],[0]
"In this section, we review the original RBP algorithm and discuss its assumptions.",3. Revisiting Recurrent Back-Propagation,[0],[0]
We denote the input data and initial hidden state as x and h0.,3.1. Recurrent Back-Propagation,[0],[0]
"During inference, the hidden state at time t is computed as follows,
ht+1 = F (x,wF , ht), (1)
where F is the update function parameterized by wF .",3.1. Recurrent Back-Propagation,[0.9999999386814372],"['During inference, the hidden state at time t is computed as follows, ht+1 = F (x,wF , ht), (1) where F is the update function parameterized by wF .']"
"A typical instantiation of F is an LSTM (Hochreiter & Schmidhuber, 1997) cell function.",3.1. Recurrent Back-Propagation,[0],[0]
"This RNN formulation differs from the one commonly used in language modeling, as the input is not time-dependent.",3.1. Recurrent Back-Propagation,[0],[0]
We restrict our attention to RNNs with fixed inputs for now as it requires fewer assumptions.,3.1. Recurrent Back-Propagation,[0],[0]
"Assuming the dynamical system, (i.e., the forward pass of the RNN), reaches steady state before time step T , we have the following equation,
h∗ = F (x,wF , h ∗), (2)
where h∗ is the steady hidden state.",3.1. Recurrent Back-Propagation,[0],[0]
"We compute the predicted output y based on the steady hidden state as follows,
y = G(x,wG, h ∗), (3)
where G is the output function parameterized by wG. Typically, a loss function L = l(ȳ, y) measures the closeness
between ground truth ȳ and predicted output y. Since the input data x is fixed for all time steps, we can construct a function Ψ of wF and h as follows,
Ψ(wF , h) = h− F (x,wF , h).",3.1. Recurrent Back-Propagation,[0.9701857655080134],"['We compute the predicted output y based on the steady hidden state as follows, y = G(x,wG, h ∗), (3) where G is the output function parameterized by wG.']"
"(4)
At the fixed point, we have Ψ(wF , h∗) = 0.",3.1. Recurrent Back-Propagation,[0],[0]
"Assuming some proper conditions on F , e.g., continuous differentiability, we can take the derivative w.r.t.",3.1. Recurrent Back-Propagation,[0],[0]
wF at h∗ on both sides.,3.1. Recurrent Back-Propagation,[0],[0]
"Using the total derivative and the dependence of h∗ on wF we obtain,
∂Ψ(wF , h ∗)
∂wF =
∂h∗
∂wF − dF",3.1. Recurrent Back-Propagation,[0],[0]
"(x,wF , h
∗)
dwF
= (I − JF,h∗) ∂h∗
∂wF − ∂F (x,wF , h
∗)
∂wF = 0, (5)
where JF,h∗ = ∂F (x,wF ,h ∗)",3.1. Recurrent Back-Propagation,[0],[0]
∂h is the Jacobian matrix of F evaluated at h∗ and d is the total derivative operator.,3.1. Recurrent Back-Propagation,[0],[0]
"Assuming that I − JF,h∗ is invertible, we rearrange Eq.",3.1. Recurrent Back-Propagation,[0],[0]
"(5) to get,
∂h∗ ∂wF = (I − JF,h∗)−1 ∂F (x,wF , h ∗) ∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"(6)
In fact, Equations (4- 6) are an application of the Implicit Function Theorem (Rudin, 1964), which guarantees the existence and uniqueness of an implicit function φ such that h∗ = φ(wF ) if two conditions hold: I, Ψ is continuously differentiable and II, I − JF,h∗ is invertible.",3.1. Recurrent Back-Propagation,[0.9999999755189528],"['(6) In fact, Equations (4- 6) are an application of the Implicit Function Theorem (Rudin, 1964), which guarantees the existence and uniqueness of an implicit function φ such that h∗ = φ(wF ) if two conditions hold: I, Ψ is continuously differentiable and II, I − JF,h∗ is invertible.']"
"Although we do not know the analytic expression of the function φ, we can still compute its gradient at the fixed point.
",3.1. Recurrent Back-Propagation,[0],[0]
Based on Eq.,3.1. Recurrent Back-Propagation,[0],[0]
"(6), we now turn our attention towards computing the gradient of the loss w.r.t.",3.1. Recurrent Back-Propagation,[0],[0]
the parameters of the RNN.,3.1. Recurrent Back-Propagation,[0],[0]
"By using the total derivative and the chain rule, we have
∂L ∂wG = ∂L ∂y
∂G(x,wG, h ∗)
",3.1. Recurrent Back-Propagation,[0],[0]
"∂wG (7)
∂L ∂wF = ∂L ∂y ∂y ∂h∗",3.1. Recurrent Back-Propagation,[0],[0]
(,3.1. Recurrent Back-Propagation,[0],[0]
"I − JF,h∗)−1
∂F (x,wF , h ∗)
∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"(8)
Since the gradient of the loss w.r.t. wG can be easily obtained by back-propagation, we focus our exposition on the computation of ∂L∂wF .",3.1. Recurrent Back-Propagation,[0],[0]
"The original RBP algorithm (Pineda, 1987; Almeida, 1987) introduces an auxiliary variable z such that,
z =",3.1. Recurrent Back-Propagation,[0],[0]
"( I − J>F,h∗ )−1(∂L ∂y ∂y ∂h∗ )> , (9)
where z is a column vector.",3.1. Recurrent Back-Propagation,[0],[0]
"If we managed to compute z, then we can substitute it into Eq.",3.1. Recurrent Back-Propagation,[0],[0]
(8) to get the gradient.,3.1. Recurrent Back-Propagation,[0],[0]
"Note that the Jacobian matrix JF,h∗ is nonsymmetric for
Algorithm 1 : Original RBP 1: Initialization: initial guess z0, e.g., draw uniformly
from [0, 1], i = 0, threshold 2: repeat 3: i = i+ 1
4: zi = J>F,h∗zi−1 +",3.1. Recurrent Back-Propagation,[0],[0]
( ∂L ∂y ∂y ∂h∗ )> 5: until ‖zi − zi−1‖,3.1. Recurrent Back-Propagation,[0],[0]
< 6: ∂L∂wF =,3.1. Recurrent Back-Propagation,[0],[0]
z >,3.1. Recurrent Back-Propagation,[0],[0]
"i ∂F (x,wF ,h ∗) ∂wF 7:",3.1. Recurrent Back-Propagation,[0],[0]
"Return ∂L∂wF
general RNNs which renders direct solvers of linear system impractical.",3.1. Recurrent Back-Propagation,[0],[0]
"To compute z, the original RBP algorithm uses fixed point iteration.",3.1. Recurrent Back-Propagation,[0],[0]
"In particular, we multiply ( I − J>F,h∗ ) on the left hand of both sides of Eq.",3.1. Recurrent Back-Propagation,[0],[0]
"(9) and rearrange the terms as follows,
z = J>F,h∗z +
( ∂L
∂y
∂y
∂h∗
)> .",3.1. Recurrent Back-Propagation,[0],[0]
"(10)
If we view the right hand side of the above equation as a function of z, then applying the fixed point iteration results in the Algorithm 1.",3.1. Recurrent Back-Propagation,[0],[0]
"Note that the most expensive operation in this algorithm is the matrix-vector product J>F,h∗z, which is the same operator as back-propagation.",3.1. Recurrent Back-Propagation,[0],[0]
"In this section, we discuss how to satisfy the assumptions of RBP.",3.2. Assumptions of RBP,[0],[0]
"Recall that in order to apply the implicit function theorem, Ψ(wF , h) has to satisfy two assumptions: I, Ψ is continuously differentiable.",3.2. Assumptions of RBP,[1.0],"['Recall that in order to apply the implicit function theorem, Ψ(wF , h) has to satisfy two assumptions: I, Ψ is continuously differentiable.']"
"II, I − JF,h∗ is invertible.",3.2. Assumptions of RBP,[0],[0]
"Condition I requires the derivative of F to be continuous, a condition satisfied by many RNNs, like LSTM and GRU (Cho et al., 2014).",3.2. Assumptions of RBP,[0],[0]
"Condition II is equivalent to requiring the determinant of I − JF,h∗ to be nonzero, i.e., det(I − JF,h∗) 6= 0.",3.2. Assumptions of RBP,[1.0],"['Condition II is equivalent to requiring the determinant of I − JF,h∗ to be nonzero, i.e., det(I − JF,h∗) 6= 0.']"
"One sufficient but not necessary condition to ensure this is to force F to be a contraction map, as in Scarselli et al. (2009).",3.2. Assumptions of RBP,[0],[0]
"Recall that F is a contraction map on Banach space B, i.e., a complete normed vector space, iff, ∀h1, h2 ∈ B, ‖F (h1)− F (h2)‖ ≤ µ‖h1",3.2. Assumptions of RBP,[0.965793175250735],"['Recall that F is a contraction map on Banach space B, i.e., a complete normed vector space, iff, ∀h1, h2 ∈ B, ‖F (h1)− F (h2)‖ ≤ µ‖h1 − h2‖ where 0 ≤ µ < 1.']"
− h2‖ where 0 ≤ µ < 1.,3.2. Assumptions of RBP,[0],[0]
Banach fixed point theorem guarantees the uniqueness of the fix point of the contraction map F in B. Note that here we drop the dependency of F on w for readability.,3.2. Assumptions of RBP,[0.9651555444373611],['Banach fixed point theorem guarantees the uniqueness of the fix point of the contraction map F in B.']
"Based on the first order Taylor approximation, F (h) = F (h∗) + JF,h∗(h− h∗), we have,
‖F (h)− F (h∗)‖ ‖h− h∗‖ = ‖JF,h∗(h− h∗)‖",3.2. Assumptions of RBP,[0],[0]
‖h− h∗‖ .,3.2. Assumptions of RBP,[0],[0]
"(11)
Note that if we use L2 vector norm, then the induced matrix norm, a.k.a., operator norm, is,
‖JF,h∗‖ = sup { ‖JF,h∗h‖ ‖h‖ : ∀h 6= 0",3.2. Assumptions of RBP,[0],[0]
"} = σmax(JF,h∗), (12)
",3.2. Assumptions of RBP,[0],[0]
where σmax is the largest singular value.,3.2. Assumptions of RBP,[0],[0]
"Therefore, relying on the contraction map definition, we have,
‖JF,h∗‖ ≤ µ < 1, (13)
",3.2. Assumptions of RBP,[0],[0]
"Moreover, since the minimum singular value of I − JF,h∗ is 1− σmax(JF,h∗), we have
|det(I − JF,h∗)| = ∏",3.2. Assumptions of RBP,[0],[0]
i |σi(I,3.2. Assumptions of RBP,[0],[0]
"− JF,h∗)|
≥",3.2. Assumptions of RBP,[0],[0]
"[1− σmax(JF,h∗)]d > 0.",3.2. Assumptions of RBP,[0],[0]
"(14)
Thus our second condition holds following Eq.",3.2. Assumptions of RBP,[0],[0]
"(14).
",3.2. Assumptions of RBP,[0],[0]
"Scarselli et al. (2009) use L1 vector norm which results in a looser inequality since ‖JF,h∗‖2 ≤ √ d‖JF,h∗‖1.",3.2. Assumptions of RBP,[0],[0]
"They obtain an easier to compute regularization term maxi(‖JF,h∗(: , i)‖1 − η)2 where (:, i) denotes the i-th column and η ∈ (0, 1) is the desired contraction constant.",3.2. Assumptions of RBP,[0],[0]
"We note, however, that this work makes a claim that the contraction map assumption can be achieved by regularizing the local Jacobian JF,h∗ of a general neural network.",3.2. Assumptions of RBP,[0],[0]
"This is problematic because the contraction map property is a global property of F that requires regularizing every h in the spaceB, not just h∗. Nevertheless, this regularization evaluated at h∗ encourages local contraction at the fixed point h∗, which is sufficient for satisfying condition II.",3.2. Assumptions of RBP,[0],[0]
"Another way to enforce condition II to hold is directly formalizing the Lagrangian of equality constraint Ψ(wF , h∗) = 0.",3.2. Assumptions of RBP,[0],[0]
"Since all applications we considered in this paper have converged dynamic systems in practice, we leave further discussions of condition II to the appendix.",3.2. Assumptions of RBP,[0],[0]
"In this section, we present our newly proposed variants of RBP, CG-RBP and Neumann-RBP, in detail.",4. New Recurrent Back-Propagation Variants,[0],[0]
"Facing the system of linear equations like Eq. (9) in the derivation of original RBP, one would naturally think of the most common iterative solver, i.e., conjugate gradient method (Hestenes & Stiefel, 1952).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"In particular, multiplying I − J>F,h∗ on both sides, we obtain the following equations,
( I − J>F,h∗ ) z",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"=
( ∂L
∂y
∂y
∂h∗
)> .",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(15)
Unfortunately, for general RNNs, the Jacobian matrix JF,h∗ of the update function, e.g., a cell function of LSTM, is non-symmetric in general.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
This increases the difficulty of solving the system.,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"One simple yet sometimes effective way to approach this problem is to exploit the conjugate
gradient method on the normal equations (CGNE) (Golub & Van Loan, 2012).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Specifically, we multiply I − JF,h∗ on both sides of Eq.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(15) which results in,
(I − JF,h∗) ( I − J>F,h∗ ) z =",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"(I − JF,h∗)
( ∂L
∂y
∂y
∂h∗
)> .
",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Having a symmetric matrix multiplying z on the left hand side, we can now use the conjugate gradient method.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[1.0],"['Having a symmetric matrix multiplying z on the left hand side, we can now use the conjugate gradient method.']"
The detailed algorithm is easily obtained by instantiating the standard conjugate gradient (CG) template.,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[1.0],['The detailed algorithm is easily obtained by instantiating the standard conjugate gradient (CG) template.']
"The most expensive operation used in CGNE is JF,h∗J>F,h∗z, which can be implemented by successive matrix-vector products similarly for computing the Fisher information product of the natural gradient method (Schraudolph, 2002).",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Once we solve z via K-step CGNE, we obtain the final gradient by substituting the solution into Eq.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
(8).,4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Since the condition number of the current system is the square of the original one, the system may be slower to converge in practice.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"Exploring more advanced and faster convergent numerical methods under this setting, like LSQR (Paige & Saunders, 1982), is left for future work.",4.1. Recurrent Back-Propagation based on Conjugate Gradient,[0],[0]
"We now develop a new RBP variant called Neumann-RBP, which uses Neumann series from functional analysis and is efficient in terms of computation and memory.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
We then show its connections to BPTT and TBPTT.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"A Neumann series is a mathematical series of the form∑∞ t=0A
t where A is an operator.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In matrix theory, it is also known as the geometric series of a matrix.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"A convergent Neumann series has the following property,
(I −A)−1 = ∞∑ k=0 Ak. (16)
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"One sufficient condition of convergence is that the spectral radius (i.e., the largest absolute eigenvalue value) ofA is less than 1.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"This convergence criterion applied to A = JF,h∗ implies condition II.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
Other cases where the convergence hold is beyond the scope of this paper.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, we can use it to replace the term (I − JF,h∗)−1 in E.q.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
(8).,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Furthermore, the gradient of RBP can be approximated with the K-th order truncation of Neumann series as below,
∂L ∂wF ≈ ∂L ∂y K∑ k=0 ∂y ∂h∗ JkF,h∗ ∂F (x,wF , h ∗) ∂wF .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"(17)
There is a rich body of literature on how to compute Neumann series efficiently using binary or ternary decomposition (Westreich, 1989; Vassil & Diego, 2017).",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"However,
Algorithm 2 : Neumann-RBP 1: Initialization: v0 = g0 = ( ∂L ∂y ∂y ∂h∗ )> 2: for step t = 1, 2, . . .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
",K do 3: vt = J>vt−1",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
4: gt = gt−1 + vt 5: end for 6: ∂L∂wF = (gK) > ∂F,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"(x,wF ,h∗) ∂wF
7: Return ∂L∂wF
these decomposition based approaches are inapplicable in our context since we cannot compute the Jacobian matrix JF,h∗ efficiently for general neural networks.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Fortunately, we can instead efficiently compute the matrix-vector product J>F,h∗u and JF,h∗u (u is a proper sized vector) by using reverse and forward mode auto-differentiation (Pearlmutter, 1994).",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Relying on this technique, we summarize the Neumann series based RBP algorithm in Algorithm 2.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In practice, we can obtain further memory efficiency by performing updates within the for loops in-place (please refer to the example code in appendix), so that memory usage need not scale with the number of truncation steps.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Moreover, since the algorithm does not rely on hidden states except the fixed point h∗, we no longer need to store the hidden states in the forward pass of the RNN.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Besides the computational benefit, we now have the following proposition to connect Neumann-RBP to BPTT and TBPTT.
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
Proposition 1.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Assume that there exists some step K where 0 < K ≤ T such that for the convergent sequence of hidden states h0, h1, . . .",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
", hT of an RNN, we have h∗ = hT = hT−1 = · · · = hT−K where h∗ is the fixed point.",4.2. Recurrent Back-Propagation based on Neumann Series,[1.0],"[', hT of an RNN, we have h∗ = hT = hT−1 = · · · = hT−K where h∗ is the fixed point.']"
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, then the full and K-step Neumann-RBP are equivalent to BPTT and K-step TBPTT respectively.
",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"Moreover, the following proposition bounds the error of K-step Neumann-RBP.",4.2. Recurrent Back-Propagation based on Neumann Series,[1.0],"['Moreover, the following proposition bounds the error of K-step Neumann-RBP.']"
Proposition 2.,4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"If the Neumann series ∑∞ t=0 J t F,h∗ converges, then the error between K-step and full Neumann series is as follows,∥∥∥∥∥ K∑ t=0 JtF,h∗",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"− (I − JF,h∗)−1 ∥∥∥∥∥ ≤ ∥∥(I",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"− JF,h∗)−1∥∥ ‖JF,h∗‖K+1
We leave all proofs in appendix.",4.2. Recurrent Back-Propagation based on Neumann Series,[0],[0]
"In this section, we thoroughly study all RBP variants on diverse applications.",5. Experiments,[0],[0]
Our implementation based on PyTorch is publicly available1.,5. Experiments,[0],[0]
"Note that our Neumann-RBP is very
1https://github.com/lrjconan/RBP
simple to implement using automatic differentiation and we provide a very short example program in the appendix.",5. Experiments,[0],[0]
"The classical testbed for RBP is the associative memory (Hopfield, 1982).",5.1. Associative Memory,[0],[0]
Several images or patterns are presented to the neural network which learns to store or memorize the images.,5.1. Associative Memory,[0],[0]
"After the learning process, the network is subsequently presented with a corrupted or noisy version of the original image.",5.1. Associative Memory,[0],[0]
The task is then to retrieve the corresponding original image.,5.1. Associative Memory,[0],[0]
"We consider a simplified continuous Hopfield network as described in (Haykin, 1993).",5.1. Associative Memory,[1.0],"['We consider a simplified continuous Hopfield network as described in (Haykin, 1993).']"
"Specifically, the system of nonlinear first-order differential equations is,
d dt hi(t) =",5.1. Associative Memory,[0],[0]
− hi(t),5.1. Associative Memory,[0],[0]
a + N∑ j=1 wijφ(b · hj(t)),5.1. Associative Memory,[0],[0]
"+ Ii, (18)
where subscript i denotes the index of the neuron.",5.1. Associative Memory,[0],[0]
wij is the learnable weight between a pair of neurons.,5.1. Associative Memory,[0],[0]
hi is the hidden state of the i-th neuron.,5.1. Associative Memory,[0],[0]
φ is a nonlinear activate function which is a sigmoid function in our experiments.,5.1. Associative Memory,[0],[0]
"a, b are positive constants and are set to 1 and 0.5.",5.1. Associative Memory,[0],[0]
"The set of neurons consists of three parts: observed, hidden and output neurons, of size 784, 1024 and 784 respectively.",5.1. Associative Memory,[1.0],"['The set of neurons consists of three parts: observed, hidden and output neurons, of size 784, 1024 and 784 respectively.']"
"For observed neuron, the state hi is clamped to observed pixel value Ii.",5.1. Associative Memory,[0],[0]
"For hidden and output neurons, the observed pixel value Ii = 0 and their states hi are updated according to Eq.",5.1. Associative Memory,[0],[0]
(18).,5.1. Associative Memory,[0],[0]
"During inference, the output neurons return xi = φ(b · hi) and we further binarize it for visualization.",5.1. Associative Memory,[0],[0]
"An important property of continuous Hopfield networks is
that by updating the states according to Eq.",5.1. Associative Memory,[0],[0]
"(18) until convergence (which corresponds to the forward pass of RNNs), we are guaranteed to minimize the following (Lyapunov) energy function.
",5.1. Associative Memory,[0.9999999254544396],"['(18) until convergence (which corresponds to the forward pass of RNNs), we are guaranteed to minimize the following (Lyapunov) energy function.']"
E = N∑ i=1,5.1. Associative Memory,[0],[0]
( 1 a ∫ xi 0 φ−1(x)dx− Iixi ),5.1. Associative Memory,[0],[0]
− N∑ i=1,5.1. Associative Memory,[0],[0]
"N∑ j=1 wijxixj 2 ,
where we drop the dependency on time t for simplicity.",5.1. Associative Memory,[0],[0]
"Instead of adopting the Hebbian learning rule as in (Hopfield, 1982), we directly formulate the learning objective as minimizing ∑ i∈I ‖xi− Ii‖1 where I is the set of observed neurons.",5.1. Associative Memory,[0],[0]
"In our experiments, we train and test on 10 MNIST images.",5.1. Associative Memory,[0],[0]
"In training we feed clean data, and during testing we randomly corrupt 50% of the non-zero pixel values to zero.",5.1. Associative Memory,[1.0],"['In training we feed clean data, and during testing we randomly corrupt 50% of the non-zero pixel values to zero.']"
"The number of updates for one inference pass is 50.
",5.1. Associative Memory,[0],[0]
Fig. 1 shows the training and validation curves of continuous Hopfield network with different optimization methods.,5.1. Associative Memory,[0],[0]
"Here truncation steps for TBPTT, RBP, CG-RBP and Neumann-RBP are all set to 20.",5.1. Associative Memory,[0],[0]
"From the figure, we can see that CG-RBP and Neumann-RBP match BPTT under this setting which verifies that their gradients are accurate.",5.1. Associative Memory,[0],[0]
"Nevertheless, we can see that training curve of the original RBP blows up which validates its instability issue.",5.1. Associative Memory,[1.0],"['Nevertheless, we can see that training curve of the original RBP blows up which validates its instability issue.']"
The hidden state of Hopfield network becomes steady within 10 steps.,5.1. Associative Memory,[0],[0]
"However, we notice that if we set the truncation step to 10, original RBP exhibits behaviors which fails to converge.",5.1. Associative Memory,[1.0],"['However, we notice that if we set the truncation step to 10, original RBP exhibits behaviors which fails to converge.']"
We also show some visualizations of retrieved images of the Hopfield network under different optimization methods in Fig. 2.,5.1. Associative Memory,[0],[0]
More visual results are provided in the appendix.,5.1. Associative Memory,[0],[0]
We investigate RBPs on semi-supervised document classification with citation networks.,5.2. Semi-supervised Document Classification,[0],[0]
A node of a network represents a document associated with a bag-of-words feature.,5.2. Semi-supervised Document Classification,[0],[0]
Nodes are connected based on the citation links.,5.2. Semi-supervised Document Classification,[0],[0]
"Given a portion of nodes labeled with subject categories, e.g., science, history, the task is to predict the categories for unlabeled nodes within the same network.",5.2. Semi-supervised Document Classification,[0],[0]
"We use two citation networks from (Yang et al., 2016), i.e., Cora, Pubmed, of which the statistics are summarized in the appendix.",5.2. Semi-supervised Document Classification,[0],[0]
"We adopt graph neural networks (GNNs) (Scarselli et al., 2009) model and employ the GRU as the update function similarly as (Li et al., 2016).",5.2. Semi-supervised Document Classification,[0],[0]
"We refer to (Li et al., 2016; Liao et al., 2018) for more details.",5.2. Semi-supervised Document Classification,[1.0],"['We refer to (Li et al., 2016; Liao et al., 2018) for more details.']"
We compare different optimization methods with the same GNN.,5.2. Semi-supervised Document Classification,[0],[0]
We also add a logistic regression model as a baseline which is applied to every node independently.,5.2. Semi-supervised Document Classification,[0],[0]
"The labeled documents are randomly split into 1%, 49% and 50% for training, validation and testing.",5.2. Semi-supervised Document Classification,[0],[0]
We run all experiments with 10 different random seeds and report the average results.,5.2. Semi-supervised Document Classification,[0],[0]
"The training, validation and difference norm curves of BPTT, TBPTT and all RBPs are shown in Fig. 3.",5.2. Semi-supervised Document Classification,[0],[0]
We can see that the hidden states of GNNs with different optimization methods become steady during inference from Fig. 3 (c).,5.2. Semi-supervised Document Classification,[0],[0]
"As shown in Fig. 3 (a) and (b), Neumann-RBP is on par with TBPTT on both datasets.",5.2. Semi-supervised Document Classification,[0],[0]
This matches our analysis in proposition 1 since the changes of successive hidden states of TBPTT and Neumann-RBP are almost zero as shown in Fig. 3 (c).,5.2. Semi-supervised Document Classification,[0],[0]
"Moreover, they outperform other variants and the baseline model.",5.2. Semi-supervised Document Classification,[0],[0]
"On the other hand, BPTT on both datasets encounter issues in learning which may be attributable to the accumulation of errors in
the many steps of unrolling.",5.2. Semi-supervised Document Classification,[0],[0]
"Note that CG-RBP sometimes performs significantly worse than Neumann-RBP, e.g., on Cora.",5.2. Semi-supervised Document Classification,[0],[0]
This may be caused by the fact that the underlying linear system of CG-RBP is ill-conditioned in some applications as the condition number is squared in CGNE.,5.2. Semi-supervised Document Classification,[0],[0]
The test accuracy of different methods are summarized in Table 1.,5.2. Semi-supervised Document Classification,[0],[0]
It generally matches the behavior in the validation curves.,5.2. Semi-supervised Document Classification,[0],[0]
"In our next experiment, we test the abilities of RBP to perform hyperparameter optimization.",5.3. Hyperparameter Optimization,[0],[0]
"In this experiment, we view the optimization process as a RNN.",5.3. Hyperparameter Optimization,[0],[0]
"When training a neural network, the model parameters, e.g., weights and bias, are regarded as the hidden states of the RNN.",5.3. Hyperparameter Optimization,[0],[0]
Hyperparameters such as learning rate and momentum are learnable parameters of this ‘meta-learning’ RNN.,5.3. Hyperparameter Optimization,[0],[0]
"Here we focus on the gradient based hyperparameter optimization rather than the gradient-free one (Snoek et al., 2012).",5.3. Hyperparameter Optimization,[0],[0]
"We adopt the same experiment setting as in (Maclaurin et al., 2015), using an initial learning rate of exp(−1) and momentum 0.5.",5.3. Hyperparameter Optimization,[0],[0]
"The optimization is on a fully connected network with 4 layers, of sizes 784, 50, 50, and 50.",5.3. Hyperparameter Optimization,[0],[0]
"For each layer, we associate one learning rate and one momentum with weight and bias respectively which results in 16 hyperparameters in total.",5.3. Hyperparameter Optimization,[0],[0]
"We use tanh non-linearities and train on 10, 000 examples on MNIST.",5.3. Hyperparameter Optimization,[0],[0]
"At each forward step of the RNN, i.e., at each optimization step, a different mini-batch of images is fed to the model.",5.3. Hyperparameter Optimization,[0],[0]
This is different from the previous setting where input data is fixed.,5.3. Hyperparameter Optimization,[0],[0]
"However, since the minibatches are assumed to be i.i.d., the sequential input data can be viewed as sampled from a stationary distribution.",5.3. Hyperparameter Optimization,[0],[0]
We can thus safely apply RBP as the steady state holds in expectation.,5.3. Hyperparameter Optimization,[0],[0]
"In terms of implementation, we just need to average the meta gradient returned by RBPs or TBPTT across multiple mini-batches at the end of one meta step.",5.3. Hyperparameter Optimization,[0],[0]
"We use Adam (Kingma & Ba, 2014) as the meta optimizer and set the learning rate to 0.05.",5.3. Hyperparameter Optimization,[0],[0]
"The initialization of the
fully connected network at each meta step is controlled to be the same.
",5.3. Hyperparameter Optimization,[0],[0]
Fig. 5 shows the meta training losses under different training and truncation steps.,5.3. Hyperparameter Optimization,[0],[0]
"For better understanding, one can consider the training step as the unrolling step of the RNN.",5.3. Hyperparameter Optimization,[0],[0]
Truncation step is the the number of steps that TBPTT and RBPs execute.,5.3. Hyperparameter Optimization,[0],[0]
"From the figure, we can see that as the number of training steps increases (e.g., from (a) to (d)), the meta loss becomes smoother.",5.3. Hyperparameter Optimization,[0],[0]
This makes sense since more steps make the training per meta step closer to convergence.,5.3. Hyperparameter Optimization,[0],[0]
Another surprising phenomenon we found is the meta loss of TBPTT becomes worse when the training step increases.,5.3. Hyperparameter Optimization,[0],[0]
"One possible explanation is that the initial meta training loss of small training steps (e.g., (a)) is still very high as you can see from the log y-axis whereas the one with large training step, e.g., (d) is much lower.",5.3. Hyperparameter Optimization,[0],[0]
The probability of using incorrect gradients to decrease the meta loss in case (a) is most likely higher than that of (d) since it is farther from convergence.,5.3. Hyperparameter Optimization,[0],[0]
"On the other hand, our Neumann-RBP performs consistently better than the original RBP and TBPTT which empirically validates that Neumann-RBP provides better estimation of the gradient in this case.",5.3. Hyperparameter Optimization,[0],[0]
The potential reason why RBP performs poorly is that the stochasticity of mini-batches worsen the instability issue.,5.3. Hyperparameter Optimization,[0],[0]
Training losses under similar settings at the last meta step are also provided in Fig. 6.,5.3. Hyperparameter Optimization,[0],[0]
"We can see that at the end of hyperparameter optimization, our Neumann-RBP generally matches the performance of BPTT and outperforms the other methods.",5.3. Hyperparameter Optimization,[0],[0]
"Fig. 4 depicts the trajectories of hidden states in 2D space via t-SNE (Maaten & Hinton, 2008).",5.3. Hyperparameter Optimization,[0],[0]
"From the figure, we can see that as the meta training goes on, TBPTT tends to oscillate whereas Neumann-RBP converges, which matches the finding in the train loss curves in Fig. 6.
",5.3. Hyperparameter Optimization,[0],[0]
"We also compare the running time and memory cost of our unoptimized Neumann-RBP implementation with the standard BPTT, i.e., using autograd of PyTorch.",5.3. Hyperparameter Optimization,[0],[0]
"With 1000 training steps, one meta step of BPTT cost 310.4s and 4061MB GPU memory in average.",5.3. Hyperparameter Optimization,[0],[0]
"We take BPTT as the reference cost and report the ratio BPTT’s cost divided by Neumann-
RBP’s in Table 2.",5.3. Hyperparameter Optimization,[0],[0]
All results are reported as the average of 10 runs.,5.3. Hyperparameter Optimization,[0],[0]
"Even without optimizing the code, the practical runtime and memory footprint advantages of Neumann-RBP over BPTT is still significant.",5.3. Hyperparameter Optimization,[0],[0]
"In this paper, we revisit the RBP algorithm and discuss its assumptions and how to satisfy them for deep learning.",6. Conclusion,[0],[0]
"Moreover, we propose two variants of RBP based on conjugate gradient on normal equations and Neumann series.",6. Conclusion,[0],[0]
Connections between Neumann-RBP and TBPTT are established which sheds some light on analyzing the approximation quality of the gradient of TBPTT.,6. Conclusion,[0],[0]
Experimental results on diverse tasks demonstrate that Neumann-RBP is a stable and efficient alternative to original RBP and is promising for several practical problems.,6. Conclusion,[0],[0]
"In the future, we would like to explore RBP on hyperparameter optimization with large scale deep neural networks.",6. Conclusion,[0],[0]
We thank Barak Pearlmutter for the enlightening discussion and anonymous ICML reviewers for valuable comments.,Acknowledgements,[0],[0]
R.L. was supported by Connaught International Scholarships.,Acknowledgements,[0],[0]
"R.L., E.F., L.Z., K.Y., X.P., R.U. and R.Z. were supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DoI/IBC) contract number D16PC00003.",Acknowledgements,[0],[0]
K.Y. and X.P. were supported in part by BRAIN Initiative grant NIH 5U01NS094368.,Acknowledgements,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.,Acknowledgements,[0],[0]
"Disclaimer: the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the U.S. Government.",Acknowledgements,[0],[0]
"In this paper, we revisit the recurrent backpropagation (RBP) algorithm (Almeida, 1987; Pineda, 1987), discuss the conditions under which it applies as well as how to satisfy them in deep neural networks.",abstractText,[0],[0]
We show that RBP can be unstable and propose two variants based on conjugate gradient on the normal equations (CG-RBP) and Neumann series (Neumann-RBP).,abstractText,[0],[0]
We further investigate the relationship between Neumann-RBP and back propagation through time (BPTT) and its truncated version (TBPTT).,abstractText,[0],[0]
"Our NeumannRBP has the same time complexity as TBPTT but only requires constant memory, whereas TBPTT’s memory cost scales linearly with the number of truncation steps.",abstractText,[0],[0]
"We examine all RBP variants, along with BPTT and TBPTT, in three different application domains: associative memory with continuous Hopfield networks, document classification in citation networks using graph neural networks, and hyperparameter optimization for fully connected networks.",abstractText,[0],[0]
"All experiments demonstrate that RBPs, especially the Neumann-RBP variant, are efficient and effective for optimizing convergent recurrent neural networks.",abstractText,[0],[0]
Reviving and Improving Recurrent Back-Propagation,title,[0],[0]

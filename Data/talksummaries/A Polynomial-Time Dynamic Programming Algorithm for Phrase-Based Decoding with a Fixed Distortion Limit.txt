7	35	This paper describes an algorithm for phrasebased decoding with a fixed distortion limit whose runtime is linear in the length of the sentence, and for a fixed distortion limit is polynomial in other factors.
71	13	For any vertex v ∈ Bj , the degree of v in Hj and H ′j is the same.
90	32	We now describe the dynamic programming algorithm for phrase-based decoding with a fixed distortion limit.
93	17	xn for some integer n. We assume that x1 = <s> and xn = </s> where <s> and </s> are the sentence start and end symbols respectively.
96	47	xt in the source language have a translation as e1 .
97	22	We use s(p), t(p) and e(p) to refer to the three components of a phrase p = (s, t, e), and e1(p) .
103	61	• Each source word is translated exactly once.
104	14	• The distortion limit is satisfied for each pair of phrases pi−1, pi, that is: |t(pi−1) + 1− s(pi)| ≤ d ∀ i = 2 .
106	40	pL, a target-language translation can be obtained by concatenating the target-language strings e(p1) .
107	15	The scoring function is defined as follows: f(p1 .
108	13	e(pL)) + L∑ i=1 κ(pi) + L∑ i=2 η × |t(pi−1) + 1− s(pi)| (1) For each phrase p, κ(p) is the translation score for the phrase.
118	15	Intuitively the algorithm builds a derivation by processing the source-language sentence in strictly left-to-right order.
119	22	This is in contrast with the algorithm of Koehn et al. (2007b), where the targetlanguage sentence is constructed from left to right.
137	25	Thus for each integer j such that there is a phrase in H ending at point j, we can divide the phrases in H into two sets: phrases p with t(p) ≤ j, and phrases pwith s(p) > j.
146	16	πr〉 satisfies the following properties: 1. s(π1) = 1 and e1(π1) = <s>.
147	43	j}, there exists a phrase p ∈ π, for some phrase sequence π ∈ Hj , such that s(p) ≤ i ≤ t(p).
171	14	We can now state the following Lemma: Lemma 3.
201	38	In this case phrase p is appended to signature σi, and prepended to signature σi′ , effectively joining the two signatures together.
210	29	This will be the product of terms N and M , where N is an upper bound on the number of states in the dynamic program, and M is an upper bound on the number of outgoing transitions from any state.
211	17	n}, define first(j) to be the set of target-language words that can begin at position j and last(j) to be the set of target-language words that can end at position j. first(j) = {w : ∃ p = (s, t, e) s.t.
224	13	For a fixed choice of {(s(σi), t(σi))}ri=1 we will argue that there are at most hd+1 possible values for {(ws(σi), wt(σi))}ri=1.
237	15	We conclude the paper with discussion of some issues.
239	22	Second, we give more analysis of the complexity of the widely-used decoding algorithm of Koehn et al. (2003).
240	15	Beam search is widely used in phrase-based decoding; it can also be applied to our dynamic programming construction.
241	29	We can replace the line for each state T ∈ Tj in the algorithm in Figure 2 with for each state T ∈ beam(Tj) where beam is a function that returns a subset of Tj , most often the highest scoring elements of Tj under some scoring criterion.
243	58	One proposal is to define γ(T ) = α(T ) + β(T ) where α(T ) is the score used in the dynamic program, and β(T ) = ∑ i:ws(σi)6=<s> λu(ws(σi)).
244	82	Here λu(w) is the score of word w under a unigram language model.
245	32	The β(T ) scores allow different states in Tj , which have different words ws(σi) at the start of signatures, to be comparable: for example it compensates for the case wherews(σi) is a rare word, which will incur a low probability when the bigram 〈w ws(σi)〉 for some word w is constructed during search.
252	14	A natural question is whether the number of possible bit strings for a model with a fixed distortion limit d can grow exponentially quickly with respect to the length of the input sentence.
257	28	With a distortion limit d ≥ 5, the number of possible bit strings in this example is at least 2(n−2)/4.

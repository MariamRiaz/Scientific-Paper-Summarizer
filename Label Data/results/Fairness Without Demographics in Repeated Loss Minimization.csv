0,1,label2,summary_sentences
A key to the success of probabilistic modeling is the pairing of rich probability models with fast and accurate inference algorithms.,1. Introduction,[0],[0]
Probabilistic graphical models enable this by providing a flexible class of probability distributions together with algorithms that exploit the graph structure for efficient inference.,1. Introduction,[0],[0]
"However, exact inference algorithms are only available when both the distributions involved and the graph structure are simple enough.",1. Introduction,[0],[0]
"How-
",1. Introduction,[0],[0]
"1College of Information and Computer Sciences, University of Massachusetts Amherst 2Department of Computer Science, Mount Holyoke College.",1. Introduction,[0],[0]
"Correspondence to: Kevin Winner <kwinner@cs.umass.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
ever, this situation is rare and consequently, much research today is devoted to general-purpose approximate inference techniques (e.g. Ranganath et al., 2014; Kingma & Welling, 2014; Carpenter et al., 2016).
",1. Introduction,[0],[0]
"Despite many advances in probabilistic inference, there remain relatively simple (and useful) models for which exact inference algorithms are not available.",1. Introduction,[0],[0]
This paper considers the case of graphical models with a simple structure but with (unbounded) latent count random variables.,1. Introduction,[0],[0]
"These are a natural modeling choice for many real world problems in ecology (Zonneveld, 1991; Royle, 2004; Dail & Madsen, 2011) and epidemiology (Farrington et al., 2003; Panaretos, 2007; Kvitkovicova & Panaretos, 2011).",1. Introduction,[0],[0]
"However, they pose a unique challenge for inference: even though algorithms like belief propagation (Pearl, 1986) or variable elimination (Zhang & Poole, 1994) are well defined mathematically, they cannot be implemented in an obvious way because factors have a countably infinite number of entries.",1. Introduction,[0],[0]
"As a result, approximations like truncating the support of the random variables or MCMC are applied (Royle, 2004; Gross et al., 2007; Chandler et al., 2011; Dail & Madsen, 2011; Zipkin et al., 2014; Winner et al., 2015).
",1. Introduction,[0],[0]
"Recently, Winner & Sheldon (2016) introduced a new technique for exact inference in models with latent count variables.",1. Introduction,[0],[0]
"Their approach executes the same operations as variable elimination, but with factors, which are infinite sequences of values, represented in a compact way using probability generating functions (PGFs).",1. Introduction,[0],[0]
"They developed an efficient exact inference algorithm for a specific class of Poisson hidden Markov models (HMMs) that represent a population undergoing mortality and immigration, and noisy observations of the population over time.
",1. Introduction,[0],[0]
A key open question is the extent to which PGF-based inference generalizes to a broader class of models.,1. Introduction,[0],[0]
There are two primary considerations.,1. Introduction,[0],[0]
"First, for what types of factors can the required operations (multiplication, marginalization, and conditioning) be “lifted” to PGF-based representations?",1. Introduction,[0],[0]
"Here, there is significant room for generalization: the mathematical PGF operations developed in (Winner & Sheldon, 2016) already apply to a broad class of nonPoisson immigration models, and we will generalize the models further to allow richer models of population survival and growth.",1. Introduction,[0],[0]
"Second, and more significantly, for what
types of PGFs can the requisite mathematical operations be implemented efficiently?",1. Introduction,[0],[0]
Winner & Sheldon (2016) manipulated PGFs symbolically.,1. Introduction,[0],[0]
"Their compact symbolic representation seems to rely crucially on properties of the Poisson distribution; it remains unclear whether symbolic PGF inference can be generalized beyond Poisson models.
",1. Introduction,[0],[0]
"This paper introduces a new algorithmic technique based on higher-order automatic differentiation (Griewank & Walther, 2008) for inference with PGFs.",1. Introduction,[0],[0]
A key insight is that most inference tasks do not require a full symbolic representation of the PGF.,1. Introduction,[0],[0]
"For example, the likelihood is computed by evaluating a PGF F (s) at s = 1.",1. Introduction,[0],[0]
Other probability queries can be posed in terms of derivatives F (k)(s) evaluated at either s = 0 or s = 1.,1. Introduction,[0],[0]
"In all cases, it suffices to evaluate F and its higher-order derivatives at particular values of s, as opposed to computing a compact symbolic representation of F .",1. Introduction,[0],[0]
"It may seem that this problem is then solved by standard techniques, such as higher-order forward-mode automatic differentiation (Griewank & Walther, 2008).",1. Introduction,[0],[0]
"However, the requisite PGF F is complex—it is defined recursively in terms of higher-order derivatives of other PGFs—and offthe-shelf automatic differentiation methods do not apply.",1. Introduction,[0],[0]
"We therefore develop a novel recursive procedure using building blocks of forward-mode automatic differentiation (generalized dual numbers and univariate Taylor polynomials; Griewank & Walther, 2008) to evaluate F and its derivatives.
",1. Introduction,[0],[0]
"Our algorithmic contribution leads to the first efficient exact algorithms for a class of HMMs that includes many well-known models as special cases, and has many applications.",1. Introduction,[0],[0]
"The hidden variables represent a population that undergoes three different processes: mortality (or emigration), immigration, and growth.",1. Introduction,[0],[0]
A variety of different distributional assumptions may be made about each process.,1. Introduction,[0],[0]
The models may also be viewed without this interpretation as a flexible class of models for integer-valued time series.,1. Introduction,[0],[0]
"Special cases include models from population ecology (Royle, 2004; Gross et al., 2007; Dail & Madsen, 2011), branching processes (Watson & Galton, 1875; Heathcote, 1965), queueing theory (Eick et al., 1993), and integer-valued autoregressive models (McKenzie, 2003).",1. Introduction,[0],[0]
Additional details about the relation to these models are given in Section 2.,1. Introduction,[0],[0]
"Our algorithms permit exact calculation of the likelihood for all of these models even when they are partially observed.
",1. Introduction,[0],[0]
"We demonstrate experimentally that our new exact inference algorithms are more scalable than competing approximate approaches, and support learning via exact likelihood calculations in a broad class of models for which this was not previously possible.",1. Introduction,[0],[0]
"We consider a hidden Markov model with integer latent variables N
1 , . . .",2. Model and Problem Statement,[0],[0]
", NK and integer observed variables Y 1
, . . .",2. Model and Problem Statement,[0],[0]
", YK .",2. Model and Problem Statement,[0],[0]
All variables are assumed to be non-negative.,2. Model and Problem Statement,[0],[0]
"The model is most easily understood in the context of its application to population ecology or branching processes (which are similar): in these cases, the variable Nk represents the size of a hidden population at time tk, and Yk represents the number of individuals that are observed at time tk.",2. Model and Problem Statement,[0],[0]
"However, the model is equally valid without this interpretation as a flexible class of autoregressive processes (McKenzie, 2003).
",2. Model and Problem Statement,[0],[0]
We introduce some notation to describe the model.,2. Model and Problem Statement,[0],[0]
"For an integer random variable N , write Y = ⇢ N to mean that Y ⇠ Binomial(N, ⇢).",2. Model and Problem Statement,[0],[0]
This operation is known as “binomial thinning”: the count Y is the number of “survivors” from the original count N .,2. Model and Problem Statement,[0],[0]
We can equivalently write Y = PN i=1,2. Model and Problem Statement,[0],[0]
Xi for iid Xi ⇠ Bernoulli(⇢) to highlight the fact that this is a compound distribution.,2. Model and Problem Statement,[0],[0]
"Indeed, compound distributions will play a key role: for independent integer random variables N and X , let Z = N X denote the compound random variable Z = PN i=1",2. Model and Problem Statement,[0],[0]
"Xi, where {Xi} are independent copies of X .",2. Model and Problem Statement,[0],[0]
"Now, we can describe our model as:
Nk = (Nk 1 Xk) +Mk, (1) Yk = ⇢k Nk. (2)
",2. Model and Problem Statement,[0],[0]
The variable Nk represents the population size at time tk.,2. Model and Problem Statement,[0],[0]
The random variable Nk 1 Xk 1 = PNk 1 i=1,2. Model and Problem Statement,[0],[0]
"Xk 1,i is the number of offspring of individuals from the previous time step, where Xk 1,i is the total number of individuals “caused by” the ith individual alive at time tk 1.",2. Model and Problem Statement,[0],[0]
"This definition of offspring is flexible enough to model immediate offspring, surviving individuals, and descendants of more than one generation.",2. Model and Problem Statement,[0],[0]
"The random variable Mk is the number of immigrants at time tk, and Yk is the number of individuals observed at time tk, with the assumption that each individual is observed independently with probability ⇢",2. Model and Problem Statement,[0],[0]
"k. We have left unspecified the distributions of Mk and Xk, which we term the immigration and offspring distributions, respectively.",2. Model and Problem Statement,[0],[0]
These may be arbitrary distributions over non-negative integers.,2. Model and Problem Statement,[0],[0]
"We will assume the initial condition N
0 = 0, though the model can easily be extended to accommodate arbitrary initial distributions.
",2. Model and Problem Statement,[0],[0]
Problem Statement We use lower case variables to denote specific settings of random variables.,2. Model and Problem Statement,[0],[0]
"Let yi:j = (yi, . . .",2. Model and Problem Statement,[0],[0]
", yj) and ni:j = (ni, . . .",2. Model and Problem Statement,[0],[0]
", nj).",2. Model and Problem Statement,[0],[0]
"The model above defines a joint probability mass function (pmf) p(n
1:K , y1:K ; ✓) where we introduce the vector ✓ containing parameters of all component distributions when necessary.",2. Model and Problem Statement,[0],[0]
"It is clear that the density factors according to a hidden Markov model: p(n
1:K , y1:K) =
QK k=1 p(nk |nk 1)p(yk |nk).",2. Model and Problem Statement,[0],[0]
"We will consider several inference problems that are standard for HMMs, but pose unique challenges when the hidden variables have countably infinite support.",2. Model and Problem Statement,[0],[0]
"Specifically, suppose y
1:K are observed, then we seek to:
• Compute the likelihood L(✓) = p(y 1:K ; ✓) for any ✓,
• Compute moments and values of the pmf of the filtered marginals p(nk | y1:k; ✓), for any k, ✓,
• Estimate parameters ✓ by maximizing the likelihood.
",2. Model and Problem Statement,[0],[0]
"We focus technically on the first two problems, which will enable numerical optimization to maximize the likelihood.",2. Model and Problem Statement,[0],[0]
Another standard problem is to compute smoothed marginals p(nk | y1:K ; ✓) given both past and future observations relative to time step k.,2. Model and Problem Statement,[0],[0]
"Although this is interesting, it is technically more difficult, and we defer it for future work.
",2. Model and Problem Statement,[0],[0]
Connections to Other Models This model specializes to capture many different models in the literature.,2. Model and Problem Statement,[0],[0]
The latent process of Eq.,2. Model and Problem Statement,[0],[0]
"(1) is a Galton-Watson branching process with immigration (Watson & Galton, 1875; Heathcote, 1965).",2. Model and Problem Statement,[0],[0]
"It also captures a number of different AR(1) (first-order autoregressive) processes for integer variables (McKenzie, 2003); these typically assume Xk ⇠ Bernoulli( k), i.e., that the offspring process is binomial thinning of the current individuals.",2. Model and Problem Statement,[0],[0]
"For clarity when describing this as an offspring distribution, we will refer to it as Bernoulli offspring.",2. Model and Problem Statement,[0],[0]
"With Bernoulli offspring and time-homogenous Poisson immigration, the model is an M/M/1 queue (McKenzie, 2003); with time-varying Poisson immigration it is an Mt/M/1 queue (Eick et al., 1993).",2. Model and Problem Statement,[0],[0]
"For each of these models, we contribute the first known algorithms for exact inference and likelihood calculations when the process is partially observed.",2. Model and Problem Statement,[0],[0]
"This allows estimation from data that is noisy and has variability that should not be modeled by the latent process.
",2. Model and Problem Statement,[0],[0]
Special cases of our model with noisy observations occur in statistical estimation problems in population ecology.,2. Model and Problem Statement,[0],[0]
"When immigration is zero after the first time step and Xk = 1, the population size is a fixed random variable, and we recover the N -mixture model of Royle (2004) for estimating the size of an animal population from repeated counts.",2. Model and Problem Statement,[0],[0]
"With Poisson immigration and Bernoulli offspring, we recover the basic model of Dail & Madsen (2011) for open metapopulations; extended versions with overdispersion and population growth also fall within our framework by using negative-binomial immigration and Poisson offspring.",2. Model and Problem Statement,[0],[0]
"Related models for insect populations also fall within our framework (Zonneveld, 1991; Gross et al., 2007; Winner et al., 2015).",2. Model and Problem Statement,[0],[0]
The main goal in most of this literature is parameter estimation.,2. Model and Problem Statement,[0],[0]
"Until very recently, no exact algorithms were known to compute the likelihood, so ap-
proximations such as truncating the support of the latent variables (Royle, 2004; Fiske & Chandler, 2011; Chandler et al., 2011; Dail & Madsen, 2011) or MCMC (Gross et al., 2007; Winner et al., 2015) were used.",2. Model and Problem Statement,[0],[0]
Winner & Sheldon (2016) introduced PGF-based exact algorithms for the restricted version of the model with Bernoulli offspring and Poisson immigration.,2. Model and Problem Statement,[0],[0]
We will build on that work to provide exact inference and likelihood algorithms for all of the aforementioned models.,2. Model and Problem Statement,[0],[0]
"The standard approach for inference in HMMs is the forward-backward algorithm (Rabiner, 1989), which is a special case of more general propagation or messagepassing algorithms (Pearl, 1986; Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990; Shenoy & Shafer, 1990).",3. Methods,[0],[0]
"Winner & Sheldon (2016) showed how to implement the forward algorithm using PGFs for models with Bernoulli offspring and Poisson immigration.
",3. Methods,[0],[0]
Forward Algorithm,3. Methods,[0],[0]
"The forward algorithm recursively computes “messages”, which are unnormalized distributions of subsets of the variables.",3. Methods,[0],[0]
"Specifically, define ↵k(nk) :",3. Methods,[0],[0]
"= p(nk, y1:k) and k(nk)",3. Methods,[0],[0]
":= p(nk, y1:k 1).",3. Methods,[0],[0]
"These satisfy the recurrence:
k(nk) =",3. Methods,[0],[0]
"X
nk 1
↵k 1(nk 1)p(nk |nk 1), (3)
↵k(nk) = k(nk)p(yk |nk).",3. Methods,[0],[0]
"(4)
We will refer to Equation (3) as the prediction step (the value of nk is predicted based on the observations y1:k 1), and Equation (4) as the evidence step (the new evidence yk is incorporated).",3. Methods,[0],[0]
"In finite models, the forward algorithm can compute the ↵k messages for k = 1, . . .",3. Methods,[0],[0]
",K directly using Equations (3) and (4).",3. Methods,[0],[0]
"However, if nk is unbounded, this cannot be done directly; for example, ↵k(nk) is an infinite sequence, and Equation (3) contains an infinite sum.",3. Methods,[0],[0]
"Winner & Sheldon (2016) observed that, for some conditional distributions p(nk |nk 1) and p(yk |nk), the operations of the forward algorithm can be carried out using PGFs.",3.1. Forward Algorithm with PGFs,[0],[0]
"Specifically, define the PGFs k(uk) and Ak(sk) of k(nk) and ↵k(nk), respectively, as:
k(uk) := 1X
nk=0
k(nk)u nk k , (5)
Ak(sk) := 1X
nk=0
↵k(nk)s nk k .",3.1. Forward Algorithm with PGFs,[0],[0]
"(6)
The PGFs k and Ak are power series in the variables uk and sk with coefficients equal to the message entries.
",3.1. Forward Algorithm with PGFs,[0],[0]
These functions capture all relevant information about the associated distributions.,3.1. Forward Algorithm with PGFs,[0],[0]
"Technically, k and Ak are unnormalized PGFs because the coefficients do not sum to one.",3.1. Forward Algorithm with PGFs,[0],[0]
"However, the normalization constants are easily recovered by evaluating the PGF on input value 1: for example, Ak(1) =",3.1. Forward Algorithm with PGFs,[0],[0]
"P nk
↵k(nk) = p(y1:k).",3.1. Forward Algorithm with PGFs,[0],[0]
This also shows that we can recover the likelihood as AK(1) = p(y1:K).,3.1. Forward Algorithm with PGFs,[0],[0]
"After normalizing, the PGFs can be interpreted as expectations, for example Ak(sk)/Ak(1) =",3.1. Forward Algorithm with PGFs,[0],[0]
E[sNkk,3.1. Forward Algorithm with PGFs,[0],[0]
"| y1:k].
In general, it is well known that the PGF F (s) of a nonnegative integer-valued random variable X uniquely defines the entries of the probability mass function and the moments of X , which are recovered from (higher-order) derivatives of F evaluated at zero and one, respectively:
Pr(X = r)",3.1. Forward Algorithm with PGFs,[0],[0]
=,3.1. Forward Algorithm with PGFs,[0],[0]
"F (r)(0)/r!, (7)
E[X] = F (1)(1), (8)
Var(X) = F (2)(1)",3.1. Forward Algorithm with PGFs,[0],[0]
h F (1)(1),3.1. Forward Algorithm with PGFs,[0],[0]
i 2 + F (1)(1).,3.1. Forward Algorithm with PGFs,[0],[0]
"(9)
More generally, the first q moments are determined by the derivatives F (r)(1) for r  q.",3.1. Forward Algorithm with PGFs,[0],[0]
"Therefore, if we can evaluate the PGF Ak and its derivatives for sk 2 {0, 1}, we can answer arbitrary queries about the filtering distributions p(nk, y1:k), and, in particular, solve our three stated inference problems.
",3.1. Forward Algorithm with PGFs,[0],[0]
"But how can we compute values of Ak, k, and their derivatives?",3.1. Forward Algorithm with PGFs,[0],[0]
What form do these PGFs have?,3.1. Forward Algorithm with PGFs,[0],[0]
"One key result of Winner & Sheldon (2016), which we generalize here, is the fact that there is also a recurrence relation among the PGFs.",3.1. Forward Algorithm with PGFs,[0],[0]
Proposition 1.,3.1. Forward Algorithm with PGFs,[0],[0]
Consider the probability model defined in Equations (1) and (2).,3.1. Forward Algorithm with PGFs,[0],[0]
"Let Fk be the PGF of the offspring random variable Xk, and let Gk be the PGF of the immigration random variable Mk.",3.1. Forward Algorithm with PGFs,[0],[0]
"Then k and Ak satisfy the following recurrence:
k(uk) =",3.1. Forward Algorithm with PGFs,[0],[0]
"Ak 1 Fk(uk) ·Gk(uk) (10)
Ak(sk)",3.1. Forward Algorithm with PGFs,[0],[0]
"= (sk⇢k)yk
yk! · (yk)k sk(1 ⇢k)
",3.1. Forward Algorithm with PGFs,[0],[0]
"(11)
Proof.",3.1. Forward Algorithm with PGFs,[0],[0]
"A slightly less general version of Equation (10) appeared in Winner & Sheldon (2016); the general version appears in the literature on branching processes with immigration (Heathcote, 1965).",3.1. Forward Algorithm with PGFs,[0],[0]
"Equation (11) follows directly from general PGF operations outlined in (Winner & Sheldon, 2016).
",3.1. Forward Algorithm with PGFs,[0],[0]
The PGF recurrence has the same two elements as the pmf recurrence in equations (3) and (4).,3.1. Forward Algorithm with PGFs,[0],[0]
"Equation (10) is the prediction step: it describes the PGF of k(nk) = p(nk, y1:k 1) in terms of previous PGFs.",3.1. Forward Algorithm with PGFs,[0],[0]
"Equation (11) is the evidence step: it describes the PGF for ↵k(nk) =
p(nk, y1:k) in terms of the previous PGF and the new observation yk.",3.1. Forward Algorithm with PGFs,[0],[0]
"Note that the evidence step involves the ykth derivative of the PGF k from the prediction step, where yk is the observed count.",3.1. Forward Algorithm with PGFs,[0],[0]
These high-order derivatives complicate the calculation of the PGFs.,3.1. Forward Algorithm with PGFs,[0],[0]
The recurrence reveals structure about Ak and k but does not immediately imply an algorithm.,3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Winner & Sheldon (2016) showed how to use the recurrence to compute symbolic representations of all PGFs in the special case of Bernoulli offspring and Poisson immigration: in this case, they proved that all PGFs have the form F (s) = f(s)",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"exp(as + b), where f is a polynomial of bounded degree.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Hence, they can be represented compactly and computed efficiently using the recurrence.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"The result is a symbolic representation, so, for example, one obtains a closed form representation of the final PGF AK , from which the likelihood, entries of the pmf, and moments can be calculated.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"However, the compact functional form f(s) exp(as + b) seems to rely crucially on properties of the Poisson distribution.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"When other distributions are used, the size of the symbolic PGF representation grows quickly with K. It is an open question whether the symbolic methods can be extended to other classes of PGFs.
",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
This motivates an alternate approach.,3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Instead of computing Ak symbolically, we will evaluate Ak and its derivatives at particular values of sk corresponding to the queries we wish to make (cf. Equations (7)–(9)).",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"To develop the approach, it is helpful to consider the feed-forward computation for evaluating Ak at a particular value sk.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"The circuit diagram in Figure 1 is a directed acyclic graph that describes this calculation; the nodes are intermediate quantities in the calculation, and the shaded rectangles illustrate the recursively nested PGFs.
",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Now, we can consider techniques from automatic differentiation (autodiff) to compute Ak and its derivatives.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"How-
ever, these will not apply directly.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Note that Ak is defined in terms of higher-order derivatives of the function k, which depends on higher-order derivatives of k 1, and so forth.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
Standard autodiff techniques cannot handle these recursively nested derivatives.,3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
"Therefore, we will develop a novel algorithm.",3.2. Evaluating Ak via Automatic Differentiation,[0],[0]
We now develop basic notation and building blocks that we will assemble to construct our algorithm.,3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"It is helpful to abstract from our particular setting and describe a general model for derivatives within a feed-forward computation, following Griewank & Walther (2008).",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"We consider a procedure that assigns values to a sequence of variables v 0 , v 1
, . . .",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
", vn, where v0 is the input variable, vn is the output variable, and each intermediate variable vj is computed via a function 'j(vi)i j of some subset (vi)i j of the variables v
0:j 1.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
Here the dependence relation,3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"i j simply means that 'j depends directly on vi, and (vi)i j is the vector of variables for which that is true.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"Note that the dependence relation defines a directed acyclic graph G (e.g., the circuit in Figure 1), and v
0 , . . .",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
", vn is a topological ordering of G.
We will be concerned with the values of a variable v` and its derivatives with respect to some earlier variable vi.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"To represent this cleanly, we first introduce a notation to capture the partial computation between the assignment of vi and v`.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"For i  `, define fi`(v0:i) to be the value that is assigned to v` if the values of the first i variables are given by v 0:i (now treated as fixed input values).",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"This can be defined formally in an inductive fashion:
fi`(v0:i) = '`(uij)j `, uij = ( vj if j  i fij(v0:i) if j >",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"i
This can be interpreted as recursion with memoization for v 0:i. When '` “requests” the value of uij of vj : if j  i, this value was given as an input argument of fi`, so we just “look it up”; but if j > i, we recursively compute the correct value via the partial computation from i to j. Now, we define a notation to capture derivatives of a variable v` with respect to an earlier variable vi.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
Definition 1 (Dual numbers).,3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"The generalized dual number hv`, dviiq for 0  i  ` and q > 0 is the sequence consisting of v` and its first q derivatives with respect to vi:
hv`,",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"dviiq = ✓ @p
@vpi fi`(v0:i)
◆q
p=0
We say that hv`, dviiq is a dual number of order q with respect to vi.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
Let DRq be the set of dual numbers of order q.,3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"We will commonly write dual numbers as:
hs, duiq = ⇣ s, ds
du , . . .",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
",
dqs
duq
⌘
in which case it is understood that s = v` and u = vi for some 0  i  `, and the function fi`(·) will be clear from context.
",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
Our treatment of dual numbers and partial computations is more explicit than what is standard.,3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"In particular, we are explicit both about the variable v` we are differentiating and the variable vi with respect to which we are differentiating.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"This is important for our algorithm, and also helps distinguish our approach from traditional automatic differentiation approaches.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"Forward-mode autodiff computes derivatives of all variables with respect to v
0 , i.e., it computes hvj , dv0iq for j = 1, . . .",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
", n. Reverse-mode autodiff computes derivatives of vn with respect to all variables, i.e., it computes hvn, dviiq for i = n 1, . . .",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
", 0.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
"In each case, one of the two variables is fixed, so the notation can be simplified.",3.2.1. COMPUTATION MODEL AND DUAL NUMBERS,[0],[0]
The general idea of our algorithm will resemble forwardmode autodiff.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Instead of sequentially calculating the values v
1 , . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", vn in our feed-forward computation, we will calculate dual numbers hv
1 , dvi1iq1 , . . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", hvn, dviniqn , where we leave unspecified (for now) the variables with respect to which we differentiate, and the order of the dual numbers.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
We will require three high-level operations on dual numbers.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"The first one is “lifting” a scalar function.
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Definition 2 (Lifted Function).,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Let f : Rm !,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"R be a function of variables x
1 , . . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", xm.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
The qth-order lifted function Lqf : (DRq)m !,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"DRq is the function that accepts as input dual numbers hx
1 , duiq, . . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", hxm, duiq of order q with respect to the same variable u, and returns the value⌦ f(x
1 , . . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", xm), du ↵ q .
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Lifting is the basic operation of higher-order forward mode autodiff.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"For functions f consisting only of “primitive operations”, the lifted function Lqf can be computed at a modest overhead relative to computing f .
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Proposition 2 (Griewank & Walther, 2008).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Let f : Rm !,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"R be a function that consists only of the following primitive operations, where x and y are arbitrary input variables and all other numbers are constants: x",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"+ cy, x ⇤ y, x/y, xr, ln(x), exp(x), sin(x), cos(x).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Then Lqf can be computed in time O(q2) times the running time of f .
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Based on this proposition, we will write algebraic operations on dual numbers, e.g., hx, duiq⇥hy, duiq , and understand these to be lifted versions of the corresponding scalar operations.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"The standard lifting approach is to represent dual numbers as univariate Taylor polynomials (UTPs), in which case many operations (e.g., multiplication, addition) translate directly to the corresponding operations on polynomials.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"We will use UTPs in the proof of Theorem 1.
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
The second operation we will require is composition.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Say that variable vj separates vi from v` if all paths from vi to v` in G go through vj .,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Theorem 1 (Composition).,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Suppose vj separates vi from v`.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"In this case, the dual number hv`, dviiq depends only on the dual numbers hv`, dvjiq and hvj , dviiq , and we define the composition operation:
hv`, dvjiq hvj , dviiq := hv`, dviiq
If vj does not separate vi from v`, the written composition operation is undefined.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"The composition operation can be performed in O(q2 log q) time by composing two UTPs.
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Proof.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"If all paths from vi to v` go through vj , then vj is a “bottleneck” in the partial computation fil.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Specifically, there exist functions F and H such that vj = F (vi) and v` = H(vj).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Here, the notation suppresses dependence on variables that either are not reachable from vi, or do not have a path to v`, and hence may be treated as constants because they they do not impact the dual number hv`, viiq .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
A detailed justification of this is given in the supplementary material.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Now, our goal is to compute the higher-order derivatives of v` = H(F (vi)).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Let ˆF and ˆH be infinite Taylor expansions about vi and vj , respectively, omitting the constant terms F (vi) and H(vj):
ˆF ("") := 1X
p=1
F (p)(vi)
p!",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"""p, ˆH("") :=
1X
p=1
H(p)(vj)
p!",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"""p.
These are polynomials in "", and the first q coefficients are given in the input dual numbers.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"The coefficient of ""p in ˆU("") := ˆH( ˆF ("")) for p 1 is exactly dpv`/dvpi (see Wheeler, 1987, where the composition of Taylor polynomials is related directly to the higher-order chain rule known as Faà dı́ Bruno’s Formula).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
So it suffices to compute the first q coefficients of ˆH( ˆF (✏)).,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"This can be done by executing Horner’s method (Horner, 1819) in truncated Taylor polynomial arithmetic (Griewank & Walther, 2008), which keeps only the first q coefficients of all polynomials (i.e., it assumes ✏p = 0 for p > q).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"After truncation, Horner’s method involves q additions and q multiplications of polynomials of degree at most q. Polynomial multiplication takes time O(q log q) using the FFT, so the overall running time is O(q2 log q).
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
The final operation we will require is differentiation.,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"This will support local functions '` that differentiate a previous value, e.g., v` = '`(vj) = dpvj/dvpi .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
Definition 3 (Differential Operator).,3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"Let hs, duiq be a dual number.",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"For p  q, the differential operator Dp applied to hs, duiq returns the dual number of order q p given by:
Dphs, duiq := ⇣ dps dup , . . .",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
", dqs duq ⌘
The differential operator can be applied in O(q) time.
",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"This operation was defined in (Kalaba & Tesfatsion, 1986).",3.2.2. OPERATIONS ON DUAL NUMBERS,[0],[0]
"We will now use these operations to lift the function Ak to compute h↵k, skiq = LA hsk, dskiq), i.e., the output of Ak and its derivatives with respect to its input.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Algorithm 1 gives a sequence of mathematical operations to compute Ak(sk).,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Algorithm 2 shows the corresponding operations on dual numbers; we call this algorithm the generalized dual-number forward algorithm or GDUALFORWARD.,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Note that a dual number of a variable with respect to itself is simply hx, dxiq = (x, 1, 0, . . .",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
", 0); such expressions are used without explicit initialization in Algorithm 2.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Also, if the dual number hx, dyiq has been assigned, we will assume the scalar value x is also available, for example, to initialize a new dual variable hx, dxiq (cf.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
the dual number on the RHS of Line 3).,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Note that Algorithm 1 contains a non-primitive operation on Line 5: the derivative dyk k/duykk .,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"To evaluate this in Algorithm 2, we must manipulate the dual number of k to be taken with respect to uk, and not the original input value sk, as in forward-mode autodiff.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Our approach can be viewed as following a different recursive principle from either forward or reverse-mode autodiff: in the circuit diagram of Figure 1, we calculate derivatives of each nested circuit with respect to its own input, starting with the innermost circuit and working out.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Theorem 2.,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"LAK computes h↵k, dskiq in time O K(q",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"+
Y )2 log(q + Y ) where Y = PK
k=1 yk is the sum of the observed counts and q is the requested number of derivatives.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Therefore, the likelihood can be computed in O(KY 2 log Y ) time, and the first q moments or the first q entries of the filtered marginals can be computed in time",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
O K(q,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"+ Y )2 log(q + Y ) .
",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Proof.,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"To see that GDUAL-FORWARD is correct, note that it corresponds to Algorithm 1, but applies the three operations from the previous section to operate on dual numbers instead of scalars.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
We will verify that the conditions for applying each operation are met.,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
Lines 2–5 each use lifting of algebraic operations or the functions,3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Fk and Gk, which are assumed to consist only of primitive operations.",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Lines 4 and 5 apply the composition operation; here, we can verify from Figure 1 that sk 1 separates uk and ↵k 1 (Line 4) and that uk separates sk and k (Line 5).",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"The conditions for applying the differential operator on Line 5 are also met.
",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"For the running time, note that the total number of operations on dual numbers in LAK , including recursive calls, is O(K).",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"The order of the dual numbers is initially q, but increases by yk in each recursive call (Line 4).",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Therefore, the maximum value is q + Y .",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Each of the operations on
Algorithm 1 Ak(sk) if k = 0 then
1: return ↵k = 1 end if 2: uk = sk(1 ⇢k) 3: sk 1 = Fk(uk) 4: k = Ak 1(sk 1) ·Gk(uk) 5: ↵k = d yk
du yk k k · (sk⇢k)yk/yk! 6: return ↵k
Algorithm 2 LAk(hsk, dskiq) — GDUAL-FORWARD if k = 0 then
1: return h↵k, dskiq = (1, 0, . . .",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
", 0) end if 2: huk, dskiq = hsk, dskiq · (1 ⇢k) 3: hsk 1, dukiq+yk = LFk huk, dukiq+yk
4: h k, dukiq+yk = ⇥ LAk 1",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"hsk 1, dsk 1iq+yk hsk 1, dukiq+yk ⇤ ⇥",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"LGk huk, dukiq+yk 5: h↵k, dskiq = ⇥",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"Dyk h k, dukiq+yk huk, dskiq ⇤ ⇥ ⇢khsk, dskiq
yk/yk! 6: return h↵k, dskiq
dual numbers is O(p2 log p) for dual numbers of order p, so the total is O(K(q + Y )2 log(q + Y )).",3.2.3. THE GDUAL-FORWARD ALGORITHM,[0],[0]
"In this section we describe simulation experiments to evaluate the running time of GDUAL-FORWARD against other algorithms, and to assess the ability to learn a wide variety of models for which exact likelihood calculations were not previously possible, by using GDUAL-FORWARD within a parameter estimation routine.
",4. Experiments,[0],[0]
Running time vs Y .,4. Experiments,[0],[0]
"We compared the running time of GDUAL-FORWARD with the PGF-FORWARD algorithm from (Winner & Sheldon, 2016) as well as TRUNC, the standard truncated forward algorithm (Dail & Madsen, 2011).",4. Experiments,[0],[0]
"PGF-FORWARD is only applicable to the Poisson HMM from (Winner & Sheldon, 2016), which, in our terminology, is a model with a Poisson immigration distribution and a Bernoulli offspring distribution.",4. Experiments,[0],[0]
"TRUNC applies to any choice of distributions, but is approximate.",4. Experiments,[0],[0]
"For these experiments, we restrict to Poisson HMMs for the sake of comparison with the less general PGF-FORWARD algorithm.
",4. Experiments,[0],[0]
A primary factor affecting running time is the magnitude of the counts.,4. Experiments,[0],[0]
We measured the running time for all algorithms to compute the likelihood p(y; ✓) for vectors y,4. Experiments,[0],[0]
:= y 1:K = c ⇥,4. Experiments,[0],[0]
"(1, 1, 1, 1, 1) with increasing c.",4. Experiments,[0],[0]
"In this case, Y = P k yk = 5c.",4. Experiments,[0],[0]
"PGF-FORWARD and GDUAL-FORWARD have running times O(KY 2) and O(KY 2 log Y ), respectively, which depend only on Y and not ✓.",4. Experiments,[0],[0]
"The running time of an FFT-based implementation of TRUNC is O(KN2
max
logN max ), where N max is the value used to truncate the support of each latent variable.",4. Experiments,[0],[0]
"A heuristic is required to choose N
max so that it captures most of the probability mass of p(y; ✓) but is not too big.",4. Experiments,[0],[0]
"The appropriate value depends strongly on ✓, which in practice may be unknown.",4. Experiments,[0],[0]
"In preliminary experiments with realistic immigration and offspring models (see below) and known parameters, we found that an excellent heuristic is N
max = 0.4Y/⇢, which we use here.",4. Experiments,[0],[0]
"With this heuristic, TRUNC’s running time is O(K⇢2Y 2 log Y ).
",4. Experiments,[0],[0]
"Figure 3 shows the results for ⇢ 2 {0.15, 0.85}, averaged over 20 trials with error bars showing 95% confidence intervals of the mean.",4. Experiments,[0],[0]
"GDUAL-FORWARD and TRUNC have the same asymptotic dependence on Y but GDUALFORWARD scales better empirically, and is exact.",4. Experiments,[0],[0]
"It is about 8x faster than TRUNC for the largest Y when ⇢ = 0.15, and 2x faster for ⇢ = 0.85.",4. Experiments,[0],[0]
"PGF-FORWARD is faster by a factor of log Y in theory and scales better in practice, but applies to fewer models.
",4. Experiments,[0],[0]
Running time for different ✓.,4. Experiments,[0],[0]
"We also conducted experiments where we varied parameters and used an oracle method to select N
max for TRUNC.",4. Experiments,[0],[0]
"This was done by running the algorithm for increasing values of N
max and selecting the smallest one such that the likelihood was within 10 6 of the true value (see Winner & Sheldon, 2016).
",4. Experiments,[0],[0]
"We simulated data from Poisson HMMs and measured the time to compute the likelihood p(y; ✓) for the true parameters ✓ = ( , , ⇢), where is a vector whose kth entry is the mean of the Poisson immigration distribution at time k, and and ⇢ are scalars representing the Bernoulli survival probability and detection probability, respectively, which are shared across time steps.",4. Experiments,[0],[0]
"We set and to mimic three different biological models; for each, we varied ⇢ from 0.05 to 0.95.",4. Experiments,[0],[0]
"The biological models were as follows: ‘PHMM’ follows a temporal model for insect populations (Zonneveld, 1991) with = (5.13, 23.26, 42.08, 30.09, 8.56) and = 0.26; ‘PHMM-peaked’ is similar, but sets = (0.04, 10.26, 74.93, 25.13, 4.14) so the immigration is temporally “peaked” at the middle time step; ‘NMix’ sets = (80, 0, 0, 0, 0) and = 0.4, which is similar to the N-mixture model (Royle, 2004), with no immigration following the first time step.
",4. Experiments,[0],[0]
Figure 2 shows the running time of all three methods versus ⇢.,4. Experiments,[0],[0]
"In these models, E[Y ] is proportional to ⇢, and the running times of GDUAL-FORWARD and PGF-FORWARD increase with ⇢ due to the corresponding increase in Y .",4. Experiments,[0],[0]
"PGFFORWARD is faster by a factor of log Y , but is applicable to fewer models.",4. Experiments,[0],[0]
"GDUAL-FORWARD perfoms best relative to PGF-FORWARD for the NMix model, because it is fastest when counts occur in early time steps.
",4. Experiments,[0],[0]
"Recall that the running time of TRUNC is O(N2
max
logN max ).",4. Experiments,[0],[0]
"For these models, the distribution of the hidden population depends only on and , and these are the primary factors determining N
max .",4. Experiments,[0],[0]
"Running time decreases slightly as ⇢ increases, because the observation model p(y |n; ⇢) exerts more influence restricting implausible settings of n when the detection probability is higher.
",4. Experiments,[0],[0]
Parameter Estimation.,4. Experiments,[0],[0]
"To demonstrate the flexibility of the method, we used GDUAL-FORWARD within an optimization routine to compute maximum likelihood estimates (MLEs) for models with different immigration and growth distributions.",4. Experiments,[0],[0]
"In each experiment, we generated 10 independent observation vectors for K = 7 time steps from the same model p(y; ✓), and then used the L-BFGS-B algorithm to numerically find ✓ to maximize the loglikelihood of the 10 replicates.",4. Experiments,[0],[0]
We varied the distributional forms of the immigration and offspring distributions as well as the mean R := E[Xk] of the offspring distribution.,4. Experiments,[0],[0]
"We fixed the mean immigration := E[Mk] = 6 and the de-
tection probability to ⇢ = 0.6 across all time steps.",4. Experiments,[0],[0]
"The quantity R is the “basic reproduction number”, or the average number of offspring produced by a single individual, and is of paramount importance for disease and population models.",4. Experiments,[0],[0]
"We varied R, which was also shared across time steps, between 0.2 and 1.2.",4. Experiments,[0],[0]
"The parameters and R were learned, and ⇢ was fixed to resolve ambiguity between population size and detection probability.",4. Experiments,[0],[0]
"Each experiment was repeated 50 times; a very small number of optimizer runs failed to converge after 10 random restarts and were excluded.
",4. Experiments,[0],[0]
Figure 4 shows the distribution of 50 MLE estimates for R vs. the true values for each model.,4. Experiments,[0],[0]
Results for two additional models appear in the supplementary material.,4. Experiments,[0],[0]
In all cases the distribution of the estimate is centered around the true parameter.,4. Experiments,[0],[0]
It is evident that GDUAL-FORWARD can be used effectively to produce parameter estimates across a variety of models for which exact likelihood computations were not previously possible.,4. Experiments,[0],[0]
This material is based upon work supported by the National Science Foundation under Grant No. 1617533.,Acknowledgments,[0],[0]
Graphical models with latent count variables arise in a number of areas.,abstractText,[0],[0]
"However, standard inference algorithms do not apply to these models due to the infinite support of the latent variables.",abstractText,[0],[0]
"Winner & Sheldon (2016) recently developed a new technique using probability generating functions (PGFs) to perform efficient, exact inference for certain Poisson latent variable models.",abstractText,[0],[0]
"However, the method relies on symbolic manipulation of PGFs, and it is unclear whether this can be extended to more general models.",abstractText,[0],[0]
"In this paper we introduce a new approach for inference with PGFs: instead of manipulating PGFs symbolically, we adapt techniques from the autodiff literature to compute the higher-order derivatives necessary for inference.",abstractText,[0],[0]
"This substantially generalizes the class of models for which efficient, exact inference algorithms are available.",abstractText,[0],[0]
"Specifically, our results apply to a class of models that includes branching processes, which are widely used in applied mathematics and population ecology, and autoregressive models for integer data.",abstractText,[0],[0]
Experiments show that our techniques are more scalable than existing approximate methods and enable new applications.,abstractText,[0],[0]
Exact Inference for Integer Latent-Variable Models,title,[0],[0]
"Given a graphical model, one essential problem is MAP inference, that is, finding the most likely configuration of states according to the model. Although this problem is NP-hard, large instances can be solved in practice and it is a major open question is to explain why this is true. We give a natural condition under which we can provably perform MAP inference in polynomial time—we require that the number of fractional vertices in the LP relaxation exceeding the optimal solution is bounded by a polynomial in the problem size. This resolves an open question by Dimakis, Gohari, and Wainwright. In contrast, for general LP relaxations of integer programs, known techniques can only handle a constant number of fractional vertices whose value exceeds the optimal solution. We experimentally verify this condition and demonstrate how efficient various integer programming methods are at removing fractional solutions.",text,[0],[0]
"Given a graphical model, one essential problem is MAP inference, that is, finding the most likely configuration of states according to the model.
",1. Introduction,[0],[0]
"Consider graphical models with binary random variables and pairwise interactions, also known as Ising models.",1. Introduction,[0],[0]
"For a graph G = (V,E) with node weights θ ∈ RV and edge weights W ∈ RE , the probability of a variable configura-
1Department of Electrical and Computer Engineering, University of Texas at Austin, USA 2Department of Computer Science, University of Texas at Austin, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Erik M. Lindgren <erikml@utexas.edu>, Alexandros G. Dimakis <dimakis@austin.utexas.edu>, Adam Klivans <klivans@cs.utexas.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
tion is given by
P(X = x) = 1
Z exp ∑ i∈V θixi + ∑ ij∈E",1. Introduction,[0],[0]
"Wijxixj  , (1) where Z is a normalization constant.
",1. Introduction,[0],[0]
"The MAP problem is to find the configuration x ∈ {0, 1}V that maximizes Equation (1).",1. Introduction,[0],[0]
"We can write this as an integer linear program (ILP) as follows:
max q∈RV ∪E ∑ i∈V θiqi + ∑ ij∈E",1. Introduction,[0],[0]
"Wijqij
s.t. qi ∈ {0, 1} ∀i ∈ V qij ≥ max{0, qi + qj",1. Introduction,[0],[0]
− 1} ∀ij ∈,1. Introduction,[0],[0]
E,1. Introduction,[0],[0]
qij ≤,1. Introduction,[0],[0]
"min{qi, qj} ∀ij ∈",1. Introduction,[0],[0]
"E. (2)
",1. Introduction,[0],[0]
"The MAP problem on binary, pairwise graphical models contains, as a special case, the Max-cut problem and is therefore NP-hard.",1. Introduction,[0],[0]
"For this reason, a significant amount of attention has focused on analyzing the LP relaxation of the ILP, which can be solved efficiently in practice.
",1. Introduction,[0],[0]
max q∈RV ∪E ∑ i∈V θiqi + ∑ ij∈E,1. Introduction,[0],[0]
"Wijqij
s.t. 0 ≤ qi ≤ 1 ∀i ∈ V qij ≥ max{0, qi + qj",1. Introduction,[0],[0]
− 1} ∀ij ∈,1. Introduction,[0],[0]
E,1. Introduction,[0],[0]
qij ≤,1. Introduction,[0],[0]
"min{qi, qj} ∀ij ∈ E (3)
",1. Introduction,[0],[0]
This relaxation has been an area of intense research in machine learning and statistics.,1. Introduction,[0],[0]
"In (Meshi et al., 2016), the authors state that a major open question is to identify why real world instances of Problem (2) can be solved efficiently despite the theoretical worst case complexity.
",1. Introduction,[0],[0]
"We make progress on this open problem by analyzing the fractional vertices of the LP relaxation, that is, the extreme points of the polytope with fractional coordinates.",1. Introduction,[0],[0]
Vertices of the relaxed polytope with fractional coordinates are called pseudomarginals for graphical models and pseudocodewords in coding theory.,1. Introduction,[0],[0]
"If a fractional vertex has higher objective value (i.e. likelihood) compared to the best integral one, the LP relaxation fails.",1. Introduction,[0],[0]
"We call fractional vertices with an objective value at least as good as the objective
value of the optimal integral vertex confounding vertices.",1. Introduction,[0],[0]
"Our main result is that it is possible to prune all confounding vertices efficiently when their number is polynomial.
",1. Introduction,[0],[0]
"Our contributions:
• Our first contribution is a general result on integer programs.",1. Introduction,[0],[0]
"We show that any 0-1 integer linear program (ILP) can be solved exactly in polynomial time, if the number confounding vertices is bounded by a polynomial.",1. Introduction,[0],[0]
This applies to MAP inference for a graphical model over any alphabet size and any order of connection.,1. Introduction,[0],[0]
"The same result (exact solution if the number of confounding vertices is bounded by a polynomial) was established by (Dimakis et al., 2009) for the special case of LP decoding of LDPC codes (Feldman et al., 2005).",1. Introduction,[0],[0]
"The algorithm from (Dimakis et al., 2009) relies on the special structure of the graphical models that correspond to LDPC codes.",1. Introduction,[0],[0]
In this paper we generalize this result for any ILP in the unit hypercube.,1. Introduction,[0],[0]
"Our results extend to finding all integral vertices among the M -best vertices.
",1. Introduction,[0],[0]
"• Given our condition, one may be tempted to think that we generate the top M -best vertices of a linear program (for M polynomial) and output the best integral one in this list.",1. Introduction,[0],[0]
We actually show that such an approach would be computationally intractable.,1. Introduction,[0],[0]
"Specifically, we show that it is NP-hard to produce a list of the M -best vertices if M = O(nε) for any fixed ε > 0.",1. Introduction,[0],[0]
This result holds even if the list is allowed to be approximate.,1. Introduction,[0],[0]
"This strengthens the previously known hardness result (Angulo et al., 2014) which was M = O(n) for the exact M -best vertices.",1. Introduction,[0],[0]
"In terms of achievability, the best previously known result (from (Angulo et al., 2014)) can only solve the ILP if there is at most a constant number of confounding vertices.
",1. Introduction,[0],[0]
"• We obtain a complete characterization of the fractional vertices of the local polytope for binary, pairwise graphical models.",1. Introduction,[0],[0]
We show that any variable in the fractional support must be connected to a frustrated cycle by other fractional variables in the graphical model.,1. Introduction,[0],[0]
"This is a complete structural characterization that was not previously known, to the best of our knowledge.
",1. Introduction,[0],[0]
• We develop an approach to estimate the number of confounding vertices of a half-integral polytope.,1. Introduction,[0],[0]
We use this method in an empirical evaluation of the number of confounding vertices of previously studied problems and analyze how well common integer programming techniques perform at pruning confounding vertices.,1. Introduction,[0],[0]
"For some classes of graphical models, it is possible to solve the MAP problem exactly.",2. Background and Related Work,[0],[0]
"For example see (Weller et al., 2016) for balanced and almost balanced models, (Jebara, 2009) for perfect graphs, and (Wainwright et al., 2008) for graphs with constant tree-width.
",2. Background and Related Work,[0],[0]
These conditions are often not true in practice and a wide variety of general purpose algorithms are able to solve the MAP problem for large inputs.,2. Background and Related Work,[0],[0]
"One class is belief propagation and its variants (Yedidia et al., 2000; Wainwright et al., 2003; Sontag et al., 2008).",2. Background and Related Work,[0],[0]
"Another class involves general ILP optimization methods (see e.g. (Nemhauser & Wolsey, 1999)).",2. Background and Related Work,[0],[0]
"Techniques specialized to graphical models include cutting-plane methods based on the cycle inequalities (Sontag & Jaakkola, 2007; Komodakis & Paragios, 2008; Sontag et al., 2012).",2. Background and Related Work,[0],[0]
"See also (Kappes et al., 2013) for a comparative survey of techniques.
",2. Background and Related Work,[0],[0]
"In (Weller et al., 2014), the authors investigate how pseudomarginals and relaxations relate to the success of the Bethe approximation of the partition function.
",2. Background and Related Work,[0],[0]
"There has been substantial prior work on improving inference building on these LP relaxations, especially for LDPC codes in the information theory community.",2. Background and Related Work,[0],[0]
"This work ranges from very fast solvers that exploit the special structure of the polytope (Burshtein, 2009), connections to unequal error protection (Dimakis et al., 2007), and graphical model covers (Koetter et al., 2007).",2. Background and Related Work,[0],[0]
"LP decoding currently provides the best known finite-length error-correction bounds for LDPC codes both for random (Daskalakis et al., 2008; Arora et al., 2009), and adversarial bit-flipping errors (Feldman et al., 2007).
",2. Background and Related Work,[0],[0]
"For binary graphical models, there is a body of work which tries to exploit the persistency of the LP relaxation, that is, the property that integer components in the solution of the relaxation must take the same value in the optimal solution, under some regularity assumptions (Boros & Hammer, 2002; Rother et al., 2007; Fix et al., 2012).
",2. Background and Related Work,[0],[0]
"Fast algorithms for solving large graphical models in practice include (Ihler et al., 2012; Dechter & Rish, 2003).
",2. Background and Related Work,[0],[0]
"The work most closely related to this paper involves eliminating fractional vertices (so-called pseudocodewords in coding theory) by changing the polytope or the objective function (Zhang & Siegel, 2012; Chertkov & Stepanov, 2008; Liu et al., 2012).",2. Background and Related Work,[0],[0]
"A binary integer linear program is an optimization problem of the following form.
",3. Provable Integer Programming,[0],[0]
"max x
cTx
subject to Ax ≤ b x ∈ {0, 1}n
which is relaxed to a linear program by replacing the x ∈ {0, 1}n constraint with 0 ≤ x ≤ 1.",3. Provable Integer Programming,[0],[0]
For binary integer programs with the box constraints 0 ≤,3. Provable Integer Programming,[0],[0]
"xi ≤ 1 for all i, every integral vector x is a vertex of the polytope described by the constraints of the LP relaxation.",3. Provable Integer Programming,[0],[0]
"However fraction vertices may also be in this polytope, and fractional solutions can potentially have an objective value larger than every integral vertex.
",3. Provable Integer Programming,[0],[0]
"If the optimal solution to the linear program happens to be integral, then this is the optimal solution to the original integer linear program.",3. Provable Integer Programming,[0],[0]
"If the optimal solution is fractional, then a variety of techniques are available to tighten the LP relaxation and eliminate the fractional solution.
",3. Provable Integer Programming,[0],[0]
"We establish a success condition for integer programming based on the number of confounding vertices, which to the best of our knowledge was unknown.",3. Provable Integer Programming,[0],[0]
"The algorithm used in proving Theorem 1 is a version of branch-and-bound, a classic technique in integer programming (Land & Doig, 1960) (see (Nemhauser & Wolsey, 1999) for a modern reference on integer programming).",3. Provable Integer Programming,[0],[0]
"This algorithm works by starting with a root node, then branching on a fractional coordinate by making two new linear programs with all the constraints of the parent node, with the constraint xi = 0 added to one new leaf and xi = 1 added to the other.",3. Provable Integer Programming,[0],[0]
The decision on which leaf of the tree to branch on next is based on which leaf has the best objective value.,3. Provable Integer Programming,[0],[0]
"When the best leaf is integral, we know that this is the best integral solution.",3. Provable Integer Programming,[0],[0]
"This algorithm is formally written in Algorithm 1.
",3. Provable Integer Programming,[0],[0]
Theorem 1.,3. Provable Integer Programming,[0],[0]
"Let x∗ be the optimal integral solution and let {v1, v2, . . .",3. Provable Integer Programming,[0],[0]
", vM} be the set of confounding vertices in the LP relaxation.",3. Provable Integer Programming,[0],[0]
"Algorithm 1 will find the optimal integral solution x∗ after 2M calls to an LP solver.
",3. Provable Integer Programming,[0],[0]
"Since MAP inference is a binary integer program regardless of the alphabet size of the variables and order of the clique potentials, we have the following corollary:
Corollary 2.",3. Provable Integer Programming,[0],[0]
"Given a graphical model such that the local polytope has M as cofounding variables, Algorithm 1 can find the optimal MAP configuration with 2M calls to an LP solver.
",3. Provable Integer Programming,[0],[0]
"Cutting-plane methods, which remove a fractional vertex by introducing a new constraint in the polytope may not have this property, since this cut may create new confound-
Algorithm 1 Branch and Bound test Input: an LP {min cTx :",3. Provable Integer Programming,[0],[0]
"Ax ≤ b, 0 ≤ x ≤ 1}
# branch (v, I0, I1) means v is optimal LP # with xI0 = 0 and xI1 = 1.",3. Provable Integer Programming,[0],[0]
"def LP(I0, I1): v∗ ← argmax cTx subject to:",3. Provable Integer Programming,[0],[0]
Ax ≤ b xI0 = 0,3. Provable Integer Programming,[0],[0]
"xI1 = 1
return v∗ if feasible, else return null
v ← LP(∅, ∅)",3. Provable Integer Programming,[0],[0]
"B ← {(v, ∅, ∅)} while optimal integral vertex not found:
(v, I0, I1)←",3. Provable Integer Programming,[0],[0]
"argmax(v,I0,I1)∈B c T v if v is integral: return v else: find a fractional coordinate i v(0)",3. Provable Integer Programming,[0],[0]
"← LP(I0 ∪ {i}, I1) v(1) ← LP(I0, I1 ∪ {i}) remove (v, I0, I1) from B add (v(0), I0 ∪ {i}, I1) to B if feasible add (v(1), I0, I1 ∪ {i}) to B if feasible
ing vertices.",3. Provable Integer Programming,[0],[0]
This branch-and-bound algorithm has the desirable property that it never creates a new fractional vertex.,3. Provable Integer Programming,[0],[0]
"We note that other branching algorithms, such as the algorithm presented by the authors in (Marinescu & Dechter, 2009), do not immediately allow us to prove our desired theorem.
",3. Provable Integer Programming,[0],[0]
Note that warm starting a linear program with slightly modified constraints allows subsequent calls to an LP solver to be much more efficient after the root LP has been solved.,3. Provable Integer Programming,[0],[0]
"The proof follows from the following invariants:
• At every iteration we remove at least one fractional vertex.
•",3.1. Proof of Theorem 1,[0],[0]
"Every integral vertex is in exactly one branch.
",3.1. Proof of Theorem 1,[0],[0]
•,3.1. Proof of Theorem 1,[0],[0]
"Every fractional vertex is in at most one branch.
",3.1. Proof of Theorem 1,[0],[0]
•,3.1. Proof of Theorem 1,[0],[0]
"No fractional vertices are created by the new constraints.
",3.1. Proof of Theorem 1,[0],[0]
"To see the last invariant, note that every vertex of a polytope can be identified by the set of inequality constraints that are satisfied with equality (see (Bertsimas & Tsitsiklis, 1997)).",3.1. Proof of Theorem 1,[0],[0]
"By forcing an inequality constraint to be tight, we cannot possibly introduce new vertices.",3.1. Proof of Theorem 1,[0],[0]
"As mentioned in the introduction, the algorithm used to prove Theorem 1 does not enumerate all the fractional vertices until it finds an integral vertex.",3.2. The M -Best LP Problem,[0],[0]
"Enumerating the M - best vertices of a linear program is theM -best LP problem.
",3.2. The M -Best LP Problem,[0],[0]
Definition.,3.2. The M -Best LP Problem,[0],[0]
"Given a linear program {min cTx : x ∈ P} over a polytope P and a positive integer M , the M -best LP problem is to optimize
max {v1,...,vM}⊆V (P ) M∑",3.2. The M -Best LP Problem,[0],[0]
"k=1 cT vk.
",3.2. The M -Best LP Problem,[0],[0]
"This was established by (Angulo et al., 2014) to be NP-hard when M = O(n).",3.2. The M -Best LP Problem,[0],[0]
"We strengthen this result to hardness of approximation even when M = nε for any ε > 0.
Theorem 3.",3.2. The M -Best LP Problem,[0],[0]
"It is NP-hard to approximate the M -best LP problem by a factor better than O(n ε
M ) for any fixed ε > 0.
",3.2. The M -Best LP Problem,[0],[0]
Proof.,3.2. The M -Best LP Problem,[0],[0]
"Consider the circulation polytope described in (Khachiyan et al., 2008), with the graph and weight vector w described in (Boros et al., 2011).",3.2. The M -Best LP Problem,[0],[0]
"By adding anO(logM) long series of 2×2 bipartite subgraphs, we can make it such that one long path in the original graph implies M long paths in the new graph, and thus it is NP-hard to find any of these long paths in the new graph.",3.2. The M -Best LP Problem,[0],[0]
"By adding the constraint vector wTx ≤ 0, and using the cost function −w, the vertices corresponding to the short paths have value 1/2, the vertices corresponding to the long paths have value O(1/n), and all other vertices have value 0.",3.2. The M -Best LP Problem,[0],[0]
Thus the optimal set has value O(n+ Mn ).,3.2. The M -Best LP Problem,[0],[0]
"However it is NP-hard to find a set of value greater than O(n) in polynomial time, which gives an O( nM ) approximation.",3.2. The M -Best LP Problem,[0],[0]
"Using a padding argument, we can replace n with nε.
",3.2. The M -Best LP Problem,[0],[0]
"The best known algorithm for the M -best LP problem is a generalization of the facet guessing algorithm (Dimakis et al., 2009) developed in (Angulo et al., 2014), which would require O(mM ) calls to an LP solver, where m is the number of constraints of the LP.",3.2. The M -Best LP Problem,[0],[0]
"Since we only care about integral solutions, we can find the single best integral vertex with O(M) calls to an LP solver, and if we want all of the K-best integral solutions among the top M vertices of the polytope, we can find these with O(nK",3.2. The M -Best LP Problem,[0],[0]
"+M) calls to an LP-solver, as we will see in the next section.
3.3.",3.2. The M -Best LP Problem,[0],[0]
"K-Best Integral Solutions
Finding the K-best solutions to general optimization problems has been uses in several machine learning applications.",3.2. The M -Best LP Problem,[0],[0]
Producing multiple high-value outputs can be naturally combined with post-processing algorithms that select the most desired solution using additional sideinformation.,3.2. The M -Best LP Problem,[0],[0]
"There is a significant volume of work in the general area, see (Fromer & Globerson, 2009; Batra et al., 2012) for MAP solutions in graphical models and (Eppstein, 2014) for a survey on M -best problems.
",3.2. The M -Best LP Problem,[0],[0]
We further generalize our theorem to find the K-best integral solutions.,3.2. The M -Best LP Problem,[0],[0]
Theorem 4.,3.2. The M -Best LP Problem,[0],[0]
"Under the assumption that there are less than M fractional vertices with objective value at least as good as the K-best integral solutions, we can find all of the Kbest integral solutions, O(nK",3.2. The M -Best LP Problem,[0],[0]
"+M) calls to an LP solver.
",3.2. The M -Best LP Problem,[0],[0]
The algorithm used in this theorem is Algorithm 2.,3.2. The M -Best LP Problem,[0],[0]
"It combines Algorithm 1 with the space partitioning technique used in (Murty, 1968; Lawler, 1972).",3.2. The M -Best LP Problem,[0],[0]
"If the current optimal solution in the solution tree is fractional, then we use the branching technique in Algorithm 1.",3.2. The M -Best LP Problem,[0],[0]
"If the current optimal solution in the solution tree x∗ is integral, then we branch by creating a new leaf for every i not currently constrained by the parent with the constraint",3.2. The M -Best LP Problem,[0],[0]
xi = ¬x∗i .,3.2. The M -Best LP Problem,[0],[0]
"We now describe the fractional vertices of the local polytope for binary, pairwise graphical models, which is described in Equation 3.",4. Fractional Vertices of the Local Polytope,[0],[0]
"It was shown in (Padberg, 1989) that all the vertices of this polytope are half-integral, that is, all coordinates have a value from {0, 12 , 1} (see (Weller et al., 2016) for a new proof of this).
",4. Fractional Vertices of the Local Polytope,[0],[0]
"Given a half-integral point q ∈ {0, 12 , 1} V ∪E in the local polytope, we say that a cycle C = (VC , EC) ⊆ G is frustrated if there is an odd number of edges ij ∈ EC such that qij = 0.",4. Fractional Vertices of the Local Polytope,[0],[0]
"If a point q has a frustrated cycle, then it is a pseudomarginal, as no probability distribution exists that has as its singleton and pairwise marginals the coordinates of q. Half-integral points q with a frustrated cycle do not satisfy the cycle inequalities (Sontag & Jaakkola, 2007; Wainwright et al., 2008), for all cycles C = (VC , EC), F = (VF , EF ) ⊆ C, |EF",4. Fractional Vertices of the Local Polytope,[0],[0]
| odd we must have∑ ij∈EF qi+qj−2qij− ∑ ij∈EC\EF qi+qj−2qij ≤ |FC |−1.,4. Fractional Vertices of the Local Polytope,[0],[0]
"(4)
Frustrated cycles allow a solution to be zero on negative weights in a way that is not possible for any integral solution.
",4. Fractional Vertices of the Local Polytope,[0],[0]
"We have the following theorem describing all the vertices of the local polytope for binary, pairwise graphical models.
",4. Fractional Vertices of the Local Polytope,[0],[0]
Algorithm 2 M -best Integral Input: an LP {max cTx :,4. Fractional Vertices of the Local Polytope,[0],[0]
"Ax ≤ b, 0 ≤ x ≤ 1} Input: number of solutions K
def LP(I0, I1): same as Algorithm 1
def SplitIntegral(v, I0, I1): P ← { } for i ∈",4. Fractional Vertices of the Local Polytope,[0],[0]
[n] if i /∈,4. Fractional Vertices of the Local Polytope,[0],[0]
"I0 ∪ I1: a← ¬vi I ′0, I ′",4. Fractional Vertices of the Local Polytope,[0],[0]
"1 ← copy(I0, I1)
add i to I ′a v′",4. Fractional Vertices of the Local Polytope,[0],[0]
"← LP(I ′0, I ′1) add (v′, I ′0, I ′ a) to P if feasible
return P
v ← LP(∅, ∅)",4. Fractional Vertices of the Local Polytope,[0],[0]
"B ← {(v, ∅, ∅)} results← { } while K integral vertices not found: (v, I0, I1)←",4. Fractional Vertices of the Local Polytope,[0],[0]
"argmax(v,I0,I1)∈B c
T v if v is integral:
add v to results add SplitIntegeral(v, I0, I1) to B remove (v, I0, I1) from B
else: find a fractional coordinate i v(0)",4. Fractional Vertices of the Local Polytope,[0],[0]
"← LP(I0 ∪ {i}, I1) v(1) ← LP(I0, I1 ∪ {i}) remove (v, I0, I1) from B add (v(0), I0 ∪ {i}, I1) to B if feasible add (v(1), I0, I1 ∪ {i}) to B if feasible
return results
Theorem 5.",4. Fractional Vertices of the Local Polytope,[0],[0]
"Given a point q in the local polytope, q is a vertex of this polytope if and only if q ∈ {0, 12 , 1}
V ∪E and the induced subgraph on the fractional nodes of q is such that every connected component of this subgraph contains a frustrated cycle.",4. Fractional Vertices of the Local Polytope,[0],[0]
"Every vertex q of an n-dimensional polytope is such that there are n constraints such that q satisfies them with equality, known as active constraints (see (Bertsimas & Tsitsiklis, 1997)).",4.1. Proof of Theorem 5,[0],[0]
Every integral q is thus a vertex of the local polytope.,4.1. Proof of Theorem 5,[0],[0]
"We now describe the fractional vertices of the local polytope.
Definition.",4.1. Proof of Theorem 5,[0],[0]
"Let q ∈ {0, 12 , 1} n+m be a point of the local polytope.",4.1. Proof of Theorem 5,[0],[0]
"Let GF = (VF , EF ) be an induced subgraph of points such that qi = 12 for all i ∈ VF .",4.1. Proof of Theorem 5,[0],[0]
"We say that GF is
full rank if the following system of equations is full rank.
",4.1. Proof of Theorem 5,[0],[0]
qi + qj,4.1. Proof of Theorem 5,[0],[0]
− qij = 1 ∀ij ∈ EF such that qij = 0 qij = 0,4.1. Proof of Theorem 5,[0],[0]
"∀ij ∈ EF such that qij = 0
qi",4.1. Proof of Theorem 5,[0],[0]
"− qij = 0 ∀ij ∈ EF such that qij = 1
2
qj",4.1. Proof of Theorem 5,[0],[0]
"− qij = 0 ∀ij ∈ EF such that qij = 1
2
(5)
Theorem 5 follows from the following lemmas.
",4.1. Proof of Theorem 5,[0],[0]
Lemma 6.,4.1. Proof of Theorem 5,[0],[0]
"Let q ∈ {0, 12 , 1} n+m be a point of the local polytope.",4.1. Proof of Theorem 5,[0],[0]
"Let GF = (VF , EF ) be the subgraph induced by the nodes i ∈ V such that qi = 12 .",4.1. Proof of Theorem 5,[0],[0]
"The point q is a vertex if and only if every connected component of GF is full rank.
",4.1. Proof of Theorem 5,[0],[0]
Lemma 7.,4.1. Proof of Theorem 5,[0],[0]
"Let q ∈ {0, 12 , 1} n+m be a point of the local polytope.",4.1. Proof of Theorem 5,[0],[0]
"Let GF = (VF , EF ) be a connected subgraph induced from nodes such that such that qi = 12 for all i ∈ VF .",4.1. Proof of Theorem 5,[0],[0]
"GF is full rank if and only if GF contains cycle that is full rank.
",4.1. Proof of Theorem 5,[0],[0]
Lemma 8.,4.1. Proof of Theorem 5,[0],[0]
"Let q ∈ {0, 12 , 1} n+m be a point of the local polytope.",4.1. Proof of Theorem 5,[0],[0]
"Let C = (VC , EC) be a cycle of G such that qi is fractional for all i ∈ VC .",4.1. Proof of Theorem 5,[0],[0]
"C is full rank if and only if C is a frustrated cycle.
",4.1. Proof of Theorem 5,[0],[0]
Proof of Lemma 6.,4.1. Proof of Theorem 5,[0],[0]
Suppose every connected component is full rank.,4.1. Proof of Theorem 5,[0],[0]
Then every fractional node and edge between fractional nodes is fully specified by their corresponding equations in Problem 3.,4.1. Proof of Theorem 5,[0],[0]
"It is easy to check that all integral nodes, edges between integral nodes, and edges between integral and fractional nodes is also fixed.",4.1. Proof of Theorem 5,[0],[0]
"Thus q is a vertex.
",4.1. Proof of Theorem 5,[0],[0]
Now suppose that there exists a connected component that is not full rank.,4.1. Proof of Theorem 5,[0],[0]
The only other constraints involving this connected component are those between fractional nodes and integral nodes.,4.1. Proof of Theorem 5,[0],[0]
"However, note that these constraints are always rank 1, and also introduce a new edge variable.",4.1. Proof of Theorem 5,[0],[0]
"Thus all the constraints where q is tight do not make a full rank system of equations.
",4.1. Proof of Theorem 5,[0],[0]
Proof of Lemma 7.,4.1. Proof of Theorem 5,[0],[0]
Suppose GF has a full rank cycle.,4.1. Proof of Theorem 5,[0],[0]
We will build the graph starting with the full rank cycle then adding one connected edge at a time.,4.1. Proof of Theorem 5,[0],[0]
"It is easy to see from Equations 5 that all new variables introduced to the system of equations have a fixed value, and thus the whole connected component is full rank.
",4.1. Proof of Theorem 5,[0],[0]
Now suppose GF has no full rank cycle.,4.1. Proof of Theorem 5,[0],[0]
We will again build the graph starting from the cycle then adding one connected edge at a time.,4.1. Proof of Theorem 5,[0],[0]
"If we add an edge that connects to a new node, then we added two variables and two equations, thus we did not make the graph full rank.",4.1. Proof of Theorem 5,[0],[0]
"If we add an edge between two existing nodes, then we have a cycle involving this edge.",4.1. Proof of Theorem 5,[0],[0]
"We introduce two new equations, however with
one of the equations and the other cycle equations, we can produce the other equation, thus we can increase the rank by one but we also introduced a new edge.",4.1. Proof of Theorem 5,[0],[0]
"Thus the whole graph cannot be full rank.
",4.1. Proof of Theorem 5,[0],[0]
"The proof of Lemma 8 from the following lemma.
",4.1. Proof of Theorem 5,[0],[0]
Lemma 9.,4.1. Proof of Theorem 5,[0],[0]
"Consider a collection of n vectors
v1 = (1, t1, 0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0)
",4.1. Proof of Theorem 5,[0],[0]
"v2 = (0, 1, t2, 0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0)
",4.1. Proof of Theorem 5,[0],[0]
"v3 = (0, 0, 1, t3, 0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0)
...
",4.1. Proof of Theorem 5,[0],[0]
"vn−1 = (0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0, 1, tn−1)
vn = (tn, 0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0, 1)
",4.1. Proof of Theorem 5,[0],[0]
"for ti ∈ {−1, 1}.",4.1. Proof of Theorem 5,[0],[0]
"We have rank(v1, v2, . . .",4.1. Proof of Theorem 5,[0],[0]
", vn) = n",4.1. Proof of Theorem 5,[0],[0]
"if and only if there is an odd number of vectors such that ti = 1.
",4.1. Proof of Theorem 5,[0],[0]
Proof of Lemma 9.,4.1. Proof of Theorem 5,[0],[0]
Let k be the number of vectors such that ti = 1.,4.1. Proof of Theorem 5,[0],[0]
"Let S1 = v1 and define
Si+1 = { Si − vi+1",4.1. Proof of Theorem 5,[0],[0]
"if Si(i+ 1) = 1 Si + vi+1 if Si(i+ 1) = −1
for i = 2, . .",4.1. Proof of Theorem 5,[0],[0]
.,4.1. Proof of Theorem 5,[0],[0]
", n− 1.
Note that if ti+1 = −1 then Si+1(i+2) = Si(i+1) and if ti+1 = 1 then Si+1(i+2) = −Si(i+1).",4.1. Proof of Theorem 5,[0],[0]
"Thus the number of times the sign changes is exactly the number of ti = 1 for i ∈ {2, . . .",4.1. Proof of Theorem 5,[0],[0]
", n− 1}.
",4.1. Proof of Theorem 5,[0],[0]
"Using the value of Sn−1 we can now we can check for all values of t1 and tn that the following is true.
",4.1. Proof of Theorem 5,[0],[0]
"• If k is odd then (1, 0, . . .",4.1. Proof of Theorem 5,[0],[0]
", 0) ∈ span(v1, v2, . . .",4.1. Proof of Theorem 5,[0],[0]
", vn), which allows us to create the entire standard basis, showing the vectors are full rank.
",4.1. Proof of Theorem 5,[0],[0]
"• If k is even then vn ∈ span(v1, v2, . . .",4.1. Proof of Theorem 5,[0],[0]
", vn−1) and thus the vectors are not full rank.",4.1. Proof of Theorem 5,[0],[0]
For this section we generalize generalize Theorem 1.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
We see after every iteration we potentially remove more than one confounding vertex—we remove all confounding vertices that agree with xI0 = 0 and xI1,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
= 1 and are fractional with any value at coordinate i.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"We also observe that we can
handle a mixed integer program (MIP) with the same algorithm.
",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"max x
cTx+ dT",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"z
subject to Ax+Bz ≤ b x ∈ {0, 1}n
",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"We will call a vertex (x, z) fractional if its x component is fractional.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"For each fractional vertex (x, z), we create a half-integral vector S(x) such that
S(x)i =  0",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"if xi = 0 1 2 if xi is fractional 1 if xi = 1
For a set of vertices V , we define S(V ) to be the set {S(x) : (x, z) ∈ V }, i.e. we remove all duplicate entries.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
Theorem 10.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"Let (x∗, z∗) be the optimal integral solution and let VC be the set of confounding vertices.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"Algorithm 1 will find the optimal integral solution (x∗, z∗) after 2|S(VC)| calls to an LP solver.
",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"For MAP inference in graphical models, S(VC) refers to the fractional singleton marginals qV such that there exists a set of pairwise pseudomarginals qE such that (qV , qE) is a cofounding vertex.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
In this case we call qV a confounding singleton marginal.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
We develop Algorithm 3 to estimate the number of confounding singleton marginals for our experiments section.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"It is based on the k-best enumeration method developed in (Murty, 1968; Lawler, 1972).
",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
Algorithm 3 works by a branching argument.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
The root node is the original LP.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"A leaf node is branched on by introducing a new leaf for every node in V and every element of {0, 12 , 1} such that qi 6=",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
a in the parent node and the constraint {qi = a} is not in the constraints for the parent node.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"For i ∈ V , a ∈ {0, 12 , 1}, we create the leaf such that it has all the constraints of its parents plus the constraint qi = a.
Note that Algorithm 3 actually generates a superset of the elements of S(VC), since the introduction of constraints of the type qi = 12 introduce vertices into the new polytope that were not in the original polytope.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"This does not seem to be an issue for the experiments we consider, however this does occur for other graphs.",5. Estimating the number of Confounding Singleton Marginals,[0],[0]
An interesting question is if the vertices of the local polytope can be provably enumerated.,5. Estimating the number of Confounding Singleton Marginals,[0],[0]
"We consider a synthetic experiment on randomly created graphical models, which were also used in (Sontag & Jaakkola, 2007; Weller, 2016; Weller et al., 2014).",6. Experiments,[0],[0]
The graph topology used is the complete graph on 12 nodes.,6. Experiments,[0],[0]
"We first reparametrize the model to use the sufficient statistics
Algorithm 3 Estimate S(VC) for Binary, Pairwise Graphical Models
Input: a binary, pairwise graphical model LP
# branch (v, I0, I 1 2 , I1) means v is optimal LP # with xI0 = 0, xI 1 2 = 12 , and xI1 = 1.",6. Experiments,[0],[0]
"def LP(I0, I 1 2 , I1):
optimize LP with additional constraints: xI0 = 0 xI 1
2 = 12 xI1 = 1
return q∗ if feasible, else return null
q ← LP(∅, ∅, ∅)",6. Experiments,[0],[0]
"B ← {(q, ∅, ∅, ∅)}",6. Experiments,[0],[0]
"solution← { } while optimal integral vertex not found: (q, I0, I 1
2 , I1)←",6. Experiments,[0],[0]
"argmax(q,I0,I 1 2 ,I1)∈B objective val
add q to solution remove (q, I0, I 1
2 , I1) from B
for i ∈ V if i /∈",6. Experiments,[0],[0]
"I0 ∪ I 1 2 ∪ I1:
for a ∈ {0, 12 , 1} if qi 6=",6. Experiments,[0],[0]
"a: I ′0, I
′ 1 2 , I ′1 ← copy(I0, I 12 , I1)",6. Experiments,[0],[0]
I ′a ←,6. Experiments,[0],[0]
I ′a ∪ {i} q′,6. Experiments,[0],[0]
"← LP(I ′0, I ′1
2
, I ′1)
add (q′, I ′0, I ′ 1 2 , I ′1) to B if feasible return solution
1(xi = xj) and 1(xi = 1).",6. Experiments,[0],[0]
"The node weights are drawn θi ∼ Uniform(−1, 1) and the edge weights are drawn Wij ∼ Uniform(−w,w) for varying w.",6. Experiments,[0],[0]
The quantity w determines how strong the connections are between nodes.,6. Experiments,[0],[0]
"We do 100 draws for each choice of edge strength w.
For the complete graph, we observe that Algorithm 3 does not yield any points that do not correspond to vertices, however this does occur for other topologies.
",6. Experiments,[0],[0]
We first compare how the number of fractional singleton marginals |S(VC)| changes with the connection strengthw.,6. Experiments,[0],[0]
"In Figure 1, we plot the sample CDF of the probability that |S(VC)| is some given value.",6. Experiments,[0],[0]
We observe that |S(VC)| increases as the connection strength increases.,6. Experiments,[0],[0]
"Further we see that while most instances have a small number for |S(VC)|, there are rare instances where |S(VC)| is quite large.
",6. Experiments,[0],[0]
Now we compare how the number of cycle constraints from Equation (4) that need to be introduced to find the best integral solution changes with the number of confounding singleton marginals in Figure 2.,6. Experiments,[0],[0]
"We use the algorithm for finding the most frustrated cycle in (Sontag & Jaakkola, 2007) to introduce new constraints.",6. Experiments,[0],[0]
"We observe that each constraint seems to remove many confounding singleton
marginals.
",6. Experiments,[0],[0]
"We also observe the number of introduced confounding singleton marginals that are introduced by the cycle constraints increases with the number of confounding singleton marginals in Figure 3.
",6. Experiments,[0],[0]
Finally we compare the number of branches needed to find the optimal solution increases with the number of confounding singleton marginals in Figure 4.,6. Experiments,[0],[0]
A similar trend arises as with the number of cycle inequalities introduced.,6. Experiments,[0],[0]
"To compare the methods, note that branch-and-bound uses twice as many LP calls as there are branches.",6. Experiments,[0],[0]
"For this family of graphical models, branch-and-bound tends to require less calls to an LP solver than the cut constraints.",6. Experiments,[0],[0]
"Perhaps the most interesting follow-up question to our work is to determine when, in theory and practice, our condition on the number of confounding pseudomarginals in the LP relaxation is small.",7. Conclusion,[0],[0]
Another interesting question is to see if it is possible to prune the number of confounding pseudomarginals at a faster rate.,7. Conclusion,[0],[0]
The algorithm presented for our main theorem removes one pseudomarginal after two calls to an LP solver.,7. Conclusion,[0],[0]
Is it possible to do this at a faster rate?,7. Conclusion,[0],[0]
"From our experiments, this seems to be the case in practice.",7. Conclusion,[0],[0]
"This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1110007 as well as NSF Grants CCF 1344364, 1407278, 1422549, 1618689, 1018829 and ARO YIP W911NF-14-1-0258.",Acknowledgements,[0],[0]
"Given a graphical model, one essential problem is MAP inference, that is, finding the most likely configuration of states according to the model.",abstractText,[0],[0]
"Although this problem is NP-hard, large instances can be solved in practice and it is a major open question is to explain why this is true.",abstractText,[0],[0]
We give a natural condition under which we can provably perform MAP inference in polynomial time—we require that the number of fractional vertices in the LP relaxation exceeding the optimal solution is bounded by a polynomial in the problem size.,abstractText,[0],[0]
"This resolves an open question by Dimakis, Gohari, and Wainwright.",abstractText,[0],[0]
"In contrast, for general LP relaxations of integer programs, known techniques can only handle a constant number of fractional vertices whose value exceeds the optimal solution.",abstractText,[0],[0]
We experimentally verify this condition and demonstrate how efficient various integer programming methods are at removing fractional solutions.,abstractText,[0],[0]
Exact MAP Inference by Avoiding Fractional Vertices,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 694–699 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
694
Many corpora span broad periods of time. Language processing models trained during one time period may not work well in future time periods, and the best model may depend on specific times of year (e.g., people might describe hotels differently in reviews during the winter versus the summer). This study investigates how document classifiers trained on documents from certain time intervals perform on documents from other time intervals, considering both seasonal intervals (intervals that repeat across years, e.g., winter) and non-seasonal intervals (e.g., specific years). We show experimentally that classification performance varies over time, and that performance can be improved by using a standard domain adaptation approach to adjust for changes in time.",text,[0],[0]
"Language, and therefore data derived from language, changes over time (Ullmann, 1962).",1 Introduction,[0],[0]
"Word senses can shift over long periods of time (Wilkins, 1993; Wijaya and Yeniterzi, 2011; Hamilton et al., 2016), and written language can change rapidly in online platforms (Eisenstein et al., 2014; Goel et al., 2016).",1 Introduction,[0],[0]
"However, little is known about how shifts in text over time affect the performance of language processing systems.
",1 Introduction,[0],[0]
"This paper focuses on a standard text processing task, document classification, to provide insight into how classification performance varies with time.",1 Introduction,[0],[0]
We consider both long-term variations in text over time and seasonal variations which change throughout a year but repeat across years.,1 Introduction,[0],[0]
"Our empirical study considers corpora contain-
ing formal text spanning decades as well as usergenerated content spanning only a few years.
",1 Introduction,[0],[0]
"After describing the datasets and experiment design, this paper has two main sections, respectively addressing the following research questions:
1.",1 Introduction,[0],[0]
"In what ways does document classification depend on the timestamps of the documents?
2.",1 Introduction,[0],[0]
"Can document classifiers be adapted to perform better in time-varying corpora?
",1 Introduction,[0],[0]
"To address question 1, we train and test on data from different time periods, to understand how performance varies with time.",1 Introduction,[0],[0]
"To address question 2, we apply a domain adaptation approach, treating time intervals as domains.",1 Introduction,[0],[0]
"We show that in most cases this approach can lead to improvements in classification performance, even on future time intervals.",1 Introduction,[0],[0]
"Time is implicitly embedded in the classification process: classifiers are often built to be applied to future data that doesn’t yet exist, and performance on held-out data is measured to estimate performance on future data whose distribution may have changed.",1.1 Related Work,[0],[0]
"Methods exist to adjust for changes in the data distribution (covariate shift) (Shimodaira, 2000; Bickel et al., 2009), but time is not typically incorporated into such methods explicitly.
",1.1 Related Work,[0],[0]
"One line of work that explicitly studies the relationship between time and the distribution of data is work on classifying the time period in which a document was written (document dating) (Kanhabua and Nørvåg, 2008; Chambers, 2012; Kotsakos et al., 2014).",1.1 Related Work,[0],[0]
"However, this task is directed differently from our work: predicting timestamps given documents, rather than predicting information about documents given timestamps.",1.1 Related Work,[0],[0]
"Our study experiments with six corpora:
• Reviews: Three corpora containing reviews labeled with sentiment: music reviews from Amazon (He and McAuley, 2016), and hotel reviews and restaurant reviews from Yelp.1 We discarded reviews that had fewer than 10 tokens or a helpfulness/usefulness score of zero.",2 Datasets and Experimental Setup,[0],[0]
"The reviews with neutral scores were removed.
",2 Datasets and Experimental Setup,[0],[0]
"• Politics: Sentences from the American party platforms of Republicans and Democrats from 1948 to 2016, available every four years.2
• News: Newspaper articles from 1950-2014, labeled with whether the article is relevant to the US economy.3
• Twitter: Tweets labeled with whether they indicate that the user received an influenza vaccination (i.e., a flu shot) (Huang et al., 2017).
",2 Datasets and Experimental Setup,[0],[0]
Our experiments require documents to be grouped into time intervals.,2 Datasets and Experimental Setup,[0],[0]
Table 1 shows the intervals for each corpus.,2 Datasets and Experimental Setup,[0],[0]
Documents that fall outside of these time intervals were removed.,2 Datasets and Experimental Setup,[0],[0]
"We grouped documents into two types of intervals:
• Seasonal: Time intervals within a year (e.g., January through March) that may be repeated across years.
",2 Datasets and Experimental Setup,[0],[0]
"• Non-seasonal: Time intervals that do not repeat (e.g., 1997-1999).
",2 Datasets and Experimental Setup,[0],[0]
"For each dataset, we performed binary classification, implemented in sklearn (Pedregosa et al., 2011).",2 Datasets and Experimental Setup,[0],[0]
"We built logistic regression classifiers with TF-IDF weighted n-gram features (n ∈ {1, 2, 3}), removing features that appeared in less than 2 documents.",2 Datasets and Experimental Setup,[0],[0]
"Except when otherwise specified, we held out a random 10% of documents as
1https://www.yelp.com/dataset 2https://www.comparativeagendas.net/
datasets_codebooks 3https://www.crowdflower.com/ data-for-everyone/
validation data for each dataset.",2 Datasets and Experimental Setup,[0],[0]
"We used Elastic Net (combined `1 and `2) regularization (Zou and Hastie, 2005), and tuned the regularization parameters to maximize performance on the validation data.",2 Datasets and Experimental Setup,[0],[0]
We evaluated the performance using weighted F1 scores.,2 Datasets and Experimental Setup,[0],[0]
We first conduct an analysis of how classifier performance depends on the time intervals in which it is trained and applied.,3 How Does Classification Performance Vary with Time?,[0],[0]
"For each corpus, we train the classifier on each time interval and test on each time interval.",3 How Does Classification Performance Vary with Time?,[0],[0]
"We downsampled the training data within each time interval to match the number of documents in the smallest interval, so that differences in performance are not due to the size of the training data.
",3 How Does Classification Performance Vary with Time?,[0],[0]
"In all experiments, we train a classifier on a partition of 80% of the documents in the time interval, and repeat this five times on different partitions, averaging the five F1 scores to produce the final estimate.",3 How Does Classification Performance Vary with Time?,[0],[0]
"When training and testing on the same interval, we test on the held-out 20% of documents in that interval (standard cross-validation).",3 How Does Classification Performance Vary with Time?,[0],[0]
"When testing on different time intervals, we test on all documents, since they are all held-out from the training interval; however, we still train on five subsets of 80% of documents, so that the training data is identical across all experiments.
",3 How Does Classification Performance Vary with Time?,[0],[0]
"Finally, to understand why performance varies, we also qualitatively examined how the distribution of content changes across time intervals.",3 How Does Classification Performance Vary with Time?,[0],[0]
"To measure the distribution of content, we trained a topic model with 20 topics using gensim (Řehůřek and Sojka, 2010) with default parameters.",3 How Does Classification Performance Vary with Time?,[0],[0]
"We associated each document with one topic (the most probable topic in the document), and then calculated the proportion of each topic within a time period as the proportion of documents in that time period assigned to that topic.",3 How Does Classification Performance Vary with Time?,[0],[0]
"We can then visualize the extent to which the distribution of 20 topics varies by time.
",3 How Does Classification Performance Vary with Time?,[0],[0]
Jan-M ar Apr-Ju n,3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-Se p Oct-D ec
Train
JanMar",3 How Does Classification Performance Vary with Time?,[0],[0]
Apr -Jun,3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-S ep
Oct -De
c
Te st
0.948 0.912 0.913 0.910
0.916 0.949 0.914 0.909
0.916 0.912 0.952 0.910
0.916 0.914 0.918 0.945
Reviews data - music
Jan-M ar Apr-Ju n",3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-Se p Oct-D ec
Train
JanMar",3 How Does Classification Performance Vary with Time?,[0],[0]
Apr -Jun,3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-S ep
Oct -De
c
Te st
0.865 0.862 0.862 0.861
0.863 0.862 0.861 0.858
0.862 0.859 0.866 0.861
0.863 0.863 0.863 0.858
Reviews data - hotels
Jan-M ar Apr-Ju n",3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-Se p Oct-D ec
Train
JanMar",3 How Does Classification Performance Vary with Time?,[0],[0]
Apr -Jun,3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-S ep
Oct -De
c
Te st
0.898 0.806 0.750 0.769
0.795 0.876 0.745 0.787
0.794 0.795 0.900 0.767
0.791 0.790 0.731 0.891
News data - economy
Jan-M ar Apr-Ju n",3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-Se p Oct-D ec
Train
JanMar",3 How Does Classification Performance Vary with Time?,[0],[0]
Apr -Jun,3 How Does Classification Performance Vary with Time?,[0],[0]
"Jul-S ep
Oct -De
c
Te st
0.896 0.894 0.891 0.856
0.808 0.940 0.853 0.829
0.836 0.904 0.917 0.845
0.849 0.891 0.884 0.902
Twitter data - vaccine
2006 -08 2009 -11 2012 -14 2015 -17
Train
200 6-08 200 9-11 201 2-14 201 5-17 Te st
0.823 0.828 0.825 0.859
0.799 0.843 0.830 0.858
0.800 0.819 0.833 0.869
0.790 0.813 0.835 0.880
Reviews data - hotels
2006 -08 2009 -11 2012 -14 2015 -17
Train
200 6-08 200 9-11 201 2-14 201 5-17 Te st
0.829 0.838 0.869 0.883
0.814 0.856 0.870 0.883
0.815 0.842 0.884 0.894
0.814 0.839 0.875 0.902
Reviews data - restaurants
1948 -56 1960 -68 1972 -80 1984 -92",3 How Does Classification Performance Vary with Time?,[0],[0]
"1996 -20042008 -16
",3 How Does Classification Performance Vary with Time?,[0],[0]
"Train
194 8-56 196 0-68 197 2-80 198 4-92
199 6-20
04 200 8-16
Te st
0.659 0.567 0.518 0.544 0.525 0.532 0.551 0.800 0.529 0.477 0.474 0.495 0.545 0.506 0.678 0.635 0.573 0.523 0.515 0.473 0.565 0.866 0.594 0.569 0.435 0.404 0.490 0.618 0.848 0.684 0.435 0.416 0.480 0.606 0.674 0.819
Politics - US political data
1985 -89 1990 -94 1995 -99 2000 -04 2005 -09 2010 -14
",3 How Does Classification Performance Vary with Time?,[0],[0]
"Train
198 5-89 199 0-94 199 5-99 200 0-04 200 5-09 201 0-14",3 How Does Classification Performance Vary with Time?,[0],[0]
"Te st
0.876 0.758 0.783 0.794 0.777 0.756 0.764 0.883 0.771 0.802 0.789 0.748 0.759 0.760 0.905 0.798 0.806 0.763 0.760 0.756 0.770 0.926 0.805 0.771 0.773 0.767 0.783 0.826 0.900 0.778 0.773 0.750 0.778 0.810 0.786 0.897
News data - economy
Figure 1: Document classification performance when training and testing on different times of year (top) and different years (bottom).",3 How Does Classification Performance Vary with Time?,[0],[0]
Some corpora are omitted for space.,3 How Does Classification Performance Vary with Time?,[0],[0]
The top row of Figure 1 shows the test scores from training and testing on each pair of seasonal time intervals for four of the datasets.,3.1 Seasonal Variability,[0],[0]
"We observe very strong seasonal variations in the economic news corpus, with a drop in F1 score on the order of 10 when there is a mismatch in the season between training and testing.",3.1 Seasonal Variability,[0],[0]
"There is a similar, but weaker, effect on performance in the music reviews from Amazon and the vaccine tweets.",3.1 Seasonal Variability,[0],[0]
"There was virtually no difference in performance in any of the pairs in both review corpora from Yelp (restaurants, not pictured, and hotels).
",3.1 Seasonal Variability,[0],[0]
"To help understand why the performance varies, Figure 2 (left) shows the distribution of topics in each seasonal interval for two corpora: Amazon music reviews and Twitter.",3.1 Seasonal Variability,[0],[0]
"We observe very little variation in the topic distribution across seasons in the Amazon corpus, but some variation in the Twitter corpus, which may explain the large performance differences when testing on held-out seasons in the Twitter data as compared to the Amazon corpus.
",3.1 Seasonal Variability,[0],[0]
"For space, we do not show the descriptions of the topics, but instead only the shape of the distributions to show the degree of variability.",3.1 Seasonal Variability,[0],[0]
"We did qualitatively examine the differences in word features across the time periods, but had difficulty interpreting the observations and were unable to draw clear conclusions.",3.1 Seasonal Variability,[0],[0]
"Thus, characterizing the ways in which content distributions vary over time, and why this affects performance, is still an open question.",3.1 Seasonal Variability,[0],[0]
The bottom row of Figure 1 shows the test scores from training and testing on each pair of nonseasonal time intervals.,3.2 Non-seasonal Variability,[0],[0]
A strong pattern emerges in the political parties corpus: F1 scores can drop by as much as 40 points when testing on different time intervals.,3.2 Non-seasonal Variability,[0],[0]
"This is perhaps unsurprising, as this collection spans decades, and US party positions have substantially changed over time.",3.2 Non-seasonal Variability,[0],[0]
"The performance declines more when testing on time intervals that are further away in time from the training interval, suggesting that changes in party platforms shift gradually over time.",3.2 Non-seasonal Variability,[0],[0]
"In contrast, while there was a performance drop when testing outside the training interval in the economic news corpus, the drop was not gradual.",3.2 Non-seasonal Variability,[0],[0]
"In the Twitter dataset (not pictured), F1 dropped by an average of 4.9 points outside the training interval.
",3.2 Non-seasonal Variability,[0],[0]
"We observe an intriguing non-seasonal pattern that is consistent in both of the review corpora from Yelp, but not in the music review corpus from Amazon (not pictured), which is that the classification performance fairly consistently increases over time.",3.2 Non-seasonal Variability,[0],[0]
"Since we sampled the dataset so that the time intervals have the same number of reviews, this suggests something else changed over time about the way reviews are written that makes the sentiment easier to detect.
",3.2 Non-seasonal Variability,[0],[0]
The right side of Figure 2 shows the topic distribution in the Amazon and Twitter datasets across non-seasonal intervals.,3.2 Non-seasonal Variability,[0],[0]
We observe higher levels of variability across time in the non-seasonal intervals as compared to the seasonal intervals.,3.2 Non-seasonal Variability,[0],[0]
"Overall, it is clear that classifiers generally perform best when applied to the same time interval they were trained.",3.3 Discussion,[0],[0]
"Performance diminishes when applied to different time intervals, although different corpora exhibit differ patterns in the way in which the performance diminishes.",3.3 Discussion,[0],[0]
This kind of analysis can be applied to any corpus and could provide insights into characteristics of the corpus that may be helpful when designing a classifier.,3.3 Discussion,[0],[0]
We now consider how to improve classifiers when working with datasets that span different time intervals.,4 Making Classification Robust to Temporality,[0],[0]
We propose to treat this as a domain adaptation problem.,4 Making Classification Robust to Temporality,[0],[0]
"In domain adaptation, any partition of data that is expected to have a different distribution of features can be treated as a domain (Joshi et al., 2013).",4 Making Classification Robust to Temporality,[0],[0]
"Traditionally, domain adaptation is used to adapt models to a common task across rather different sets of data, e.g., a sentiment classifier for different types of products (Blitzer et al., 2007).",4 Making Classification Robust to Temporality,[0],[0]
"Recent work has also applied domain adaptation to adjust for potentially more subtle differences in data, such as adapting for differences in the demographics of authors (Volkova et al., 2013; Lynn et al., 2017).",4 Making Classification Robust to Temporality,[0],[0]
"We follow the same approach, treating time intervals as domains.
",4 Making Classification Robust to Temporality,[0],[0]
"In our experiments, we use the feature augmentation approach of Daumé III (2007) to perform domain adaptation.",4 Making Classification Robust to Temporality,[0],[0]
"Each feature is duplicated to have a specific version of the feature for every domain, as well as a domain-independent version of the feature.",4 Making Classification Robust to Temporality,[0],[0]
"In each instance, the domainindependent feature and the domain-specific feature for that instance’s domain have the same feature value, while the value is zeroed out for the domain-specific features for the other domains.
",4 Making Classification Robust to Temporality,[0],[0]
"This is equivalent to a model where the feature weights are domain specific but share a Gaussian prior across domains (Finkel and Manning, 2009).",4 Making Classification Robust to Temporality,[0],[0]
"This approach is widely used due to its simplicity, and derivatives of this approach have been used in similar work (e.g., (Lynn et al., 2017)).",4 Making Classification Robust to Temporality,[0],[0]
"Following Finkel and Manning (2009), we separately adjust the regularization strength for the domain-independent feature weights and the domain-specific feature weights.",4 Making Classification Robust to Temporality,[0],[0]
"We first examine classification performance on the datasets when grouping the seasonal time intervals (January-March, April-June, July-August, September-December) as domains and applying the feature augmentation approach for domain adaptation.",4.1 Seasonal Adaptation,[0],[0]
"As a baseline comparison, we apply the same classifier, but without domain adaptation.
",4.1 Seasonal Adaptation,[0],[0]
Results are shown in Table 2.,4.1 Seasonal Adaptation,[0],[0]
"We see that applying domain adaptation provides a small boost in three of the datasets, and has no effect on two of the datasets.",4.1 Seasonal Adaptation,[0],[0]
"If this pattern holds in other corpora, then this suggests that it does not hurt performance to apply domain adaptation across different times of year, and in some cases can lead to a small performance boost.",4.1 Seasonal Adaptation,[0],[0]
We now consider the non-seasonal time intervals (spans of years).,4.2 Non-seasonal Adaptation,[0],[0]
"In particular, we consider the scenario when one wants to apply a classifier trained on older data to future data.",4.2 Non-seasonal Adaptation,[0],[0]
"This requires a modification to the domain adaptation approach, because future data includes domains that did not exist in the training data, and thus we cannot learn domain-specific feature weights.",4.2 Non-seasonal Adaptation,[0],[0]
"To solve this, we train in the usual way, but when testing on future data, we only include the domain-independent features.",4.2 Non-seasonal Adaptation,[0],[0]
"The intuition is that the domain-independent parameters should be applicable to all domains, and so using only these features should lead to better generalizability to new domains.",4.2 Non-seasonal Adaptation,[0],[0]
"We test this hypothesis by training the classifiers on all but the last time interval, and testing on the final interval.",4.2 Non-seasonal Adaptation,[0],[0]
"For hyperparameter tuning, we used the final time interval of the training data (i.e., the penultimate interval) as the validation set.",4.2 Non-seasonal Adaptation,[0],[0]
"The intuition is that the penultimate interval is the closest to the test data and thus is expected to be most similar to it.
",4.2 Non-seasonal Adaptation,[0],[0]
Results are shown in the first three columns of Table 3.,4.2 Non-seasonal Adaptation,[0],[0]
We see that this approach leads to a small performance boost in all cases except the Twitter dataset.,4.2 Non-seasonal Adaptation,[0],[0]
"This means that this simple feature augmentation approach has the potential to make classifiers more robust to future changes in data.
",4.2 Non-seasonal Adaptation,[0],[0]
How to apply the feature augmentation technique to unseen domains is not well understood.,4.2 Non-seasonal Adaptation,[0],[0]
"By removing the domain-specific features, as we did here, the prediction model has changed, and so its behavior may be hard to predict.",4.2 Non-seasonal Adaptation,[0],[0]
"Nonetheless, this appears to be a successful approach.",4.2 Non-seasonal Adaptation,[0],[0]
We also experimented with including the seasonal features when performing non-seasonal adaptation.,4.2.1 Adding Seasonal Features,[0],[0]
"In this setting, we train the models with two domain-specific features in addition to the domain-independent features: one for the season,
and one for the non-seasonal interval.",4.2.1 Adding Seasonal Features,[0],[0]
"As above, we remove the non-seasonal features at test time; however, we retain the season-specific features in addition to the domain-independent features, as they can be reused in future years.
",4.2.1 Adding Seasonal Features,[0],[0]
The results of this approach are shown in the last column of Table 3.,4.2.1 Adding Seasonal Features,[0],[0]
We find that combining seasonal and non-seasonal features together leads to an additional performance gain in most cases.,4.2.1 Adding Seasonal Features,[0],[0]
"Our experiments suggest that time can substantially affect the performance of document classification, and practitioners should be cognizant of this variable when developing classifiers.",5 Conclusion,[0],[0]
"A simple analysis comparing pairs of time intervals can provide insights into how performance varies with time, which could be a good practice to do when initially working with a corpus.",5 Conclusion,[0],[0]
"Our experiments also suggest that simple domain adaptation techniques can help account for this variation.4
We make two practical recommendations following the insights from this work.",5 Conclusion,[0],[0]
"First, evaluation will be most accurate if the test data is as similar as possible to whatever future data the classifier will be applied to, and one way to achieve this is to select test data from the chronological end of the corpus, rather than randomly sampling data without regard to time.",5 Conclusion,[0],[0]
"Second, we observed that performance on future data tends to increase when hyperparameter tuning is conducted on later data; thus, we also recommend sampling validation data from the chronological end of the corpus.",5 Conclusion,[0],[0]
The authors thank the anonymous reviews for their insightful comments and suggestions.,Acknowledgements,[0],[0]
"This work was supported in part by the National Science Foundation under award number IIS-1657338.
4Our code is available at: https://github.com/ xiaoleihuang/Domain_Adaptation_ACL2018",Acknowledgements,[0],[0]
Many corpora span broad periods of time.,abstractText,[0],[0]
"Language processing models trained during one time period may not work well in future time periods, and the best model may depend on specific times of year (e.g., people might describe hotels differently in reviews during the winter versus the summer).",abstractText,[0],[0]
"This study investigates how document classifiers trained on documents from certain time intervals perform on documents from other time intervals, considering both seasonal intervals (intervals that repeat across years, e.g., winter) and non-seasonal intervals (e.g., specific years).",abstractText,[0],[0]
"We show experimentally that classification performance varies over time, and that performance can be improved by using a standard domain adaptation approach to adjust for changes in time.",abstractText,[0],[0]
Examining Temporality in Document Classification,title,[0],[0]
"Proceedings of the SIGDIAL 2015 Conference, pages 260–269, Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"The amount of textual content that is produced and consumed each day all over the world, through news websites, social media, and other information sources, is constantly growing.",1 Introduction,[0],[0]
This makes the process of selecting the right content to read and quickly recognizing basic facts and topics in texts a core task for making content accessible to the users.,1 Introduction,[0],[0]
Automatic summarization strives to provide a means to this end.,1 Introduction,[0],[0]
"This paper describes our automatic summarization system, and its participation in the MultiLing 2015 summarization challenge.
",1 Introduction,[0],[0]
"Our focus has been on producing a largely language-independent solution for the MultiLing 2015 challenge that, in contrast to most attempts in this field, requires a strict minimum of languagespecific components and uses no language-specific materials for the core innovative elements.
",1 Introduction,[0],[0]
"Our motivation comes in part from Hong et al. (2014), who compares a number of single language summarization systems on the same standardized data set and shows that many complex, language-specific, highly optimized and trained
methods do not significantly out-perform simplistic algorithms that date back to the first summarization competitions in 2004.
",1 Introduction,[0],[0]
"Language-independent text summarization is generally based on sentence extractive methods: A subset of sentences in a text are identified and combined to form a summary, rather than performing more complex operations, and the primary task of summarization algorithms is to identify the set of sentences that form the best summary.",1 Introduction,[0],[0]
"In this case, algorithms differ mostly in how sentences are selected.
",1 Introduction,[0],[0]
One textual feature that has proven useful in identifying good summary sentences is the relative prominence of specific words in texts when contrasted to a reference distribution (like frequency in a large general corpus).,1 Introduction,[0],[0]
"For example, the “keyness” metric in El-Haj and Rayson (2013), singular value decomposition on a term-vector matrix (Steinberger, 2013) and neural network-derived transformations of term vectors (Kågebäck et al., 2014) have all produced significant results.",1 Introduction,[0],[0]
There are also a number of rule-based approaches like Anechitei and Ignat (2013).,1 Introduction,[0],[0]
"Hong et al. (2014) provides an overview of various current approaches, ranging from simple baseline algorithms to complex systems with many machine learning and rule-based components of various kinds.
",1 Introduction,[0],[0]
"One promising recent approach is graph theorybased schemes which construct sentence similarity graphs and use various graph techniques to determine the importance of specific sentences as a heuristic to identify good summary sentences (Barth, 2004; Li et al., 2013b; Mihalcea and Tarau, 2004).
",1 Introduction,[0],[0]
"In this paper, we describe ExB’s graphbased summarization approach and its results in two MultiLing 2015 tasks: Multilingual Singledocument Summarization and Multilingual Multidocument Summarization.",1 Introduction,[0],[0]
ExB’s submissions covered all languages in each task.,1 Introduction,[0],[0]
"Furthermore,
260
we summarize and discuss some unexpected negative experimental results, particularly in light of the problems posed by summarization tasks and their evaluation using ROUGE (Lin, 2004).",1 Introduction,[0],[0]
"The procedures used in both tasks start from similar assumptions and use a generalized framework for language-independent sentence selectionbased summarization.
",2 Process Overview,[0],[0]
We start from the same basic model as LDA approaches to text analysis: Every document contains a mixture of topics that are probabilistically indicative of the tokens present in it.,2 Process Overview,[0],[0]
"We select sentences in order to generate summaries whose topic mixtures most closely match that of the document as a whole (Blei et al., 2003).
",2 Process Overview,[0],[0]
"We construct a graph representation of the text in which each node corresponds to a sentence, and edges are weighted by a similarity metric for comparing them.",2 Process Overview,[0],[0]
"We then extract key sentences for use in summaries by applying the PageRank/TextRank algorithm, a well-studied algorithm for measuring graph centrality.",2 Process Overview,[0],[0]
"This technique has proven to be good model for similar extraction tasks in the past (Mihalcea and Tarau, 2004).
",2 Process Overview,[0],[0]
We deliberately chose not to optimize any parameters of our core algorithm for specific languages.,2 Process Overview,[0],[0]
Every parameter and design decision applied to all languages equally and was based on cross-linguistic performance.,2 Process Overview,[0],[0]
"Typically it is possible to increase evaluation performance by 2%-4% through fine tuning, but this tends to produce overfitting and the gains are lost when applied to any broader set of languages or domains.
",2 Process Overview,[0],[0]
"Our approach consists of three stages:
1.",2 Process Overview,[0],[0]
Preprocessing using common NLP tools.,2 Process Overview,[0],[0]
"This includes steps like tokenization and sentence identification, and in the multilingual summarization case, an extractor for time references like dates and specific times of day.",2 Process Overview,[0],[0]
"These tools are not entirely languageindependent.
2.",2 Process Overview,[0],[0]
"Sentence graph construction and sentence ranking as described in Sections 2.2 and 2.3 respectively.
3.",2 Process Overview,[0],[0]
Post-processing using simple and languageindependent rules for selecting the highest ranking sentences up to the desired length of text.,2 Process Overview,[0],[0]
Our processing pipeline starts with tokenization and sentence boundary detection.,2.1 Preprocessing,[0],[0]
For most languages we employ ExB’s proprietary languageindependent rule-based tokenizer.,2.1 Preprocessing,[0],[0]
"For Chinese, Japanese and Thai tokenization we use languagedependent approaches:
• Chinese is tokenized using a proprietary algorithm that relies on a small dictionary, the probability distribution of token lengths in Chinese, and a few handcrafted rules for special cases.
",2.1 Preprocessing,[0],[0]
"• For Thai, we use a dictionary containing data from NECTEC (2003) and Satayamas (2014) to calculate the optimal partition of Thai letter sequences based on a shortest path algorithm in a weighted, directed acyclic character graph using dictionary terms found in the text.
",2.1 Preprocessing,[0],[0]
"• For Japanese, we employ the CRF-based MeCab (Kudo et al., 2004; Kudo, 2013) morphological analyzer and tokenizer.",2.1 Preprocessing,[0],[0]
"MeCab is considered state-of-the-art and is currently being used in the construction of annotated reference corpora for Japanese by Maekawa et al. (2014).
",2.1 Preprocessing,[0],[0]
"Sentence boundary detection is rule-based and uses all sentence separators available in the Unicode range of the document’s main language, along with an abbreviation list and a few rules to correctly identify expressions like “p.ex.” or “...”
Finally, we use a proprietary SVM-based stemmer trained for a wide variety of languages on custom corpora.",2.1 Preprocessing,[0],[0]
"Given a set of tokenized sentences S, we construct a weighted undirected graph G = (V,E), where each vertex Vi ∈ V corresponds to a sentence in S. The weighted edges (Si, Sj , w) of the graph are defined as a subset of S × S where i",2.2 Graph construction,[0],[0]
"6= j and (w ← sim(Si, Sj))",2.2 Graph construction,[0],[0]
≥ t for a given similarity measure sim and a given threshold t.,2.2 Graph construction,[0],[0]
"We always assume a normalized similarity measure with a scale between 0 and 1.
",2.2 Graph construction,[0],[0]
"Sentence similarity is computed with the standard vector space model (Salton, 1989), where each sentence is defined by a vector of its tokens.
",2.2 Graph construction,[0],[0]
"We compared these vectors using a number of techniques:
• An unweighted bag-of-words model with sentence similarity computed using the Jacquard index.
",2.2 Graph construction,[0],[0]
"• Conventional cosine similarity of sentence vectors weighted by term frequency in the sentence.
",2.2 Graph construction,[0],[0]
"• TF-IDF weighted cosine similarity, where term frequencies in sentences are normalized with respect to the document collection.
",2.2 Graph construction,[0],[0]
"• Semantic similarity measured using the ExB Themis semantic approach described in Hänig et al. (2015).
",2.2 Graph construction,[0],[0]
"We also evaluated different settings for the threshold t. We did not optimize t separately for different languages, instead setting a single value for all languages.
",2.2 Graph construction,[0],[0]
"Surprisingly, when averaged over all 38 languages in the MSS training set, the simple bag-ofwords model with a threshold t = 0.3 produced the best result using the ROUGE-2 measure.",2.2 Graph construction,[0],[0]
"We then apply to the sentence similarity graph an iterative extension of the PageRank algorithm (Brin and Page, 1998) that we have called FairTextRank (FRank) to rank the sentences in the graph.",2.3 Sentence ranking,[0],[0]
"PageRank has been used as a ranker for an extractive summarizer before in Mihalcea and Tarau (2004), who named it TextRank when used for this purpose.",2.3 Sentence ranking,[0],[0]
"PageRank constitutes a measure of graph centrality, so intuitively we would expect it to select the most central, topical, and summarizing sentences in the text.
",2.3 Sentence ranking,[0],[0]
"Following our assumption that every document constitutes a mix of topics, we further assume that every topic corresponds to a cluster in the sentence graph.",2.3 Sentence ranking,[0],[0]
"However, PageRank is not a cluster sensitive algorithm and does not, by itself, ensure coverage of the different clusters present in any graph.",2.3 Sentence ranking,[0],[0]
"Therefore, our FRank algorithm invokes PageRank iteratively on the graph, at each step ranking all the sentences, then removing the top ranking sentence from the graph, and then running PageRank again to extract the next highest ranking sentence.",2.3 Sentence ranking,[0],[0]
"Because the most central sentence in the entire graph is also, by definition, the most central sentence in some cluster, removing it weakens
the centrality of the other sentences in that cluster and increases the likelihood that the next sentence selected will be the highest ranking sentence in another cluster.
",2.3 Sentence ranking,[0],[0]
"A similar method of removing selected sentences is used in the UWB Summarizer by Steinberger (2013), which was one of the top performing systems at MultiLing 2013.",2.3 Sentence ranking,[0],[0]
"However, the UWB Summarizer uses an LSA algorithm on a sentence-term matrix to identify representative sentences, where we have employed PageRank.
",2.3 Sentence ranking,[0],[0]
The complete algorithm is detailed in Algorithm 1.,2.3 Sentence ranking,[0],[0]
"The function adj returns the weighted adjacency matrix of the sentence graph G. An inner for-loop transforms the weighted adjacency matrix into a column-stochastic matrix where for each column c, where A[i, c] is the weight of the edge between sentence i and sentence c, the following expression holds: ∑ i∈|A|A[i, c] = 1.",2.3 Sentence ranking,[0],[0]
"Informally, each column is normalized at each iteration so that its values sum to 1.",2.3 Sentence ranking,[0],[0]
"pr is the PageRank-algorithm with the default parameters β = 0.85, a convergence threshold of 0.001 and allowed to run for at most 100 iterations as implemented in the JUNG API (O’Madadhain et al., 2010).
",2.3 Sentence ranking,[0],[0]
Algorithm 1,2.3 Sentence ranking,[0],[0]
FairTextRank 1: function FRANK(G) 2:,2.3 Sentence ranking,[0],[0]
R←,2.3 Sentence ranking,[0],[0]
[] 3: while |G| > 0,2.3 Sentence ranking,[0],[0]
"do 4: A← adj(G) 5: for (r, c)← |A|2 do 6: Anorm[r, c]← A[r,c],∑
i∈|A| A[i,c]
7: rank ← pr(Anorm) 8: v ← rank[0] 9: R← R+ v
10: G← G \ v return R",2.3 Sentence ranking,[0],[0]
The final step in processing is the production of a plain text summary.,2.4 Post-processing,[0],[0]
"Given a fixed maximum summary length, we selected the highest ranked sentences produced by the ranking algorithm until total text length was greater than the maximum allowed length, then truncated the last sentence to fit exactly the maximum allowed length.",2.4 Post-processing,[0],[0]
"Although this reduces the human readability of the summary - the last sentence is interrupted without any consideration of the reader at all - it can only increase
the score of an n-gram based evaluation metric like ROUGE.",2.4 Post-processing,[0],[0]
The Multilingual Single-document Summarization (MSS) task consisted of producing summaries for Wikipedia articles in 38 languages.,3 Single Document Summarizer,[0],[0]
All articles were provided as UTF-8 encoded plain-text files and as XML documents that mark sections and other elements of the text structure.,3 Single Document Summarizer,[0],[0]
"We took advantage of the availability of headers and section boundary information in performing this task.
",3 Single Document Summarizer,[0],[0]
There was no overlap between the training data and the evaluation data for the MSS task.,3 Single Document Summarizer,[0],[0]
The released training data consisted of the evaluation data set from MultiLing 2013 as described in Kubina et al. (2013).,3 Single Document Summarizer,[0],[0]
This training data contains 30 articles in each of 40 languages.,3 Single Document Summarizer,[0],[0]
"The MSS task itself at MultiLing 2015 used 30 articles in each of 38 languages, dropping two languages because there were not enough new articles not included in the training data.
",3 Single Document Summarizer,[0],[0]
"In addition to the preprocessing steps described in Section 2.1, for this task we applied a list of sentence filters developed specifically for Wikipedia texts:
• Skip all headers.",3 Single Document Summarizer,[0],[0]
•,3 Single Document Summarizer,[0],[0]
"Skip every sentence with with less than 2 to-
kens (mostly errors in sentence boundary detection).
",3 Single Document Summarizer,[0],[0]
•,3 Single Document Summarizer,[0],[0]
"Skip every sentence that contains double quotes.
",3 Single Document Summarizer,[0],[0]
"We then performed sentence graph construction and ranking as described in Sections 2.2 and 2.3
In the post-processing stage, we sorted the sentences selected to go into the summary in order of their position in the original article, before producing a plain text summary by concatenating them.",3 Single Document Summarizer,[0],[0]
The organizers of the MultiLing 2015 challenge measured the quality of our system’s output using five different versions of the ROUGE score.,3.1 Results,[0],[0]
We provide a summary of the results for all participants in Table 1.,3.1 Results,[0],[0]
"It shows the average ranking of each participating system over all the languages on which it was tested, as well as the number of languages on which each system was tested.",3.1 Results,[0],[0]
The systems labelled Lead and Oracles are special systems.,3.1 Results,[0],[0]
"Lead just uses the beginning of the article
as the summary and represents a very simple baseline.",3.1 Results,[0],[0]
"Oracles, on the other hand, is a cheating system that marks the upper bound for any extractive approach.
",3.1 Results,[0],[0]
Only three submissions - highlighted in bold - participated in more than 3 languages.,3.1 Results,[0],[0]
"We submitted only one run of our system, defined as a fixed set of parameters that are the same over all languages.",3.1 Results,[0],[0]
One of the other two systems that participated in all 38 languages submitted five runs.,3.1 Results,[0],[0]
"According to the frequently used ROUGE-1 and ROUGE-2 scores, our system achieved an average ranking of 3.2 and 3.3, respectively.",3.1 Results,[0],[0]
"This table shows that the CCS system performed better on average than our system, and the LCS-IESI system performed on average worse.
",3.1 Results,[0],[0]
"However, ROUGE-1 only measures matching single words, whereas ROUGE-2 measures matching bigrams.",3.1 Results,[0],[0]
More complex combinations of words are more indicative of topic matches between gold standard data and system output.,3.1 Results,[0],[0]
"We believe that ROUGE-SU4, which measures bigrams of words with some gaps as well as unigrams, would be a better measure of output quality.",3.1 Results,[0],[0]
"When manually inspecting the summaries, we have the strong impression that system runs in which our system scored well by ROUGESU4 measures, but poorly by ROUGE-2, did produce better summaries with greater readability and topic coverage.
",3.1 Results,[0],[0]
"Our system achieves a significantly better overall ranking using ROUGE-SU4 instead of ROUGE-2, even though the system was optimized to produce the highest ROUGE-2 scores.",3.1 Results,[0],[0]
Only two runs of the winning system CCS scored better than our system according to ROUGE-SU4.,3.1 Results,[0],[0]
"This underlines the robustness of our system’s underlying principles, despite the known problems with ROUGE evaluations.",3.1 Results,[0],[0]
The Multilingual Multi-document Summarization (MMS) task involves summarizing ten news articles on a single topic in a single language.,4 Multi Document Summarizer,[0],[0]
"For each language, the dataset consists of ten to fifteen topics, and ten languages were covered in all, including and expanding on the data used in the 2013 MMS task described by Li et al. (2013a).
",4 Multi Document Summarizer,[0],[0]
"The intuition guiding our approach to this task is the idea that if news articles on the same topic contain temporal references that are close together
or overlapping in time, then they are likely to describe the same event.",4 Multi Document Summarizer,[0],[0]
We therefore cluster the documents in each collection by the points in time referenced in the text rather than attempting to summarize the concatenation of the documents directly.,4 Multi Document Summarizer,[0],[0]
"This approach has the natural advantage that we can present summary information in chronological order, thereby often improving readability.",4 Multi Document Summarizer,[0],[0]
"Unfortunately, this improvement is not measurable using ROUGE-style metrics as employed in evaluating this task.
",4 Multi Document Summarizer,[0],[0]
"An official training data set with model summaries was released, but too late to inform our submission, which was not trained with any new 2015 data.",4 Multi Document Summarizer,[0],[0]
"We did, however, use data from the 2011 MultiLing Pilot including gold standard summaries (Giannakopoulos et al., 2011), which forms a part of the 2015 dataset.",4 Multi Document Summarizer,[0],[0]
"We used only the 700 documents and summaries from the 2011 task as training data, and did not use any Chinese, Spanish or Romanian materials in preparing our submission.
",4 Multi Document Summarizer,[0],[0]
"Our submission follows broadly the same procedure as for the single document summarization task, as described in Section 2 and Section 3, except for the final step, which relies on section information not present in the news articles that form the dataset for this task.",4 Multi Document Summarizer,[0],[0]
"Instead, a manual examination of the dataset revealed that the news articles all have a fixed structure: the first line is the headline, the second is the date, and the remaining lines form the main text.",4 Multi Document Summarizer,[0],[0]
"We used this underlying structure in preprocessing to identify the dateline of the news article, and we use this date to disambiguate relative time expressions in the text like “yesterday” or “next week”.",4 Multi Document Summarizer,[0],[0]
"Articles are also ordered in
time with respect to each other on the basis of the article date.
",4 Multi Document Summarizer,[0],[0]
"Furthermore, we remove in preprocessing any sentence that contains only time reference tokens because they are uninformative for summarization.
",4 Multi Document Summarizer,[0],[0]
"We then extract temporal references from the text, using ExB’s proprietary TimeRec framework described in Thomas (2012), which is available for all the languages used in this task.",4 Multi Document Summarizer,[0],[0]
"With the set of disambiguated time references in each document, we can provide a “timeframe” for each document that ranges from the earliest time referenced in the text to the latest.",4 Multi Document Summarizer,[0],[0]
"Note that this may not include the date of the document itself, if, for example, it is a retrospective article about an event that may have happened years in the past.",4 Multi Document Summarizer,[0],[0]
Ng et al. (2014) and,4.1 Time information processing,[0],[0]
Wan (2007) investigate using textural markers of time for multi-document summarization of news articles using very different algorithms.,4.1 Time information processing,[0],[0]
Our approach is more similar to Ng et al. in constructing a timeline for each document and for the collection as a whole based on references extracted from texts.,4.1 Time information processing,[0],[0]
"Once document timeframes are ordered chronologically, we organize them into groups based on their positions on a time line.",4.1 Time information processing,[0],[0]
"We explored two strategies to produce these groups:
• Least Variance Clustering (LVC):",4.1 Time information processing,[0],[0]
Grouping the documents iteratively by adding a new document to the group if the overall variance of the group doesn’t go over a threshold.,4.1 Time information processing,[0],[0]
"We set the standard deviation limit of the group
in 0.1.",4.1 Time information processing,[0],[0]
The algorithm is a divisive clustering algorithm based on the central time of the documents and the standard deviation.,4.1 Time information processing,[0],[0]
"At first the minimal central time of a document collection is subtracted from all other central times, then we compute mean, variance and standard deviation based on days as a unit and normalized by the mean.",4.1 Time information processing,[0],[0]
"Afterwards we recursively split the groups with the goal to minimize the variance of both splits until either a group consists only of one document or the recomputed standard deviation of a group is less than 0.1.
",4.1 Time information processing,[0],[0]
"• Overlapping Time Clustering (OTC): Grouping documents together if their timeframes overlap more than a certain amount, which we empirically set to 0.9 after experimenting with various values.",4.1 Time information processing,[0],[0]
"This means that if two texts A and B are grouped together, then either A’s timeframe includes at least 90% of B’s timeframe, or B’s timeframe includes 90% of A’s.",4.1 Time information processing,[0],[0]
"This approach proceeds iteratively, with each new addition to a group updating the timeframe of the group as a whole, and any text which overlaps more than 90% with this new interval is then grouped with it in the next iteration.
",4.1 Time information processing,[0],[0]
"In addition, we provide two baseline clusterings:
• One document per cluster (1PC): Each document is in a cluster by itself.
",4.1 Time information processing,[0],[0]
"• All in one cluster (AIO): All documents from one topic are clustered together.
",4.1 Time information processing,[0],[0]
"In the LVC and OTC cases, clustering is iterative and starts with the earliest document as determined by a fixed “central” date for each document.",4.1 Time information processing,[0],[0]
"We explored different ways of determining that “central” date: One was using the dateline found in preprocessing on the second line of each document, another was the median of the time references in the document.",4.1 Time information processing,[0],[0]
"Our best result used the dateline from each article and, as can be seen in Table 2, was produced by the OTC strategy.",4.1 Time information processing,[0],[0]
"This is a surprising result, as we expected LVC to perform better since variance is generally a better measure of clustering.",4.1 Time information processing,[0],[0]
"However, we found that LVC generally produced more clusters than OTC and we believe that to account for its poor performance.
",4.1 Time information processing,[0],[0]
"We experimented with a number of other ordering and clustering approaches, although they do not figure into our submission to the MMS task, but in all cases they failed to out-perform the OTC approach according to the ROUGE-2 recall measure.
",4.1 Time information processing,[0],[0]
"For all conditions, identical preprocessing was performed using ExB’s proprietary languagespecific tokenizer and sentence identifier.",4.1 Time information processing,[0],[0]
"ROUGE scores, because they are based on token n-grams, are very sensitive to discrepancies between tokenizers and stemmers.",4.1 Time information processing,[0],[0]
"In English, because most tokenizers perform very similarly, this causes fewer problems in scoring than for Arabic or other languages where tokenizers vary dramatically.",4.1 Time information processing,[0],[0]
"We used the results in Table 2 to decide which conditions to use in the competition, but we cannot be sure to what degree our results have been influenced by these kinds of ROUGE-related problems.
",4.1 Time information processing,[0],[0]
"After clustering, we perform graph-based sentence ranking as described in Sections 2.2 and 2.3 separately for each cluster.",4.1 Time information processing,[0],[0]
"We then select sentences from each cluster, ensuring that they are all represented in the final summary, so that the entire time span of the articles is covered.",4.1 Time information processing,[0],[0]
"We also order the selected sentences in the summary based on the temporal ordering of the clusters, so that summary presentation is in event order.",4.1 Time information processing,[0],[0]
"When experimenting with the challenge data we made several observations:
1.",4.2 Experimental results,[0],[0]
"Since the dataset of MMS is composed of news articles, just selecting the headlines and first sentences will produce a strong baseline with very high ROUGE scores.",4.2 Experimental results,[0],[0]
"It is difficult to beat this baseline using sentence extraction techniques.
",4.2 Experimental results,[0],[0]
2.,4.2 Experimental results,[0],[0]
The quality of the summaries varies a great deal between languages.,4.2 Experimental results,[0],[0]
"Instead of producing fine-tuned configurations for each lan-
guage that optimize ROUGE scores, we focused on increasing the performance in English - a language we can read and in which we can qualitatively evaluate the produced summaries.
",4.2 Experimental results,[0],[0]
3.,4.2 Experimental results,[0],[0]
All the results here of the time information processing are at document-level.,4.2 Experimental results,[0],[0]
"We also tried to apply the time grouping algorithms per sentence, but we noticed a drop of about 3% ROUGE-2 score on average.
",4.2 Experimental results,[0],[0]
"The most important finding is that using temporal expressions and chronological information does improve the performance of the summary system, and that the iterative FairTextRank algorithm shows a solid performance even for multiple documents.
",4.2 Experimental results,[0],[0]
"As can be seen in Table 3, our system gets ranked in middle position in the official scores of the challenge using the NPowER, MeMoG and AutoSummENG measures as described in Giannakopoulos and Karkaletsis (2013) and Giannakopoulos and Karkaletsis (2011).",4.2 Experimental results,[0],[0]
"We also note that our system out-performs all other participants in Chinese, a language for which we had no training data.",4.2 Experimental results,[0],[0]
"We feel that it is important not only to publish positive results, but also negative ones, to counter the strong publication bias identified in many areas in the natural and social sciences (Dickersin et al., 1987; Ioannidis, 2005).",5 Negative results,[0],[0]
"Since we conducted a large number of experiments in creating this system, we inevitably also came across a number of ideas that seemed good, but turned out to not improve our algorithm, at least as measured using ROUGE-2.
",5 Negative results,[0],[0]
In another challenge participation we developed a very powerful “semantic text similarity” (STS) toolkit.,5 Negative results,[0],[0]
"In SemEval 2015 Task 2 (Agirre et al., 2015), it achieved by far the highest scores for Spanish texts and the second best scores for English.",5 Negative results,[0],[0]
"Since our text summarization methodology is based on a sentence similarity graph, our intuitive hypothesis was that when using this module as opposed to simple matching-words strategies, performance should increase significantly.",5 Negative results,[0],[0]
"Matching-words strategies are used as the baseline in SemEval tasks, and it is easily out-performed by more sophisticated approaches.
",5 Negative results,[0],[0]
"Therefore, we tried out our STS module as a replacement for Jacquard and cosine similarity measures when constructing the sentence graph, while keeping all other parameters fixed.",5 Negative results,[0],[0]
"Surprisingly, it did not improve performance, and lowered ROUGE-2 scores by 2%.",5 Negative results,[0],[0]
"We also attempted to use word2vec embeddings precomputed on very large corpora (Mikolov et al., 2013) to represent words and hence compute a much finer-grained sentence similarity, but those results were 4% worse.",5 Negative results,[0],[0]
"It is possible that those systems were, in fact, better, but because ROUGE scoring focuses on word matches, any other improvement cannot be measured directly.",5 Negative results,[0],[0]
"We also attempted to include other factors such as sentence length, position, number of named entities, temporal expressions, and physical measurements into the sentence similarity score, all without seeing any increase in ROUGE scores.
",5 Negative results,[0],[0]
"Since identifying temporal expressions increases ROUGE scores, as this paper shows, we surmised that name recognition might also improve summarization.",5 Negative results,[0],[0]
"We applied our named entity recognition system, which is available in a number of different languages and won the Germeval 2014 (Benikova et al., 2014) NER challenge, and weighted more heavily sentences with detected names before extracting summary sentences.",5 Negative results,[0],[0]
"Interestingly, no matter how the weighting scheme was set up, the performance of the system always dropped by a few percent.",5 Negative results,[0],[0]
"Often, the system would select useless sentences that contain long lists of participating authors, or enumerations of entities participating in some reported event.",5 Negative results,[0],[0]
"Even when these kinds of sentences are explicitly removed, it still selects sentences that simply contain many names with little relevance to the topics of the news article.",5 Negative results,[0],[0]
"We conclude that sen-
tences describing central topics in documents are not strongly correlated with named entity usage.
",5 Negative results,[0],[0]
"Another very intuitive assumption is that filtering stop words, or down-weighting very frequent words, or using a TF-IDF based scheme with a similar effect, would improve the results.",5 Negative results,[0],[0]
"However, we did not observe any improvement by using these techniques.",5 Negative results,[0],[0]
"Nonetheless, there are strong indications that this is due to the limitations of ROUGE-2 scoring and we cannot conclude that these kinds of techniques are useless for summarization.",5 Negative results,[0],[0]
It is easy to achieve very competitive ROUGE-2 scores by just filling the summary with very frequent stop word combinations.,5 Negative results,[0],[0]
"A human would immediately recognize the uselessness of such a “summary”, but ROUGE-2 would count many bigram matches with a gold standard summary.
",5 Negative results,[0],[0]
"Finally, we considered the hypothesis that the summary system could be helped by explicitly removing very similar sentences presenting redundant information.",5 Negative results,[0],[0]
"Surprisingly, explicitly removing such sentences did not improve the performance of the system.",5 Negative results,[0],[0]
"Manually inspecting a number of summaries, we notice that very similar sentences recurring often in texts are rarely selected by the FRank algorithm.",5 Negative results,[0],[0]
We believe this is because our approach is sufficiently robust to discount these sentences on its own.,5 Negative results,[0],[0]
"In this paper we outline ExB’s largely languageindependent system for text summarization based on sentence selection, and show that it supports at least the 38 languages used in this completion without any language-specific fine-tuning.",6 Conclusions,[0],[0]
Sentences are selected using an iterative extension of PageRank calculation on a sentence similarity graph.,6 Conclusions,[0],[0]
"Our results in the MultiLing 2015 challenge have validated this approach by achieving the best scores for several languages and competitive scores for most of them, generally surpassed by only one other participating system.
",6 Conclusions,[0],[0]
"We also show that one basic summarization system can apply to different domains, different languages, and different tasks without special configuration, while retaining state-of-the-art performance.",6 Conclusions,[0],[0]
"Furthermore, for multi-document news summarization, we show that extracting temporal expressions is a useful feature for combining articles on the same topic.
",6 Conclusions,[0],[0]
"Our most relevant conclusion is that both the current evaluation methodology (based on various forms of ROUGE) as well as the current principal approach to language-independent text summarization (context-free, sentence selection based) are highly inadequate to model the vague requirements users associate with a text summarization product.
",6 Conclusions,[0],[0]
Participants in MultiLing 2015 did not receive the scripts and parameters used in producing evaluations.,6 Conclusions,[0],[0]
This made it difficult to optimize parameters and algorithms and has a significant impact on results using ROUGE measures and probably the other measures as well.,6 Conclusions,[0],[0]
"Hong et al. (2014), for example, notes values between 30.8% and 39.1% using ROUGE-1 for one well-known algorithm on one data set by different authors.",6 Conclusions,[0],[0]
It is not clear how the vastly different scores obtained for identical summaries using different ROUGE parameters correlate with the objective quality of a given summary.,6 Conclusions,[0],[0]
"We have no clear indication that ROUGE scores really capture the quality of a given summary at all.
",6 Conclusions,[0],[0]
"While it is possible to formulate summarization solutions based on sentence selection and even iteratively improve them using ROUGE scores, the actual achievable performance measured using ROUGE is very low.",6 Conclusions,[0],[0]
"We have noticed that stemming, stopword filtering and various tokenization strategies can have a very large influence on ROUGE scores, especially in morphologically richer languages than English.",6 Conclusions,[0],[0]
"More modern evaluation measures like MeMog or NPoweR might solve the problems inherent to ROUGE, however they currently lack widespread adoption in the research community.
",6 Conclusions,[0],[0]
"Nonetheless, even if these issues in evaluation can be addressed, we do not believe that summaries based on sentence selection will ever reach a quality where they could be accepted as comparable to a human written summary.",6 Conclusions,[0],[0]
We present our state of the art multilingual text summarizer capable of single as well as multi-document text summarization.,abstractText,[0],[0]
"The algorithm is based on repeated application of TextRank on a sentence similarity graph, a bag of words model for sentence similarity and a number of linguistic preand post-processing steps using standard NLP tools.",abstractText,[0],[0]
We submitted this algorithm for two different tasks of the MultiLing 2015 summarization challenge: Multilingual Singledocument Summarization and Multilingual Multi-document Summarization.,abstractText,[0],[0]
ExB Text Summarizer,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1329–1338 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1329
In this paper we present the Exemplar Encoder-Decoder network (EED), a novel conversation model that learns to utilize similar examples from training data to generate responses. Similar conversation examples (context-response pairs) from training data are retrieved using a traditional TF-IDF based retrieval model. The retrieved responses are used to create exemplar vectors that are used by the decoder to generate the response. The contribution of each retrieved response is weighed by the similarity of corresponding context with the input context. We present detailed experiments on two large data sets and find that our method outperforms state of the art sequence to sequence generative models on several recently proposed evaluation metrics. We also observe that the responses generated by the proposed EED model are more informative and diverse compared to existing state-of-the-art method.",text,[0],[0]
"With the availability of large datasets and the recent progress made by neural methods, variants of sequence to sequence learning (seq2seq) (Sutskever et al., 2014) architectures have been successfully applied for building conversational systems (Serban et al., 2016, 2017b).",1 Introduction,[0],[0]
"However, despite these methods being the stateof-the art frameworks for conversation generation, they suffer from problems such as lack of diversity in responses and generation of short, repetitive and uninteresting responses (Liu et al., 2016; Serban et al., 2016, 2017b).",1 Introduction,[0],[0]
"A large body of recent
literature has focused on overcoming such challenges (Li et al., 2016a; Lowe et al., 2017).
",1 Introduction,[0],[0]
"In part, such problems arise as all information required to generate responses needs to be captured as part of the model parameters learnt from the training data.",1 Introduction,[0],[0]
These model parameters alone may not be sufficient for generating natural conversations.,1 Introduction,[0],[0]
"Therefore, despite providing enormous amount of data, neural generative systems have been found to be ineffective for use in real world applications (Liu et al., 2016).
",1 Introduction,[0],[0]
"In this paper, we focus our attention on closed domain conversations.",1 Introduction,[0],[0]
"A characteristic feature of such conversations is that over a period of time, some conversation contexts1 are likely to have occurred previously (Lu et al., 2017b).",1 Introduction,[0],[0]
"For instance, Table 1 shows some contexts from the Ubuntu dialog corpus.",1 Introduction,[0],[0]
"Each row presents an input dialog context with its corresponding gold response followed by a similar context and response seen in training data – as can be seen, contexts for “installing dms”, “sharing files”, “blocking ufw ports” have all occurred in training data.",1 Introduction,[0],[0]
"We hypothesize that being able to refer to training responses for previously seen similar contexts could be a helpful signal to use while generating responses.
",1 Introduction,[0],[0]
"In order to exploit this aspect of closed domain conversations we build our neural encoderdecoder architecture called the Exemplar Encoder Decoder (EED), that learns to generate a response for a given context by exploiting similar contexts from training conversations.",1 Introduction,[0],[0]
"Thus, instead of having the seq2seq model learn patterns of language only from aligned parallel corpora, we assist the model by providing it closely related (similar) samples from the training data that it can refer to while generating text.
",1 Introduction,[0],[0]
"Specifically, given a context c, we retrieve a set 1We use the phrase “dialog context”, “conversation con-
text” and “context” interchangeably throughout the paper.
of context-response pairs (c(k), r(k)), 1 ≤ k ≤ K using an inverted index of training data.",1 Introduction,[0],[0]
We create an exemplar vector e(k) by encoding the response r(k) (also referred to as exemplar response) along with an encoded representation of the current context c. We then learn the importance of each exemplar vector e(k) based on the likelihood of it being able to generate the ground truth response.,1 Introduction,[0],[0]
We believe that e(k) may contain information that is helpful in generating the response.,1 Introduction,[0],[0]
"Table 1 highlights the words in exemplar responses that appear in the ground truth response as well.
",1 Introduction,[0],[0]
"Contributions: We present a novel Exemplar Encoder-Decoder (EED) architecture that makes use of similar conversations, fetched from an index of training data.",1 Introduction,[0],[0]
"The retrieved contextresponse pairs are used to create exemplar vectors which are used by the decoder in the EED model, to learn the importance of training context-response pairs, while generating responses.",1 Introduction,[0],[0]
"We present detailed experiments on the publicly benchmarked Ubuntu dialog corpus data set (Lowe et al., 2015) as well a large collection of more than 127,000 technical support conversations.",1 Introduction,[0],[0]
"We compare the performance of the EED model with the existing state of the art generative models such as HRED (Serban et al., 2016) and VHRED (Serban et al., 2017b).",1 Introduction,[0],[0]
"We find that our model out-performs these models on a wide variety of metrics such as the recently proposed Activity Entity metrics (Serban et al., 2017a) as well as Embedding-based metrics (Lowe et al., 2015).",1 Introduction,[0],[0]
"In addition, we present qualitative insights into our results and we find that exemplar based responses
are more informative and diverse.",1 Introduction,[0],[0]
The rest of the paper is organized as follows.,1 Introduction,[0],[0]
Section 2 briefly describes the recent works in neural dialogue generation The details of the proposed EED model for dialogue generation are described in detail in Section 3.,1 Introduction,[0],[0]
"In Section 4, we describe the datasets as well as the details of the models used during training.",1 Introduction,[0],[0]
We present quantitative and qualitative results of EED model in Section 5.,1 Introduction,[0],[0]
"In this section, we compare our work against other data-driven end-to-end conversation models.",2 Related Work,[0],[0]
"Endto-end conversation models can be further classified into two broad categories — generation based models and retrieval based models.
",2 Related Work,[0],[0]
Generation based models cast the problem of dialogue generation as a sequence to sequence learning problem.,2 Related Work,[0],[0]
"Initial works treat the entire context as a single long sentence and learn an encoder-decoder framework to generate response word by word (Shang et al., 2015; Vinyals and Le, 2015).",2 Related Work,[0],[0]
"This was followed by work that models context better by breaking it into conversation history and last utterance (Sordoni et al., 2015b).",2 Related Work,[0],[0]
"Context was further modeled effectively by using a hierarchical encoder decoder (HRED) model which first learns a vector representation of each utterance and then combines these representations to learn vector representation of context (Serban et al., 2016).",2 Related Work,[0],[0]
"Later, an alternative hierarchical model called VHRED (Serban et al., 2017b) was proposed, where generated responses were conditioned on latent variables.",2 Related Work,[0],[0]
"This leads to more in-
formative responses and adds diversity to response generation.",2 Related Work,[0],[0]
"Models that explicitly incorporate diversity in response generation have also been studied in literature (Li et al., 2016b; Vijayakumar et al., 2016; Cao and Clark, 2017; Zhao et al., 2017).
",2 Related Work,[0],[0]
"Our work differs from the above as none of these above approaches utilize similar conversation contexts observed in the training data explicitly.
",2 Related Work,[0],[0]
"Retrieval based models on the other hand treat the conversation context as a query and obtain a set of responses using information retrieval (IR) techniques from the conversation logs (Ji et al., 2014).",2 Related Work,[0],[0]
"There has been further work where the responses are further ranked using a deep learning based model (Yan et al., 2016a,b; Qiu et al., 2017).",2 Related Work,[0],[0]
"On the other hand of the spectrum, endto-end deep learning based rankers have also been employed to generate responses (Wu et al., 2017; Henderson et al., 2017).",2 Related Work,[0],[0]
"Recently a framework has also been proposed that uses a discriminative dialog network that ranks the candidate responses received from a response generator network and trains both the networks in an end to end manner (Lu et al., 2017a).
",2 Related Work,[0],[0]
"In contrast to the above models, we use the input contexts as well as the retrieved responses for generating the final responses.",2 Related Work,[0],[0]
"Contemporaneous to our work, a generative model for machine translation that employs retrieved translation pairs has also been proposed (Gu et al., 2017).",2 Related Work,[0],[0]
"We note that while the underlying premise of both the papers remains the same, the difference lies in the mechanism of incorporating the retrieved data.",2 Related Work,[0],[0]
A conversation consists of a sequence of utterances.,3.1 Overview,[0],[0]
"At a given point in the conversation, the utterances expressed prior to it are jointly referred to as the context.",3.1 Overview,[0],[0]
The utterance that immediately follows the context is referred to as the response.,3.1 Overview,[0],[0]
"As discussed in Section 1, given a conversational context, we wish to to generate a response by utilizing similar context-response pairs from the training data.",3.1 Overview,[0],[0]
We retrieve a set of K exemplar contextresponse pairs from an inverted index created using the training data in an off-line manner.,3.1 Overview,[0],[0]
"The input and the retrieved context-response pairs are then fed to the Exemplar Encoder Decoder (EED)
network.",3.1 Overview,[0],[0]
A schematic illustration of the EED network is presented in Figure 1.,3.1 Overview,[0],[0]
The EED encoder combines the input context and the retrieved responses to create a set of exemplar vectors.,3.1 Overview,[0],[0]
The EED decoder then uses the exemplar vectors based on the similarity between the input context and retrieved contexts to generate a response.,3.1 Overview,[0],[0]
We now provide details of each of these modules.,3.1 Overview,[0],[0]
"Given a large collection of conversations as (context, response) pairs, we index each response and its corresponding context in tf",3.2 Retrieval of Similar Context-Response Pairs,[0],[0]
− idf vector space.,3.2 Retrieval of Similar Context-Response Pairs,[0],[0]
"We further extract the last turn of a conversation and index it as an additional attribute of the context-response document pairs so as to allow directed queries based on it.
",3.2 Retrieval of Similar Context-Response Pairs,[0],[0]
"Given an input context c, we construct a query that weighs the last utterance in the context twice as much as the rest of the context and use it to retrieve the top-k similar context-response pairs from the index based on a BM25 (Robertson et al., 2009) retrieval model.",3.2 Retrieval of Similar Context-Response Pairs,[0],[0]
"These retrieved pairs form our exemplar context-response pairs (c(k), r(k)), 1 ≤ k ≤ K.",3.2 Retrieval of Similar Context-Response Pairs,[0],[0]
"Given the exemplar pairs (c(k), r(k)), 1 ≤ k ≤ K and an input context-response pair (c, r), we feed the input context c and the exemplar contexts c(1), . . .",3.3 Exemplar Encoder Network,[0],[0]
", c(K)",3.3 Exemplar Encoder Network,[0],[0]
"through an encoder to generate the embeddings as given below:
ce = Encodec(c)
c(k)e =",3.3 Exemplar Encoder Network,[0],[0]
"Encodec(c (k)), 1 ≤ k ≤",3.3 Exemplar Encoder Network,[0],[0]
"K
Note that we do not constrain our choice of encoder and that any parametrized differentiable architecture can be used as the encoder to generate the above embeddings.",3.3 Exemplar Encoder Network,[0],[0]
"Similarly, we feed the exemplar responses r(1), . . .",3.3 Exemplar Encoder Network,[0],[0]
", r(K) through a response encoder to generate response embeddings r (1) e , . . .",3.3 Exemplar Encoder Network,[0],[0]
", r (K) e , that is,
r(k)e =",3.3 Exemplar Encoder Network,[0],[0]
"Encoder(r (k)), 1 ≤ k ≤",3.3 Exemplar Encoder Network,[0],[0]
"K (1)
",3.3 Exemplar Encoder Network,[0],[0]
"Next, we concatenate the exemplar response encoding r(k)e with an encoded representation of current context ce as shown in equation 2 to create the exemplar vector e(k).",3.3 Exemplar Encoder Network,[0],[0]
"This allows us to include in-
formation about similar responses along with the encoded input context representation.
e(k) =",3.3 Exemplar Encoder Network,[0],[0]
"[ce; r (k) e ], 1 ≤ k ≤",3.3 Exemplar Encoder Network,[0],[0]
"K (2)
",3.3 Exemplar Encoder Network,[0],[0]
"The exemplar vectors e(k), 1 ≤ k ≤",3.3 Exemplar Encoder Network,[0],[0]
K are further used by the decoder for generating the ground truth response as described in the next section.,3.3 Exemplar Encoder Network,[0],[0]
Recall that we want the exemplar responses to help generate the responses based on how similar the corresponding contexts are with the input context.,3.4 Exemplar Decoder Network,[0],[0]
"More similar an exemplar context is to the input context, higher should be its effect in generating the response.",3.4 Exemplar Decoder Network,[0],[0]
"To this end, we compute the similarity scores s(k), 1 ≤ k ≤ K using the encodings computed in Section 3.3 as shown below.
s(k) =",3.4 Exemplar Decoder Network,[0],[0]
"exp(cTe c (k) e )∑K
l=1",3.4 Exemplar Decoder Network,[0],[0]
"exp(c T e c (l) e )
(3)
",3.4 Exemplar Decoder Network,[0],[0]
"Next, each exemplar vector e(k) computed in Section 3.3, is fed to a decoder, where the decoder is responsible for predicting the ground truth response from the exemplar vector.",3.4 Exemplar Decoder Network,[0],[0]
Let pdec(r|e(k)),3.4 Exemplar Decoder Network,[0],[0]
be the distribution of generating the ground truth response given the exemplar embedding.,3.4 Exemplar Decoder Network,[0],[0]
"The objective function to be maximized, is expressed as a
function of the scores s(k), the decoding distribution pdec and the exemplar vectors e(k) as shown below:
ll = K∑ k=1 s(k) log pdec(r|e(k))",3.4 Exemplar Decoder Network,[0],[0]
"(4)
Note that we weigh the contribution of each exemplar vector to the final objective based on how similar the corresponding context is to the input context.",3.4 Exemplar Decoder Network,[0],[0]
"Moreover, the similarities are differentiable function of the input and hence, trainable by back propagation.",3.4 Exemplar Decoder Network,[0],[0]
"The model should learn to assign higher similarities to the exemplar contexts, whose responses are helpful for generating the correct response.
",3.4 Exemplar Decoder Network,[0],[0]
The model description uses encoder and decoder networks that can be implemented using any differentiable parametrized architecture.,3.4 Exemplar Decoder Network,[0],[0]
We discuss our choices for the encoders and decoder in the next section.,3.4 Exemplar Decoder Network,[0],[0]
"In this section, we discuss the various encoders and the decoder used by our model.",3.5 The Encoders and Decoder,[0],[0]
The conversation context consists of an ordered sequence of utterances and each utterance can be further viewed as a sequence of words.,3.5 The Encoders and Decoder,[0],[0]
"Thus, context can be viewed as having multiple levels of
hierarchies—at the word level and then at the utterance (sentence) level.",3.5 The Encoders and Decoder,[0],[0]
"We use a hierarchical recurrent encoder—popularly employed as part of the HRED framework for generating responses and query suggestions (Sordoni et al., 2015a; Serban et al., 2016, 2017b).",3.5 The Encoders and Decoder,[0],[0]
The word-level encoder encodes the vector representations of words of an utterance to an utterance vector.,3.5 The Encoders and Decoder,[0],[0]
"Finally, the utterance-level encoder encodes the utterance vectors to a context vector.
",3.5 The Encoders and Decoder,[0],[0]
"Let (u1, . . .",3.5 The Encoders and Decoder,[0],[0]
",uN ) be the utterances present in the context.",3.5 The Encoders and Decoder,[0],[0]
"Furthermore, let (wn1, . . .",3.5 The Encoders and Decoder,[0],[0]
", wnMn) be the words present in the nth utterance for 1 ≤ n ≤",3.5 The Encoders and Decoder,[0],[0]
N .,3.5 The Encoders and Decoder,[0],[0]
"For each word in the utterance, we retrieve its corresponding embedding from an embedding matrix.",3.5 The Encoders and Decoder,[0],[0]
The word embedding for wnm will be denoted as wenm.,3.5 The Encoders and Decoder,[0],[0]
"The encoding of the nth utterance can be computed iteratively as follows:
hnm = f1(hnm−1, wenm), 1 ≤ m ≤Mn (5)
We use an LSTM (Hochreiter and Schmidhuber, 1997) to model the above equation.",3.5 The Encoders and Decoder,[0],[0]
"The last hidden state hnMn is referred to as the utterance encoding and will be denoted as hn.
",3.5 The Encoders and Decoder,[0],[0]
"The utterance-level encoder takes the utterance encodings h1, . . .",3.5 The Encoders and Decoder,[0],[0]
", hN as input and generates the encoding for the context as follows:
cen = f2(cen−1, hn), 1 ≤ n ≤",3.5 The Encoders and Decoder,[0],[0]
"N (6)
",3.5 The Encoders and Decoder,[0],[0]
"Again, we use an LSTM to model the above equation.",3.5 The Encoders and Decoder,[0],[0]
"The last hidden state ceN is referred to as the context embedding and is denoted as ce.
",3.5 The Encoders and Decoder,[0],[0]
A single level LSTM is used for embedding the response.,3.5 The Encoders and Decoder,[0],[0]
"In particular, let (w1, . . .",3.5 The Encoders and Decoder,[0],[0]
", wM ) be the sequence of words present in the response.",3.5 The Encoders and Decoder,[0],[0]
"For each word w, we retrieve the corresponding word embedding we from a word embedding matrix.",3.5 The Encoders and Decoder,[0],[0]
"The response embedding is computed from the word embeddings iteratively as follows:
rem = g(rem−1, wem), 1 ≤ m ≤M (7)
",3.5 The Encoders and Decoder,[0],[0]
"Again, we use an LSTM to model the above equation.",3.5 The Encoders and Decoder,[0],[0]
The last hidden state rem is referred to as the response embedding and is denoted as re.,3.5 The Encoders and Decoder,[0],[0]
"We conduct experiments on Ubuntu Dialogue Corpus (Lowe et al., 2015)(v2.0)2.",4.1.1 Ubuntu Dataset,[0],[0]
Ubuntu dialogue corpus has about 1M context response pairs along with a label.,4.1.1 Ubuntu Dataset,[0],[0]
The label value 1 indicates that the response associated with a context is the correct response and is incorrect otherwise.,4.1.1 Ubuntu Dataset,[0],[0]
As we are only interested in positive labeled data we work with label = 1.,4.1.1 Ubuntu Dataset,[0],[0]
Table 2 depicts some statistics for the dataset.,4.1.1 Ubuntu Dataset,[0],[0]
We also conduct our experiments on a large technical support dataset with more than 127K conversations.,4.1.2 Tech Support Dataset,[0],[0]
We will refer to this dataset as Tech Support dataset in the rest of the paper.,4.1.2 Tech Support Dataset,[0],[0]
"Tech Support dataset contains conversations pertaining to an employee seeking assistance from an agent (technical support) — to resolve problems such as password reset, software installation/licensing, and wireless access.",4.1.2 Tech Support Dataset,[0],[0]
"In contrast to Ubuntu dataset, this dataset has clearly two distinct users — employee and agent.",4.1.2 Tech Support Dataset,[0],[0]
"In our experiments we model the agent responses only.
",4.1.2 Tech Support Dataset,[0],[0]
"For each conversation in the tech support data, we sample context and response pairs to create a dataset similar to the Ubuntu dataset format.",4.1.2 Tech Support Dataset,[0],[0]
Note that multiple context-response pairs can be generated from a single conversation.,4.1.2 Tech Support Dataset,[0],[0]
"For each conversation, we sample 25% of the possible contextresponse pairs.",4.1.2 Tech Support Dataset,[0],[0]
We create validation pairs by selecting 5000 conversations randomly and sampling context response pairs).,4.1.2 Tech Support Dataset,[0],[0]
"Similarly, we create test pairs from a different subset of 5000 conversations.",4.1.2 Tech Support Dataset,[0],[0]
"The remaining conversations are used to
2https://github.com/rkadlec/ ubuntu-ranking-dataset-creator
create training context-response pairs.",4.1.2 Tech Support Dataset,[0],[0]
Table 3 depicts some statistics for this dataset:,4.1.2 Tech Support Dataset,[0],[0]
"The EED and HRED models were implemented using the PyTorch framework (Paszke et al., 2017).",4.2 Model and Training Details,[0],[0]
We initialize the word embedding matrix as well as the weights of context and response encoders from the standard normal distribution with mean 0 and variance 0.01.,4.2 Model and Training Details,[0],[0]
The biases of the encoders and decoder are initialized with 0.,4.2 Model and Training Details,[0],[0]
The word embedding matrix is shared by the context and response encoders.,4.2 Model and Training Details,[0],[0]
"For Ubuntu dataset, we use a word embedding size of 600, whereas the size of the hidden layers of the LSTMs in context and response encoders and the decoder is fixed at 1200.",4.2 Model and Training Details,[0],[0]
"For Tech support dataset, we use a word embedding size of 128.",4.2 Model and Training Details,[0],[0]
"Furthermore, the size of the hidden layers of the multiple LSTMs in context and response encoders and the decoder is fixed at 256.",4.2 Model and Training Details,[0],[0]
"A smaller embedding size was chosen for the Tech Support dataset since we observed much less diversity in the responses of the Tech Support dataset as compared to Ubuntu dataset.
",4.2 Model and Training Details,[0],[0]
Two different encoders are used for encoding the input context (not shown in Figure 1 for simplicity).,4.2 Model and Training Details,[0],[0]
The output of the first context encoder is concatenated with the exemplar response vectors to generate exemplar vectors as detailed in Section 3.3.,4.2 Model and Training Details,[0],[0]
The output of the second context encoder is used to compute the scoring function as detailed in Section 3.4.,4.2 Model and Training Details,[0],[0]
"For each input context, we retrieve 5 similar context-response pairs for Ubuntu dataset and 3 context-response pairs for Tech support dataset using the tf-idf mechanism discussed in Section 3.2.
",4.2 Model and Training Details,[0],[0]
"We use the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e",4.2 Model and Training Details,[0],[0]
− 4 for training the model.,4.2 Model and Training Details,[0],[0]
"A batch size of 20 samples was used
during training.",4.2 Model and Training Details,[0],[0]
"In order to prevent overfitting, we use early stopping with log-likelihood on validation set as the stopping criteria.",4.2 Model and Training Details,[0],[0]
"In order to generate the samples using the proposed EED model, we identify the exemplar context that is most similar to the input context based on the learnt scoring function discussed in Section 3.4.",4.2 Model and Training Details,[0],[0]
The corresponding exemplar vector is fed to the decoder to generate the response.,4.2 Model and Training Details,[0],[0]
The samples are generated using a beam search with width 5.,4.2 Model and Training Details,[0],[0]
The average per-word log-likelihood is used to score the beams.,4.2 Model and Training Details,[0],[0]
"A traditional and popular metric used for comparing a generated sentence with a ground truth sentence is BLEU (Papineni et al., 2002) and is frequently used to evaluate machine translation.",5.1.1 Activity and Entity Metrics,[0],[0]
"The metric has also been applied to compute scores for predicted responses in conversations, but it has been found to be less indicative of actual performance (Liu et al., 2016; Sordoni et al., 2015a; Serban et al., 2017a), as it is extremely sensitive to the exact words in the ground truth response, and gives equal importance to stop words/phrases and informative words.
",5.1.1 Activity and Entity Metrics,[0],[0]
Serban et al. (2017a) recently proposed a new set of metrics for evaluating dialogue responses for the Ubuntu corpus.,5.1.1 Activity and Entity Metrics,[0],[0]
"It is important to highlight that these metrics have been specifically designed for the Ubuntu corpus and evaluate a generated response with the ground truth response by comparing the coarse level representation of an utterance (such as entities, activities, Ubuntu OS commands).",5.1.1 Activity and Entity Metrics,[0],[0]
"Here is a brief description of each metric:
• Activity: Activity metric compares the activities present in a predicted response with the ground truth response.",5.1.1 Activity and Entity Metrics,[0],[0]
Activity can be thought of as a verb.,5.1.1 Activity and Entity Metrics,[0],[0]
"Thus, all the verbs in a response are mapped to a set of manually identified list of 192 verbs.
",5.1.1 Activity and Entity Metrics,[0],[0]
•,5.1.1 Activity and Entity Metrics,[0],[0]
Entity:,5.1.1 Activity and Entity Metrics,[0],[0]
This compares the technical entities that overlap with the ground truth response.,5.1.1 Activity and Entity Metrics,[0],[0]
"A total of 3115 technical entities is identified using public resources such as Debian package manager APT.
",5.1.1 Activity and Entity Metrics,[0],[0]
•,5.1.1 Activity and Entity Metrics,[0],[0]
"Tense: This measure compares the time tense of ground truth with predicted response.
",5.1.1 Activity and Entity Metrics,[0],[0]
• Cmd:,5.1.1 Activity and Entity Metrics,[0],[0]
"This metric computes accuracy by comparing commands identified in ground truth utterance with a predicted response.
",5.1.1 Activity and Entity Metrics,[0],[0]
"Table 4 compares our model with other recent generative models (Serban et al., 2017a) — LSTM (Shang et al., 2015), HRED (Serban et al., 2016) & VHRED (Serban et al.,",5.1.1 Activity and Entity Metrics,[0],[0]
"2017b).We do not compare our model with Multi-Resolution RNN (MRNN) (Serban et al., 2017a), as MRNN explicitly utilizes the activities and entities during the generation process.",5.1.1 Activity and Entity Metrics,[0],[0]
"In contrast, the proposed EED model and the other models used for comparison are agnostic to the activity and entity information.",5.1.1 Activity and Entity Metrics,[0],[0]
"We use the standard script3 to compute the metrics.
",5.1.1 Activity and Entity Metrics,[0],[0]
"The EED model scores better than generative models on almost all of the metrics, indicating that we generate more informative responses than other state-of-the-art generative based approaches for Ubuntu corpus.",5.1.1 Activity and Entity Metrics,[0],[0]
"The results show that responses associated with similar contexts may contain the activities and entities present in the ground truth response, and thus help in response generation.",5.1.1 Activity and Entity Metrics,[0],[0]
This is discussed further in Section 5.2.,5.1.1 Activity and Entity Metrics,[0],[0]
"Additionally, we compared our proposed EED with a retrieval only baseline.",5.1.1 Activity and Entity Metrics,[0],[0]
"The retrieval baseline achieves an activity F1 score of 4.23 and entity F1 score of 2.72 compared to 4.87 and 2.99 respectively achieved by our method on the Ubuntu corpus.
",5.1.1 Activity and Entity Metrics,[0],[0]
"The Tech Support dataset is not evaluated using the above metrics, since activity and entity information is not available for this dataset.
",5.1.1 Activity and Entity Metrics,[0],[0]
3https://github.com/julianser/Ubuntu-MultiresolutionTools/blob/master/ActEntRepresentation/eval file.sh,5.1.1 Activity and Entity Metrics,[0],[0]
"Embedding metrics (Lowe et al., 2017) were proposed as an alternative to word by word comparison metrics such as BLEU.",5.1.2 Embedding Metrics,[0],[0]
"We use pre-trained Google news word embeddings4 similar to Serban et al. (2017b), for easy reproducibility as these metrics are sensitive to the word embeddings used.",5.1.2 Embedding Metrics,[0],[0]
"The three metrics of interest utilize the word vectors in ground truth response and a predicted response and are discussed below:
• Average: Average word embedding vectors are computed for the candidate response and ground truth.",5.1.2 Embedding Metrics,[0],[0]
The cosine similarity is computed between these averaged embeddings.,5.1.2 Embedding Metrics,[0],[0]
"High similarity gives as indication that ground truth and predicted response have similar words.
",5.1.2 Embedding Metrics,[0],[0]
"• Greedy: Greedy matching score finds the most similar word in predicted response to ground truth response using cosine similarity.
",5.1.2 Embedding Metrics,[0],[0]
"• Extrema: Vector extrema score computes the maximum or minimum value of each dimension of word vectors in candidate response and ground truth.
",5.1.2 Embedding Metrics,[0],[0]
"Of these, the embedding average metric is the most reflective of performance for our setup.",5.1.2 Embedding Metrics,[0],[0]
"The extrema representation, for instance, is very sensitive to text length and becomes ineffective beyond single length sentences(Forgues et al., 2014).",5.1.2 Embedding Metrics,[0],[0]
We use the publicly available script5 for all our computations.,5.1.2 Embedding Metrics,[0],[0]
"As the test outputs for HRED are not available for Technical Support dataset, we use our
4GoogleNews-vectors-negative300.bin from https:// code.google.com/archive/p/word2vec/
5https://github.com/julianser/ hed-dlg-truncated/blob/master/",5.1.2 Embedding Metrics,[0],[0]
"Evaluation/embedding_metrics.py
own implementation of HRED.",5.1.2 Embedding Metrics,[0],[0]
"Table 5 compares our model with HRED, and depicts that our model scores better on all metrics for Technical Support
dataset, and on majority of the metrics for Ubuntu dataset.
",5.1.2 Embedding Metrics,[0],[0]
"We note that the improvement achieved by the
EED model on activity and entity metrics are much more significant than those on embedding metrics.",5.1.2 Embedding Metrics,[0],[0]
"This suggests that the EED model is better able to capture the specific information (objects and actions) present in the conversations.
",5.1.2 Embedding Metrics,[0],[0]
"Finally, we evaluate the diversity of the generated responses for EED against HRED by counting the number of unique tokens, token-pairs and token-triplets present in the generated responses on Ubuntu and Tech Support dataset.",5.1.2 Embedding Metrics,[0],[0]
The results are shown in Table 6.,5.1.2 Embedding Metrics,[0],[0]
"As can be observed, the responses in EED have a larger number of distinct tokens, token-pairs and token-triplets than HRED, and hence, are arguably more diverse.",5.1.2 Embedding Metrics,[0],[0]
"Table 7 presents the responses generated by HRED, VHRED and the proposed EED for a few selected contexts along with the corresponding similar exemplar responses.",5.2 Qualitative Evaluation,[0],[0]
"As can be observed from the table, the responses generated by EED tend to be more specific to the input context as compared to the responses of HRED and VHRED.",5.2 Qualitative Evaluation,[0],[0]
"For example, in conversations 1 and 2 we find that both HRED and VHRED generate simple generic responses whereas EED generates responses with additional information such as the type of disk partition used or a command not working.",5.2 Qualitative Evaluation,[0],[0]
This is also confirmed by the quantitative results obtained using activity and entity metrics in the previous section.,5.2 Qualitative Evaluation,[0],[0]
We further observe that the exemplar responses contain informative words that are utilized by the EED model for generating the responses as highlighted in Table 7.,5.2 Qualitative Evaluation,[0],[0]
"In this work, we propose a deep learning method, Exemplar Encoder Decoder (EED), that given a conversation context uses similar contexts and corresponding responses from training data for generating a response.",6 Conclusions,[0],[0]
We show that by utilizing this information the system is able to outperform state of the art generative models on publicly available Ubuntu dataset.,6 Conclusions,[0],[0]
"We further show improvements achieved by the proposed method on a large collection of technical support conversations.
",6 Conclusions,[0],[0]
"While in this work, we apply the exemplar encoder decoder network on conversational task, the method is generic and could be used with other tasks such as question answering and machine translation.",6 Conclusions,[0],[0]
"In our future work we plan to extend
the proposed method to these other applications.",6 Conclusions,[0],[0]
We are grateful to the anonymous reviewers for their comments that helped in improving the paper.,Acknowledgements,[0],[0]
"In this paper we present the Exemplar Encoder-Decoder network (EED), a novel conversation model that learns to utilize similar examples from training data to generate responses.",abstractText,[0],[0]
Similar conversation examples (context-response pairs) from training data are retrieved using a traditional TF-IDF based retrieval model.,abstractText,[0],[0]
The retrieved responses are used to create exemplar vectors that are used by the decoder to generate the response.,abstractText,[0],[0]
The contribution of each retrieved response is weighed by the similarity of corresponding context with the input context.,abstractText,[0],[0]
We present detailed experiments on two large data sets and find that our method outperforms state of the art sequence to sequence generative models on several recently proposed evaluation metrics.,abstractText,[0],[0]
We also observe that the responses generated by the proposed EED model are more informative and diverse compared to existing state-of-the-art method.,abstractText,[0],[0]
Exemplar Encoder-Decoder for Neural Conversation Generation,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 377–382, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"Training good predictive NLP models typically requires annotated data, but getting professional annotators to build useful data sets is often timeconsuming and expensive.",1 Introduction,[0],[0]
"Snow et al. (2008) showed, however, that crowdsourced annotations can produce similar results to annotations made by experts.",1 Introduction,[0],[0]
"Crowdsourcing services such as Amazon’s Mechanical Turk has since been successfully used for various annotation tasks in NLP (Jha et al., 2010; Callison-Burch and Dredze, 2010).
",1 Introduction,[0],[0]
"However, most applications of crowdsourcing in NLP have been concerned with classification problems, such as document classification and constructing lexica (Callison-Burch and Dredze, 2010).",1 Introduction,[0],[0]
"A large part of NLP problems, however, are structured prediction tasks.",1 Introduction,[0],[0]
"Typically, sequence labeling tasks employ a larger set of labels than classification problems, as well as complex interactions between the annotations.",1 Introduction,[0],[0]
"Disagreement among annotators is therefore potentially higher, and the task of annotating structured data thus harder.
",1 Introduction,[0],[0]
"Only a few recent studies have investigated crowdsourcing sequential tasks; specifically, named entity recognition (Finin et al., 2010; Rodrigues et al., 2013).",1 Introduction,[0],[0]
Results for this are good.,1 Introduction,[0],[0]
"However, named entities typically use only few labels (LOC, ORG, and PER), and the data contains mostly non-entities, so the complexity is manageable.",1 Introduction,[0],[0]
"The question of whether a more linguistically involved structured task like part-of-speech (POS) tagging can be crowdsourced has remained largely unaddressed.1
In this paper, we investigate how well lay annotators can produce POS labels for Twitter data.",1 Introduction,[0],[0]
"In our setup, we present annotators with one word at a time, with a minimal surrounding context (two words to each side).",1 Introduction,[0],[0]
"Our choice of annotating Twitter data is not coincidental: with the shortlived nature of Twitter messages, models quickly lose predictive power (Eisenstein, 2013), and retraining models on new samples of more representative data becomes necessary.",1 Introduction,[0],[0]
Expensive professional annotation may be prohibitive for keeping NLP models up-to-date with linguistic and topical changes on Twitter.,1 Introduction,[0],[0]
"We use a minimum of instructions and require few qualifications.
",1 Introduction,[0],[0]
"Obviously, lay annotation is generally less reliable than professional annotation.",1 Introduction,[0],[0]
It is therefore common to aggregate over multiple annotations for the same item to get more robust annotations.,1 Introduction,[0],[0]
"In this paper we compare two aggregation schemes, namely majority voting (MV) and MACE (Hovy et al., 2013).",1 Introduction,[0],[0]
"We also show how we can use Wiktionary, a crowdsourced lexicon, to filter crowdsourced annotations.",1 Introduction,[0],[0]
"We evaluate the annotations in several ways: (a) by testing their accuracy with respect to a gold standard, (b) by evaluating the performance of POS models trained on
1One of the reviewers alerted us to an unpublished masters thesis, which uses pre-annotation to reduce tagging to fewer multiple-choice questions.",1 Introduction,[0],[0]
"See Related Work section for details.
",1 Introduction,[0],[0]
"377
the annotations across several existing data sets, as well as (c) by applying our models in downstream tasks.",1 Introduction,[0],[0]
"We show that with minimal context and annotation effort, we can produce structured annotations of near-expert quality.",1 Introduction,[0],[0]
"We also show that these annotations lead to better POS tagging models than previous models learned from crowdsourced lexicons (Li et al., 2012).",1 Introduction,[0],[0]
"Finally, we show that models learned from these annotations are competitive with models learned from expert annotations on various downstream tasks.",1 Introduction,[0],[0]
We crowdsource the training section of the data from Gimpel et al. (2011)2 with POS tags.,2 Our Approach,[0],[0]
"We use Crowdflower,3 to collect five annotations for each word, and then find the most likely label for each word among the possible annotations.",2 Our Approach,[0],[0]
See Figure 1 for an example.,2 Our Approach,[0],[0]
"If the correct label is not among the annotations, we are unable to recover the correct answer.",2 Our Approach,[0],[0]
This was the case for 1497 instances in our data (cf.,2 Our Approach,[0],[0]
the token “:” in the example).,2 Our Approach,[0],[0]
"We thus report on oracle score, i.e., the best label sequence that could possibly be found, which is correct except for the missing tokens.",2 Our Approach,[0],[0]
"Note that while we report agreement between the crowdsourced annotations and the crowdsourced annotations, our main evaluations are based on models learned from expert vs. crowdsourced annotations and downstream applications thereof (chunking and NER).",2 Our Approach,[0],[0]
We take care in evaluating our models across different data sets to avoid biasing our evaluations to particular annotations.,2 Our Approach,[0],[0]
"All the data sets used in our experiments are publicly available at http://lowlands.ku.dk/results/.
2http://www.ark.cs.cmu.edu/TweetNLP/ 3http://crowdflower.com",2 Our Approach,[0],[0]
"In order to use the annotations to train models that can be applied across various data sets, i.e., making out-of-sample evaluation possible (see Section 5), we follow Hovy et al. (2014) in using the universal tag set (Petrov et al., 2012) with 12 labels.
",3 Crowdsourcing Sequential Annotation,[0],[0]
Annotators were given a bold-faced word with two words on either side and asked to select the most appropriate tag from a drop down menu.,3 Crowdsourcing Sequential Annotation,[0],[0]
"For each tag, we spell out the name of the syntactic category, and provide a few example words.",3 Crowdsourcing Sequential Annotation,[0],[0]
See Figure 2 for a screenshot of the interface.,3 Crowdsourcing Sequential Annotation,[0],[0]
"Annotators were also told that words can belong to several classes, depending on the context.",3 Crowdsourcing Sequential Annotation,[0],[0]
"No additional guidelines were given.
",3 Crowdsourcing Sequential Annotation,[0],[0]
Only trusted annotators (in Crowdflower: Bronze skills) that had answered correctly on 4 gold tokens (randomly chosen from a set of 20 gold tokens provided by the authors) were allowed to submit annotations.,3 Crowdsourcing Sequential Annotation,[0],[0]
"In total, 177 individual annotators supplied answers.",3 Crowdsourcing Sequential Annotation,[0],[0]
We paid annotators a reward of $0.05 for 10 tokens.,3 Crowdsourcing Sequential Annotation,[0],[0]
"The full data set contains 14,619 tokens.",3 Crowdsourcing Sequential Annotation,[0],[0]
Completion of the task took slightly less than 10 days.,3 Crowdsourcing Sequential Annotation,[0],[0]
Contributors were very satisfied with the task (4.5 on a scale from 1 to 5).,3 Crowdsourcing Sequential Annotation,[0],[0]
"In particular, they felt instructions were clear (4.4/5), and that the pay was reasonable (4.1/5).",3 Crowdsourcing Sequential Annotation,[0],[0]
"After collecting the annotations, we need to aggregate the annotations to derive a single answer for each token.",4 Label Aggregation,[0],[0]
"In the simplest scheme, we choose the majority label, i.e., the label picked by most annotators.",4 Label Aggregation,[0],[0]
"In case of ties, we select the final label at random.",4 Label Aggregation,[0],[0]
"Since this is a stochastic process, we average results over 100 runs.",4 Label Aggregation,[0],[0]
We refer to this as MAJORITY VOTING (MV).,4 Label Aggregation,[0],[0]
Note that in MV we trust all annotators to the same degree.,4 Label Aggregation,[0],[0]
"However, crowdsourcing attracts people with different mo-
tives, and not all of them are equally reliable— even the ones with Bronze level.",4 Label Aggregation,[0],[0]
"Ideally, we would like to factor this into our decision process.
",4 Label Aggregation,[0],[0]
"We use MACE4 (Hovy et al., 2013) as our second scheme to learn both the most likely answer and a competence estimate for each of the annotators.",4 Label Aggregation,[0],[0]
"MACE treats annotator competence and the correct answer as hidden variables and estimates their parameters via EM (Dempster et al., 1977).",4 Label Aggregation,[0],[0]
"We use MACE with default parameter settings to give us the weighted average for each annotated example.
",4 Label Aggregation,[0],[0]
"Finally, we also tried applying the joint learning scheme in Rodrigues et al. (2013), but their scheme requires that entire sequences are annotated by the same annotators, which we don’t have, and it expects BIO sequences, rather than POS tags.
",4 Label Aggregation,[0],[0]
"Dictionaries Decoding tasks profit from the use of dictionaries (Merialdo, 1994; Johnson, 2007; Ravi and Knight, 2009) by restricting the number of tags that need to be considered for each word, also known as type constraints (Täckström et al., 2013).",4 Label Aggregation,[0],[0]
"We follow Li et al. (2012) in including Wiktionary information as type constraints into our decoding: if a word is found in Wiktionary, we disregard all annotations that are not licensed by the dictionary entry.",4 Label Aggregation,[0],[0]
"If the word is not found in Wiktionary, or if none of its annotations is licensed by Wiktionary, we keep the original annotations.",4 Label Aggregation,[0],[0]
"Since we aggregate annotations independently (unlike Viterbi decoding), we basically use Wiktionary as a pre-filtering step, such that MV and MACE only operate on the reduced annotations.",4 Label Aggregation,[0],[0]
Each of the two aggregation schemes above produces a final label sequence ŷ for our training corpus.,5 Experiments,[0],[0]
"We evaluate the resulting annotated data in three ways.
1.",5 Experiments,[0],[0]
We compare ŷ to the available expert annotation on the training data.,5 Experiments,[0],[0]
"This tells us how similar lay annotation is to professional annotation.
2.",5 Experiments,[0],[0]
"Ultimately, we want to use structured annotations for supervised training, where annotation quality influences model performance on held-out test data.",5 Experiments,[0],[0]
"To test this, we train a CRF model (Lafferty et al., 2001) with simple orthographic features and word clusters (Owoputi et al., 2013)
4http://www.isi.edu/publications/ licensed-sw/mace/
on the annotated Twitter data described in Gimpel et al. (2011).",5 Experiments,[0],[0]
"Leaving out the dedicated test set to avoid in-sample bias, we evaluate our models across three data sets: RITTER (the 10% test split of the data in Ritter et al. (2011) used in Derczynski et al. (2013)), the test set from Foster et al. (2011), and the data set described in Hovy et al. (2014).
",5 Experiments,[0],[0]
We will make the preprocessed data sets available to the public to facilitate comparison.,5 Experiments,[0],[0]
"In addition to a supervised model trained on expert annotations, we compare our tagging accuracy with that of a weakly supervised system (Li et al., 2012) re-trained on 400,000 unlabeled tweets to adapt to Twitter, but using a crowdsourced lexicon, namely Wiktionary, to constrain inference.",5 Experiments,[0],[0]
"We use parameter settings from Li et al. (2012), as well as their Wikipedia dump, available from their project website.5
3.",5 Experiments,[0],[0]
"POS tagging is often the first step for further analysis, such as chunking, parsing, etc.",5 Experiments,[0],[0]
We test the downstream performance of the POS models from the previous step on chunking and NER.,5 Experiments,[0],[0]
"We use the models to annotate the training data portion of each task with POS tags, and use them as features in a chunking and NER model.",5 Experiments,[0],[0]
"For both tasks, we train a CRF model on the respective (POS-augmented) training set, and evaluate it on several held-out test sets.",5 Experiments,[0],[0]
"For chunking, we use the test sets from Foster et al. (2011) and Ritter et al. (2011) (with the splits from Derczynski et al. (2013)).",5 Experiments,[0],[0]
"For NER, we use data from Finin et al. (2010) and again Ritter et al. (2011).",5 Experiments,[0],[0]
"For chunking, we follow Sha and Pereira (2003) for the set of features, including token and POS information.",5 Experiments,[0],[0]
"For NER, we use standard features, including POS tags (from the previous experiments), indicators for hyphens, digits, single quotes, upper/lowercase, 3-character prefix and suffix information, and Brown word cluster features6 with 2,4,8,16 bitstring prefixes estimated from a large Twitter corpus (Owoputi et al., 2013).",5 Experiments,[0],[0]
We report macro-averages over all these data sets.,5 Experiments,[0],[0]
Agreement with expert annotators Table 1 shows the accuracy of each aggregation compared to the gold labels.,6 Results,[0],[0]
"The crowdsourced annotations
5https://code.google.com/p/ wikily-supervised-pos-tagger/
6http://www.ark.cs.cmu.edu/TweetNLP/
aggregated using MV agree with the expert annotations in 79.54% of the cases.",6 Results,[0],[0]
"If we pre-filter the data using Wiktionary, the agreement becomes 80.58%.",6 Results,[0],[0]
MACE leads to higher agreement with expert annotations under both conditions (79.89 and 80.75).,6 Results,[0],[0]
"The small difference indicates that annotators are consistent and largely reliable, thus confirming the Bronze-level qualification we required.",6 Results,[0],[0]
"Both schemes cannot recover the correct answer for the 1497 cases where none of the crowdsourced labels matched the gold label, i.e. y /∈ Zi.",6 Results,[0],[0]
"The best possible result either of them could achieve (the oracle) would be matching all but the missing labels, an agreement of 89.63%.
",6 Results,[0],[0]
Most of the cases where the correct label was not among the annotations belong to a small set of confusions.,6 Results,[0],[0]
"The most frequent was mislabeling “:” and “. . .”, both mapped to X. Annotators mostly decided to label these tokens as punctuation (.).",6 Results,[0],[0]
"They also predominantly labeled your, my and this as PRON (for the former two), and a variety of labels for the latter, when the gold label is DET.
",6 Results,[0],[0]
"Effect on POS Tagging Accuracy Usually, we don’t want to match a gold standard, but we rather want to create new annotated training data.",6 Results,[0],[0]
"Crowdsourcing matches our gold standard to about 80%, but the question remains how useful this data is when training models on it.",6 Results,[0],[0]
"After all, inter-annotator agreement among professional an-
notators on this task is only around 90% (Gimpel et al., 2011; Hovy et al., 2014).",6 Results,[0],[0]
"In order to evaluate how much each aggregation scheme influences tagging performance of the resulting model, we train separate models on each scheme’s annotations and test on the same four data sets.",6 Results,[0],[0]
Table 2 shows the results.,6 Results,[0],[0]
Note that the differences between the four schemes are insignificant.,6 Results,[0],[0]
"More importantly, however, POS tagging accuracy using crowdsourced annotations are on average only 2.6% worse than gold using professional annotations.",6 Results,[0],[0]
"On the other hand, performance is much better than the weakly supervised approach by Li et al. (2012), which only relies on a crowdsourced POS lexicon.
",6 Results,[0],[0]
Downstream Performance Table 3 shows the accuracy when using the POS models trained in the previous evaluation step.,6 Results,[0],[0]
Note that we present the average over the two data sets used for each task.,6 Results,[0],[0]
Note also how the Wiktionary constraints lead to improvements in downstream performance.,6 Results,[0],[0]
"In chunking, we see that using the crowdsourced annotations leads to worse performance than using the professional annotations.",6 Results,[0],[0]
"For NER, however, we find that some of the POS taggers trained on aggregated data produce better NER performance than POS taggers trained on expert-annotated gold data.",6 Results,[0],[0]
"Since the only difference between models are the respective POS features, the results suggest that at least for some tasks, POS taggers learned from crowdsourced annotations may be as good as those learned from expert annotations.",6 Results,[0],[0]
"There is considerable work in the literature on modeling answer correctness and annotator competence as latent variables (Dawid and Skene,
1979; Smyth et al., 1995; Carpenter, 2008; Whitehill et al., 2009; Welinder et al., 2010; Yan et al., 2010; Raykar and Yu, 2012).",7 Related Work,[0],[0]
Rodrigues et al. (2013) recently presented a sequential model for this.,7 Related Work,[0],[0]
They estimate annotator competence as latent variables in a CRF model using EM.,7 Related Work,[0],[0]
"They evaluate their approach on synthetic and NER data annotated on Mechanical Turk, showing improvements over the MV baselines and the multi-label model by Dredze et al. (2009).",7 Related Work,[0],[0]
"The latter do not model annotator reliability but rather model label priors by integrating them into the CRF objective, and re-estimating them during learning.",7 Related Work,[0],[0]
"Both require annotators to supply a full sentence, while we use minimal context, which requires less annotator commitment and makes the task more flexible.",7 Related Work,[0],[0]
"Unfortunately, we could not run those models on our data due to label incompatibility and the fact that we typically do not have complete sequences annotated by the same annotators.
",7 Related Work,[0],[0]
Mainzer (2011) actually presents an earlier paper on crowdsourcing POS tagging.,7 Related Work,[0],[0]
"However, it differs from our approach in several ways.",7 Related Work,[0],[0]
It uses the Penn Treebank tag set to annotate Wikipedia data (which is much more canonical than Twitter) via a Java applet.,7 Related Work,[0],[0]
"The applet automatically labels certain categories, and only presents the users with a series of multiple choice questions for the remainder.",7 Related Work,[0],[0]
"This is highly effective, as it eliminates some sources of possible disagreement.",7 Related Work,[0],[0]
"In contrast, we do not pre-label any tokens, but always present the annotators with all labels.",7 Related Work,[0],[0]
We use crowdsourcing to collect POS annotations with minimal context (five-word windows).,8 Conclusion,[0],[0]
"While the performance of POS models learned from this data is still slightly below that of models trained on expert annotations, models learned from aggregations approach oracle performance for POS tagging.",8 Conclusion,[0],[0]
"In general, we find that the use of a dictionary tends to make aggregations more useful, irrespective of aggregation method.",8 Conclusion,[0],[0]
"For some downstream tasks, models using the aggregated POS tags perform even better than models using expert-annotated tags.",8 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for valuable comments and feedback.,Acknowledgments,[0],[0]
"This research is funded by the ERC Starting Grant LOW-
LANDS",Acknowledgments,[0],[0]
No. 313695.,Acknowledgments,[0],[0]
Crowdsourcing lets us collect multiple annotations for an item from several annotators.,abstractText,[0],[0]
"Typically, these are annotations for non-sequential classification tasks.",abstractText,[0],[0]
"While there has been some work on crowdsourcing named entity annotations, researchers have largely assumed that syntactic tasks such as part-of-speech (POS) tagging cannot be crowdsourced.",abstractText,[0],[0]
This paper shows that workers can actually annotate sequential data almost as well as experts.,abstractText,[0],[0]
"Further, we show that the models learned from crowdsourced annotations fare as well as the models learned from expert annotations in downstream tasks.",abstractText,[0],[0]
Experiments with crowdsourced re-annotation of a POS tagging data set,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3275–3284 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3275",text,[0],[0]
Character-level features are an essential part of many Natural Language Processing (NLP) tasks.,1 Introduction,[0],[0]
"These features are for instance used for language modeling (Kim et al., 2016), part-of-speech tagging (Plank et al., 2016) and machine translation (Luong and Manning, 2016).",1 Introduction,[0],[0]
"They are especially useful in the context of part-of-speech and morphological tagging, where for example the suffix -s can easily differentiate plural words from singular words in English or Spanish.
",1 Introduction,[0],[0]
The use of character-level features is not new.,1 Introduction,[0],[0]
"Rule-based taggers were amongst the earliest systems that used character-level features/rules for grammatical tagging (Klein and Simmons, 1963).",1 Introduction,[0],[0]
"Other approaches rely on fixed lists of affixes (Ratnaparkhi, 1996; Toutanova et al., 2003).",1 Introduction,[0],[0]
"Next, these features are used by a tagging model, such
as a rule-based model or statistical model.",1 Introduction,[0],[0]
"Rulebased taggers are transparent models that allow us to easily trace back why the tagger made a certain decision (e.g., Brill (1994)).",1 Introduction,[0],[0]
"Similarly, statistical models are merely a weighted sum of features.
",1 Introduction,[0],[0]
"For example, Brill (1994)’s transformationbased error-driven tagger uses a set of templates to derive rules by fixing errors.",1 Introduction,[0],[0]
"The following rule template:
""Change the most-likely tag X to Y if the last (1,2,3,4) characters of the word are x"",
resulted in the rule:
""Change the tag common noun to plural common noun if the word has suffix -s"".
",1 Introduction,[0],[0]
"Subsequently, whenever the tagger makes a tagging mistake, it is easy to trace back why this happened.",1 Introduction,[0],[0]
"Following the above rule, the word mistress will mistakingly be tagged as a plural common noun while it actually is a common noun1.
",1 Introduction,[0],[0]
"This is in stark contrast with the most recent generation of part-of-speech and morphological taggers which mainly rely on neural networks.
1In Brill (1994), an additional rule encodes an exception to this rule to correctly tag the word mistress.
",1 Introduction,[0],[0]
"Words are split into individual characters and are in general either aggregated using a Bidirectional Long Short-Term Memory network (BiLSTM) (Plank et al., 2016) or Convolutional Neural Network (CNN) (dos Santos and Zadrozny, 2014).",1 Introduction,[0],[0]
"However, it is currently unknown which characterlevel patterns these neural network models learn and whether these patterns coincide with our linguistic knowledge.",1 Introduction,[0],[0]
"Moreover, different neural network architectures are currently only compared quantitatively and lack a qualitative analysis.
",1 Introduction,[0],[0]
"In this paper, we investigate which character patterns neural networks learn and to what extent those patterns comprise any known linguistic rules.",1 Introduction,[0],[0]
"We do this for three morphologically different languages: Finnish, Spanish and Swedish.",1 Introduction,[0],[0]
A Spanish example is shown in Figure 1.,1 Introduction,[0],[0]
"By visualizing the contributions of each character, we observe that the model indeed uses the suffix -s to correctly predict that the word is plural.
",1 Introduction,[0],[0]
"Our main contributions are as follows:
• We show how word-level tagging decisions can be traced back to specific sets of characters and interactions between them.
",1 Introduction,[0],[0]
"• We extend the contextual decomposition method (Murdoch et al., 2018) to CNNs.
",1 Introduction,[0],[0]
"• We quantitatively compare CNN and BiLSTM models in the context of morphological tagging by performing an evaluation on three manually segmented and morphologically annotated corpora.
",1 Introduction,[0],[0]
"• We found out that the studied neural models are able to implicitly discover character patterns that coincide with the same rules linguists use to indicate the morphological function of subword segments.
",1 Introduction,[0],[0]
Our implementation is available online2.,1 Introduction,[0],[0]
"Neural network-based taggers currently outperform statistical taggers in morphological tagging (Heigold et al., 2017) and part-of-speech tagging (Plank et al., 2016) for a wide variety of languages.",2 Related Work,[0],[0]
Character-level features form a crucial part of many of these systems.,2 Related Work,[0],[0]
"Generally, two neural network architectures are considered for aggregating the individual characters: a BiLSTM (Ling
2https://github.com/FredericGodin/ ContextualDecomposition-NLP
et al., 2015; Plank et al., 2016) or a CNN (dos Santos and Zadrozny, 2014; Bjerva et al., 2016; Heigold et al., 2017).",2 Related Work,[0],[0]
"These architectures outperform similar models that use manually defined features (Ling et al., 2015; dos Santos and Zadrozny, 2014).",2 Related Work,[0],[0]
"However, it is still unclear which useful character-level features they have learned.",2 Related Work,[0],[0]
Architectures are compared quantitatively but lack insight into learned patterns.,2 Related Work,[0],[0]
"Moreover, Vania and Lopez (2017) showed in the context of language modeling that training a BiLSTM on ground truth morphological features still yields better results than eight other character-based neural network architectures.",2 Related Work,[0],[0]
"Hence, this raises the question which patterns neural networks learn and whether these patterns coincide with manually-defined linguistic rules.
",2 Related Work,[0],[0]
"While a number of interpretation techniques have been proposed for images (Springenberg et al., 2014; Selvaraju et al., 2017; Shrikumar et al., 2017), these are generally not applicable in the context of NLP where LSTMs are mainly used.",2 Related Work,[0],[0]
"Moreover, gradient-based techniques are not trustworthy when strongly saturating activation functions such as tanh and sigmoid are used (e.g., Li et al. (2016a)).",2 Related Work,[0],[0]
"Hence, current interpretations in NLP are limited to visualizing the magnitude of the LSTM hidden states of each word (Linzen et al., 2016; Radford et al., 2017; Strobelt et al., 2018), removing words (Li et al., 2016b; Kádár et al., 2017) or changing words (Linzen et al., 2016) and measuring the impact, or training surrogate tasks (Adi et al., 2017; Chrupała et al., 2017; Belinkov et al., 2017).",2 Related Work,[0],[0]
These techniques only provide limited local interpretations and do not model fine-grained interactions of groups of inputs or intermediate representations.,2 Related Work,[0],[0]
"In contrast, Murdoch et al. (2018) recently introduced an LSTM interpretation technique called Contextual Decomposition (CD), providing a solution to the aforementioned issues.",2 Related Work,[0],[0]
"We will build upon this interpretation technique and introduce an extension for CNNs, making it possible to compare different neural network architectures within a single interpretation framework.",2 Related Work,[0],[0]
"For visualizing the contributions of character sets, we use the recently introduced Contextual Decomposition (CD) framework, as originally developed for LSTMs (Murdoch et al., 2018), and extend it to
CNNs.",3 Method,[0],[0]
"First, we introduce the concept of CD, followed by the extension for CNNs.",3 Method,[0],[0]
"For details on CD for LSTMs, we refer the reader to the aforementioned paper.",3 Method,[0],[0]
"Finally, we explain how the CD of the final classification layer is done.",3 Method,[0],[0]
"The idea behind CD is that, in the context of character-level decomposition, we can decompose the output value of the network for a certain class into two distinct groups of contributions: (1) contributions originating from a specific character or set of characters within a word and (2) contributions originating from all the other characters within the same word.
",3.1 Contextual decomposition,[0],[0]
"More generally, we can decompose every output value z of every neural network component into a relevant contribution β and an irrelevant contribution γ:
z = β + γ (1)",3.1 Contextual decomposition,[0],[0]
"A CNN typically consist of three components: the convolution itself, an activation function and an optional max-pooling operation.",3.2 Decomposing CNN layers,[0],[0]
"We will discuss each component in the next paragraphs.
",3.2 Decomposing CNN layers,[0],[0]
"Decomposing the convolution Given a sequence of character embeddings x1, ...,xT ∈ Rd1 of length T , we can calculate the convolution of size n of a single filter over the sequence x1:T by applying the following equation to each n-length subsequence {xt+i, i = 0, .., n",3.2 Decomposing CNN layers,[0],[0]
"− 1}, denoted as xt:t+n−1:
zt = n−1∑",3.2 Decomposing CNN layers,[0],[0]
"i=0 Wi · xt+i + b, (2)
with zt ∈ R and where W ∈ Rd1×n and b ∈ R are the weight matrix and bias of the convolutional filter.",3.2 Decomposing CNN layers,[0],[0]
"Wi denotes the i-th column of the weight matrix W .
",3.2 Decomposing CNN layers,[0],[0]
"When we want to calculate the contribution of a subset of characters, where S is the set of corresponding character position indexes and S ⊆ {1, ..., T}, we should decompose the output of the filter zt into three parts:
zt = βt + γt + b. (3)
",3.2 Decomposing CNN layers,[0],[0]
"That is, the relevant contribution βt originating from the selected subset of characters with indexes S, the irrelevant contribution γt originating
from the remaining characters in the sequence, and a bias which is deemed neutral (Murdoch et al., 2018).
",3.2 Decomposing CNN layers,[0],[0]
"This can be achieved by decomposing the convolution itself as follows:
βt = n−1∑ i=0",3.2 Decomposing CNN layers,[0],[0]
"Wi · xt+i (t+ i) ∈ S, (4)
",3.2 Decomposing CNN layers,[0],[0]
γt = n−1∑ i=0 Wi · xt+i (t+ i) /∈,3.2 Decomposing CNN layers,[0],[0]
"S, (5)
Linearizing the activation function After applying a linear transformation to the input, a nonlinearity is typically applied.",3.2 Decomposing CNN layers,[0],[0]
"In CNNs, the ReLU activation function is often used.
",3.2 Decomposing CNN layers,[0],[0]
"In Murdoch et al. (2018), a linearization method for the non-linear activation function f is proposed, based on the differences of partial sums of all N components yi involved in the preactivation sum zt.",3.2 Decomposing CNN layers,[0],[0]
"In other words, we want to split fReLU (zt) =",3.2 Decomposing CNN layers,[0],[0]
"fReLU ( ∑N i=1 yi) into a sum of individual linearized contributions LfReLU (yi), namely fReLU ( ∑N i=1 yi)",3.2 Decomposing CNN layers,[0],[0]
= ∑N i=1 LfReLU (yi).,3.2 Decomposing CNN layers,[0],[0]
"To that end, we compute LfReLU (yk), the linearized contribution of yk as the average difference of partial sums over all possible permutations π1, ..., πMN of all N components yi involved:
Lf (yk) =
1
MN MN∑ i=1",3.2 Decomposing CNN layers,[0],[0]
[f( π−1i (k)∑ l=1 yπi(l))− f( π−1i (k)−1∑ l=1 yπi(l)),3.2 Decomposing CNN layers,[0],[0]
"]
(6)
Consequently, we can decompose the output ct after the activation function as follows:
ct =",3.2 Decomposing CNN layers,[0],[0]
"fReLU (zt) (7)
=",3.2 Decomposing CNN layers,[0],[0]
"fReLU (βz,t + γz,t + b) (8)
=LReLU (βz,t)
+",3.2 Decomposing CNN layers,[0],[0]
"[LReLU (γz,t) + LReLU (b)] (9)
=βc,t + γc,t (10)
",3.2 Decomposing CNN layers,[0],[0]
"Following Murdoch et al. (2018), βc,t contains the contributions that can be directly attributed to the specific set of input indexes S. Hence, the bias b is part of γc,t. Note that, while the decomposition in Eq.",3.2 Decomposing CNN layers,[0],[0]
"(10) is exact in terms of the total sum, the individual attribution to relevant (βc,t) and irrelevant (γc,t) is an approximation, due to the linearization.
",3.2 Decomposing CNN layers,[0],[0]
"Max-pooling over time When applying a fixedsize convolution over a variable-length sequence, the output is again of variable size.",3.2 Decomposing CNN layers,[0],[0]
"Hence, a maxpooling operation is executed over the time dimension, resulting in a fixed-size representation that is independent of the sequence length:
c = max t (ct).",3.2 Decomposing CNN layers,[0],[0]
"(11)
Instead of applying a max operation over the βc,t and γc,t contributions separately, we first determine the position t of the highest ct value and propagate the corresponding βc,t and γc,t values.",3.2 Decomposing CNN layers,[0],[0]
"The final layer is a classification layer, which is the same for a CNN- or LSTM-based architecture.",3.3 Calculating the final contribution scores,[0],[0]
"The probability pj of predicting class j is defined as follows:
pj = eWj ·x+bj∑C i=1",3.3 Calculating the final contribution scores,[0],[0]
"e Wi·x+bi , (12)
in which W ∈ Rd2×C is a weight matrix and Wi the i-th column, x ∈ Rd2 the input, b ∈ Rd2 the bias vector and bi the i-th element, d2 the input vector size and C the total number of classes.
",3.3 Calculating the final contribution scores,[0],[0]
The input x is either the output c of a CNN or h of a LSTM.,3.3 Calculating the final contribution scores,[0],[0]
"Consequently, we can decompose x into β and γ contributions.",3.3 Calculating the final contribution scores,[0],[0]
"In practice, we only consider the preactivation and decompose it as follows:
Wj · x+ bj =Wj · β +Wj · γ + bj .",3.3 Calculating the final contribution scores,[0],[0]
"(13)
Finally, the contribution of a set of characters with indexes S to the final score of class j is equal to Wj · β.",3.3 Calculating the final contribution scores,[0],[0]
The latter score is used throughout the paper for visualizing contributions of sets of characters.,3.3 Calculating the final contribution scores,[0],[0]
"We execute experiments on morphological tagging in three different languages: Finnish, Spanish and Swedish.",4 Experimental Setup,[0],[0]
"We describe the dataset in Section 4.1, whereas model and training details can be found in Section 4.2.",4 Experimental Setup,[0],[0]
"For our experiments, we use the Universal Dependencies 1.4 (UD) dataset (Nivre et al., 2016), which contains morphological features for a large number of sentences.",4.1 Dataset,[0],[0]
"Additionally, we acquired
manually-annotated character-level morphological segmentations and labels for a subset of the test set for three morphological different languages: Finnish, Spanish and Swedish.",4.1 Dataset,[0],[0]
"3
For each language, Silfverberg and Hulden (2017) selected the first non-unique 300 words from the UD test set and manually segmented each word according to the associated lemma and morphological features in the dataset.",4.1 Dataset,[0],[0]
"Whenever possible, they assigned each feature to a specific subset of characters.",4.1 Dataset,[0],[0]
"For example, the Spanish word ""económicas"" is segmented as follows:
• económic : lemma=económico
• a : gender=feminine
• s : number=plural
For our experiments, we are only interested in word/feature pairs for which a feature can be assigned to a specific subset of characters.",4.1 Dataset,[0],[0]
"Hence, we filter the test set on those specific word/feature pairs.",4.1 Dataset,[0],[0]
"In the above example, we have two word/feature pairs.",4.1 Dataset,[0],[0]
"This resulted in 278, 340 and 137 word/feature pairs for Finnish, Spanish and Swedish, respectively.",4.1 Dataset,[0],[0]
"Using the same procedure, we selected relevant feature classes, resulting in 12, 6 and 9 feature classes for Finnish, Spanish and Swedish, respectively.4 For each class, when a feature was not available, we introduced an additional Not Applicable (NA) label.
",4.1 Dataset,[0],[0]
We always train and validate on the full UD dataset for which we have filtered out all duplicate words.,4.1 Dataset,[0],[0]
"After that, we perform our analysis on either the UD test set or the annotated subset of manually segmented and annotated words.",4.1 Dataset,[0],[0]
"An overview can be found in Table 1.
",4.1 Dataset,[0],[0]
"3Available online: http://github.com/mpsilfve/ud-segmen ter/commit/5959214d494cbc13e53e1b26650813ff950d2ee3
4Full list available as supplementary material",4.1 Dataset,[0],[0]
"We experiment with both a CNN and BiLSTM architecture for character-level modeling of words.
",4.2 Model,[0],[0]
"At the input, we split every word into characters and add a start-of-word (ˆ) and an end-of-word ($) character.",4.2 Model,[0],[0]
"With every character, we associate a character embedding of size 50.
",4.2 Model,[0],[0]
"Our CNN architecture is inspired by Kim et al. (2016) and consists of a set of filters of varying width, followed by a ReLU activation function and a max-over-time pooling operation.",4.2 Model,[0],[0]
"We adopt their small-CNN parameter choices and have 25, 50, 75, 100, 125 and 150 convolutional filters of size 1, 2, 3, 4, 5 and 6, respectively.",4.2 Model,[0],[0]
"We do not add an additional highway layer.
",4.2 Model,[0],[0]
"For the character-level BiLSTM architecture, we follow the variant used in Plank et al. (2016).",4.2 Model,[0],[0]
"That is, we simply run a BiLSTM over all the characters and concatenate the final forward and backward hidden state.",4.2 Model,[0],[0]
"To obtain a similar number of parameters as the CNN model, we set the hidden state size to 100 units for each LSTM.
",4.2 Model,[0],[0]
"Finally, the word-level representation generated by either the CNN or BiLSTM architecture is classified by a multinomial logistic regression layer.",4.2 Model,[0],[0]
Each morphological class type has a different layer.,4.2 Model,[0],[0]
"We do not take into account context to rule out any influence originating from somewhere other than the characters of the word itself.
",4.2 Model,[0],[0]
"Training details For morphological tagging, we train a single model for all classes at once.",4.2 Model,[0],[0]
We minimize the joint loss by summing the cross-entropy losses of each class.,4.2 Model,[0],[0]
"We orthogonally initialize all weight matrices, except for the embeddings, which are uniformly initialized ([- 0.01;0.01]).",4.2 Model,[0],[0]
"All models are trained using Adam (Kingma and Ba, 2015) with minibatches of size 20 and learning rate 0.001.",4.2 Model,[0],[0]
No specific regularization is used.,4.2 Model,[0],[0]
We select our final model based on early stopping on the validation set.,4.2 Model,[0],[0]
"First, we verify that the CD algorithm works correctly by executing a controlled experiment with a synthetic token.",5 Experiments,[0],[0]
"Next, we quantitatively and qualitatively evaluate on the full test set.",5 Experiments,[0],[0]
"To verify that the contextual decomposition of CNNs works correctly, we devise an experiment
in which we add a synthetic token to a word of a certain class, testing whether this token gets a high attribution score with respect to that specific class.
",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Given a word w and a corresponding binary label t, we add a synthetic character c to the beginning of word w with probability psyn if that word belongs to the class t = 1 and with probability 1 − psyn if that word belongs to the class t = 0.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Consequently, if psyn = 1, the model should predict the label with a 100% accuracy, thus attributing this to the synthetic character c. When psyn = 0.5, the synthetic character does not provide any additional information about the label t, and c should thus have a small contribution.
",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
Experimental setup We train a CNN model on the Spanish dataset and only use words having the morphological label number.,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"This label has two classes plur and sing, and assign those classes to the binary labels zero and one, respectively.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Furthermore, we add a synthetic character to each word with probability psyn, varying psyn from 1 to 0.5 with steps of 0.1.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
We selected 112 unique word/feature pairs from our test set with label sing or plur.,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"While plurality is marked by the suffix s, a variety of suffixes are used for the singular form.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Therefore, we focus on the latter class (t = 1).",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"The corresponding suffix is called the Ground Truth (GT) character.
",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"To measure the impact of psyn, we add a synthetic character to each word of the class t = 1 and
calculate the contribution of each character by using the CD algorithm.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
We run the experiment five times with a different random seed and report the average correct attribution.,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"The attribution is correct if the contribution of the synthetic/GT character is the highest contribution of all character contributions.
",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
Results The results of our evaluation are depicted in Figure 2.,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"When psyn = 1, all words of the class t = 1 contain the synthetic character, and consequently, the accuracy for predicting t = 1 is indeed 100%.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Moreover, the correct prediction is effectively attributed to the synthetic character (‘syn.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
char attr.’,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"in Figure 2 at 100%), with the GT character being deemed irrelevant.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"When the synthetic character probability psyn is lowered, the synthetic character is less trustworthy and the GT character becomes more important (increasing ‘GT char attr.’",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
in Figure 2).,5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Finally, when psyn = 0.5, the synthetic character is equally plausible in both classes.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Hence, the contribution of the synthetic character becomes irrelevant and the model attributes the prediction to other characters.
",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"Consequently, we can conclude that whenever there is a clear character-level pattern, the model learns the pattern and the CD algorithm is able to accurately attribute it to the correct character.",5.1 Validation of contextual decomposition for convolutional neural networks,[0],[0]
"In this section, we measure and analyze (1) which characters contribute most to the final prediction of a certain label and (2) whether those contributions coincide with our linguistic knowledge about a language.",5.2 Evaluation of character-level attribution,[0],[0]
"To that end, we train a model to predict morphological features, given a particular word.",5.2 Evaluation of character-level attribution,[0],[0]
"The model does not have prior word seg-
mentation information and thus needs to discover useful character patterns by itself.",5.2 Evaluation of character-level attribution,[0],[0]
"After training, we calculate the attribution scores of each character pattern within a word with respect to the correct feature class using CD, and evaluate whether this coincides with the ground truth attribution.
",5.2 Evaluation of character-level attribution,[0],[0]
"Model We train CNN and BiLSTM models on Finnish, Spanish and Swedish.",5.2 Evaluation of character-level attribution,[0],[0]
"The average accuracies on the full test set are reported in Table 2.5 As a reference for the trained models’ ability to predict morphological feature classes, we provide a naive baseline, constructed from the majority vote for each feature type.
",5.2 Evaluation of character-level attribution,[0],[0]
"Overall, our neural models yield substantially higher average accuracies than the baseline and perform very similar.",5.2 Evaluation of character-level attribution,[0],[0]
"Consequently, both the CNN and LSTM models learned useful character patterns for predicting the correct morphological feature classes.",5.2 Evaluation of character-level attribution,[0],[0]
"Hence, this raises the question whether these patterns coincide with our linguistic knowledge.
",5.2 Evaluation of character-level attribution,[0],[0]
"Evaluation For each annotated word/feature pair, we measure if the ground truth character se-
5The results of the individual classes are provided as supplementary material.
",5.2 Evaluation of character-level attribution,[0],[0]
ˆ,5.2 Evaluation of character-level attribution,[0],[0]
o,5.2 Evaluation of character-level attribution,[0],[0]
l,5.2 Evaluation of character-level attribution,[0],[0]
"i v a t $ BiLSTM
CNN
-3.2 0",5.2 Evaluation of character-level attribution,[0],[0]
"3.2
(a) Example of Finnish.",5.2 Evaluation of character-level attribution,[0],[0]
"Word (verb): olivat (were), target class: Tense=Past
ˆ g r a t u",5.2 Evaluation of character-level attribution,[0],[0]
"i t a $ BiLSTM
CNN
-2.6 0",5.2 Evaluation of character-level attribution,[0],[0]
"2.6
(b) Example of Spanish.",5.2 Evaluation of character-level attribution,[0],[0]
"Word (adjective): gratuita (free), target: Gender=Fem.
quence corresponds to the set or sequence of characters with the same length within the considered word that has the highest contribution for predicting the correct label for that word.
",5.2 Evaluation of character-level attribution,[0],[0]
"In the first setup, we only compare with character sequences having a consecutive set of characters (denoted cons).",5.2 Evaluation of character-level attribution,[0],[0]
"In the second setup, we compare with any set of characters (denoted all).",5.2 Evaluation of character-level attribution,[0],[0]
"We rank the contributions of each character set and report top one, two, and three scores.",5.2 Evaluation of character-level attribution,[0],[0]
"Because startof-word and end-of-word characters are not annotated in the dataset, we do not consider them part of the candidate character sets.
",5.2 Evaluation of character-level attribution,[0],[0]
"Results The aggregated results for all classes and character sequence lengths are shown in Fig-
ure 3.",5.2 Evaluation of character-level attribution,[0],[0]
"In general, we observe that for almost all models and setups, the contextual decomposition attribution coincides with the manually-defined segmentations for at least half of the word/feature pairs.",5.2 Evaluation of character-level attribution,[0],[0]
"When we only consider the top two consecutive sequences (marked as cons), accuracies range from 76% up to 93% for all three languages.",5.2 Evaluation of character-level attribution,[0],[0]
"For Spanish and Swedish, the top two accuracies for character sets (marked as all) are still above 67%, despite the large space of possible character sets, whereas all ground truth patterns are consecutive sequences.",5.2 Evaluation of character-level attribution,[0],[0]
"While the accuracy for Finnish is lower, the top two accuracy is still above 50%.
",5.2 Evaluation of character-level attribution,[0],[0]
"Examples for Finnish, Spanish and Swedish are shown in Figure 4.",5.2 Evaluation of character-level attribution,[0],[0]
"For Finnish, the character with the highest contribution i coincides with the ground truth character for the CNN model.",5.2 Evaluation of character-level attribution,[0],[0]
"This is not the case for the BiLSTM model which focuses on the character v, even though the correct label is predicted.",5.2 Evaluation of character-level attribution,[0],[0]
"For Spanish, both models strongly focus on the ground truth character a for predicting the feminine gender.",5.2 Evaluation of character-level attribution,[0],[0]
"For Swedish, the ground truth character sequence is the suffix or which denotes plurality.",5.2 Evaluation of character-level attribution,[0],[0]
"Given that or consists of two characters, all contributions of character sets of two characters are visualized.",5.2 Evaluation of character-level attribution,[0],[0]
"As can be seen, the most important set of two characters is {o,r} for the CNN and {k,r} for the BiLSTM model.",5.2 Evaluation of character-level attribution,[0],[0]
"However, {o,r} is the second most important character set for the BiLSTM model.",5.2 Evaluation of character-level attribution,[0],[0]
"Consequently, the BiLSTM model deemed the interaction between a root and suffix character more important than between two suffix characters.",5.2 Evaluation of character-level attribution,[0],[0]
"In the previous section, we showed that there is a strong relationship between the manually-defined morphological segmentation and the patterns a neural network learns.",5.3 Analysis of learned patterns,[0],[0]
"However, there is still an accuracy gap between the results obtained using consecutive sequences only and results obtained using all possible character sets.",5.3 Analysis of learned patterns,[0],[0]
"Hence, this leads to the question which patterns the neural network focuses on, other than the manually defined patterns we evaluated before.",5.3 Analysis of learned patterns,[0],[0]
"To that end, for each of the three languages, we selected a morphological class of interest and evaluated for all words in the full UD test set that were assigned to that class what the most important character set of length one, two and three was.",5.3 Analysis of learned patterns,[0],[0]
"In other words, we evaluated for each word for which the class was cor-
rectly predicted, which character set had the highest positive contribution towards predicting that class.",5.3 Analysis of learned patterns,[0],[0]
"The results can be found in Table 3.
",5.3 Analysis of learned patterns,[0],[0]
"Finnish In Finnish, adding the suffix i to a verb, transforms it in the past tense.",5.3 Analysis of learned patterns,[0],[0]
"Sometimes the character s is added, resulting in the suffix si.",5.3 Analysis of learned patterns,[0],[0]
The latter is a frequently used bigram pattern by the CNN but less by the BiLSTM.,5.3 Analysis of learned patterns,[0],[0]
"The BiLSTM combines the suffix i with another suffix vat which denotes third person plural in the character pattern iv_t.
Spanish While there is no single clear-cut rule for the Spanish gender, in general the suffix a denotes the feminine gender in adjectives.",5.3 Analysis of learned patterns,[0],[0]
"However, there exist many nouns that are feminine but do not have the suffix a. Teschner and Russell (1984) identify d, and ión as typical endings of feminine nouns, which our models identified too as for example ad$ or ió/sió.
",5.3 Analysis of learned patterns,[0],[0]
"Swedish In Swedish, there exist four suffixes for creating a plural form: or, ar, (e)r and n. Both models identified the suffix or.",5.3 Analysis of learned patterns,[0],[0]
"However, similar to Finnish, multiple suffixes are merged.",5.3 Analysis of learned patterns,[0],[0]
"In Swedish, the suffix na only occurs together with one of the first three plural suffixes.",5.3 Analysis of learned patterns,[0],[0]
"Hence, both models correctly identified this pattern as an important pattern for predicting the class number=plural, rather than the linguistically-defined pattern.",5.3 Analysis of learned patterns,[0],[0]
"In the previous section, the pattern a$ showed to be the most important pattern in 34% of the correctly-predicted feminine Spanish words in our dataset.",5.4 Interactions of learned patterns,[0],[0]
"However, there exist many words that end with the character a that are not feminine.",5.4 Interactions of learned patterns,[0],[0]
For example the third person singular form of the verb gustar is gusta.,5.4 Interactions of learned patterns,[0],[0]
"Hence, this raises the question if the model will classify gusta wrongly as feminine or correctly as NA.",5.4 Interactions of learned patterns,[0],[0]
"As an illustration of the applicability of CD for morphological analysis, we will study this case in more detail.
",5.4 Interactions of learned patterns,[0],[0]
"From the full UD test set, we selected all words that end with the character a and that do not belong to the class gender=feminine.",5.4 Interactions of learned patterns,[0],[0]
"Using the Spanish CNN model, we predicted the gender class for each word and divided the words into two groups: predicted as feminine and predicted as not-feminine (_NA_ or masculine).",5.4 Interactions of learned patterns,[0],[0]
The resulted in 44 and 199 words.,5.4 Interactions of learned patterns,[0],[0]
"Next, for each word in both groups we calculated the most positively and negatively contributing character set out of all possible character sets of any length within the considered word, using the CD algorithm.",5.4 Interactions of learned patterns,[0],[0]
"We compared the contribution scores in both groups using a Kruskal-Wallis significance test.6 While no significant (p < 0.05) difference could be found between the positive contributions of both groups (p=1.000), a borderline significant difference could be found between the negative
6The full statistical analysis is provided as supplementary material.
contributions of words predicted as feminine and words predicted as not-feminine (p=0.070).
",5.4 Interactions of learned patterns,[0],[0]
"Consequently, the CNN model’s classification decision is based on finding enough negative evidence to counteract the positive evidence found in the pattern a$, which CD was able to uncover.
",5.4 Interactions of learned patterns,[0],[0]
A visualization of this interaction is shown in Figure 5 for the word gusta.,5.4 Interactions of learned patterns,[0],[0]
"While the positive evidence is the strongest for the class feminine, the model identifies the verb stem gust as negative evidence which ultimately leads to the correct final prediction NA.",5.4 Interactions of learned patterns,[0],[0]
"While neural network-based models are part of many NLP systems, little is understood on how they handle the input data.",6 Conclusion,[0],[0]
"We investigated how specific character sequences at the input of a neural network model contribute to word-level tagging decisions at the output, and if those contributions follow linguistically interpretable rules.
",6 Conclusion,[0],[0]
"First, we presented an analysis and visualization technique to decompose the output of CNN models into separate input contributions, based on the principles outlined by Murdoch et al. (2018) for LSTMs.",6 Conclusion,[0],[0]
This allowed us then to quantitatively and qualitatively compare the character-level patterns the CNNs and BiLSTMs learned for the task of morphological tagging.,6 Conclusion,[0],[0]
"We showed that these patterns generally coincide with the morphological segments as defined by linguists for three morphologically different languages, but that sometimes other linguistically plausible patterns are learned.",6 Conclusion,[0],[0]
"Finally, we showed that our CD algorithm for CNNs is able to explain why the model made a wrong or correct prediction.
",6 Conclusion,[0],[0]
"By visualizing the contributions of each input unit or combinations thereof, we believe that much can be learned on how a neural network handles
the input data, why it makes certain decisions, or even for debugging neural network models.",6 Conclusion,[0],[0]
The authors would like to thank the anonymous reviewers and members of IDLab for their valuable feedback.,Acknowledgments,[0],[0]
"FG would like to thank Kim Bettens for helping out with the statistical analysis.
",Acknowledgments,[0],[0]
"The research activities as described in this paper were funded by Ghent University, imec, Flanders Innovation & Entrepreneurship (VLAIO), the Fund for Scientific Research-Flanders (FWOFlanders), and the European Union.",Acknowledgments,[0],[0]
Character-level features are currently used in different neural network-based natural language processing algorithms.,abstractText,[0],[0]
"However, little is known about the character-level patterns those models learn.",abstractText,[0],[0]
"Moreover, models are often compared only quantitatively while a qualitative analysis is missing.",abstractText,[0],[0]
"In this paper, we investigate which character-level patterns neural networks learn and if those patterns coincide with manually-defined word segmentations and annotations.",abstractText,[0],[0]
"To that end, we extend the contextual decomposition (Murdoch et al., 2018) technique to convolutional neural networks which allows us to compare convolutional neural networks and bidirectional long short-term memory networks.",abstractText,[0],[0]
We evaluate and compare these models for the task of morphological tagging on three morphologically different languages and show that these models implicitly discover understandable linguistic rules.,abstractText,[0],[0]
Explaining Character-Aware Neural Networks for Word-Level Prediction: Do They Discover Linguistic Rules?,title,[0],[0]
"It is now well known that modern convolutional neural networks (e.g. Krizhevsky et al. 2012, Simonyan & Zisserman 2015, He et al. 2016, Szegedy et al. 2016) can achieve remarkable performance on large-scale image databases, e.g. ImageNet (Deng et al. 2009) and Places 365 (Zhou et al. 2017), but it is really dissatisfying to see the vast amounts of data, computing time and power consumption that are necessary to train deep networks.",1. Introduction,[0],[0]
"Fortunately, such convolutional networks, once trained on a large database, can be refined to solve related but different visual tasks by means of transfer learning, using fine-tuning (Yosinski et al. 2014, Simonyan & Zisserman 2015).
",1. Introduction,[0],[0]
"Some form of knowledge is believed to be extracted by
1Sorbonne universités, Université de technologie de Compiègne, CNRS, Heudiasyc, UMR 7253, Compiègne, France.",1. Introduction,[0],[0]
"Correspondence to: Xuhong LI <xuhong.li@hds.utc.fr>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
learning from the large-scale database of the source task and this knowledge is then transferred to the target task by initializing the network with the pre-trained parameters.,1. Introduction,[0],[0]
"However, we will show in the experimental section that some parameters may be driven far away from their initial values during fine-tuning.",1. Introduction,[0],[0]
"This leads to important losses of the initial knowledge that is assumed to be relevant for the targeted problem.
",1. Introduction,[0],[0]
"In order to help preserve the knowledge embedded in the initial network, we consider a series of other parameter regularization methods during fine-tuning.",1. Introduction,[0],[0]
"We argue that the standard L2 regularization, which drives the parameters towards the origin, is not adequate in the framework of transfer learning, where the initial values provide a more sensible reference point than the origin.",1. Introduction,[0],[0]
"This simple modification keeps the original control of overfitting, by constraining the effective search space around the initial solution, while encouraging committing to the acquired knowledge.",1. Introduction,[0],[0]
"We show that it has noticeable effects in inductive transfer learning scenarios.
",1. Introduction,[0],[0]
"This paper copes with the inconsistency that still prevails in transfer learning scenarios, where the model is initialized with some parameters, while the abuse of L2 regularization encourages departing from these initial values.",1. Introduction,[0],[0]
"We thus advocate for a coherent parameter regularization approach, where the pre-trained model is both used as the starting point of the optimization process and as the reference in the penalty that encodes an explicit inductive bias.",1. Introduction,[0],[0]
This type of penalty will be designated with SP to recall that they encourage similarity with the starting point of the fine-tuning process.,1. Introduction,[0],[0]
"We evaluate regularizers based on the L2, Lasso and Group-Lasso penalties, which can freeze some individual parameters, or groups of parameters, to the pre-trained parameters.",1. Introduction,[0],[0]
Fisher information is also taken into account when we test L2-SP and Group-Lasso-SP approaches.,1. Introduction,[0],[0]
Our experiments indicate that all tested parameter regularization methods using the pre-trained parameters as a reference get an edge over the standard L2 weight decay approach.,1. Introduction,[0],[0]
We eventually recommend using L2-SP as the standard baseline for solving transfer learning tasks and benchmarking new algorithms.,1. Introduction,[0],[0]
"In this section, we recall the approaches to inductive transfer learning in convolutional networks.",2. Related Work,[0],[0]
We focus on approaches that also encourage similarity (of features or parameters) on different models.,2. Related Work,[0],[0]
Our proposal departs either by the goal pursued or by the type of model used.,2. Related Work,[0],[0]
Regularization has been a means to build shrinkage estimators for decades.,2.1. Shrinking Toward Chosen Parameters,[0],[0]
"Shrinking towards zero is the most common form of shrinkage, but shrinking towards adaptively chosen targets has been around for some time, starting with Stein shrinkage (see e.g. Lehmann & Casella 1998, chapter 5), where it can be related to empirical Bayes arguments.",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"In transfer learning, it has been used in maximum entropy models (Chelba & Acero 2006) or SVM (Yang et al. 2007, Aytar & Zisserman 2011, Tommasi et al. 2014).",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"These approaches were shown to outperform standard L2 regularization with limited labeled data in the target task (Aytar & Zisserman 2011, Tommasi et al. 2014).
",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"These relatives differ from the application to deep networks in several respects, the more important one being that they consider a fixed representation, where transfer learning aims at producing similar classification parameters in that space, that is, similar classification rules.",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"For deep networks, transfer usually aims at learning similar representations upon which classification parameters will be learned from scratch.",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"Hence, even though the techniques we discuss here are very similar regarding the analytical form of the regularizers, they operate on parameters having a very different role.",2.1. Shrinking Toward Chosen Parameters,[0],[0]
"Regarding transfer learning, we follow here the nomenclature of Pan & Yang (2010), who categorized several types of transfer learning according to domain and task settings during the transfer.",2.2. Transfer Learning for Deep Networks,[0],[0]
"A domain corresponds to the feature space and its distribution, whereas a task corresponds to the label space and its conditional distribution with respect to features.",2.2. Transfer Learning for Deep Networks,[0],[0]
"The initial learning problem is defined on the source domain and source task, whereas the new learning problem is defined on the target domain and the target task.
",2.2. Transfer Learning for Deep Networks,[0],[0]
"In the typology of Pan & Yang, we consider the inductive transfer learning setting, where the target domain is identical to the source domain, and the target task is different from the source task.",2.2. Transfer Learning for Deep Networks,[0],[0]
"We furthermore focus on the case where a vast amount of data was available for training on the source problem, and some limited amount of labeled data is available for solving the target problem.",2.2. Transfer Learning for Deep Networks,[0],[0]
"Under this setting, we aim at improving the performance on the target problem through parameter regularization methods that explicitly encourage the similarity of the solutions to the target and source prob-
lems.",2.2. Transfer Learning for Deep Networks,[0],[0]
"Note that, though we refer here to problems that were formalized or popularized after (Pan & Yang 2010), such as lifelong learning, Pan & Yang’s typology remains valid.",2.2. Transfer Learning for Deep Networks,[0],[0]
Donahue et al. (2014) repurposed features extracted from different layers of the pre-trained AlexNet of Krizhevsky et al. (2012) and plugged them into an SVM or a logistic regression classifier.,2.2.1. REPRESENTATION TRANSFER,[0],[0]
This approach outperformed the state of the art of that time on the Caltech-101 database (Fei-Fei et al. 2006).,2.2.1. REPRESENTATION TRANSFER,[0],[0]
"Later, Yosinski et al. (2014) showed that finetuning the whole AlexNet resulted in better performance than using the network as a static feature extractor.",2.2.1. REPRESENTATION TRANSFER,[0],[0]
"Finetuning pre-trained VGG (Simonyan & Zisserman 2015) on the image classification task of VOC-2012 (Everingham et al. 2010) and Caltech 256 (Griffin et al. 2007) achieved the best results of that time.
",2.2.1. REPRESENTATION TRANSFER,[0],[0]
Ge & Yu (2017) proposed a scheme for selecting a subset of images from the source problem that have similar local features to those in the target problem and then jointly finetuned a pre-trained convolutional network.,2.2.1. REPRESENTATION TRANSFER,[0],[0]
"Besides image classification, many procedures for object detection (Girshick et al. 2014, Redmon et al. 2016, Ren et al. 2015) and image segmentation (Long et al. 2015a, Chen et al. 2017, Zhao et al. 2017) have been proposed relying on fine-tuning to improve over training from scratch.",2.2.1. REPRESENTATION TRANSFER,[0],[0]
"These approaches showed promising results in a challenging transfer learning setup, as going from classification to object detection or image segmentation requires rather heavy modifications of the architecture of the network.
",2.2.1. REPRESENTATION TRANSFER,[0],[0]
The success of transfer learning with convolutional networks relies on the generality of the learned representations that have been constructed from a large database like ImageNet.,2.2.1. REPRESENTATION TRANSFER,[0],[0]
"Yosinski et al. (2014) also quantified the transferability of these pieces of information in different layers, e.g. the first layers learn general features, the middle layers learn highlevel semantic features and the last layers learn the features that are very specific to a particular task.",2.2.1. REPRESENTATION TRANSFER,[0],[0]
That can be also noticed by the visualization of features (Zeiler & Fergus 2014).,2.2.1. REPRESENTATION TRANSFER,[0],[0]
"Overall, the learned representations can be conveyed to related but different domains and the parameters in the network are reusable for different tasks.",2.2.1. REPRESENTATION TRANSFER,[0],[0]
"In lifelong learning (Thrun & Mitchell 1995, Pentina & Lampert 2015), where a series of tasks is learned sequentially by a single model, the knowledge extracted from the previous tasks may be lost as new tasks are learned, resulting in what is known as catastrophic forgetting.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"In order to achieve a good performance on all tasks, Li & Hoiem (2017) proposed to use the outputs of the target examples, computed by the original network on the source task, to de-
fine a learning scheme preserving the memory of the source tasks when training on the target task.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"They also tried to preserve the pre-trained parameters instead of the outputs of examples but they did not obtain interesting results.
",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
Kirkpatrick et al. (2017) developed a similar approach with success.,2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
They get sensible improvements by measuring the sensitivity of the parameters of the network learned on the source data thanks to the Fisher information.,2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"The Fisher information matrix defines a metric in parameter space that is used in their regularizer to preserve the representation learned on the source data, thereby retaining the knowledge acquired on the previous tasks.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"This scheme, named elastic weight consolidation, was shown to avoid forgetting, but fine-tuning with plain stochastic gradient descent was more effective than elastic weight consolidation for learning new tasks.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"Hence, elastic weight consolidation may be thought as being inadequate for transfer learning, where performance is only measured on the target task.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"We will show that this conclusion is not appropriate in typical transfer learning scenarios with few target examples.
",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"In domain adaptation (Long et al. 2015b), where the target domain differs from the source domain whereas the target task is identical to the source task and no (or few) target examples are labeled, most approaches are searching for a common representation space for source and target domains to reduce domain shift.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
Rozantsev et al. (2016) proposed a parameter regularization scheme for encouraging the similarity of the representations of the source and the target domains.,2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"Their regularizer encourages similar source and target parameters, up to a linear transformation.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"Still in domain adaptation, besides vision, encouraging similar parameters in deep networks has been proposed in speaker adaptation problems (Liao 2013, Ochiai et al. 2014) and neural machine translation (Barone et al. 2017), where it proved to be helpful.
",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"The L2-SP regularizer was used independently by Grachten & Chacón (2017) for transfer in vision application, but where they used a random reinitialization of parameters.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"For convex optimization problems, this is equivalent to finetuning with L2-SP, but we are obviously not in that situation.",2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
Grachten & Chacón (2017) conclude that their strategy behaves similarly to learning from scratch.,2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
We will show that using the starting point as an initialization of the fine-tuning process and as the reference in the regularizer improves results consistently upon the standard fine-tuning process.,2.2.2. REGULARIZERS IN RELATED LEARNING SETUPS,[0],[0]
"In this section, we detail the penalties we consider for finetuning.",3. Regularizers for Fine-Tuning,[0],[0]
Parameter regularization is critical when learning from small databases.,3. Regularizers for Fine-Tuning,[0],[0]
"When learning from scratch, regularization is aimed at facilitating optimization and avoiding
overfitting, by implicitly restricting the capacity of the network, that is, the effective size of the search space.",3. Regularizers for Fine-Tuning,[0],[0]
"In transfer learning, the role of regularization is similar, but the starting point of the fine-tuning process conveys information that pertains to the source problem (domain and task).",3. Regularizers for Fine-Tuning,[0],[0]
"Hence, the network capacity has not to be restricted blindly: the pre-trained model sets a reference that can be used to define the functional space effectively explored during finetuning.
",3. Regularizers for Fine-Tuning,[0],[0]
"Since we are using early stopping, fine-tuning a pre-trained model is an implicit form of inductive bias towards the initial solution.",3. Regularizers for Fine-Tuning,[0],[0]
"We explore here how a coherent explicit inductive bias, encoded by a regularization term, affects the training process.",3. Regularizers for Fine-Tuning,[0],[0]
"Section 4 shows that all such schemes get an edge over the standard approaches that either use weight decay or freeze part of the network for preserving the low-level representations that are built in the first layers of the network.
",3. Regularizers for Fine-Tuning,[0],[0]
Let w ∈,3. Regularizers for Fine-Tuning,[0],[0]
Rn be the parameter vector containing all the network parameters that are to be adapted to the target task.,3. Regularizers for Fine-Tuning,[0],[0]
The regularized objective function J̃ that is to be optimized is the sum of the standard objective function J and the regularizer Ω(w).,3. Regularizers for Fine-Tuning,[0],[0]
"In our experiments, J is the negative log-likelihood, so that the criterion J̃ could be interpreted in terms of maximum a posteriori estimation, where the regularizer Ω(w) would act as the log prior of w. More generally, the minimizer of J̃ is a trade-off between the data-fitting term and the regularization term.
L2 penalty The current baseline penalty for transfer learning is the usual L2 penalty, also known as weight decay, since it drives the weights of the network to zero:
Ω(w) = α
2 ‖w‖22 , (1)
where α is the regularization parameter setting the strength of the penalty and ‖·‖p is the p-norm of a vector.
",3. Regularizers for Fine-Tuning,[0],[0]
"L2-SP Let w0 be the parameter vector of the model pretrained on the source problem, acting as the starting point (-SP) in fine-tuning.",3. Regularizers for Fine-Tuning,[0],[0]
"Using this initial vector as the reference in the L2 penalty, we get:
Ω(w) = α
2
∥∥w −w0∥∥2 2 .",3. Regularizers for Fine-Tuning,[0],[0]
"(2)
Typically, the transfer to a target task requires some modifications of the network architecture used for the source task, such as on the last layer used for predicting the outputs.",3. Regularizers for Fine-Tuning,[0],[0]
"Then, there is no one-to-one mapping between w and w0, and we use two penalties: one for the part of the target network that shares the architecture of the source network, denoted wS , the other one for the novel part, denoted wS̄ .
",3. Regularizers for Fine-Tuning,[0],[0]
"The compound penalty then becomes:
Ω(w) = α
2 ∥∥wS −w0S∥∥22 + β2 ‖wS̄‖22 .",3. Regularizers for Fine-Tuning,[0],[0]
"(3) L2-SP-Fisher Elastic weight consolidation (Kirkpatrick et al. 2017) was proposed to avoid catastrophic forgetting in the setup of lifelong learning, where several tasks should be learned sequentially.",3. Regularizers for Fine-Tuning,[0],[0]
"In addition to preserving the initial parameter vector w0, it consists in using the estimated Fisher information to define the distance between wS and w0S .",3. Regularizers for Fine-Tuning,[0],[0]
"More precisely, it relies on the diagonal of the Fisher information matrix, resulting in the following penalty:
Ω(w) = α
2 ∑ j∈S F̂jj ( wj − w0j )2 + β 2 ‖wS̄‖ 2 2 , (4)
where F̂jj is the estimate of the jth diagonal element of the Fisher information matrix.",3. Regularizers for Fine-Tuning,[0],[0]
"It is computed as the average of the squared Fisher’s score on the source problem, using the inputs of the source data:
F̂jj = 1
m m∑ i=1 K∑ k=1 fk(x (i);w0) ( ∂ ∂wj log fk(x (i);w0) )2 ,
where the outer average estimates the expectation with respect to inputs x and the inner weighted sum is the estimate of the conditional expectation of outputs given input x(i), with outputs drawn from a categorical distribution of parameters (f1(x(i);w), . . .",3. Regularizers for Fine-Tuning,[0],[0]
", fk(x(i);w), . . .",3. Regularizers for Fine-Tuning,[0],[0]
", fK(x(i);w)).
",3. Regularizers for Fine-Tuning,[0],[0]
"L1-SP We also experiment the L1 variant of L2-SP:
Ω(w) = α ∥∥wS",3. Regularizers for Fine-Tuning,[0],[0]
−w0S∥∥1 + β2 ‖wS̄‖22 .,3. Regularizers for Fine-Tuning,[0],[0]
"(5)
The usual L1 penalty encourages sparsity; here, by using w0S as a reference in the penalty, L
1-SP encourages some components of the parameter vector to be frozen, equal to the pre-trained initial values.",3. Regularizers for Fine-Tuning,[0],[0]
The penalty can thus be thought as intermediate between L2-SP (3) and the strategies consisting in freezing a part of the initial network.,3. Regularizers for Fine-Tuning,[0],[0]
"We explore below other ways of doing so.
",3. Regularizers for Fine-Tuning,[0],[0]
"Group-Lasso-SP (GL-SP) Instead of freezing some individual parameters, we may encourage freezing some groups of parameters corresponding to channels of convolution kernels.",3. Regularizers for Fine-Tuning,[0],[0]
"Formally, we endow the set of parameters with a group structure, defined by a fixed partition of the index set I = {1, . . .",3. Regularizers for Fine-Tuning,[0],[0]
", p}, that is, I = ⋃G g=0 Gg, with Gg ∩ Gh = ∅ for g 6= h.",3. Regularizers for Fine-Tuning,[0],[0]
"In our setup, G0 = S̄, and for g > 0, Gg is the set of fan-in parameters of channel g.",3. Regularizers for Fine-Tuning,[0],[0]
"Let pg denote the cardinality of group g, and wGg ∈ Rpg be the vector (wj)j∈Gg .",3. Regularizers for Fine-Tuning,[0],[0]
"Then, the GL-SP penalty is:
Ω(w) = α G∑",3. Regularizers for Fine-Tuning,[0],[0]
g=1 sg ∥∥∥wGg −w0Gg∥∥∥,3. Regularizers for Fine-Tuning,[0],[0]
"2 + β 2 ‖wS̄‖ 2 2 , (6)
where w0G0 = w 0 S̄ 4 = 0, and,",3. Regularizers for Fine-Tuning,[0],[0]
"for g > 0, sg is a predefined constant that may be used to balance the different cardinalities of groups.",3. Regularizers for Fine-Tuning,[0],[0]
"In our experiments, we used sg = p 1/2 g .
",3. Regularizers for Fine-Tuning,[0],[0]
"Our implementation of Group-Lasso-SP can freeze feature extractors at any depth of the convolutional network, to preserve the pre-trained feature extractors as a whole instead of isolated pre-trained parameters.",3. Regularizers for Fine-Tuning,[0],[0]
"The group Gg of size pg = hg × wg × dg gathers all the parameters of a convolution kernel of height hg, width wg, and depth dg.",3. Regularizers for Fine-Tuning,[0],[0]
"This grouping is done at each layer of the network, for each output channel, so that the group index g corresponds to two indexes in the network architecture: the layer index l and the output channel index at layer l.",3. Regularizers for Fine-Tuning,[0],[0]
"If we have cl such channels at layer l, we have a total of G = ∑ l cl groups.
",3. Regularizers for Fine-Tuning,[0],[0]
Group-Lasso-SP-Fisher (GL-SP-Fisher),3. Regularizers for Fine-Tuning,[0],[0]
"Following the idea of L2-SP-Fisher, the Fisher version of GL-SP is:
Ω(w) = α G∑ g=1 sg ( ∑ j∈Gg F̂jj ( wj − w0j )2 )1/2 + β 2 ‖wG0‖ 2 2 .",3. Regularizers for Fine-Tuning,[0],[0]
We evaluate the aforementioned parameter regularizers on several pairs of source and target tasks.,4. Experiments,[0],[0]
"We use ResNet (He et al. 2016) as our base network, since it has proven its wide applicability on transfer learning tasks.",4. Experiments,[0],[0]
"Conventionally, if the target task is also a classification task, the training process starts by replacing the last layer with a new one, randomly generated, whose size depends on the number of classes in the target task.",4. Experiments,[0],[0]
"For comparing the effect of similarity between the source problem and the target problem on transfer learning, we chose two source databases: ImageNet (Deng et al. 2009) for generic object recognition and Places 365 (Zhou et al. 2017) for scene classification.",4.1. Source and Target Databases,[0],[0]
"Likewise, we have three different databases related to three target problems: Caltech 256 (Griffin et al. 2007) contains different objects for generic object recognition; MIT Indoors 67 (Quattoni & Torralba 2009) consists of 67 indoor scene categories; Stanford Dogs 120 (Khosla et al. 2011) contains images of 120 breeds of dogs; Each target database is split into training and testing sets following the suggestion of their creators (see Table 1 for details).",4.1. Source and Target Databases,[0],[0]
"In addition, we consider two configurations for Caltech 256: 30 or 60 examples randomly drawn from each category for training, and 20 remaining examples for test.",4.1. Source and Target Databases,[0],[0]
Most images in those databases are color images.,4.2. Training Details,[0],[0]
"If not, we create a three-channel image by duplicating the grayscale data.",4.2. Training Details,[0],[0]
"All images are pre-processed: we resize images to 256×256 and subtract the mean activity computed over the training set from each channel, then we adopt random blur, random mirror and random crop to 224×224 for data augmentation.",4.2. Training Details,[0],[0]
The network parameters are regularized as described in Section 3.,4.2. Training Details,[0],[0]
"Cross validation is used for searching the best regularization hyperparameters α and β: α differs across experiments, and β = 0.01 is consistently picked by cross-validation for regularizing the last layer.",4.2. Training Details,[0],[0]
"Figure 1 illustrates that the test accuracy varies smoothly according to the regularization strength, and that there is a sensible benefit in penalizing the last layer (that is, β ≥ 0) for the best α values.",4.2. Training Details,[0],[0]
"When applicable, the Fisher information matrix is estimated on the source database.",4.2. Training Details,[0],[0]
The two source databases (ImageNet or Places 365) yield different estimates.,4.2. Training Details,[0],[0]
"Regarding testing, we use central crops as inputs to compute the classification accuracy.
",4.2. Training Details,[0],[0]
Stochastic gradient descent with momentum 0.9 is used for optimization.,4.2. Training Details,[0],[0]
We run 9000 iterations and divide the learning rate by 10 after 6000 iterations.,4.2. Training Details,[0],[0]
"The initial learning rates are 0.005, 0.01 or 0.02, depending on the tasks.",4.2. Training Details,[0],[0]
Batch size is 64.,4.2. Training Details,[0],[0]
"Then, under the best configuration, we repeat five times the learning process to obtain an average classification accuracy and standard deviation.",4.2. Training Details,[0],[0]
All the experiments are performed with Tensorflow (Abadi et al. 2015).,4.2. Training Details,[0],[0]
"Table 2 displays the results of fine-tuning with L2-SP and L2-SP-Fisher, which are compared to the current baseline of fine-tuning with L2.",4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
We report the average accuracies and their standard deviations on 5 different runs.,4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
"Since we use the same data and the same starting point, runs differ only due to the randomness of stochastic gradient descent and to the weight initialization of the last layer.",4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
"We can observe that L2-SP and L2-SP-Fisher always improve over L2, and that when less training data are available for the target problem, the improvement of L2-SP and L2-SPFisher compared to L2 are more important.",4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
"Meanwhile, no large difference is observed between L2-SP and L2-SPFisher.
",4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
"We can boost the performance and outperform the state of the art (Ge & Yu 2017) in some cases by exploiting more training techniques and post-processing methods, which are described in the supplementary material.",4.3.1. FINE-TUNING FROM A SIMILAR SOURCE,[0],[0]
A comprehensive view of our experimental results is given in Figure 2.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
Each plot corresponds to one of the four target databases listed in Table 1.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"The light red points mark the accuracies of transfer learning when using Places 365 as the source database, whereas the dark blue points correspond to the results obtained with ImageNet.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"As expected, the results
Table 2.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Average classification accuracies (in %) of L2, L2-SP and L2-SP-Fisher on 5 different runs.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"The source database is Places 365 for MIT Indoors 67 and ImageNet for Stanford Dogs 120 and Caltech 256.
","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"MIT Indoors 67 Stanford Dogs 120 Caltech 256 – 30 Caltech 256 – 60 L2 79.6±0.5 81.4±0.2 81.5±0.2 85.3±0.2
L2-SP 84.2±0.3 85.1±0.2 83.5±0.1 86.4±0.2 L2-SP-Fisher 84.0±0.4 85.1±0.2 83.3±0.1 86.0±0.1
of transfer learning are much better when source and target are alike: the scene classification target task MIT Indoor 67 (top left) is better transferred from the scene classification source task Places 365, whereas the object recognition target tasks benefit more from the object recognition source task ImageNet.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
It is however interesting to note that the trends are similar for the two source databases: all the fine-tuning strategies based on penalties using the starting point -SP as a reference perform consistently better than standard finetuning (L2).,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"There is thus a benefit in having an explicit bias towards the starting point, even when the target task is not too similar to the source task.
","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
This benefit is comparable for L2-SP and L2-SP-Fisher penalties; the strategies based on L1 and Group-Lasso penalties behave rather poorly in comparison.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
They are even less accurate than the plain L2 strategy on Caltech 256 – 60 when the source problem is Places 365.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Stochastic gradient
descent does not handle well these penalties whose gradient is discontinuous at the starting point where the optimization starts.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"The stochastic forward-backward splitting algorithm of Duchi & Singer (2009), which is related to proximal methods, leads to substandard results, presumably due to the absence of a momentum term.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"In the end, we used plain stochastic gradient descent on a smoothed version of the penalties eliminating the discontinuities of their gradients, but some instability remains.
","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Finally, the variants using the Fisher information matrix behave like the simpler variants using a Euclidean metric on parameters.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"We believe that this is due to the fact that, contrary to lifelong learning, our objective does not favor solutions that retain accuracy on the source task.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
The metric defined by the Fisher information matrix may thus be less relevant for our actual objective that only relates to the target task.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Table 3 confirms that L2-SP-Fisher is indeed a better approach in the situation of lifelong learning, where accuracies on the source tasks matter.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"It reports the drop in performance when the fine-tuned models are applied on the source task, without any retraining, simply using the original classification layer instead of the classification layer learned for the target task.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
The performance drop is smaller for L2SP-Fisher than for L2-SP.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"In comparison, L2 fine-tuning results in catastrophic forgetting: the performance on the source task is considerably affected by fine-tuning.
4.3.3.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"FINE-TUNING vs. FREEZING THE NETWORK
Freezing the first layers of a network during transfer learning is another way to ensure a very strong inductive bias,
letting less degrees of freedom to transfer learning.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Figure 3 shows that this strategy, which is costly to implement if one looks for the optimal number of layers to be frozen, can improve L2 fine-tuning considerably, but that it is a rather inefficient strategy for L2-SP fine-tuning.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Among all possible choices, L2 fine-tuning with partial freezing is dominated by the plain L2-SP fine-tuning.","4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
Note that L2-SP-Fisher (not displayed) behaves similarly to L2-SP.,"4.3.2. BEHAVIOR ACROSS PENALTIES, SOURCE AND TARGET DATABASES",[0],[0]
"Among all -SP methods, L2-SP and L2-SP-Fisher always reach a better accuracy on the target task.",4.4. Analysis and Discussion,[0],[0]
"We expected L2SP-Fisher to outperform L2-SP, since Fisher information helps in lifelong learning, but there is no significant difference between the two options.",4.4. Analysis and Discussion,[0],[0]
"Since L2-SP is simpler than L2-SP-Fisher, we recommend the former, and we focus on the analysis of L2-SP, although most of the analysis and the discussion would also apply to L2-SP-Fisher.",4.4. Analysis and Discussion,[0],[0]
"The -SP penalties introduce no extra parameters, and they only increase slightly the computational burden.",4.4.1. COMPUTATIONAL EFFICIENCY,[0],[0]
L2-SP increases the number of floating point operations required for a learning step of ResNet-101 by less than 1%.,4.4.1. COMPUTATIONAL EFFICIENCY,[0],[0]
"Hence, at a negligible computational cost, we can obtain significant improvements in classification accuracy, and no additional cost is experienced at test time.",4.4.1. COMPUTATIONAL EFFICIENCY,[0],[0]
Analytical results are very difficult to obtain in the deep learning framework.,4.4.2. THEORETICAL INSIGHTS,[0],[0]
"Under some (highly) simplifying assumptions, we show in supplementary material that the optimum of the regularized objective function with L2-SP is a compromise between the optimum of the unregularized objective function and the pre-trained parameter vector, precisely an affine combination along the directions of eigenvectors of the Hessian matrix of the unregularized objective function.",4.4.2. THEORETICAL INSIGHTS,[0],[0]
This contrasts with L2 that leads to a compromise between the optimum of the unregularized objective function and the origin.,4.4.2. THEORETICAL INSIGHTS,[0],[0]
"Clearly, searching for a solution in the vicinity of the pre-trained parameters is intuitively much more appealing, since it is the actual motivation for using the pre-trained parameters as the starting point of the fine-tuning process.
",4.4.2. THEORETICAL INSIGHTS,[0],[0]
"Using L2-SP instead of L2 can also be motivated by an analogy with shrinkage estimation (see e.g. Lehmann & Casella 1998, chapter 5).",4.4.2. THEORETICAL INSIGHTS,[0],[0]
"Although it is known that shrinking toward any reference is better than raw fitting, it is also known that shrinking towards a value that is close to the “true parameters” is more effective.",4.4.2. THEORETICAL INSIGHTS,[0],[0]
"The notion of “true parameters” is not readily applicable to deep networks, but the connection with Stein shrinking effect may be inspiring by surveying the literature considering shrinkage towards other references, such as linear subspaces.",4.4.2. THEORETICAL INSIGHTS,[0],[0]
"In particular, it is likely that manifolds of parameters defined from the pre-trained network would provide a more relevant reference than the single parameter value provided by the pre-trained network.",4.4.2. THEORETICAL INSIGHTS,[0],[0]
"We complement our experimental results by an analysis relying on the activations of the hidden units of the network, to provide another view on the differences between L2 and L2SP fine-tuning.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"Activation similarities are easier to interpret than parameter similarities, and they provide a view of the network that is closer to the functional perspective we are actually pursuing.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"Matching individual activations makes sense, provided that the networks slightly differ before and after tuning so that few roles are switched between units or feature maps.
",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"The dependency between the pre-trained and the fine-tuned
activations throughout the network is displayed in Figure 4, with boxplots of the R2 coefficients, gathered layer-wise, of the fine-tuned activations with respect to the original activations.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"This figure shows that, indeed, the roles of units or feature maps have not changed much after L2-SP and L2SP-Fisher fine-tuning.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"The R2 coefficients are very close to 1 on the first layers, and smoothly decrease throughout the network, staying quite high, around 0.6, for L2-SP and L2-SP-Fisher at the greatest depth.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"In contrast, for L2 regularization, some important changes are already visible in the first layers, and the R2 coefficients eventually reach quite low values at the greatest depth.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
"This illustrates in details how the roles of the network units is remarkably retained with L2-SP and L2-SP-Fisher fine-tuning, not only for the first layers of the networks, but also for the last high-level representations before classification.",4.4.3. LAYER-WISE ANALYSIS,[0],[0]
We described and tested simple regularization techniques for inductive transfer learning.,5. Conclusion,[0],[0]
"They all encode an explicit bias towards the solution learned on the source task, resulting in a compromise with the pre-trained parameter that is coherent with the original motivation for fine-tuning.",5. Conclusion,[0],[0]
"All the regularizers evaluated here have been already used for other purposes or in other contexts, but we demonstrated their relevance for inductive transfer learning with deep convolutional networks.
",5. Conclusion,[0],[0]
"We show that a simple L2 penalty using the starting point as a reference, L2-SP, is useful, even if early stopping is used.",5. Conclusion,[0],[0]
This penalty is much more effective than the standard L2 penalty that is commonly used in fine-tuning.,5. Conclusion,[0],[0]
It is also more effective and simpler to implement than the strategy consisting in freezing the first layers of a network.,5. Conclusion,[0],[0]
"We provide
theoretical hints and strong experimental evidence showing that L2-SP retains the memory of the features learned on the source database.",5. Conclusion,[0],[0]
"We thus believe that this simple L2-SP scheme should be considered as the standard baseline in inductive transfer learning, and that future improvements of transfer learning should rely on this baseline.
",5. Conclusion,[0],[0]
"Besides, we tested the effect of more elaborate penalties, based on L1 or Group-L1 norms, or based on Fisher information.",5. Conclusion,[0],[0]
"None of the L1 or Group-L1 options seem to be valuable in the context of inductive transfer learning that we considered here, and using the Fisher information with L2SP does not improve accuracy on the target task.",5. Conclusion,[0],[0]
"Different approaches, which implement an implicit bias at the functional level, alike Li & Hoiem (2017), remain to be tested: being based on a different principle, their value should be assessed in the framework of inductive transfer learning.",5. Conclusion,[0],[0]
"This work was carried out with the supports of the China Scholarship Council and of a PEPS grant through the DESSTOPT project jointly managed by the National Institute of Mathematical Sciences and their Interactions (INSMI) and the Institute of Information Science and their Interactions (INS2I) of the CNRS, France.",Acknowledgments,[0],[0]
We acknowledge the support of NVIDIA Corporation with the donation of GPUs used for this research.,Acknowledgments,[0],[0]
"In inductive transfer learning, fine-tuning pretrained convolutional networks substantially outperforms training from scratch.",abstractText,[0],[0]
"When using finetuning, the underlying assumption is that the pretrained model extracts generic features, which are at least partially relevant for solving the target task, but would be difficult to extract from the limited amount of data available on the target task.",abstractText,[0],[0]
"However, besides the initialization with the pre-trained model and the early stopping, there is no mechanism in fine-tuning for retaining the features learned on the source task.",abstractText,[0],[0]
"In this paper, we investigate several regularization schemes that explicitly promote the similarity of the final solution with the initial model.",abstractText,[0],[0]
"We show the benefit of having an explicit inductive bias towards the initial model, and we eventually recommend a simple L penalty with the pre-trained model being a reference as the baseline of penalty for transfer learning tasks.",abstractText,[0],[0]
Explicit Inductive Bias for Transfer Learning with Convolutional Networks,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2826–2831 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Neural machine translation (NMT) has been rapidly developed in recent years (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015; Tu et al., 2016).",1 Introduction,[0],[0]
"The encoderdecoder architecture is widely employed, in which the encoder summarizes the source sentence into a vector representation, and the decoder generates the target sentence word by word from the vector representation.",1 Introduction,[0],[0]
"Using the encoder-decoder framework as well as gating and attention techniques, it has been shown that the performance of NMT has surpassed the performance of traditional statistical machine translation (SMT) on various language pairs (Luong et al., 2015).
",1 Introduction,[0],[0]
"The continuous vector representation of a symbol encodes multiple dimensions of similarity, equivalent to encoding more than one meaning of
∗Corresponding Author: Zhaopeng Tu
a word.",1 Introduction,[0],[0]
"Consequently, NMT needs to spend a substantial amount of its capacity in disambiguating source and target words based on the context defined by a source sentence (Choi et al., 2016).",1 Introduction,[0],[0]
"Consistency is another critical issue in documentlevel translation, where a repeated term should keep the same translation throughout the whole document (Xiao et al., 2011; Carpuat and Simard, 2012).",1 Introduction,[0],[0]
"Nevertheless, current NMT models still process a documents by translating each sentence alone, suffering from inconsistency and ambiguity arising from a single source sentence.",1 Introduction,[0],[0]
"These problems are difficult to alleviate using only limited intra-sentence context.
",1 Introduction,[0],[0]
"The cross-sentence context, or global context, has proven helpful to better capture the meaning or intention in sequential tasks such as query suggestion (Sordoni et al., 2015) and dialogue modeling (Vinyals and Le, 2015; Serban et al., 2016).",1 Introduction,[0],[0]
"The leverage of global context for NMT, however, has received relatively little attention from the research community.1",1 Introduction,[0],[0]
"In this paper, we propose a cross-sentence context-aware NMT model, which considers the influence of previous source sentences in the same document.2
Specifically, we employ a hierarchy of Recurrent Neural Networks (RNNs) to summarize the cross-sentence context from source-side previous sentences, which deploys an additional documentlevel RNN on top of the sentence-level RNN encoder (Sordoni et al., 2015).",1 Introduction,[0],[0]
"After obtaining the global context, we design several strategies to integrate it into NMT to translate the current sentence:
• Initialization, that uses the history represen1To the best of our knowledge, our work and Jean et al. (2017) are two independently early attempts to model crosssentence context for NMT.
",1 Introduction,[0],[0]
"2In our preliminary experiments, considering target-side history inversely harms translation performance, since it suffers from serious error propagation problems.
2826
tation as the initial state of the encoder, decoder, or both;
• Auxiliary Context, that uses the history representation as static cross-sentence context, which works together with the dynamic intrasentence context produced by an attention model, to good effect.
",1 Introduction,[0],[0]
"• Gating Auxiliary Context, that adds a gate to Auxiliary Context, which decides the amount of global context used in generating the next target word at each step of decoding.
",1 Introduction,[0],[0]
"Experimental results show that the proposed initialization and auxiliary context (w/ or w/o gating) mechanisms significantly improve translation performance individually, and combining them achieves further improvement.",1 Introduction,[0],[0]
"Given a source sentence xm to be translated, we consider its K previous sentences in the same document as cross-sentence context C = {xm−K , ...,xm−1}.",2 Approach,[0],[0]
"In this section, we first model C, which is then integrated into NMT.",2 Approach,[0],[0]
"As shown in Figure 1, we summarize the representation of C in a hierarchical way:
Sentence RNN For a sentence xk in C, the sentence RNN reads the corresponding words {x1,k, ..., xn,k, . . .",2.1 Summarizing Global Context,[0],[0]
", xN,k}",2.1 Summarizing Global Context,[0],[0]
"sequentially and updates its hidden state:
hn,k = f(hn−1,k, xn,k) (1)
where f(·) is an activation function, and hn,k is the hidden state at time n. The last state hN,k stores order-sensitive information about all the words in xk, which is used to represent the summary of the whole sentence, i.e. Sk ≡",2.1 Summarizing Global Context,[0],[0]
"hN,k.",2.1 Summarizing Global Context,[0],[0]
"After processing
each sentence in C, we can obtain all sentencelevel representations, which will be fed into document RNN.
",2.1 Summarizing Global Context,[0],[0]
"Document RNN It takes as input the sequence of the above sentence-level representations {S1, ..., Sk, ..., SK} and computes the hidden state as:
hk = f(hk−1, Sk) (2)
where hk is the recurrent state at time k, which summarizes the previous sentences that have been processed to the position",2.1 Summarizing Global Context,[0],[0]
"k. Similarly, we use the last hidden state to represent the summary of the global context, i.e. D ≡ hK .",2.1 Summarizing Global Context,[0],[0]
"We propose three strategies to integrate the history representation D into NMT:
Initialization We useD to initialize either NMT encoder, NMT decoder or both.",2.2 Integrating Global Context into NMT,[0],[0]
"For encoder, we useD as the initialization state rather than all-zero states as in the standard NMT (Bahdanau et al., 2015).",2.2 Integrating Global Context into NMT,[0],[0]
"For decoder, we rewrite the calculation of the initial hidden state s0 = tanh(WshN ) as s0 = tanh(WshN +WDD) where hN is the last hidden state in encoder and {Ws,WD} are the corresponding weight metrices.
",2.2 Integrating Global Context into NMT,[0],[0]
"Auxiliary Context In standard NMT, as shown in Figure 2 (a), the decoder hidden state for time i is computed by
si = f(si−1, yi−1, ci) (3)
where yi−1 is the most recently generated target word, and ci is the intra-sentence context summarized by NMT encoder for time i.",2.2 Integrating Global Context into NMT,[0],[0]
"As shown in Figure 2 (b), Auxiliary Context method adds the representation of cross-sentence context D to jointly update the decoding state si:
si = f(si−1, yi−1, ci, D) (4)
",2.2 Integrating Global Context into NMT,[0],[0]
"In this strategy, D serves as an auxiliary information source to better capture the meaning of the source sentence.",2.2 Integrating Global Context into NMT,[0],[0]
Now the gated NMT decoder has four inputs rather than the original three ones.,2.2 Integrating Global Context into NMT,[0],[0]
"The concatenation [ci, D], which embeds both intraand cross-sentence contexts, can be fed to the decoder as a single representation.",2.2 Integrating Global Context into NMT,[0],[0]
"We only need to modify the size of the corresponding parameter matrix for least modification effort.
",2.2 Integrating Global Context into NMT,[0],[0]
Gating Auxiliary Context The starting point for this strategy is an observation: the need for information from the global context differs from step to step during generation of the target words.,2.2 Integrating Global Context into NMT,[0],[0]
"For example, global context is more in demand when generating target words for ambiguous source words, while less by others.",2.2 Integrating Global Context into NMT,[0],[0]
"To this end, we extend auxiliary context strategy by introducing a context gate (Tu et al., 2017a) to dynamically control the amount of information flowing from the auxiliary global context at each decoding step, as shown in Figure 2 (c).
",2.2 Integrating Global Context into NMT,[0],[0]
"Intuitively, at each decoding step i, the context gate looks at decoding environment (i.e., si, yi−1, and ci), and outputs a number between 0 and 1 for each element in D, where 1 denotes “completely transferring this” while 0 denotes “completely ignoring this”.",2.2 Integrating Global Context into NMT,[0],[0]
"The global context vector D is then processed with an element-wise multiplication before being fed to the decoder activation layer.
",2.2 Integrating Global Context into NMT,[0],[0]
"Formally, the context gate consists of a sigmoid neural network layer and an element-wise multiplication operation.",2.2 Integrating Global Context into NMT,[0],[0]
"It assigns an element-wise weight to D, computed by
zi = σ(Uzsi−1 +Wzyi−1 + Czci) (5)
",2.2 Integrating Global Context into NMT,[0],[0]
"Here σ(·) is a logistic sigmoid function, and {Wz, Uz, Cz} are the weight matrices, which are trained to learn when to exploit global context to maximize the overall translation performance.",2.2 Integrating Global Context into NMT,[0],[0]
"Note that zi has the same dimensionality asD, and thus each element in the global context vector has its own weight.",2.2 Integrating Global Context into NMT,[0],[0]
"Accordingly, the decoder hidden state is updated by
si = f(si−1, yi−1, ci, zi ⊗D) (6)",2.2 Integrating Global Context into NMT,[0],[0]
We carried out experiments on Chinese–English translation task.,3.1 Setup,[0],[0]
"As the document information is necessary when selecting the previous sentences, we collect all LDC corpora that contain document boundary.",3.1 Setup,[0],[0]
The training corpus consists of 1M sentence pairs extracted from LDC corpora3 with 25.4M Chinese words and 32.4M English words.,3.1 Setup,[0],[0]
"We chose the NIST05 (MT05) as our development set, and NIST06 (MT06) and NIST08",3.1 Setup,[0],[0]
(MT08) as test sets.,3.1 Setup,[0],[0]
"We used case-insensitive BLEU score (Papineni et al., 2002) as our evaluation metric, and sign-test (Collins et al., 2005) for calculating statistical significance.
",3.1 Setup,[0],[0]
"We implemented our approach on top of an open source attention-based NMT model, Nematus4 (Sennrich and Haddow, 2016; Sennrich et al., 2017).",3.1 Setup,[0],[0]
"We limited the source and target vocabularies to the most frequent 35K words in Chinese and English, covering approximately 97.1% and 99.4% of the data in the two languages respectively.",3.1 Setup,[0],[0]
We trained each model on sentences of length up to 80 words in the training data with early stopping.,3.1 Setup,[0],[0]
"The word embedding dimension was 600, the hidden layer size was 1000, and the batch size was 80.",3.1 Setup,[0],[0]
"All our models considered the previous three sentences (i.e., K = 3) as crosssentence context.
",3.1 Setup,[0],[0]
"3The LDC corpora indexes are: 2003E07, 2003E14, 2004T07, 2005E83, 2005T06, 2006E24, 2006E34, 2006E85, 2006E92, 2007E87, 2007E101, 2007T09, 2008E40, 2008E56, 2009E16, 2009E95.
4Available at https://github.com/EdinburghNLP/nematus.",3.1 Setup,[0],[0]
Table 1 shows the translation performance in terms of BLEU score.,3.2 Results,[0],[0]
"Clearly, the proposed approaches significantly outperforms baseline in all cases.
",3.2 Results,[0],[0]
"Baseline (Rows 1-2) NEMATUS significantly outperforms Moses – a commonly used phrasebased SMT system (Koehn et al., 2007), by 2.3 BLEU points on average, indicating that it is a strong NMT baseline system.",3.2 Results,[0],[0]
"It is consistent with the results in (Tu et al., 2017b) (i.e., 26.93 vs. 29.41) on training corpora of similar scale.
",3.2 Results,[0],[0]
"Initialization Strategy (Rows 3-5) Initenc and Initdec improve translation performance by around +1.0 and +1.3 BLEU points individually, proving the effectiveness of warm-start with crosssentence context.",3.2 Results,[0],[0]
"Combining them achieves a further improvement.
",3.2 Results,[0],[0]
Auxiliary Context Strategies (Rows 6-7) The gating auxiliary context strategy achieves a significant improvement of around +1.0 BLEU point over its non-gating counterpart.,3.2 Results,[0],[0]
"This shows that, by acting as a critic, the introduced context gate learns to distinguish the different needs of the global context for generating target words.
",3.2 Results,[0],[0]
Combining (Row 8),3.2 Results,[0],[0]
"Finally, we combine the best variants from the initialization and auxiliary context strategies, and achieve the best performance, improving upon NEMATUS by +2.1 BLEU points.",3.2 Results,[0],[0]
This indicates the two types of strategies are complementary to each other.,3.2 Results,[0],[0]
"We first investigate to what extent the mistranslated errors are fixed by the proposed system.
",3.3 Analysis,[0],[0]
We randomly select 15 documents (about 60 sentences) from the test sets.,3.3 Analysis,[0],[0]
"As shown in Table 2, we count how many related errors: i) are made by NMT (Total), and ii) fixed by our method (Fixed); as well as iii) newly generated (New).",3.3 Analysis,[0],[0]
"About Ambiguity, while we found that 38 words/phrases were translated into incorrect equivalents, 76% of them are corrected by our model.",3.3 Analysis,[0],[0]
"Similarly, we solved 75% of the Inconsistency errors including lexical, tense and definiteness (definite or indefinite articles) cases.",3.3 Analysis,[0],[0]
"However, we also observe that our system brings relative 21% new errors.
",3.3 Analysis,[0],[0]
Case Study Table 3 shows an example.,3.3 Analysis,[0],[0]
The word “腐官” (corrupt officials) is mis-translated as “enemy” by the baseline system.,3.3 Analysis,[0],[0]
"With the help
of the similar word “贪官” in the previous sentence, our approach successfully correct this mistake.",3.3 Analysis,[0],[0]
This demonstrates that cross-sentence context indeed helps resolve certain ambiguities.,3.3 Analysis,[0],[0]
"While our approach is built on top of hierarchical recurrent encoder-decoder (HRED) (Sordoni et al., 2015), there are several key differences which reflect how we have generalized from the original model.",4 Related Work,[0],[0]
"Sordoni et al. (2015) use HRED to summarize a single representation from both the current and previous sentences, which limits itself to (1) it is only applicable to encoder-decoder framework without attention model, (2) the representation can only be used to initialize decoder.",4 Related Work,[0],[0]
"In contrast, we use HRED to summarize the previous sentences alone, which provides additional cross-sentence context for NMT.",4 Related Work,[0],[0]
"Our approach is more flexible at (1) it is applicable to any encoderdecoder frameworks (e.g., with attention), (2) the cross-sentence context can be used to initialize either encoder, decoder or both.
",4 Related Work,[0],[0]
"While both our approach and Serban et al. (2016) use Auxiliary Context mechanism for incorporating cross-sentence context, there are two main differences: 1) we have separate parameters to better control the effects of the cross- and intrasentence contexts, while they only have one parameter matrix to manage the single representation that encodes both contexts; 2) based on the intuition that not every target word generation requires equivalent cross-sentence context, we introduce a context gate (Tu et al., 2017a) to control the amount of information from it, while they don’t.
",4 Related Work,[0],[0]
"At the same time, some researchers propose to use an additional set of an encoder and attention to model more information.",4 Related Work,[0],[0]
"For example, Jean et al. (2017) use it to encode and select part of the previous source sentence for generating each target word.",4 Related Work,[0],[0]
Calixto et al. (2017) utilize global image features extracted using a pre-trained convolutional neural network and incorporate them in NMT.,4 Related Work,[0],[0]
"As additional attention leads to more computational cost, they can only incorporate limited information such as single preceding sentence in Jean et al. (2017).",4 Related Work,[0],[0]
"However, our architecture is free to this limitation, thus we use multiple preceding sentences (e.g. K = 3) in our experiments.
",4 Related Work,[0],[0]
"Our work is also related to multi-source (Zoph and Knight, 2016) and multi-target NMT (Dong
et al., 2015), which incorporate additional source or target languages.",4 Related Work,[0],[0]
"They investigate one-tomany or many-to-one languages translation tasks by integrating additional encoders or decoders into encoder-decoder framework, and their experiments show promising results.",4 Related Work,[0],[0]
"We proposed two complementary approaches to integrating cross-sentence context: 1) a warmstart of encoder and decoder with global context representation, and 2) cross-sentence context serves as an auxiliary information source for updating decoder states, in which an introduced context gate plays an important role.",5 Conclusion and Future Work,[0],[0]
We quantitatively and qualitatively demonstrated that the presented model significantly outperforms a strong attention-based NMT baseline system.,5 Conclusion and Future Work,[0],[0]
"We release the code for these experiments at https:// www.github.com/tuzhaopeng/LC-NMT.
",5 Conclusion and Future Work,[0],[0]
"Our models benefit from larger contexts, and would be possibly further enhanced by other document level information, such as discourse relations.",5 Conclusion and Future Work,[0],[0]
We propose to study such models for full length documents with more linguistic features in future work.,5 Conclusion and Future Work,[0],[0]
This work is supported by the Science Foundation of Ireland (SFI) ADAPT project (Grant No.:13/RC/2106).,Acknowledgments,[0],[0]
The authors also wish to thank the anonymous reviewers for many helpful comments with special thanks to Henry Elder for his generous help on proofreading of this manuscript.,Acknowledgments,[0],[0]
"In translation, considering the document as a whole can help to resolve ambiguities and inconsistencies.",abstractText,[0],[0]
"In this paper, we propose a cross-sentence context-aware approach and investigate the influence of historical contextual information on the performance of neural machine translation (NMT).",abstractText,[0],[0]
"First, this history is summarized in a hierarchical way.",abstractText,[0],[0]
"We then integrate the historical representation into NMT in two strategies: 1) a warm-start of encoder and decoder states, and 2) an auxiliary context source for updating decoder states.",abstractText,[0],[0]
Experimental results on a large Chinese-English translation task show that our approach significantly improves upon a strong attention-based NMT system by up to +2.1 BLEU points.,abstractText,[0],[0]
Exploiting Cross-Sentence Context for Neural Machine Translation,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4253–4262 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4253",text,[0],[0]
"Neural machine translation (NMT) models have advanced the machine translation community in recent years (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014).",1 Introduction,[0],[0]
"NMT models generally consist of two components: an encoder network to summarize the input sentence into sequential representations, based on which a decoder network generates target sentence word by word with an attention model (Bahdanau et al., 2015; Luong et al., 2015).
",1 Introduction,[0],[0]
"Nowadays, advanced NMT models generally implement encoder and decoder as multiple layers, regardless of the specific model architectures such as RNN (Zhou et al., 2016; Wu et al., 2016), CNN (Gehring et al., 2017), or Self-Attention Network (Vaswani et al., 2017; Chen et al., 2018).
∗ Zhaopeng Tu is the corresponding author of the paper.",1 Introduction,[0],[0]
"This work was conducted when Zi-Yi Dou was interning at Tencent AI Lab.
",1 Introduction,[0],[0]
"Several researchers have revealed that different layers are able to capture different types of syntax and semantic information (Shi et al., 2016; Peters et al., 2018; Anastasopoulos and Chiang, 2018).",1 Introduction,[0],[0]
"For example, Shi et al. (2016) find that both local and global source syntax are learned by the NMT encoder and different types of syntax are captured at different layers.
",1 Introduction,[0],[0]
"However, current NMT models only leverage the top layers of encoder and decoder in the subsequent process, which misses the opportunity to exploit useful information embedded in other layers.",1 Introduction,[0],[0]
"Recently, aggregating layers to better fuse semantic and spatial information has proven to be of profound value in computer vision tasks (Huang et al., 2017; Yu et al., 2018).",1 Introduction,[0],[0]
"In natural language processing community, Peters et al. (2018) have proven that simultaneously exposing all layer representations outperforms methods that utilize just the top layer for transfer learning tasks.
",1 Introduction,[0],[0]
"Inspired by these findings, we propose to exploit deep representations for NMT models.",1 Introduction,[0],[0]
"Specifically, we investigate two types of strategies to better fuse information across layers, ranging from layer aggregation to multi-layer attention.",1 Introduction,[0],[0]
"While layer aggregation strategies combine hidden states at the same position across different layers, multi-layer attention allows the model to combine information in different positions.",1 Introduction,[0],[0]
"In addition, we introduce an auxiliary objective to encourage different layers to capture diverse information, which we believe would make the deep representations more meaningful.
",1 Introduction,[0],[0]
We evaluated our approach on two widelyused WMT14 English⇒German and WMT17 Chinese⇒English translation tasks.,1 Introduction,[0],[0]
"We employed TRANSFORMER (Vaswani et al., 2017) as the baseline system since it has proven to outperform other architectures on the two tasks (Vaswani et al., 2017; Hassan et al., 2018).",1 Introduction,[0],[0]
"Experimen-
tal results show that exploiting deep representations consistently improves translation performance over the vanilla TRANSFORMER model across language pairs.",1 Introduction,[0],[0]
It is worth mentioning that TRANSFORMER-BASE with deep representations exploitation outperforms the vanilla TRANSFORMER-BIG model with only less than half of the parameters.,1 Introduction,[0],[0]
"Deep representations have proven to be of profound value in machine translation (Meng et al., 2016; Zhou et al., 2016).",2 Background: Deep NMT,[0],[0]
Multiple-layer encoder and decoder are employed to perform the translation task through a series of nonlinear transformations from the representation of input sequences to final output sequences.,2 Background: Deep NMT,[0],[0]
"The layer can be implemented as RNN (Wu et al., 2016), CNN (Gehring et al., 2017), or Self-Attention Network (Vaswani et al., 2017).",2 Background: Deep NMT,[0],[0]
"In this work, we take the advanced Transformer as an example, which will be used in experiments later.",2 Background: Deep NMT,[0],[0]
"However, we note that the proposed approach is generally applicable to any other type of NMT architectures.
",2 Background: Deep NMT,[0],[0]
"Specifically, the encoder is composed of a stack of L identical layers, each of which has two sublayers.",2 Background: Deep NMT,[0],[0]
"The first sub-layer is a self-attention network, and the second one is a position-wise fully connected feed-forward network.",2 Background: Deep NMT,[0],[0]
"A residual connection (He et al., 2016) is employed around each of the two sub-layers, followed by layer normalization (Ba et al., 2016).",2 Background: Deep NMT,[0],[0]
"Formally, the output of the first sub-layer Cle and the second sub-layer H l e are calculated as
Cle = LN ( ATT(Qle,K l−1 e ,V l−1 e )",2 Background: Deep NMT,[0],[0]
"+H l−1 e ) ,
Hle = LN ( FFN(Cle) +C l e ) , (1)
where ATT(·), LN(·), and FFN(·) are selfattention mechanism, layer normalization, and feed-forward networks with ReLU activation in between, respectively.",2 Background: Deep NMT,[0],[0]
"{Qle,Kl−1e ,Vl−1e } are query, key and value vectors that are transformed from the (l-1)-th encoder layer Hl−1e .
",2 Background: Deep NMT,[0],[0]
The decoder is also composed of a stack of L identical layers.,2 Background: Deep NMT,[0],[0]
"In addition to two sub-layers in each decoder layer, the decoder inserts a third sublayer Dld to perform attention over the output of
the encoder stack HLe :
Cld = LN ( ATT(Qld,K l−1 d ,V l−1 d )",2 Background: Deep NMT,[0],[0]
"+H l−1 d ) ,
Dld = LN ( ATT(Cld,K L e ,V L e )",2 Background: Deep NMT,[0],[0]
"+C l d ) ,
Hld = LN ( FFN(Dld) +D l d ) , (2)
where {Qld,K l−1 d ,V l−1 d } are transformed from the (l-1)-th decoder layer Hl−1d , and {K L e ,V L e } are transformed from the top layer of the encoder.",2 Background: Deep NMT,[0],[0]
"The top layer of the decoder HLd is used to generate the final output sequence.
",2 Background: Deep NMT,[0],[0]
"Multi-layer network can be considered as a strong feature extractor with extended receptive fields capable of linking salient features from the entire sequence (Chen et al., 2018).",2 Background: Deep NMT,[0],[0]
"However, one potential problem about the vanilla Transformer, as shown in Figure 1a, is that both the encoder and decoder stack layers in sequence and only utilize the information in the top layer.",2 Background: Deep NMT,[0],[0]
"While studies have shown deeper layers extract more semantic and more global features (Zeiler and Fergus, 2014; Peters et al., 2018), these do not prove that the last layer is the ultimate representation for any task.",2 Background: Deep NMT,[0],[0]
"Although residual connections have been incorporated to combine layers, these connections have been “shallow” themselves, and only fuse by simple, one-step operations (Yu et al., 2018).",2 Background: Deep NMT,[0],[0]
"We investigate here how to better fuse information across layers for NMT models.
",2 Background: Deep NMT,[0],[0]
"In the following sections, we simplify the equations to Hl = LAYER(Hl−1) for brevity.",2 Background: Deep NMT,[0],[0]
"In this section, we first introduce how to exploit deep representations by simultaneously exposing all of the signals from all layers (Sec 3.1).",3 Proposed Approaches,[0],[0]
"Then, to explicitly encourage different layers to incorporate various information, we propose one way to measure the diversity between layers and add a regularization term to our objective function to maximize the diversity across layers (Sec 3.2).",3 Proposed Approaches,[0],[0]
"To exploit deep representations, we investigate two types of strategies to fuse information across layers, from layer aggregation to multi-layer attention.",3.1 Deep Representations,[0],[0]
"While layer aggregation strategies combine hidden states at the same position across different layers, multi-layer attention allows the model to combine information in different positions.",3.1 Deep Representations,[0],[0]
"While the aggregation strategies are inspired by previous work, there are several differences since we have simplified and generalized from the original model, as described below.",3.1.1 Layer Aggregation,[0],[0]
Dense Connection.,3.1.1 Layer Aggregation,[0],[0]
"The first strategy is to allow all layers to directly access previous layers:
Hl = f(H1, . . .",3.1.1 Layer Aggregation,[0],[0]
",Hl−1).",3.1.1 Layer Aggregation,[0],[0]
"(3)
In this work, we mainly investigate whether densely connected networks work for NMT, which have proven successful in computer vision tasks (Huang et al., 2017).",3.1.1 Layer Aggregation,[0],[0]
"The basic strategy of densely connected networks is to connect each layer to every previous layer with a residual connection:
Hl = Layer(Hl−1) + l−1∑ i=1",3.1.1 Layer Aggregation,[0],[0]
"Hi. (4)
",3.1.1 Layer Aggregation,[0],[0]
Figure 1b illustrates the idea of this approach.,3.1.1 Layer Aggregation,[0],[0]
"Our implementation differs from (Huang et al., 2017) in that we use an addition instead of a concatenation operation in order to keep the state size constant.",3.1.1 Layer Aggregation,[0],[0]
"Another reason is that concatenation operation is computationally expensive, while residual connections are more efficient.
",3.1.1 Layer Aggregation,[0],[0]
"While dense connection directly feeds previous layers to the subsequent layers, the following mechanisms maintain additional layers to aggregate standard layers, from shallow linear combination, to deep non-linear aggregation.
",3.1.1 Layer Aggregation,[0],[0]
Linear Combination.,3.1.1 Layer Aggregation,[0],[0]
"As shown in Figure 1c, an intuitive strategy is to linearly combine the outputs of all layers:
Ĥ = L∑ l=1",3.1.1 Layer Aggregation,[0],[0]
"WlH l, (5)
",3.1.1 Layer Aggregation,[0],[0]
"where {W1, . . .",3.1.1 Layer Aggregation,[0],[0]
",WL} are trainable matrices.",3.1.1 Layer Aggregation,[0],[0]
"While the strategy is similar in spirit to (Peters et al., 2018), there are two main differences: (1) they use normalized weights while we directly use parameters that could be either positive or negative numbers, which may benefit from more modeling flexibility.",3.1.1 Layer Aggregation,[0],[0]
"(2) they use a scalar that is shared by all elements in the layer states, while we use learnable matrices.",3.1.1 Layer Aggregation,[0],[0]
"The latter offers a more precise control of the combination by allowing the model to be more expressive than scalars (Tu et al., 2017).
",3.1.1 Layer Aggregation,[0],[0]
"We also investigate strategies that iteratively and hierarchically merge layers by incorporating more depth and sharing, which have proven effective for computer vision tasks (Yu et al., 2018).
",3.1.1 Layer Aggregation,[0],[0]
Iterative Aggregation.,3.1.1 Layer Aggregation,[0],[0]
"As illustrated in Figure 1d, iterative aggregation follows the iterated stacking of the backbone architecture.",3.1.1 Layer Aggregation,[0],[0]
"Aggregation begins at the shallowest, smallest scale and then iteratively merges deeper, larger scales.",3.1.1 Layer Aggregation,[0],[0]
"The iterative deep aggregation function I for a series of layers Hl1 = {H1, · · · ,Hl} with increasingly deeper and semantic information is formulated as
Ĥl = I(Hl1) = AGG(H",3.1.1 Layer Aggregation,[0],[0]
"l, Ĥl−1), (6)
where we set Ĥ1 = H1 and AGG(·, ·) is the aggregation function:
AGG(x, y) = LN(FF([x; y])",3.1.1 Layer Aggregation,[0],[0]
+ x+ y).,3.1.1 Layer Aggregation,[0],[0]
"(7)
As seen, in this work, we first concatenate x and y into z =",3.1.1 Layer Aggregation,[0],[0]
"[x; y], which is subsequently fed to a feed-forward network with a sigmoid activation in between.",3.1.1 Layer Aggregation,[0],[0]
Residual connection and layer normalization are also employed.,3.1.1 Layer Aggregation,[0],[0]
"Specifically, both x and y have residual connections to the output.",3.1.1 Layer Aggregation,[0],[0]
"The choice of the aggregation function will be further studied in the experiment section.
",3.1.1 Layer Aggregation,[0],[0]
Hierarchical Aggregation.,3.1.1 Layer Aggregation,[0],[0]
"While iterative aggregation deeply combines states, it may still be insufficient to fuse the layers for its sequential architecture.",3.1.1 Layer Aggregation,[0],[0]
"Hierarchical aggregation, on the other hand, merges layers through a tree structure to preserve and combine feature channels, as shown in Figure 2.",3.1.1 Layer Aggregation,[0],[0]
"The original model proposed by Yu et al. (2018) requires the number of layers to be the power of two, which limits the applicability of these methods to a broader range of NMT architectures (e.g. six layers in (Vaswani et al., 2017)).",3.1.1 Layer Aggregation,[0],[0]
"To solve this problem, we introduce a CNN-like tree with the filter size being two, as shown in Figure 2a.",3.1.1 Layer Aggregation,[0],[0]
"Following (Yu et al., 2018), we first merge aggregation nodes of the same depth for efficiency so that there would be at most one aggregation node for each depth.",3.1.1 Layer Aggregation,[0],[0]
"Then, we further feed the output of an aggregation node back into the backbone as the input to the next sub-tree, instead of only routing intermediate aggregations further up the tree, as shown in Figure 2b.",3.1.1 Layer Aggregation,[0],[0]
"The interaction between aggregation and backbone nodes allows the model to better preserve features.
",3.1.1 Layer Aggregation,[0],[0]
"Formally, each aggregation node Ĥi is calculated as
Ĥi = { AGG(H2i−1,H2i), i = 1 AGG(H2i−1,H2i, Ĥi−1), i = 2, 3
where AGG(H2i−1,H2i) is computed via Eqn. 7, and AGG(H2i−1,H2i, Ĥi−1) is computed as
AGG(x, y, z) = LN(FF([x; y; z])",3.1.1 Layer Aggregation,[0],[0]
"+ x+ y + z).
",3.1.1 Layer Aggregation,[0],[0]
The aggregation node at the top layer ĤL/2 serves as the final output of the network.,3.1.1 Layer Aggregation,[0],[0]
"Partially inspired by Meng et al. (2016), we also propose to introduce a multi-layer attention mechanism into deep NMT models, for more power of
transforming information across layers.",3.1.2 Multi-Layer Attention,[0],[0]
"In other words, for constructing each hidden state in any layer-l, we allow the self-attention model to attend any layers lower than l, instead of just layer l-1:
Cl−1 = ATT(Q l,Kl−1,Vl−1), Cl−2 = ATT(Q l,Kl−2,Vl−2),
. .",3.1.2 Multi-Layer Attention,[0],[0]
".
",3.1.2 Multi-Layer Attention,[0],[0]
Cl−k = ATT(Q,3.1.2 Multi-Layer Attention,[0],[0]
"l,Kl−k,Vl−k),
Cl = AGG(Cl−1, . . .",3.1.2 Multi-Layer Attention,[0],[0]
",C l −k), (8)
where Cl−i is sequential vectors queried from layer",3.1.2 Multi-Layer Attention,[0],[0]
"l-i using a separate attention model, and AGG(·) is similar to the pre-defined aggregation function to transform k vectors {Cl−1, . . .",3.1.2 Multi-Layer Attention,[0],[0]
",Cl−k} to a d-dimension vector, which is subsequently used to construct the encoder and decoder layers via Eqn. 1 and 2 respectively.",3.1.2 Multi-Layer Attention,[0],[0]
"Note that multilayer attention only modifies the self-attention blocks in both encoder and decoder, while does not revises the encoder-decoder attention blocks.",3.1.2 Multi-Layer Attention,[0],[0]
"Intuitively, combining layers would be more meaningful if different layers are able to capture diverse information.",3.2 Layer Diversity,[0],[0]
"Therefore, we explicitly add a regularization term to encourage the diversities between layers:
L = Llikelihood + λLdiversity, (9)
where λ is a hyper-parameter and is set to 1.0 in this paper.",3.2 Layer Diversity,[0],[0]
"Specifically, the regularization term measures the average of the distance between ev-
ery two adjacent layers:
Ldiversity = 1
L− 1 L−1∑ l=1 D(Hl,Hl+1).",3.2 Layer Diversity,[0],[0]
"(10)
HereD(Hl,Hl+1) is the averaged cosine-squared distance between the states in layers",3.2 Layer Diversity,[0],[0]
"Hl = {hl1, . . .",3.2 Layer Diversity,[0],[0]
",hlN} and Hl+1",3.2 Layer Diversity,[0],[0]
"= {h l+1 1 , . . .",3.2 Layer Diversity,[0],[0]
",h l+1 N }:
D(Hl,Hl+1)",3.2 Layer Diversity,[0],[0]
"= 1
N N∑ n=1",3.2 Layer Diversity,[0],[0]
"(1− cos2(hln,hl+1n )).
",3.2 Layer Diversity,[0],[0]
"The cosine-squared distance between two vectors is maximized when two vectors are linearly independent and minimized when two vectors are linearly dependent, which satisfies our goal.1",3.2 Layer Diversity,[0],[0]
Dataset.,4.1 Setup,[0],[0]
"To compare with the results reported by previous work (Gehring et al., 2017; Vaswani et al., 2017; Hassan et al., 2018), we conducted experiments on both Chinese⇒English (Zh⇒En) and English⇒German (En⇒De) translation tasks.",4.1 Setup,[0],[0]
"For the Zh⇒En task, we used all of the available parallel data with maximum length limited to 50, consisting of about 20.62 million sentence pairs.",4.1 Setup,[0],[0]
We used newsdev2017 as the development set and newstest2017 as the test set.,4.1 Setup,[0],[0]
"For the En⇒De task, we trained on the widely-used WMT14 dataset consisting of about 4.56 million sentence pairs.",4.1 Setup,[0],[0]
We used newstest2013 as the development set and newstest2014 as the test set.,4.1 Setup,[0],[0]
"Byte-pair encoding (BPE) was employed to alleviate the Out-of-Vocabulary problem (Sennrich et al., 2016) with 32K merge operations for both language pairs.",4.1 Setup,[0],[0]
"We used 4-gram NIST BLEU score (Papineni et al., 2002) as the evaluation metric, and sign-test (Collins et al., 2005) to test for statistical significance.
Models.",4.1 Setup,[0],[0]
"We evaluated the proposed approaches on advanced Transformer model (Vaswani et al., 2017), and implemented on top of an open-source toolkit – THUMT (Zhang et al., 2017).",4.1 Setup,[0],[0]
"We followed Vaswani et al. (2017) to set the configurations and train the models, and have reproduced
1We use cosine-squared distance instead of cosine distance, since the latter is maximized when two vectors are in opposite directions.",4.1 Setup,[0],[0]
"In such case, the two vectors are in fact linearly dependent, while we aim at encouraging the vectors independent from each other.
",4.1 Setup,[0],[0]
their reported results on the En⇒De task.,4.1 Setup,[0],[0]
The parameters of the proposed models were initialized by the pre-trained model.,4.1 Setup,[0],[0]
"We tried k = 2 and k = 3 for the multi-layer attention model, which allows to attend to the lower two or three layers.
",4.1 Setup,[0],[0]
"We have tested both Base and Big models, which differ at hidden size (512 vs. 1024), filter size (2048 vs. 4096) and the number of attention heads (8 vs. 16).2 All the models were trained on eight NVIDIA P40 GPUs where each was allocated with a batch size of 4096 tokens.",4.1 Setup,[0],[0]
"In consideration of computation cost, we studied model variations with Base model on En⇒De task, and evaluated overall performance with Big model on both Zh⇒En and En⇒De tasks.",4.1 Setup,[0],[0]
Table 1 shows the results on WMT14 En⇒De translation task.,4.2 Results,[0],[0]
"As seen, the proposed approaches improve the translation quality in all cases, although there are still considerable differences among different variations.
",4.2 Results,[0],[0]
"Model Complexity Except for dense connection, all other deep representation strategies introduce new parameters, ranging from 14.7M to 33.6M. Accordingly, the training speed decreases due to more efforts to train the new parameters.",4.2 Results,[0],[0]
"Layer aggregation mechanisms only marginally decrease decoding speed, while multi-layer attention decreases decoding speed by 21% due to an additional attention process for each layer.
",4.2 Results,[0],[0]
Layer Aggregation (Rows 2-5):,4.2 Results,[0],[0]
"Although dense connection and linear combination only marginally improve translation performance, iterative and hierarchical aggregation strategies achieve more significant improvements, which are up to +0.99 BLEU points better than the baseline model.",4.2 Results,[0],[0]
"This indicates that deep aggregations outperform their shallow counterparts by incorporating more depth and sharing, which is consistent with the results in computer vision tasks (Yu et al., 2018).
",4.2 Results,[0],[0]
"Multi-Layer Attention (Rows 6-7): Benefiting from the power of attention models, multi-layer attention model can also significantly outperform baseline, although it only attends to one or two additional layers.",4.2 Results,[0],[0]
"However, increasing the number of lower layers to be attended from k = 2 to
2Here “filter size” refers to the hidden size of the feedforward network in the Transformer model.
",4.2 Results,[0],[0]
"k = 3 only gains marginal improvement, at the cost of slower training and decoding speeds.",4.2 Results,[0],[0]
"In the following experiments, we set set k = 2 for the multi-layer attention model.
",4.2 Results,[0],[0]
Layer Diversity (Rows 8-10): The introduced diversity regularization consistently improves performance in all cases by encouraging different layers to capture diverse information.,4.2 Results,[0],[0]
Our best model outperforms the vanilla Transformer by +1.14 BLEU points.,4.2 Results,[0],[0]
"In the following experiments, we used hierarchical aggregation with diversity regularization (Row 8) as the default strategy.
",4.2 Results,[0],[0]
Main Results Table 2 lists the results on both WMT17 Zh⇒En and WMT14 En⇒De translation tasks.,4.2 Results,[0],[0]
"As seen, exploiting deep represen-
tations consistently improves translation performance across model variations and language pairs, demonstrating the effectiveness and universality of the proposed approach.",4.2 Results,[0],[0]
"It is worth mentioning that TRANSFORMER-BASE with deep representations exploitation outperforms the vanilla TRANSFORMER-BIG model, with only less than half of the parameters.",4.2 Results,[0],[0]
We conducted extensive analysis from different perspectives to better understand our model.,4.3 Analysis,[0],[0]
"All results are reported on the En⇒De task with TRANSFORMER-BASE.
",4.3 Analysis,[0],[0]
"Sentence Length
B LE
U
22
23
24
25
26
27
28
29
30
31
Length of Source Sentence
(0, 10
]
(10 , 2
0]
(20 , 3
0]
(30 , 4
0]
(40 , 5
0] (50 , )
",4.3 Analysis,[0],[0]
"Ours Base
B LE
U
25
26
27
28
29
30
Length of Source Sentence
(0, 15
]
(15 , 3
0]
(30 , 4
5] > 4 5
Ours Base
B LE
U
25
26
27
28
29
30
Length of Source Sentence
(0, 15
]
(15 , 3
0]
(30 , 4
5]",4.3 Analysis,[0],[0]
"> 4 5
Hier.+Div. Hier.",4.3 Analysis,[0],[0]
"Base
Figure 4: BLEU scores on the En⇒De test set with respect to various input sentence lengths.",4.3 Analysis,[0],[0]
“Hier.” denotes hierarchical aggregation and “Div.” denotes diversity regularization.,4.3 Analysis,[0],[0]
"Following Bahdanau et al. (2015) and Tu et al. (2016), we grouped sentences of similar lengths together and computed the BLEU score for each group, as shown in Figure 4.",4.3.1 Length Analysis,[0],[0]
"Generally, the performance of TRANSFORMER-BASE goes up with the increase of input sentence lengths, which is superior to the performance of RNN-based NMT models on long sentences reported by (Bentivogli et al., 2016).",4.3.1 Length Analysis,[0],[0]
"We attribute this to the strength of self-attention mechanism to model global dependencies without regard to their distance.
",4.3.1 Length Analysis,[0],[0]
"Clearly, the proposed approaches outperform the baseline model in all length segments, while there are still considerable differences between the two variations.",4.3.1 Length Analysis,[0],[0]
"Hierarchical aggregation consistently outperforms the baseline model, and the improvement goes up on long sentences.",4.3.1 Length Analysis,[0],[0]
One possible reason is that long sentences indeed require deep aggregation mechanisms.,4.3.1 Length Analysis,[0],[0]
"Introducing diversity regularization further improves performance on most sentences (e.g. ≤ 45), while the improvement degrades on long sentences (e.g. > 45).",4.3.1 Length Analysis,[0],[0]
"We conjecture that complex long sentences may need to store duplicate information across layers, which conflicts with the diversity objective.",4.3.1 Length Analysis,[0],[0]
"Both encoder and decoder are composed of a stack of L layers, which may benefit from the proposed approach.",4.3.2 Effect on Encoder and Decoder,[0],[0]
"In this experiment, we investigated how our models affect the two components, as shown
Model Applied to BLEU Encoder Decoder
BASE N/A N/A 26.13
OURS X × 26.32 × X 26.41 X X 26.69
Table 3:",4.3.2 Effect on Encoder and Decoder,[0],[0]
"Experimental results of applying hierarchical aggregation to different components on En⇒De validation set.
in Table 3.",4.3.2 Effect on Encoder and Decoder,[0],[0]
"Exploiting deep representations of encoder or decoder individually consistently outperforms the vanilla baseline model, and exploiting both components further improves the performance.",4.3.2 Effect on Encoder and Decoder,[0],[0]
These results provide support for the claim that exploiting deep representations is useful for both understanding input sequence and generating output sequence.,4.3.2 Effect on Encoder and Decoder,[0],[0]
"As described in Section 3.1.1, the function of hierarchical layer aggregation is defined as
AGG(x, y, z) = LN(FF([x; y; z])",4.3.3 Impact of Aggregation Choices,[0],[0]
"+ x+ y + z),
where FF(·) is a feed-forward network with a sigmoid activation in between.",4.3.3 Impact of Aggregation Choices,[0],[0]
"In addition, all the input layers {x, y, z} have residual connections to the output.",4.3.3 Impact of Aggregation Choices,[0],[0]
"In this experiment, we evaluated the impact of residual connection options, as well as different choices for the aggregation function, as shown in Table 4.
",4.3.3 Impact of Aggregation Choices,[0],[0]
"Concerning residual connections, if none of the input layers are connected to the output layer (“None”), the performance would decrease.",4.3.3 Impact of Aggregation Choices,[0],[0]
"The translation performance is improved when the output is connected to only the top level of the input layers (“Top”), while connecting to all input layers (“All”) achieves the best performance.",4.3.3 Impact of Aggregation Choices,[0],[0]
"This indi-
cates that cross-layer connections are necessary to avoid the gradient vanishing problem.
",4.3.3 Impact of Aggregation Choices,[0],[0]
"Besides the feed-forward network with sigmoid activation, we also tried two other aggregation functions for FF(·): (1) A feed-forward network with a RELU activation in between; and (2) multihead self-attention layer that constitutes the encoder and decoder layers in the TRANSFORMER model.",4.3.3 Impact of Aggregation Choices,[0],[0]
"As seen, all the three functions consistently improve the translation performance, proving the robustness of the proposed approaches.
",4.3.3 Impact of Aggregation Choices,[0],[0]
"4.4 Visualization of Aggregation
To investigate the impact of diversity regularization, we visualized the exploitation of the input representations for hierarchical aggregation in encoder side, as shown in Figure 5.",4.3.3 Impact of Aggregation Choices,[0],[0]
"Let Hi = {H2i, H2i−1, Ĥ i−1} be the input representations, we calculated the exploitation of the j-th input as
sj =
∑ w∈Wj |w|∑
Hj′∈H { ∑ w′∈Wj′ |w′|} , (11)
where Wj is the parameter matrix associated with the input Hj .",4.3.3 Impact of Aggregation Choices,[0],[0]
The score sj is a rough estimation of the contribution of Hj to the aggregation,4.3.3 Impact of Aggregation Choices,[0],[0]
"Ĥ i.
We have two observations.",4.3.3 Impact of Aggregation Choices,[0],[0]
"First, the model tends to utilize the bottom layer more than the top one, indicating the necessity of fusing information across layers.",4.3.3 Impact of Aggregation Choices,[0],[0]
"Second, using the diversity regularization in Figure 5(b) can encourage each layer to contribute more equally to the aggregation.",4.3.3 Impact of Aggregation Choices,[0],[0]
We hypothesize this is because of the diversity regularization term encouraging the different layers to contain diverse and equally important information.,4.3.3 Impact of Aggregation Choices,[0],[0]
Representation learning is at the core of deep learning.,5 Related Work,[0],[0]
"Our work is inspired by technological advances in representation learning, specifically in the field of deep representation learning and representation interpretation.
",5 Related Work,[0],[0]
"Deep Representation Learning Deep neural networks have advanced the state of the art in various communities, such as computer vision and natural language processing.",5 Related Work,[0],[0]
"One key challenge of training deep networks lies in how to transform information across layers, especially when the network consists of hundreds of layers.
",5 Related Work,[0],[0]
"In response to this problem, ResNet (He et al., 2016) uses skip connections to combine layers by simple, one-step operations.",5 Related Work,[0],[0]
"Densely connected network (Huang et al., 2017) is designed to better propagate features and losses through skip connections that concatenate all the layers in stages.",5 Related Work,[0],[0]
"Yu et al. (2018) design structures iteratively and hierarchically merge the feature hierarchy to better fuse information in a deep fusion.
",5 Related Work,[0],[0]
"Concerning machine translation, Meng et al. (2016) and Zhou et al. (2016) have shown that deep networks with advanced connecting strategies outperform their shallow counterparts.",5 Related Work,[0],[0]
"Due to its simplicity and effectiveness, skip connection becomes a standard component of state-of-the-art NMT models (Wu et al., 2016; Gehring et al., 2017; Vaswani et al., 2017).",5 Related Work,[0],[0]
"In this work, we prove that deep representation exploitation can further improve performance over simply using skip connections.
",5 Related Work,[0],[0]
"Representation Interpretation Several researchers have tried to visualize the representation of each layer to help better understand what information each layer captures (Zeiler and Fergus, 2014; Li et al., 2016; Ding et al., 2017).",5 Related Work,[0],[0]
"Concerning natural language processing tasks, Shi et al. (2016) find that both local and global source syntax are learned by the NMT encoder and different types of syntax are captured at different layers.",5 Related Work,[0],[0]
Anastasopoulos and Chiang (2018) show that higher level layers are more representative than lower level layers.,5 Related Work,[0],[0]
Peters et al. (2018) demonstrate that higher-level layers capture context-dependent aspects of word meaning while lower-level layers model aspects of syntax.,5 Related Work,[0],[0]
"Inspired by these observations, we propose to expose all of these representations to better
fuse information across layers.",5 Related Work,[0],[0]
"In addition, we introduce a regularization to encourage different layers to capture diverse information.",5 Related Work,[0],[0]
"In this work, we propose to better exploit deep representations that are learned by multiple layers for neural machine translation.",6 Conclusion,[0],[0]
"Specifically, the hierarchical aggregation with diversity regularization achieves the best performance by incorporating more depth and sharing across layers and by encouraging layers to capture different information.",6 Conclusion,[0],[0]
"Experimental results on WMT14 English⇒German and WMT17 Chinese⇒English show that the proposed approach consistently outperforms the state-of-theart TRANSFORMER baseline by +0.54 and +0.63 BLEU points, respectively.",6 Conclusion,[0],[0]
"By visualizing the aggregation process, we find that our model indeed utilizes lower layers to effectively fuse the information across layers.
",6 Conclusion,[0],[0]
"Future directions include validating our approach on other architectures such as RNN (Bahdanau et al., 2015) or CNN (Gehring et al., 2017) based NMT models, as well as combining with other advanced techniques (Shaw et al., 2018; Shen et al., 2018; Yang et al., 2018; Li et al., 2018) to further improve the performance of TRANSFORMER.",6 Conclusion,[0],[0]
We thank the anonymous reviewers for their insightful comments.,Acknowledgments,[0],[0]
"Advanced neural machine translation (NMT) models generally implement encoder and decoder as multiple layers, which allows systems to model complex functions and capture complicated linguistic structures.",abstractText,[0],[0]
"However, only the top layers of encoder and decoder are leveraged in the subsequent process, which misses the opportunity to exploit the useful information embedded in other layers.",abstractText,[0],[0]
"In this work, we propose to simultaneously expose all of these signals with layer aggregation and multi-layer attention mechanisms.",abstractText,[0],[0]
"In addition, we introduce an auxiliary regularization term to encourage different layers to capture diverse information.",abstractText,[0],[0]
Experimental results on widely-used WMT14 English⇒German and WMT17 Chinese⇒English translation data demonstrate the effectiveness and universality of the proposed approach.,abstractText,[0],[0]
Exploiting Deep Representations for Neural Machine Translation,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 155–160 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2024",text,[0],[0]
"Neural models are powerful in part due to their ability to learn good representations of raw textual inputs, mitigating the need for extensive task-specific feature engineering (Collobert et al., 2011).",1 Introduction,[0],[0]
"However, a downside of learning from scratch is failing to capitalize on prior linguistic or semantic knowledge, often encoded in existing resources such as ontologies.",1 Introduction,[0],[0]
Such prior knowledge can be particularly valuable when estimating highly flexible models.,1 Introduction,[0],[0]
"In this work, we address how to exploit known relationships between words when training neural models for NLP tasks.
",1 Introduction,[0],[0]
"We propose exploiting the feature-hashing trick, originally proposed as a means of neural network compression (Chen et al., 2015).",1 Introduction,[0],[0]
"Here we instead view the partial parameter sharing induced by feature hashing as a flexible mechanism for tying together network node weights that we believe
to be similar a priori.",1 Introduction,[0],[0]
"In effect, this acts as a regularizer that constrains the model to learn weights that agree with the domain knowledge codified in external resources like ontologies.
",1 Introduction,[0],[0]
"More specifically, as external resources we use Brown clusters (Brown et al., 1992), WordNet (Miller, 1995) and the Unified Medical Language System (UMLS) (Bodenreider, 2004).",1 Introduction,[0],[0]
From these we derive groups of words with similar meaning.,1 Introduction,[0],[0]
We then use feature hashing to share a subset of weights between the embeddings of words that belong to the same semantic group(s).,1 Introduction,[0],[0]
"This forces the model to respect prior domain knowledge, insofar as words similar under a given ontology are compelled to have similar embeddings.
",1 Introduction,[0],[0]
"Our contribution is a novel, simple and flexible method for injecting domain knowledge into neural models via stochastic weight sharing.",1 Introduction,[0],[0]
"Results on seven diverse classification tasks (three sentiment and four biomedical) show that our method consistently improves performance over (1) baselines that fail to capitalize on domain knowledge, and (2) an approach that uses retrofitting (Faruqui et al., 2014) as a preprocessing step to encode domain knowledge prior to training.
155",1 Introduction,[0],[0]
"We incorporate similarity relations codified in existing resources (here derived from Brown clusters, SentiWordNet and the UMLS) as prior knowledge in a Convolutional Neural Network (CNN).1 To achieve this we construct a shared embedding matrix such that words known a priori to be similar are constrained to share some fraction of embedding weights.
",2 Grouped Weight Sharing,[0],[0]
"Concretely, suppose we have N groups of words derived from an external resource.",2 Grouped Weight Sharing,[0],[0]
"Note that one could derive such groups in several ways; e.g., using the synsets in SentiWordNet.",2 Grouped Weight Sharing,[0],[0]
"We denote groups by {g1, g2, ..., gN}.",2 Grouped Weight Sharing,[0],[0]
"Each group is associated with an embedding ggi , which we initialize by averaging the pre-trained embeddings of each word in the group.
",2 Grouped Weight Sharing,[0],[0]
"To exploit both grouped and independent word weights, we adopt a two-channel CNN model (Zhang et al., 2016b).",2 Grouped Weight Sharing,[0],[0]
The embedding matrix of the first channel is initialized with pre-trained word vectors.,2 Grouped Weight Sharing,[0],[0]
We denote this input by Ep ∈ RV×d,2 Grouped Weight Sharing,[0],[0]
(V is the vocabulary size and d the dimension of the word embeddings).,2 Grouped Weight Sharing,[0],[0]
The second channel input matrix is initialized with our proposed weightsharing embedding Es ∈ RV×d.,2 Grouped Weight Sharing,[0],[0]
"Es is initialized by drawing from both Ep and the external resource following the process we describe below.
",2 Grouped Weight Sharing,[0],[0]
"Given an input text sequence of length l, we construct sequence embedding representations Wp ∈",2 Grouped Weight Sharing,[0],[0]
Rl×d,2 Grouped Weight Sharing,[0],[0]
and,2 Grouped Weight Sharing,[0],[0]
Ws ∈,2 Grouped Weight Sharing,[0],[0]
Rl×d using the corresponding embedding matrices.,2 Grouped Weight Sharing,[0],[0]
We then apply independent sets of linear convolution filters on these two matrices.,2 Grouped Weight Sharing,[0],[0]
Each filter will generate a feature map vector v ∈,2 Grouped Weight Sharing,[0],[0]
Rl−h+1 (h is the filter height).,2 Grouped Weight Sharing,[0],[0]
"We perform 1-max pooling over each v, extracting one scalar per feature map.",2 Grouped Weight Sharing,[0],[0]
"Finally, we concatenate scalars from all of the feature maps (from both channels) into a feature vector which is fed to a softmax function to predict the label (Figure 2).
",2 Grouped Weight Sharing,[0],[0]
We initialize Es as follows.,2 Grouped Weight Sharing,[0],[0]
Each row ei ∈ Rd of Es is the embedding of word i. Words may belong to one or more groups.,2 Grouped Weight Sharing,[0],[0]
"A mapping function G(i) retrieves the groups that word i belongs to, i.e., G(i) returns a subset of {g1, g2, ..., gN}, which we denote by {g(i)1 , g (i) 2 ...",2 Grouped Weight Sharing,[0],[0]
"g (i) K }, where K is the number of groups that contain word i. To initialize Es, for each dimension j of each word embedding ei, we use a hash function hi to map
1The idea of sharing weights to reflect known similarity is general and could be applied with other neural architectures.
",2 Grouped Weight Sharing,[0],[0]
(hash) the index j to one of the K group IDs:,2 Grouped Weight Sharing,[0],[0]
"hi : N → {g(i)1 , g (i) 2 ...",2 Grouped Weight Sharing,[0],[0]
g (i) K }.,2 Grouped Weight Sharing,[0],[0]
"Following (Weinberger et al., 2009; Shi et al., 2009), we use a second hash function b to remove bias induced by hashing.",2 Grouped Weight Sharing,[0],[0]
"This is a signing function, i.e., it maps (i, j) tuples to {+1,−1} 2.",2 Grouped Weight Sharing,[0],[0]
"We then set ei,j to the product of ghi(j),j and b(i, j).",2 Grouped Weight Sharing,[0],[0]
h and b are both approximately uniform hash functions.,2 Grouped Weight Sharing,[0],[0]
"Algorithm 1 provides the full initialization procedure.
",2 Grouped Weight Sharing,[0],[0]
"Algorithm 1 Initialization of Es
1: for i in {1, . . .",2 Grouped Weight Sharing,[0],[0]
", V } do 2: {g(i)1 , g (i) 2 , . . .",2 Grouped Weight Sharing,[0],[0]
", g (i) K } := G(i).",2 Grouped Weight Sharing,[0],[0]
"3: for j ∈ {1, . . .",2 Grouped Weight Sharing,[0],[0]
", d} do 4: ei,j := ghi(j),j · b(i, j) 5: end for 6: end for
For illustration, consider Figure 1.",2 Grouped Weight Sharing,[0],[0]
"Here g1 contains three words: good, nice and amazing, while g2 has two words: good and interesting.",2 Grouped Weight Sharing,[0],[0]
"The group embeddings gg1 , gg2 are initialized as averages over the pre-trained embeddings of the words they comprise.",2 Grouped Weight Sharing,[0],[0]
"Here, embedding parameters e1,1 and e2,1 are both mapped to gg1,1, and thus share this value.",2 Grouped Weight Sharing,[0],[0]
"Similarly, e1,3 and e2,3 will share value at gg1,3.",2 Grouped Weight Sharing,[0],[0]
"We have elided the second hash function b from this figure for simplicity.
",2 Grouped Weight Sharing,[0],[0]
"2Empirically, we found that using this signing function does not affect performance.
",2 Grouped Weight Sharing,[0],[0]
"During training, we update Ep as usual using back-propagation (Rumelhart et al., 1986).",2 Grouped Weight Sharing,[0],[0]
We update Es and group embeddings g in a manner similar to Chen et al. (2015).,2 Grouped Weight Sharing,[0],[0]
"In the forward propagation before each training step (mini-batch), we derive the value of ei,j from g:
ei,j := ghi(j),j ∗",2 Grouped Weight Sharing,[0],[0]
"b(i, j) (1)
We use this newly updated ei,j to perform forward propagation in the CNN.
",2 Grouped Weight Sharing,[0],[0]
"During backward propagation, we first compute the gradient of Es, and then we use this to derive the gradient w.r.t gs.",2 Grouped Weight Sharing,[0],[0]
"To do this, for each dimension j in ggk , we aggregate the gradients w.r.t E s whose elements are mapped to this dimension:
∇ggk,j := ∑
(i,j)
∇Esi,j · δhi(j)=gk · b(i, j) (2)
where δhi(j)=gk = 1 when h i(j) = gk, and 0 otherwise.",2 Grouped Weight Sharing,[0],[0]
Each training step involves executing Equations 1 and 2.,2 Grouped Weight Sharing,[0],[0]
"Once the shared gradient is calculated, gradient descent proceeds as usual.",2 Grouped Weight Sharing,[0],[0]
"We update all parameters aside from the shared weights in the standard way.
",2 Grouped Weight Sharing,[0],[0]
The number of parameters in our approach scales linearly with the number of channels.,2 Grouped Weight Sharing,[0],[0]
"But the gradients can actually be back-propagated in a distributed way for each channel, since the convolutional and embedding layers are independent across these.",2 Grouped Weight Sharing,[0],[0]
Thus training time scales approximately linearly with the number of parameters in one channel (if the gradient is back-propagated in a distributed way).,2 Grouped Weight Sharing,[0],[0]
"We use three sentiment datasets: a movie review (MR) dataset (Pang and Lee, 2005)3; a customer review (CR) dataset (Hu and Liu, 2004)4; and an opinion dataset (MPQA) (Wiebe et al., 2005)5.
",3.1 Datasets,[0],[0]
"We also use four biomedical datasets, which concern systematic reviews.",3.1 Datasets,[0],[0]
The task here is to classify published articles describing clinical trials as relevant or not to a well-specified clinical question.,3.1 Datasets,[0],[0]
"Articles deemed relevant are included in
3www.cs.cornell.edu/people/pabo/ movie-review-data/
4www.cs.uic.edu/˜liub/FBS/ sentiment-analysis.html
5mpqa.cs.pitt.edu/corpora/mpqa_corpus/
the corresponding review, which is a synthesis of all pertinent evidence (Wallace et al., 2010).",3.1 Datasets,[0],[0]
"We use data from reviews that concerned: clopidogrel (CL) for cardiovascular conditions (Dahabreh et al., 2013); biomarkers for assessing iron deficiency in anemia (AN) experienced by patients with kidney disease (Chung et al., 2012); statins (ST) (Cohen et al., 2006); and proton beam (PB) therapy (Terasawa et al., 2009).",3.1 Datasets,[0],[0]
"We use SentiWordNet (Baccianella et al., 2010)6 for the sentiment tasks.",3.2 Implementation Details and Baselines,[0],[0]
"SentiWordNet assigns to each synset of wordnet three sentiment scores: positivity, negativity and objectivity, constrained to sum to 1.",3.2 Implementation Details and Baselines,[0],[0]
"We keep only the synsets with positivity or negativity scores greater than 0, i.e., we remove synsets deemed objective.",3.2 Implementation Details and Baselines,[0],[0]
The synsets in SentiWordNet constitute our groups.,3.2 Implementation Details and Baselines,[0],[0]
We also use the Brown clustering algorithm7 on the three sentiment datasets.,3.2 Implementation Details and Baselines,[0],[0]
"We generate 1000 clusters and treat each as a group.
",3.2 Implementation Details and Baselines,[0],[0]
"For the biomedical datasets, we use the Medical Subject Headings (MeSH) terms8 attached to each abstract to classify them.",3.2 Implementation Details and Baselines,[0],[0]
Each MeSH term has a tree number indicating the path from the root in the UMLS.,3.2 Implementation Details and Baselines,[0],[0]
"For example, ‘Alagille Syndrome’ has tree number ‘C06.552.150.125’; periods denote tree splits, numbers are nodes.",3.2 Implementation Details and Baselines,[0],[0]
"We induce groups comprising MeSH terms that share the same first three parent nodes, e.g., all terms with ‘C06.552.150’ as their tree number prefix constitute one group.
",3.2 Implementation Details and Baselines,[0],[0]
We compare our approach to several baselines.,3.2 Implementation Details and Baselines,[0],[0]
"All use pre-trained embeddings to initialize Ep, but we explore several approaches to exploiting Es: (1) randomly initialize Es; (2) initialize Es to reflect the group embedding g, but do not share weights during the training process, i.e., do not constrain their weights to be equal when we perform back-propagation; (3) use linguistic resources to retro-fit (Faruqui et al., 2014) the pretrained embeddings, and use these to initialize Es.",3.2 Implementation Details and Baselines,[0],[0]
"For retro-fitting, we first construct a graph derived from SentiWordNet.",3.2 Implementation Details and Baselines,[0],[0]
Then we run beliefpropagation on the graph to encourage linked words to have similar vectors.,3.2 Implementation Details and Baselines,[0],[0]
"This is a preprocessing step only; we do not impose weight sharing constraints during training.
",3.2 Implementation Details and Baselines,[0],[0]
"6sentiwordnet.isti.cnr.it 7github.com/percyliang/brown-cluster 8www.nlm.nih.gov/bsd/disted/
meshtutorial/
For the sentiment datasets we use three filter heights (3,4,5) for each of the two CNN channels.",3.2 Implementation Details and Baselines,[0],[0]
"For the biomedical datasets, we use only one filter height (1), because the inputs are unstructured MeSH terms.9",3.2 Implementation Details and Baselines,[0],[0]
In both cases we use 100 filters of each unique height.,3.2 Implementation Details and Baselines,[0],[0]
"For the sentiment datasets, we use Google word2vec (Mikolov et al., 2013)10 to initialize Ep.",3.2 Implementation Details and Baselines,[0],[0]
"For the biomedical datasets, we use word2vec trained on biomedical texts (Moen and Ananiadou, 2013)11 to initialize Ep.",3.2 Implementation Details and Baselines,[0],[0]
"For parameter estimation, we use Adadelta (Zeiler, 2012).",3.2 Implementation Details and Baselines,[0],[0]
"Because the biomedical datasets are imbalanced, we use downsampling (Zhang et al., 2016a; Zhang and Wallace, 2015) to effectively train on balanced subsets of the data.
",3.2 Implementation Details and Baselines,[0],[0]
"We developed our approach using the MR sentiment dataset, tuning our approach to constructing groups from the available resources – experiments on other sentiment datasets were run after we finalized the model and hyperparameters.",3.2 Implementation Details and Baselines,[0],[0]
"Similarly, we used the anemia (AN) review as a development set for the biomedical tasks, especially w.r.t.",3.2 Implementation Details and Baselines,[0],[0]
constructing groups from MeSH terms using UMLS.,3.2 Implementation Details and Baselines,[0],[0]
"We replicate each experiment five times (each is a 10-fold cross validation), and report the mean (min, max) across these replications.",4 Results,[0],[0]
"Results on the sentiment and biomedical corpora in are presented in Tables 2 and 3, respectively.12 These exploit different external resources to induce the word groupings that in turn inform weight sharing.",4 Results,[0],[0]
"We report AUC for the biomedical datasets because these are highly imbalanced (see Table 1).
",4 Results,[0],[0]
"Our method improves performance compared to all relevant baselines (including an approach that
9For this work we are ignoring title and abstract texts.",4 Results,[0],[0]
"10code.google.com/archive/p/word2vec/ 11bio.nlplab.org/ 12Sentiment task results are not directly comparable to
prior work due to different preprocessing steps.
also exploits external knowledge via retrofitting) in six of seven cases.",4 Results,[0],[0]
"Informing weight initialization using external resources improves performance independently, but additional gains are realized by also enforcing sharing during training.
",4 Results,[0],[0]
"We note that our aim here is not necessarily to achieve state-of-art results on any given dataset, but rather to evaluate the proposed method for incorporating external linguistic resources into neural models via weight sharing.",4 Results,[0],[0]
We have therefore compared to baselines that enable us to assess this.,4 Results,[0],[0]
Neural Models for NLP.,5 Related Work,[0],[0]
"Recently there has been enormous interest in neural models for NLP generally (Collobert et al., 2011; Goldberg, 2016).",5 Related Work,[0],[0]
"Most relevant to this work, simple CNN based models (which we have built on here) have proven extremely effective for text categorization (Kim, 2014; Zhang and Wallace, 2015).",5 Related Work,[0],[0]
Exploiting Linguistic Resources.,5 Related Work,[0],[0]
A potential drawback to learning from scratch in end-to-end neural models is a failure to capitalize on existing knowledge sources.,5 Related Work,[0],[0]
"There have been efforts to exploit such resources specifically to induce better word vectors (Yu and Dredze, 2014; Faruqui et al., 2014; Yu et al., 2016; Xu et al., 2014).",5 Related Work,[0],[0]
"But these models do not attempt to exploit external resources jointly during training for a particular downstream task (which uses word embeddings as inputs), as we do here.
",5 Related Work,[0],[0]
Past work on sparse linear models has shown the potential of exploiting linguistic knowledge in statistical NLP models.,5 Related Work,[0],[0]
"For example, Yogatama and Smith (2014) used external resources to inform structured, grouped regularization of loglinear text classification models, yielding improvements over standard regularization approaches.",5 Related Work,[0],[0]
"Elsewhere, Doshi-Velez et al. (2015) proposed a variant of LDA that exploits a priori known tree-
structured relations between tokens (e.g., derived from the UMLS) in topic modeling.",5 Related Work,[0],[0]
Weight-sharing in NNs.,5 Related Work,[0],[0]
Recent work has considered stochastically sharing weights in neural models.,5 Related Work,[0],[0]
"Notably, Chen et al. (2015).",5 Related Work,[0],[0]
proposed randomly sharing weights in neural networks.,5 Related Work,[0],[0]
"Elsewhere, Han et al. (2015) proposed quantized weight sharing as an intermediate step in their deep compression model.",5 Related Work,[0],[0]
"In these works, the primary motivation was model compression, whereas here we view the hashing trick as a mechanism to encode domain knowledge.",5 Related Work,[0],[0]
We have proposed a novel method for incorporating prior semantic knowledge into neural models via stochastic weight sharing.,6 Conclusion,[0],[0]
We have showed it generally improves text classification performance vs. model variants which do not exploit external resources and vs. an approach based on retrofitting prior to training.,6 Conclusion,[0],[0]
"In future work, we will investigate generalizing our approach beyond classification, and to inform weight sharing using other varieties and sources of linguistic knowledge.
Acknowledgements.",6 Conclusion,[0],[0]
"This work was made possible by NPRP grant NPRP 7-1313-1-245 from the Qatar National Research
Fund (a member of Qatar Foundation).",6 Conclusion,[0],[0]
"The statements made
herein are solely the responsibility of the authors.",6 Conclusion,[0],[0]
A fundamental advantage of neural models for NLP is their ability to learn representations from scratch.,abstractText,[0],[0]
"However, in practice this often means ignoring existing external linguistic resources, e.g., WordNet or domain specific ontologies such as the Unified Medical Language System (UMLS).",abstractText,[0],[0]
"We propose a general, novel method for exploiting such resources via weight sharing.",abstractText,[0],[0]
Prior work on weight sharing in neural networks has considered it largely as a means of model compression.,abstractText,[0],[0]
"In contrast, we treat weight sharing as a flexible mechanism for incorporating prior knowledge into neural models.",abstractText,[0],[0]
We show that this approach consistently yields improved performance on classification tasks compared to baseline strategies that do not exploit weight sharing.,abstractText,[0],[0]
Exploiting Domain Knowledge via Grouped Weight Sharing with Application to Text Categorization,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 918–924 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
918",text,[0],[0]
"The task of semantic parsing is to translate text to its formal meaning representations, such as logical forms or structured queries.",1 Introduction,[0],[0]
"Recent neural semantic parsers approach this problem by learning soft alignments between natural language and logical forms from (text, logic) pairs (Jia and Liang, 2016; Dong and Lapata, 2016; Krishnamurthy et al., 2017).",1 Introduction,[0],[0]
All these parsers follow the conventional encoder-decoder architecture that first encodes the text into a distributional representation and then decodes it to a logical form.,1 Introduction,[0],[0]
"These parsers may differ in the choice of the decoders, such as sequence or tree decoders, but they utilize the same encoder which is essentially a sequential Long Short-Term Memory network (SeqLSTM).",1 Introduction,[0],[0]
"This encoder only extracts word order features while neglecting useful syntactic information, such as dependency parse and constituency parse.
",1 Introduction,[0],[0]
"However, the syntactic features capture important structural information of the natural lan-
∗ Work done when the author was at IBM Research.
guage input, which complements the simple word sequence.",1 Introduction,[0],[0]
"For example, a dependency graph presents grammatical relations that hold among the words; and a constituent tree provides a phrase structure representation.",1 Introduction,[0],[0]
"Intuitively, by incorporating such additional information, the encoder could produce a more meaningful and robust sentence representation.",1 Introduction,[0],[0]
"The combination of these features (i.e., sequence + trees) forms a general graph structure (see Figure 1).",1 Introduction,[0],[0]
This inspires us to apply a graph encoder to produce a representation of a graph-structured input.,1 Introduction,[0],[0]
"The graph encoder also has the advantages that it could simultaneously encode all types of syntactic contexts, and incorporate multiple types of syntactic structures in a unified way.
",1 Introduction,[0],[0]
"In this paper, we first introduce a structure, namely syntactic graph, to represent three types of syntactic information, i.e., word order, dependency and constituency features (see §2).",1 Introduction,[0],[0]
"We then employ a novel graph-to-sequence (Graph2Seq) model (Xu et al., 2018), which consists of a graph encoder and a sequence decoder, to learn the representation of the syntactic graph (see §3).",1 Introduction,[0],[0]
"Specifically, the graph encoder learns the representation of each node by aggregating information from its K-hop neighbors.",1 Introduction,[0],[0]
"Given the learned node embeddings, the graph encoder uses a pooling-based method to generate the graph embedding.",1 Introduction,[0],[0]
"On the decoder side, a Recurrent Neural Network (RNN) decoder takes the graph embedding as its initial hidden state to generate the logical form while employing an attention mechanism over the node embeddings.",1 Introduction,[0],[0]
"Experimental results show that our model achieves the competitive performance on Jobs640, ATIS, and Geo880 datasets.
",1 Introduction,[0],[0]
"Different from existing works, we also investigate the robustness of our model by evaluating the model on two types of adversarial examples (Belinkov and Bisk, 2017; Cheng et al., 2018).
",1 Introduction,[0],[0]
"Experimental results show that the model coupling all syntactic features has the best robustness, achieving the best performance.",1 Introduction,[0],[0]
Our code and data is available at https://github.com/IBM/ Text-to-LogicForm.,1 Introduction,[0],[0]
"We represent three types of syntactic features, i.e., word order, dependency parse and constituency parse, as the syntactic graph (see Figure 1).",2 Syntactic Graph,[0],[0]
•Word Order Features.,2 Syntactic Graph,[0],[0]
Previous neural semantic parsers mainly use these features by building a SeqLSTM that works on the word sequence.,2 Syntactic Graph,[0],[0]
Our syntactic graph also incorporates this information by generating a node for each word and connecting them in the chain form.,2 Syntactic Graph,[0],[0]
"In order to capture the forward and backward contextual information, we link these nodes in two directions, that is, from left to right and from right to left.",2 Syntactic Graph,[0],[0]
• Dependency Features.,2 Syntactic Graph,[0],[0]
A dependency parse describes the grammatical relations that hold among words.,2 Syntactic Graph,[0],[0]
"Reddy et al. (2016, 2017) have demonstrated that the dependency parse tree could be directly transformed to a logical form, which indicates that the dependency information (i.e., tree structure and dependency labels) is critical to the semantic parsing task.",2 Syntactic Graph,[0],[0]
We incorporate this information into the syntactic graph by adding directed edges between the word nodes and assign them with dependency labels.,2 Syntactic Graph,[0],[0]
• Constituency Features.,2 Syntactic Graph,[0],[0]
"Similar to the dependency parse, the constituency parse represents the phrase structure, which is also important to the semantic parsing task.",2 Syntactic Graph,[0],[0]
"Take Figure 1 as an example: given the constituent tree that explicitly annotates “not related with AI” (node #1) is a proposition phrase, the model could learn a meaningful embedding for this phrase by encoding this structure into the model.",2 Syntactic Graph,[0],[0]
"Motivated by this observation, we
add the non-terminal nodes of the constituent tree and the edges describing their parent-child relationships into the syntactic graph.",2 Syntactic Graph,[0],[0]
"After building the syntactic graph for the input text, we employ a novel graph-to-sequence model (Xu et al., 2018), which includes a graph encoder and a sequence decoder with attention mechanism, to map the syntactic graph to the logical form.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Conceptually, the graph encoder generates node embeddings for each node by accumulating information from its K-hop neighbors, and then produces a graph embedding for the entire graph by abstracting all these node embeddings.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Next, the sequence decoder takes the graph embedding as the initial hidden state, and calculates the attention over all node embeddings on the encoder side to generate logical forms.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Note that this graph encoder does not explicitly encode the edge label information, therefore, for each labeled edge, we add a node whose text attribute is the edge’s label.
",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
Node Embedding.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Given the syntactic graph G = (V, E), we take the embedding generation process for node v ∈ V as an example to explain the node embedding generation algorithm1: (1) We first transform node v’s text attribute to a feature vector, av, by looking up the embedding matrix We; (2) The neighbors of v are categorized into forward neighbors N`(v) and backward neighbors Na(v) according to the edge direction.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"In particular, N`(v) returns the nodes that v directs to and Na(v) returns the nodes that direct to v; (3) We aggregate the forward representations of v’s forward neighbors {hk−1u` , ∀u ∈ N`(v)} into
1Interested readers may refer to (Xu et al., 2018) for more implementation details.
",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"a single vector, hkN`(v), where k∈{1, ...,K} is the iteration index.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Specifically, this aggregator feeds each neighbor’s vector to a fully-connected neural network and applies an element-wise max-pooling operation to capture different aspects of the neighbor set.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"Notice that, at iteration k, this aggregator only uses the representations generated at k − 1.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
The initial forward representation of each node is its feature vector calculated in step (1); (4) We concatenate v’s current forward representation hk−1v` with the newly generated neighborhood vector hkN`(v).,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"The resulted vector is fed into a fully connected layer with nonlinear activation function σ, which updates the forward representation of v, hkv`, to be used at the next iteration; (5) We update the backward representation of v, hkva using the similar procedure as introduced in step (3) and (4) except that operating on the backward representations; (6) We repeat steps (3)∼(5) K times, and the concatenation of the final forward and backward representations is used as the final representation of v. Since the neighbor information from different hops may have different impacts on the node embedding, we learn a distinct aggregator at each iteration.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
Graph Embedding.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"We feed the obtained node embeddings into a fully-connected neural network, and apply the element-wise max-pooling operation on all node embeddings.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
We did not find substantial performance improvement using mean-pooling.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
Sequence Decoding.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"The decoder is an RNN which predicts the next token yi given all the previous words y<i = y1, ..., yi−1, the RNN hidden state si for time-step i and the context vector ci that captures the attention of the encoder side.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"In particular, the context vector ci depends on a set of node representations (h1,...,hV ) to which the encoder maps the input graph.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
The context vector ci is dynamically computed using an attention mechanism over the node representations.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
The whole model is jointly trained to maximize the conditional log-probability of the correct description given a source graph.,3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"In the inference phase, we use the beam search algorithm to generate a description with beam size = 3.",3 Graph-to-sequence Model for Semantic Parsing,[0],[0]
"We evaluate our model on three datasets: Jobs640, a set of 640 queries to a database of job listings;
Geo880, a set of 880 queries to a database of U.S. geography; and ATIS, a set of 5,410 queries to a flight booking system.",4 Experiments,[0],[0]
"We use the standard train/development/test split as previous works, and the logical form accuracy as our evaluation metric.
",4 Experiments,[0],[0]
"The model is trained using the Adam optimizer (Kingma and Ba, 2014), with mini-batch size 30.",4 Experiments,[0],[0]
"Our hyper-parameters are cross-validated on the training set for Jobs640 and Geo880, and tuned on the development set for ATIS.",4 Experiments,[0],[0]
The learning rate is set to 0.001.,4 Experiments,[0],[0]
"The decoder has 1 layer, and its hidden state size is 300.",4 Experiments,[0],[0]
"The dropout strategy (Srivastava et al., 2014) with the ratio of 0.5 is applied at the decoder layer to avoid overfitting.",4 Experiments,[0],[0]
We is initialized using GloVe word vectors from Pennington et al. (2014) and the dimension of word embedding is 300.,4 Experiments,[0],[0]
"For the graph encoder, the hop size K is set to 10, the non-linearity function σ is implemented as ReLU (Glorot et al., 2011), the parameters of the aggregators are randomly initialized.",4 Experiments,[0],[0]
"We use the Stanford CoreNLP tool (Manning et al., 2014) to generate the dependency and constituent trees.
Results and Discussion.",4 Experiments,[0],[0]
Table 1 summarizes the results of our model and existing semantic parsers on three datasets.,4 Experiments,[0],[0]
"Our model achieves competitive performance on Jobs640, ATIS and Geo880.",4 Experiments,[0],[0]
"Our work is the first to use both multiple trees and the word sequence for semantic parsing, and it outperforms the Seq2Seq model reported in Dong and Lapata (2016), which only uses limited syntactic information.",4 Experiments,[0],[0]
Comparison with Baseline.,4 Experiments,[0],[0]
"To better demonstrate that our work is an effective way to utilize both multiple trees and the word sequence for semantic parsing, we compare with an addi-
tional straightforward baseline method (referred as BASELINE in Table 1).",4 Experiments,[0],[0]
"To deal with the graph input, the BASELINE decomposes the graph embedding to two steps and applies different types of encoders sequentially: (1) a SeqLSTM to extract word order features, which results in word embeddings, Wseq; (",4 Experiments,[0],[0]
"2) two TreeLSTMs (Tai et al., 2015) to extract the dependency tree and constituency features while taking Wseq as initial word embeddings.",4 Experiments,[0],[0]
"The resulted word embeddings and nonterminal node embeddings (from TreeLSTMs) are then fed into a sequence decoder.
",4 Experiments,[0],[0]
We can see that our model significantly outperforms the BASELINE.,4 Experiments,[0],[0]
One possible reason is that our graph encoder jointly extracts these features in a unified model by propagating the dependency and constituency information to all nodes in the syntactic graph.,4 Experiments,[0],[0]
"However, BASELINE separately models these features using two distinct TreeLSTMs.",4 Experiments,[0],[0]
"As a result, the non-terminal tree nodes only retain only one type of syntactic information propagated from their descendants in the tree.
",4 Experiments,[0],[0]
Ablation Study.,4 Experiments,[0],[0]
"In Table 1, we also report the results of three ablation variants of our model, i.e., without word order features/dependency features/constituency features.",4 Experiments,[0],[0]
"We find that Graph2Seq is superior to Seq2Seq (Dong and Lapata, 2016) which is expected since Graph2Seq exploits more syntactic information.",4 Experiments,[0],[0]
"Among these features, the word order feature have more impact on the performance than other two syntactic features.",4 Experiments,[0],[0]
"By incorporating either the dependency or the constituency features, the model could gain further performance improvement, which underlines the importance of utilizing more aspects of syntactic information.",4 Experiments,[0],[0]
"Finally, removing both syntactic features (w/ ONLY word order) performs slightly worse compared to the Seq2Seq baseline.",4 Experiments,[0],[0]
"This shows that using K=10 hops is good enough for memorizing the sentences in our benchmarks, although still weaker compared to a bidirectional LSTM encoder.
",4 Experiments,[0],[0]
A natural question here is on which type of queries our model could benefit from incorporating these parse features.,4 Experiments,[0],[0]
"By analyzing the queries and our predicted logical forms, we find that the parse features mainly improve the prediction accuracy for the queries with complex logical forms.",4 Experiments,[0],[0]
Table 2 gives some running examples of complicated queries in three datasets.,4 Experiments,[0],[0]
"We find that the model that exploits three syntactic information
could correctly predict these logical forms while the model that only uses word order features may fail.
",4 Experiments,[0],[0]
Robustness Study.,4 Experiments,[0],[0]
"Different from previous works, we evaluate the robustness of our model by creating adversarial examples with the hope to investigate the impact of introducing more syntactic information on robustness.",4 Experiments,[0],[0]
"Specifically, we create two types of adversarial examples and conduct experiments on the ATIS dataset.",4 Experiments,[0],[0]
"Following Belinkov and Bisk (2017), we first experiment with the synthetic noise, SWAP, which swaps two letters (e.g. noise→nosie).",4 Experiments,[0],[0]
It is common to see such noisy information when typing quickly.,4 Experiments,[0],[0]
"Given a text, we randomly perform swap on m ∈ {1, 2, 3, 4, 5} words that not correspond to the operators or arguments in logical forms, ensuring the meaning of the text is not changed.",4 Experiments,[0],[0]
"We train Graph2Seq on the training data and first evaluate it on the original development data, Devori.",4 Experiments,[0],[0]
"Then we use the same model but evaluate it on a variant of Devori, whose queries contain m swapped words.
",4 Experiments,[0],[0]
"Figure 2 summarizes the results of our model on the first type of adversarial examples, i.e., the ATIS development set with the SWAP noise.",4 Experiments,[0],[0]
"From Figure 2, we can see that (1) the performance of our model on all combinations of features degrade significantly when increasing the number of swapped words; (2) the model that uses three syntactic features (our default model) always achieves the best performance, and the performance gap
compared to others increases when rising the number of swapped words; (3) word order features are the most sensitive to the word sequence while the dependency and constituency features seem more robust to such noisy information; (4) thanks to the robustness of the dependency and constituency features, the default model performs significantly better than the one that only uses word order features on the noisy sentences.",4 Experiments,[0],[0]
"These findings demonstrate that incorporating more aspects of syntactic information could enhance the robustness of the model.
",4 Experiments,[0],[0]
We also experiment with the paraphrase of the input text as the second type of adversarial examples.,4 Experiments,[0],[0]
"More specifically, we collect the paraphrase of a text by first translating it to the other language such as Chinese and then translating it back to English, using the Google Translate service.",4 Experiments,[0],[0]
We use this method to collect a new variant of Devori whose queries are the paraphrases of the original ones.,4 Experiments,[0],[0]
"By manually reading these queries, we find 94% queries convey the same meaning as original ones.",4 Experiments,[0],[0]
"Similar to the first experiment, we still train the model on Devori and evaluate it on the newly created dataset.
",4 Experiments,[0],[0]
"Table 3 shows the results of our model on the second type of adversarial examples, i.e., the paraphrased ATIS development set.",4 Experiments,[0],[0]
"We also report the
result of our model on the original ATIS development set.",4 Experiments,[0],[0]
"We can see that (1) no matter which feature our model uses, the performance degrades at least 2.5% on the paraphrased dataset; (2) the model that only uses word order features achieves the worst robustness to the paraphrased queries while the dependency feature seems more robust than other two features.",4 Experiments,[0],[0]
(3) simultaneously utilizing three syntactic features could greatly enhance the robustness of our model.,4 Experiments,[0],[0]
These results again demonstrate that our model could benefit from incorporating more aspects of syntactic information.,4 Experiments,[0],[0]
Existing works of generating text representation has evolved into two main streams.,5 Related Work,[0],[0]
"The first one is based on the word order, that is, either generating general purpose and domain independent embeddings of word sequences (Wu et al., 2018a; Arora et al., 2017), or building Bi-directional LSTMs over the text (Zhang et al., 2018).",5 Related Work,[0],[0]
"These methods neglect other syntactic information, which, however, has been proved to be useful in shallow semantic parsing, e.g., semantic role labeling (Punyakanok et al., 2008).",5 Related Work,[0],[0]
"To address this, recent works attempt to incorporate these syntactic information into the text representation.",5 Related Work,[0],[0]
"For example, Xu et al. (2016) builds separated neural networks for different types of syntactic annotation.",5 Related Work,[0],[0]
Gormley et al. (2015); Wu et al. (2018b) decompose a graph to simpler sub-graphs and embed these subgraphs independently.,5 Related Work,[0],[0]
"Our approach, compared to the above methods, provided a unified solution to arbitrary combinations of syntactic graphs.",5 Related Work,[0],[0]
"In parallel to syntactic features, other works leverage additional information such as dialogue and paraphrasing for semantic parsing (Su and Yan, 2017; Gur et al., 2018).",5 Related Work,[0],[0]
Existing neural semantic parsers mainly leverage word order features while neglecting other valuable syntactic information.,6 Conclusions,[0],[0]
"To address this, we propose to build a syntactic graph which represents three types of syntactic information, and further apply a novel graph-to-sequence model to map the syntactic graph to a logical form.",6 Conclusions,[0],[0]
"Experimental results show that the robustness of our model is improved due to the incorporating more aspects of syntactic information, and our model outperforms previous semantic parsing systems.",6 Conclusions,[0],[0]
"Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a sequential LSTM, to extract word order features while neglecting other valuable syntactic information such as dependency or constituent trees.",abstractText,[0],[0]
"In this paper, we first propose to use the syntactic graph to represent three types of syntactic information, i.e., word order, dependency and constituency features; then employ a graph-tosequence model to encode the syntactic graph and decode a logical form.",abstractText,[0],[0]
"Experimental results on benchmark datasets show that our model is comparable to the state-of-the-art on Jobs640, ATIS, and Geo880.",abstractText,[0],[0]
Experimental results on adversarial examples demonstrate the robustness of the model is also improved by encoding more syntactic information.,abstractText,[0],[0]
Exploiting Rich Syntactic Information for Semantic Parsing with Graph-to-Sequence Model,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2193–2203, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
The problem of discovering semantic relationships between two sentences has given birth to several NLP tasks over the years.,1 Introduction,[0],[0]
"Textual entailment (Dagan et al., 2013, inter alia) asks about the truth of a hypothesis sentence given another sentence (or more generally a paragraph).",1 Introduction,[0],[0]
"Paraphrase identification (Dolan et al., 2004, inter alia) asks whether two sentences have the same meaning.",1 Introduction,[0],[0]
"Foregoing the binary entailment and paraphrase decisions, the semantic textual similarity (STS) task (Agirre et al., 2012) asks for a numeric measure of semantic equivalence between two sentences.",1 Introduction,[0],[0]
"All three tasks have attracted much interest in the form of shared tasks.
",1 Introduction,[0],[0]
"While various approaches have been proposed to predict these sentence relationships, a commonly employed strategy (Das and Smith, 2009; Chang et
al., 2010a) is to postulate an alignment between constituents of the sentences and use this alignment to make the final prediction (a binary decision or a numeric similarity score).",1 Introduction,[0],[0]
"The implicit assumption in such approaches is that better constituent alignments can lead to better identification of semantic relationships between sentences.
",1 Introduction,[0],[0]
Constituent alignments serve two purposes.,1 Introduction,[0],[0]
"First, they act as an intermediate representation for predicting the final output.",1 Introduction,[0],[0]
"Second, the alignments help interpret (and debug) decisions made by the overall system.",1 Introduction,[0],[0]
"For example, the alignment between the sentences in Figure 1 can not only be useful to determine the equivalence of the two sentences, but also help reason about the predictions.
",1 Introduction,[0],[0]
"The importance of this intermediate representation led to the creation of the interpretable semantic textual similarity task (Agirre et al., 2015a) that focuses on predicting chunk-level alignments and similarities.",1 Introduction,[0],[0]
"However, while extensive resources exist for sentence-level relationships, human annotated chunk-aligned data is comparatively smaller.
",1 Introduction,[0],[0]
"In this paper, we address the following question: can we use sentence-level resources to better pre-
2193
dict constituent alignments and similarities?",1 Introduction,[0],[0]
"To answer this question, we focus on the semantic textual similarity (STS) task and its interpretable variant.",1 Introduction,[0],[0]
We propose a joint model that aligns constituents and integrates the information across the aligned edges to predict both constituent and sentence level similarity.,1 Introduction,[0],[0]
"The key advantage of modeling these two problems jointly is that, during training, the sentence-level information can provide feedback to the constituent-level predictions.
",1 Introduction,[0],[0]
We evaluate our model on the SemEval-2016 task of interpretable STS.,1 Introduction,[0],[0]
"We show that even without the sentence information, our joint model that uses constituent alignments and similarities forms a strong baseline.",1 Introduction,[0],[0]
"Further, our easily extensible joint model can incorporate sentence-level similarity judgments to produce alignments and chunk similarities that are comparable to the best results in the shared task.
",1 Introduction,[0],[0]
"In summary, the contributions of this paper are:
1.",1 Introduction,[0],[0]
We present the first joint model for predicting constituent alignments and similarities.,1 Introduction,[0],[0]
"Our model can naturally take advantage of the much larger sentence-level annotations.
2.",1 Introduction,[0],[0]
We evaluate our model on the SemEval-2016 task of interpretable semantic similarity and show state-of-the-art results.,1 Introduction,[0],[0]
"In this section, we will introduce the notation used in the paper using the sentences in Figure 1 as a running example.",2 Problem Definition,[0],[0]
"The input to the problem is a pair of sentences, denoted by",2 Problem Definition,[0],[0]
"x. We will assume that the sentences are chunked (Tjong Kim Sang and Buchholz, 2000) into constituents.",2 Problem Definition,[0],[0]
We denote the chunks using subscripts.,2 Problem Definition,[0],[0]
"Thus, the input x consists of two sequences of chunks s = (s1, s2, · · · ) and t = (t1, t2, · · · ) respectively.",2 Problem Definition,[0],[0]
"In our running example, we have s = (Gunmen, abduct, seven foreign workers) and t =",2 Problem Definition,[0],[0]
"(Seven foreign workers, kidnapped).
",2 Problem Definition,[0],[0]
"The output consists of three components:
1.",2 Problem Definition,[0],[0]
Alignment:,2 Problem Definition,[0],[0]
"The alignment between a pair of chunks is a labeled, undirected edge that explains the relation that exists between them.",2 Problem Definition,[0],[0]
"The labels can be one of EQUI (semantically
equivalent), OPPO (opposite meaning in context), SPE1, SPE2 (the chunk from s is more specific than the one from t and vice versa), SIMI (similar meaning, but none of the previous ones) or REL (related, but none of the above)1.",2 Problem Definition,[0],[0]
"In Figure 1, we see two EQUI edges.",2 Problem Definition,[0],[0]
"A chunk from either sentence can be unaligned, as in the case of the chunk Gunmen.
",2 Problem Definition,[0],[0]
We will use y to denote the alignment for an input x.,2 Problem Definition,[0],[0]
"The alignment y consists of a sequence of triples of the form (si, tj , l).",2 Problem Definition,[0],[0]
"Here, si and tj denote a pair of chunks that are aligned with a label l. For brevity, we will include unaligned chunks into this format using a special null chunk and label to indicate that a chunk is unaligned.",2 Problem Definition,[0],[0]
"Thus, the alignment for our running example contain the triple (Gunmen, ∅, ∅).
2.",2 Problem Definition,[0],[0]
"Chunk similarity: Every aligned chunk is associated with a relatedness score between zero and five, denoting the range from unrelated to equivalent.",2 Problem Definition,[0],[0]
Note that even chunks labeled OPPO can be assigned a high score because the polarity is captured by the label rather than the score.,2 Problem Definition,[0],[0]
"We will denote the chunk similarities using z, comprising of numeric zi,j,l for elements of the corresponding alignment y. For an unaligned chunk, the corresponding similarity z is fixed to zero.
3.",2 Problem Definition,[0],[0]
"Sentence similarity: The pair of sentences is associated with a scalar score from zero to five, to be interpreted as above.",2 Problem Definition,[0],[0]
"We will use r to denote the sentence similarity for an input x.
Thus, the prediction problem is the following: Given a pair of chunked sentences x = (s, t), predict the alignment y, the alignment similarities z and the sentence similarity r. Note that this problem definition integrates the canonical semantic textual similarity task (only predicting r) and its interpretable variant (predicting both y and z) into a single task.
",2 Problem Definition,[0],[0]
"1We refer the reader to the guidelines of the task (Agirre et al., 2015a) for further details on these labels.",2 Problem Definition,[0],[0]
"Also, for simplicity, in this paper, we ignore the factuality and polarity tags from the interpretable task.",2 Problem Definition,[0],[0]
"This section describes our model for predicting alignments, alignment scores, and the sentence similarity scores for a given pair of sentences.",3 Predicting Alignments and Similarities,[0],[0]
"We will assume that learning is complete and we have all the scoring functions we need and defer discussing the parameterization and learning to Section 4.
",3 Predicting Alignments and Similarities,[0],[0]
We frame the problem of inference as an instance of an integer linear program (ILP).,3 Predicting Alignments and Similarities,[0],[0]
We will first see the scoring functions and the ILP formulation in Section 3.1.,3 Predicting Alignments and Similarities,[0],[0]
"Then, in Section 3.2, we will see how we can directly read off the similarity scores at both chunk and sentence level from the alignment.",3 Predicting Alignments and Similarities,[0],[0]
"We have two kinds of 0-1 inference variables to represent labeled aligned chunks and unaligned chunks.
",3.1 Alignment via Integer Linear Programs,[0],[0]
"We will use the inference variables 1i,j,l to denote the decision that chunks si and tj are aligned with a label l. To allow chunks to be unaligned, the variables 1i,0 and 10,j denote the decisions that si and tj are unaligned respectively.
",3.1 Alignment via Integer Linear Programs,[0],[0]
Every inference decision is scored by the trained model.,3.1 Alignment via Integer Linear Programs,[0],[0]
"Thus, we have score(i, j, l), score(i, 0) and score(0, j) for the three kinds of inference variables respectively.",3.1 Alignment via Integer Linear Programs,[0],[0]
"All scores are of the form A ( wTΦ (·, s, t) ) , where w is a weight vector that is learned, Φ (·, s, t) is a feature function whose arguments include the constituents and labels in question, and A is a sigmoidal activation function that flattens the scores to the range",3.1 Alignment via Integer Linear Programs,[0],[0]
"[0, 5].",3.1 Alignment via Integer Linear Programs,[0],[0]
"In all our experiments, we used the function A(x) = 5
1+e−x .",3.1 Alignment via Integer Linear Programs,[0],[0]
The goal of inference is to find the assignment to the inference variables that maximizes total score.,3.1 Alignment via Integer Linear Programs,[0],[0]
"That is, we seek to solve
arg max 1∈C
∑
i,j,l
score(i, j, l)1i,j,l
+ ∑
i
score(i, 0)1i,0
+ ∑
j
score(0, j)10,j (1)
",3.1 Alignment via Integer Linear Programs,[0],[0]
"Here 1 represents all the inference variables together and C denotes the set of all valid assignments to the variables, defined by the following set of constraints:
1.",3.1 Alignment via Integer Linear Programs,[0],[0]
"A pair of chunks can have at most one label.
2.",3.1 Alignment via Integer Linear Programs,[0],[0]
"Either a chunk can be unaligned or it should participate in a labeled alignment with exactly one chunk of the other sentence.
",3.1 Alignment via Integer Linear Programs,[0],[0]
"We can convert these constraints into linear inequalities over the inference variables using standard techniques for ILP inference (Roth and Yih, 2004)2.",3.1 Alignment via Integer Linear Programs,[0],[0]
"Note that, by construction, there is a oneto-one mapping from an assignment to the inference variables 1 and the alignment y.",3.1 Alignment via Integer Linear Programs,[0],[0]
"In the rest of the paper, we use these two symbols interchangeably, using 1 referring details of inference and y referring to the alignment as a sequence of labeled edges.",3.1 Alignment via Integer Linear Programs,[0],[0]
"To complete the prediction, we need to compute the numeric chunk and sentence similarities given the alignment y.",3.2 From Alignments to Similarities,[0],[0]
"In each case, we make modeling assumptions about how the alignments and similarities are related, as described below.
",3.2 From Alignments to Similarities,[0],[0]
"Chunk similarities To predict the chunk similarities, we assume that the label-specific chunk similarities of aligned chunks are the best edge-weights for the corresponding inference variables.",3.2 From Alignments to Similarities,[0],[0]
"That is, for a pair of chunks (si, tj) that are aligned with a label l, the chunk pair similarity zi,j,l is the coefficient associated with the corresponding inference variable.",3.2 From Alignments to Similarities,[0],[0]
"If the alignment edge indicates an unaligned chunk, then the corresponding score is zero.",3.2 From Alignments to Similarities,[0],[0]
"That is,
zi,j,l =
{ A ( wTΦ (si, tj , l, s, t) )",3.2 From Alignments to Similarities,[0],[0]
"if l 6= ∅
0 if l = ∅. (2)
But can chunk similarities directly be used to find good alignments?",3.2 From Alignments to Similarities,[0],[0]
"To validate this assumption, we performed a pilot experiment on the chunk aligned part of our training dataset.",3.2 From Alignments to Similarities,[0],[0]
"We used the gold standard chunk similarities as scores of the inference variables in the integer program in Eq. 1, with the variables associated with unaligned chunks being scored zero.",3.2 From Alignments to Similarities,[0],[0]
"We found that this experiment gives a near-perfect typed alignment F-score of 0.9875.
2While it may be possible to find the score maximizing alignment in the presence of these constraints using dynamic programming (say, a variant of the Kuhn-Munkres algorithm), we model inference as an ILP to allow us the flexibility to explore more sophisticated output interactions in the future.
",3.2 From Alignments to Similarities,[0],[0]
"The slight disparity is because the inference only allows 1-to-1 matches between chunks (constraint 2), which does not hold in a small number of examples.
",3.2 From Alignments to Similarities,[0],[0]
"Sentence similarities Given the aligned chunks y, the similarity between the sentences s and t (i.e., in our notation, r) is the weighted average of the chunk similarities (i.e., zi,j,l).",3.2 From Alignments to Similarities,[0],[0]
"Formally,
r = 1 |y| ∑
(si,tj ,l)∈y αlzi,j,l. (3)
Note that the weights αl depend only on the labels associated with the alignment edge and are designed to capture the polarity and strength of the label.",3.2 From Alignments to Similarities,[0],[0]
Eq. 3 bridges sentence similarities and chunk similarities.,3.2 From Alignments to Similarities,[0],[0]
"During learning, this provides the feedback from sentence similarities to chunk similarities.",3.2 From Alignments to Similarities,[0],[0]
The values of theα’s can be learned or fixed before learning commences.,3.2 From Alignments to Similarities,[0],[0]
"To simplify our model, we choose the latter approach .",3.2 From Alignments to Similarities,[0],[0]
"Section 5 gives more details.
",3.2 From Alignments to Similarities,[0],[0]
"Features To complete the description of the model, we now describe the features that define the scoring functions.",3.2 From Alignments to Similarities,[0],[0]
"We use standard features from the STS literature (Karumuri et al., 2015; Agirre et al., 2015b; Banjade et al., 2015).
",3.2 From Alignments to Similarities,[0],[0]
"For a pair of chunks, we extract the following similarity features: (1) Absolute cosine similarities of GloVe embeddings (Pennington et al., 2014) of head words, (2) WordNet based Resnik (Resnik, 1995), Leacock (Leacock and Chodorow, 1998) and Lin (Lin, 1998) similarities of head words, (3) Jaccard similarity of content words and lemmas.",3.2 From Alignments to Similarities,[0],[0]
"In addition, we also add indicators for: (1) the part of speech tags of the pair of head words, (2) the pair of head words being present in the lexical large section of the Paraphrase Database (Ganitkevitch et al., 2013), (3) a chunk being longer than the other while both are not named entity chunks, (4) a chunk having more content words than the other, (5) contents of one chunk being a part of the other, (6) having the same named entity type or numeric words, (7) sharing synonyms or antonyms, (8) sharing conjunctions or prepositions, (9) the existence of unigram/bigram/trigram overlap, (10) if only one chunk has a negation, and (11) a chunk having extra content words that are also present in the other sentence.
",3.2 From Alignments to Similarities,[0],[0]
"For a chunk being unaligned, we conjoin an indicator that the chunk is unaligned with the part of speech tag of its head word.",3.2 From Alignments to Similarities,[0],[0]
"In the model proposed above, by predicting the alignment, we will be able to deterministically calculate both chunk and sentence level similarities.",3.3 Discussion,[0],[0]
"This is in contrast to other approaches for the STS task, which first align constituents and then extract features from alignments to predict similarities in a pipelined fashion.",3.3 Discussion,[0],[0]
"The joint prediction of alignment and similarities allows us to address the primary motivation of the paper, namely using the abundant sentence level data to train the aligner and scorer.
",3.3 Discussion,[0],[0]
The crucial assumption that drives the joint model is that the same set of parameters that can discover a good alignment can also predict similarities.,3.3 Discussion,[0],[0]
"This assumption – similar to the one made by Chang et al. (2010b) – and the associated model described above, imply that the goal of learning is to find parameters that drive the inference towards good alignments and similarities.",3.3 Discussion,[0],[0]
"Under the proposed model, the alignment directly predicts the chunk and sentence similarities as well.",4 Learning the Alignment Model,[0],[0]
"We utilize two datasets to learn the model:
1.",4 Learning the Alignment Model,[0],[0]
"The alignment dataset DA consists of fully annotated aligned chunks and respective chunk similarity scores.
",4 Learning the Alignment Model,[0],[0]
2.,4 Learning the Alignment Model,[0],[0]
"The sentence dataset DS that consists of pairs of sentences where each pair is labeled with a numeric similarity score between zero and five.
",4 Learning the Alignment Model,[0],[0]
The goal of learning is to use these two datasets to train the model parameters.,4 Learning the Alignment Model,[0],[0]
"Note that unlike standard multi-task learning problems, the two tasks in our case are tightly coupled both in terms of their definition and via the model described in Section 3.
",4 Learning the Alignment Model,[0],[0]
"We define three types of loss functions corresponding to the three components of the final output (i.e., alignment, chunk similarity and sentence similarity).",4 Learning the Alignment Model,[0],[0]
"Naturally, for each kind of loss, we assume that we have the corresponding ground truth.",4 Learning the Alignment Model,[0],[0]
We will denote ground truth similarity scores and alignments using asterisks.,4 Learning the Alignment Model,[0],[0]
"Also, the loss functions
defined below depend on the weight vector w, but this is not shown to simplify notation.
1.",4 Learning the Alignment Model,[0],[0]
The alignment loss La is a structured loss function that penalizes alignments that are far away from the ground truth.,4 Learning the Alignment Model,[0],[0]
"We used the structured hinge loss (Taskar et al., 2004; Tsochantaridis et al., 2005) for this purpose.
La(s, t,y ∗) = max y wTΦ",4 Learning the Alignment Model,[0],[0]
"(s, t,y)
+∆",4 Learning the Alignment Model,[0],[0]
"(y,y∗)−wTΦ (s, t,y∗) .
",4 Learning the Alignment Model,[0],[0]
"Here, ∆ refers to the Hamming distance between the alignments.
2.",4 Learning the Alignment Model,[0],[0]
The chunk score loss Lc is designed to penalize errors in predicted chunk level similarities.,4 Learning the Alignment Model,[0],[0]
"To account for cases where chunk boundaries may be incorrect, we define this loss as the sum of squared errors of token similarities.",4 Learning the Alignment Model,[0],[0]
"However, neither our output nor the gold standard similarities are at the granularity of tokens.",4 Learning the Alignment Model,[0],[0]
"Thus, to compute the loss, we project the chunk scores zi,j,l for an aligned chunk pair (si, tj , l) to the tokens that constitute the chunks by equally partitioning the scores among all possible internal alignments.",4 Learning the Alignment Model,[0],[0]
"In other words, for a token wi in the chunk si and token wj in chunk sj , we define token similarity scores as
z(wi, wj , l) = zi,j,l
N(si,tj)
Here, the normalizing function N is the product of the number of tokens in the chunks3.",4 Learning the Alignment Model,[0],[0]
Note that this definition of the token similarity scores applies to both predicted and gold standard similarities.,4 Learning the Alignment Model,[0],[0]
"Unaligned tokens are associated with a zero score.
",4 Learning the Alignment Model,[0],[0]
"We can now define the loss for a token pair (wi, wj) ∈ (s, t) and a label l as the squared error of their token similarity scores:
l(wi, wj , l) =",4 Learning the Alignment Model,[0],[0]
"(z(wi, wj , l)− z∗(wi, wj ,",4 Learning the Alignment Model,[0],[0]
"l))2
3Following the official evaluation of the interpretable STS task, we also experimented with the max(|si|, |tj |) for the normalizer, but we found via cross validation that the product performs better.
",4 Learning the Alignment Model,[0],[0]
"The chunk loss score Lc for a sentence pair is the sum of all the losses over all pairs of tokens and labels.
",4 Learning the Alignment Model,[0],[0]
"Lc(s, t,y,y ∗, z, z∗) =
∑
wi,wj ,l
l(wi, wj , l)
3.",4 Learning the Alignment Model,[0],[0]
The sentence similarity loss Ls provides feedback to the aligner by penalizing alignments that are far away from the ground truth in their similarity assessments.,4 Learning the Alignment Model,[0],[0]
"For a pair of sentences (s, t), given the ground truth sentence similarity r∗ and the predicted sentence similarity r (using Equation (3)), the sentence similarity loss is the squared error:
Ls(s, t, r ∗)",4 Learning the Alignment Model,[0],[0]
"= (r − r∗)2 .
",4 Learning the Alignment Model,[0],[0]
Our learning objective is the weighted combination of the above three components and a `2 regularizer on the weight vector.,4 Learning the Alignment Model,[0],[0]
"The importance of each type of loss is controlled by a corresponding hyperparameter: λa, λc and λs respectively.
",4 Learning the Alignment Model,[0],[0]
Learning algorithm,4 Learning the Alignment Model,[0],[0]
"We have two scenarios to consider: with only alignment dataset DA, and with both DA and sentence dataset DS .",4 Learning the Alignment Model,[0],[0]
"Note that even if we train only on the alignment dataset DA, our learning objective is not convex because the activation function is sigmoidal (in Section 3.1).
",4 Learning the Alignment Model,[0],[0]
"In both cases, we use stochastic gradient descent with minibatch updates as the optimizer.",4 Learning the Alignment Model,[0],[0]
"In the first scenario, we simply perform the optimization using the alignment and the chunk score losses.",4 Learning the Alignment Model,[0],[0]
"We found by preliminary experiments on training data that initializing the weights to one performed best.
",4 Learning the Alignment Model,[0],[0]
"Algorithm 1 Learning alignments and similarities, given alignment dataset DA and sentence similarity dataset DS .",4 Learning the Alignment Model,[0],[0]
"See the text for more details.
1: Initialize all weights to one.",4 Learning the Alignment Model,[0],[0]
2: w0 ← SGD(DA): Train an initial model 3: Use w0 to predict alignments on examples in DS .,4 Learning the Alignment Model,[0],[0]
Call this D̂S .,4 Learning the Alignment Model,[0],[0]
4: w ← SGD(DA ∪ D̂S): Train on both sets of examples.,4 Learning the Alignment Model,[0],[0]
"5: return w
When we have both DA and DS (Algorithm 1), we first initialize the model on the alignment data
only.",4 Learning the Alignment Model,[0],[0]
"Using this initial model, we hypothesize alignments on all examples in DS to get fully labeled examples.",4 Learning the Alignment Model,[0],[0]
"Then, we optimize the full objective (all three loss terms) on the combined dataset.",4 Learning the Alignment Model,[0],[0]
"Because our goal is to study the impact on the chunk level predictions, in the full model, the sentence loss does not play a part on examples from DA.",4 Learning the Alignment Model,[0],[0]
"The primary research question we seek to answer via experiments is: Can we better predict chunk alignments and similarities by taking advantage of sentence level similarity data?
",5 Experiments and Results,[0],[0]
"Datasets We used the training and test data from the 2016 SemEval shared tasks of predicting semantic textual similarity (Agirre et al., 2016a) and interpretable STS (Agirre et al., 2016b), that is, tasks 1 and 2 respectively.",5 Experiments and Results,[0],[0]
"For our experiments, we used the headlines and images sections of the data.",5 Experiments and Results,[0],[0]
"The data for the interpretable STS task, consisting of manually aligned and scored chunks, provides the alignment datasets for training (DA).",5 Experiments and Results,[0],[0]
"The headlines section of the training data consists for 756 sentence pairs, while the images section consists for 750 sentence pairs.",5 Experiments and Results,[0],[0]
The data for the STS task acts as our sentence level training dataset (DS).,5 Experiments and Results,[0],[0]
"For the headlines section, we used the 2013 headlines test set consisting of 750 sentence pairs with gold sentence similarity scores.",5 Experiments and Results,[0],[0]
"For the images section, we used the 2014 images test set consisting of 750 examples.",5 Experiments and Results,[0],[0]
"We evaluated our models on the official Task 2 test set, consisting of 375 sentence pairs for both the headlines and images sections.",5 Experiments and Results,[0],[0]
"In all experiments, we used gold standard chunk boundaries if they are available (i.e., for DA).
",5 Experiments and Results,[0],[0]
"Pre-processing We pre-processed the sentences with parts of speech using the Stanford CoreNLP toolkit (Manning et al., 2014).",5 Experiments and Results,[0],[0]
"Since our setting assumes that we have the chunks as input, we used the Illinois shallow parser (Clarke et al., 2012) to extract chunks from DS .",5 Experiments and Results,[0],[0]
We post-processed the predicted chunks to correct for errors using the following steps: 1.,5 Experiments and Results,[0],[0]
Split on punctuation; 2.,5 Experiments and Results,[0],[0]
Split on verbs in NP; 3.,5 Experiments and Results,[0],[0]
Split on nouns in VP; 4.,5 Experiments and Results,[0],[0]
Merge PP+NP into PP; 5.,5 Experiments and Results,[0],[0]
"Merge VP+PRT into VP if the PRT chunk is not a preposition or a subordinating
conjunction; 6.",5 Experiments and Results,[0],[0]
Merge SBAR+NP into SBAR; and 7.,5 Experiments and Results,[0],[0]
Create new contiguous chunks using tokens that are marked as being outside a chunk by the shallow parser.,5 Experiments and Results,[0],[0]
"We found that using the above postprocessing rules, improved the F1 of chunk accuracy from 0.7865 to 0.8130.",5 Experiments and Results,[0],[0]
We also found via crossvalidation that this post-processing improved overall alignment accuracy.,5 Experiments and Results,[0],[0]
"The reader may refer to other STS resources (Karumuri et al., 2015) for further improvements along this direction.
",5 Experiments and Results,[0],[0]
"Experimental setup We performed stochastic gradient descent for 200 epochs in our experiments, with a mini-batch size of 20.",5 Experiments and Results,[0],[0]
"We determined the three λ’s using cross-validation, with different hyperparameters for examples fromDA andDS .",5 Experiments and Results,[0],[0]
Table 1 lists the best hyperparameter values.,5 Experiments and Results,[0],[0]
"For performing inference, we used the Gurobi optimizer4.
",5 Experiments and Results,[0],[0]
"As noted in Section 3.1, the parameter αl combines chunk scores into sentence scores.",5 Experiments and Results,[0],[0]
"To find these hyper-parameters, we used a set of 426 sentences from the from the headlines training data that had both sentence and chunk annotation.",5 Experiments and Results,[0],[0]
We simplified the search by assuming that αEqui is always 1.0 and all labels other than OPPO have the same α.,5 Experiments and Results,[0],[0]
"Using grid search over [−1, 1] in increments of 0.1, we selected α’s that gave us the highest Pearson correlation for sentence level similarities.",5 Experiments and Results,[0],[0]
"The best α’s (with a Pearson correlation of 0.7635) were:
αl =    1, l = EQUI, −1, l = OPPO, 0.7, otherwise
Results Following the official evaluation for the SemEval task, we evaluate both alignments and their
4http://www.gurobi.com/
corresponding similarity scores.",5 Experiments and Results,[0],[0]
"The typed alignment evaluation (denoted by typed ali in the results table) measures F1 over the alignment edges where the types need to match, but scores are ignored.",5 Experiments and Results,[0],[0]
"The typed similarity evaluation (denoted by typed score) is the more stringent evaluation that measures F1 of the alignment edge labels, but penalizes them if the similarity scores do not match.",5 Experiments and Results,[0],[0]
The untyped versions of alignment and scored alignment evaluations ignore alignment labels.,5 Experiments and Results,[0],[0]
"These metrics, based on Melamed (1997), are tailored for the interpretable STS task5.",5 Experiments and Results,[0],[0]
We refer the reader to the guidelines of the task for further details.,5 Experiments and Results,[0],[0]
We report both scores in Table 2.,5 Experiments and Results,[0],[0]
"We also list the performance of the baseline system (Sultan et al., 2014a) and the top ranked systems from the 2016 shared task for each dataset6.
",5 Experiments and Results,[0],[0]
"By comparing the rows labeledDA andDA +DS in Table 2 (a) and Table 2 (b), we see that in both the headlines and the images datasets, adding sentence level information improves the untyped score, lifting the stricter typed score F1.",5 Experiments and Results,[0],[0]
"On the headlines dataset, incorporating sentence-level information degrades both the untyped and typed alignment quality because we cross-validated on the typed score metric.
",5 Experiments and Results,[0],[0]
"The typed score metric is the combination of untyped alignment, untyped score and typed alignment.",5 Experiments and Results,[0],[0]
"From the row DA +DS in Table 2(a), we observe that the typed score F1 is slightly behind that of rank 1 system while all other three metrics are significantly better, indicating that we need to improve our modeling of the intersection of the three aspects.",5 Experiments and Results,[0],[0]
"However, this does not apply to images
5In the SemEval 2016 shared task, the typed score is the metric used for system ranking.
",5 Experiments and Results,[0],[0]
"6http://alt.qcri.org/semeval2016/task2/
dataset where the improvement on the typed score F1 comes from the typed alignment.
",5 Experiments and Results,[0],[0]
"Further, we see that even our base model that only depends on the alignment data offers strong alignment F1 scores.",5 Experiments and Results,[0],[0]
This validates the utility of jointly modeling alignments and chunk similarities.,5 Experiments and Results,[0],[0]
Adding sentence data to this already strong system leads to performance that is comparable to or better than the state-of-the-art systems.,5 Experiments and Results,[0],[0]
"Indeed, our final results would have been ranked first on the images task and a close second on the headlines task in the official standings.
",5 Experiments and Results,[0],[0]
The most significant feedback coming from sentence-level information is with respect to the chunk similarity scores.,5 Experiments and Results,[0],[0]
"While we observed slight change in the unscored alignment performance, for both the headlines and the images datasets, we saw improvements in both scored precision and recall when sentence level data was used.",5 Experiments and Results,[0],[0]
"In this section, first, we report the results of manual error analysis.",6 Analysis and Discussion,[0],[0]
"Then, we study the ability of our model to handle data from different domains.",6 Analysis and Discussion,[0],[0]
"To perform a manual error analysis, we selected 40 examples from the development set of the headlines section.",6.1 Error Analysis,[0],[0]
We classified the errors made by the full model trained on the alignment and sentence datasets.,6.1 Error Analysis,[0],[0]
"Below, we report the four most significant types of errors:
1.",6.1 Error Analysis,[0],[0]
"Contextual implication: Chunks that are meant to be aligned are not synonyms by them-
selves but are implied by the context.",6.1 Error Analysis,[0],[0]
"For instance, Israeli forces and security forces might be equivalent in certain contexts.",6.1 Error Analysis,[0],[0]
"Out of the 16 instances of EQUI being misclassified as SPE, eight were caused by the features’ inability to ascertain contextual implications.",6.1 Error Analysis,[0],[0]
"This also accounted for four out of the 15 failures to identify alignments.
2.",6.1 Error Analysis,[0],[0]
"Semantic phrase understanding: These are the cases where our lexical resources failed, e. g., ablaze and left burning.",6.1 Error Analysis,[0],[0]
This accounted for ten of the 15 chunk alignment failures and nine of the 21 labeling errors.,6.1 Error Analysis,[0],[0]
"Among these, some errors (four alignment failures and four labeling errors) were much simpler than others that could be handled with relatively simple features (e.g. family reunions↔ family unions).
",6.1 Error Analysis,[0],[0]
3.,6.1 Error Analysis,[0],[0]
Preposition semantics:,6.1 Error Analysis,[0],[0]
The inability to account for preposition semantics accounts for three of the 16 cases where EQUI is mistaken as a SPE.,6.1 Error Analysis,[0],[0]
"Some examples include at 91 ↔ aged 91 and catch fire↔ after fire.
4.",6.1 Error Analysis,[0],[0]
"Underestimated EQUI score: Ten out of 14 cases of score underestimation happened on EQUI label.
",6.1 Error Analysis,[0],[0]
Our analysis suggests that we need better contextual features and phrasal features to make further gains in aligning constituents.,6.1 Error Analysis,[0],[0]
"In all the experiments in Section 5, we used sentence datasets belonging to the same domain as the alignment dataset (either headlines or images).",6.2 Does the text domain matter?,[0],[0]
"Given that our model can take advantage of two separate datasets, a natural question to ask is how the domain of the sentence dataset influences overall alignment performance.",6.2 Does the text domain matter?,[0],[0]
"Additionally, we can also ask how well the trained classifiers perform on out-ofdomain data.",6.2 Does the text domain matter?,[0],[0]
We performed a series of experiments to explore these two questions.,6.2 Does the text domain matter?,[0],[0]
"Table 3 summarizes the results of these experiments.
",6.2 Does the text domain matter?,[0],[0]
The columns labeled Train and Test of the table show the training and test sets used.,6.2 Does the text domain matter?,[0],[0]
"Each dataset can be either the headlines section (denoted by hdln), or the images section (img) or not used
(∅).",6.2 Does the text domain matter?,[0],[0]
The last two columns report performance on the test set.,6.2 Does the text domain matter?,[0],[0]
"The rows 1 and 5 in the table correspond to the in-domain settings and match the results of typed alignment and score in Table 2.
",6.2 Does the text domain matter?,[0],[0]
"When the headlines data is tested on the images section, we see that there is the usual domain adaptation problem (row 3 vs row 1) and using target images sentence data does not help (row 4 vs row 3).",6.2 Does the text domain matter?,[0],[0]
"In contrast, even though there is a domain adaptation problem when we compare the rows 5 and 7, we see that once again, using headlines sentence data improves the predicted scores (row 7 vs row 8).",6.2 Does the text domain matter?,[0],[0]
"This observation can be explained by the fact that the images sentences are relatively simpler and headlines dataset can provide richer features in comparison, thus allowing for stronger feedback from sentences to constituents.
",6.2 Does the text domain matter?,[0],[0]
The next question concerns how the domain of the sentence dataset DS influences alignment and similarity performance.,6.2 Does the text domain matter?,[0],[0]
"To answer this, we can compare the results in every pair of rows (i.e., 1 vs 2, 3 vs 4, etc.)",6.2 Does the text domain matter?,[0],[0]
"We see that when the sentence data from the image data is used in conjunction to the headlines chunk data, it invariably makes the classifiers worse.",6.2 Does the text domain matter?,[0],[0]
"In contrast, the opposite trend is observed when the headlines sentence data augments the images chunk data.",6.2 Does the text domain matter?,[0],[0]
"This can once again be explained by relatively simpler sentence constructions in the images set, suggesting that we can leverage linguistically complex corpora to improve alignment on simpler ones.",6.2 Does the text domain matter?,[0],[0]
"Indeed, surprisingly, we obtain marginally better performance on the images set when we use images chunk level data in conjunction
with the headlines sentence data (row 6 vs the row labeled DA +DS in the Table 2(b)).",6.2 Does the text domain matter?,[0],[0]
Aligning words and phrases between pairs of sentences is widely studied in NLP.,7 Related Work,[0],[0]
"Machine translation has a rich research history of using alignments (for e.g., (Koehn et al., 2003; Och and Ney, 2003)), going back to the IBM models (Brown et al., 1993).",7 Related Work,[0],[0]
"From the learning perspective, the alignments are often treated as latent variables during learning, as in this work where we treated alignments in the sentence level training examples as latent variables.",7 Related Work,[0],[0]
"Our work is also conceptually related to (Ganchev et al., 2008), which asked whether improved alignment error implied better translation.
",7 Related Work,[0],[0]
"Outside of machine translation, alignments are employed either explicitly or implicitly for recognizing textual entailment (Brockett, 2007; Chang et al., 2010a) and paraphrase recognition (Das and Smith, 2009; Chang et al., 2010a).",7 Related Work,[0],[0]
"Additionally, alignments are explored in multiple ways (tokens, phrases, parse trees and dependency graphs) as a foundation for natural logic inference (Chambers et al., 2007; MacCartney and Manning, 2007; MacCartney et al., 2008).",7 Related Work,[0],[0]
"Our proposed aligner can be used to aid such applications.
",7 Related Work,[0],[0]
"For predicting sentence similarities, in both variants of the task, word or chunk alignments have extensively been used (Sultan et al., 2015; Sultan et al., 2014a; Sultan et al., 2014b; Hänig et al., 2015; Karumuri et al., 2015; Agirre et al., 2015b; Banjade et al., 2015, and others).",7 Related Work,[0],[0]
"In contrast to these systems, we proposed a model that is trained jointly to predict alignments, chunk similarities and sentence similarities.",7 Related Work,[0],[0]
"To our knowledge, this is the first approach that combines sentence-level similarity data with fine grained alignments to train a chunk aligner.",7 Related Work,[0],[0]
"In this paper, we presented the first joint framework for aligning sentence constituents and predicting constituent and sentence similarities.",8 Conclusion,[0],[0]
We showed that our predictive model can be trained using both aligned constituent data and sentence similarity data.,8 Conclusion,[0],[0]
"Our jointly trained model achieves stateof-the-art performance on the task of predicting in-
terpretable sentence similarities.",8 Conclusion,[0],[0]
The authors wish to thank the anonymous reviewers and the members of the Utah NLP group for their valuable comments and pointers to references.,Acknowledgments,[0],[0]
We study the problem of jointly aligning sentence constituents and predicting their similarities.,abstractText,[0],[0]
"While extensive sentence similarity data exists, manually generating reference alignments and labeling the similarities of the aligned chunks is comparatively onerous.",abstractText,[0],[0]
This prompts the natural question of whether we can exploit easy-to-create sentence level data to train better aligners.,abstractText,[0],[0]
"In this paper, we present a model that learns to jointly align constituents of two sentences and also predict their similarities.",abstractText,[0],[0]
"By taking advantage of both sentence and constituent level data, we show that our model achieves state-of-the-art performance at predicting alignments and constituent similarities.",abstractText,[0],[0]
Exploiting Sentence Similarities for Better Alignments,title,[0],[0]
We consider the problem of regularized empirical risk minimization (ERM) of linear predictors.,1. Introduction,[0],[0]
"Let a1, . . .",1. Introduction,[0],[0]
", an ∈ Rd be the feature vectors of n data samples, φi : R → R be a convex loss function associated with the linear prediction aTi x, for i = 1, . . .",1. Introduction,[0],[0]
",",1. Introduction,[0],[0]
"n,",1. Introduction,[0],[0]
and g : Rd → R be a convex regularization function for the predictor x ∈ Rd.,1. Introduction,[0],[0]
"ERM amounts to solving the following convex optimization problem:
min x∈Rd
{ P (x)
",1. Introduction,[0],[0]
def = 1n,1. Introduction,[0],[0]
∑n i=1,1. Introduction,[0],[0]
φi(a,1. Introduction,[0],[0]
T i x) + g(x) } .,1. Introduction,[0],[0]
"(1)
This formulation covers many well-known classification and regression problems.",1. Introduction,[0],[0]
"For example, logistic regression is obtained by setting φi(z) = log(1 + exp(−biz))",1. Introduction,[0],[0]
where bi ∈ {±1}.,1. Introduction,[0],[0]
"For linear regression problems, the loss
1Department of Computer Science, The University of Chicago, Chicago, Illinois 60637, USA.",1. Introduction,[0],[0]
"2Microsoft Research, Redmond, Washington 98052, USA.",1. Introduction,[0],[0]
"Correspondence to: Jialei Wang <jialei@uchicago.edu>, Lin Xiao <lin.xiao@microsoft.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
function is φi(z) =",1. Introduction,[0],[0]
"(1/2)(z − bi)2, and we get ridge regression with g(x) =",1. Introduction,[0],[0]
(λ/2)‖x‖22 and the elastic net with g(x),1. Introduction,[0],[0]
= λ1‖x‖1,1. Introduction,[0],[0]
+ (λ2/2)‖x‖22.,1. Introduction,[0],[0]
LetA =,1. Introduction,[0],[0]
"[a1, . . .",1. Introduction,[0],[0]
", an]T be the n by d data matrix.",1. Introduction,[0],[0]
"Throughout this paper, we make the following assumptions: Assumption 1.",1. Introduction,[0],[0]
"The functions φi, g and matrix A satisfy:
•",1. Introduction,[0],[0]
"Each φi is δ-strongly convex and 1/γ-smooth where γ > 0 and δ ≥ 0, and γδ ≤ 1;
• g is λ-strongly convex where λ ≥ 0;",1. Introduction,[0],[0]
"• λ+ δµ2 > 0, where µ = √ λmin(ATA).
",1. Introduction,[0],[0]
"The strong convexity and smoothness mentioned above are with respect to the standard Euclidean norm, denoted as ‖x‖ = √ xTx.",1. Introduction,[0],[0]
"(See, e.g., Nesterov (2004, Sections 2.1.1 and 2.1.3) for the exact definitions.)",1. Introduction,[0],[0]
"We allow δ = 0, which simply means φi is convex.",1. Introduction,[0],[0]
"Let R = maxi{‖ai‖} and assuming λ > 0, then R2/(γλ) is a popular definition of condition number for analyzing complexities of different algorithms.",1. Introduction,[0],[0]
"The last condition above means that the primal objective function P (x) is strongly convex, even if λ = 0.
",1. Introduction,[0],[0]
There have been extensive research activities in recent years on developing efficiently algorithms for solving problem (1).,1. Introduction,[0],[0]
A broad class of randomized algorithms that exploit the finite sum structure in the ERM problem have emerged as very competitive both in terms of theoretical complexity and practical performance.,1. Introduction,[0],[0]
"They can be put into three categories: primal, dual, and primal-dual.
",1. Introduction,[0],[0]
Primal randomized algorithms work with the ERM problem (1) directly.,1. Introduction,[0],[0]
"They are modern versions of randomized incremental gradient methods (e.g., Bertsekas, 2012; Nedic & Bertsekas, 2001) equipped with variance reduction techniques.",1. Introduction,[0],[0]
Each iteration of such algorithms only process one data point ai with complexity O(d).,1. Introduction,[0],[0]
"They includes SAG (Roux et al., 2012), SAGA (Defazio et al., 2014), and SVRG (Johnson & Zhang, 2013; Xiao & Zhang, 2014), which all achieve the iteration complexity O ( (n+R2/(γλ))",1. Introduction,[0],[0]
log(1/ǫ) ) to find an ǫoptimal solution.,1. Introduction,[0],[0]
"In fact, they are capable of exploiting the strong convexity from data, meaning that the condition number R2/(γλ) in the complexity can be replaced by the more favorable oneR2/(γ(λ+δµ2/n)).",1. Introduction,[0],[0]
"This improvement can be achieved without explicit knowledge of µ from data.
",1. Introduction,[0],[0]
"Dual algorithms solve Fenchel dual of (1) by maximizing
D(y) def = 1n",1. Introduction,[0],[0]
∑n i=1,1. Introduction,[0],[0]
−φ∗i (yi)− g∗ ( − 1n ∑n i=1 yiai ),1. Introduction,[0],[0]
(2) using randomized coordinate ascent algorithms.,1. Introduction,[0],[0]
(Here φ∗i and g∗ denotes the conjugate functions of φi and g.),1. Introduction,[0],[0]
"They include SDCA (Shalev-Shwartz & Zhang, 2013), Nesterov (2012) and Richtárik & Takáč (2014).",1. Introduction,[0],[0]
They have the same complexity O ( (n+R2/(γλ)),1. Introduction,[0],[0]
"log(1/ǫ) ) , but cannot exploit strong convexity, if any (when δµ2 > 0), from data.
",1. Introduction,[0],[0]
"Primal-dual algorithms solve the convex-concave saddle point problem minxmaxy L(x, y) where
L(x, y) def=",1. Introduction,[0],[0]
1n,1. Introduction,[0],[0]
∑n i=1,1. Introduction,[0],[0]
"( yi〈ai, x〉 − φ∗i (yi) ) + g(x).",1. Introduction,[0],[0]
"(3)
In particular, SPDC (Zhang & Xiao, 2015) achieves an accelerated linear convergence rate with iteration complexity O ( (n+ √ nR/ √ γλ) log(1/ǫ) ) , which is better than the aforementioned non-accelerated complexity when R2/(γλ)",1. Introduction,[0],[0]
"> n. Lan & Zhou (2015) developed dual-free variants of accelerated primal-dual algorithms, but without considering the linear predictor structure in ERM.",1. Introduction,[0],[0]
"Balamurugan & Bach (2016) extended SVRG and SAGA to solving saddle point problems.
",1. Introduction,[0],[0]
Accelerated primal and dual randomized algorithms have also been developed.,1. Introduction,[0],[0]
"Nesterov (2012), Fercoq & Richtárik (2015) and Lin et al. (2015b) developed accelerated coordinate gradient algorithms, which can be applied to solve the dual problem (2).",1. Introduction,[0],[0]
Allen-Zhu (2016) developed an accelerated variant of SVRG.,1. Introduction,[0],[0]
"Acceleration can also be obtained using the Catalyst framework (Lin et al., 2015a).",1. Introduction,[0],[0]
They all achieve the same O ( (n+ √ nR/ √ γλ) log(1/ǫ) ) complexity.,1. Introduction,[0],[0]
A common feature of accelerated algorithms is that they require good estimate of the strong convexity parameter.,1. Introduction,[0],[0]
"This makes hard for them to exploit strong convexity from data because the minimum singular value µ of the data matrix A is very hard to estimate in general.
",1. Introduction,[0],[0]
"In this paper, we show that primal-dual algorithms are capable of exploiting strong convexity from data if the algorithm parameters (such as step sizes) are set appropriately.",1. Introduction,[0],[0]
"While these optimal setting depends on the knowledge of the convexity parameter µ from the data, we develop adaptive variants of primal-dual algorithms that can tune the parameter automatically.",1. Introduction,[0],[0]
"Such adaptive schemes rely critically on the capability of evaluating the primal-dual optimality gaps by primal-dual algorithms.
",1. Introduction,[0],[0]
A major disadvantage of primal-dual algorithms is that the required dual proximal mapping may not admit closedform or efficient solution.,1. Introduction,[0],[0]
"We follow the approach of Lan & Zhou (2015) to derive dual-free variants of the primal-dual algorithms customized for ERM problems with the linear predictor structure, and show that they can also exploit strong convexity from data with correct choices of parameters or using an adaptation scheme.
",1. Introduction,[0],[0]
"Algorithm 1 Batch Primal-Dual (BPD) Algorithm input: parameters τ , σ, θ, initial point (x̃(0) = x(0), y(0))
for t = 0, 1, 2, . . .",1. Introduction,[0],[0]
"do y(t+1) = proxσf∗ ( y(t) + σAx̃(t) )
x(t+1) = proxτg ( x(t)",1. Introduction,[0],[0]
"− τAT y(t+1) )
x̃(t+1)",1. Introduction,[0],[0]
= x(t+1),1. Introduction,[0],[0]
+ θ(x(t+1),1. Introduction,[0],[0]
− x(t)) end for,1. Introduction,[0],[0]
"We first study batch primal-dual algorithms, by considering a “batch” version of the ERM problem (1),
minx∈Rd { P (x) def = f(Ax) + g(x) } .",2. Batch primal-dual algorithms,[0],[0]
"(4)
where A ∈ Rn×d.",2. Batch primal-dual algorithms,[0],[0]
We make the following assumptions: Assumption 2.,2. Batch primal-dual algorithms,[0],[0]
"The functions f , g and matrix A satisfy:
• f is δ-strongly convex and 1/γ-smooth where γ > 0 and δ ≥ 0, and γδ ≤ 1;
• g is λ-strongly convex where λ ≥ 0;",2. Batch primal-dual algorithms,[0],[0]
"• λ+ δµ2 > 0, where µ = √ λmin(ATA).
",2. Batch primal-dual algorithms,[0],[0]
"Using conjugate functions, we can derive the dual of (4) as
maxy∈Rn { D(y) def = −f∗(y)− g∗(−AT y) } , (5)
and the convex-concave saddle point formulation is
min x∈Rd max y∈Rn
{ L(x, y) def= g(x)",2. Batch primal-dual algorithms,[0],[0]
+,2. Batch primal-dual algorithms,[0],[0]
yTAx− f∗(y) } .,2. Batch primal-dual algorithms,[0],[0]
"(6)
We consider the primal-dual first-order algorithm proposed by Chambolle & Pock (2011; 2016) for solving the saddle point problem (6), given in Algorithm 1, where proxψ(·), for any convex function ψ",2. Batch primal-dual algorithms,[0],[0]
": Rn ∪ {∞}, is defined as
proxψ(β) = arg min α∈Rn
( ψ(α)",2. Batch primal-dual algorithms,[0],[0]
+,2. Batch primal-dual algorithms,[0],[0]
"(1/2)‖α− β‖2 ) .
",2. Batch primal-dual algorithms,[0],[0]
"Assuming that f is smooth and g is strongly convex, Chambolle & Pock (2011; 2016) showed that Algorithm 1 achieves accelerated linear convergence rate if λ > 0.",2. Batch primal-dual algorithms,[0],[0]
"However, they did not consider the case where additional or the sole source of strong convexity comes from f(Ax).",2. Batch primal-dual algorithms,[0],[0]
"In the following theorem, we show how to set the parameters τ , σ and θ to exploit both sources of strong convexity to achieve fast linear convergence.
",2. Batch primal-dual algorithms,[0],[0]
Theorem 1.,2. Batch primal-dual algorithms,[0],[0]
"Suppose Assumption 2 holds and (x⋆, y⋆) is the unique saddle point of L defined in (6).",2. Batch primal-dual algorithms,[0],[0]
Let L = ‖A‖ =√ λmax(ATA).,2. Batch primal-dual algorithms,[0],[0]
"If we set the parameters in Algorithm 1 as
σ = 1L
√ λ+δµ2
γ , τ = 1 L
√ γ
λ+δµ2 , (7)
and θ = max{θx, θy} where
θx = ( 1− δ(δ+2σ) µ2 L2 ) 1 1+τλ , θy = 1 1+σγ/2 , (8)
then we have (
1 2τ + λ 2 ) ‖x(t)",2. Batch primal-dual algorithms,[0],[0]
− x⋆‖2 + γ4 ‖y(t),2. Batch primal-dual algorithms,[0],[0]
"− y⋆‖2 ≤ θtC,
L(x(t), y⋆)− L(x⋆, y(t))",2. Batch primal-dual algorithms,[0],[0]
"≤ θtC,
whereC = (
1 2τ + λ 2
)",2. Batch primal-dual algorithms,[0],[0]
"‖x(0)−x⋆‖2+ ( 1 2σ+ γ 4 ) ‖y(0)−y⋆‖2.
",2. Batch primal-dual algorithms,[0],[0]
The proof of Theorem 1 is given in Appendices B and C. Here we give a detailed analysis of the convergence rate.,2. Batch primal-dual algorithms,[0],[0]
Substituting σ,2. Batch primal-dual algorithms,[0],[0]
"and τ in (7) into the expressions for θy and θx in (8), and assuming γ(λ+ δµ2) ≪ L2, we have
θx ≈ 1− γδµ 2
L2
( 2 √ γ(λ+δµ2)",2. Batch primal-dual algorithms,[0],[0]
L + γδ )−1,2. Batch primal-dual algorithms,[0],[0]
"− λL √ γ λ+δµ2 ,
θy = 1 1+ √ γ(λ+δµ2)/(2L)
",2. Batch primal-dual algorithms,[0],[0]
"≈ 1− √ γ(λ+δµ2)
2L .
",2. Batch primal-dual algorithms,[0],[0]
"Since the overall condition number of the problem is L2 γ(λ+δµ2) , it is clear that θy is an accelerated convergence rate.",2. Batch primal-dual algorithms,[0],[0]
"Next we examine θx in two special cases.
",2. Batch primal-dual algorithms,[0],[0]
The case of δµ2 = 0,2. Batch primal-dual algorithms,[0],[0]
but λ > 0.,2. Batch primal-dual algorithms,[0],[0]
"In this case, we have τ = 1L √ γ λ",2. Batch primal-dual algorithms,[0],[0]
"and σ = 1 L √ λ γ , and thus
θx= 1 1+ √ γλ/L",2. Batch primal-dual algorithms,[0],[0]
≈,2. Batch primal-dual algorithms,[0],[0]
1−,2. Batch primal-dual algorithms,[0],[0]
"√ γλ L , θy= 1 1+ √ γλ/(2L)",2. Batch primal-dual algorithms,[0],[0]
≈ 1−,2. Batch primal-dual algorithms,[0],[0]
√ γλ 2L .,2. Batch primal-dual algorithms,[0],[0]
"Therefore we have θ = max{θx, θy} ≈ 1 − √ λγ 2L .",2. Batch primal-dual algorithms,[0],[0]
"This indeed is an accelerated convergence rate, recovering the result of Chambolle & Pock (2011; 2016).
",2. Batch primal-dual algorithms,[0],[0]
The case of λ = 0 but δµ2 > 0.,2. Batch primal-dual algorithms,[0],[0]
"In this case, we have τ = 1Lµ √ γ δ",2. Batch primal-dual algorithms,[0],[0]
"and σ = µ L √ δ γ , and
θx = 1− γδµ 2 L2 · 12√γδµ/L+γδ , θy ≈ 1− √ γδµ 2L .
",2. Batch primal-dual algorithms,[0],[0]
"Notice that 1γδ L2
µ2 is the condition number of f(Ax).",2. Batch primal-dual algorithms,[0],[0]
"Next we assume µ≪ L and examine how θx varies with γδ.
•",2. Batch primal-dual algorithms,[0],[0]
"If γδ ≈ µ2L2 , meaning f is badly conditioned, then
θx ≈ 1− γδµ 2 L2 · 13√γδµ/L = 1− √ γδµ 3L .
",2. Batch primal-dual algorithms,[0],[0]
"Because the overall condition number is 1γδ L2
µ2 , this is an accelerated linear rate, and so is θ = max{θx, θy}.
",2. Batch primal-dual algorithms,[0],[0]
•,2. Batch primal-dual algorithms,[0],[0]
"If γδ ≈ µL , meaning f is mildly conditioned, then
θx ≈ 1− µ 3 L3 1 2(µ/L)3/2+µ/L ≈ 1− µ2L2 .
",2. Batch primal-dual algorithms,[0],[0]
"This represents a half-accelerated rate, because the overall condition number is 1γδ L2 µ2 ≈ L 3 µ3 .
",2. Batch primal-dual algorithms,[0],[0]
•,2. Batch primal-dual algorithms,[0],[0]
"If γδ = 1, i.e., f is a simple quadratic function, then
θx ≈ 1− µ 2 L2 1 2µ/L+1 ≈ 1− µ2 L2 .
",2. Batch primal-dual algorithms,[0],[0]
"This rate does not have acceleration, because the overall condition number is 1γδ L2 µ2 ≈ L 2 µ2 .
",2. Batch primal-dual algorithms,[0],[0]
"Algorithm 2 Adaptive Batch Primal-Dual (Ada-BPD) input: problem constants λ, γ, δ, L and µ̂ > 0, initial
point (x(0), y(0)), and adaptation period T .",2. Batch primal-dual algorithms,[0],[0]
"Compute σ, τ , and θ as in (7) and (8) using µ = µ̂ for t = 0, 1, 2, . . .",2. Batch primal-dual algorithms,[0],[0]
"do y(t+1) = proxσf∗ ( y(t) + σAx̃(t) )
x(t+1) = proxτg ( x(t)",2. Batch primal-dual algorithms,[0],[0]
− τAT y(t+1) ) x̃(t+1),2. Batch primal-dual algorithms,[0],[0]
= x(t+1),2. Batch primal-dual algorithms,[0],[0]
+ θ(x(t+1),2. Batch primal-dual algorithms,[0],[0]
"− x(t)) if mod(t+ 1, T )",2. Batch primal-dual algorithms,[0],[0]
"== 0 then
(σ, τ, θ) = BPD-Adapt ( {P (s), D(s)}t+1s=t−T )
end if end for
Algorithm 3 BPD-Adapt (simple heuristic) input: previous estimate µ̂, adaption period T , primal and
dual objective values {P (s), D(s)}ts=t−T if P (t) −D(t)",2. Batch primal-dual algorithms,[0],[0]
< θT (P (t−T ) −D(t−T )),2. Batch primal-dual algorithms,[0],[0]
"then µ̂ := √ 2µ̂ else µ̂ := µ̂/ √ 2 end if Compute σ, τ , and θ as in (7) and (8) using µ = µ̂
output: new parameters (σ, τ, θ)
",2. Batch primal-dual algorithms,[0],[0]
"In summary, the extent of acceleration in the dominating factor θx (which determines θ) depends on the relative size of γδ and µ2/L2, i.e., the relative conditioning between the function f and the matrix A.",2. Batch primal-dual algorithms,[0],[0]
"In general, we have full acceleration if γδ ≤",2. Batch primal-dual algorithms,[0],[0]
µ2/L2.,2. Batch primal-dual algorithms,[0],[0]
The theory predicts that the acceleration degrades as the function f gets better conditioned.,2. Batch primal-dual algorithms,[0],[0]
"However, in our numerical experiments, we often observe acceleration even if γδ gets closer to 1.
",2. Batch primal-dual algorithms,[0],[0]
"As explained in Chambolle & Pock (2011), Algorithm 1 is equivalent to a preconditioned ADMM.",2. Batch primal-dual algorithms,[0],[0]
"Deng & Yin (2016) characterized various conditions for ADMM to obtain linear convergence, but did not derive the convergence rate for the case we consider in this paper.",2. Batch primal-dual algorithms,[0],[0]
"In practice, it is often very hard to obtain a good estimate of the problem-dependent constants, especially µ =√ λmin(ATA), in order to apply the algorithmic parameters specified in Theorem 1.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"Here we explore heuristics that can enable adaptive tuning of such parameters, which often lead to much improved performance in practice.
",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"A key observation is that the convergence rate of the BPD algorithm changes monotonically with the overall convexity parameter λ + δµ2, regardless of the extent of acceleration.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"In other words, the larger λ + δµ2 is, the faster the convergence.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"Therefore, if we can monitor the progress of
Algorithm 4 BPD-Adapt (robust heuristic) input: previous rate estimate ρ > 0, ∆ = δµ̂2, period T ,
constants c < 1 and c > 1, and {P (s), D(s)}ts=t−T Compute new rate estimate ρ̂ = P
(t)−D(t)",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"P (t−T )−D(t−T )
",2.1. Adaptive batch primal-dual algorithms,[0],[0]
if ρ̂ ≤,2.1. Adaptive batch primal-dual algorithms,[0],[0]
"c ρ then ∆ := 2∆, ρ := ρ̂ else if ρ̂ ≥ c ρ then ∆ := ∆/2, ρ := ρ̂ else ∆ := ∆ end if σ = 1L √ λ+∆",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"γ , τ = 1 L √ γ λ+∆
Compute θ using (8) or set θ = 1 output: new parameters (σ, τ, θ)
the convergence and compare it with the predicted convergence rate in Theorem 1, then we can adjust the estimated parameters to exploit strong convexity from data.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"More specifically, if the observed convergence rate is slower than the predicted rate, then we should reduce the estimate of µ; otherwise we should increase µ for faster convergence.
",2.1. Adaptive batch primal-dual algorithms,[0],[0]
We formalize the above reasoning in Algorithm 2 (called Ada-BPD).,2.1. Adaptive batch primal-dual algorithms,[0],[0]
"This algorithm maintains an estimate µ̂ of the true constant µ, and adjust it every T iterations.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"We use P (t) and D(t) to represent the primal and dual objective values at P (x(t)) and D(y(t)), respectively.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"We give two implementations of the tuning procedure BPD-Adapt: Algorithm 3 is a simple heuristic for tuning the estimate µ̂, where the increasing and decreasing factor √ 2 can be changed to other values larger than 1.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
Algorithm 4 is a more robust heuristic.,2.1. Adaptive batch primal-dual algorithms,[0],[0]
It does not rely on the specific convergence rate θ established in Theorem 1.,2.1. Adaptive batch primal-dual algorithms,[0],[0]
"Instead, it simply compares the current estimate of objective reduction rate ρ̂ with the previous estimate ρ.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"It also specifies a non-tuning range of changes in ρ, specified by the interval [c, c].
",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"The capability of accessing both the primal and dual objective values allows primal-dual algorithms to have good estimate of the convergence rate, which enables effective tuning heuristics.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"Automatic tuning of primal-dual algorithms have also been studied by, e.g., Malitsky & Pock (2016) and Goldstein et al. (2013), but with different goals.",2.1. Adaptive batch primal-dual algorithms,[0],[0]
"In this section, we come back to the ERM problem and consider its saddle-point formulation in (3).",3. Randomized primal-dual algorithm,[0],[0]
"Due to its finite sum structure in the dual variables yi, we can develope randomized algorithms to exploit strong convexity from data.",3. Randomized primal-dual algorithm,[0],[0]
"In particular, we extend the stochastic primal-dual coordinate (SPDC) algorithm by Zhang & Xiao (2015).",3. Randomized primal-dual algorithm,[0],[0]
"SPDC is
Algorithm 5 Adaptive SPDC (Ada-SPDC) input: parameters σ, τ , θ > 0, initial point (x(0), y(0)),
and adaptation period T .",3. Randomized primal-dual algorithm,[0],[0]
"Set x̃(0) = x(0) for t = 0, 1, 2, . . .",3. Randomized primal-dual algorithm,[0],[0]
"do pick k ∈ {1, . . .",3. Randomized primal-dual algorithm,[0],[0]
", n}",3. Randomized primal-dual algorithm,[0],[0]
"uniformly at random for i ∈ {1, . . .",3. Randomized primal-dual algorithm,[0],[0]
", n} do
if i == k then y (t+1) k = proxσφ∗k ( y (t) k + σa T k x̃ (t) ) else y (t+1)",3. Randomized primal-dual algorithm,[0],[0]
"i = y (t) i
end if end for
x(t+1)",3. Randomized primal-dual algorithm,[0],[0]
"= proxτg
( x(t)− τ",3. Randomized primal-dual algorithm,[0],[0]
"( u(t)+ (y
(t+1) k −y (t) k )",3. Randomized primal-dual algorithm,[0],[0]
"ak
))
u(t+1) = u(t) + 1n",3. Randomized primal-dual algorithm,[0],[0]
(y (t+1) k,3. Randomized primal-dual algorithm,[0],[0]
− y (t) k )ak x̃(t+1) = x(t+1),3. Randomized primal-dual algorithm,[0],[0]
+ θ(x(t+1),3. Randomized primal-dual algorithm,[0],[0]
"− x(t)) if mod(t+ 1, T · n) = 0",3. Randomized primal-dual algorithm,[0],[0]
"then
(τ, σ, θ) = SPDC-Adapt ( {P (t−sn), D(t−sn)}Ts=0 )
end if end for
a special case of the Ada-SPDC algorithm in Algorithm 5, by setting the adaption period T = ∞ (no adaption).",3. Randomized primal-dual algorithm,[0],[0]
The following theorem is proved in Appendix E. Theorem 2.,3. Randomized primal-dual algorithm,[0],[0]
Suppose Assumption 1 holds.,3. Randomized primal-dual algorithm,[0],[0]
"Let (x⋆, y⋆) be the saddle point of the function L defined in (3), and R = max{‖a1‖, . . .",3. Randomized primal-dual algorithm,[0],[0]
", ‖an‖}.",3. Randomized primal-dual algorithm,[0],[0]
"If we set T = ∞ in Algorithm 5 (no adaption) and let
τ = 14R
√ γ
nλ+δµ2 , σ",3. Randomized primal-dual algorithm,[0],[0]
"= 1 4R
√ nλ+δµ2
γ , (9)
and θ = max{θx, θy} where
θx = ( 1− τσδµ22n(σ+4δ) )",3. Randomized primal-dual algorithm,[0],[0]
"1 1+τλ , θy = 1+((n−1)/n)σγ/2 1+σγ/2 , (10)
then we have (
1 2τ + λ 2
)",3. Randomized primal-dual algorithm,[0],[0]
E [ ‖x(t),3. Randomized primal-dual algorithm,[0],[0]
− x⋆‖2 ] + γ4E [ ‖y(t),3. Randomized primal-dual algorithm,[0],[0]
"− y⋆‖2 ] ≤ θtC,
E [ L(x(t), y⋆)− L(x⋆, y(t))",3. Randomized primal-dual algorithm,[0],[0]
"] ≤ θtC,
whereC = (
1 2τ + λ 2
)",3. Randomized primal-dual algorithm,[0],[0]
"‖x(0)−x⋆‖2+ ( 1 2σ+ γ 4 ) ‖y(0)−y⋆‖2.
",3. Randomized primal-dual algorithm,[0],[0]
"The expectation E[·] is taken with respect to the history of random indices drawn at each iteration.
",3. Randomized primal-dual algorithm,[0],[0]
"Below we give a detailed discussion on the expected convergence rate established in Theorem 2.
",3. Randomized primal-dual algorithm,[0],[0]
The cases of σµ2 = 0 but λ > 0.,3. Randomized primal-dual algorithm,[0],[0]
In this case we have τ = 14R √ γ nλ,3. Randomized primal-dual algorithm,[0],[0]
"and σ = 1 4R √ nλ γ , and
θx = 1 1+τλ = 1− 11+4R√n/(λγ) ,
θy = 1+((n−1)/n)σγ/2 1+σγ/2 = 1− 1n+8R√n/(λγ) .
",3. Randomized primal-dual algorithm,[0],[0]
Hence θ = θy .,3. Randomized primal-dual algorithm,[0],[0]
"These recover the parameters and convergence rate of the standard SPDC (Zhang & Xiao, 2015).
",3. Randomized primal-dual algorithm,[0],[0]
The cases of σµ2 > 0,3. Randomized primal-dual algorithm,[0],[0]
but λ = 0.,3. Randomized primal-dual algorithm,[0],[0]
In this case we have τ = 14Rµ,3. Randomized primal-dual algorithm,[0],[0]
√ γ δ,3. Randomized primal-dual algorithm,[0],[0]
"and σ = µ 4R √ δ γ , and
θx = 1− τσδµ 2 2n(σ+4δ)",3. Randomized primal-dual algorithm,[0],[0]
= 1− γδµ2 32nR2 · 1√γδµ/(4R)+4γδ .,3. Randomized primal-dual algorithm,[0],[0]
θy,3. Randomized primal-dual algorithm,[0],[0]
= 1− 1n+8nR/(µ√γδ),3. Randomized primal-dual algorithm,[0],[0]
"≈ 1− √ γδµ 8nR ( 1 + √ γδµ 8R )−1 .
",3. Randomized primal-dual algorithm,[0],[0]
"Since the objective is R2/γ-smooth and δµ2/n-strongly convex, θy is an accelerated rate if √ γδµ 8R ≪ 1 (otherwise θy ≈ 1− 1n ).",3. Randomized primal-dual algorithm,[0],[0]
"For θx, we consider different situations:
•",3. Randomized primal-dual algorithm,[0],[0]
"If µ ≥ R, then we have θx ≈ 1− √ γδµ nR , which is an
accelerated rate.",3. Randomized primal-dual algorithm,[0],[0]
"So is θ = max{θx, θy}.",3. Randomized primal-dual algorithm,[0],[0]
•,3. Randomized primal-dual algorithm,[0],[0]
If µ < R and γδ,3. Randomized primal-dual algorithm,[0],[0]
"≈ µ2R2 , then θx",3. Randomized primal-dual algorithm,[0],[0]
"≈ 1− √ γδµ nR , which
represents an accelerated rate.",3. Randomized primal-dual algorithm,[0],[0]
"The iteration complexity of SPDC is Õ( nR
µ √ γδ ), which is better than that of
SVRG in this case, which is Õ( nR 2
γδµ2 ).
",3. Randomized primal-dual algorithm,[0],[0]
•,3. Randomized primal-dual algorithm,[0],[0]
If µ < R and γδ,3. Randomized primal-dual algorithm,[0],[0]
≈ µR,3. Randomized primal-dual algorithm,[0],[0]
", then we get θx",3. Randomized primal-dual algorithm,[0],[0]
"≈ 1− µ2
nR2 .",3. Randomized primal-dual algorithm,[0],[0]
"This is a half-accelerated rate, because in this case SVRG requires Õ(nR 3
µ3 ) iterations, versus Õ",3. Randomized primal-dual algorithm,[0],[0]
"( nR2 µ2 ) for SPDC.
",3. Randomized primal-dual algorithm,[0],[0]
•,3. Randomized primal-dual algorithm,[0],[0]
If µ < R and γδ,3. Randomized primal-dual algorithm,[0],[0]
"≈ 1, meaning the φi’s are well conditioned, then we get θx",3. Randomized primal-dual algorithm,[0],[0]
≈ 1,3. Randomized primal-dual algorithm,[0],[0]
− γδµ 2 nR2,3. Randomized primal-dual algorithm,[0],[0]
"≈ 1 − µ2
nR2 , which is a non-accelerated rate.",3. Randomized primal-dual algorithm,[0],[0]
The corresponding iteration complexity is the same as SVRG.,3. Randomized primal-dual algorithm,[0],[0]
"The SPDC-Adapt procedure called in Algorithm 5 follows the same logics as the batch adaption schemes in Algorithms 3 and 4, and we omit the details here.",3.1. Parameter adaptation for SPDC,[0],[0]
"One thing we emphasize here is that the adaptation period T is in terms of epochs, or number of passes over the data.",3.1. Parameter adaptation for SPDC,[0],[0]
"In addition, we only compute the primal and dual objective values after each pass or every few passes, because computing them exactly usually need to take a full pass of the data.
",3.1. Parameter adaptation for SPDC,[0],[0]
"Unlike the batch case where the duality gap decreases monotonically, the duality gap for randomized algorithms can fluctuate wildly.",3.1. Parameter adaptation for SPDC,[0],[0]
So instead of using only the two end values P (t−Tn),3.1. Parameter adaptation for SPDC,[0],[0]
"− D(t−Tn) and P (t) − D(t), we can use more points to estimate the convergence rate through a linear regression.",3.1. Parameter adaptation for SPDC,[0],[0]
"Suppose the primaldual objective values for the last T + 1 passes are (P (0), D(0)), (P (1), D(1)), . . .",3.1. Parameter adaptation for SPDC,[0],[0]
", (P (T ), D(T )), and we need to estimate ρ (rate per pass) such that
P (t)−D(t)",3.1. Parameter adaptation for SPDC,[0],[0]
"≈ ρt ( P (0)−D(0) ) , t = 1, . . .",3.1. Parameter adaptation for SPDC,[0],[0]
", T.
We can turn it into a linear regression problem after taking logarithm and obtain the estimate ρ̂",3.1. Parameter adaptation for SPDC,[0],[0]
"through
log(ρ̂) = 112+22+···+T 2",3.1. Parameter adaptation for SPDC,[0],[0]
∑T t=1,3.1. Parameter adaptation for SPDC,[0],[0]
"t log P (t)−D(t) P (0)−D(0) .
",3.1. Parameter adaptation for SPDC,[0],[0]
"Algorithm 6 Dual-Free BPD Algorithm input: parameters σ, τ , θ > 0, initial point (x(0), y(0))
",3.1. Parameter adaptation for SPDC,[0],[0]
Set x̃(0) = x(0) and v(0) =,3.1. Parameter adaptation for SPDC,[0],[0]
"(f∗)′(y(0)) for t = 0, 1, 2, . . .",3.1. Parameter adaptation for SPDC,[0],[0]
do v(t+1) = v,3.1. Parameter adaptation for SPDC,[0],[0]
"(t)+σAx̃(t)
1+σ , y (t+1) = f ′(v(t+1))
",3.1. Parameter adaptation for SPDC,[0],[0]
x(t+1),3.1. Parameter adaptation for SPDC,[0],[0]
= proxτg ( x(t),3.1. Parameter adaptation for SPDC,[0],[0]
"− τAT y(t+1) )
x̃(t+1)",3.1. Parameter adaptation for SPDC,[0],[0]
= x(t+1),3.1. Parameter adaptation for SPDC,[0],[0]
+ θ(x(t+1),3.1. Parameter adaptation for SPDC,[0],[0]
− x(t)) end for,3.1. Parameter adaptation for SPDC,[0],[0]
"Compared with primal algorithms, one major disadvantage of primal-dual algorithms is the requirement of computing the proximal mapping of the dual function f∗ or φ∗i , which may not admit closed-formed solution or efficient computation.",4. Dual-free Primal-dual algorithms,[0],[0]
"This is especially the case for logistic regression, one of the most popular loss functions used in classification.
",4. Dual-free Primal-dual algorithms,[0],[0]
Lan & Zhou (2015) developed “dual-free” variants of primal-dual algorithms that avoid computing the dual proximal mapping.,4. Dual-free Primal-dual algorithms,[0],[0]
Their main technique is to replace the Euclidean distance in the dual proximal mapping with a Bregman divergence defined over the dual loss function itself.,4. Dual-free Primal-dual algorithms,[0],[0]
We show how to apply this approach to solve the structured ERM problems considered in this paper.,4. Dual-free Primal-dual algorithms,[0],[0]
They can also exploit strong convexity from data if the algorithmic parameters are set appropriately or adapted automatically.,4. Dual-free Primal-dual algorithms,[0],[0]
"First, we consider the batch setting.",4.1. Dual-free BPD algorithm,[0],[0]
"We replace the dual proximal mapping (computing y(t+1)) in Algorithm 1 with
y(t+1)=argmin y
{ f∗(y)−yTAx̃(t)+ 1σD(y, y(t)) } , (11)
where D is the Bregman divergence of a strictly convex kernel function h, defined as
Dh(y, y(t))",4.1. Dual-free BPD algorithm,[0],[0]
"= h(y)− h(y(t))− 〈∇h(y(t)), y − y(t)〉.",4.1. Dual-free BPD algorithm,[0],[0]
"Algorithm 1 is obtained in the Euclidean setting with h(y) = 12‖y‖2 and D(y, y(t))",4.1. Dual-free BPD algorithm,[0],[0]
= 12‖y−y(t)‖2.,4.1. Dual-free BPD algorithm,[0],[0]
"Here we use f∗ as the kernel function, and show that it allows us to compute y(t+1) in (11) very efficiently.",4.1. Dual-free BPD algorithm,[0],[0]
"The following lemma explains the details (Cf. Lan & Zhou, 2015, Lemma 1).",4.1. Dual-free BPD algorithm,[0],[0]
Lemma 1.,4.1. Dual-free BPD algorithm,[0],[0]
"Let the kernel h ≡ f∗ in the Bregman divergence D. If we construct a sequence of vectors {v(t)} such that v(0) = (f∗)′(y(0)) and for all t ≥ 0,
v(t+1) = v (t)+σAx̃(t)
1+σ , (12)
then the solution to problem (11) is y(t+1) = f ′(v(t+1)).
",4.1. Dual-free BPD algorithm,[0],[0]
Proof.,4.1. Dual-free BPD algorithm,[0],[0]
Suppose v(t) = (f∗)′(y(t)),4.1. Dual-free BPD algorithm,[0],[0]
"(true for t = 0), then
D(y, y(t))",4.1. Dual-free BPD algorithm,[0],[0]
"= f∗(y)− f∗(y(t))− v(t)T (y − y(t)).
",4.1. Dual-free BPD algorithm,[0],[0]
"The solution to (11) can be written as
y(t+1)= argmin y
{",4.1. Dual-free BPD algorithm,[0],[0]
"f∗(y)−yTAx̃(t)+ 1σ ( f∗(y)−v(t)T y )}
= argmin y
{( 1 + 1σ ) f∗(y)− ( Ax̃(t)",4.1. Dual-free BPD algorithm,[0],[0]
+ 1σv (t) ),4.1. Dual-free BPD algorithm,[0],[0]
"T y }
= argmax y
{( v(t)+σAx̃(t)
1+σ
)T y",4.1. Dual-free BPD algorithm,[0],[0]
"− f∗(y) }
= argmax y
{ v(t+1) T y",4.1. Dual-free BPD algorithm,[0],[0]
"− f∗(y) } = f ′(v(t+1)),
where in the last equality we used the property of conjugate function when f is strongly convex and smooth.",4.1. Dual-free BPD algorithm,[0],[0]
"Moreover,
v(t+1) =",4.1. Dual-free BPD algorithm,[0],[0]
(f ′)−1(y(t+1)),4.1. Dual-free BPD algorithm,[0],[0]
"= (f∗)′(y(t+1)),
which completes the proof.
",4.1. Dual-free BPD algorithm,[0],[0]
"According to Lemma 1, we only need to provide initial points such that v(0) =",4.1. Dual-free BPD algorithm,[0],[0]
(f∗)′(y(0)) is easy to compute.,4.1. Dual-free BPD algorithm,[0],[0]
We do not need to compute (f∗)′(y(t)),4.1. Dual-free BPD algorithm,[0],[0]
"directly for any t > 0, because it is can be updated as v(t) in (12).",4.1. Dual-free BPD algorithm,[0],[0]
"Consequently, we can update y(t) in the BPD algorithm using the gradient f ′(v(t)), without the need of dual proximal mapping.",4.1. Dual-free BPD algorithm,[0],[0]
The resulting dual-free algorithm is given in Algorithm 6.,4.1. Dual-free BPD algorithm,[0],[0]
Theorem 3.,4.1. Dual-free BPD algorithm,[0],[0]
"Suppose Assumption 2 holds and let (x⋆, y⋆) be the unique saddle point of L defined in (6).",4.1. Dual-free BPD algorithm,[0],[0]
"If we set the parameters in Algorithm 6 as
τ = 1L
√ γ
λ+δµ2 , σ = 1 L
√ γ(λ+ δµ2), (13)
and θ = max{θx, θy} where
θx = ( 1− τσδµ2(4+2σ) )",4.1. Dual-free BPD algorithm,[0],[0]
"1 1+τλ , θy = 1 1+σ/2 , (14)
then we have (
1 2τ + λ 2 ) ‖x(t)",4.1. Dual-free BPD algorithm,[0],[0]
"− x⋆‖2 + 12D(y⋆, y(t))",4.1. Dual-free BPD algorithm,[0],[0]
"≤ θtC,
L(x(t), y⋆)− L(x⋆, y(t))",4.1. Dual-free BPD algorithm,[0],[0]
"≤ θtC,
where C = (
1 2τ + λ 2
) ‖x(0) − x⋆‖2 + ( 1 σ+ 1 2 ) D(y⋆, y(0)).
",4.1. Dual-free BPD algorithm,[0],[0]
"Theorem 3 is proved in Appendices B and D. Assuming γ(λ+ δµ2) ≪ L2, we have
θx",4.1. Dual-free BPD algorithm,[0],[0]
≈ 1−,4.1. Dual-free BPD algorithm,[0],[0]
"γδµ 2 16L2 − λ2L √ γ λ+δµ2 , θy ≈ 1− √ γ(λ+δµ2)",4.1. Dual-free BPD algorithm,[0],[0]
"4L .
",4.1. Dual-free BPD algorithm,[0],[0]
"Again, we gain insights by consider the special cases:
•",4.1. Dual-free BPD algorithm,[0],[0]
If δµ2 = 0,4.1. Dual-free BPD algorithm,[0],[0]
"and λ > 0, then θy ≈ 1",4.1. Dual-free BPD algorithm,[0],[0]
"− √ γλ 4L and θx ≈
1− √ γλ 2L .",4.1. Dual-free BPD algorithm,[0],[0]
"So θ = max{θx, θy} is an accelerated rate.
",4.1. Dual-free BPD algorithm,[0],[0]
•,4.1. Dual-free BPD algorithm,[0],[0]
If δµ2 > 0,4.1. Dual-free BPD algorithm,[0],[0]
"and λ = 0, then θy ≈ 1 − √ γδµ2
4L and
θx",4.1. Dual-free BPD algorithm,[0],[0]
≈ 1− γδµ 2 16L2 .,4.1. Dual-free BPD algorithm,[0],[0]
"Thus θ = max{θx, θy} ≈ 1− γδµ2
16L2 is not accelerated.",4.1. Dual-free BPD algorithm,[0],[0]
"This conclusion does not depends on the relative sizes of γδ and µ2/L2, and it is the major difference from the Euclidean case in Section 2.
",4.1. Dual-free BPD algorithm,[0],[0]
"Algorithm 7 Adaptive Dual-Free SPDC (ADF-SPDC) input: parameters σ, τ , θ > 0, initial point (x(0), y(0)),
and adaptation period T .
",4.1. Dual-free BPD algorithm,[0],[0]
Set x̃(0) = x(0) and v(0)i =,4.1. Dual-free BPD algorithm,[0],[0]
(φ ∗ i ),4.1. Dual-free BPD algorithm,[0],[0]
"′(y(0)i ) for i = 1, . . .",4.1. Dual-free BPD algorithm,[0],[0]
", n for t = 0, 1, 2, . . .",4.1. Dual-free BPD algorithm,[0],[0]
"do
pick k ∈ {1, . . .",4.1. Dual-free BPD algorithm,[0],[0]
", n}",4.1. Dual-free BPD algorithm,[0],[0]
"uniformly at random for i ∈ {1, . . .",4.1. Dual-free BPD algorithm,[0],[0]
", n} do
if i == k then
v (t+1) k =
v (t) k",4.1. Dual-free BPD algorithm,[0],[0]
"+σa T k x̃ (t)
1+σ , y (t+1) k",4.1. Dual-free BPD algorithm,[0],[0]
= φ ′,4.1. Dual-free BPD algorithm,[0],[0]
"k(v (t+1) k )
else v (t+1) i = v (t) i , y (t+1)",4.1. Dual-free BPD algorithm,[0],[0]
"i = y (t) i
end if end for
x(t+1)",4.1. Dual-free BPD algorithm,[0],[0]
"= proxτg
( x(t)− τ",4.1. Dual-free BPD algorithm,[0],[0]
"( u(t)+ (y
(t+1) k −y (t) k )",4.1. Dual-free BPD algorithm,[0],[0]
"ak
))
u(t+1) = u(t) + 1n",4.1. Dual-free BPD algorithm,[0],[0]
(y (t+1) k,4.1. Dual-free BPD algorithm,[0],[0]
− y (t) k )ak x̃(t+1) = x(t+1),4.1. Dual-free BPD algorithm,[0],[0]
+ θ(x(t+1),4.1. Dual-free BPD algorithm,[0],[0]
"− x(t)) if mod(t+ 1, T · n) = 0",4.1. Dual-free BPD algorithm,[0],[0]
"then
(τ, σ, θ) = SPDC-Adapt ( {P (t−sn), D(t−sn)}Ts=0 )
end if end for
If both δµ2 > 0",4.1. Dual-free BPD algorithm,[0],[0]
"and λ > 0, then the extent of acceleration depends on their relative size.",4.1. Dual-free BPD algorithm,[0],[0]
"If λ is on the same order as δµ2 or larger, then accelerated rate is obtained.",4.1. Dual-free BPD algorithm,[0],[0]
"If λ is much smaller than δµ2, then the theory predicts no acceleration.",4.1. Dual-free BPD algorithm,[0],[0]
"Following the same approach, we can derive an Adaptive Dual-Free SPDC algorithm, given in Algorithm 7.",4.2. Dual-free SPDC algorithm,[0],[0]
"On related work, Shalev-Shwartz & Zhang (2016) and (Shalev-Shwartz, 2016) introduced dual-free SDCA.
",4.2. Dual-free SPDC algorithm,[0],[0]
The following theorem characterizes the choice of algorithmic parameters that can exploit strong convexity from data to achieve linear convergence (proof given in Appendix F).,4.2. Dual-free SPDC algorithm,[0],[0]
Theorem 4.,4.2. Dual-free SPDC algorithm,[0],[0]
Suppose Assumption 1 holds.,4.2. Dual-free SPDC algorithm,[0],[0]
"Let (x⋆, y⋆) be the saddle point of L in (3) andR=max{‖a1‖, . . .",4.2. Dual-free SPDC algorithm,[0],[0]
", ‖an‖}.",4.2. Dual-free SPDC algorithm,[0],[0]
"If we set T = ∞ in Algorithm 7 (non adaption) and let
σ = 14R √ γ(nλ+ δµ2), τ = 14R",4.2. Dual-free SPDC algorithm,[0],[0]
"√ γ nλ+δµ2 , (15)
and θ = max{θx, θy} where
θx = ( 1− τσδµ2n(4+2σ) )",4.2. Dual-free SPDC algorithm,[0],[0]
"1 1+τλ , θy = 1+((n−1)/n)σ/2 1+σ/2 ,
(16) then we have (
1 2τ + λ 2
)",4.2. Dual-free SPDC algorithm,[0],[0]
E [ ‖x(t),4.2. Dual-free SPDC algorithm,[0],[0]
"− x⋆‖2 ] + γ4E [ D(y⋆, y(t))",4.2. Dual-free SPDC algorithm,[0],[0]
"] ≤ θtC,
E [ L(x(t), y⋆)− L(x⋆, y(t))",4.2. Dual-free SPDC algorithm,[0],[0]
"] ≤ θtC,
where C = (
1 2τ + λ 2
) ‖x(0) − x⋆‖2 + ( 1 σ+ 1 2 ) D(y⋆, y(0)).
",4.2. Dual-free SPDC algorithm,[0],[0]
"Now we discuss the results of Theorem 4 in further details.
",4.2. Dual-free SPDC algorithm,[0],[0]
The cases of σµ2 = 0 but λ > 0.,4.2. Dual-free SPDC algorithm,[0],[0]
In this case we have τ = 14R √ γ nλ,4.2. Dual-free SPDC algorithm,[0],[0]
"and σ = 1 4R √ nγλ, and
θx = 1− 1 1+4R √ n/(λγ) , θy = 1− 1 n+8R √ n/(λγ) .
",4.2. Dual-free SPDC algorithm,[0],[0]
"The rate is the same as for SPDC in Zhang & Xiao (2015).
",4.2. Dual-free SPDC algorithm,[0],[0]
The cases of σµ2 > 0,4.2. Dual-free SPDC algorithm,[0],[0]
but λ = 0.,4.2. Dual-free SPDC algorithm,[0],[0]
In this case we have τ = 14Rµ,4.2. Dual-free SPDC algorithm,[0],[0]
√ γ δ,4.2. Dual-free SPDC algorithm,[0],[0]
"and σ = µ 4R √ δγ, thus
θx = 1− τσδµ 2 2n(σ+4)",4.2. Dual-free SPDC algorithm,[0],[0]
"= 1− γδµ2 32nR2 · 1√γδµ/(4R)+4 , θy = 1+((n−1)/n)σ/2
1+σ/2 = 1− 1n+8nR/(µ√γδ) .
",4.2. Dual-free SPDC algorithm,[0],[0]
We note that the primal function now is R2/γ-smooth and δµ2/n-strongly convex.,4.2. Dual-free SPDC algorithm,[0],[0]
"We discuss the following cases:
•",4.2. Dual-free SPDC algorithm,[0],[0]
"If √γδµ > R, then we have θx ≈ 1 − √ γδµ
8nR and θy ≈ 1− 1n .",4.2. Dual-free SPDC algorithm,[0],[0]
"Therefore θ = max{θx, θy} ≈ 1− 1n .
",4.2. Dual-free SPDC algorithm,[0],[0]
"• Otherwise, we have θx ≈ 1 − γδµ 2
64nR2 and θy is of the same order.",4.2. Dual-free SPDC algorithm,[0],[0]
"This is not an accelerated rate, and we have the same iteration complexity as SVRG.
",4.2. Dual-free SPDC algorithm,[0],[0]
"Finally, we give concrete examples of how to compute the initial points y(0) and v(0) such that v(0)i =",4.2. Dual-free SPDC algorithm,[0],[0]
(φ ∗ i ),4.2. Dual-free SPDC algorithm,[0],[0]
"′(y(0)i ).
",4.2. Dual-free SPDC algorithm,[0],[0]
•,4.2. Dual-free SPDC algorithm,[0],[0]
"For squared loss, φi(α) = 12 (α − bi)2 and φ∗i (β) = 1 2β 2 + biβ.",4.2. Dual-free SPDC algorithm,[0],[0]
So v (0) i = (φ ∗ i ),4.2. Dual-free SPDC algorithm,[0],[0]
′(y(0)i ) = y (0),4.2. Dual-free SPDC algorithm,[0],[0]
i + bi.,4.2. Dual-free SPDC algorithm,[0],[0]
•,4.2. Dual-free SPDC algorithm,[0],[0]
"For logistic regression, we have bi ∈ {1,−1} and φi(α) = log(1 + e
−biα).",4.2. Dual-free SPDC algorithm,[0],[0]
The conjugate function is φ∗i (β) = (−biβ) log(−biβ) + (1 + biβ) log(1 + biβ) if biβ ∈,4.2. Dual-free SPDC algorithm,[0],[0]
"[−1, 0] and +∞ otherwise.",4.2. Dual-free SPDC algorithm,[0],[0]
We can choose y (0) i =− 12bi and v (0) i =0 such that v (0),4.2. Dual-free SPDC algorithm,[0],[0]
i =(φ ∗ i ),4.2. Dual-free SPDC algorithm,[0],[0]
"′(y(0)i ).
",4.2. Dual-free SPDC algorithm,[0],[0]
"For logistic regression, we have δ = 0 over the full domain of φi.",4.2. Dual-free SPDC algorithm,[0],[0]
"However, each φi is locally strongly convex in bounded domain (Bach, 2014): if z ∈",4.2. Dual-free SPDC algorithm,[0],[0]
"[−B,B], then we know δ = minz φi′′(z)",4.2. Dual-free SPDC algorithm,[0],[0]
≥ exp(−B)/4.,4.2. Dual-free SPDC algorithm,[0],[0]
Therefore it is well suitable for an adaptation scheme similar to Algorithm 4 that do not require knowledge of either δ or µ.,4.2. Dual-free SPDC algorithm,[0],[0]
We present preliminary experiments to demonstrate the effectiveness of our proposed algorithms.,5. Preliminary experiments,[0],[0]
"First, we consider batch primal-dual algorithms for ridge regression over a synthetic dataset.",5. Preliminary experiments,[0],[0]
"The data matrix A has sizes n = 5000 and d = 3000, and its entries are sampled from multivariate normal distribution with mean zero and covariance matrix Σij = 2|i−j|/2.",5. Preliminary experiments,[0],[0]
"We normalize all datasets
such that ai = ai/ (maxj ‖aj‖), to ensure the maximum norm of the data points is 1.",5. Preliminary experiments,[0],[0]
We use ℓ2-regularization g(x) =,5. Preliminary experiments,[0],[0]
"(λ/2)‖x‖2 with three choices of parameter λ: 1/n, 10−2/n and 10−4/n, which represent the strong, medium, and weak levels of regularization, respectively.
",5. Preliminary experiments,[0],[0]
"Figure 1 shows the performance of four different algorithms: the primal accelerated gradient (Primal AG) algorithm (Nesterov, 2004) using λ as strong convexity parameter, the BPD algorithm (Algorithm 1) that uses the same λ and µ2δ = 0, the optimal BPD algorithm (Opt-BPD) that uses µ2δ = λmin(A
TA) n",5. Preliminary experiments,[0],[0]
"≈ 0.022n computed from data,
and the Ada-BPD algorithm (Algorithm 2) with the robust adaptation heuristic (Algorithm 4) with T = 10, c = 0.95 and c = 1.5.",5. Preliminary experiments,[0],[0]
"As expected, the performance of Primal-AG is very similar to that of BPD, and Opt-BPD has the fastest convergence.",5. Preliminary experiments,[0],[0]
"The Ada-BPD algorithm can partially exploit strong convexity from data without knowledge of µ.
",5. Preliminary experiments,[0],[0]
"Next we compare DF-SPDC (Algorithm 5 without adaption) and ADF-SPDC (Algorithm 7 with adaption) against several state-of-the-art randomized algorithms for ERM: SVRG (Johnson & Zhang, 2013), SAGA (Defazio et al., 2014)",5. Preliminary experiments,[0],[0]
"Katyusha (Allen-Zhu, 2016) and the standard SPDC method (Zhang & Xiao, 2015).",5. Preliminary experiments,[0],[0]
"For SVRG and Katyusha (an accelerated variant of SVRG), we choose the variance reduction period as m = 2n.",5. Preliminary experiments,[0],[0]
The step sizes of all algorithms are set as their original paper suggested.,5. Preliminary experiments,[0],[0]
"For
Ada-SPDC and ADF-SPDC, we use the robust adaptation scheme with T = 10, c = 0.95 and c = 1.5.
",5. Preliminary experiments,[0],[0]
We first compare these randomized algorithms for ridge regression over the cpuact data from the LibSVM website (https://www.csie.ntu.edu.tw/˜cjlin/libsvm/).,5. Preliminary experiments,[0],[0]
The results are shown in Figure 2.,5. Preliminary experiments,[0],[0]
"With relatively strong regularization λ = 1/n, all methods perform similarly as predicted by theory.",5. Preliminary experiments,[0],[0]
"When λ becomes smaller, the nonaccelerated algorithms (SVRG and SAGA) automatically exploit strong convexity from data, so they become faster than the non-adaptive accelerated methods (Katyusha, SPDC and DF-SPDC).",5. Preliminary experiments,[0],[0]
"The adaptive accelerated method, ADF-SPDC, has the fastest convergence.",5. Preliminary experiments,[0],[0]
"This indicates that our theoretical results, which predict no acceleration in this case, may be further improved.
",5. Preliminary experiments,[0],[0]
"Finally we compare these algorithms for logistic regression on the rcv1 dataset (from LibSVM website) and another synthetic dataset with n = 5000 and d = 500, generated similarly as before but with covariance matrix Σij = 2
|i−j|/100.",5. Preliminary experiments,[0],[0]
"For the standard SPDC, we compute the coordinate-wise dual proximal mapping using a few steps of scalar Newton’s method to high precision.",5. Preliminary experiments,[0],[0]
The dualfree SPDC algorithms only use gradients of the logistic function.,5. Preliminary experiments,[0],[0]
The results are presented in Figure 3.,5. Preliminary experiments,[0],[0]
"For both datasets, the strong convexity from data is very weak, and the accelerated algorithms performs better.",5. Preliminary experiments,[0],[0]
We consider empirical risk minimization of linear predictors with convex loss functions.,abstractText,[0],[0]
Such problems can be reformulated as convex-concave saddle point problems and solved by primal-dual first-order algorithms.,abstractText,[0],[0]
"However, primal-dual algorithms often require explicit strongly convex regularization in order to obtain fast linear convergence, and the required dual proximal mapping may not admit closed-form or efficient solution.",abstractText,[0],[0]
"In this paper, we develop both batch and randomized primal-dual algorithms that can exploit strong convexity from data adaptively and are capable of achieving linear convergence even without regularization.",abstractText,[0],[0]
"We also present dual-free variants of adaptive primal-dual algorithms that do not need the dual proximal mapping, which are especially suitable for logistic regression.",abstractText,[0],[0]
Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms,title,[0],[0]
"Proceedings of NAACL-HLT 2013, pages 765–771, Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics",text,[0],[0]
Negation is a linguistic phenomenon where a negation cue (e.g. not) can alter the meaning of a particular text segment or of a fact.,1 Introduction,[0],[0]
This text segment (or fact) is said to be inside the scope of that negation (cue).,1 Introduction,[0],[0]
"In the context of RE, there is not much work that aims to exploit the scope of negations.1 The only work on RE that we are aware of is SanchezGraillet and Poesio (2007) where they used various heuristics to extract negative protein interaction.
",1 Introduction,[0],[0]
Despite the recent interest on automatically detecting the scope of negation2 till now there seems to be no empirical evidence supporting its exploitation for the purpose of RE.,1 Introduction,[0],[0]
"Even if we could manage to obtain highly accurate automatically detected
1In the context of event extraction (a closely related task of RE), there have been efforts in BioNLP shared tasks of 2009 and 2011 for (non-mandatory sub-task of) event negation detection (3 participants in 2009; 2 in 2011)",1 Introduction,[0],[0]
"(Kim et al., 2009; Kim et al., 2011).",1 Introduction,[0],[0]
"The participants approached the sub-task using either pre-defined patterns or some heuristics.
",1 Introduction,[0],[0]
"2This task is popularized by various recently held shared tasks (Farkas et al., 2010; Morante and Blanco, 2012).
negation scopes, it is not clear how to feed this information inside the RE approach.",1 Introduction,[0],[0]
"Simply considering whether a pair of candidate mentions falls under the scope of a negation cue might not be helpful.
",1 Introduction,[0],[0]
"In this paper, we propose that the scope of negations can be exploited at two different levels.",1 Introduction,[0],[0]
"Firstly, the system would check whether all the target entity3 mentions inside a sentence along with possible relation clues (or trigger words), if any, fall (directly or indirectly) under the scope of a negation cue.",1 Introduction,[0],[0]
"If such a sentence is found, then it should be discarded (i.e. candidate mention pairs4 inside that sentence would not be considered).",1 Introduction,[0],[0]
"Secondly, for each of the remaining pairs of candidate mentions, the system should exploit features related to the scope of negation (rather than simply adding a feature for negation cue, approach adopted in various RE systems) that can provide indication (if any such evidence exists) that the corresponding relation of interest actually does not hold in that particular context.
",1 Introduction,[0],[0]
"In the subsequent sections, we describe our approach.",1 Introduction,[0],[0]
The RE task considered is drug-drug interaction (DDI) extraction.,1 Introduction,[0],[0]
"The task has significant importance for public health safety.5 We used
3The target entities, for example, for DDI extraction and for EMP-ORG relation extraction would be {DRUG} and {PER, GPE, ORG} respectively.",1 Introduction,[0],[0]
Any entity other than the target entities (w.r.t.,1 Introduction,[0],[0]
"the particular RE task) belongs to non-target entities.
",1 Introduction,[0],[0]
"4Candidate mention pairs for RE are taken from target entity mentions.
",1 Introduction,[0],[0]
"5After the death of pop star Michael Jackson, allegedly due to DDI, it was reported that about 2.2 million people in USA, age 57 to 85, were taking potentially dangerous combinations of drugs (Landau, 2009).",1 Introduction,[0],[0]
"An earlier report mentioned that deaths from accidental drug interactions rose 68 percent between 1999 and 2004 (Payne, 2007).
",1 Introduction,[0],[0]
"765
the DDIExtraction-2011 challenge corpus (SeguraBedmar et al., 2011).",1 Introduction,[0],[0]
"The official training and test data of the corpus contain 4,267 and 1,539 sentences, and 2,402 and 755 DDI annotations respectively.",1 Introduction,[0],[0]
We propose a two stage RE approach.,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"In the first stage, our goal is to exploit the scope of negations to reduce the number of candidate mention pairs by discarding sentences.",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"For this purpose, we propose the following features to train a binary classifier:
• has2TM: If the sentence has exactly 2 target entity mentions (i.e. drug mentions for DDI extraction).
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
• has3OrMoreTM:,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"Whether the sentence has more than 2 target entity mentions.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"• allTMonRight: Whether all target entity mentions inside the sentence appear after the negation cue.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
• neitherAllTMonLeftOrRight:,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"Whether some but not all target entity mentions appear after the negation cue.
• negCue:",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
The negation cue itself.,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
• immediateGovernor:,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"The word on which the cue is
directly syntactically dependent.
• nearestVerbGovernor: The nearest verb in the dependency graph on which the cue is syntactically dependent.
• isVerbGovernorRoot: Whether the nearestVerbGovernor is root of the dependency graph of the sentence.
• allTMdependentOnNVG: Whether all target entity mentions are syntactically dependent (directly/indirectly) on the nearestVerbGovernor.
• allButOneTMdependentOnNVG: Whether all but one target entity mentions are syntactically dependent on the nearestVerbGovernor.
• although*PrecedeCue: Whether the syntactic clause containing the negation cue begins with “although / though / despite / in spite”.
• commaBeforeNextTM: Whether there is a comma in the text between the negation cue and the next target entity mention after the cue.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
• commaAfterPrevTM:,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"Whether there is a comma in the text between the previous target entity mention before the negation cue and the cue itself.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"• sentHasBut: Whether the sentence contains the word “but”.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"The objective of the classifier is to decide whether all of the target entity mentions (i.e. drugs) as well as any possible evidence of the relation of interest (for which we assume the immediate and the nearest verb governors of the negation cue would be good candidates) inside the corresponding sentence fall under the scope of a negation cue in such a way that the sentence is unlikely to contain a DDI.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"At present, we limit our focus only on the first occurrence of the following negation cues: “no”, “n’t” or “not”.6 In the Stage 1, any sentence that contains at least one DDI is considered by the classifier as a positive (training/test) instance.",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
Other sentences are considered as negative instances.,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"We rule out any sentence (i.e. we do not consider as training/test instance for the classifier that filters less informative sentences) during both training and testing if any of the following conditions holds:
•",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"The sentence contains less than two target entity mentions (such sentence would not contain the relation of interest anyway).
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"• It has any of the following phrases – “not recommended”, “should not be” or “must not be”.7
•",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"There is no “no”, “n’t” or “not” in the sentence.",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
•,2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"No target entity mention appears in the sentence af-
ter “no”, “n’t” or “not”.
",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"To assess the effectiveness of the proposed Stage 1 classifier, we defined a baseline classifier that filters any sentence that contains “no”, “n’t” or “not”.",2.1 Stage 1: Exploiting scope of negation to filter out sentences,[0],[0]
"Once the sentences which are likely to have no DDI are identified and removed, the next step is to apply a state-of-the-art RE approach on the remaining sentences.",2.2 Stage 2,[0],[0]
"In this section, we propose a new hybrid kernel, KHybrid, for this purpose.",2.2 Stage 2,[0],[0]
"It is defined as follows:
KHybrid (R1, R2) = KHF (R1, R2) + KSL (R1, R2) +",2.2 Stage 2,[0],[0]
"w * KPET (R1, R2)
6These cues usually occur more frequently and generally have larger negation scope than other negation cues.
",2.2 Stage 2,[0],[0]
"7These expressions often provide clues that one of the bioentity mentions negatively influences the level of activity of the other.
",2.2 Stage 2,[0],[0]
"Here, KHF stands for a new feature based kernel (proposed in this paper) that uses a heterogeneous set of features.",2.2 Stage 2,[0],[0]
KSL stands for the Shallow Linguistic (SL) kernel proposed by Giuliano et al. (2006).,2.2 Stage 2,[0],[0]
"KPET stands for the Path-enclosed Tree (PET) kernel (Moschitti, 2004).",2.2 Stage 2,[0],[0]
w is a multiplicative constant used for the PET kernel.,2.2 Stage 2,[0],[0]
"It allows the hybrid kernel to assign more (or less) weight to the information obtained using tree structures depending on the corpus.
",2.2 Stage 2,[0],[0]
The proposed kernel composition is valid according to the closure properties of kernels.,2.2 Stage 2,[0],[0]
"We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation.",2.2 Stage 2,[0],[0]
"In Stage 2, each candidate drug mention pair represents an instance.
2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features.",2.2 Stage 2,[0],[0]
"The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works.",2.2 Stage 2,[0],[0]
"The former is Zhou et al. (2005), which uses 51 different features.",2.2 Stage 2,[0],[0]
"We select the following 27 of their features for our feature set:
WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, ET12SameNP, ET12SamePP, ET12SameVP, PTP, PTPH
",2.2 Stage 2,[0],[0]
"The latter is the TPWF kernel (Chowdhury and Lavelli, 2012a) from which we use following features:
HasTriggerWord, Trigger-X, DepPattern-i, ewalk, v-walk
The TPWF kernel extracts the HasTriggerWord, Trigger-X and DepPattern-i features from a subgraph called reduced graph.",2.2 Stage 2,[0],[0]
We also follow this approach with one minor difference.,2.2 Stage 2,[0],[0]
"Unlike Chowdhury and Lavelli (2012a), we look for trigger words in the whole reduced graph instead of using only the root of the sub-graph.
",2.2 Stage 2,[0],[0]
"Due to space limitation we refer the readers to the corresponding papers for the description of the above mentioned features and the definition of reduced graph.
",2.2 Stage 2,[0],[0]
"In addition, HF v1 also includes surrounding tokens within the window of {-2,+2} for each candidate mention.",2.2 Stage 2,[0],[0]
We are unaware of any available list of trigger words for drug-drug interaction.,2.2 Stage 2,[0],[0]
"So, we created such a list.8
We extend the heterogeneous feature set by adding features related to the scope of negation (henceforth, HF v2).",2.2 Stage 2,[0],[0]
We use a list of 13 negation cues9 to search inside the reduced graph of a candidate pair.,2.2 Stage 2,[0],[0]
"If the reduced graph contains any of the negation cues or their morphological variants then we add the following features:
• negCue:",2.2 Stage 2,[0],[0]
The corresponding negation cue.,2.2 Stage 2,[0],[0]
•,2.2 Stage 2,[0],[0]
immediateNegatedWord,2.2 Stage 2,[0],[0]
:,2.2 Stage 2,[0],[0]
"If the word following the
negation cue is neither a preposition nor a “be verb”, then that word, otherwise the word after the next word.10
Furthermore, if the corresponding matched negation cue is either “no”, “n’t” or “not”, then we add additional features related to negation scope:
• bothEntDependOnImmediateGovernor:",2.2 Stage 2,[0],[0]
"Whether the immediate governor (if any) of the negation cue is also governor of a dependency sub-tree (of the dependency graph of the corresponding sentence) that includes both of the candidate mentions.
",2.2 Stage 2,[0],[0]
• immediateGovernorIsVerbGovernor:,2.2 Stage 2,[0],[0]
"Whether the immediate governor of the negation cue is a verb.
",2.2 Stage 2,[0],[0]
• nearestVerbGovernor:,2.2 Stage 2,[0],[0]
"The closest verb governor (i.e. parent or grandparent inside the dependency graph), if any, of the negation cue.
",2.2 Stage 2,[0],[0]
"We further extend the heterogeneous feature set by adding features related to relevant non-target entities (with respect to the relation of interest; henceforth, HF v3).",2.2 Stage 2,[0],[0]
"For the purpose of DDI extraction, we deem the presence of DISEASE mentions (which might result as a consequence of a DDI) can provide some clues.",2.2 Stage 2,[0],[0]
"So, we use a publicly available state-of-the-art disease NER system called BioEnEx (Chowdhury and Lavelli, 2010) to annotate the DDIExtraction-2011 challenge corpus.",2.2 Stage 2,[0],[0]
"For
8The RE system developed for this work and the created list of trigger words for DDI can be downloaded from https://github.com/fmchowdhury/HyREX .
9No, not, neither, without, lack, fail, unable, abrogate, absence, prevent, unlikely, unchanged, rarely.
",2.2 Stage 2,[0],[0]
"10For example, “interested” from “... not interested ...”, and “confused” from “... not to be confused ...”.
",2.2 Stage 2,[0],[0]
"each candidate (drug) mention pair, we add the following features in HF v3:
• NTEMinsideSentence: Whether the corresponding sentence contains important non-target entity mention(s) (e.g. disease for DDI).
",2.2 Stage 2,[0],[0]
"• immediateGovernorIsVerbGovernorOfNTEM: The immediate governor (if any) of the non-target entity mention, only if such governor is also governing a dependency sub-tree that includes both of the target candidate entity mentions.
",2.2 Stage 2,[0],[0]
• nearestVerbGovernorOfNTEM:,2.2 Stage 2,[0],[0]
"The closest verb governor (if any) of the non-target entity mention, only if it also governs the candidate entity mentions.
• immediateGovernorIsVerbGovernorOfNTEM: Whether the immediate governor is a verb.",2.2 Stage 2,[0],[0]
We train a linear SVM classifier in Stage 1 and tune the hyper-parameters (by doing 5-fold crossvalidation) for obtaining maximum possible recall.,3 Results and Discussion,[0],[0]
"In this way we minimize the number of false negatives (i.e. sentences that contain DDIs but are wrongly identified as not having any).
",3 Results and Discussion,[0],[0]
"During the cross-validation experiments on the training data, 334 sentences (7.83% of the total sentences) containing at least 2 drug mentions were identified by our proposed classifier (in Section 2.1) as unlikely to have any DDI and hence are candidates for discarding.",3 Results and Discussion,[0],[0]
Only 19 of these sentences were incorrectly identified.,3 Results and Discussion,[0],[0]
"When we trained on the training data and tested on the official test data of DDIExtraction-2011 challenge corpus, 121 sentences (7.86% of the total test sentences) were identified by the classifier as candidates for discarding.",3 Results and Discussion,[0],[0]
"Only 5 of them were incorrectly identified.
",3 Results and Discussion,[0],[0]
"Unlike Stage 1, in Stage 2 where we train the hybrid kernel based RE classifier and use it for RE (i.e. DDI extraction) from the test data, sentences are not the RE training/test instances.",3 Results and Discussion,[0],[0]
"Instead, a RE instance corresponds to a candidate mention pair.
",3 Results and Discussion,[0],[0]
"All the DDIs (i.e. positive RE instances) of the incorrectly identified sentences in Stage 1 (i.e. the sentences which are incorrectly labelled as not having any DDI and filtered) are automatically considered as false negatives during the calculation of DDI extraction results in Stage 2.
",3 Results and Discussion,[0],[0]
"To verify whether our proposed hybrid kernel achieves state-of-the-art results without taking benefits of the output of Stage 1, we did some experiments without discarding any sentence.",3 Results and Discussion,[0],[0]
"These experiments are done using Zhou et al. (2005), TPWF kernel, SL kernel, different versions of proposed KHF kernel and KHybrid kernel.",3 Results and Discussion,[0],[0]
Table 1 shows the results of 5-fold cross-validation experiments (hyper-parameters are tuned for obtaining maximum F-score).,3 Results and Discussion,[0],[0]
"As the results show, there is a gain +0.9 points in F-score (mainly due to the boost in recall) after the addition of features related to negation scope.",3 Results and Discussion,[0],[0]
"There is also some minor improvement due to the proposed non-target entity specific features.
",3 Results and Discussion,[0],[0]
"We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kernel, SL kernel, PET kernel, KHF kernel and KHybrid kernel separately (only the results of KHybrid are reported in Table 1 due to space limitation).",3 Results and Discussion,[0],[0]
"In each case, there were improvements in precision, recall and Fscore.",3 Results and Discussion,[0],[0]
"The gain in F-score ranged from 1.0 to 1.4 points.
",3 Results and Discussion,[0],[0]
Table 2 reports the results of the previously published studies that used the same corpus.,3 Results and Discussion,[0],[0]
"Our proposed KHybrid kernel obtains an F-score that is higher than that of the previous state of the art.
",3 Results and Discussion,[0],[0]
"When the Stage 1 classifier (based on negation scope features) is exploited before using the KHybrid kernel, the F-score reaches up to 67.4.",3 Results and Discussion,[0],[0]
"This is +1.0 points higher than without exploiting the Stage 1 classifier and +1.7 higher than previous state of
the art.",3 Results and Discussion,[0],[0]
We did separate experiments (also reported in Table 2) to assess the performance improvement when the output of Stage 1 is used to filter sentences from either training or test data only.,3 Results and Discussion,[0],[0]
The results remain the same when only training sentences are filtered; while there are some improvements when only test sentences are filtered.,3 Results and Discussion,[0],[0]
"Filtering both training and test sentences provides the larger gain which is statistically significant.
",3 Results and Discussion,[0],[0]
"Usually, the number of negative instances in a corpus is much higher than that of the positive instances.",3 Results and Discussion,[0],[0]
"In a recent work, Chowdhury and Lavelli (2012b) showed that by removing less informative (negative) instances (henceforth, LIIs), not only the skewness in instance distribution could be reduced but it also leads to a better result.",3 Results and Discussion,[0],[0]
"The proposed Stage 1 classifier, presented in this work, also reduces skewness in instance distribution.",3 Results and Discussion,[0],[0]
This is because we are only removing those sentences that are unlikely to contain any positive instance.,3 Results and Discussion,[0],[0]
"So, in principle, the Stage 1 classifier is focused on removing only negative instances (although the classifier mistakenly discards few positive instances, too).
",3 Results and Discussion,[0],[0]
We wanted to study how the Stage 1 classifier would contribute if we use it on top of the techniques that were proposed in Chowdhury and Lavelli (2012b) to remove LIIs.,3 Results and Discussion,[0],[0]
"As Table 2 shows, by using the Stage 1 classifier along with LLI filtering, we could further improve the results (+3.2 points difference in F-score with the previous state of the art).",3 Results and Discussion,[0],[0]
A major flexibility in the proposed approach is that it does not require a separate dataset (which needs to match the genre of the text to be used for RE) annotated with negation scopes.,4 Conclusion,[0],[0]
"Instead, the proposed Stage 1 classifier uses the RE training data (which do not have negation scope annotations) to self-supervise itself.",4 Conclusion,[0],[0]
Various new features have been exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted.,4 Conclusion,[0],[0]
"The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list).
",4 Conclusion,[0],[0]
"Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies.
",4 Conclusion,[0],[0]
"The results considerably improve when possible irrelevant sentences from both training and test data are filtered by exploiting features related to the scope of negations.
",4 Conclusion,[0],[0]
"In future, we would like to exploit the scope of more negation cues, apart from the three cues that are used in this study.",4 Conclusion,[0],[0]
We believe our approach would help to improve RE in other genres of text (such as newspaper) as well.,4 Conclusion,[0],[0]
This work was carried out in the context of the project “eOnco - Pervasive knowledge and data management in cancer care”.,Acknowledgement,[0],[0]
This paper presents an approach that exploits the scope of negation cues for relation extraction (RE) without the need of using any specifically annotated dataset for building a separate negation scope detection classifier.,abstractText,[0],[0]
New features are proposed which are used in two different stages.,abstractText,[0],[0]
These also include non-target entity specific features.,abstractText,[0],[0]
The proposed RE approach outperforms the previous state of the art for drug-drug interaction (DDI) extraction.,abstractText,[0],[0]
Exploiting the Scope of Negations and Heterogeneous Features for Relation Extraction: A Case Study for Drug-Drug Interaction Extraction,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 85–91 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2014",text,[0],[0]
"Neural sequence to sequence models have been successfully used in many applications (Graves, 2012), from speech and signal processing to text processing or dialogue systems (Serban et al., 2015).",1 Introduction,[0],[0]
"Neural machine translation (Cho et al., 2014; Bahdanau et al., 2014) is a particular type of sequence to sequence model that recently attracted a lot of attention from industry (Wu et al., 2016) and academia, especially due to the capability to obtain state-of-the-art results for various translation tasks (Bojar et al., 2016).",1 Introduction,[0],[0]
"Unlike classical statistical machine translation (SMT) systems (Koehn, 2010), neural networks are being trained end-to-end, without the need to have external decoders, language models or phrase tables.",1 Introduction,[0],[0]
"The architectures are relatively simpler and more flexible, making possible the use of character models (Luong and Manning, 2016) or even training multilingual systems in one go (Firat et al., 2016).
",1 Introduction,[0],[0]
"Automated text simplification (ATS) systems are meant to transform original texts into differ-
∗Both authors have contributed equally to this work
ent (simpler) variants which would be understood by wider audiences and more successfully processed by various NLP tools.",1 Introduction,[0],[0]
"In the last several years, great attention has been given to addressing ATS as a monolingual machine translation problem translating from ‘original’ to ‘simple’ sentences.",1 Introduction,[0],[0]
"So far, attempts were made at standard phrase-based SMT (PBSMT) models (Specia, 2010; Štajner et al., 2015), PBSMT models with added phrasal deletion rules (Coster and Kauchak, 2011) or reranking of the n-best outputs according to their dissimilarity to the output (Wubben et al., 2012), tree-based translation models (Zhu et al., 2010; Paetzold and Specia, 2013), and syntax-based MT with specially designed tuning function (Xu et al., 2016).",1 Introduction,[0],[0]
"Recently, lexical simplification (LS) was addressed by unsupervised approaches leveraging word-embeddings, with reported good success (Glavaš and Štajner, 2015; Paetzold and Specia, 2016).
",1 Introduction,[0],[0]
"To the best of our knowledge, our work is the first to address the applicability of neural sequence to sequence models for ATS.",1 Introduction,[0],[0]
We make use of the recent advances in neural machine translation (NMT) and adapt the existing architectures for our specific task.,1 Introduction,[0],[0]
We also perform an extensive human evaluation to directly compare our systems with the current state-of-the-art (supervised) MT-based and unsupervised lexical simplification systems.,1 Introduction,[0],[0]
"We use the OpenNMT framework (Klein et al., 2017) to train and build our architecture with two LSTM layers (Hochreiter and Schmidhuber, 1997), hidden states of size 500 and 500 hidden units, and a 0.3 dropout probability (Srivastava et al., 2014).",2 Neural Text Simplification (NTS),[0],[0]
"The vocabulary size is set to 50,000 and we train the model for 15 epochs with plain SGD optimizer, and after epoch 8 we halve the
85
learning rate.",2 Neural Text Simplification (NTS),[0],[0]
At the end of each epoch we save the current state of the model and predict the perplexity values of the models on the development set.,2 Neural Text Simplification (NTS),[0],[0]
We employ early-stopping and select the model resulted from the epoch with the best perplexity to avoid over-fitting.,2 Neural Text Simplification (NTS),[0],[0]
"The parameters are initialized over uniform distribution with support [-0.1, 0.1].",2 Neural Text Simplification (NTS),[0],[0]
"Additionally, for the decoder we employ global attention in combination with input feeding as described by Luong et al. (2015).",2 Neural Text Simplification (NTS),[0],[0]
"The architecture1 is depicted in Figure 1, with the input feeding approach represented only for the last hidden state of the decoder.
",2 Neural Text Simplification (NTS),[0],[0]
"For the attention layer, we compute a context vector ct by using the information provided from the hidden states of the source sentence and by computing a weighted average with the alignment weights at.",2 Neural Text Simplification (NTS),[0],[0]
"The new hidden state is obtained using a concatenation of the previous hidden state and the context vector:
h̃t = tanhW",2 Neural Text Simplification (NTS),[0],[0]
"[ct;ht]
",2 Neural Text Simplification (NTS),[0],[0]
"The global alignment weights at are being computed with a softmax function over the general scoring method for attention:
at(s) = exphTt Wash̄s∑",2 Neural Text Simplification (NTS),[0],[0]
"s′ exph T t Was′ h̄s′
Input feeding is a process that sends the previous hidden state obtained using the alignment
1The architecture configurations, data, and the pretrained models are released in https://github.com/ senisioi/NeuralTextSimplification
method, to the input at the next step, presumably making the model keep track of anterior alignment decisions.",2 Neural Text Simplification (NTS),[0],[0]
"Luong et al. (2015) showed this approach can increase the evaluation scores for neural machine translation, while in our case, for monolingual data, we believe it can be helpful to create better alignments.",2 Neural Text Simplification (NTS),[0],[0]
"Our approach does not involve the use of character-based models (Sennrich et al., 2015; Luong and Manning, 2016) to handle out of vocabulary words and entities.",2 Neural Text Simplification (NTS),[0],[0]
"Instead, we make use of alignment probabilities between the predictions and the original sentences to retrieve the original words.",2 Neural Text Simplification (NTS),[0],[0]
"Furthermore, we are interested to explore whether large scale pre-trained embeddings can improve text simplification models.",2.1 Word2vec Embeddings,[0],[0]
Kauchak (2013) indicates that combining normal data with simplified data can increase the performance of ATS systems.,2.1 Word2vec Embeddings,[0],[0]
"Therefore, we construct a secondary model (NTSw2v) using a combination of pre-trained word2vec from Google News corpus (Mikolov et al., 2013a) of size 300 and locally trained embeddings of size 200.",2.1 Word2vec Embeddings,[0],[0]
"To ensure good representations of lowfrequency words, we use word2vec (Řehůřek and Sojka, 2010; Mikolov et al., 2013b) to train skipgram with hierarchical softmax and we set a window of 10 words.
",2.1 Word2vec Embeddings,[0],[0]
"Following Garten et al. (2015) who showed that simple concatenation can improve the word representations, we construct two different sets of embeddings for the encoder and for the decoder.",2.1 Word2vec Embeddings,[0],[0]
The former are constructed using the word2vec trained on the original English texts combined with Google News and the later (decoder) embeddings are built from word2vec trained on the simplified version of the training data combined with Google News.,2.1 Word2vec Embeddings,[0],[0]
"To merge the local and global embeddings, we concatenate the representations for each word in the vocabulary, thus obtaining a new representation of size 500.",2.1 Word2vec Embeddings,[0],[0]
"If a word is missing in the global embeddings, we replace it with a sample from a Gaussian distribution with mean 0 and standard deviation of 0.9.",2.1 Word2vec Embeddings,[0],[0]
The remaining parameters are left unchanged from the previous model description.,2.1 Word2vec Embeddings,[0],[0]
"To ensure the best predictions and the best simplified sentences at each step, we use beam search to sample multiple outputs from the two systems
described previously (NTS and NTS-w2v).",2.2 Prediction Ranking,[0],[0]
Beam search works by generating the first k hypotheses at each step ordered by the log-likelihood of the target sentence given the input sentence.,2.2 Prediction Ranking,[0],[0]
"By default, we use a beam size of 5 and take the first hypothesis, but we also observe that higher beam size and lower-ranked hypotheses can generate good simplification results.",2.2 Prediction Ranking,[0],[0]
"Therefore, we generate the first two candidate hypotheses for each beam size from 5 to 12.",2.2 Prediction Ranking,[0],[0]
"We then attempt to find the best beam size and hypothesis based on two metrics: the traditional MT-evaluation metric, BLEU (Papineni et al., 2002; Bird et al., 2009) with NIST smoothing (Bird et al., 2009), and SARI (Xu et al., 2016), a recent text-simplification metric.",2.2 Prediction Ranking,[0],[0]
"To train our models, we use the publicly available dataset provided by Hwang et al. (2015) based on manual and automatic alignments between standard English Wikipedia and Simple English Wikipedia (EW–SEW).",2.3 Dataset,[0],[0]
"We discard the uncategorized matches, and use only good matches and partial matches which were above the 0.45 threshold (Hwang et al., 2015), totaling to 280K aligned sentences (around 150K full matches and 130K partial matches).",2.3 Dataset,[0],[0]
"It is one of the largest freely available resources for text simplification, and unlike the previously used EW–SEW corpus2",2.3 Dataset,[0],[0]
"(Kauchak, 2013), which only contains full matches (167K pairs), the newer dataset also contains partial matches.",2.3 Dataset,[0],[0]
"Therefore, it is not only larger, but it also allows for learning sentence shortening (dropping irrelevant parts) transformations (see Table 3, Appendix A).
",2.3 Dataset,[0],[0]
"We use the Stanford NER system (Finkel et al., 2005) to get an approximate number of locations, persons, organizations and miscellaneous entities
2http://www.cs.pomona.edu/˜dkauchak/ simplification/
in the corpus.",2.3 Dataset,[0],[0]
"A brief analysis of the vocabulary is rendered in Table 1.
",2.3 Dataset,[0],[0]
"The dataset we use contains an abundant amount of named entities and consequently a large amount of low frequency words, but the majority of entities are not part of the model’s 50,000 words vocabulary due to their small frequency.",2.3 Dataset,[0],[0]
These words are replaced with ’UNK’ symbols during training.,2.3 Dataset,[0],[0]
"At prediction time, we replace the unknown words with the highest probability score from the attention layer.",2.3 Dataset,[0],[0]
"We believe it is important to ensure that the models learn good word representations, either during the model training or through word2vec, in order to accurately create alignments between source and target sentences.
",2.3 Dataset,[0],[0]
"Given that in TS there is not only one best simplification, and that the quality of simplifications in Simple English Wikipedia has been disputed before (Amancio and Specia, 2014; Xu et al., 2015), for tuning and testing we use the dataset previously released by Xu et al. (2016), which contains 2000 sentences for tuning and 359 for testing, each with eight simplification variants obtained by eight Amazon Mechanical Turkers.3",2.3 Dataset,[0],[0]
The tune subset is also used as reference corpus in combination with BLEU and SARI to select the best beam size and hypothesis for prediction reranking.,2.3 Dataset,[0],[0]
"For the first 70 original sentences of the Xu et al.’s (2016) test set4 we perform three types of human evaluation to assess the output of our best systems and three ATS systems of different architectures: (1) the PBSMT system with reranking of n-best outputs (Wubben et al., 2012), which represent the best PBSMT approach to ATS, trained and tuned over the same datasets as our systems; (2) the state-of-the-art SBMT system (Xu et al., 2016) with modified tuning function (using SARI) and using PPDB paraphrase database (Ganitkevitch et al., 2013);5 and (3) one of the state-of-theart unsupervised lexical simplification (LS) systems that leverages word-embeddings (Glavaš and
3None of the 359 test sentences was present in the datasets we used for training and tuning.
",3 Evaluation,[0],[0]
"4https://github.com/cocoxu/ simplification/
5For the first two systems, we use publicly available output at: https://github.com/ cocoxu/simplification/tree/master/data/ systemoutputs
Štajner, 2015).6
We evaluate the output of all systems using three types of human evaluation.
",3 Evaluation,[0],[0]
Correctness and Number of Changes.,3 Evaluation,[0],[0]
"First, we count the total number of changes made by each system (Total), counting the change of a whole phrase (e.g. “become defunct” → “was dissolved”) as one change.",3 Evaluation,[0],[0]
"Those changes that preserve the original meaning and grammaticality of the sentence (assessed by two native English speakers) and, at the same time, make the sentence easier to understand (assessed by two non-native fluent English speakers) are marked as Correct.",3 Evaluation,[0],[0]
"In the case of content reduction, we instructed the annotators to count the deletion of each array of consecutive words as one change and consider the meaning unchanged if the main information of the sentence was retained and unchanged.",3 Evaluation,[0],[0]
"The sentences for which the two annotators did not agree were given to a third annotator to obtain the majority vote.
",3 Evaluation,[0],[0]
Grammaticality and Meaning Preservation.,3 Evaluation,[0],[0]
"Second, three native English speakers rate the grammaticality (G) and meaning preservation (M) of each (whole) sentence with at least one change on a 1–5 Likert scale (1 – very bad; 5 – very good).",3 Evaluation,[0],[0]
"The obtained inter-annotator agreement (quadratic Cohens kappa) was 0.78 for G and 0.63 for M.
Simplicity of sentences.",3 Evaluation,[0],[0]
"Third, the three nonnative fluent English speakers were shown original (reference) sentences and target (output) sentences, one pair at the time, and asked whether the target sentence is: +2 – much simpler; +1 – somewhat simpler; 0 – equally difficult; -1 – somewhat more difficult; -2 – much more difficult, than the reference sentence.",3 Evaluation,[0],[0]
"The obtained inter-annotator agreement (quadratic Cohens kappa) was 0.66.
",3 Evaluation,[0],[0]
"While the correctness of changes takes into account the influence of each individual change on grammaticality, meaning and simplicity of a sentence, the Scores (G and M) and Rank (S) take into account the mutual influence of all changes within a sentence.",3 Evaluation,[0],[0]
"The results of the human evaluation (Table 2) revealed that all NTS models achieve higher percentage of correct changes and more simplified output than any of the state-of-the-art ATS systems
6For the LightLS system (Glavaš and Štajner, 2015) we use the output of the original system provided by the authors.
with different architectures (PBSMT-R, SBMT, and LightLS).",4 Results and Discussion,[0],[0]
"We also notice that the best models according to BLEU are obtained with hypothesis 1 and the maximum beam size for both models, while the SARI re-ranker prefers hypothesis 2 and beam size 5 for the first NTS and the maximum beam size for the custom word embeddings model.
",4 Results and Discussion,[0],[0]
"The NTS with custom word2vec embeddings ranked with the text simplification specific metric (SARI) obtained the highest total number of changes among the neural systems, one of the highest percentage of correct changes, the second highest simplicity score, and solid grammaticality and meaning preservation scores.",4 Results and Discussion,[0],[0]
"An example of the output of different systems is presented in Table 4 (Appendix A).
",4 Results and Discussion,[0],[0]
"The use of different metrics for ranking the NTS predictions optimizes the output towards different evaluation objectives: SARI leads to the highest number of total changes, BLEU to the highest percentage of correct changes, and the default beam scores to the best grammaticality (G) and meaning preservation (M).",4 Results and Discussion,[0],[0]
"In addition, custom composed global and local word embeddings in combination with SARI metric improve the default translation system, given the joint scores for each evaluation criterion.
",4 Results and Discussion,[0],[0]
"Here is important to note that for ATS systems, the precision of the system (correctness of changes, grammaticality, meaning preservation, and simplicity of the output) is more important than the recall (the total number of changes made).",4 Results and Discussion,[0],[0]
"The low recall would just leave the sentences similar to their originals thus not improving much the understanding or reading speed of the target users, or not improving much the NLP systems in which they are used as a pre-processing step.",4 Results and Discussion,[0],[0]
"A low precision, on the other hand, would make texts even more difficult to read and understand, and would worsen the performances of the NLP systems in which ATS is used as a pre-processing step.",4 Results and Discussion,[0],[0]
We presented a first attempt at modelling sentence simplification with a neural sequence to sequence model.,5 Conclusions,[0],[0]
"Our extensive human evaluation showed that our NTS systems, if the output is ranked with the right metric, can significantly7 outperform the best phrase-based and syntax-based MT approaches, and unsupervised lexical ATS approach,
7Wilcoxon’s signed rank test, p < 0.001.
by grammaticality, meaning preservation and simplicity of the output sentences, the percentage of correct transformations, while at the same time achieving more than 1.5 changes per sentence, on average.",5 Conclusions,[0],[0]
"Furthermore, we discovered that NTS systems are capable of correctly performing significant content reduction, thus being the only TS models proposed so far which can jointly perform lexical simplification and content reduction.",5 Conclusions,[0],[0]
"This work has been partially supported by a grant of the Romanian National Authority for Scientific Research and Innovation, CNCS/CCCDI UEFISCDI, project number PN-III-P2-2.1-53BG/2016, within PNCDI III, and by the SFB 884 on the Political Economy of Reforms at the University of Mannheim (project C4), funded by the German Research Foundation (DFG).",Acknowledgments,[0],[0]
We present the first attempt at using sequence to sequence neural networks to model text simplification (TS).,abstractText,[0],[0]
"Unlike the previously proposed automated TS systems, our neural text simplification (NTS) systems are able to simultaneously perform lexical simplification and content reduction.",abstractText,[0],[0]
An extensive human evaluation of the output has shown that NTS systems achieve almost perfect grammaticality and meaning preservation of output sentences and higher level of simplification than the state-of-the-art automated TS systems.,abstractText,[0],[0]
Exploring Neural Text Simplification Models,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 652–658 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
652",text,[0],[0]
"“You know, ever since we were little, I would get this feeling like... Like I’m floating outside of my body, looking down at myself...",1 Introduction,[0],[0]
And I hate what I see...,1 Introduction,[0],[0]
"How I’m acting, the way I sound.",1 Introduction,[0],[0]
And I don’t know how to change it.,1 Introduction,[0],[0]
And I’m so scared...,1 Introduction,[0],[0]
"That the feeling is never gonna go away.”
The Edge of Seventeen1
Much has been written about optimism and pessimism in psychological studies for decades (Scheier and Carver, 1992).",1 Introduction,[0],[0]
These feelings are affected by one’s personality from an early age (as pinpointed above) and can strongly impact one’s psychological and physical health.,1 Introduction,[0],[0]
"For example, pessimism and negative attitudes impact negatively one’s mental health, can induce suicidal thoughts, and affect negatively not only the person in question, but also their family and friends (Peterson and Bossio, 2001; Achat et al., 2000;
1https://www.imdb.com/title/tt1878870/
Scheier et al., 2001).",1 Introduction,[0],[0]
"On the other hand, optimism reduces stress and promotes better physical health and overall well-being (Carver et al., 2010).
",1 Introduction,[0],[0]
"Despite that optimism and pessimism are under the scrutiny of many researchers (Rasmussen et al., 2009; Kumar et al., 2017), large scale analyses that explore optimism and pessimism in social media have just started to emerge (Ruan et al., 2016).",1 Introduction,[0],[0]
"However, Ruan et al. (2016) focused on identifying optimism and pessimism in Twitter using a simple “bag of words” representation with no emphasis on incorporating semantic information hidden in text.",1 Introduction,[0],[0]
"Often, a deeper understanding of the text that accounts for textual semantic similarities and the writer’s intention are required in order to correctly detect the characteristics of optimistic and pessimistic feelings in tweets.",1 Introduction,[0],[0]
"Towards this end, our contributions in this paper are as follows.",1 Introduction,[0],[0]
"First, we focus on the question: “Would a deep learning approach help to discover these characteristics better than traditional machine learning classifiers used in prior work?”",1 Introduction,[0],[0]
"To our knowledge, we take the first step towards exploring the performance of deep learning models for optimism/pessimism prediction in Twitter and identify the most promising deep learning models for this task.",1 Introduction,[0],[0]
"Identifying optimism and pessimism in Twitter has many applications including identifying suicidal/depressive people and providing better social support (e.g., emotional/empathetic support) that can improve people’s moods and attitudes (Yan and Tan, 2014; Biyani et al., 2014; Khanpour et al., 2018, 2017; Qiu et al., 2011).
",1 Introduction,[0],[0]
"Second, since it may seem intuitive that a positive sentiment is associated with optimism and a negative sentiment with pessimism, we address the question: “Would a sentiment classifier be sufficient to correctly identify optimism and pessimism in social media?”",1 Introduction,[0],[0]
"Figure 1 shows evidence that a sentiment tool would not suffice on accurately
predicting tweets with pessimistic and optimistic connotations (left and right side of the figure, respectively).",1 Introduction,[0],[0]
"We answer the above question by investigating a spectrum of sentiment analysis tools and datasets for optimism/pessimism prediction.
",1 Introduction,[0],[0]
"Third, we perform a linguistic analysis, first of its kind, and study the usage of verb tenses (past, present, future) in optimistic and pessimistic tweets, as well as the presence of polarity words associated with both types of tweets.",1 Introduction,[0],[0]
"In this section, we first describe the optimism/ pessimism Twitter dataset and then present two datasets used for sentiment analysis.
",2 Datasets,[0],[0]
The Optimism/Pessimism Twitter dataset (OPT) was made available to us by Ruan et al. (2016).,2 Datasets,[0],[0]
"The total number of tweets in the dataset is 7,475.",2 Datasets,[0],[0]
"These tweets were sampled from data corresponding to 500 optimist and 500 pessimist users, and were manually annotated using Amazon Mechanical Turk.",2 Datasets,[0],[0]
"Precisely, each tweet was manually annotated by five independent annotators using a score between −3 (very pessimistic) and 3 (very optimistic).",2 Datasets,[0],[0]
"For our evaluation, we consider two different thresholds (0 and 1/-1) on the above score and create two settings as follows.",2 Datasets,[0],[0]
"In the first evaluation setting, a tweet is labeled as pessimistic if its score is smaller than or equal to 0, and optimistic, otherwise.",2 Datasets,[0],[0]
"In the second evaluation setting, a tweet is labeled as pessimistic if its score is smaller than or equal to −1, and optimistic if its score is greater than or equal to 1.",2 Datasets,[0],[0]
"A summary of this dataset is given in Table 1.
",2 Datasets,[0],[0]
"The Stanford Sentiment Treebank (SST) (Socher et al., 2013) is a corpus for sentiment analysis that capture complex linguistic patterns.",2 Datasets,[0],[0]
"This dataset2 is based on a dataset originally introduced by Pang and Lee (2005) and consists of 10,662 sentences from movie reviews downloaded from rottentomatoes.com.",2 Datasets,[0],[0]
"From these sentences, 215,154 phrases were extracted using the Stanford Parser (Klein and Manning, 2003) and labeled using Amazon Mechanical Turk such that each phrase was annotated by 3 human judges.
",2 Datasets,[0],[0]
"The Twitter Sentiment Analysis (TSA) dataset,3 available online for download, contains 1,578,627 tweets that are classified as 1 for positive sentiment and 0 for negative sentiment.",2 Datasets,[0],[0]
"In experiments, we explore several deep learning models for optimism/pessimism prediction.",3 Experiments and Results,[0],[0]
The general training strategy is as follows: sentence embeddings are fed into a sentence encoder to obtain the sentence representation.,3 Experiments and Results,[0],[0]
The classifier consists of three fully connected layers topped by a softmax layer.,3 Experiments and Results,[0],[0]
Dropout was applied to the first layer only.,3 Experiments and Results,[0],[0]
"We used several encoders as follows, based on: (1) Bidirectional Long Short Term Memory networks (BiLSTMs), which are a special type of Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997); (2) Convolutional Neural Networks (CNNs), which consist of convolution and max pooling (Kim, 2014); and (3) Stacked Gated RNNs (Chung et al., 2015).
",3 Experiments and Results,[0],[0]
"We used SGD optimizer (Goodfellow et al., 2016) with a learning rate of 0.1 and no weight decay.",3 Experiments and Results,[0],[0]
"At every tenth epoch we decreased the learn-
2https://nlp.stanford.edu/sentiment/ 3http://thinknook.com/twitter-sentiment-analysis-
training-corpus-dataset-2012-09-22/
ing rate by half.",3 Experiments and Results,[0],[0]
We used mini-batches of 40 samples.,3 Experiments and Results,[0],[0]
"Dropout rate was set to 0.5 and the classifier’s last three layers have 300, 200, and 100 neurons.",3 Experiments and Results,[0],[0]
"We used GloVe vectors (Pennington et al., 2014) trained on Common Crawl 840B4 with 300 dimensions as fixed word embeddings.
",3 Experiments and Results,[0],[0]
"For sentence embedding, after a cleanup process, sentences were transformed into a list of words, then words were replaced with word embeddings (GloVe) and padding was used to align batch sentences to the same size.",3 Experiments and Results,[0],[0]
"In our first experiment, we explore the above deep learning models on the OPT dataset and compare their performance with that of two traditional machine learning classifiers, Naı̈ve Bayes (NB) and Support Vector Machines (SVM), which were used in the previous work for this task by Ruan et al. (2016).",3.1 Optimism/Pessimism Prediction,[0],[0]
"In this experiment, the OPT dataset is split in train-dev-test as 80-10-10(%), respectively.",3.1 Optimism/Pessimism Prediction,[0],[0]
We repeated each experiment 5 times and averaged the results.,3.1 Optimism/Pessimism Prediction,[0],[0]
"Our deep learning implementation is built on top of TensorFlow (Abadi et al., 2015).",3.1 Optimism/Pessimism Prediction,[0],[0]
"For NB and SVM, we used their implementation available in scikit-learn (Pedregosa et al., 2011).",3.1 Optimism/Pessimism Prediction,[0],[0]
"Table 2 shows the accuracy of all these models at tweet and user level for the two thresholds 0 and 1/-1 (as discussed in Section 2).
",3.1 Optimism/Pessimism Prediction,[0],[0]
"We can see that overall, the deep learning models achieve a much higher performance compared with the work by Ruan et al. (2016), i.e., the NB and SVM classifiers on “bag of words,” for both tweet and user level with both thresholds, yielding an improvement in performance between 5%- 10%.",3.1 Optimism/Pessimism Prediction,[0],[0]
"For example, at tweet level and 1/-1 threshold, CNN yields an accuracy of 90.32% as compared with NB, which achieves an accuracy of 84.10%.",3.1 Optimism/Pessimism Prediction,[0],[0]
"At user level and 1/-1 threshold, GRUStack yields an accuracy of 92.24%, as compared
4https://nlp.stanford.edu/projects/glove/
with 81.80% achieved by SVM.",3.1 Optimism/Pessimism Prediction,[0],[0]
"Not surprising, for both tweet and user level, when we use a threshold of 0, the performance of all models is smaller compared with that of models obtained when we use a 1/-1 threshold.",3.1 Optimism/Pessimism Prediction,[0],[0]
"Intuitively, this is true since most of the tweets with a humanannotated score between -1 and 1 are in the “gray” area that is harder to classify.",3.1 Optimism/Pessimism Prediction,[0],[0]
Note that Ruan et al. (2016) considered the tweets with a score between -1 and 1 as being neutral.,3.1 Optimism/Pessimism Prediction,[0],[0]
"In our second experiment, we investigate the correlation between sentiment and optimism / pessimism, and argue that sentiment analyzers, that are trained to predict sentiment (Liu, 2012; Pang and Lee, 2008), fail to detect optimism and pessimism.",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"Specifically, we train several sentiment classifiers on the large SST and TSA sentiment datasets (described in Section 2) and evaluate the performance of these classifiers on the optimism/pessimism categories from the OPT dataset.
",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
Table 3 shows the performance of several deep learning models trained on either SST or TSA datasets and evaluated on the OPT dataset.,3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
Note that the Dev set was used for model selection.,3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"As can be seen from the table, the models trained on the sentiment datasets perform poorly on the optimism/pessimism dataset.",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"For example, there is a drop in performance from 80.19% to 67.60% when training on TSA (with an even larger decrease when we train on SST).
",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"The SST/TSA sentiment classifiers are trained to predict the sentiment as negative, neutral, or positive.",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"To calculate the accuracy in Table 3, an optimistic tweet predicted as positive by the sentiment classifier counts as a correct prediction, whereas an optimistic tweet predicted as either neutral or negative by the sentiment classifier counts as an incorrect prediction (similarly for pessimistic tweets).",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"This analysis is done at tweet level for the threshold of 0.
",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"Figure 2 shows the normalized number of examples from optimism and pessimism categories classified as positive, negative and neutral, using the CNN model trained on TSA.",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"Precisely, we show how many tweets from the set of optimistic (or pessimistic) tweets in the OPT dataset are predicted as negative, neutral or positive by the TSA sentiment classifier.",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
The numbers on each row sum up to 1.,3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"As we can see from the figure, although pessimism is more correlated with a negative sentiment, 13% of the pessimistic tweets are classified as positive (with similar results on the optimism category).",3.2 Sentiment vs. Optimism/Pessimism,[0],[0]
"In this section, we perform a linguistic analysis and study the usage of verb tenses in optimistic and pessimistic tweets, as well as the presence of polarity words associated with both types of tweets.",3.3 Linguistic Analysis,[0],[0]
This analysis is done at tweet level with 1/- 1 threshold.,3.3 Linguistic Analysis,[0],[0]
The reason for using the 1/-1 threshold is that we wanted to study the usage of verb tenses and polarity words in tweets that are clear optimistic or clear pessimistic (far from the decision boundary).,3.3 Linguistic Analysis,[0],[0]
"For this analysis, we used the part of speech tagger spaCy5 and assigned the verbs to their corresponding tenses according to the Penn Treebank Project; that is, the tags VBD and VBN correspond to past tense, VBG, VBZ , VBP correspond to present tense, whereas an MD tag followed by VB (possibly with a negation between them) corresponds to the future tense.
",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"5http://textanalysisonline.com/spacy-pos-tagging
As mentioned, a tweet was considered optimist if its manually annotated score was above 1 and pessimist if the score was below −1.",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"The numbers of tweets with past, present, and future tenses in the optimistic category are: 1,474, 7,444, and 561, respectively, whereas these numbers in the pessimistic category are: 1,276, 5,311, and 325, respectively.
",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"Figure 3 shows the normalized verb occurrences at past, present and future tenses in optimistic and pessimistic tweets.",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"As can be seen from the figure, the present tense is the most prevalent for both categories, although there are more present tense verbs in the optimistic category compared with the pessimistic one.",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"We can also observe that more past tense verbs occur in the pessimistic category and less future tense verbs in the pessimistic one.
",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"While there are some common verbs such as “be,” “have,” and “do,” that appear most frequently in both optimistic and pessimistic categories at all three tenses, there are some verbs that are more specific to one category than the other.",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
Examples of such verbs and their frequencies from both categories at the present tense are shown in Table 4.,3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"As we can see, optimism is characterized more by verbs with a positive connotation.",3.3.1 Verb Tenses in Optimism/Pessimism,[0],[0]
"Next, we analyze the association of polarity words from the positive and negative lexicons constructed by Hu and Liu (2004), in both tweet categories: optimism and pessimism.",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"Instead of using the presence or absence of the words from the two lexicons in tweets, we calculated the cosine similarity between the word embeddings of the words in the two lexicons with the words in the tweets.",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"If the similarity is above 0.8, then we consider the word from the corresponding lexicon to be present in the tweet (or synonym with a word in tweet).",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"Using the cosine similarity between the word embeddings of words in lexicons with words in tweets captures not only the exact match between the words (a cosine similarity of 1 for exact match), but also incorporates the semantic information that exists in the text.
",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"Although this word similarity computation relaxes the exact match/presence of a word in a tweet and aims at incorporating semantic similarity, a high similarity between antonyms may occur since word embeddings are known to not differentiate well between synonyms and antonyms, which tend to appear in similar contexts.
",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
Figure 4 shows the number of polarity words in optimistic and pessimistic tweets.,3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"As shown in the figure, more positive words appear in optimistic tweets compared with negative words (1,242 vs. 71), while there is not a substantial difference between the numbers of positive and negative words in pessimistic tweets (118 vs. 210).
",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
Table 5 shows the top most frequent polarity words associated with optimism and pessimism.,3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"As we can see, words with a negative polarity (e.g., bad) although not very frequent, still appear in optimistic tweets.",3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
This supports our intuition that a sentiment model is not enough to accurately predict pessimism and optimism in Twitter.,3.3.2 Polarity Words in Optimism/Pessimism,[0],[0]
"In this paper, we explored deep learning models for optimism and pessimism prediction in Twitter and showed that these models substantially outperform traditional classifiers such as Naı̈ve Bayes and Support Vector Machines.",4 Concluding Remarks,[0],[0]
"To our knowledge, this work is the first computational study that explores optimism and pessimism using deep learning.",4 Concluding Remarks,[0],[0]
We also showed that a sentiment classifier would not be sufficient for accurately predicting optimism and pessimism.,4 Concluding Remarks,[0],[0]
"This topic is less explored despite its importance in many applications such as identifying suicidal/depressive people.
",4 Concluding Remarks,[0],[0]
"Interesting future directions are: understanding how one’s age is correlated with optimism / pessimism; if one user is characterized by a mixture of topics, is that user optimist (pessimist) across all these topics?",4 Concluding Remarks,[0],[0]
"Thus, decomposing a user’s textual data into topic and correlating this with optimism and pessimism may be interesting to explore; last, studying how optimism and pessimism are affected by sarcasm.
",4 Concluding Remarks,[0],[0]
"As we started our study with a pessimistic quote from the movie “The Edge of Seventeen,” we end our study with a quote from the same movie, with a positive sentiment and full of optimism:
“Life’s about taking risks.",4 Concluding Remarks,[0],[0]
Don’t be afraid to put yourself out there.”,4 Concluding Remarks,[0],[0]
All authors contributed equally.,Acknowledgments,[0],[0]
"LP Dinu was supported by UEFISCDI, project #53BG/2016.",Acknowledgments,[0],[0]
We thank our reviewers for their constructive comments and feedback.,Acknowledgments,[0],[0]
"Identifying optimistic and pessimistic viewpoints and users from Twitter is useful for providing better social support to those who need such support, and for minimizing the negative influence among users and maximizing the spread of positive attitudes and ideas.",abstractText,[0],[0]
"In this paper, we explore a range of deep learning models to predict optimism and pessimism in Twitter at both tweet and user level and show that these models substantially outperform traditional machine learning classifiers used in prior work.",abstractText,[0],[0]
"In addition, we show evidence that a sentiment classifier would not be sufficient for accurately predicting optimism and pessimism in Twitter.",abstractText,[0],[0]
"Last, we study the verb tense usage as well as the presence of polarity words in optimistic and pessimistic tweets.",abstractText,[0],[0]
Exploring Optimism and Pessimism in Twitter Using Deep Learning,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4785–4790 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4785",text,[0],[0]
"Recently, end-to-end Neural Machine Translation (NMT) models (Sutskever et al., 2014; Bahdanau et al., 2015) have achieved notable success.",1 Introduction,[0],[0]
"A remarkable characteristic of NMT is that the decoder, which is typically implemented using Recurrent Neural Network (RNN), can capture the features of the entire decoding history.",1 Introduction,[0],[0]
"This model
∗Zhisong Zhang was a graduate student at SJTU and a research intern at NICT when conducting this work.",1 Introduction,[0],[0]
"This work is partially supported by the program “Promotion of Global Communications Plan: Research, Development, and Social Demonstration of Multilingual Speech Translation Technology” of MIC, Japan.",1 Introduction,[0],[0]
"Hai Zhao was partially supported by National Key Research and Development Program of China (No. 2017YFB0304100), National Natural Science Foundation of China (No. 61672343 and No. 61733011), Key Project of National Society Science Foundation of China (No. 15-ZDA041), The Art and Science Interdisciplinary Funds of Shanghai Jiao Tong University (No. 14JCRZ04).",1 Introduction,[0],[0]
"Thanks a lot for the helpful discussions with Kehai Chen.
",1 Introduction,[0],[0]
"†Co-corresponding authors
with “cities” correspond to the nodes box ed in Figure 1 (only three hypotheses are listed for brevity).",1 Introduction,[0],[0]
"The negative log probabilities calculated by the model for the words predicted after “cities” are given in parentheses.
",1 Introduction,[0],[0]
"nodes inside the box represent the hidden features of partial hypotheses ending with “cities”.
does not depend on any independence assumptions and treats sequences with different prefixes as totally different hypotheses.",1 Introduction,[0],[0]
"However, many of the NMT output sequences are quite similar and they typically contain only local differences that do not influence future decoding significantly.
",1 Introduction,[0],[0]
Table 1 and Figure 1 present an example of such pattern of local differences in NMT decoding.,1 Introduction,[0],[0]
"As shown in Table 1, the three partial hypotheses that
Algorithm 1 Merging for Beam Search.",1 Introduction,[0],[0]
"Require: list of sorted candidates C; beam size k;
equivalence function Eq.",1 Introduction,[0],[0]
"Ensure: list of candidates surviving in the beam: C′.
1:",1 Introduction,[0],[0]
C′ =,1 Introduction,[0],[0]
[ ] 2: # Scan according to the sorted order.,1 Introduction,[0],[0]
3: for c in C: 4: merge flag = False 5: #,1 Introduction,[0],[0]
Check previous surviving states for merging.,1 Introduction,[0],[0]
6: for s in C′: 7: # Check with candidate merger states.,1 Introduction,[0],[0]
"8: for s′ in sequence(s): 9: if Eq(c, s′) and score(c)<score(s′):
10: merge flag = True 11:",1 Introduction,[0],[0]
# Pruning by the merger.,1 Introduction,[0],[0]
12: if not merge flag: 13: C′.append(c) 14:,1 Introduction,[0],[0]
# Pruning by the beam size.,1 Introduction,[0],[0]
15: if len(C′),1 Introduction,[0],[0]
">= k: 16: break 17: return C′
end with “cities” share similar patterns.",1 Introduction,[0],[0]
"Firstly, as shown in Figure 1, their hidden layer features are close in the latent space.",1 Introduction,[0],[0]
"Moreover, for future predictions, the model predicts identical sequences and gives similar scores for them.",1 Introduction,[0],[0]
"Although going through different paths, these partial hypotheses appear to be similar or likely equivalent.
",1 Introduction,[0],[0]
"Intuitively, for efficiency, we do not need to expand all of these partial hypotheses (states) since they have similar future predictions.",1 Introduction,[0],[0]
"In fact, this corresponds to the idea of hypothesis recombination (also known as state merging, which will be used interchangeably) from traditional PhraseBased Statistical Machine Translation (PBSMT) (Koehn et al., 2003).",1 Introduction,[0],[0]
"Given a method to find mergeable states, we can employ recombination in NMT decoding as well.
",1 Introduction,[0],[0]
"In this paper, we adopt the mechanism of recombination in NMT decoding based on the definition of “equivalence” of partial hypotheses.",1 Introduction,[0],[0]
"Heuristically, we try a simple n-gram suffix based equivalence function and apply it to beam search without adding any neural computation cost.",1 Introduction,[0],[0]
"Through experiments on two large-scale translation tasks, we show that it can help to make the decoding more efficient.
",1 Introduction,[0],[0]
"Most recent NMT studies have focused on model improvement (Luong et al., 2015; Tu et al., 2016b; Gehring et al., 2017; Vaswani et al., 2017), and only a few have studied the search problem directly.",1 Introduction,[0],[0]
"For example, Khayrallah et al. (2017) and Stahlberg et al. (2016) explored searching on lattices generated by traditional Statistical Machine Translation (SMT).",1 Introduction,[0],[0]
"In addition, Freitag and Al-
Onaizan (2017) investigated different beam search pruning strategies; however, they primarily focused on pruning candidates locally.",1 Introduction,[0],[0]
"(Niehues et al., 2017) analyzed the effects of modeling and searching, but focused on re-ranking analysis.",1 Introduction,[0],[0]
"Rather than considering candidates from other model’s k-best lists, we focus on the own exploration space of a single NMT model and provide a method for more efficient searching.",1 Introduction,[0],[0]
"For state merging, “equivalence” should be defined from the aspect of future predictions: states with the same predictions in the future decoding process can be regarded as equivalent.",2 Method,[0],[0]
"We use an equivalence function Eq(s1, s2) to denote that the two states s1 and s2 can be regarded as equivalent.
",2 Method,[0],[0]
"With the concept of equivalence, we can build the method of recombination over it.",2 Method,[0],[0]
There are mainly two problems to solve: 1.,2 Method,[0],[0]
How to merge states given function Eq?,2 Method,[0],[0]
(§2.1) 2.,2 Method,[0],[0]
How to obtain this equivalence function?,2 Method,[0],[0]
(§2.2),2 Method,[0],[0]
"To adopt an equivalence function Eq(s1, s2) to merge states in a search process, we need to specify the logic of the merging mechanism.",2.1 Search with Merging,[0],[0]
"Here, without loss of generality, we specifically focus on the typical beam search.
",2.1 Search with Merging,[0],[0]
We adopt merging in NMT beam search with a simple method: retaining the word-level search process and adding a state merger when pruning the beam at each time step.,2.1 Search with Merging,[0],[0]
"Algorithm 1 shows the proposed merging-enhanced pruning method.
",2.1 Search with Merging,[0],[0]
"Ordinary beam search only prunes candidates based on beam size (Lines 15-16), while the proposed method adds a merger to prune extra equivalent states (Lines 6-10).",2.1 Search with Merging,[0],[0]
"To manage the merging process, candidate list C are ordered1 by model score and considered in turn.",2.1 Search with Merging,[0],[0]
"When checking equivalence for one candidate state c, we consider all current-step surviving states and their previous-step antecedences.",2.1 Search with Merging,[0],[0]
"We include previousstep states, because equivalent states may have different sequence lengths and thus not be in the same beam-search step.",2.1 Search with Merging,[0],[0]
"In Line 8, we define “sequence” as a function of obtaining the possible states that
1In plain beam search, the candidates may not need to be sorted.",2.1 Search with Merging,[0],[0]
"We use a local selector to make the sorting efficient: a local k-best selector is first applied on each previous-step candidate states, making the size of the candidate list at most k ∗ k rather than k ∗ |V",2.1 Search with Merging,[0],[0]
"|, where |V | is the vocabulary size.
can merge the current candidate c.",2.1 Search with Merging,[0],[0]
"If a candidate state c is not merged with any higher-ranked state, it is added to the surviving list C ′",2.1 Search with Merging,[0],[0]
"(Line 13) and can possibly merge the lower-ranked ones later.
",2.1 Search with Merging,[0],[0]
"When deciding whether to merge, we also consider a criterion on model scores: we only merge state c when its score is lower than s′. Since we also consider previous-step states with different sequence lengths, a length reward λ is added for this comparison of partial hypotheses: score(s) =∑
y∈s λ+ log p(y).",2.1 Search with Merging,[0],[0]
"We also attempted length normalization, but found it performed slightly worse.
",2.1 Search with Merging,[0],[0]
"The merged partial hypotheses can be stored, and by assuming that their future predictions will be the same as their mergers, a lattice-like translation graph can be obtained.",2.1 Search with Merging,[0],[0]
We can further extract k-best list from this structure using another beam-search on the lattice (also with length reward when comparing partial hypotheses).,2.1 Search with Merging,[0],[0]
"Note that this beam search process can be fast, since we reuse the model scores from previous search and no extra neural computations will be included.",2.1 Search with Merging,[0],[0]
"Finding an exact equivalence function for NMT is difficult, because future predictions relies on the features from the entire previous sequence and any different sequences are not the same according to the NMT model.",2.2 Equivalence Function,[0],[0]
"Here, we consider a n-gram suffix based heuristic approximation for this problem.
",2.2 Equivalence Function,[0],[0]
"We adopt an approximate equivalence function:
Eq′(s1, s2) ≡ s1.suffix(n) = s2.suffix(n) ∧ |s1.length− s2.length|",2.2 Equivalence Function,[0],[0]
"< r
Here, suffix(n) represents the n-gram suffix of the sequence of a state, and r is the threshold for the length different of the two states.
",2.2 Equivalence Function,[0],[0]
"This definition of equivalence only considers a subset of state features, which are inspired by PBSMT.",2.2 Equivalence Function,[0],[0]
"In PBSMT, different sequences could lead to states with identical features based on n-gram suffix, and these states are exactly equivalent.",2.2 Equivalence Function,[0],[0]
"Although this is not the case for NMT, the subset may encodes important and relevant features.
",2.2 Equivalence Function,[0],[0]
"Although this function is simple and brings extra approximation, it has the merit of efficiency.",2.2 Equivalence Function,[0],[0]
"In Algorithm 1, we can store the n-gram features of the surviving states in a hash-map and replace the for-loop checking (Line 6-10) with hashing, making the extra time-complexity O(1) for each state.",2.2 Equivalence Function,[0],[0]
"During experiments, we found the extra cost
brought by feature matching is far less than the cost of original neural computation.",2.2 Equivalence Function,[0],[0]
The proposed method was evaluated on two translation tasks: NIST Chinese-English (Zh-En) and WMT English-German (En-De).,3 Experiments and Analysis,[0],[0]
"For Zh-En, the training set comprised 1.4M sentences pairs from LDC corpora.",3 Experiments and Analysis,[0],[0]
NIST 02 was selected as the development set and NIST 03 to 06 were used for testing.,3 Experiments and Analysis,[0],[0]
"For En-De, 4.5M WMT training data were utilized, the concatenation of newstest 2012 and 2013 was adopted as the development set, and newstest 2014 to 2016 were adopted as the test set.
",3 Experiments and Analysis,[0],[0]
"We implemented2 an attentional RNN-based NMT model and its decoder in Python with the DyNet toolkit (Neubig et al., 2017).",3 Experiments and Analysis,[0],[0]
All the experiments were carried out on one P100 GPU.,3 Experiments and Analysis,[0],[0]
"For Zh-En, we set the vocabulary size of both sides to 30K, and for En-De, we adopted 50K BPE operations (Sennrich et al., 2016).",3 Experiments and Analysis,[0],[0]
"The evaluation metric was tokenized BLEU (Papineni et al., 2002) calculated by multi-bleu.perl.",3 Experiments and Analysis,[0],[0]
"Detailed settings can be found in the supplementary material.
",3 Experiments and Analysis,[0],[0]
We added a local threshold pruner to exclude unlikely words whose probabilities were less than 10% of the highest and adopted length normalization for final hypotheses ranking.,3 Experiments and Analysis,[0],[0]
"For comparing partial hypotheses, the length reward λ was set to 1.0 and 0.4 for Zh-En and En-De, respectively.",3 Experiments and Analysis,[0],[0]
"For the equivalence function, we utilized a suffix of 4- gram and a length difference threshold r of 2.
",3 Experiments and Analysis,[0],[0]
These hyper-parameters were set by preliminary experiments.,3 Experiments and Analysis,[0],[0]
"For the length difference threshold r, we found that relatively small r like 1 or 2 was better than larger ones, which is reasonable since if the merged hypotheses differs too much in length, there are higher chances that they covered different information.",3 Experiments and Analysis,[0],[0]
"For n-gram suffix, we found smaller n-grams made more bad merges and 4-gram is a reasonably good choice, slightly larger ones gave slightly worse results and also less chances of recombination.",3 Experiments and Analysis,[0],[0]
Figure 2 show the results of various beam sizes on the concatenation of all test sets.,3.1 Results,[0],[0]
"Separate results are given in the supplementary material.
",3.1 Results,[0],[0]
"As shown by the speed curves, merging adds little extra cost (less than 10%) to decoding at
2https://github.com/zzsfornlp/znmt-merge
the same beam size.",3.1 Results,[0],[0]
"Moreover, since bringing no extra neural computations, the proposed merging mechanism is transparent to neural architectures and easy to adopt.",3.1 Results,[0],[0]
"In our experiments, we used batched decoding on GPU and merging did not influence the efficiency of this implementation.
",3.1 Results,[0],[0]
"For translation quality, the results indicate that the proposed methods can yield improvements at various beam sizes for Zh-En and small beam sizes for En-De.",3.1 Results,[0],[0]
"Moreover, in some way, merging can make the search more efficient.",3.1 Results,[0],[0]
"For example, in both datasets, merge-enhanced searchers with beam-size 6 can obtain comparable or better results compared to those of ordinary searchers with beam-size 12 (on BLEU, 37.17 vs. 37.11 for ZhEn, 24.64 vs. 24.67 for En-De).",3.1 Results,[0],[0]
"As for decoding speed, the one of beam-size 6 can be more than twice of the one of beam-size 12 (over 200 tokens/second vs. around 100 tokens/second).",3.1 Results,[0],[0]
"That is to say, with merging, we can achieve similar translation quality with a smaller beam size, which leads to higher decoding speed.
",3.1 Results,[0],[0]
"The results show that for large beam sizes, expanding explored search space by increasing beam size or adopting merging helps more in Zh-En than En-De.",3.1 Results,[0],[0]
"A possible explanation for this is that in NIST Zh-En dataset, each source sentences has four references for evaluation, which encourages the diversity brought by expanding reached search space.",3.1 Results,[0],[0]
"In Table 2, we compare the BLEU scores with multiple and single references on several beam sizes, and the single-reference results does not always increase along the beam size like the multiple ones.",3.1 Results,[0],[0]
"The En-De dataset also has only one reference and is similar to this case.
",3.1 Results,[0],[0]
The results also show that expanding explored search space does not always bring improvements.,3.1 Results,[0],[0]
"This concerns more on modeling than searching and corresponds with previous findings on the relations between NMT searching and modeling (Tu et al., 2016a; Niehues et al., 2017; Li et al., 2018).
",3.1 Results,[0],[0]
The potential of the proposed method might be better realized with improved NMT models.,3.1 Results,[0],[0]
We further analyzed the merge-enhanced search process.,3.2 Analysis,[0],[0]
"For these analyses, we mainly checked decoding with a beam size of 10 on Zh-En dataset.
",3.2 Analysis,[0],[0]
"Frequency of Merging First, we investigated how often recombination occurs and how much it expands the explored output space.",3.2 Analysis,[0],[0]
"For a beam size of 10, with influences from the local pruner and the proposed merger, the average expanding size is 7.60 for each step, and the average number of merger-pruned partial hypotheses is 0.61 per step (22.5 per sentence).",3.2 Analysis,[0],[0]
This indicates that a partial hypothesis is recombined in every two steps.,3.2 Analysis,[0],[0]
"The output translation graph can hold much more output space than the original k-best list, and we found that on average the possible output sequences were averagely 200 times the beam size.",3.2 Analysis,[0],[0]
"Figure 3 shows an example of the output translation graph.
",3.2 Analysis,[0],[0]
"Merging and Similarity of Hidden States It is nearly impossible to explore such a large space with an exact NMT model; thus, we depend on the assumption that merged hypotheses have nearly the same features.",3.2 Analysis,[0],[0]
"To evaluate this assumption, we calculated the similarity between the hidden layers of the merged partial hypotheses.",3.2 Analysis,[0],[0]
"Among the 122772 merge points in 5453 Zh-En sentences, the average cosine similarity (in range [−1, 1]) was 0.986, which indicates that the recombinations are reasonable.",3.2 Analysis,[0],[0]
"In addition, we tried adding simple cosine similarity constraints (using another
threshold) in the equivalence function, however, we found that this does not bring obvious additional benefits.
",3.2 Analysis,[0],[0]
Effects of Merging We further conducted comparisons between the predictions of ordinary and merge-enhanced beam search.,3.2 Analysis,[0],[0]
"First, we investigated the model scores of their predictions.",3.2 Analysis,[0],[0]
"As shown in Table 3, we selected “Beam=10, no merge” as the basic setting, and compared the predictions of other settings with it.",3.2 Analysis,[0],[0]
"Overall, the merge-enhanced searcher can obtain higher model score predictions, which suggests its stronger search ability, because the goal of searching is to return hypotheses with higher model scores.
",3.2 Analysis,[0],[0]
"Moreover, we tried a re-ranking experiment on 100-best lists with 4-checkpoint-model-ensemble, and only found similar slight improvements for plain and merge-enhanced search.",3.2 Analysis,[0],[0]
"Nevertheless, since merge-enhanced search can obtain a output translation graph, we expect that the graph can contain more diverse hypotheses.
",3.2 Analysis,[0],[0]
"To verify this, we compared the oracle BLEU scores within the reached space.",3.2 Analysis,[0],[0]
"To extract or-
acle hypotheses from the translation graphs, we simply adopted approximate Partial BLEU Oracle (Dreyer et al., 2007; Sokolov et al., 2012).",3.2 Analysis,[0],[0]
"Merge-based searcher could obtain an oracle score of 47.83, while ordinary beam searcher could only get 42.57.",3.2 Analysis,[0],[0]
Only by increasing the beam size up to 100 could the ordinary beam searcher achieve a better result of 48.74.,3.2 Analysis,[0],[0]
This indicates that recombination helps to touch more output space.,3.2 Analysis,[0],[0]
"In this work, 1) we show that decoding with heuristic recombination can obtain similar translation qualities with smaller beam sizes, thus increasing efficiency, and, 2) we empirically explore the decoding process and analyze the influences of recombination from various aspects.
",4 Conclusion and Discussion,[0],[0]
"Although the improvements brought by recombination depend on careful refinements of the model, this concerns more on modeling, since the goal of decoding is to find hypotheses with higher model scores.",4 Conclusion and Discussion,[0],[0]
The potential of recombination may be further realized by improving how the output sequences are modeled.,4 Conclusion and Discussion,[0],[0]
"Another interesting topic will be the combination with SMT or extra larger language models (Wang et al., 2013, 2014).
",4 Conclusion and Discussion,[0],[0]
"For the equivalence function, there can also be extensions.",4 Conclusion and Discussion,[0],[0]
"For example, a model-based equivalence function can be trained by using the neural features (hidden layers in RNN).",4 Conclusion and Discussion,[0],[0]
"However, modelbased equivalence functions may bring extra neural computation cost and be harder to efficiently implemented.",4 Conclusion and Discussion,[0],[0]
"In this work, we focus on the merging mechanism and leave the study of equivalence function for future work.",4 Conclusion and Discussion,[0],[0]
"In Neural Machine Translation (NMT), the decoder can capture the features of the entire prediction history with neural connections and representations.",abstractText,[0],[0]
This means that partial hypotheses with different prefixes will be regarded differently no matter how similar they are.,abstractText,[0],[0]
"However, this might be inefficient since some partial hypotheses can contain only local differences that will not influence future predictions.",abstractText,[0],[0]
"In this work, we introduce recombination in NMT decoding based on the concept of the “equivalence” of partial hypotheses.",abstractText,[0],[0]
"Heuristically, we use a simple n-gram suffix based equivalence function and adapt it into beam search decoding.",abstractText,[0],[0]
"Through experiments on large-scale Chinese-to-English and English-to-Germen translation tasks, we show that the proposed method can obtain similar translation quality with a smaller beam size, making NMT decoding more efficient.",abstractText,[0],[0]
Exploring Recombination for Efficient Decoding of Neural Machine Translation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 632–637 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
632",text,[0],[0]
Neural vector representations have become ubiquitous in all subfields of natural language processing.,1 Introduction,[0],[0]
"For the case of word vectors, important properties of the representations have been studied, including their linear substructures (Mikolov et al., 2013; Levy and Goldberg, 2014), the linear superposition of word senses (Arora et al., 2016b), and the nexus to pointwise mutual information scores between co-occurring words (Arora et al., 2016a).
",1 Introduction,[0],[0]
"However, thus far, only little is known about the properties of sentence embeddings.",1 Introduction,[0],[0]
Sentence embedding methods attempt to encode a variablelength input sentence into a fixed length vector.,1 Introduction,[0],[0]
"A number of such sentence embedding methods have been proposed in recent years (Le and Mikolov, 2014; Kiros et al., 2015; Wieting et al., 2015; Conneau et al., 2017; Arora et al., 2017).
",1 Introduction,[0],[0]
"Sentence embeddings have mainly been evaluated in terms of how well their cosine similarities mirror human judgments of semantic relatedness, typically with respect to the SemEval Semantic Textual Similarity competitions.",1 Introduction,[0],[0]
"The SICK
dataset (Marelli et al., 2014) was created to better benchmark the effectiveness of different models across a broad range of challenging lexical, syntactic, and semantic phenomena, in terms of both similarities and the ability to be predictive of entailment.",1 Introduction,[0],[0]
"However, even on SICK, oftentimes very shallow methods prove effective at obtaining fairly competitive results (Wieting et al., 2015).",1 Introduction,[0],[0]
Adi et al. investigated to what extent different embedding methods are predictive of i),1 Introduction,[0],[0]
"the occurrence of words in the original sentence, ii) the order of words in the original sentence, and iii) the length of the original sentence (Adi et al., 2016, 2017).",1 Introduction,[0],[0]
"Belinkov et al. (2017) inspected neural machine translation systems with regard to their ability to acquire morphology, while Shi et al. (2016) investigated to what extent they learn source side syntax.",1 Introduction,[0],[0]
Wang et al. (2016) argue that the latent representations of advanced neural reading comprehension architectures encode information about predication.,1 Introduction,[0],[0]
"Finally, sentence embeddings have also often been investigated in classification tasks such as sentiment polarity or question type classification (Kiros et al., 2015).",1 Introduction,[0],[0]
"Concurrently with our research, Conneau et al. (2018) investigated to what extent one can learn to classify specific syntactic and semantic properties of sentences using large amounts of training data (100,000 instances) for each property.
",1 Introduction,[0],[0]
"Overall, still, remarkably little is known about what specific semantic properties are directly reflected by such embeddings.",1 Introduction,[0],[0]
"In this paper, we specifically focus on a few select aspects of sentence semantics and inspect to what extent prominent sentence embedding methods are able to capture them.",1 Introduction,[0],[0]
Our framework generates triplets of sentences to explore how changes in the syntactic structure or semantics of a given sentence affect the similarities obtained between their sentence embeddings.,1 Introduction,[0],[0]
"To conduct our analysis, we proceed by generating new phenomena-specific evaluation datasets.
",2 Analysis,[0],[0]
Our starting point is that even minor alterations of a sentence may lead to notable shifts in meaning.,2 Analysis,[0],[0]
"For instance, a sentence S such as A rabbit is jumping over the fence and a sentence S∗ such as A rabbit is not jumping over the fence diverge with respect to many of the inferences that they warrant.",2 Analysis,[0],[0]
"Even if sentence S∗ is somewhat less idiomatic than alternative wordings such as There are no rabbits jumping over the fence, we nevertheless expect sentence embedding methods to interpret both correctly, just as humans do.
",2 Analysis,[0],[0]
"Despite the semantic differences between the two sentences due to the negation, we still expect the cosine similarity between their respective embeddings to be fairly high, in light of their semantic relatedness in touching on similar themes.
",2 Analysis,[0],[0]
"Hence, only comparing the similarity between sentence pairs of this sort does not easily lend itself to insightful automated analyses.",2 Analysis,[0],[0]
"Instead, we draw on another key idea.",2 Analysis,[0],[0]
It is common for two sentences to be semantically close despite differences in their specific linguistic realizations.,2 Analysis,[0],[0]
"Building on the previous example, we can construct a further contrasting sentence S+ such as A rabbit is hopping over the fence.",2 Analysis,[0],[0]
"This sentence is very close in meaning to sentence S, despite minor differences in the choice of words.",2 Analysis,[0],[0]
"In this case, we would want for the semantic relatedness between sentences S and S+ to be assessed as higher than between sentence S and sentence",2 Analysis,[0],[0]
"S∗.
We refer to this sort of scheme as sentence triplets.",2 Analysis,[0],[0]
We rely on simple transformations to generate several different sets of sentence triplets.,2 Analysis,[0],[0]
"In the following, we first describe the kinds of transformations we apply to generate altered sentences.",2.1 Sentence Modification Schemes,[0],[0]
"Subsequently, in Section 2.2, we shall consider how to assemble such sentences into sentence triplets of various kinds so as to assess different semantic properties of sentence embeddings.
",2.1 Sentence Modification Schemes,[0],[0]
Not-Negation.,2.1 Sentence Modification Schemes,[0],[0]
"We negate the original sentence by inserting the negation marker not before the first verb of the original sentence A to generate a new sentence B, including contractions as appropriate, or removing negations when they are already present, as in:
A: The young boy is climbing the wall made of rock.
",2.1 Sentence Modification Schemes,[0],[0]
B:,2.1 Sentence Modification Schemes,[0],[0]
"The young boy isn’t climbing the wall made of rock.
",2.1 Sentence Modification Schemes,[0],[0]
Quantifier-Negation.,2.1 Sentence Modification Schemes,[0],[0]
"We prepend the quantifier expression there is no to original sentences beginning with A to generate new sentences.
",2.1 Sentence Modification Schemes,[0],[0]
A: A girl is cutting butter into two pieces.,2.1 Sentence Modification Schemes,[0],[0]
B:,2.1 Sentence Modification Schemes,[0],[0]
"There is no girl cutting butter into two pieces.
",2.1 Sentence Modification Schemes,[0],[0]
Synonym Substitution.,2.1 Sentence Modification Schemes,[0],[0]
"We substitute the verb in the original sentence with an appropriate synonym to generate a new sentence B.
A: The man is talking on the telephone.",2.1 Sentence Modification Schemes,[0],[0]
B:,2.1 Sentence Modification Schemes,[0],[0]
"The man is chatting on the telephone.
",2.1 Sentence Modification Schemes,[0],[0]
Embedded Clause Extraction.,2.1 Sentence Modification Schemes,[0],[0]
"For those sentences containing verbs such as say, think with embedded clauses, we extract the clauses as the new sentence.
",2.1 Sentence Modification Schemes,[0],[0]
A: Octel said the purchase was expected.,2.1 Sentence Modification Schemes,[0],[0]
B:,2.1 Sentence Modification Schemes,[0],[0]
"The purchase was expected.
",2.1 Sentence Modification Schemes,[0],[0]
Passivization.,2.1 Sentence Modification Schemes,[0],[0]
"Sentences that are expressed in active voice are changed to passive voice.
",2.1 Sentence Modification Schemes,[0],[0]
A: Harley asked Abigail to bake some muffins.,2.1 Sentence Modification Schemes,[0],[0]
B:,2.1 Sentence Modification Schemes,[0],[0]
"Abigail is asked to bake some muffins.
",2.1 Sentence Modification Schemes,[0],[0]
Argument Reordering.,2.1 Sentence Modification Schemes,[0],[0]
"For sentences matching the structure “〈somebody〉 〈verb〉 〈somebody〉 to 〈do something〉”, we swap the subject and object of the original sentence A to generate a new sentence B.
A: Matilda encouraged Sophia to compete in a match.
",2.1 Sentence Modification Schemes,[0],[0]
"B: Sophia encouraged Matilda to compete in a match.
",2.1 Sentence Modification Schemes,[0],[0]
Fixed Point Inversion.,2.1 Sentence Modification Schemes,[0],[0]
We select a word in the sentence as the pivot and invert the order of words before and after the pivot.,2.1 Sentence Modification Schemes,[0],[0]
"The intuition here is that this simple corruption is likely to result in a new sentence that does not properly convey the original meaning, despite sharing the original words in common with it.",2.1 Sentence Modification Schemes,[0],[0]
"Hence, these sorts of corruptions can serve as a useful diagnostic.
",2.1 Sentence Modification Schemes,[0],[0]
"A: A dog is running on concrete and is holding a blue ball
B: concrete and is holding a blue ball a dog is running on.",2.1 Sentence Modification Schemes,[0],[0]
"Given the above forms of modified sentences, we induce five evaluation datasets, consisting of triplets of sentences as follows.
1.",2.2 Sentence Triplet Generation,[0],[0]
"Negation Detection: Original sentence, Synonym Substitution, Not-Negation
With this dataset, we seek to explore how well sentence embeddings can distinguish sentences with similar structure and opposite meaning, while using Synonym Substitution as the contrast set.",2.2 Sentence Triplet Generation,[0],[0]
"We would want the similarity between the original sentence and the negated sentence to be lower than that between the original sentence and its synonym version.
2.",2.2 Sentence Triplet Generation,[0],[0]
"Negation Variants: Quantifier-Negation, Not-Negation, Original sentence
In the second dataset, we aim to investigate how well the sentence embeddings reflect negation quantifiers.",2.2 Sentence Triplet Generation,[0],[0]
"We posit that the similarity between the Quantifier-Negation and Not-Negation versions should be a bit higher than between either the Not-Negation or the Quantifier-Negation and original sentences.
3.",2.2 Sentence Triplet Generation,[0],[0]
"Clause Relatedness: Original sentence, Embedded Clause Extraction, Not-Negation
In this third set, we want to explore whether the similarity between a sentence and its embedded clause is higher than between a sentence and its negation.
4.",2.2 Sentence Triplet Generation,[0],[0]
"Argument Sensitivity: Original sentence, Passivization, Argument Reordering
With this last test, we wish to ascertain whether the sentence embeddings succeed in distinguishing semantic information from structural information.",2.2 Sentence Triplet Generation,[0],[0]
"Consider, for instance, the following triplet.
",2.2 Sentence Triplet Generation,[0],[0]
S: Lilly loves Imogen.,2.2 Sentence Triplet Generation,[0],[0]
S+,2.2 Sentence Triplet Generation,[0],[0]
:,2.2 Sentence Triplet Generation,[0],[0]
Imogen is loved by Lilly. S∗:,2.2 Sentence Triplet Generation,[0],[0]
"Imogen loves Lilly.
",2.2 Sentence Triplet Generation,[0],[0]
"Here, S and S+ mostly share the same meaning, whereas S+ and S∗ have a similar word order, but do not possess the same specific meaning.",2.2 Sentence Triplet Generation,[0],[0]
"If the sentence embeddings focus more on semantic cues, then the similarity
between S and S+ ought to be larger than that between S+ and S∗. If the sentence embedding however is easily misled by matching sentence structures, the opposite will be the case.
",2.2 Sentence Triplet Generation,[0],[0]
5.,2.2 Sentence Triplet Generation,[0],[0]
"Fixed Point Reorder: Original sentence, Semantically equivalent sentence, Fixed Point Inversion
With this dataset",2.2 Sentence Triplet Generation,[0],[0]
", our objective is to explore how well the sentence embeddings account for shifts in meaning due to the word order in a sentence.",2.2 Sentence Triplet Generation,[0],[0]
We select sentence pairs from the SICK dataset according to their semantic relatedness score and entailment labeling.,2.2 Sentence Triplet Generation,[0],[0]
Sentence pairs with a high relatedness score and the Entailment tag are considered semantically similar sentences.,2.2 Sentence Triplet Generation,[0],[0]
"We rely on the Levenshtein Distance as a filter to ensure a structural similarity between the two sentences, i.e., sentence pairs whose Levenshtein Distance is sufficiently high are regarded as eligible.
",2.2 Sentence Triplet Generation,[0],[0]
"Additionally, we use the Fixed Point Inversion technique to generate a contrastive sentence.",2.2 Sentence Triplet Generation,[0],[0]
The resulting sentence likely no longer adequately reflects the original meaning.,2.2 Sentence Triplet Generation,[0],[0]
"Hence, we expect that, on average, the similarity between the original sentence and the semantically similar sentence should be higher than that between the original sentence and the contrastive version.",2.2 Sentence Triplet Generation,[0],[0]
We now proceed to describe our experimental evaluation based on this paradigm.,3 Experiments,[0],[0]
"Using the aforementioned triplet generation methods, we create the evaluation datasets listed in Table 1, drawing on source sentences from SICK, Penn Treebank WSJ and MSR Paraphase corpus.",3.1 Datasets,[0],[0]
"Although the process to modify the sentences is automatic, we rely on human annotators to double-check the results for grammaticality and semantics.",3.1 Datasets,[0],[0]
"This is particularly important for synonym substitution, for which we relied on WordNet (Fellbaum, 1998).",3.1 Datasets,[0],[0]
"Unfortunately, not all synonyms are suitable as replacements in a given context.",3.1 Datasets,[0],[0]
"In our experiments, we compare three particularly prominent sentence embedding methods:
1.",3.2 Embedding Methods,[0],[0]
GloVe Averaging (GloVe Avg.):,3.2 Embedding Methods,[0],[0]
The simple approach of taking the average of the word vectors for all words in a sentence.,3.2 Embedding Methods,[0],[0]
"Although this method neglects the order of words entirely, it can fare reasonably well on some of the most commonly invoked forms of evaluation (Wieting et al., 2015; Arora et al., 2017).",3.2 Embedding Methods,[0],[0]
"Note that we here rely on regular unweighted GloVe vectors (Pennington et al., 2014) instead of fine-tuned or weighted word vectors.
2.",3.2 Embedding Methods,[0],[0]
"Concatenated P-Mean Embeddings (PMeans): Rücklé et al. (2018) proposed concatenating different p-means of multiple kinds of word vectors.
3.",3.2 Embedding Methods,[0],[0]
"Sent2Vec: Pagliardini et al. (2018) proposed a method to learn word and n-gram embeddings such that the average of all words and n-grams in a sentence can serve as a highquality sentence vector.
4.",3.2 Embedding Methods,[0],[0]
"The Skip-Thought Vector approach (SkipThought) by Kiros et al. (2015) applies the neighbour prediction intuitions of the word2vec Skip-Gram model at the level of entire sentences, as encoded and decoded via recurrent neural networks.",3.2 Embedding Methods,[0],[0]
"The method trains an encoder to process an input sentence such that the resulting latent representation is optimized for predicting neighbouring sentences via the decoder.
5.",3.2 Embedding Methods,[0],[0]
"InferSent (Conneau et al., 2017) is based on supervision from an auxiliary task, namely the Stanford NLI dataset.",3.2 Embedding Methods,[0],[0]
Negation Detection.,3.3 Results and Discussion,[0],[0]
"Table 2 lists the results for the Negation Detection dataset, where S, S+, S∗
refer to the original, Synonym Substitution, and Not-Negation versions of the sentences, respectively.",3.3 Results and Discussion,[0],[0]
"For each of the considered embedding methods, we first report the average cosine similarity scores between all relevant sorts of pairings of two sentences, i.e. between the original and the Synonym-Substitution sentences (S and S+), between original and Not-Negated (S and S∗), and between Not-Negated and Synonym-Substitution (S+ and S∗).",3.3 Results and Discussion,[0],[0]
"Finally, in the last column, we report the Accuracy, computed as the percentage of sentence triplets for which the proximity relationships were as desired, i.e., the cosine similarity between the original and synonym-substituted versions was higher than the similarity between that same original and its Not-Negation version.
",3.3 Results and Discussion,[0],[0]
"On this dataset, we observe that GloVe Avg. is more often than not misled by the introduction of synonyms, although the corresponding word vector typically has a high cosine similarity with the original word’s embedding.",3.3 Results and Discussion,[0],[0]
"In contrast, both InferSent and SkipThought succeed in distinguishing unnegated sentences from negated ones.
",3.3 Results and Discussion,[0],[0]
Negation Variants.,3.3 Results and Discussion,[0],[0]
"In Table 3, S, S+, S∗ refer to the original, Not-Negation, and QuantifierNegation versions of a sentence, respectively.",3.3 Results and Discussion,[0],[0]
Accuracy in this problem is defined as percentage of sentence triples whose similarity between S+ and S∗ is the higher than similarity between S and S+ and S+ and S∗,3.3 Results and Discussion,[0],[0]
The results of both averaging of word embeddings.,3.3 Results and Discussion,[0],[0]
and SkipThought are dismal in terms of the accuracy.,3.3 Results and Discussion,[0],[0]
"InferSent, in contrast, appears to have acquired a better understanding of negation quantifiers, as these are commonplace in many NLI datasets.
",3.3 Results and Discussion,[0],[0]
Clause Relatedness.,3.3 Results and Discussion,[0],[0]
"In Table 4, S, S+, S∗ refer to original, Embedded Clause Extraction, and Not-Negation, respectively.",3.3 Results and Discussion,[0],[0]
"Although not particularly more accurate than random guessing, among the considered approaches, Sent2vec fares best in distinguishing the embedded clause of a sentence
from a negation of said sentence.",3.3 Results and Discussion,[0],[0]
"For a detailed analysis, we can divide the sentence triplets in this dataset into two categories as exemplified by the following examples:
a)",3.3 Results and Discussion,[0],[0]
Copperweld said it doesn’t expect a protracted strike. —,3.3 Results and Discussion,[0],[0]
Copperweld said it expected a protracted strike.,3.3 Results and Discussion,[0],[0]
"— It doesn’t expect a protracted strike.
",3.3 Results and Discussion,[0],[0]
"b) ”We made our own decision,” he said.",3.3 Results and Discussion,[0],[0]
"— ”We didn’t make our own decision,” he said.",3.3 Results and Discussion,[0],[0]
"— We made our own decision.
",3.3 Results and Discussion,[0],[0]
"For cases resembling a), the average SkipThought similarity between the sentence and its Not-Negation version is 79.90%, while for cases resembling b), it is 26.71%.",3.3 Results and Discussion,[0],[0]
"The accuracy of SkipThought on cases resembling a is 36.90%, and the accuracy of SkipThought on cases like b is only 0.75%",3.3 Results and Discussion,[0],[0]
It seems plausible that SkipThought is more sensitive to the word order due to the recurrent architecture.,3.3 Results and Discussion,[0],[0]
"Infersent also achieved better performance on sentences resembling a) compared with sentences resembling b), its accuracy on these two structures is 28.37% and 15.73% respectively.
",3.3 Results and Discussion,[0],[0]
Argument Sensitivity.,3.3 Results and Discussion,[0],[0]
"In Table 5, S, S+, S∗ to refer to the original sentence, it Passivization form, and the Argument Reordering version, respectively.",3.3 Results and Discussion,[0],[0]
"Although recurrent architectures are able to consider the order of words, unfortunately, none of the analysed approaches prove adept at distinguishing the semantic information from structural information in this case.
",3.3 Results and Discussion,[0],[0]
Fixed Point Reorder.,3.3 Results and Discussion,[0],[0]
"In Table 6, S, S+, S∗ to refer to the original sentence, its semantically
equivalent one and Fixed Point Inversion Version.",3.3 Results and Discussion,[0],[0]
"As Table 6 indicates, sentence embeddings based on means (GloVe averages), weighted means (Sent2Vec), or concatenation of p-mean embeddings (P-Means) are unable to distinguish the fixed point inverted sentence from the semantically equivalent one, as they do not encode sufficient word order information into the sentence embeddings.",3.3 Results and Discussion,[0],[0]
Sent2Vec does consider ngrams but these do not affect the results sufficiently.,3.3 Results and Discussion,[0],[0]
SkipThought and InferSent did well when the original sentence and its semantically equivalence share similar structure.,3.3 Results and Discussion,[0],[0]
"This paper proposes a simple method to inspect sentence embeddings with respect to their semantic properties, analysing three popular embedding methods.",4 Conclusion,[0],[0]
We find that both SkipThought and InferSent distinguish negation of a sentence from synonymy.,4 Conclusion,[0],[0]
InferSent fares better at identifying semantic equivalence regardless of the order of words and copes better with quantifiers.,4 Conclusion,[0],[0]
"SkipThoughts is more suitable for tasks in which the semantics of the sentence corresponds to its structure, but it often fails to identify sentences with different word order yet similar meaning.",4 Conclusion,[0],[0]
"In almost all cases, dedicated sentence embeddings from hidden states a neural network outperform a simple averaging of word embeddings.",4 Conclusion,[0],[0]
This research is funded in part by ARO grant no.,Acknowledgments,[0],[0]
W911NF-17-C-0098 as part of the DARPA SocialSim program.,Acknowledgments,[0],[0]
Neural vector representations are ubiquitous throughout all subfields of NLP.,abstractText,[0],[0]
"While word vectors have been studied in much detail, thus far only little light has been shed on the properties of sentence embeddings.",abstractText,[0],[0]
"In this paper, we assess to what extent prominent sentence embedding methods exhibit select semantic properties.",abstractText,[0],[0]
We propose a framework that generate triplets of sentences to explore how changes in the syntactic structure or semantics of a given sentence affect the similarities obtained between their sentence embeddings.,abstractText,[0],[0]
Exploring Semantic Properties of Sentence Embeddings,title,[0],[0]
Public debate forums provide to participants a common platform for expressing their point of view on a topic; they also present to participants the different sides of an argument.,1 Introduction,[0],[0]
"The latter can be particularly important: awareness of divergent points of view allows one, in theory, to make a fair and informed decision about an issue; and exposure to new points of view can furthermore possibly persuade a reader to change his overall stance on a topic.
Research in natural language processing (NLP) has begun to study persuasive writing and the role of language in persuasion.",1 Introduction,[0],[0]
"Tan et al. (2016) and Zhang et al. (2016), for example, have shown that the language of opinion holders or debaters and their patterns of interaction play a key role in changing the mind of a reader.",1 Introduction,[0],[0]
"At the same time,
research in psychology has shown that prior beliefs can affect our interpretation of an argument even when the argument consists of numbers and empirical studies that would seemingly belie misinterpretation (Lord et al., 1979; Vallone et al., 1985; Chambliss and Garner, 1996).
",1 Introduction,[0],[0]
"We hypothesize that studying the actual effect of language on persuasion will require a more controlled experimental setting — one that takes into account any potentially confounding userlevel (i.e., reader-level) factors1 that could cause a person to change, or keep a person from changing, his opinion.",1 Introduction,[0],[0]
In this paper we study one such type of factor: the prior beliefs of the reader as impacted by their political or religious ideology.,1 Introduction,[0],[0]
"We adopt this focus since it has been shown that ideologies play an important role for an individual when they form beliefs about controversial topics, and potentially affect how open the individual is to being persuaded (Stout and Buddenbaum, 1996; Goren, 2005; Croucher and Harris, 2012).
",1 Introduction,[0],[0]
We first present a dataset of online debates that enables us to construct the setting described above in which we can study the effect of language on persuasion while taking into account selected userlevel factors.,1 Introduction,[0],[0]
"In addition to the text of the debates, the dataset contains a multitude of background information on the users of the debate platform.",1 Introduction,[0],[0]
"To the best of our knowledge, it is the first publicly available dataset of debates that simultaneously provides such comprehensive information about the debates, the debaters and those voting on the debates.
",1 Introduction,[0],[0]
"With the dataset in hand, we then propose the novel task of studying persuasion (1) at the level of individual users, and (2) in a setting that can control for selected user-level factors, in our case, the prior beliefs associated with the political or
1Variables that affect both the dependent and independent variables causing misleading associations.
",1 Introduction,[0],[0]
"ar X
iv :1
90 6.
11 30
1v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 2
6 Ju
n 20
19
religious ideology of the debaters and voters.",1 Introduction,[0],[0]
"In particular, previous studies focus on predicting the winner of a debate based on the cumulative change in pre-debate vs. post-debate votes for the opposing sides (Zhang et al., 2016; Potash and Rumshisky, 2017).",1 Introduction,[0],[0]
"In contrast, we aim to predict which debater an individual user (i.e., reader of the debate) perceives as more successful, given their stated political and religious ideology.
",1 Introduction,[0],[0]
"Finally, we identify which features appear to be most important for persuasion, considering the selected user-level factors as well as the more traditional linguistic features associated with the language of the debate itself.",1 Introduction,[0],[0]
"We hypothesize that the effect of political and religious ideology will be stronger when the debate topic is Politics and Religion, respectively.",1 Introduction,[0],[0]
"To test this hypothesis, we experiment with debates on only Politics or only Religion vs. debates from all topics including Music, Health, Arts, etc.
",1 Introduction,[0],[0]
Our main finding is that prior beliefs associated with the selected user-level factors play a larger role than linguistic features when predicting the successful debater in a debate.,1 Introduction,[0],[0]
"In addition, the effect of these factors varies according to the topic of the debate topic.",1 Introduction,[0],[0]
"The best performance, however, is achieved when we rely on features extracted from user-level factors in conjunction with linguistic features derived from the debate text.",1 Introduction,[0],[0]
"Finally, we find that the set of linguistic features that emerges as the most predictive changes when we control for user-level factors (political and religious ideology) vs. when we do not, showing the importance of accounting for these factors when studying the effect of language on persuasion.
",1 Introduction,[0],[0]
"In the remainder of the paper, we describe the debate dataset (Section 2) and the prediction task (Section 3) followed by the experimental results and analysis (Section 4), related work (Section 5) and conclusions (Section 6).",1 Introduction,[0],[0]
"For this study, we collected 67, 315 debates from debate.org2 from 23 different topic categories including Politics, Religion, Health, Science and Music3.",2 Dataset,[0],[0]
"In addition to text of the debates, we collected 198, 759 votes from the readers of these debates.",2 Dataset,[0],[0]
"Votes evaluate different dimensions of the
2www.debate.org 3The dataset will be made publicly available at
http://www.cs.cornell.edu/ esindurmus/.
debate.",2 Dataset,[0],[0]
"To study the effect of user characteristics, we collected user information for 36, 294 different users.",2 Dataset,[0],[0]
Aspects of the dataset most relevant to our task are explained in the following section in more detail.,2 Dataset,[0],[0]
Debate rounds.,2.1 Debates,[0],[0]
"Each debate consists of a sequence of ROUNDS in which two debaters from opposing sides (one is supportive of the claim (i.e., PRO) and the other is against the claim (i.e., CON)) provide their arguments.",2.1 Debates,[0],[0]
Each debater has a single chance in a ROUND to make his points.,2.1 Debates,[0],[0]
Figure 1 shows an example ROUND 1 for the debate claim “PRESCHOOL IS A WASTE OF TIME”.,2.1 Debates,[0],[0]
"The number of ROUNDS in debates ranges from 1 to 5 and the majority of debates (61, 474 out of 67, 315) contain 3 or more ROUNDS.
",2.1 Debates,[0],[0]
Votes.,2.1 Debates,[0],[0]
All users in the debate.org community can vote on debates.,2.1 Debates,[0],[0]
"As shown in Figure 2, voters share their stances on the debate topic before and after the debate and evaluate the debaters’ conduct, their spelling and grammar, the convincingness of their arguments and the reliability of the sources they refer to.",2.1 Debates,[0],[0]
"For each such dimension, voters have the option to choose one of the debaters as better or indicate a tie.",2.1 Debates,[0],[0]
This fine-grained voting system gives a glimpse into the reasoning behind the voters’ decisions.,2.1 Debates,[0],[0]
There are two alternate criteria for determining the successful debater in a debate.,2.1.1 Determining the successful debater,[0],[0]
"Our experiments consider both.
",2.1.1 Determining the successful debater,[0],[0]
Criterion 1: Argument quality.,2.1.1 Determining the successful debater,[0],[0]
"As shown in Figure 2, debaters get points for each dimension of the debate.",2.1.1 Determining the successful debater,[0],[0]
"The most important dimension — in
that it contributes most to the point total — is making convincing arguments.",2.1.1 Determining the successful debater,[0],[0]
"debate.org uses Criterion 1 to determine the winner of a debate.
",2.1.1 Determining the successful debater,[0],[0]
Criterion 2: Convinced voters.,2.1.1 Determining the successful debater,[0],[0]
"Since voters share their stances before and after the debate, the debater who convinces more voters to change their stance is declared as the winner.",2.1.1 Determining the successful debater,[0],[0]
"On debate.org, each user has the option to share demographic and private state information such as their age, gender, ethnicity, political ideology, religious ideology, income level, education level, the president and the political party they support.",2.2 User information,[0],[0]
"Beyond that, we have access to information about their activities on the website such as their overall success rate of winning debates, the debates they participated in as a debater or voter, and their votes.",2.2 User information,[0],[0]
"An example of a user profile is shown in Figure 3.
",2.2 User information,[0],[0]
Opinions on the big issues.,2.2 User information,[0],[0]
debate.org maintains a list of the most controversial debate topics as determined by the editors of the website.,2.2 User information,[0],[0]
"These are referred to as big issues.4 Each user shares his stance on each big issue on his profile (see Figure 3): either PRO (in favor), CON (against), N/",2.2 User information,[0],[0]
"O (no opinion), N/S (not saying) or UND (undecided).",2.2 User information,[0],[0]
"In this section, we first analyze which dimensions of argument quality are the most important for determining the successful debater.",3 Prediction task: which debater will be declared as more successful by an individual voter?,[0],[0]
"Then, we analyze whether there is any connection between selected user-level factors and users’ opinions on the
4http://www.debate.org/big-issues/
big issues to see if we can infer their opinions from these factors.",3 Prediction task: which debater will be declared as more successful by an individual voter?,[0],[0]
"Finally, using our findings from these analyses, we perform the task of predicting which debater will be perceived as more successful by an individual voter.",3 Prediction task: which debater will be declared as more successful by an individual voter?,[0],[0]
Figure 4 shows the correlation between pairs of voting dimensions (in the first 8 rows and columns) and the correlation of each dimension with (1) getting more points (row or column 9) and (2) convincing more people as a debater (final row or column).,3.1 Relationships between argument quality dimensions,[0],[0]
"Abbreviations stand for (on the CON side): has better conduct (CBC), makes more convincing arguments (CCA), uses more reliable sources (CRS), has better spelling and grammar (CBSG), gets more total points (CMTP) and convinces more voters (CCMV).",3.1 Relationships between argument quality dimensions,[0],[0]
"For the PRO side we
use PBC, PCA, and so on.",3.1 Relationships between argument quality dimensions,[0],[0]
"From Figure 4, we can see that making more convincing arguments (CCA) correlates the most with total points (CMTP) and convincing more voters (CCMV).",3.1 Relationships between argument quality dimensions,[0],[0]
This analysis motivates us to identify the linguistic features that are indicators of more convincing arguments.,3.1 Relationships between argument quality dimensions,[0],[0]
"opinions on the big issues and their prior beliefs
We disentangle different aspects of a person’s prior beliefs to understand how well each correlates with their opinions on the big issues.",3.2 The relationship between a user’s,[0],[0]
"As noted earlier, we focus here only on prior beliefs in the form of self-identified political and religious ideology.
",3.2 The relationship between a user’s,[0],[0]
Representing the big issues.,3.2 The relationship between a user’s,[0],[0]
"To represent the opinions of a user on a big issue, we use a fourdimensional one-hot encoding where the indices of the vector correspond to PRO, CON, N/O (no opinion), and UND (undecided), consecutively (1 if the user chooses that value for the issue, 0 otherwise).",3.2 The relationship between a user’s,[0],[0]
Note that we do not have a representation for N/S since we eliminate users having N/S for at least one big issue for this study.,3.2 The relationship between a user’s,[0],[0]
We then concatenate the vector for each big issue to get a representation for a user’s stance on all the big issues as shown in Figure 5.,3.2 The relationship between a user’s,[0],[0]
"We denote this vector by BIGISSUES.
We test the correlation between the individual’s opinions on big issues and the selected userlevel factors in this study using two different approaches: clustering and classification.
",3.2 The relationship between a user’s,[0],[0]
Clustering the users’ decisions on big issues.,3.2 The relationship between a user’s,[0],[0]
We apply PCA on the BIGISSUES vectors of users who identified themselves as CONSERVATIVE vs. LIBERAL (740 users).,3.2 The relationship between a user’s,[0],[0]
We do the same for the users who identified themselves as ATHEIST vs. CHRISTIAN (1501 users).,3.2 The relationship between a user’s,[0],[0]
"In Figure 6, we see that there are distinctive clusters of CONSERVATIVE vs. LIBERAL users in the two-dimensional representation
while for ATHEIST vs. CHRISTIAN, the separation is not as distinct.",3.2 The relationship between a user’s,[0],[0]
"This suggests that people’s opinions on the big issues identified by debate.org correlate more with their political ideology than their religious ideology.
",3.2 The relationship between a user’s,[0],[0]
Classification approach.,3.2 The relationship between a user’s,[0],[0]
We also treat this as a classification task5 using the BIGISSUES vectors for each user as features and the user’s religious and political ideology as the labels to be predicted.,3.2 The relationship between a user’s,[0],[0]
"So the classification task is: Given the user’s BIGISSUES vector, predict his political and religious ideology.",3.2 The relationship between a user’s,[0],[0]
Table 1 shows the accuracy for each case.,3.2 The relationship between a user’s,[0],[0]
"We see that using the BIGISSUES vectors as features performs significantly better6 than majority baseline7.
",3.2 The relationship between a user’s,[0],[0]
This analysis shows that there is a clear relationship between people’s opinions on the big issues and the selected user-level factors.,3.2 The relationship between a user’s,[0],[0]
It raises the question of whether it is even possible to persuade someone with prior beliefs relevant to a debate claim to change their stance on the issue.,3.2 The relationship between a user’s,[0],[0]
"It may be the case that people prefer to agree with the individuals having the same (or similar) beliefs regardless of the quality of the arguments and the
5For all the classification tasks described in this paper, we experiment with logistic regression, optimizing the regularizer (`1 or `2) and the regularization parameter C (between 10−5 and 105).
",3.2 The relationship between a user’s,[0],[0]
6We performed the McNemar significance test.,3.2 The relationship between a user’s,[0],[0]
"7The majority class baseline predicts CONSERVATIVE for political and CHRISTIAN for religious ideology for each example, respectively.
particular language used.",3.2 The relationship between a user’s,[0],[0]
"Therefore, it is important to understand the relative effect of prior beliefs vs. argument strength on persuasion.",3.2 The relationship between a user’s,[0],[0]
"Some of the previous work in NLP on persuasion focuses on predicting the winner of a debate as determined by the change in the number of people supporting each stance before and after the debate (Zhang et al., 2016; Potash and Rumshisky, 2017).",3.3 Task descriptions,[0],[0]
"However, we believe that studies of the effect of language on persuasion should take into account other, extra-linguistic, factors that can affect opinion change: in particular, we propose an experimental framework for studying the effect of language on persuasion that aims to control for the prior beliefs of the reader as denoted through their self-identified political and religious ideologies.",3.3 Task descriptions,[0],[0]
"As a result, we study a more fine-grained prediction task: for an individual voter, predict which side/debater/argument the voter will declare as the winner.
",3.3 Task descriptions,[0],[0]
Task 1 : Controlling for religious ideology.,3.3 Task descriptions,[0],[0]
"In the first task, we control for religious ideology by selecting debates for which each of the two debaters is from a different religious ideology (e.g., debater 1 is ATHEIST, debater 2 is CHRISTIAN).",3.3 Task descriptions,[0],[0]
"In addition, we consider only voters that (a) self-identify with one of these religious ideologies (e.g., the voter is either ATHEIST or CHRISTIAN) and (b) changed their stance on the debate claim post-debate vs. pre-debate.",3.3 Task descriptions,[0],[0]
"For each such voter, we want to predict which of the PRO-side debater or the CON-side debater did the convincing.",3.3 Task descriptions,[0],[0]
"Thus, in this task, we use Criterion 2 to determine the winner of the debate from the point of view of the voter.",3.3 Task descriptions,[0],[0]
"Our hypothesis is that the voter will be convinced by the debater that espouses the religious ideology of the voter.
",3.3 Task descriptions,[0],[0]
"In this setting, we can study the factors that are important for a particular voter to be convinced by a debater.",3.3 Task descriptions,[0],[0]
"This setting also provides an opportunity to understand how the voters who change their minds perceive arguments from a debater who is expressing the same vs. the opposing prior belief.
",3.3 Task descriptions,[0],[0]
"To study the effect of the debate topic, we perform this study for two cases — debates belonging to the Religion category and then all the categories.",3.3 Task descriptions,[0],[0]
"The Religion category contains debates like “IS THE BIBLE AGAINST WOMEN’S RIGHTS?” and “RELIGIOUS THEORIES SHOULD
NOT BE TAUGHT IN SCHOOL”.",3.3 Task descriptions,[0],[0]
We want to see how strongly a user’s religious ideology affects the persuasive effect of language in such a topic as compared to the all topics.,3.3 Task descriptions,[0],[0]
"We expect to see stronger effects of prior beliefs for debates on Religion.
",3.3 Task descriptions,[0],[0]
Task 2: Controlling for political ideology.,3.3 Task descriptions,[0],[0]
"Similar to the setting described above, Task 2 controls for political ideology.",3.3 Task descriptions,[0],[0]
"In particular, we only use debates where the two debaters are from different political ideologies (CONSERVATIVE vs. LIBERAL).",3.3 Task descriptions,[0],[0]
"In contrast to Task 1, we consider all voters that self-identify with one of the two debater ideologies (regardless of whether the voter’s stance changed post-debate vs. pre-debate).",3.3 Task descriptions,[0],[0]
"This time, we predict whether the voter gives more total points to the PRO side or the CON side argument.",3.3 Task descriptions,[0],[0]
"Thus, Task 2 uses Criterion 1 to determine the winner of the debate from the point of view of the voter.",3.3 Task descriptions,[0],[0]
"Our hypothesis is that the voter will assign more points to the debater that has the same political ideology as the voter.
",3.3 Task descriptions,[0],[0]
"For this task too, we perform the study for two cases — debates from the Politics category only and debates from all categories.",3.3 Task descriptions,[0],[0]
And we expect to see stronger effects of prior beliefs for debates on Politics.,3.3 Task descriptions,[0],[0]
The features we use in our model are shown in Table 2.,3.4 Features,[0],[0]
"They can be divided into two groups — features that describe the prior beliefs of the users and linguistic features of the arguments themselves.
",3.4 Features,[0],[0]
User features We use the cosine similarities between the voter and each of the debaters’ big issue vectors.,3.4 Features,[0],[0]
These features give a good approximation of the overall similarity of two user’s opinions.,3.4 Features,[0],[0]
"Second, we use indicator features to encode whether the religious and political beliefs of the voter match those of each of the debaters.
",3.4 Features,[0],[0]
Linguistic features We extract linguistic features separately for both the PRO and CON side of the debate (combining all the utterances of PRO across different turns and doing the same for CON).,3.4 Features,[0],[0]
Table 2 contains a list of these features.,3.4 Features,[0],[0]
"It includes features that carry information about the style of the language (e.g., usage of modal verbs, length, punctuation), represent different semantic aspects of the argu-
ment (e.g., showing evidence, connotation (Feng and Hirst, 2011), subjectivity (Wilson et al., 2005), sentiment, swear word features) as well as features that convey different argumentation styles (argument lexicon features (Somasundaran and Wiebe, 2010).",3.4 Features,[0],[0]
"Argument lexicon features include the counts for the phrases that match with the regular expressions of argumentation styles such as assessment, authority, conditioning, contrasting, emphasizing, generalizing, empathy, inconsistency, necessity, possibility, priority, rhetorical questions, desire, and difficulty.",3.4 Features,[0],[0]
We then concatenate these features to get a single feature representation for the entire debate.,3.4 Features,[0],[0]
"For each of the tasks, prediction accuracy is evaluated using 5-fold cross validation.",4 Results and Analysis,[0],[0]
We pick the model parameters for each split with 3-fold cross validation on the training set.,4 Results and Analysis,[0],[0]
We do ablation for each of user-based and linguistic features.,4 Results and Analysis,[0],[0]
"We report the results for the feature sets that perform better than the baseline.
",4 Results and Analysis,[0],[0]
"We perform analysis by training logistic regression models using only user-based features, only linguistic features and finally combining userbased and linguistic features for both the tasks.
",4 Results and Analysis,[0],[0]
Task 1 for debates in category Religion.,4 Results and Analysis,[0],[0]
"As shown in Table 3, the majority baseline (predicting the winner side of the majority of training examples out of PRO or CON) gets 56.10% accuracy.",4 Results and Analysis,[0],[0]
User features alone perform significantly better than the majority baseline.,4 Results and Analysis,[0],[0]
The most important user-based feature is matching religious ideology.,4 Results and Analysis,[0],[0]
This means it is very likely that people change their views in favor of a debater with the same religious ideology.,4 Results and Analysis,[0],[0]
"In a linguistic-only features analysis, combination of the personal pronouns and connotation features emerge as most important and also perform significantly better than the majority baseline at 65.37% accuracy.",4 Results and Analysis,[0],[0]
"When we use both user-based and linguistic features to predict, the accuracy improves to 66.42% with connotation features.",4 Results and Analysis,[0],[0]
An interesting observation is that including the user-based features along with the linguistic features changes the set of important linguistic features for persuasion removing the personal pronouns from the important linguistic features set.,4 Results and Analysis,[0],[0]
"This shows the importance of studying potentially confounding user-level factors.
",4 Results and Analysis,[0],[0]
Task 1 for debates in all categories.,4 Results and Analysis,[0],[0]
"As shown in Table 4, for the experiments with user-based features only, matching religious ideology and opinion similarity features are the most important.",4 Results and Analysis,[0],[0]
"For this task, length is the most predictive linguistic feature and can achieve significant improve-
ment over the baseline (61.01%).",4 Results and Analysis,[0],[0]
"When we combine the language features with user-based features, we see that with exclamation mark the accuracy improves to (65.74%).
",4 Results and Analysis,[0],[0]
Task 2 for debates in category Politics.,4 Results and Analysis,[0],[0]
"As shown in Table 5, using user-based features only, the matching political ideology feature performs the best (80.40%).",4 Results and Analysis,[0],[0]
"Linguistic features (refer to Table 5 for the full list) alone, however, can still obtain significantly better accuracy than the baseline (59.60%).",4 Results and Analysis,[0],[0]
"The most important linguistic features include approval, politeness, modal verbs, punctuation and argument lexicon features such as rhetorical questions and emphasizing.",4 Results and Analysis,[0],[0]
"When combining this linguistic feature set with the matching political ideology feature, we see that with the accuracy improves to (81.81%).",4 Results and Analysis,[0],[0]
"Length feature does not give any improvement when it is combined with the user features.
",4 Results and Analysis,[0],[0]
Task 2 for debates in all categories.,4 Results and Analysis,[0],[0]
"As shown in Table 6, when we include all categories, we see that the best performing user-based feature is the opinion similarity feature (73.96%).",4 Results and Analysis,[0],[0]
"When using language features only, length feature (56.88%) is the most important.",4 Results and Analysis,[0],[0]
"For this setting, the best accuracy is achieved when we combine user features with length and Tf-idf features.",4 Results and Analysis,[0],[0]
We see that the set of language features that improve the performance of user-based features do not include some of that perform significantly better than the baseline when used alone (modal verbs and politeness features).,4 Results and Analysis,[0],[0]
"Below we provide an overview of related work from the multiple disciplines that study persuasion.
",5 Related Work,[0],[0]
Argumentation mining.,5 Related Work,[0],[0]
"Although most recent work on argumentation has focused on identifying the structure of arguments and extracting argument components (Persing and Ng, 2015; Palau and Moens, 2009; Biran and Rambow, 2011; Mochales and Moens, 2011; Feng and Hirst, 2011; Stab and Gurevych, 2014; Lippi and Torroni, 2015; Park and Cardie, 2014; Nguyen and Litman, 2015; Peldszus and Stede, 2015; Niculae et al., 2017; Rosenthal and McKeown, 2015), more relevant is research on identifying the characteristics of persuasive text, e.g., what distinguishes persuasive from non-persuasive text (Tan et al., 2016; Zhang et al., 2016; Wachsmuth et al., 2016; Habernal and Gurevych, 2016a,b; Fang et al., 2016; Hidey et al., 2017).",5 Related Work,[0],[0]
"Similar to these, our work aims to understand the characteristics of persuasive text but also considers the effect of people’s prior beliefs.
",5 Related Work,[0],[0]
Persuasion.,5 Related Work,[0],[0]
"There has been a tremendous amount of research effort in the social sciences (including computational social science) to understand the characteristics of persuasive text (Kelman, 1961; Burgoon et al., 1975; Chaiken, 1987; Tykocinskl et al., 1994; Chambliss and Garner, 1996; Dillard and Pfau, 2002; Cialdini, 2007; Durik et al., 2008; Tan et al., 2014; Marquart
and Naderer, 2016).",5 Related Work,[0],[0]
"Most relevant among these is the research of Tan et al. (2016), Habernal and Gurevych (2016a) and Hidey et al. (2017).",5 Related Work,[0],[0]
Tan et al. (2016) focused on the effect of user interaction dynamics and language features looking at the ChangeMyView9 (an internet forum) community on Reddit and found that user interaction patterns as well as linguistic features are connected to the success of persuasion.,5 Related Work,[0],[0]
"In contrast, Habernal and Gurevych (2016a) created a crowd-sourced corpus consisting of argument pairs and, given a pair of arguments, asked annotators which is more convincing.",5 Related Work,[0],[0]
This allowed them to experiment with different features and machine learning techniques for persuasion prediction.,5 Related Work,[0],[0]
"Taking motivation from Aristotle’s definition for modes of persuasion, Hidey et al. (2017) annotated claims and premises extracted from the ChangeMyView community with their semantic types to study if certain semantic types or different combinations of semantic types appear in persuasive but not in non-persuasive essays.",5 Related Work,[0],[0]
"In contrast to the above, our work focuses on persuasion in debates than monologues and forum datasets and accounts for the user-based features.
",5 Related Work,[0],[0]
Persuasion in debates.,5 Related Work,[0],[0]
Debates are another resource for studying the different aspects of persuasive arguments.,5 Related Work,[0],[0]
"Different from monologues where the audience is exposed to only one side of the opinions about an issue, debates allow the audi-
9https://www.reddit.com/r/changemyview/
ence to see both sides of a particular issue via a controlled discussion.",5 Related Work,[0],[0]
There has been some work on argumentation and persuasion on online debates.,5 Related Work,[0],[0]
"Sridhar et al. (2015), Somasundaran and Wiebe (2010) and Hasan and Ng (2014), for example, studied detecting and modeling stance on online debates.",5 Related Work,[0],[0]
Zhang et al. (2016) found that the side that can adapt to their opponents’ discussion points over the course of the debate is more likely to be the winner.,5 Related Work,[0],[0]
"None of these studies investigated the role of prior beliefs in stance detection or persuasion.
",5 Related Work,[0],[0]
User effects in persuasion.,5 Related Work,[0],[0]
Persuasion is not independent from the characteristics of the people to be persuaded.,5 Related Work,[0],[0]
"Research in psychology has shown that people have biases in the ways they interpret the arguments they are exposed to because of their prior beliefs (Lord et al., 1979; Vallone et al., 1985; Chambliss and Garner, 1996).",5 Related Work,[0],[0]
"Understanding the effect of persuasion strategies on people, the biases people have and the effect of prior beliefs of people on their opinion change has been an active area of research interest (Correll et al., 2004; Hullett, 2005; Petty et al., 1981).",5 Related Work,[0],[0]
"Eagly and Chaiken (1975), for instance, found that the attractiveness of the communicator plays an important role in persuasion.",5 Related Work,[0],[0]
Work in this area could be relevant for the future work on modeling shared characteristics between the user and the debaters.,5 Related Work,[0],[0]
"To the best of our knowledge, Lukin et al. (2017) is the most relevant work to ours since they consider features of the audience on persuasion.",5 Related Work,[0],[0]
"In particular, they studied the effect of an individual’s personality features (open, agreeable, extrovert, neurotic, etc.) on the type of argument (factual vs. emotional) they find more persuasive.",5 Related Work,[0],[0]
Our work differs from this work since we study debates and in our setting the voters can see the debaters’ profiles as well as all the interactions between the two sides of the debate rather than only being exposed to a monologue.,5 Related Work,[0],[0]
"Finally, we look at different types of user profile information such as a user’s religious and ideological beliefs and their opinions on various topics.",5 Related Work,[0],[0]
In this work we provide a new dataset of debates and a more controlled setting to study the effects of prior belief on persuasion.,6 Conclusion,[0],[0]
The dataset we provide and the framework we propose open several avenues for future research.,6 Conclusion,[0],[0]
"One could explore
the effect different aspects of people’s background (e.g., gender, education level, ethnicity) on persuasion.",6 Conclusion,[0],[0]
"Furthermore, it would be interesting to study how people’s prior beliefs affect their other activities on the website and the language they use while interacting with people with the same and different prior beliefs.",6 Conclusion,[0],[0]
"Finally, one could also try to understand in what aspects and how the language people with different prior beliefs/backgrounds use is different.",6 Conclusion,[0],[0]
These different directions would help people better understand characteristics of persuasive arguments and the effects of prior beliefs in language.,6 Conclusion,[0],[0]
This work was supported in part by NSF grant SES-1741441 and DARPA DEFT Grant FA875013-2-0015.,7 Acknowledgements,[0],[0]
"The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of NSF, DARPA or the U.S. Government.",7 Acknowledgements,[0],[0]
"We thank Yoav Artzi, Faisal Ladhak, Amr Sharaf, Tianze Shi, Ashudeep Singh and the anonymous reviewers for their helpful feedback.",7 Acknowledgements,[0],[0]
We also thank the Cornell NLP group for their insightful comments.,7 Acknowledgements,[0],[0]
Public debate forums provide a common platform for exchanging opinions on a topic of interest.,abstractText,[0],[0]
"While recent studies in natural language processing (NLP) have provided empirical evidence that the language of the debaters and their patterns of interaction play a key role in changing the mind of a reader, research in psychology has shown that prior beliefs can affect our interpretation of an argument and could therefore constitute a competing alternative explanation for resistance to changing one’s stance.",abstractText,[0],[0]
"To study the actual effect of language use vs. prior beliefs on persuasion, we provide a new dataset and propose a controlled setting that takes into consideration two reader-level factors: political and religious ideology.",abstractText,[0],[0]
We find that prior beliefs affected by these reader-level factors play a more important role than language use effects and argue that it is important to account for them in NLP studies of persuasion.,abstractText,[0],[0]
Exploring the Role of Prior Beliefs for Argument Persuasion,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1190–1199 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1190",text,[0],[0]
Statistical parsers are often criticized for their performance outside of the domain they were trained on.,1 Introduction,[0],[0]
"The most straightforward remedy would be more training data in the target domain, but building treebanks (Marcus et al., 1993) is expensive.
",1 Introduction,[0],[0]
"In this paper, we revisit this issue in light of recent developments in neural natural language processing.",1 Introduction,[0],[0]
"Our paper rests on two observations:
1.",1 Introduction,[0],[0]
It is trivial to train on partial annotations using a span-focused model.,1 Introduction,[0],[0]
Stern et al. (2017a) demonstrated that a parser with minimal dependence between the decisions that produce a parse can achieve state-of-the-art performance.,1 Introduction,[0],[0]
"We modify their parser, hence-",1 Introduction,[0],[0]
"forth MSP, so that it trains directly on individual labeled spans instead of parse trees.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"This results in a parser that can be trained, with no adjustments to the training regime, from partial sentence bracketings.
2.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"The use of contextualized word representations (Peters et al., 2017; McCann et al., 2017) greatly reduces the amount of data needed to train linguistic models.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"Contextualized word representations, which encode tokens conditioned on their context in a sentence, have been shown to give significant boosts across a variety of NLP tasks, and also to reduce the amount of data needed by an order of magnitude in some tasks.
","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"Taken together, this suggests a way to rapidly extend a newswire-trained parser to new domains.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"Specifically, we will show it is possible to achieve large out-of-domain performance improvements using only dozens of partially annotated sentences, like those shown in Figure 1.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"The resulting parser also does not suffer any degradation on the newswire domain.
","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"Along the way, we provide several other notable contributions:
• We raise the state-of-the-art single-model F1score for constituency parsing from 92.6% to 94.3% on the Wall Street Journal (WSJ) test set.","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"A trained model is publicly available.1
•","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"We show that, even without domain-specific training data, our parser has much less out-ofdomain degradation than previous parsers on “newswire-adjacent” domains like the Brown corpus.
","In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
• We provide a version of MSP which predicts its own POS tags (rather than requiring a third-party tagger).,"In [ the figure above ] , [ [ AD = 4 ] , [ AB =",[0],[0]
"When we allow annotators to selectively annotate important phenomena, we make the process faster and simpler (Mielens et al., 2015).",2 The Reconciled Span Parser (RSP),[0],[0]
"Unfortunately, this produces a disconnect between the model (which typically asserts the probability of a full parse tree) and the annotation task (which asserts the correctness of some subcomponent, like a constituent span or a dependency arc).",2 The Reconciled Span Parser (RSP),[0],[0]
"There is a body of research (Hwa, 1999; Li et al., 2016) that discusses how to bridge this gap by modifying the training data, training algorithm, or the training objective.
",2 The Reconciled Span Parser (RSP),[0],[0]
"Alternatively, we could just better align the model with the annotation task.",2 The Reconciled Span Parser (RSP),[0],[0]
"Specifically, we could train a parser whose base model predicts exactly what we ask the annotator to annotate, e.g. whether a particular span is a constituent.",2 The Reconciled Span Parser (RSP),[0],[0]
"This makes it trivial to train with partial or full annotations, because the training data reduces to a collection of span labels in either case.
",2 The Reconciled Span Parser (RSP),[0],[0]
"Luckily, recent state-of-the-art results that model NLP tasks as independently classified spans (Stern et al., 2017a) suggest this strategy is currently viable.",2 The Reconciled Span Parser (RSP),[0],[0]
"In this section, we present the Reconciled Span Parser (RSP), a modified version of the Minimal Span Parser (MSP) of Stern et al. (2017a).",2 The Reconciled Span Parser (RSP),[0],[0]
"RSP differs from MSP in the following ways:
• It is trained on a span classification task.",2 The Reconciled Span Parser (RSP),[0],[0]
"MSP trains on a maximum margin objective; that is, the loss function penalizes the
1http://allennlp.org/models
violation of a margin between the scores of the gold parse and the next highest scoring parse decoded.",2 The Reconciled Span Parser (RSP),[0],[0]
"This couples its training procedure with its decoding procedure, resulting in two versions, a top-down parser and a chart parser.",2 The Reconciled Span Parser (RSP),[0],[0]
"To allow our model to be trained on partial annotations, we change the training task to be the span classification task described below.
",2 The Reconciled Span Parser (RSP),[0],[0]
• It uses contextualized word representations instead of predicted part-of-speech tags.,2 The Reconciled Span Parser (RSP),[0],[0]
Our model uses contextualized word representations as described in Peters et al. (2018).,2 The Reconciled Span Parser (RSP),[0],[0]
"It does not take part-of-speech-tags as input, eliminating the dependence of the parser on a newswire-trained POS-tagger.",2 The Reconciled Span Parser (RSP),[0],[0]
"We will view a parse tree as a labeling of all the spans of a sentence such that:
• Every constituent span is labeled with the sequence of non-terminals assigned to it in the parse tree.",2.1 Overview,[0],[0]
"For instance, span (2, 4) in Figure 2b is labeled with the sequence 〈S,VP〉, as shown in Figure 2a.
•",2.1 Overview,[0],[0]
"Every non-constituent is labeled with the empty sequence.
",2.1 Overview,[0],[0]
"Given a sentence represented by a sequence of tokens x of length n, define spans(x) =",2.1 Overview,[0],[0]
"{(i, j) | 0 ≤",2.1 Overview,[0],[0]
i < j ≤ n}.,2.1 Overview,[0],[0]
"Define a parse for sentence x as a function π : spans(x) 7→ L where L is the set of all sequences of non-terminal tags, including the empty sequence.
",2.1 Overview,[0],[0]
"We model the probability of a parse as the independent product of its span labels:
Pr(π|x) = ∏
s∈spans(x)
Pr(π(s) | x, s)
⇒ logPr(π|x) = ∑
s∈spans(x)
logPr(π(s)",2.1 Overview,[0],[0]
"| x, s)
Hence, we will train a base model σ(l | x, s) to estimate the log probability of label l for span s (given sentence x), and we will score the overall parse with:
score(π|x) = ∑
s∈spans(x)
σ(π(s) | x, s)
",2.1 Overview,[0],[0]
"Note that this probability model accords mass to mis-structured trees (e.g. overlapping spans like (2, 5) and (3, 7) cannot both be constituents of a well-formed tree).",2.1 Overview,[0],[0]
"We solve the following Integer Linear Program (ILP)2 to find the highest scoring parse that admits a well-formed tree:
max δ ∑ (i,j)∈spans(x) v+(i,j)δ(i,j) + v",2.1 Overview,[0],[0]
"− (i,j)(1− δ(i,j))
subject to:
i <",2.1 Overview,[0],[0]
k,2.1 Overview,[0],[0]
"< j < m =⇒ δ(i,j) + δ(k,m) ≤ 1",2.1 Overview,[0],[0]
"(i, j) ∈ spans(x) =⇒ δ(i,j) ∈ {0, 1}
where:
v+(i,j) =",2.1 Overview,[0],[0]
maxl s.t,2.1 Overview,[0],[0]
.,2.1 Overview,[0],[0]
"l 6=∅ σ(l | x, (i, j))
v−(i,j) =",2.1 Overview,[0],[0]
"σ(∅ | x, (i, j)) 2There are a number of ways to reconcile the span conflicts, including an adaptation of the standard dynamic programming chart parsing algorithm to work with spans of an unbinarized tree.",2.1 Overview,[0],[0]
"However it turns out that the classification model rarely produces span conflicts, so all methods we tried performed equivalently well.",2.1 Overview,[0],[0]
"For our span classification model σ(l | x, s), we use the model from (Stern et al., 2017a), which leverages a method for encoding spans from (Wang and Chang, 2016; Cross and Huang, 2016).",2.2 Classification Model,[0],[0]
"First, it creates a sentence encoding by running a two-layer bidirectional LSTM over the sentence to obtain forward and backward encodings for each position i, denoted by fi and bi respectively.",2.2 Classification Model,[0],[0]
"Then, spans are encoded by the difference in LSTM states immediately before and after the span; that is, span (i, j) is encoded as the concatenation of the vector differences fj − fi−1 and bi−bj+1.",2.2 Classification Model,[0],[0]
"A one-layer feedforward network maps each span representation to a distribution over labels.
",2.2 Classification Model,[0],[0]
"Classification Model Parameters and Initializations
We preserve the settings used in Stern et al. (2017a) where possible.",2.2 Classification Model,[0],[0]
"As a result, the size of the hidden dimensions of the LSTM and the feedforward network is 250.",2.2 Classification Model,[0],[0]
The dropout ratio for the LSTM is set to 0.4 .,2.2 Classification Model,[0],[0]
"Unlike the model it is based on, our model uses word embeddings of length 1124.",2.2 Classification Model,[0],[0]
"These result from concatenating a 100 dimension learned word embedding, with a 1024 di-
mension learned linear combination of the internal states of a bidirectional language model run on the input sentence as described in Peters et al. (2018).",2.2 Classification Model,[0],[0]
We refer to them below as ELMo (Embeddings from Language Models).,2.2 Classification Model,[0],[0]
"For the learned embeddings, words with n occurrences in the training data are replaced by 〈UNK〉 with probability 1+ n
10 1+n .",2.2 Classification Model,[0],[0]
This does not affect the ELMo component of the word embeddings.,2.2 Classification Model,[0],[0]
"As a result, even common words are replaced with probability at least 1 10 , making the model rely on the ELMo embeddings instead of the learned embeddings.",2.2 Classification Model,[0],[0]
"To make the model self-contained, it does not take part-ofspeech tags as input.",2.2 Classification Model,[0],[0]
"Using a linear layer over the last hidden layer of the classification model, partof-speech tags are predicted for spans containing single words.",2.2 Classification Model,[0],[0]
"On WSJTEST3, RSP outperforms (see Table 1) all previous single models trained on WSJTRAIN by a significant margin, raising the state-of-the-art result from 92.6% to 94.3%.",3.1 Performance on Newswire,[0],[0]
"Additionally, our predicted part-of-speech tags achieve 97.72%4 accuracy on WSJTEST.
3For all our experiments on the WSJ component of the Penn Treebank (Marcus et al., 1993), we use the standard split which is sections 2-21 for training, henceforth WSJTRAIN, section 22 for development, henceforth WSJDEV, and 23 for testing, henceforth WSJTEST.
4The split we used is not standard for part-of-speech tagging.",3.1 Performance on Newswire,[0],[0]
"As a result, we do not compare to part-of-speech taggers.",3.1 Performance on Newswire,[0],[0]
"The Brown Corpus The Brown corpus (Marcus et al., 1993) is a standard benchmark used to assess WSJ-trained parsers outside of the newswire domain.",3.2 Beyond Newswire,[0],[0]
"When (Kummerfeld et al., 2012) parsed the various Brown verticals with the (then state-of-the-art) Charniak parser (Charniak, 2000; Charniak and Johnson, 2005; McClosky et al., 2006a), it achieved F1 scores between 83% and 86%, even though its F1 score on WSJTEST was 92.1%.
",3.2 Beyond Newswire,[0],[0]
"In Table 3, we discover that RSP does not suffer nearly as much degradation, with an average F1-score of 90.3%.",3.2 Beyond Newswire,[0],[0]
"To determine whether this increased portability is because of the parser architecture or the use of ELMo vectors, we also run MSP on the Brown verticals.",3.2 Beyond Newswire,[0],[0]
"We used the Stanford tagger5 (Toutanova et al., 2003) to tag WSJTRAIN and the Brown verticals so that MSP could be given these at train and test time.",3.2 Beyond Newswire,[0],[0]
We learned that most of the improvement can be attributed to the ELMo word representations.,3.2 Beyond Newswire,[0],[0]
"In fact, even if we use MSP with gold POS tags, the average performance is 3.4% below RSP.
Question Bank and Genia Despite being a standard benchmark for parsing domain adaptation, the Brown corpus has considerable commonality with newswire text.",3.2 Beyond Newswire,[0],[0]
It is primarily composed of well-formed sentences with similar syntactic phenomena.,3.2 Beyond Newswire,[0],[0]
"Perhaps the main challenge with the Brown corpus is a difference in vocabulary, rather than a difference in syntax, which may explain the success of RSP, which leverages contextualized embeddings learned from a large corpus.
",3.2 Beyond Newswire,[0],[0]
"If we try to run RSP on a more syntactically divergent corpus like QuestionBank6 (Judge et al., 2006), we find much more performance degradation.",3.2 Beyond Newswire,[0],[0]
"This is unsurprising, since WSJTRAIN does not contain many examples of question syntax.",3.2 Beyond Newswire,[0],[0]
"But how many examples do we need, to get good performance?
",3.2 Beyond Newswire,[0],[0]
"5We used the english-left3words-distsim.tagger model from the 2017-06-09 release of the Stanford POS tagger since it achieved the best accuracy on the Brown corpus.
6For all our experiments on QuestionBank, we use the following split: sentences 1-1000 and 2001-3000 for training, henceforth QBANKTRAIN, 1001-1500 and 3001-3500 for development, henceforth QBANKDEV, and 1501-2000 and 2501-4000 for testing, henceforth QBANKTEST.",3.2 Beyond Newswire,[0],[0]
"This split is described at https://nlp.stanford.edu/data/QuestionBankStanford.shtml.
",3.2 Beyond Newswire,[0],[0]
"For the experiments summarized in table 4 and table 5 involving 40k sentences from WSJTRAIN, we started with RSP trained on WSJTRAIN, and fine-tuned it on minibatches containing an equal number of target domain and WSJTRAIN sentences.
",3.2 Beyond Newswire,[0],[0]
"Surprisingly, with only 50 annotated questions (see Table 4), performance on QBANKDEV jumps 5 points, from 89.9% to 94.9%.",3.2 Beyond Newswire,[0],[0]
"This is only
1.5% below training with all of WSJTRAIN and QBANKTRAIN.",3.2 Beyond Newswire,[0],[0]
"The resulting system improves slightly on WSJTEST getting 94.38%.
",3.2 Beyond Newswire,[0],[0]
"On the more difficult GENIA corpus of biomedical abstracts (Tateisi et al., 2005), we see a similar, if somewhat less dramatic, trend.",3.2 Beyond Newswire,[0],[0]
See Table 5.,3.2 Beyond Newswire,[0],[0]
"With 50 annotated sentences, performance on GENIADEV jumps from 79.5% to 86.2%, outperforming all but one parser from David McClosky’s thesis (McClosky, 2010) – the one that trains on all 14k sentences from GENIATRAIN and self-trains using 270k sentences from PubMed.",3.2 Beyond Newswire,[0],[0]
"That parser achieves 87.6%, which we outperform with just 500 sentences from GENIATRAIN.
",3.2 Beyond Newswire,[0],[0]
These results suggest that it is currently feasible to extend a parser to a syntactically distant domain (for which no gold parses exist) with a couple hours of effort.,3.2 Beyond Newswire,[0],[0]
We explore this possibility in the next section.,3.2 Beyond Newswire,[0],[0]
"To create a parser for their geometry question answering system, (Seo et al., 2015) did the following:
• Designed regular expressions to identify mathematical expressions.
",4 Rapid Parser Extension,[0],[0]
"• Replaced the identified expressions with dummy words.
",4 Rapid Parser Extension,[0],[0]
•,4 Rapid Parser Extension,[0],[0]
"Parsed the resulting sentences.
",4 Rapid Parser Extension,[0],[0]
"FRAG
.
.
",4 Rapid Parser Extension,[0],[0]
"NP
24 and QS = 10
SYM
=
NP
PR
,
,
NP
PQRS
PP
In the rhombus
(a) Training only on WSJTRAIN.
FRAG
.
.
",4 Rapid Parser Extension,[0],[0]
"NP
PR = 24 and QS = 10
,
,
PP
In the rhombus PQRS
(b) Retraining on partial annotations.
",4 Rapid Parser Extension,[0],[0]
It is clear why this was necessary.,4 Rapid Parser Extension,[0],[0]
Figure 3 (top) shows how RSP (trained only on WSJTRAIN),4 Rapid Parser Extension,[0],[0]
"parses the sentence “In the rhombus PQRS, PR = 24 and QS = 10.”",4 Rapid Parser Extension,[0],[0]
"The result is completely wrong, and useless to a downstream application.
",4 Rapid Parser Extension,[0],[0]
"Still, beyond just the inconvenience of building additional infrastructure, there are downsides to the “regex-and-replace” strategy:
1.",4 Rapid Parser Extension,[0],[0]
It assumes that each expression always maps to the same constituent label.,4 Rapid Parser Extension,[0],[0]
Consider “2x = 3y”.,4 Rapid Parser Extension,[0],[0]
"This is a verb phrase in the sentence “In the above figure, x is prime and 2x = 3y.”",4 Rapid Parser Extension,[0],[0]
"However, it is a noun phrase in the sentence “The equation 2x = 3y has 2 solutions.”",4 Rapid Parser Extension,[0],[0]
"If we replace both instances with the same dummy word, the parser will almost certainly become confused in one of the two instances.
2.",4 Rapid Parser Extension,[0],[0]
It assumes that each expression is always a constituent.,4 Rapid Parser Extension,[0],[0]
Suppose that we replace the expression “AB < 30” with a dummy word.,4 Rapid Parser Extension,[0],[0]
"This means we cannot properly parse a sentence like “When angle AB < 30, the lines are parallel,” because the constituent “angle AB” no longer exists in the resulting sentence.
3.",4 Rapid Parser Extension,[0],[0]
It does not handle other syntactic variation.,4 Rapid Parser Extension,[0],[0]
"As we will see in the next section, the
geometry domain has a propensity for using right-attaching participial adjective phrases, like “labeled x” in the phrase “the segment labeled x.” Encouraging a parser to recognize this syntactic construct is out-of-scope for the “regex-and-replace” strategy.
",4 Rapid Parser Extension,[0],[0]
"Instead, we propose directly extending the parser by providing a few domain-specific examples like those in Figure 1.",4 Rapid Parser Extension,[0],[0]
"Because RSP’s model directly predicts span constituency, we can simply mark up a sentence with the “tricky” domain-specific constituents that the model will not already have learned from WSJTRAIN.",4 Rapid Parser Extension,[0],[0]
"For instance, we mark up NOUN-LABEL constructs like “chord BD”, and equations like “AD = 4”.
",4 Rapid Parser Extension,[0],[0]
"From these marked-up sentences, we can extract training instances declaring the constituency of certain spans (like “to chord BD” in the third example) and the implied non-constituency of certain spans (like “perpendicular to chord” in the third example).",4 Rapid Parser Extension,[0],[0]
"We also allow annotators to explicitly declare the non-constituency of a span via an alternative markup (not shown).
",4 Rapid Parser Extension,[0],[0]
We do not require annotators to provide span labels (although they can if desired).,4 Rapid Parser Extension,[0],[0]
"If a training instance merely declares a span to be a constituent (but does not provide a particular label), then the loss function only records loss when that span is classified as a non-constituent (i.e. any label is ok).",4 Rapid Parser Extension,[0],[0]
"We took the publicly available training data from (Seo et al., 2015), split the data into sentences, and then annotated each sentence as in Figure 1.",5.1 Geometry Questions,[0],[0]
"Next, we randomly split these sentences into GEOTRAIN and GEODEV7.",5.1 Geometry Questions,[0],[0]
"After removing duplicate sentences spanning both sets, we ended up with 63 annotated sentences in GEOTRAIN and 62 in GEODEV.",5.1 Geometry Questions,[0],[0]
"In GEOTRAIN, we made an average of 2.8 constituent declarations and 0.3 (explicit) nonconstituent declarations per sentence.
",5.1 Geometry Questions,[0],[0]
"After preparing the data, we started with RSP trained on WSJTRAIN, and fine-tuned it on minibatches containing 50 randomly selected WSJTRAIN sentences, plus all of GEOTRAIN.",5.1 Geometry Questions,[0],[0]
The results are in table 6.,5.1 Geometry Questions,[0],[0]
"After fine-tuning, the model
7GEOTRAIN and GEODEV are available at https://github.com/vidurj/parser-adaptation/tree/master/data.
gets 87% of the 185 annotations on GEODEV correct, compared with 71.9% before fine-tuning8.",5.1 Geometry Questions,[0],[0]
"Moreover, the fraction of sentences with no errors increases from 45.2% to 72.6%.",5.1 Geometry Questions,[0],[0]
"With only a few dozen partially-annotated training examples, not only do we see a large increase in domain performance, but there is also no degradation in the parser’s performance on newswire.",5.1 Geometry Questions,[0],[0]
"Some GEODEV parses have enormous qualitative differences, like the example shown in Figure 3.
",5.1 Geometry Questions,[0],[0]
"For the GEODEV sentences on which we get errors after retraining, the errors fall predominantly into three categories.",5.1 Geometry Questions,[0],[0]
"First, approximately 44% have some mishandled math syntax, like failing to recognize “dimensions 16 by 8” as a constituent, or providing a flat structuring of the equation “BAC = 1/4 * ACB” (instead of recognizing “1/4 * ACB” as a subconstituent).",5.1 Geometry Questions,[0],[0]
"Second, approximately 19% have PP-attachment errors.",5.1 Geometry Questions,[0],[0]
"Third, another 19% fail to correctly analyze right-attaching participial adjectives like “labeled x” in the noun phrase “the segment labeled x” or
8This improvement has a p-value of 10−4 under the onesided, two-sample difference between proportions test.
“indicated” in the noun phrase “the center indicated.”",5.1 Geometry Questions,[0],[0]
This phenomenon is unusually frequent in geometry but was insufficiently marked-up in our training examples.,5.1 Geometry Questions,[0],[0]
"For instance, while we have a training instance “Find [ the measure of [ the angle designated by x ]",5.1 Geometry Questions,[0],[0]
"],” it does not explicitly highlight the constituency of “designated by x”.",5.1 Geometry Questions,[0],[0]
"This suggests that in practice, this domain adaptation method could benefit from an iterative cycle in which a user assesses the parser’s errors on their target domain, creates some partial annotations that address these issues, retrains the parser, and then repeats the process until satisfied.",5.1 Geometry Questions,[0],[0]
"As a proof-of-concept, we invented 3 additional sentences with right-attaching participial adjectives (shown in Figure 4), added them to GEOTRAIN, and then retrained.",5.1 Geometry Questions,[0],[0]
"Indeed, the handling of participial adjectives in GEODEV improved, increasing the overall percentage of correctly identified constituents to 88.6% and the percentage of errorfree sentences to 75.8%.",5.1 Geometry Questions,[0],[0]
"We ran a similar experiment using biomedical and chemistry text, taken from the unannotated data provided by (Nivre et al., 2007).",5.2 Biomedicine and Chemistry,[0],[0]
We partially annotated 134 sentences and randomly split them into BIOCHEMTRAIN (72 sentences) and BIOCHEMDEV (62 sentences)9.,5.2 Biomedicine and Chemistry,[0],[0]
"In BIOCHEMTRAIN, we made an average of 4.2 constituent declarations per sentence.",5.2 Biomedicine and Chemistry,[0],[0]
"We made no nonconstituent declarations.
",5.2 Biomedicine and Chemistry,[0],[0]
"Again, we started with RSP trained on WSJTRAIN, and fine-tuned it on minibatches containing annotations from 50 randomly selected WSJ-
9BIOCHEMTRAIN and BIOCHEMDEV are available at https://github.com/vidurj/parser-adaptation/tree/master/data.
TRAIN sentences, plus all of BIOCHEMTRAIN.",5.2 Biomedicine and Chemistry,[0],[0]
Table 7 shows the improvement in the percentage of correctly-identified annotated constituents and the percentage of test sentences for which the parse agrees with every annotation.,5.2 Biomedicine and Chemistry,[0],[0]
"As with the geometry domain, we get significant improvements using only dozens of partially annotated training sentences.",5.2 Biomedicine and Chemistry,[0],[0]
"The two major themes of this paper, domain adaptation and learning from partial annotation, each have a long tradition in natural language processing.",6 Related Work,[0],[0]
"Domain adaptation has been recognized as a major NLP problem for over a decade (Ben-David et al., 2006; Blitzer et al., 2006; Daumé, 2007; Finkel and Manning, 2009).",6.1 Domain Adaptation,[0],[0]
"In particular, domain adaptation for parsers (Plank, 2011; Ma and Xia, 2013) has received considerable attention.",6.1 Domain Adaptation,[0],[0]
"Much of this work (McClosky et al., 2006b; Reichart and Rappoport, 2007; Sagae and Tsujii, 2007; Kawahara and Uchimoto, 2008; McClosky et al., 2010; Sagae, 2010; Baucom et al., 2013; Yu et al., 2015) has focused on how to best use co-training (Blum and Mitchell, 1998) or self-training to augment a small domain corpus, or how to best combine models to perform well on a particular domain.
",6.1 Domain Adaptation,[0],[0]
"In this work, we focus on the direct impact that just a few dozen partially annotated out-of-domain examples can have, when using a particular neural model with contextualized word representations.",6.1 Domain Adaptation,[0],[0]
"Co-training, self-training, and model combination are orthogonal to our approach.",6.1 Domain Adaptation,[0],[0]
"Our work is a spiritual successor to (Garrette and Baldridge, 2013), which shows how to train a part-of-speech tagger with a minimal amount of annotation effort.",6.1 Domain Adaptation,[0],[0]
"Most literature on training parsers from partial annotations (Sassano and Kurohashi, 2010; Spreyer et al., 2010; Flannery et al., 2011; Flannery and Mori, 2015; Mielens et al., 2015) focuses on dependency parsing.",6.2 Learning from Partial Annotation,[0],[0]
"(Li et al., 2016) provides a good overview.",6.2 Learning from Partial Annotation,[0],[0]
"Here we highlight three important highlevel strategies.
",6.2 Learning from Partial Annotation,[0],[0]
"The first is “complete-then-train” (Mirroshandel and Nasr, 2011; Majidi and Crane, 2013), which “completes” every partially annotated de-
pendency parse by finding the most likely parse (according to an already trained parser model) that respects the constraints of the partial annotations.",6.2 Learning from Partial Annotation,[0],[0]
"These “completed” parses are then used to train a new parser.
",6.2 Learning from Partial Annotation,[0],[0]
"The second strategy (Nivre et al., 2014; Li et al., 2016) is similar to “complete-then-train,” but integrates parse completion into the training process.",6.2 Learning from Partial Annotation,[0],[0]
"At each iteration, new “complete” parses are created using the parser model from the most recent training iteration.
",6.2 Learning from Partial Annotation,[0],[0]
"The third strategy (Li et al., 2014, 2016) transforms each partial annotation into a forest of parses that encodes all fully-specified parses permitted by the partial annotation.",6.2 Learning from Partial Annotation,[0],[0]
"Then, the training objective is modified to support optimization over these forests.
",6.2 Learning from Partial Annotation,[0],[0]
Our work differs from these in two respects.,6.2 Learning from Partial Annotation,[0],[0]
"First, since we are training a constituency parser, our partial annotations are constituent bracketings rather than dependency arcs.",6.2 Learning from Partial Annotation,[0],[0]
"Second, and more importantly, we can use the partial annotations for training without modifying either the training algorithm or the training data.
",6.2 Learning from Partial Annotation,[0],[0]
"While the bulk of the literature on training from partial annotations focuses on dependency parsing, the earliest papers (Pereira and Schabes, 1992; Hwa, 1999) focus on constituency parsing.",6.2 Learning from Partial Annotation,[0],[0]
These leverage an adapted version of the inside-outside algorithm for estimating the parameters of a probabilistic context-free grammar (PCFG).,6.2 Learning from Partial Annotation,[0],[0]
"Our work is not tied to PCFG parsing, nor does it require a specialized training algorithm when going from full annotations to partial annotations.",6.2 Learning from Partial Annotation,[0],[0]
Recent developments in neural natural language processing have made it very easy to build custom parsers.,7 Conclusion,[0],[0]
"Not only do contextualized word representations help parsers learn the syntax of new domains with very few examples, but they also work extremely well with parsing models that correspond directly with a granular and intuitive annotation task (like identifying whether a span is a constituent).",7 Conclusion,[0],[0]
"This allows you to train with either full or partial annotations without any change to the training process.
",7 Conclusion,[0],[0]
"This work provides a convenient path forward for the researcher who requires a parser for their domain, but laments that “parsers don’t work outside of newswire.”",7 Conclusion,[0],[0]
"With a couple hours of effort
(and a layman’s understanding of syntactic building blocks), they can get significant performance improvements.",7 Conclusion,[0],[0]
"We envision an iterative use case in which a user assesses a parser’s errors on their target domain, creates some partial annotations to teach the parser how to fix these errors, then retrains the parser, repeating the process until they are satisfied.",7 Conclusion,[0],[0]
We revisit domain adaptation for parsers in the neural era.,abstractText,[0],[0]
First we show that recent advances in word representations greatly diminish the need for domain adaptation when the target domain is syntactically similar to the source domain.,abstractText,[0],[0]
"As evidence, we train a parser on the Wall Street Journal alone that achieves over 90% F1 on the Brown corpus.",abstractText,[0],[0]
"For more syntactically distant domains, we provide a simple way to adapt a parser using only dozens of partial annotations.",abstractText,[0],[0]
"For instance, we increase the percentage of error-free geometry-domain parses in a held-out set from 45% to 73% using approximately five dozen training examples.",abstractText,[0],[0]
"In the process, we demonstrate a new state-of-the-art single model result on the Wall Street Journal test set of 94.3%.",abstractText,[0],[0]
This is an absolute increase of 1.7% over the previous state-of-the-art of 92.6%.,abstractText,[0],[0]
Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 644–649 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
644",text,[0],[0]
"Automatically extracting common sense from text is a long-standing challenge in natural language processing (Schubert, 2002; Van Durme and Schubert, 2008; Vanderwende, 2005).",1 Introduction,[0],[0]
"As argued by Forbes and Yejin (2017), typical language use may reflect common sense, but the commonsense knowledge itself is not often explicitly stated, due to reporting bias (Gordon and Van Durme, 2013).",1 Introduction,[0],[0]
"Thus, additional human knowledge or annotated training data are often used to help systems learn common sense.
",1 Introduction,[0],[0]
"In this paper, we study methods for reducing the amount of human input needed to learn common sense.",1 Introduction,[0],[0]
"Specifically, we focus on learning relative comparisons of (one-dimensional) object properties, such as the fact that a cantaloupe is more round than a hammer.",1 Introduction,[0],[0]
"Methods for learning this kind of common sense have been developed previously (e.g. Forbes and Choi, 2017), but the best-performing methods in that previous work requires dozens of manually-annotated frames for each comparison property, to connect the property to how it is indirectly reflected in text—e.g., if
text asserts that “x carries y,” this implies that x is probably larger than y.
Our architecture for relative comparisons follows the zero-shot learning paradigm (Palatucci et al., 2009).",1 Introduction,[0],[0]
"It takes the form of a neural network that compares a projection of embeddings for each of two objects (e.g. “elephant” and “tiger”) to the embeddings for the two poles of the target dimension of comparison (e.g., “big” and ”small” for the size property).",1 Introduction,[0],[0]
"The projected object embeddings are trained to be closer to the appropriate pole, using a small training set of hand-labeled comparisons.",1 Introduction,[0],[0]
"Our experiments reveal that our architecture outperforms previous work, despite using less annotated data.",1 Introduction,[0],[0]
"Further, because our architecture takes the property (pole) labels as arguments, it can extend to the zero-shot setting in which we evaluate on properties not seen in training.",1 Introduction,[0],[0]
"We find that in zero-shot, our approach outperforms baselines and comes close to supervised results, but providing labels for both poles of the relation rather than just one is important.",1 Introduction,[0],[0]
"Finally, because the number of properties we wish to learn is large, we experiment with active learning (AL) over a larger property space.",1 Introduction,[0],[0]
"We show that synthesizing AL queries can be effective using an approach that explicitly models which comparison questions are nonsensical (e.g., is Batman taller than Democracy?).",1 Introduction,[0],[0]
We release our code base and a new commonsense data set to the research community.1,1 Introduction,[0],[0]
"We define the task of comparing object properties in two different ways: a three-way classification task, and a four-way classification task.",2 Problem Definition and Methods,[0],[0]
"In the three-way classification task, we want to estimate the following conditional probability:
P (L|O1,O2,Property),L ∈ { < , > , ≈ }.",2 Problem Definition and Methods,[0],[0]
"1https://github.com/yangyiben/PCE
For example, Prob(An elephant is larger than a dog) can be expressed as P (L = > |O1 = ”elephant”,O2 = ”dog”,Property = ”size”).",2 Problem Definition and Methods,[0],[0]
"The three-way classification task has been explored in previous work (Forbes and Choi, 2017) and is only performed on triples where both objects have the property, so that the comparison is meaningful.",2 Problem Definition and Methods,[0],[0]
"In applications, however, we may not know in advance which comparisons are meaningful.",2 Problem Definition and Methods,[0],[0]
"Thus, we also define a four-way classification task to include ”not applicable” as the fourth label, so that inference can be performed on any objectproperty triples.",2 Problem Definition and Methods,[0],[0]
"In the four-way task, the system is tasked with identifying the nonsensical comparisons.",2 Problem Definition and Methods,[0],[0]
"Formally, we want to estimate the following conditional probability:",2 Problem Definition and Methods,[0],[0]
"For each comparison property, we pick an adjective and its antonym to represent the { < , > } labels.",2.1 Three-way Model,[0],[0]
"For example, for the property size, we pick ”big” and ”small”.",2.1 Three-way Model,[0],[0]
The adjective ”similar” serves as the label for ≈ for all properties.,2.1 Three-way Model,[0],[0]
"Under this framework, a relative comparison question, for instance, ”Is a dog bigger than an elephant?”, can be formulated as a quintuple query to the model, namely {dog, elephant, small, similar, big}.",2.1 Three-way Model,[0],[0]
"Denoting the word embeddings for tokens in a quintuple query as X , Y , R<, R≈, R>, our three-way model is defined as follows:
P (L = s|Q) = softmax(Rs · σ((X ⊕ Y )W )),
for s ∈ {<, >, ≈}, where Q is an quintuple query, σ(·) is an activation function and W is a learnable weight matrix.",2.1 Three-way Model,[0],[0]
The symbol ⊕ represents concatenation.,2.1 Three-way Model,[0],[0]
We refer to this method as PCE (Property Comparison from Embeddings) for the 3-way task.,2.1 Three-way Model,[0],[0]
"We also experiment with generating label representations from just a single adjective (property) embedding R<, namely R≈ = σ(R<W2), R> = σ(R<W3).",2.1 Three-way Model,[0],[0]
"We refer to this simpler method as PCE(one-pole).
",2.1 Three-way Model,[0],[0]
"We note that in both the three- and four-way settings, the question ”A>B?” is equivalent to ”B<A?”.",2.1 Three-way Model,[0],[0]
"We leverage this fact at test time by feeding our network a reversed object pair, and taking the average of the aligned network outputs before the softmax layer to reduce prediction variance.",2.1 Three-way Model,[0],[0]
"We refer to our model without this technique as PCE(no reverse).
",2.1 Three-way Model,[0],[0]
The key distinction of our method is that it learns a projection from the object word embedding space to the label embedding space.,2.1 Three-way Model,[0],[0]
This allows the model to leverage the property label embeddings to perform zero-shot prediction on properties not observed in training.,2.1 Three-way Model,[0],[0]
"For example, from a training example ”dogs are smaller than elephants”, the model will learn a projection that puts ”dogs” relatively closer to ”small,” and far from ”big” and ”similar.”",2.1 Three-way Model,[0],[0]
"Doing so may also result in projecting ”dog” to be closer to ”light” than to ”heavy,” such that the model is able to predict ”dogs are lighter than elephants” despite never being trained on any weight comparison examples.",2.1 Three-way Model,[0],[0]
"Our four-way model is the same as our three-way model, with an additional module to learn whether the comparison is applicable.",2.2 Four-way Model,[0],[0]
"Keeping the other output nodes unchanged, we add an additional component into the softmax layer to output the probability of ”N/A”:
hx = σ(XWa), hy = σ(YWa), Ai = hi ·R> + hi ·R<, P (L = N/A |Q) ∝",2.2 Four-way Model,[0],[0]
exp(Ax +Ay).,2.2 Four-way Model,[0],[0]
"We propose a method to synthesize informative queries to pose to annotators, a form of active learning (Settles, 2009).",2.3 Synthesis for Active Learning,[0],[0]
We use the common heuristic that an informative training example will have a high uncertainty in the model’s predictive distribution.,2.3 Synthesis for Active Learning,[0],[0]
"We adopt the confidence measure (Culotta and McCallum, 2005) to access the uncertainty of a given example:
Uncertainty(x) = 1−max y P (y|x,Dtrain).
",2.3 Synthesis for Active Learning,[0],[0]
"Good candidates for acquisition should have high uncertainty measure, but we also want to avoid querying outliers.",2.3 Synthesis for Active Learning,[0],[0]
"As the vocabulary is finite, it is possible to evaluate the uncertainty measures for all possible inputs to synthesize the most uncertain query.",2.3 Synthesis for Active Learning,[0],[0]
"However, such a greedy policy is expensive and prone to selecting outliers.",2.3 Synthesis for Active Learning,[0],[0]
"Hence, we adopt a sampling based synthesis strategy: at each round, we generate one random object pair per property, and query the one that achieves the highest uncertainty measure.
",2.3 Synthesis for Active Learning,[0],[0]
"A classical difficulty faced by synthesis approaches to active learning is that they may pro-
duce unnatural queries that are difficult for a human to label (Baum and Lang, 1992).",2.3 Synthesis for Active Learning,[0],[0]
"However, our task formulation includes ”similar” and ”N/A” classes that encompass many of the more difficult or confusing comparisons, which we believe aids the effectiveness of the synthesis approach.",2.3 Synthesis for Active Learning,[0],[0]
We now present our experimental results on both the three-way and four-way tasks.,3 Experiments,[0],[0]
"We test our three-way model on the VERB PHYSICS data set from (Forbes and Choi, 2017).",3.1 Data Sets,[0],[0]
"As there are only 5 properties in VERB PHYSICS, we also develop a new data set we call PROPERTY COMMON SENSE.",3.1 Data Sets,[0],[0]
"We select 32 commonsense properties to form our property set (e.g., value, roundness, deliciousness, intelligence, etc.).",3.1 Data Sets,[0],[0]
"We extract object nouns from the McRae Feature Norms dataset (McRae et al., 2005) and add selected named entities to form a object vocabulary of 689 distinct objects.",3.1 Data Sets,[0],[0]
"We randomly generate 3148 object-property triples, label them and reserve 45% of the data for the test set.",3.1 Data Sets,[0],[0]
"We further add 5 manually-selected applicable comparison examples per property to our test set, in order to make sure each property has some applicable testing examples.",3.1 Data Sets,[0],[0]
"To verify the labeling, we have a second annotator redundantly label 200 examples and find a Cohen’s Kappa of 0.64, which indicates good annotator agreement (we analyze the source of the disagreements in Section 4.1).",3.1 Data Sets,[0],[0]
"The training set is used for the passive learning and pool-based active learning, and a human oracle provides labels in the synthesis active learning setting.",3.1 Data Sets,[0],[0]
"We experiment with three types of embeddings: GloVe, normalized 300-dimensional embeddings trained on a corpus of 6B tokens (Pennington et al., 2014) (the F&C method (Forbes and Choi, 2017) uses the 100-dimensional version, as it achieves the highest validation accuracy for their methods); Word2vec, normalized 300- dimensional embeddings trained on 100B tokens (Mikolov et al., 2013); and LSTM, the normalized 1024-dimensional weight matrix from the softmax layer of the Google 1B LSTM language model (Jozefowicz et al., 2016).
",3.2 Experimental Setup,[0],[0]
"For training PCE, we use an identity activation function and apply 50% dropout.",3.2 Experimental Setup,[0],[0]
"We use the Adam optimizer with default settings to train the models for 800 epochs, minimizing cross entropy loss.",3.2 Experimental Setup,[0],[0]
"For zero-shot learning, we adopt a hold-oneproperty-out scheme to test our models’ zero-shot performance.
",3.2 Experimental Setup,[0],[0]
"Finally, for active learning, we use Word2vec embeddings.",3.2 Experimental Setup,[0],[0]
All the models are trained on 200 random training examples to warm up.,3.2 Experimental Setup,[0],[0]
We train for 20 epochs after each label acquisition.,3.2 Experimental Setup,[0],[0]
"To smooth noise, we report the average of 20 different runs of random (passive learning) and least confident (LC) pool-based active learning (Culotta and McCallum, 2005) baselines.",3.2 Experimental Setup,[0],[0]
"We report the average of only 6 runs for an expected model change (EMC) pool-based active learning (Cai et al., 2013) baseline due to its high computational cost, and of only 2 runs for our synthesis active learning approach due to its high labeling cost.",3.2 Experimental Setup,[0],[0]
The pool size is 1540 examples.,3.2 Experimental Setup,[0],[0]
"In Table 1, we compare the performance of the three-way PCE model against the existing state of the art on the VERB PHYSICS data set.",3.3 Results,[0],[0]
The use of LSTM embeddings in PCE yields the best accuracy for all properties.,3.3 Results,[0],[0]
"Across all embedding choices, PCE performs as well or better than F&C, despite the fact that PCE does not use the annotated frames that F&C requires (approximately 188 labels per property).",3.3 Results,[0],[0]
"Thus, our approach matches or exceeds the performance of previous work using significantly less annotated knowledge.",3.3 Results,[0],[0]
"The lower performance of ”no reverse” shows that the simple method of averaging over the reversed object pair is effective.
",3.3 Results,[0],[0]
Table 2 evaluates our models on properties not seen in training (zero-shot learning).,3.3 Results,[0],[0]
"We compare against a random baseline, and an Emb-Similarity baseline that classifies based on the cosine similarity of the object embeddings to the pole label embeddings (i.e., without the projection layer in PCE).",3.3 Results,[0],[0]
PCE outperforms the baselines.,3.3 Results,[0],[0]
"Although the one-pole method was shown to perform similarly to the two-pole method for properties seen in training (Table 1), we see that for zero-shot learning, using two poles is important.
",3.3 Results,[0],[0]
"In Table 3, we show that our four-way models with different embeddings beat both the majority and random baselines on the PROPERTY
COMMON SENSE data.",3.3 Results,[0],[0]
"Here, the LSTM embeddings perform similarly to the Word2vec embeddings, perhaps because the PROPERTY COMMON SENSE vocabulary consists of less frequent nouns than in VERB PHYSICS.",3.3 Results,[0],[0]
"Thus, the Word2vec embeddings are able to catch up due to their larger vocabulary and much larger training corpus.
",3.3 Results,[0],[0]
"Finally, in Figure 1, we evaluate in the active learning setting.",3.3 Results,[0],[0]
"The synthesis approach performs best, especially later in training when the training pool for the pool-based methods has only uninformative examples remaining.",3.3 Results,[0],[0]
Figure 2 helps explain the relative advantage of the synthesis approach: it is able to continue synthesizing informative (uncertain) queries throughout the entire training run.,3.3 Results,[0],[0]
"As noted above, we found a “good” level of agreement (Cohen’s Kappa of 0.64) for our PROPERTY COMMON SENSE data, which is lower than one might expect for task aimed at common sense.",4.1 Sources of annotator disagreement,[0],[0]
"We
analyzed the disagreements and found that they stem from two sources of subjectivity in the task.",4.1 Sources of annotator disagreement,[0],[0]
"The first is that different labelers may have different thresholds for what counts as similar—a spider and an ant might be marked similar in size for one labeler, but not for another labeler.",4.1 Sources of annotator disagreement,[0],[0]
"In our data, 58% of the disagreements are cases in which one annotator marks similar while the other says not similar.",4.1 Sources of annotator disagreement,[0],[0]
The second is that different labelers have different standards for whether a comparison is N/A.,4.1 Sources of annotator disagreement,[0],[0]
"For example, in our data set, one labeler labels that a toaster is physically stronger than alcohol, and the other labeler says the comparison is N/A. 37% of our disagreements are due to this type of subjectivity.",4.1 Sources of annotator disagreement,[0],[0]
"The above two types of subjectivity account for almost all disagreements
(95%), and the remaining 5% are due to annotation errors (one of the annotators makes mistake).",4.1 Sources of annotator disagreement,[0],[0]
"Since we adopt an identity activation function and a single layer design, it is possible to simplify the mathematical expression of our model to make it more interpretable.",4.2 Model Interpretation,[0],[0]
"After accounting for model averaging, we have the following equality:
P (L =< |Q) ∝",4.2 Model Interpretation,[0],[0]
exp(R< · ((X ⊕ Y )W ),4.2 Model Interpretation,[0],[0]
+,4.2 Model Interpretation,[0],[0]
"R> · ((Y ⊕X)W ))
",4.2 Model Interpretation,[0],[0]
= exp(RT<(XW1 + YW2) +R T,4.2 Model Interpretation,[0],[0]
>,4.2 Model Interpretation,[0],[0]
(YW1 +XW2)),4.2 Model Interpretation,[0],[0]
∝ exp((R,4.2 Model Interpretation,[0],[0]
< −R>)T,4.2 Model Interpretation,[0],[0]
"(XW1 +XW2)),
where W = W1 ⊕W2.",4.2 Model Interpretation,[0],[0]
"So we can define a score of ”R<” for a object with embedding X as the following:
score(X,R<) =",4.2 Model Interpretation,[0],[0]
"(R< −R>)T (XW1 +XW2).
",4.2 Model Interpretation,[0],[0]
An object with a higher score for R< is more associated with the R< pole than the R> one.,4.2 Model Interpretation,[0],[0]
"For example, score(”elephant”,”small”) represents how small an elephant is—a larger score indicates a smaller object.",4.2 Model Interpretation,[0],[0]
Table 4 shows smallness scores for 5 randomly picked objects from the VERB PHYSICS data set.,4.2 Model Interpretation,[0],[0]
PCE tends to assign higher scores to the smaller objects in the set.,4.2 Model Interpretation,[0],[0]
PCE requires labels for the poles of the target object property.,4.3 Sensitivity to pole labels,[0],[0]
"Table 5 presents a limited sensitivity
analysis to pole labels, evaluating the test accuracy of PCE as the pole label varies among different combinations of synonyms for the size and speed relations.",4.3 Sensitivity to pole labels,[0],[0]
We evaluate in both the trained setting (comparable to the results in Table 1) and the zero-shot setting (comparable to Table 2).,4.3 Sensitivity to pole labels,[0],[0]
We see that the trained accuracy remains essentially unchanged for different pole labels.,4.3 Sensitivity to pole labels,[0],[0]
"In the zeroshot setting, all combinations achieve accuracy that beats the baselines in Table 2, but the accuracy value is somewhat sensitive to the choice of pole label.",4.3 Sensitivity to pole labels,[0],[0]
Exploring how to select pole labels and experimenting with richer pole representations such as textual definitions are items of future work.,4.3 Sensitivity to pole labels,[0],[0]
"In this paper, we presented a method for extracting commonsense knowledge from embeddings.",5 Conclusion,[0],[0]
Our experiments demonstrate that the approach is effective at performing relative comparisons of object properties using less hand-annotated knowledge than in previous work.,5 Conclusion,[0],[0]
"A synthesis active learner was found to boost accuracy, and further experiments with this approach are an item of future work.",5 Conclusion,[0],[0]
This work was supported in part by NSF Grant IIS-1351029.,Acknowledgments,[0],[0]
We thank the anonymous reviewers for helpful comments.,Acknowledgments,[0],[0]
"Intelligent systems require common sense, but automatically extracting this knowledge from text can be difficult.",abstractText,[0],[0]
"We propose and assess methods for extracting one type of commonsense knowledge, object-property comparisons, from pretrained embeddings.",abstractText,[0],[0]
"In experiments, we show that our approach exceeds the accuracy of previous work but requires substantially less hand-annotated knowledge.",abstractText,[0],[0]
"Further, we show that an active learning approach that synthesizes common-sense queries can boost accuracy.",abstractText,[0],[0]
Extracting Commonsense Properties from Embeddings with Limited Human Guidance,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 622–631, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
"Reflecting the rapid growth in the use of opinionated texts on the Web, such as comments on news articles and customer reviews, opinion mining has been explored to facilitate utilizing opinions mainly for improving products and decisionmaking purposes.",1 Introduction,[0],[0]
"While in a broad sense opinion mining refers to a process to discover useful knowledge latent in a corpus of opinionated texts, fundamental issues involve modeling an unit of opinions and searching the corpus for those units, each of which typically comprises the evaluation by an author for a target object from an aspect.",1 Introduction,[0],[0]
"Other elements, such as when the opinion was submitted, can optionally be included in an opinion unit.",1 Introduction,[0],[0]
"We take the following review sentence as an example opinionated description.
",1 Introduction,[0],[0]
"(1) I think hotel A offers a reasonable price if you take a family trip with small kids.
",1 Introduction,[0],[0]
"From the above example, existing methods (Pang and Lee, 2008; Seki et al., 2009; Jin et al., 2009; Zhao et al., 2010; He et al., 2011; Liu and Zhang, 2012; Liu et al., 2013; Yang and Cardie, 2013; Liu et al., 2014) are intended to extract the following quintuple as an opinion unit.
",1 Introduction,[0],[0]
"Target = “hotel A”, Aspect = “price”, Evaluation (Polarity) = “reasonable” (positive), Holder = “I (author)”, Time = N/A
Depending on the application, “Evaluation” can be any of a literal opinion word (e.g., “reasonable”), a polarity (positive/negative), or a value for multipoint scale rating.
",1 Introduction,[0],[0]
"Given those standardized units extracted from a corpus, it is feasible to overview the distribution of values for each element or a combination of elements.",1 Introduction,[0],[0]
"For example, those who intend to improve the quality of hotel A may investigate representative values for “Aspect” in the units satisfying “Target=hotel A & Polarity=negative”, while those who look for accommodation may collect the opinion units for one or more candidate hotels and investigate the distribution of values for “Polarity” on an aspect-by-aspect basis.
",1 Introduction,[0],[0]
"However, in the above example (1), the evaluation for hotel A (“a reasonable price”) is valid for “if you take a family trip with small kids”, and thus it is not clear whether this evaluation is valid irrespective of the condition.",1 Introduction,[0],[0]
"For example, the price may not be reasonable for a single customer intending for business purposes.",1 Introduction,[0],[0]
"In this paper, we shall call such a condition “condition for opinion (CFO)”.",1 Introduction,[0],[0]
"We define CFO as a condition for which an opinion unit has a polarity.
",1 Introduction,[0],[0]
"The existing methods for opinion mining, which do not consider whether a target opinion is conditional, potentially overestimate or underestimate
622
the utility of hotel A and consequently decrease the quality of opinion mining.",1 Introduction,[0],[0]
"We manually analyzed the first 7 000 sentences in the Rakuten Travel data, which consists of 348 564 Japanese reviews for hotels in Japan (see Section 4 for details of this data) and found that 2 272 sentences are opinions, of which 630 opinions are conditional and thus the result for an existing method includes up to 28% (630/2272) errors.
",1 Introduction,[0],[0]
"Motivated by the above discussion, in this paper we propose a method to extract pairs of a CFO and its corresponding opinion unit from online reviews.",1 Introduction,[0],[0]
This method provides two solutions to the above problem.,1 Introduction,[0],[0]
"First, a passive solution is detecting whether an opinion includes a CFO and, if any, isolating that opinion from the target of opinion mining.",1 Introduction,[0],[0]
"As a result, we can avoid potential errors as much as possible but the coverage is decreased.
",1 Introduction,[0],[0]
"Second, an active solution is identifying the span of each CFO in conditional opinions and classify them according to semantic categories, such as purpose, situation, and user attribute so that finer-grained opinion mining can be realized.",1 Introduction,[0],[0]
"For example, the distribution of positive and negative opinions can be available on a category-bycategory basis.",1 Introduction,[0],[0]
"However, in this paper we focus only on the identification for CFOs and leave the semantic classification future work.
",1 Introduction,[0],[0]
"To produce a practical model for CFOs, it is important to investigate them from a grammar point of view.",1 Introduction,[0],[0]
It can easily be predicted that a typical grammatical unit for CFOs is a conditional clause as in example (1).,1 Introduction,[0],[0]
"Additionally, restrictive modifiers in general can potentially be CFOs because they restrict the validity of an opinion unit from a specific perspective.",1 Introduction,[0],[0]
"A restrictive modifier comprises a word, phrase, or clause.",1 Introduction,[0],[0]
"The CFO in example (1), which is a dependent clause functioning as a condition, is also a restrictive modifier.
",1 Introduction,[0],[0]
"Example (2), which has the same meaning as example (1), includes a CFO as a prepositional phrase.
",1 Introduction,[0],[0]
"(2) Hotel A offers a reasonable price for taking a family trip with small kids.
",1 Introduction,[0],[0]
"We denote CFOs and opinion words in bold and italic faces, respectively.",1 Introduction,[0],[0]
Examples (3) and (4) also include a CFO as a prepositional phrase.,1 Introduction,[0],[0]
"Unlike example (2), the validity of “reasonable” is restricted from time and comparison points of view, respectively.
(3) Hotel A offers a reasonable price during this holiday season.
",1 Introduction,[0],[0]
"(4) Hotel A offers a reasonable price for a four star hotel.
",1 Introduction,[0],[0]
"In example (5), which has a similar meaning to example (1), the CFO is a dependent clause functioning as a reason.
",1 Introduction,[0],[0]
"(5) Hotel A offers a reasonable price because we take a family trip with small kids.
",1 Introduction,[0],[0]
"Finally, as in example (6), an opinion holder can also be a CFO because the evaluation is restricted from a perspective of that specific person.
",1 Introduction,[0],[0]
"(6) My mother regarded hotel A as a reasonable choice.
",1 Introduction,[0],[0]
"If the restriction by a CFO is associated with a user-related perspective, we call such CFOs “userrestrictive CFOs (U-CFOs)”.",1 Introduction,[0],[0]
"In other words, target users to whom an opinion unit is relevant are restricted by its corresponding U-CFO, although those users may agree or disagree with the opinion.",1 Introduction,[0],[0]
"The CFOs in examples (1), (2), and (5) are U-CFOs because the target users are mainly those who intend to travel with their children.
",1 Introduction,[0],[0]
The CFO in example (3) is also U-CFO because the target users are those who intend to travel during a specific holiday season.,1 Introduction,[0],[0]
The CFO in example (6) is also U-CFO because the opinion holder (“my mother”) implies the opinion is relevant mainly to adult females.,1 Introduction,[0],[0]
"However, opinion holders who do not represent user-related perspectives, such as “I” without any profile, are not U-CFOs.
",1 Introduction,[0],[0]
The CFO in example (4) is not a U-CFO because the relevance of the opinion is not restricted to specific customers.,1 Introduction,[0],[0]
It may be argued that in example (4) the target users are restricted to those who are interested in the price.,1 Introduction,[0],[0]
"However, in example (4) the price restricts the aspect of the opinion unit, and should not be confused with U-CFOs and even CFOs, which restrict the validity of the opinion unit.
",1 Introduction,[0],[0]
"If we fully utilize U-CFOs, as discussed for the active solution above, we need to classify U-CFOs into semantic categories so that users can selectively read relevant opinions.",1 Introduction,[0],[0]
"In other words, the identification for U-CFOs facilitates predicting the review helpfulness (O’Mahony and Smyth, 2010; Moghaddam et al., 2012).",1 Introduction,[0],[0]
"Candidate categories
include demographic and psychographic attributes for target users (e.g., age and hobby) and situations of target users (e.g., purpose, time, and place).",1 Introduction,[0],[0]
"However, we leave the classification for U-CFOs future work.",1 Introduction,[0],[0]
"As described in Section 1, the fundamental methods for opinion mining include opinion extraction, which identifies elements for opinion units (i.e., target, aspect, evaluation, holder, and time)",2 Related work,[0],[0]
"(He et al., 2011; Jin et al., 2009; Liu et al., 2013; Seki et al., 2009; Yang and Cardie, 2013; Zhao et al., 2010), and opinion classification, which determines the non-literal evaluation of each opinion unit based on bipolar categories (i.e., positive and negative) (He et al., 2011; Meng et al., 2012) or multipoint scale categories (Fu and Wang, 2010; Moghaddam and Ester, 2013).",2 Related work,[0],[0]
"However, none of these methods intends to determine whether or not an opinion is conditional and to extract their condition.
",2 Related work,[0],[0]
Narayanan et al. (2009) proposed a method for sentiment classification targeting conditional sentences.,2 Related work,[0],[0]
"Although a conditional opinion is a kind of conditional sentence, their research is fundamentally different from our research.",2 Related work,[0],[0]
"Narayanan et al. (2009) targeted such a conditional sentence that comprises a single opinion as a whole, and intended to categorize its polarity into any of positive, negative, or neutral.",2 Related work,[0],[0]
"Examples (7) and (8) are such conditional sentences associated with neutral and positive categories, respectively.
(7) Hotel A would not have survived if the price was not reasonable.
",2 Related work,[0],[0]
"(8) If you are looking for a hotel with a reasonable price, stay at hotel A.
",2 Related work,[0],[0]
"In example (7), although the subordinate clause includes the opinion word “reasonable”, none of the subordinate clause, main clause, or entire sentence is an opinion.",2 Related work,[0],[0]
"In example (8), the entire sentence is an unconditional opinion about the price for hotel A, but the main and subordinate clauses are not opinions independently.",2 Related work,[0],[0]
"In contrast, the purpose of our research is to identify conditional opinions, in which the main and subordinate clauses are an opinion and its condition, respectively.
",2 Related work,[0],[0]
"Kim and Hovy (2006) proposed a method to identify a reason for the evaluation in an opinion,
such as “the service was terrible because the staff was rude”.",2 Related work,[0],[0]
"Although as discussed in Section 1 reasons can be CFOs, their purpose is to identify grounds that justify the evaluation and thus is different from our purpose.
",2 Related work,[0],[0]
"As discussed in Section 1, our research is related to predicting the review helpfulness (O’Mahony and Smyth, 2010; Moghaddam et al., 2012).",2 Related work,[0],[0]
"The method proposed by O’Mahony and Smyth (2010) determines the helpfulness of a product review independent of the user profile and thus cannot recommend reviews based on userrelated attributes.
",2 Related work,[0],[0]
Moghaddam et al. (2012) used collaborative filtering to predict the review helpfulness.,2 Related work,[0],[0]
"The evaluation by a target user for past reviews is used to model the user and predict the helpfulness for unread reviews, which results in different predictions depending on the user.",2 Related work,[0],[0]
"An advantage of collaborative filtering is its applicability to items whose content is usually difficult to analyze, such as videos.",2 Related work,[0],[0]
"However, this advantage is diluted in recommending review text, from which effective features for user modeling, such as U-CFOs, can be obtained by opinion mining.",2 Related work,[0],[0]
The task in this paper is to extract conditionopinion relations from reviews in Japanese.,3 Proposed method,[0],[0]
"Currently, we assume that an opinion unit and its corresponding CFO are in the same sentence, and thus perform the extraction on a sentence-by-sentence basis.",3 Proposed method,[0],[0]
"Given a sentence in reviews, we first search for an opinion unit, and if found, we also search for its corresponding CFO.",3 Proposed method,[0],[0]
"Because in the first process we rely on an existing method for the opinion extraction, in this paper we focus only on the extraction for CFOs.
",3 Proposed method,[0],[0]
"As discussed in Section 1, because CFOs can be different grammatical units, their length and structure are not standardized.",3 Proposed method,[0],[0]
"We model the extraction for CFOs as the BIO chunking, which labels each token in a sentence as being the beginning (B), inside (I), or outside (O) of a span of interest.",3 Proposed method,[0],[0]
We use “Other” to refer to “O” to avoid confusion between “O” and “0” (zero).,3 Proposed method,[0],[0]
"To subdivide “B” and “I” into U-CFOs and other CFOs, we use suffixes “U” and “C”, respectively, such as “BU” denoting the beginning of a U-CFO.",3 Proposed method,[0],[0]
"We use “Cond” to refer to any of BU, IU, BC, or IC.
Because we use the same method for both U-
CFOs and other CFOs, the above distinction only increases the number of categories to which each token is classified.",3 Proposed method,[0],[0]
"If the distinction of U-CFOs is not important, the above suffixes can be omitted.
",3 Proposed method,[0],[0]
"We regard Japanese bunsetsu phrases, which consist of a content word and one or more postpositional particles, as tokens, and extract a sequence of a BU-phrase and one or more IU-phrases, or an independent BU-phrase as a condition.",3 Proposed method,[0],[0]
The same method is used for BC/IC-phrases.,3 Proposed method,[0],[0]
"However, words and phrases in an opinion unit are classified into its corresponding element.",3 Proposed method,[0],[0]
"For example, an aspect phrase is classified into the aspect category.
",3 Proposed method,[0],[0]
"Given an input sequence of bunsetsu phrases, x = x1 . . .",3 Proposed method,[0],[0]
"xn, our task is to predict a sequence of labels, y = y1 . . .",3 Proposed method,[0],[0]
"yn, where yi ∈ {BU, IU,BC, IC, Other, Target, Aspect, OpinionWord}.",3 Proposed method,[0],[0]
"However, because an opinion unit in an input sentence has been identified in advance, the task is a quinary classification with respect to yi ∈ {BU, IU,BC, IC,Other}.",3 Proposed method,[0],[0]
"We use Conditional Random Fields (CRF) (Lafferty et al., 2001) to train a classifier for categorizing each bunsetsu phrase into any of the aforementioned five categories.",3 Proposed method,[0],[0]
"We use a combination of unigram and bigram models and calculate the conditional probability, p(y|x), for linear-chain CRF by Equation (1).
p(y|x)",3 Proposed method,[0],[0]
= 1,3 Proposed method,[0],[0]
"Zx
exp (∑
i,k λk ·fk(yi, x)+ ∑ i,k µk ·gk(yi−1, yi, x) )",3 Proposed method,[0],[0]
"(1)
Here, Zx denotes a normalization factor, and fk and gk denote feature functions for unigram and bigram models, respectively.",3 Proposed method,[0],[0]
"Let xi,v denote a feature value for xi.",3 Proposed method,[0],[0]
"While in the unigram model yi depends on either xi−1,v or xi,v, in the bigram model yi depends on either a combination of xi,v and yi−1 or that of xi−1,v and yi−1.",3 Proposed method,[0],[0]
"Feature functions are produced for any possible combinations of the values for the variables used (xi,v, yi−1, and yi in fk), and take 1 if the corresponding combination appears and 0 otherwise.",3 Proposed method,[0],[0]
"We use the four combinations “unigram xi,v”, “unigram xi−1,v”, “bigram yi−1 xi,v”, and “bigram yi−1 xi−1,v” for feature functions.
",3 Proposed method,[0],[0]
The question here is how CFOs and U-CFOs can be modeled and what kind of features are needed.,3 Proposed method,[0],[0]
"We assume characteristics of CFOs, and U-CFOs and partially exemplify their validity us-
ing Figure 1, which depicts an example input sentence and information related to its constituent bunsetsu phrases.",3 Proposed method,[0],[0]
"In the upper part of Figure 1, a rectangle and an arrow denote a bunsetstu phrase and a syntactic dependency between two phrases, respectively, and in each phrase we show Japanese words based on the Hepburn system and their English translations in parentheses.
CFOs are associated with the following characteristics.
",3 Proposed method,[0],[0]
"(a) By definition, CFOs determine the validity of the evaluation in an opinion unit, and thus syntactically modify an opinion word.",3 Proposed method,[0],[0]
"Consequently, CFOs usually do not modify other elements in an opinion unit, such as an aspect.
",3 Proposed method,[0],[0]
"(b) Like a conjunction in a conditional clause in English, such as “if”, a CFO in Japanese also includes a clue expression, which is usually a functional expression (Matsuyoshi et al., 2006) in the tail phrase, such as “ni wa (“for” in English)”.
",3 Proposed method,[0],[0]
(c),3 Proposed method,[0],[0]
"The distribution for parts of speech as the head of CFOs is skewed and heads of CFOs are usually a noun or verb.
",3 Proposed method,[0],[0]
"Additionally, U-CFOs are associated with the following characteristics.
",3 Proposed method,[0],[0]
(d),3 Proposed method,[0],[0]
"If a CFO is an opinion holder as in example (6) in Section 1, it is usually a U-CFO, which is the subject appearing at the beginning of a target sentence.
",3 Proposed method,[0],[0]
"(e) By definition, U-CFOs include expressions related to user attributes, such as “nervosity” in Figure 1.
",3 Proposed method,[0],[0]
"In this paper, we propose thirteen features to model CFOs and U-CFOs.",3 Proposed method,[0],[0]
"In the bottom part of Figure 1, for each phrase we show the values of the thirteen features F1–F13 described below.",3 Proposed method,[0],[0]
These features were developed for the above five characteristics.,3 Proposed method,[0],[0]
"F1–F5, F7–F10 and F13 are associated with (a), (b) and (c), respectively, while F6 and F11–F12 are associated with (d) and (e).
",3 Proposed method,[0],[0]
"F1: Dependency distance to opinion word CFOs, which affect the evaluation in that opinion, usually syntactically modifies the opinion word.",3 Proposed method,[0],[0]
"Thus, there should be a pass of dependencies between a Cond-phrase and the opinion word, and a
phrase that leads to the opinion word via a smaller number of dependency arrows is more likely to be a Cond-phrase.",3 Proposed method,[0],[0]
"We use the dependency distance (i.e., the number of dependencies) between a phrase in question and the opinion word as the value for feature F1.",3 Proposed method,[0],[0]
The value for a phrase is −1 if there is no pass between that phrase and the opinion word.,3 Proposed method,[0],[0]
"We use “CaboCha” (Kudo and Matsumoto, 2002) for dependency analysis purposes.
F2: Phrase distance to opinion word F1 is not robust against errors of the dependency analysis.",3 Proposed method,[0],[0]
"To alleviate this problem, we approximate the dependency distance by a phrase distance.",3 Proposed method,[0],[0]
"In practice, we subtract the ID for a phrase in question from that for the opinion word as the value for feature F2.",3 Proposed method,[0],[0]
"If the opinion word consists of more than one phrase, we take the minimum difference.",3 Proposed method,[0],[0]
"Because in Japanese a modifier is usually followed by its modifying object, a phrase with a negative value for feature F2 is usually an Other-phrase.",3 Proposed method,[0],[0]
"For example, in the last phrase in Figure 1, which cannot be a modifier for the opinion word, is an Other-phrase.
",3 Proposed method,[0],[0]
"F3: Dependency pass to aspect Because a CFO rarely modifies an aspect, for the value of feature F3 we take 0 if there is a pass of dependencies between a phrase in question and an aspect and 1 otherwise.
",3 Proposed method,[0],[0]
F4: Phrase distance to aspect Similar to F1,3 Proposed method,[0],[0]
", F3 is not robust against errors of the dependency analysis.",3 Proposed method,[0],[0]
"As in F2, we approximate the value of F4 by a phrase distance between a phrase including an aspect and a phrase in question.
",3 Proposed method,[0],[0]
"F5: Difference between values for F2 and F1 A CFO usually consists of a sequence of Cond-phrases where each phrase modifies the next phrase, as in Figure 1.",3 Proposed method,[0],[0]
"There is a tendency that as the difference of values of F1 and F2 for a phrase becomes smaller, that phrase is more likely to be a Cond-phrase.",3 Proposed method,[0],[0]
"In Figure 1, the values for Condphrases #3–#6 are smaller than those for Otherphrases #0–#1.
",3 Proposed method,[0],[0]
F6:,3 Proposed method,[0],[0]
Beginning of sentence The subject of an opinion sentence is often its U-CFO because the evaluation is valid only from the perspective of that specific subject.,3 Proposed method,[0],[0]
"For example, in “my daughter was pleased with toys in the room” the positive evaluation is restricted by the daughter’s perspective.",3 Proposed method,[0],[0]
"Thus, the value of feature F6 takes 1 for the first phrase in a sentence excluding a conjunction, and 0 otherwise.
",3 Proposed method,[0],[0]
"F7: Clue expression Because a CFO often ends with one or more specific particles or auxiliary verbs, we use the existence of those clue expressions in a phrase as the value for feature F7.",3 Proposed method,[0],[0]
"We use words in a dictionary of Japanese functional expressions “Tsutsuji” (Matsuyoshi et al., 2006)
as the clue expressions.",3 Proposed method,[0],[0]
Table 1 shows examples of entries for Tsutsuji.,3 Proposed method,[0],[0]
Each entry is represented in a hierarchy structure with nine abstraction levels.,3 Proposed method,[0],[0]
"We firstly collected “Head words” in the nineteen categories (e.g., resultative condition and purpose in L2) associated with our purpose, consulting “Meaning categories”.",3 Proposed method,[0],[0]
Then we collected “Surface forms” corresponding to the collected head words and identified their corresponding surface forms to standardize different forms.,3 Proposed method,[0],[0]
"For example, for ID 1 and ID 3 in Table 1, “to sure ba” and “nde” are regarded as identical to “to suru to” and “node”, respectively.",3 Proposed method,[0],[0]
"As a result, we collected 388 words, such as “ba (if)” and “ni (for)” and used their existence in a phrase in question as value for F7.",3 Proposed method,[0],[0]
"Because the data sparseness is a crucial problem for F7, we use the existence of semantic categories in Tsutsuji as the values of F8 for smoothing purposes.",F8: Semantic categories for clue expression,[0],[0]
"For example, in Table 1, “to suru to” and “ba” have the same feature values “resultative condition”.",F8: Semantic categories for clue expression,[0],[0]
"If a clue expression belongs to more than one semantic category as in “ni” of Table 1, the feature value is a set of these categories.
",F8: Semantic categories for clue expression,[0],[0]
F9: Dependency pass to phrase including clue expression (Surface form),F8: Semantic categories for clue expression,[0],[0]
"As described in F7 above, the last phrase in a CFO often includes one or more clue expressions.",F8: Semantic categories for clue expression,[0],[0]
"In addition, a CFO often consists of more than one phrase.",F8: Semantic categories for clue expression,[0],[0]
"Given those conditions, a phrase that modifies a phrase containing a clue expression is also likely to be a Condphrase.",F8: Semantic categories for clue expression,[0],[0]
"We use the existence of a dependency pass between a phrase in question and a phrase containing a clue expression as the values of feature F9.
F10:",F8: Semantic categories for clue expression,[0],[0]
"Dependency pass to phrase including clue expression (Category) As with F8, we use the existence of semantic categories of Tsutsuji as the values of feature F10.
",F8: Semantic categories for clue expression,[0],[0]
F11: Restrictive words We use the existence of words that are strongly associated with U-CFO as the value for F11.,F8: Semantic categories for clue expression,[0],[0]
We call such words restrictive words.,F8: Semantic categories for clue expression,[0],[0]
"We automatically produced a dictionary of restrictive words from advertising slogans for hotels, which often include descriptions for target users, such as “Fjoshikai ya kappuru ni osusume!!F (Recommended to girls get-together and couples)”.",F8: Semantic categories for clue expression,[0],[0]
"First, we extracted words in the advertising slogan based on the following steps.
",F8: Semantic categories for clue expression,[0],[0]
"Step 1: Extracting sentences that match to a regular expression “( | hito | mono | kata) ni ( | wa | mo) osusume” (i.e., “recommended to” or “recommend to those who”).
",F8: Semantic categories for clue expression,[0],[0]
"Step 2: Collecting a sequence of content words for each bunsetsu-phrase in the extracted sentences.
",F8: Semantic categories for clue expression,[0],[0]
"For the above advertising slogan, we can collect two restrictive words “joshikai (girls gettogether)” and “kappuru (couple)” by performing those 2 steps.
",F8: Semantic categories for clue expression,[0],[0]
"Second, we collected a sequence of independent words for bunsetsu phrases which comprises UCFO in an annotated corpus.",F8: Semantic categories for clue expression,[0],[0]
"We combined the extracted words from the advertising slogans an annotated corpora, discarded redundancy, and standardized similar words, such as “kanko suru (do sightseeing) and “kanko (sightseeing)”.",F8: Semantic categories for clue expression,[0],[0]
"As a result, we collected 934 words.
",F8: Semantic categories for clue expression,[0],[0]
"Finally, we calculated a mutual information like score, Score(r, u), between a restrictive word r and labels u, Cond-phrases for U-CFOs (i.e., phrases labeled with either of BU or IU), by Equation 2.
",F8: Semantic categories for clue expression,[0],[0]
"Score(r, u) = P (r, u) log P (r, u)
P (r)P (u) (2)
P (r, u) denotes the probability that a phrase including r is labeled with BU or IU in the annotated corpus.",F8: Semantic categories for clue expression,[0],[0]
P (r) denotes the probability that a phrase including r appears in the annotated corpus while P (u) denotes the probability that a phrase labeled with BU or IU in the annotated corpus.,F8: Semantic categories for clue expression,[0],[0]
"If a phrase includes a restrictive word r and Score(r, u) is greater than threshold θ, the feature value is r, and “nothing” otherwise.
",F8: Semantic categories for clue expression,[0],[0]
"F12: Existence of restrictive word Because the data sparseness is a crucial problem for F11, we integrate all the restrictive words for F11 into a single category for smoothing purposes.",F8: Semantic categories for clue expression,[0],[0]
"The value for F12 is the existence (1/0) of restrictive words.
",F8: Semantic categories for clue expression,[0],[0]
F13: Part of speech for head The likelihood that a phrase in question is a Cond-phrases partially depends on the part of speech for the head in that phrase.,F8: Semantic categories for clue expression,[0],[0]
"For example, in Figure 1, a phrase whose head is a noun or verb tends to be a Condphrase",F8: Semantic categories for clue expression,[0],[0]
"To evaluate the effectiveness of our method, we used the Rakuten Travel data1, which consists of 348 564 Japanese reviews for hotels in Japan.",4 Experiments,[0],[0]
"From this dataset, we selected 580 reviews and manually identified elements for opinion units.",4 Experiments,[0],[0]
We removed sentences consisting only of opinion unit such as “The location is good” from the evaluation.,4 Experiments,[0],[0]
"As a result, 3 155 sentences remained, which comprise our corpus.",4 Experiments,[0],[0]
"To evaluate the effectiveness for identifying CFOs, we used the manually annotated opinion elements as output of a pseudo automatic method.
",4 Experiments,[0],[0]
"Given the above corpus, two annotators independently identified U-CFOs or CFOs, if any, for each opinion unit.",4 Experiments,[0],[0]
"For both annotations of CFOs and U-CFOs, the Kappa value for the interannotator agreement was 0.87, indicating strong agreement.",4 Experiments,[0],[0]
We show the details of our corpus in Table 2.,4 Experiments,[0],[0]
"Using this corpus, we performed 10-fold cross-validation and compared different methods from different perspectives.",4 Experiments,[0],[0]
"Also, we determined the threshold for Score (see Eq 2) by a development set for each fold.
",4 Experiments,[0],[0]
"To evaluate the effectiveness of extracting UCFOs and CFOs independently, we first classified bunsetsu phrases into any of BU, IU, BC, IC, or Other.",4 Experiments,[0],[0]
"Then, for the U-CFO extraction we regarded phrases for BU and IU as the Cond-phrases while for the CFO extraction we regarded phrases for BU, IU, BC, and IC as the Cond-phrases.
",4 Experiments,[0],[0]
"We used “Partial match” and “Exact match”, which denote different criteria for the correctness of methods under evaluation.",4 Experiments,[0],[0]
"While in the partial match each method was requested to only detect whether or not a test sentence includes CFO, in the exact match each method was also requested to identify the span of each CFO.",4 Experiments,[0],[0]
"Also, we used different evaluation measures, namely precision (P), recall (R), F-measure (F), and accuracy (A).
",4 Experiments,[0],[0]
Rule-based method and SVM-based method are used for comparison purposes.,4 Experiments,[0],[0]
"Rule-based
1https://alaginrc.nict.go.jp/resources/rakutendataset/rakuten-outline.html
method first identifies a bunsetsu phrase whose dependency distance to the opinion word is 1 and including a clue expression (see Section 3), and also identifies a sequence of the phrases from which there is a dependency path to the above phrase as a CFO.",4 Experiments,[0],[0]
"For example, in Figure 1 because phrase #6 includes a clue expression, a sequence of phrases #3–#6 is extracted as a CFO.",4 Experiments,[0],[0]
"These rules are based on features F1, F7 and F9.",4 Experiments,[0],[0]
"For the U-CFO extraction task, we regarded a sequence of Cond-phrases extracted by the above method as U-CFO if that sequence includes a restrictive word.",4 Experiments,[0],[0]
"For SVM, the thirteen features F1–F13 proposed in Section 3 was used.",4 Experiments,[0],[0]
"We used LIBSVM (Chang and Lin, 2011) to train a classifier.",4 Experiments,[0],[0]
Our method used CRF to train a classifier with the thirteen features and four patterns for feature functions.,4 Experiments,[0],[0]
"We used CRF++2 to train a classifier for each phrase and regularized the parameters using L2-norm.
",4 Experiments,[0],[0]
Figure 2 shows the relationship between values of regularization parameter and F-measure for exact match.,4 Experiments,[0],[0]
"In Figure 2, “Rule”, “SVM”, and “CRF” denote a rule-based method, SVM-based method, and our method, respectively.",4 Experiments,[0],[0]
"The Fmeasure for Rule, independent of the regularization parameter, is a constant.",4 Experiments,[0],[0]
"While the F-measure for SVM substantially varied depending on the parameter value, that for CRF did not vary that much.",4 Experiments,[0],[0]
"Additionally, the F-measure for CRF was larger than that for SVM irrespective of the parameter value and matching criterion.
",4 Experiments,[0],[0]
Table 3 shows results obtained with the optimal value for the regularization parameter.,4 Experiments,[0],[0]
"Looking at Table 3, one can see that CRF outperformed the other methods in terms of F-measure and accuracy for both partial and exact matches.",4 Experiments,[0],[0]
"We used the two-tailed paired t-test for statistical testing and found that the differences of CRF and each of the other methods in F-measure and accuracy were statistically significant at the 1% level irrespective of the configuration.
",4 Experiments,[0],[0]
Figure 3 shows the effectiveness of the proposed features for exact match.,4 Experiments,[0],[0]
The horizontal axis “w/o X” denotes a method without feature X.,4 Experiments,[0],[0]
The vertical axis denotes a ratio of each method to our method.,4 Experiments,[0],[0]
"If a method without feature X takes less than 1 for value of vertical axis, the feature X is effective for extracting CFOs.",4 Experiments,[0],[0]
"Looking at Figure 3, one can see that our complete method outperformed any variation of our method in terms of
2http://crfpp.googlecode.com/svn/trunk/doc/index.html
F-measure.",4 Experiments,[0],[0]
"Thus, we conclude that each of our thirteen features was independently effective for extracting CFO and U-CFO in review sentences and that when used together the improvement was even greater.
",4 Experiments,[0],[0]
"For the U-CFO extraction, we analyzed the errors by our method.",4 Experiments,[0],[0]
The total number of errors was 363 by condition unit.,4 Experiments,[0],[0]
"We describe causes of the errors with example sentences, translated into English by the authors.",4 Experiments,[0],[0]
"In those examples, double and single underlines denote false positive and false negative, respectively.",4 Experiments,[0],[0]
"For each cause, we show the number of errors in parentheses.
",4 Experiments,[0],[0]
E1 (124) Errors were due to F11 and F12 with insufficient dictionary for restrictive words.,4 Experiments,[0],[0]
"Typically, low frequency words (e.g., pilgrimage) and words related to miscellaneous activities during a travel (e.g., charging a battery of a mobile phone) were not included in our dictionary.",4 Experiments,[0],[0]
"While it is important to increase the vocabulary size of our dictionary, identifying synonymous expressions with partial matching (e.g., go to sleep / go to bed) is also important.
",4 Experiments,[0],[0]
"E2 (53) Errors were due to dependency analysis, which often mistakenly recognizes sentence boundaries in an informal writing style and dependency relations in a sentence comprising a phrase, such as “the best location for fully enjoying Asakusa”.",4 Experiments,[0],[0]
"In this example, CaboCha mistakenly associated the adnominal modifier “for fully enjoying Asakusa” with “location (aspect)” instead of “best (opinion word)”.",4 Experiments,[0],[0]
"As a result, F1 and F3 did not regard this modifier as a U-CFO.
E3 (40) Restrictive modifiers that modify a nonopinion segment were mistakenly extracted as U-CFOs.",4 Experiments,[0],[0]
"For example, in “I used this hotel for business and the meal was good”, “for business” includes the clue expression “for” but does not modifies the opinion unit.
",4 Experiments,[0],[0]
E4 (39) Similar to E3 but errors were due to restrictive words instead of clue expressions.,4 Experiments,[0],[0]
"In the example for E3, the restrict word “business” caused the error.
E5 (26)",4 Experiments,[0],[0]
"U-CFOs that consist of a large number of phrases were often not extracted due to F5, such as “This hotel is acceptable for one night to take the train at the Chuo station next morning”.
",4 Experiments,[0],[0]
"E6 (25) Errors were due to irrelevant entries in our restrictive word dictionary.
",4 Experiments,[0],[0]
"E7 (11) Due to the sparseness problem for restrictive words in the training data, U-CFOs and CFOs were not correctly distinguished.
E8 (9) Errors were due to part-of-speech tagging.
",4 Experiments,[0],[0]
"E9 (6) Errors were due to extracting modifiers consisting of a personal pronoun without additional user-related attributes, such as “enough for me” , as U-CFOs.",4 Experiments,[0],[0]
"We need to identify whether an expression for a person is associated with userrelated attributes, such as “the bed is small for a person who is tall”, which indicates a physical attribute of a user.
",4 Experiments,[0],[0]
"Additionally, there are 65 errors for which we have not found a reason.",4 Experiments,[0],[0]
"Although a number of methods have been proposed to search an opinionated corpus for opinion units, few attempts have so far been made at addressing cases where the validity of an evaluation is restricted on a condition in the source text.",5 Conclusion,[0],[0]
We proposed a method to identify such conditions from sentences including opinion units.,5 Conclusion,[0],[0]
Our method performs sequence labeling to determine whether each phrase is a constituent of an condition for opinion.,5 Conclusion,[0],[0]
"We proposed thirteen features associated with lexical and syntactic information of Japanese, and showed their effectiveness using reviews for hotels.",5 Conclusion,[0],[0]
"The contributions of this paper are introducing the notion of conditions for opinions, which is language-independent, proposing a method to extract condition-opinion relations from opinionated corpora, and giving an insight into its potential applications in opinion mining.",5 Conclusion,[0],[0]
We would like to thank Professor Takenobu Tokunaga (Tokyo Institute of Technology) for his valuable comments.,Acknowledgments,[0],[0]
This research was supported in part by Grant-in-Aid for Scientific Research (Grant No. 15H02747).,Acknowledgments,[0],[0]
"A fundamental issue in opinion mining is to search a corpus for opinion units, each of which typically comprises the evaluation by an author for a target object from an aspect, such as “This hotel is in a good location”.",abstractText,[0],[0]
"However, few attempts have been made to address cases where the validity of an evaluation is restricted on a condition in the source text, such as “for traveling with small kids”.",abstractText,[0],[0]
"In this paper, we propose a method to extract condition-opinion relations from online reviews, which enables fine-grained analysis for the utility of target objects depending the user attribute, purpose, and situation.",abstractText,[0],[0]
Our method uses supervised machine learning to identify sequences of words or phrases that comprise conditions for opinions.,abstractText,[0],[0]
"We propose several features associated with lexical and syntactic information, and show their effectiveness experimentally.",abstractText,[0],[0]
Extracting Condition-Opinion Relations Toward Fine-grained Opinion Mining,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 142–151 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
142",text,[0],[0]
Automatic summarization aims to shorten a text document while maintaining the salient information of the original text.,1 Introduction,[0],[0]
"The practical need for such systems is growing with the rapid and continuous increase in textual information sources in multiple domains.
",1 Introduction,[0],[0]
Summarization tools can be broadly classified into two categories: extractive and abstractive.,1 Introduction,[0],[0]
Extractive summarization selects parts of the input document to create its summary while abstractive summarization generates summaries that may have words or phrases not present in the input document.,1 Introduction,[0],[0]
Abstractive summarization is clearly harder as methods have to address factual and grammatical errors that may be introduced and problems in utilizing external knowledge sources to obtain paraphrasing or generalization.,1 Introduction,[0],[0]
"Extractive summarizers obviate the need to
solve these problems by selecting the most salient textual units (usually sentences) from the input documents.",1 Introduction,[0],[0]
"As a result, they generate summaries that are grammatically and semantically more accurate than those from abstractive methods.",1 Introduction,[0],[0]
"While they may have problems like incorrect or unclear referring expressions or lack of coherence, they are computationally simpler and more efficient to generate.",1 Introduction,[0],[0]
"Indeed, state-of-the-art extractive summarizers are comparable or often better in performance to competitive abstractive summarizers (see (Nallapati et al., 2017) for a recent empirical comparison).
",1 Introduction,[0],[0]
Classical approaches to extractive summarization have relied on human-engineered features from the text that are used to score sentences in the input document and select the highestscoring sentences.,1 Introduction,[0],[0]
These include graph or constraint-optimization based approaches as well as classifier-based methods.,1 Introduction,[0],[0]
A review of these approaches can be found in Nenkova et al. (2011).,1 Introduction,[0],[0]
Some of these methods generate summaries from multiple documents.,1 Introduction,[0],[0]
"In this paper, we focus on single document summarization.
",1 Introduction,[0],[0]
Modern approaches that show the best performance are based on end-to-end deep learning models that do not require human-crafted features.,1 Introduction,[0],[0]
"Neural models have tremendously improved performance in several difficult problems in NLP such as machine translation (Chen et al., 2017) and question-answering (Hao et al., 2017).",1 Introduction,[0],[0]
"Deep models with thousands of parameters require large, labeled datasets and for summarization this hurdle of labeled data was surmounted by Cheng and Lapata (2016), through the creation of a labeled dataset of news stories from CNN and Daily Mail consisting of around 280,000 documents and human-generated summaries.
",1 Introduction,[0],[0]
"Recurrent neural networks with encoderdecoder architecture (Sutskever et al., 2014) have
been successful in a variety of NLP tasks where an encoder obtains representations of input sequences and a decoder generates target sequences.",1 Introduction,[0],[0]
"Attention mechanisms (Bahdanau et al., 2015) are used to model the effects of different loci in the input sequence during decoding.",1 Introduction,[0],[0]
"Pointer networks (Vinyals et al., 2015) use this mechanism to obtain target sequences wherein each decoding step is used to point to elements of the input sequence.",1 Introduction,[0],[0]
"This pointing ability has been effectively utilized by state-of-the-art extractive and abstractive summarizers (Cheng and Lapata, 2016; Nallapati et al., 2016; See et al., 2017).
",1 Introduction,[0],[0]
"In this work, we design SWAP-NET a new deep learning model for extractive summarization.",1 Introduction,[0],[0]
"Similar to previous models, we use an encoderdecoder architecture with attention mechanism to select important sentences.",1 Introduction,[0],[0]
Our key contribution is to design an architecture that utilizes key words in the selection process.,1 Introduction,[0],[0]
"Salient sentences of a document, that are useful in summaries, often contain key words and, to our knowledge, none of the previous models have explicitly modeled this interaction.",1 Introduction,[0],[0]
"We model this interaction through a two-level encoder and decoder, one for words and the other for sentences.",1 Introduction,[0],[0]
"An attention-based mechanism, similar to that of Pointer Networks, is used to learn important words and sentences from labeled data.",1 Introduction,[0],[0]
A switch mechanism is used to select between words and sentences during decoding and the final summary is generated using a combination of selected sentences and words.,1 Introduction,[0],[0]
We demonstrate the efficacy of our model on the CNN/Daily Mail corpus where it outperforms state-of-the-art extractive summarizers.,1 Introduction,[0],[0]
Our experiments also suggest that the semantic redundancy in SWAPNET generated summaries is comparable to that of human-generated summaries.,1 Introduction,[0],[0]
"Let D denote an input document, comprising of a sequence of N sentences: s1, . . .",2 Problem Formulation,[0],[0]
", sN .",2 Problem Formulation,[0],[0]
"Ignoring sentence boundaries, let w1, . . .",2 Problem Formulation,[0],[0]
", wn be the sequence of n words in document D. An extractive summary aims to obtain a subset of the input sentences that forms a salient summary.
",2 Problem Formulation,[0],[0]
We use the interaction between words and sentences in a document to predict important words and sentences.,2 Problem Formulation,[0],[0]
"Let the target sequence of indices of important words and sentences be V = v1, . . .",2 Problem Formulation,[0],[0]
", vm, where each index vj can point to ei-
ther a sentence or a word in an input document.",2 Problem Formulation,[0],[0]
"We design a supervised sequence-to-sequence recurrent neural network model, SWAP-NET, that uses these target sequences (of sentences and words) to learn salient sentences and key words.",2 Problem Formulation,[0],[0]
"Our objective is to find SWAP-NET model parameters M that maximize the probability p(V |M,D) =",2 Problem Formulation,[0],[0]
"∏ j p(vj |v1, . .",2 Problem Formulation,[0],[0]
.,2 Problem Formulation,[0],[0]
", vj−1,M,D) =∏
j p(vj |v<j ,M,D).",2 Problem Formulation,[0],[0]
We omit M in the following to simplify notation.,2 Problem Formulation,[0],[0]
"SWAP-NET predicts both key words and salient sentences, that are subsequently used for extractive summary generation.",2 Problem Formulation,[0],[0]
"We briefly describe Pointer Networks (Vinyals et al., 2015).",3 Background,[0],[0]
"Our approach, detailed in the following sections, uses a similar attention mechanism.
",3 Background,[0],[0]
"Given a sequence of n vectors X = x1, ....xn and a sequence of indices R = r1, ....rm, each between 1 and n, the Pointer Network is an encoder-decoder architecture trained to maximize p(R|X; θ) = ∏m j=1 pθ(rj |r1, ....rj−1,X; θ), where θ denotes the model parameters.",3 Background,[0],[0]
"Let the encoder and decoder hidden states be (e1, ...., en) and (d1, ...., dm) respectively.",3 Background,[0],[0]
"The attention vector at each output step j is computed as follows:
uji = v T tanh(Weei +Wddj), i ∈",3 Background,[0],[0]
"(1, . . .",3 Background,[0],[0]
",",3 Background,[0],[0]
"n)
",3 Background,[0],[0]
αji =,3 Background,[0],[0]
"softmax(u j i ), i ∈ (1, . . .",3 Background,[0],[0]
",",3 Background,[0],[0]
"n)
",3 Background,[0],[0]
The softmax normalizes vector uj to be an attention mask over inputs.,3 Background,[0],[0]
"In a pointer network, the same attention mechanism is used to select one of the n input vectors with the highest probability, at each decoding step, thus effectively pointing to an input:
p(rj |r1, ....rj−1,X) = softmax(uj)
Here, v,Wd, and We are learnable parameters of the model.",3 Background,[0],[0]
We use an encoder-decoder architecture with an attention mechanism similar to that of Pointer Networks.,4 SWAP-NET,[0],[0]
"To model the interaction between words and sentences in a document we use two encoders and decoders, one at the word level and the other at the sentence level.",4 SWAP-NET,[0],[0]
"The sentence-level decoder learns to point to important sentences while the
word-level decoder learns to point to important words.",4 SWAP-NET,[0],[0]
A switch mechanism is trained to select either a word or a sentence at each decoding step.,4 SWAP-NET,[0],[0]
The final summary is created using the output words and sentences.,4 SWAP-NET,[0],[0]
We now describe the details of the architecture.,4 SWAP-NET,[0],[0]
We use two encoders: a bi-directional LSTM at the word level and a LSTM at the sentence level.,4.1 Encoder,[0],[0]
"Each word wi is represented by a K-dimensional embedding (e.g., via word2vec), denoted by xi.",4.1 Encoder,[0],[0]
"The word embedding xi is encoded as ei using bi-directional LSTM for i = 1, . . .",4.1 Encoder,[0],[0]
",",4.1 Encoder,[0],[0]
"n. The vector output of BiLSTM at the end of a sentence is used to represent that entire sentence, which is further encoded by the sentence-level LSTM as Ek = LSTM(ekl , Ek−1), where k
l is the index of the last word in the kth sentence in D and Ek is the hidden state at the kth step of LSTM, for k = 1, . . .",4.1 Encoder,[0],[0]
", N .",4.1 Encoder,[0],[0]
See figure 1.,4.1 Encoder,[0],[0]
"We use two decoders – a sentence-level and a word-level decoder, that are both LSTMs, with each decoder pointing to sentences and words re-
spectively (similar to a pointer network).",4.2 Decoder,[0],[0]
"Thus, we can consider the output of each decoder step to be an index in the input sequence to the encoder.",4.2 Decoder,[0],[0]
Let m be the number of steps in each decoder.,4.2 Decoder,[0],[0]
"Let T1, . . .",4.2 Decoder,[0],[0]
", Tm be the sequence of indices generated by the sentence-level decoder, where each index Tj ∈ {1, . . .",4.2 Decoder,[0],[0]
", N}; and let t1, . . .",4.2 Decoder,[0],[0]
", tm be the sequence of indices generated by the word-level decoder, where each index tj ∈ {1, . . .",4.2 Decoder,[0],[0]
", n}.",4.2 Decoder,[0],[0]
"At the jth decoding step, we have to select a sentence or a word which is done through a binary switch Qj that has two states Qj = 0 and Qj = 1 to denote word and sentence selection respectively.",4.3 Network Details,[0],[0]
"So, we first determine the switch probability p(Qj |v<j , D).",4.3 Network Details,[0],[0]
"Let αskj denote the probability of selecting the kth input sentence at the jth decoding step of sentence decoder:
αskj = p(Tj = k|v<j , Qj = 1, D),
and let αwij denote the probability of selecting the ith input word at the jth decoding step of word decoder:
αwij = p(tj = i|v<j , Qj = 0, D),
both conditional on the corresponding switch selection.",4.3 Network Details,[0],[0]
"We set vj based on the probability values:
vj =
{ k = argmaxk p s kj if maxk p s kj > maxi p w ij
i = argmaxi p w ij if maxi p w ij",4.3 Network Details,[0],[0]
>,4.3 Network Details,[0],[0]
"maxk p s kj
pskj = α s kjp(Qj = 1|v<j , D),
pwij = α w ijp(Qj = 0|v<j , D).
",4.3 Network Details,[0],[0]
"These probabilities are obtained through the attention weight vectors at the word and sentence levels and the switch probabilities:
αwij = softmax(v T t φ(whhj + wtei)),
αskj = softmax(V T T φ(WHHj +WTEk)).
",4.3 Network Details,[0],[0]
"Parameters vt, wh, wt, VT ,WH and WT are trainable parameters.",4.3 Network Details,[0],[0]
"Parameters hj and Hj are the hidden vectors at the jth step of the wordlevel and sentence-level decoder respectively defined as:
hj = LSTM(hj−1, aj−1, φ(Aj−1))",4.3 Network Details,[0],[0]
"(1)
Hj = LSTM(Hj−1, Aj−1, φ(aj−1))",4.3 Network Details,[0],[0]
"(2)
where aj = ∑n i=0 α w ijei, Aj = ∑N k=0 α s kjEk.",4.3 Network Details,[0],[0]
"The non-linear transformation, φ (we choose tanh), is used to connect the word-level encodings to the sentence decoder and the sentence-level encodings to the word decoder.",4.3 Network Details,[0],[0]
"Specifically, the word-level decoder updates its state by considering a sum of sentence encodings, weighted by the attentions from the previous state and mutatis mutandis for the sentence-level decoder.
",4.3 Network Details,[0],[0]
"The switch probability p(Qj |v<j , D) at the jth decoding step is given by:
p(Qj = 1|v<j , D) = σ(wTQ(Hj−1, Aj−1, φ(hj−1, aj−1)))
p(Qj = 0|v<j , D) = 1− p(Qj = 1|v<j , D)
where wQ is a trainable parameter and σ denotes the sigmoid function and φ is the chosen nonlinear transformation (tanh).
",4.3 Network Details,[0],[0]
During training the loss function lj at jth step is set to lj = − log(pskjqsj + pwijqwj ),4.3 Network Details,[0],[0]
"− log p(Qj |v<j , D).",4.3 Network Details,[0],[0]
"Note that at each decoding step, switch is either qwj = 1, q s j = 0",4.3 Network Details,[0],[0]
"if the j th output is a word or qwj = 0, q s j = 1 if the j
th output is a sentence.",4.3 Network Details,[0],[0]
The switch probability is also considered in the loss function.,4.3 Network Details,[0],[0]
"Given a document whose summary is to be generated, its sentences and words are given as input to the trained encoder.",4.4 Summary Generation,[0],[0]
"At the jth decoding step, either a sentence or a word is chosen based on the probability values αskj and α w ij and the switch probability p(Qj |v<j , D).",4.4 Summary Generation,[0],[0]
We assign importance scores to the selected sentences based on their probability values during decoding as well as the probabilities of the selected words that are present in the selected sentences.,4.4 Summary Generation,[0],[0]
Thus sentences with words selected by the decoder are given higher importance.,4.4 Summary Generation,[0],[0]
Let the kth input sentence sk be selected at the jth decoding step and ith input word wi be selected at the lth decoding step.,4.4 Summary Generation,[0],[0]
"Then the importance of sk is defined as
I(sk) = α s kj",4.4 Summary Generation,[0],[0]
"+ λ ∑ wi∈sk αwil (3)
",4.4 Summary Generation,[0],[0]
In our experiments we choose λ = 1.,4.4 Summary Generation,[0],[0]
The final summary consists of three sentences with the highest importance scores.,4.4 Summary Generation,[0],[0]
"Traditional approaches to extractive summarization rely on human-engineered features based on, for example, part of speech (Erkan and Radev, 2004) and term frequency (Nenkova et al., 2006).",5 Related Work,[0],[0]
"Sentences in the input document are scored using these features, ranked and then selected for the final summary.",5 Related Work,[0],[0]
"Methods used for extractive summarization include graph-based approaches (Mihalcea, 2005) and Integer Linear Programming (Gillick and Favre, 2009).",5 Related Work,[0],[0]
"There are many classifier-based approaches that select sentences for the extractive summary using methods such as Conditional Random Fields (Shen et al., 2007) and Hidden Markov models (Conroy and O’leary, 2001).",5 Related Work,[0],[0]
"A review of these classical approaches can be found in Nenkova et al. (2011).
",5 Related Work,[0],[0]
"End-to-end deep learning based neural models that can effectively learn from text data, without human-crafted features, have witnessed rapid development, resulting in improved performance in multiple areas such as machine translation (Chen et al., 2017) and question-answering (Hao et al., 2017), to name a few.",5 Related Work,[0],[0]
"Large labelled corpora based on news stories from CNN and Daily Mail, with human generated summaries have become available (Cheng and Lapata, 2016), that have
spurred the use of deep learning models in summarization.",5 Related Work,[0],[0]
"Recurrent neural network based architectures have been designed for both extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (See et al., 2017; Tan et al., 2017) summarization problems.",5 Related Work,[0],[0]
"Among these, the work of Cheng and Lapata (2016) and Nallapati et al. (2017) are closest to our work on extractive singledocument summarization.
",5 Related Work,[0],[0]
An encoder-decoder architecture with an attention mechanism similar to that of a pointer network is used by Cheng and Lapata (2016).,5 Related Work,[0],[0]
Their hierarchical encoder uses a CNN at the word level leading to sentence representations that are used in an RNN to obtain document representations.,5 Related Work,[0],[0]
"They use a hierarchical attention model where the first level decoder predicts salient sentences used for an extractive summary and based on this output, the second step predicts keywords which are used for abstractive summarization.",5 Related Work,[0],[0]
Thus they do not use key words for extractive summarization and for abstractive summarization they generate key words based on sentences predicted independently of key words.,5 Related Work,[0],[0]
"SWAP-NET, in contrast, is simpler using only two-level RNNs for word and sentence level representations in both the encoder and decoder.",5 Related Work,[0],[0]
In our model we predict both words and sentences in such a way that their attentions interact with each other and generate extractive summaries considering both the attentions.,5 Related Work,[0],[0]
"By modeling the interaction between these key words and important sentences in our decoder architecture, we are able to extract sentences that are closer to the gold summaries.
",5 Related Work,[0],[0]
"SummaRuNNer, the method developed by Nallapati et al. (2017) is not similar to our method in its architecture but only in the aim of extractive summary generation.",5 Related Work,[0],[0]
It does not use an encoderdecoder architecture; instead it is an RNN based binary classifier that decides whether or not to include a sentence in the summary.,5 Related Work,[0],[0]
"The RNN is multi-layered representing inputs, words, sentences and the final sentence labels.",5 Related Work,[0],[0]
"The decision of selecting a sentence at each step of the RNN is based on the content of the sentence, salience in the document, novelty with respect to previously selected sentences and other positional features.",5 Related Work,[0],[0]
"Their approach is considerably simpler than that of Cheng and Lapata (2016) but obtains summaries closer to the gold summaries, and additionally, facilitates interpretable visualization and
training from abstractive summaries.",5 Related Work,[0],[0]
"Their experiments show improved performance over both abstractive and extractive summarizers from several previous models (Nallapati et al., 2017).
",5 Related Work,[0],[0]
We note that several elements of our architecture have been introduced and used in earlier work.,5 Related Work,[0],[0]
"Pointer networks (Vinyals et al., 2015) used the attention mechanism of (Bahdanau et al., 2015) to solve combinatorial optimization problems.",5 Related Work,[0],[0]
"They have also been used to point to sentences in extractive (Cheng and Lapata, 2016) and abstractive (Nallapati et al., 2016; See et al., 2017) summarizers.",5 Related Work,[0],[0]
"The switch mechanism was introduced to incorporate rare or out-of-vocabulary words (Gulcehre et al., 2016) and are used in several summarizers (e.g. (Nallapati et al., 2016)).",5 Related Work,[0],[0]
"However, we use it to select between word and sentence level decoders in our model.
",5 Related Work,[0],[0]
"The importance of all the three interactions: (i) sentence-sentence, (ii) word-word and (iii) sentence-word, for summarization, have been studied by Wan et al. (2007) using graph-based approaches.",5 Related Work,[0],[0]
"In particular, they show that methods that account for saliency using both the following considerations perform better than methods that consider either one of them alone, and SWAP-NET is based on the same principles.
",5 Related Work,[0],[0]
"• A sentence should be salient if it is heavily linked with other salient sentences, and a word should be salient if it is heavily linked with other salient words.
",5 Related Work,[0],[0]
"• A sentence should be salient if it contains many salient words, and a word should be salient if it appears in many salient sentences.",5 Related Work,[0],[0]
"In our experiments the maximum number of words per document is limited to 800, and the maximum number of sentences per document to 50 (padding is used to maintain the length of word sequences).",6.1 Experimental Settings,[0],[0]
We also use the symbols <GO> and <EOS> to indicate start and end of prediction by decoders.,6.1 Experimental Settings,[0],[0]
"The total vocabulary size is 150,000 words.
",6.1 Experimental Settings,[0],[0]
"We use word embeddings of dimension 100 pretrained using word2vec (Mikolov et al., 2013) on the training dataset.",6.1 Experimental Settings,[0],[0]
We fix the LSTM hidden state size at 200.,6.1 Experimental Settings,[0],[0]
"We use a batch size of 16 and the ADAM optimizer (Kingma and Ba, 2015) with parameters: learning rate = 0.001, β1 = 0.9, β2 =
0.999 to train SWAP-NET.",6.1 Experimental Settings,[0],[0]
"We employ gradient clipping to regularize our model and an early stopping criterion based on the validation loss.
",6.1 Experimental Settings,[0],[0]
During training we find that SWAP-NET learns to predict important sentences faster than to predict words.,6.1 Experimental Settings,[0],[0]
"To speed up learning of word probabilities, we add the term− logαwij to our loss function lj in the final iterations of training.",6.1 Experimental Settings,[0],[0]
It is possible to get the same sentence or word in multiple (usually consecutive) decoding steps.,6.1 Experimental Settings,[0],[0]
"In that case, in Eq. 3 we consider the maximum value of alpha obtained across these steps and calculate maximum scores of distinct sentences and words.
",6.1 Experimental Settings,[0],[0]
"We select 3 top scoring sentences for the summary, as there are 3.11 sentences on average in the gold summary of the training set (similar to settings used by others, e.g., (Narayan et al., 2017)).",6.1 Experimental Settings,[0],[0]
"Two state-of-the-art methods for extractive summarization are SummaRuNNer (Nallapati et al., 2017) and NN, the neural summarizer of Cheng and Lapata (2016).",6.2 Baselines,[0],[0]
"SummaRuNNer can also provide extractive summaries while being trained abstractively (Nallapati et al., 2017); we denote this method by SummaRuNNer-abs.",6.2 Baselines,[0],[0]
"In addition, we compare our method with the Lead-3 summary which consists of the first three sentences from each document.",6.2 Baselines,[0],[0]
"We also compare our method with an abstractive summarizer that uses a similar attention-based encoder-decoder architecture (Nallapati et al., 2016), denoted by ABS.",6.2 Baselines,[0],[0]
"For our experiments, we use the CNN/DailyMail corpus (Hermann et al., 2015).",6.3 Benchmark Datasets,[0],[0]
"We use the anonymized version of this dataset, from Cheng and Lapata (2016), which has labels for important sentences, that are used for training.",6.3 Benchmark Datasets,[0],[0]
"To obtain labels for words, we extract keywords from each gold summary using RAKE, an unsupervised keyword extraction method (Rose et al., 2010).",6.3 Benchmark Datasets,[0],[0]
These keywords are used to label words in the corresponding input document during training.,6.3 Benchmark Datasets,[0],[0]
"We replace numerical values in the documents by zeros to limit the vocabulary size.
",6.3 Benchmark Datasets,[0],[0]
"We have 193,986 training documents, 12,147 validation documents and 10,346 test documents from the DailyMail corpus and 83,568 training documents, 1,220 validation documents and 1,093 test documents from CNN subset with labels for sentences and words.",6.3 Benchmark Datasets,[0],[0]
"We use the ROUGE toolkit (Lin and Hovy, 2003) for evaluation of the generated summaries in comparison to the gold summaries.",6.4 Evaluation Metrics,[0],[0]
"We use three variants of this metric: ROUGE-1 (R1), ROUGE-2 (R2) and ROUGE-L (RL) that are computed by matching unigrams, bigrams and longest common subsequences respectively between the two summaries.",6.4 Evaluation Metrics,[0],[0]
"To compare with (Cheng and Lapata, 2016) and (Nallapati et al., 2017) we use limited length ROUGE recall at 75 and 275 bytes for the Daily-Mail test set, and full length ROUGE-F1 score, as reported by them.",6.4 Evaluation Metrics,[0],[0]
"Performance on Daily Mail Data
Table 1 shows the performance of SWAP-NET, state-of-the-art baselines NN and SummaRuNNer and other baselines, using ROUGE recall with summary length of 75 bytes, on the entire Daily Mail test set.",6.5 Results on Benchmark Datasets,[0],[0]
The performance of SWAP-NET is comparable to that of SummaRuNNer and better than NN and other baselines.,6.5 Results on Benchmark Datasets,[0],[0]
Table 2 compares the same algorithms using ROUGE recall with summary length of 275 bytes.,6.5 Results on Benchmark Datasets,[0],[0]
"SWAP-NET outperforms both state-of-the-art summarizers SummaRuNNer as well as NN.
Performance on CNN/DailyMail Data SWAP-NET has the best performance on the combined CNN and Daily Mail corpus, outperforming
the previous best reported F-score by SummaRuNNer, as seen in table 3, with a consistent improvement of over 2 ROUGE points in all three metrics.",6.5 Results on Benchmark Datasets,[0],[0]
"SWAP-NET outperforms state-of-the-art extractive summarizers SummaRuNNer (Nallapati et al., 2017) and NN (Cheng and Lapata, 2016) on benchmark datasets.",6.6 Discussion,[0],[0]
"Our model is similar, although simpler, than that of NN and the main difference between SWAP-NET and these baselines is its explicit modeling of the interaction between key words and salient sentences.
",6.6 Discussion,[0],[0]
"Automatic keyword extraction has been studied extensively (Hasan and Ng, 2014).",6.6 Discussion,[0],[0]
"We use a popular and well tested method, RAKE (Rose et al., 2010) to obtain key words in the training documents.",6.6 Discussion,[0],[0]
"A disadvantage with such methods is that they do not guarantee representation, via extracted keywords, of all the topics in the text (Hasan and Ng, 2014).",6.6 Discussion,[0],[0]
"So, if RAKE key words are directly applied to the input test document (without using word decoder trained on RAKE words, obtained from gold summary as done in SWAP-NET), then there is a possibility of missing sentences from the missed topics.",6.6 Discussion,[0],[0]
"So, we train SWAP-NET to predict key words and also model their interactions with sentences.
",6.6 Discussion,[0],[0]
We investigate the importance of modeling this interaction and the role of key words in the final summary.,6.6 Discussion,[0],[0]
Table 4 shows statistics that reflect the importance of key words in extractive summaries.,6.6 Discussion,[0],[0]
"Key word coverage measures the proportion of key
words from those in the gold summary present in the generated summary.",6.6 Discussion,[0],[0]
SWAP-NET obtains nearly 74% of the key words.,6.6 Discussion,[0],[0]
"In comparison Lead3 has only about 62% of the key words from the gold summary.
",6.6 Discussion,[0],[0]
Sentences with key words measures the proportion of sentences containing at least one key word.,6.6 Discussion,[0],[0]
"It is not surprising that in SWAP-NET summaries 98% of the sentences, on average, contain at least one key word: this is by design of SWAP-NET.",6.6 Discussion,[0],[0]
"However, note that Lead-3 which has poorer performance in all the benchmark datasets has much fewer sentences with key words.",6.6 Discussion,[0],[0]
"This highlights the importance of key words in finding salient sentences for extractive summaries.
",6.6 Discussion,[0],[0]
We also find the SWAP-NET obtains summaries that have less semantic redundancy.,6.6 Discussion,[0],[0]
"Table 6 shows the average distance between pairs of sentences from the gold summary, and summaries generated from SWAP-NET and Lead-3.",6.6 Discussion,[0],[0]
"Distances are measured using cosine distance of paragraph vectors of each sentence (Le and Mikolov, 2014) from randomly selected 500 documents of the Daily Mail test set.",6.6 Discussion,[0],[0]
"Paragraph vectors have been found to be effective semantic representations of sentences (Le and Mikolov, 2014) and experiments in (Dai et al., 2015) also show that paragraph vectors can be effectively used to measure semantic similarity using cosine distance.",6.6 Discussion,[0],[0]
"For training we use GENSIM (Řehůřek and Sojka, 2010) with embedding size 200 and initial learning rate 0.025.",6.6 Discussion,[0],[0]
"The model is trained on 500 documents from DailyMail dataset for 10 epochs and learning rate is decreased by 0.002 at each epoch.
",6.6 Discussion,[0],[0]
"The average pair-wise distance of SWAP-NET is very close to that of the gold summary, both
nearly 0.8.",6.6 Discussion,[0],[0]
"In contrast, the average pairwise distance in Lead-3 summaries is 0.553 indicating higher redundancy.",6.6 Discussion,[0],[0]
"This highly desirable feature of SWAP-NET is likely due to use of of key words, that is affecting the choice of sentences in the final summary.
",6.6 Discussion,[0],[0]
"Table 5 shows a sample gold summary from the Daily Mail dataset and the generated summary from SWAP-NET and, for comparison, from Lead-3.",6.6 Discussion,[0],[0]
We observe the presence of key words in all the overlapping segments of text with the gold summary indicating the importance of key words in finding salient sentences.,6.6 Discussion,[0],[0]
"Modeling this interaction, we believe, is the reason for the superior performance of SWAP-NET in our experiments.
",6.6 Discussion,[0],[0]
An implementation of SWAP-NET and all the generated summaries from the test sets are available online in a github repository1.,6.6 Discussion,[0],[0]
"We present SWAP-NET, a neural sequence-tosequence model for extractive summarization that outperforms state-of-the-art extractive summarizers SummaRuNNer (Nallapati et al., 2017) and NN (Cheng and Lapata, 2016) on large scale benchmark datasets.",7 Conclusion,[0],[0]
"The architecture of SWAPNET is simpler than that of NN but due to its effective modeling of interaction between salient sentences and key words in a document, SWAPNET achieves superior performance.",7 Conclusion,[0],[0]
SWAP-NET models this interaction using a new two-level pointer network based architecture with a switching mechanism.,7 Conclusion,[0],[0]
Our experiments also suggest that modeling sentence-keyword interaction has the desirable property of less semantic redundancy in summaries generated by SWAP-NET.,7 Conclusion,[0],[0]
The authors thank the ACL reviewers for their valuable comments.,8 Acknowledgment,[0],[0]
Vaibhav Rajan acknowledges the support from Singapore Ministry of Education Academic Research Fund Tier 1 towards funding this research.,8 Acknowledgment,[0],[0]
We present a new neural sequence-tosequence model for extractive summarization called SWAP-NET (Sentences and Words from Alternating Pointer Networks).,abstractText,[0],[0]
"Extractive summaries comprising a salient subset of input sentences, often also contain important key words.",abstractText,[0],[0]
"Guided by this principle, we design SWAP-NET that models the interaction of key words and salient sentences using a new twolevel pointer network based architecture.",abstractText,[0],[0]
"SWAP-NET identifies both salient sentences and key words in an input document, and then combines them to form the extractive summary.",abstractText,[0],[0]
Experiments on large scale benchmark corpora demonstrate the efficacy of SWAP-NET that outperforms state-of-the-art extractive summarizers.,abstractText,[0],[0]
Extractive Summarization with SWAP-NET: Sentences and Words from Alternating Pointer Networks,title,[0],[0]
"Learning a ranking function based on pairwise comparisons has been studied extensively in recent years, with many successful applications in building search engines and other information retrieval tasks.",1. Introduction,[0],[0]
"Given a set of training instances with features x1, ...,xn and pairwise comparisons, the goal is to find the optimal decision function f(·) such that f(xi) > f(xj) if i is preferred over j. This is usually referred to as a learning-to-rank problem, and several algorithms have been proposed, including RankSVM (Herbrich et al., 1999),",1. Introduction,[0],[0]
"gradient boosting decision tree (Li et al., 2007), and many others (Cao et al., 2007; Yue et al., 2007;
1Department of Computer Science, University of California Davis, USA. 2Department of Statistics, University of California Davis, USA .",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Minhao Cheng <mhcheng@ucdavis.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Negahban et al., 2012; Wauthier et al., 2013).
",1. Introduction,[0],[0]
"However, in many modern applications, a single global ranking is not sufficient to represent the variety of individual users preferences.",1. Introduction,[0],[0]
"For example, in movie ranking systems, it is preferable to learn an individual ranking function for each user since users’ tastes can vary largely.",1. Introduction,[0],[0]
"The issue also arises in many other applications such as product recommendation, and personalized web search ranking.
",1. Introduction,[0],[0]
"Motivated by these real scenarios, we consider the problem of learning hundreds of thousands of ranking functions jointly, one for each user.",1. Introduction,[0],[0]
"Our target problem is different from collaborative ranking and BPR (Rendle et al., 2009; Wu et al., 2017a) since they only aim to recover ranking over existing items without using item features, while our goal is to obtain the ranking functions (taking item features as input) that can generalize to unseen items.",1. Introduction,[0],[0]
"This is also different from existing work on learning multiple ranking functions (i.e. (Qian et al., 2014))",1. Introduction,[0],[0]
because in that setting they are learning only several ranking functions.,1. Introduction,[0],[0]
"Here we focus on problems where the number of ranking functions T is very large (e.g.,100K) but the amount of data to learn each ranking function is limited.",1. Introduction,[0],[0]
"The naive extensions of learning to rank algorithms fail since the training time grows dramatically, and also due to the over-fitting problem because of insufficient number of pairs for training.
",1. Introduction,[0],[0]
"To resolve this dilemma, we propose the Factorization RankSVM model for learning multiple ranking functions jointly.",1. Introduction,[0],[0]
The main idea is to assume the T ranking functions can be represented by a dictionary of k ranking functions with k T .,1. Introduction,[0],[0]
"In the linear RankSVM case, this assumption implies a low-rank structure when we stack all the T linear hyper-planes together into a matrix.",1. Introduction,[0],[0]
"By exploiting this low rank structure, our algorithm can be efficient for both time and sample complexity.
",1. Introduction,[0],[0]
"Our contributions can be summarized as follows:
• We propose the Factorization RankSVM model for learning a large number of different ranking functions on different sets of data simultaneously.",1. Introduction,[0],[0]
"By exploiting the low-rank structure, we show that the gradient can be calculated very efficiently, and the resulting algorithm can scale to problems with large number of tasks.",1. Introduction,[0],[0]
"• We derive the generalization error bound of our model,
showing that by training all the T tasks jointly, the sample complexity is much better than training individual rankSVMs under the low rank assumption.",1. Introduction,[0],[0]
"• We conduct experiments on real world datasets, showing that the algorithm achieves higher accuracy and faster training time compared with state-of-the-art methods.",1. Introduction,[0],[0]
This is a critical result as it shows the low rank ranking conjecture that underlies our research does occur.,1. Introduction,[0],[0]
"• We further visualize the basic ranking functions learned by our algorithm, which has some interesting and meaningful patterns.",1. Introduction,[0],[0]
Learning to rank.,2. Related Work,[0],[0]
"Given a set of pairwise comparisons between instances and the feature vectors associated with each instance, the goal of learning to rank is to discover the ranking function.",2. Related Work,[0],[0]
"There are three main categories of learning to rank algorithms: pointwise (Li et al., 2007), listwise (Cao et al., 2007; Yue et al., 2007), and pairwise methods (Herbrich et al., 2000; Cao et al., 2006).",2. Related Work,[0],[0]
"In this paper, we mainly focus on pairwise methods, which process a pair of documents or entries at a time.",2. Related Work,[0],[0]
"Among all the pairwise methods, rankSVM is a very popular one, so we choose it as our basic model.
",2. Related Work,[0],[0]
We focus on the problem of solving T learning-to-rank problems jointly when the problems share the same feature space and there is some hidden correlation between tasks.,2. Related Work,[0],[0]
"Obviously, we could apply existing learning-to-rank algorithms to solve each task independently, but this approach has several major drawbacks, as will be discussed in next section.
",2. Related Work,[0],[0]
"Collaborative filtering and matrix factorization Lowrank approximation has been widely used in matrix completion and collaborative filtering (Koren et al., 2009), and there are several extensions for matrix completion (Weimer et al., 2007).",2. Related Work,[0],[0]
"However, these methods cannot be applied in our setting, since our predictions are based on item features, and the corresponding items may not even appear in the training data.",2. Related Work,[0],[0]
"To conduct prediction based on item features, the inductive matrix factorization model has been recently proposed in (Jain & Dhillon, 2013; Xu et al., 2013), and factorization machine (Rendle, 2010) also uses a similar model.",2. Related Work,[0],[0]
"However, this model only allows input to be user-item ratings, not the pairwise comparisons used in our problem.",2. Related Work,[0],[0]
"In the experiments, we observe that even if the rating data is available, our model still outperforms inductive matrix completion significantly.
",2. Related Work,[0],[0]
"Bayesian Personalized Ranking (Rendle et al., 2009) proposes Bayesian Personalized Ranking(BPR) method to solve personalized ranking task.",2. Related Work,[0],[0]
"However, there are several major differences with our work.",2. Related Work,[0],[0]
"First, our target problem
is different from BPR.",2. Related Work,[0],[0]
"We consider problems given both pairwise comparisons and “explicit” item features, and the goal is to learn the personalized ranking “functions” that can generalize to unseen items as long as we know their features.",2. Related Work,[0],[0]
"In comparison, the BPR does not take item features into account, and the goal of BPR is to recover the ranking among existing items.",2. Related Work,[0],[0]
"Also, the ranking cannot generalize to unseen items.",2. Related Work,[0],[0]
"Moreover, BPR considers implicit (0/1) feedback instead of explicit feedback.
",2. Related Work,[0],[0]
Collaborative Ranking is another line of research that incorporates ranking loss in collaborative filtering.,2. Related Work,[0],[0]
"(Park et al., 2015; Weimer et al., 2007; Wu et al., 2017a) combines the ranking loss with matrix completion model, and (Yun et al., 2014) also uses a low-rank model with ranking loss given a binary observed matrix.",2. Related Work,[0],[0]
"However, similar to matrix completion and BPR, these collaborative ranking approaches do not use the item features.",2. Related Work,[0],[0]
So they are not able to predict the preferences for unseen items.,2. Related Work,[0],[0]
"Also in this category, (Barjasteh et al., 2015) uses a trace norm to constraint ranking function, which is similar with our idea.",2. Related Work,[0],[0]
"However, they use implicit feedback which will lose certain information.
",2. Related Work,[0],[0]
"Multi-task Learning: has been extensively studied, especially in computer vision application.",2. Related Work,[0],[0]
"To model the shared information across tasks, a low-rank structure is widely assumed (Chen et al., 2012; 2009).",2. Related Work,[0],[0]
"(Hwang et al., 2011; Su et al., 2015) takes the attributes correlation as low-rank embeddings to learn SVM.",2. Related Work,[0],[0]
"However, our approach of learning basic ranking functions has not been discussed in the literature.
",2. Related Work,[0],[0]
A summary of the differences between our algorithm with others are showed in Table 1.,2. Related Work,[0],[0]
"Our goal is to learn multiple ranking functions together, one for each user.",3. Problem Setting,[0],[0]
"Assume there are in total T ranking functions to be learned (each one can be viewed as a task), and we are given pairwise comparisons for these ranking functions among n items with features x1,x2, . . .",3. Problem Setting,[0],[0]
",xn ∈ Rd.",3. Problem Setting,[0],[0]
"For each task i, the pairwise comparisons are denoted as Ωi = {(j, k)}, where (j, k) ∈",3. Problem Setting,[0],[0]
"Ωi means task i compares item j with k, and yijk ∈ {+1,−1} is the observed outcome.",3. Problem Setting,[0],[0]
"For convenience, we use Ω to denote the union of all Ωi.",3. Problem Setting,[0],[0]
"Given these pairwise comparisons, we aim to learn a set of linear ranking functions w1,w2, . . .",3. Problem Setting,[0],[0]
",wT ∈ Rd such that
sign(wTi (xj−xk))",3. Problem Setting,[0],[0]
"≈ yijk, ∀(j, k) ∈ Ωi, ∀i = 1, . . .",3. Problem Setting,[0],[0]
", T
The only assumption we make for these T ranking tasks is that the items involved in each task share the same feature space with d features.",3. Problem Setting,[0],[0]
"Note that our algorithm allows each task has non-overlapping items—in that case we can still gather all the items together, and define Ωi to be the comparisons within each task’s own item block.
",3. Problem Setting,[0],[0]
"This model can be easily deployed into recommendation systems where each user i has a corresponding ranking function and the items could be movies, music, goods etc.",3. Problem Setting,[0],[0]
Then the objective of the task is to learn a ranking function for each user i.,3. Problem Setting,[0],[0]
Note,3. Problem Setting,[0],[0]
that after obtaining wi for each,3. Problem Setting,[0],[0]
"i, we can predict the preference for any pairs of items xj ,xk even when they are “unseen items” that are not in the training set.",3. Problem Setting,[0],[0]
And most collaborative filtering approaches such as matrix completion cannot solve this problem.,3. Problem Setting,[0],[0]
"We are able to predict preferences on unseen items because we try to learn ranking functions based on features instead of just completing the rating matrix over “seen” items.
",3. Problem Setting,[0],[0]
"Naive approaches: For a single ranking function, (Herbrich et al., 1999) proposes the following RankSVM algorithm:
min w∈Rd
1 2",3. Problem Setting,[0],[0]
"‖w‖2 + C ∑ (i,j,k)∈Ω ξ2ijk
s.t. yijkwT",3. Problem Setting,[0],[0]
"(xj − xk) ≥ 1− ξijk, ξijk ≥ 0.",3. Problem Setting,[0],[0]
"∀i, j, k.
",3. Problem Setting,[0],[0]
"Here we use L2 hinge loss in our model, however it could be extended to L1 loss as well.",3. Problem Setting,[0],[0]
We can take RankSVM into multiple-user case by simply assuming that all ranking functions share a common w. We denote this method as RANKSVM JOINTLY.,3. Problem Setting,[0],[0]
"(Evgeniou & Pontil, 2004) provides a variation by assuming each ranking function to be wi = w + vi, where w is the centralized model and vi is the task-dependent variance.",3. Problem Setting,[0],[0]
"However, this algorithm follows the strong assumption that T ranking functions {wi}d1i=1 are all close to a single base function w. We call this algorithm RANKSVM VAR.",3. Problem Setting,[0],[0]
"This assumption is not always true in practice so that it will cause the model to under-fit training data (see our experimental results).
",3. Problem Setting,[0],[0]
"On the other hand, we can treat every user separately, which means we train every ranking function wi independently by solving the following problem for every i = 1, . . .",3. Problem Setting,[0],[0]
", T :
min wi
1 2 ‖wi‖2 + C ∑ (j,k)∈Ωi ξ2ijk
s.t. yijkwTi (xj − xk) ≥ 1− ξijk, ξijk ≥ 0,∀(j, k) ∈",3. Problem Setting,[0],[0]
"Ωi
We call this method as RANKSVM SEPARATELY.",3. Problem Setting,[0],[0]
It is obvious that this model has more freedom to fit the training data.,3. Problem Setting,[0],[0]
"However, due to the limited number of observed pairs Ωi per user, each wi has poor prediction quality due to over-fitting.",3. Problem Setting,[0],[0]
"We will analyze the sample complexity of RANKSVM SEPARATELY in Section 4, and experimental results in Section 5 also support our analysis.",3. Problem Setting,[0],[0]
"Our low rank personalized ranking conjecture assumes that all the T ranking functions can be well-approximated by a linear combination of k basic ranking functions, where k T .",4. Proposed Algorithm,[0],[0]
"This makes sense in many real applications; for example, in personalized recommender systems, there are group of users who have similar preferences.",4. Proposed Algorithm,[0],[0]
"Let {uj}kj=1 to be the basic (linear) ranking functions, we can linearly combine weight then using vi to obtain a ranking function for user i as follows: wi = ∑k j=1 vijuj for all i.",4. Proposed Algorithm,[0],[0]
"This can be written as W = UV T , where columns of W,U are wi and uj respectively, and V is the coefficients.",4. Proposed Algorithm,[0],[0]
"Therefore, W will be a rank-k matrix, which leads to the following nuclear norm regularized problem to enforce the low-rankness of W :
min W∈Rd×T
‖W‖∗ + C ∑
(i,j,k)∈Ω
ξ2ijk
s.t. yijkw T",4. Proposed Algorithm,[0],[0]
"i (xj − xk) ≥ 1− ξijk,
ξijk ≥ 0, ∀(i, j, k) ∈",4. Proposed Algorithm,[0],[0]
"Ω.
where || · ||∗ is the nuclear norm of matrix, defined by summation of singular values.",4. Proposed Algorithm,[0],[0]
"We could use some recent developed nuclear norm solvers to solve (4) (see (Cai et al., 2010; Hsieh & Olsen, 2014)).
",4. Proposed Algorithm,[0],[0]
"While the nuclear norm regularized formulation is statistically near optimal for recovering the underlying low-rank model, it cannot be efficiently solved since there are dT parameters in the problem.",4. Proposed Algorithm,[0],[0]
"Therefore, we solve the following
equivalent non-convex formulation:
min U,V
C ∑
(i,j,k)∈Ω
ξ2ijk + 1
2 (‖U‖2F + ‖V ‖2F )
s.t. yijkv̄Ti U T (xj − xk) ≥ 1− ξijk,
ξijk ≥ 0,∀(i, j, k) ∈",4. Proposed Algorithm,[0],[0]
"Ω. (1)
where we replace the nuclear norm regularization in Equation (4) using the property ‖W‖∗",4. Proposed Algorithm,[0],[0]
"= minW=UV T 12 (‖U‖ 2 F+ ‖V ‖2F ), U ∈ Rd×k, V ∈ RT×k, and v̄Ti is the i-th row of V .",4. Proposed Algorithm,[0],[0]
"With this non-convex relaxation, there are only (d+T )k parameters involved.",4. Proposed Algorithm,[0],[0]
"So it is preferred over the convex form.
",4. Proposed Algorithm,[0],[0]
"However, developing a fast solver for (1) is still nontrivial.",4. Proposed Algorithm,[0],[0]
"Although RankSVM is often solved in the dual space using stochastic dual coordinate ascent (SDCA) (ShalevShwartz & Zhang, 2013), in our case, it is not suitable because there are |Ω|k dual variables, where each corresponds to one constraint.",4. Proposed Algorithm,[0],[0]
So applying a dual coordinate ascent will take O(|Ωk|) time complexity (to go through all dual variables) and the same order of memory complexity to store all of them.,4. Proposed Algorithm,[0],[0]
"Therefore, we solve the problem in the primal space using alternating minimization.",4. Proposed Algorithm,[0],[0]
"Instead of solving the constrained form, we solve the following equivalent unconstrained problem:
min U,V
{ C ∑ (i,j,k)∈Ω max(0, 1− yijkv̄Ti UT (xj − xk))2
+ 1
2 (‖U‖2F + ‖V ‖2F )
} := f(U, V ).
",4. Proposed Algorithm,[0],[0]
"(2)
Following the alternating minimization scheme, our algorithm iteratively updates one ofU, V while keeping the other one fixed.",4. Proposed Algorithm,[0],[0]
"When updating U with V fixed, the subproblem becomes:
U = argmin U∈Rd×k
C ∑
(i,j,k)∈Ω
max(0, 1− yijkv̄Ti UT (xj − xk))2
+ 1
2 ‖U‖2F .
",4. Proposed Algorithm,[0],[0]
"(3) To solve the problem in the primal space, the main bottleneck is the gradient computation when we apply gradient descent.",4. Proposed Algorithm,[0],[0]
"The gradient can be written as
∇Uf(U, V ) = U+ T∑ i=1",4. Proposed Algorithm,[0],[0]
"∑ (j,k)∈Ωi −2Cyijk max ( 0, 1− yijkv̄Ti UT (xj − xk) ) (xj − xk)v̄Ti
(4) Computing (4) naively takes O(|Ω|kd) time, since we need to go through the summation, and each term requires O(kd) computing time for computing (xj − xk)v̄Ti .",4. Proposed Algorithm,[0],[0]
"However, by re-organizing the computation using a book-keeping technique, we are able to do this in O(T n̄k + dkn + |Ω|)
",4. Proposed Algorithm,[0],[0]
Algorithm 1 Factorization RankSVM:,4. Proposed Algorithm,[0],[0]
"Computing ∇Uf(U, V )
",4. Proposed Algorithm,[0],[0]
"Input: X,V,Ω, Y Compute pj = U
Txj and set zj = 0 for all j = 1, . . .",4. Proposed Algorithm,[0],[0]
", n",4. Proposed Algorithm,[0],[0]
"for i = 1, 2, . . .",4. Proposed Algorithm,[0],[0]
", T do
Compute qj =",4. Proposed Algorithm,[0],[0]
"v̄ T i pj for all j ∈ Ωi Set sj = 0 for all j ∈ Ωi for (j, k) ∈",4. Proposed Algorithm,[0],[0]
Ωi do sj ← sj,4. Proposed Algorithm,[0],[0]
"− 2Cyijk max(0, 1− yijk(qj − qk))",4. Proposed Algorithm,[0],[0]
"sk ← sk + 2Cyijk max(0, 1− yijk(qj − qk)) end for zj ← zj + sjvi for all j ∈ Ωi
end for for j = 1, 2, . . .",4. Proposed Algorithm,[0],[0]
", n do ∇Uf(U, V )← ∇Uf(U, V ) + xjzTj end for Output ∇Uf(U, V ) +",4. Proposed Algorithm,[0],[0]
"U
time, where n̄ is the average number of ratings per user.",4. Proposed Algorithm,[0],[0]
"The details are presented in Algorithm 1.
",4. Proposed Algorithm,[0],[0]
"For updating V , the objective function (1) can be decomposed into T subproblems:
v̄i = argmin v̄i∈Rk
C ∑
(j,k)∈Ωi
max(0, 1− yijkv̄Ti UT (xj − xk))2
+ 1
2 ‖vi‖22,
(5) where each of them is just an RankSVM problem that can be easily solved by gradient descent or Newton method (Chapelle & Keerthi, 2010).",4. Proposed Algorithm,[0],[0]
"The details are omitted here, but the time complexity for this part isO(T n̄k+dkn+ |Ω|), which is exactly the same with the U part.
",4. Proposed Algorithm,[0],[0]
"To sum up, our algorithm has an overall time complexity O(T n̄k + dkn+ |Ω|) per iteration, which is quite small because the dominated term |Ω| (number of pairs) is separated from rest of the terms.",4. Proposed Algorithm,[0],[0]
"Also, k (rank) and n̄ (averaged items involves in a ranking task) are usually small.",4. Proposed Algorithm,[0],[0]
"Furthermore, we could adapt Newton method proposed by (Wu et al., 2017b) to further speed up the optimization.",4. Proposed Algorithm,[0],[0]
"As a result, we are able to scaleto very large datasets.",4. Proposed Algorithm,[0],[0]
Now we analyze the sample complexity of the proposed model.,5. Sample Complexity Analysis,[0],[0]
"If we keep growing T (number of ranking functions), under the low-rank assumptionW = O(T 1/2), the samples needed for Factorization RankSVM to achieve the same -error is approximately O(T 1/2), which is much better than training T individual RankSVMs which requires O(T ) samples.",5. Sample Complexity Analysis,[0],[0]
"Detailed proofs can be found in the appendix.
",5. Sample Complexity Analysis,[0],[0]
"Sample complexity of our model
Assume we observe a set of (i, j, k) pairs and comparison results yijk ∈ {+1,−1} from a fixed but unknown distribution.",5. Sample Complexity Analysis,[0],[0]
"To recover the underlying model, we proposed to solve (4), and it is equivalent to the constraint form:
Ŵ = arg min W∈Rd×T ∑",5. Sample Complexity Analysis,[0],[0]
(,5. Sample Complexity Analysis,[0],[0]
"i,j,k)∈Ω `((ITi W T (xj − xk)), yijk),
s.t. ‖W‖∗ ≤",5. Sample Complexity Analysis,[0],[0]
"W, (6)
where I ∈ RT×T is the indicator matrix, each column Ii is [0, 0, ..., 1, 0, 0] where the i-th element equals to one.",5. Sample Complexity Analysis,[0],[0]
"Without loss of generality, we assume ‖xj‖ ≤ 1 for all j. The prediction function we want to learn is
fW",5. Sample Complexity Analysis,[0],[0]
"(i, j, k) =",5. Sample Complexity Analysis,[0],[0]
I T,5. Sample Complexity Analysis,[0],[0]
"i W T (xj − xk) = 〈W, (xj − xk)ITi 〉,
and in our formulation (6), we search within the function class FW := {fW : ‖W‖∗ ≤ W}.
",5. Sample Complexity Analysis,[0],[0]
"The quality of any ranking function fW can be measured by the following expected ranking error (where 1(·) is the indicator function):
R(f) := Ei,j,k[1 ( sign(f(i, j, k))",5. Sample Complexity Analysis,[0],[0]
6= sign(yijk) ),5. Sample Complexity Analysis,[0],[0]
].,5. Sample Complexity Analysis,[0],[0]
"(7)
We denote R∗ = minf R(f) to be the optimal risk we can get.",5. Sample Complexity Analysis,[0],[0]
"Since optimizing 0/1 loss is hard, our algorithm uses a convex surrogate loss `, and the following concepts of `-risk will be used in our analysis:
• Expected `-risk: R`(f) =",5. Sample Complexity Analysis,[0],[0]
"Ei,j,k[`(f(i, j, k), yijk)]",5. Sample Complexity Analysis,[0],[0]
"• Empirical `-risk: R̂`(f) = 1 m ∑ (i,j,k)∈Ω `(f(i, j, k), yijk)
",5. Sample Complexity Analysis,[0],[0]
"We begin with the following lemma to bound the expected `-risk:
Lemma 1 (Bound on Expected `-risk (Bartlett & Mendelson, 2002)).",5. Sample Complexity Analysis,[0],[0]
"Assume `(·, ·) is a loss function upper bounded by B and with Lipschitz constant L` with respect to its first argument.",5. Sample Complexity Analysis,[0],[0]
"Let R(FW ) be the model complexity of the function class FW (w.r.t Ω and associated with `) defined as:
R(FW ) =",5. Sample Complexity Analysis,[0],[0]
"Eσ[ sup f∈FW
1
m ∑ (i,j,k)∈Ω σα`(f(i, j, k), yijk)],
(8) where each σα takes values {±1} with equal probability.",5. Sample Complexity Analysis,[0],[0]
"Then with probability at least 1 − δ, for all f ∈ FW , we have
R`(f) ≤ R̂`(f) + 2EΩ[R(FW )]",5. Sample Complexity Analysis,[0],[0]
"+ B √ log 1δ 2m .
",5. Sample Complexity Analysis,[0],[0]
"To achieve an upper bound for R`(f), we derive a bound of the Radamacker complexity EΩ[R(FW )]:
Lemma 2.",5. Sample Complexity Analysis,[0],[0]
"The model complexity of (6) can be upper bounded by:
EΩ[R(FW )]",5. Sample Complexity Analysis,[0],[0]
"≤ min { 2L`W √ log 2d
m ,
√ 9L`BCW( √ T + n)
m
} ,
(9) where L` is the Lipchitz constant of loss function and C is a universal constant.
",5. Sample Complexity Analysis,[0],[0]
"With the above lemma, we now derive the following theorem to bound the expected ranking error:
Theorem 1.",5. Sample Complexity Analysis,[0],[0]
"With probability 1− δ, the expected error of the optimal solution of our model (6) is:
R(fŴ )−R ∗ ≤O(R̂`(fŴ )−R ∗ ` )",5. Sample Complexity Analysis,[0],[0]
"+O(B
√ log(1/δ)
",5. Sample Complexity Analysis,[0],[0]
"m )
",5. Sample Complexity Analysis,[0],[0]
"+O( min(
√ WB(
√ T + n),W log d) √ m ),
(10) where R∗ = inff R(f) and R∗` := inff R`(f).
",5. Sample Complexity Analysis,[0],[0]
Note that all the hidden constants can be found in the appendix.,5. Sample Complexity Analysis,[0],[0]
"In general, the first term on the right hand side will be small since fŴ minimizes the empirical error.",5. Sample Complexity Analysis,[0],[0]
"This is a standard generalization error bound (as shown in (Kakade et al., 2009))",5. Sample Complexity Analysis,[0],[0]
"that works for any distribution of yijk.
",5. Sample Complexity Analysis,[0],[0]
"If we further assume the yijk is generated from an unseen groudtruth W ∗ with ‖W∗‖∗ ≤ W , then the following theorem shows that the error is small when m goes to infinity:
Lemma 3.",5. Sample Complexity Analysis,[0],[0]
"If the observed yijk = xTj w∗i − xTkw∗i for all i, j, k, and loss function satisfies `(a, b) = 0 if sign(a) = sign(b), then we have R(fŴ ) ≤
O( min( √ WB( √ T+n),W log d)√ m )",5. Sample Complexity Analysis,[0],[0]
+,5. Sample Complexity Analysis,[0],[0]
"O(B √ log(1/δ) m ).
",5. Sample Complexity Analysis,[0],[0]
"Note that the loss `(a, y) = max(−ay, 0)2 satisfies the assumption of Lemma 3, but in practice adding a margin will improve the performance (using `(a, y) = max(1−ay, 0)2).",5. Sample Complexity Analysis,[0],[0]
"From Theorem 1 and Lemma 3, we can conclude that the error of our model decreases roughly with 1/ √ m (m is number of samples), and increases with √ W (nuclear norm of the underlying model).
",5. Sample Complexity Analysis,[0],[0]
"Comparison with RANKSVM SEPARATELY.
",5. Sample Complexity Analysis,[0],[0]
"Training T independent RankSVMs separately can also achieve arbitrary small error under similar condition, so the main question is whether our model can reduce the number of samplesm needed.",5. Sample Complexity Analysis,[0],[0]
"In RANKSVM SEPARATELY, it is equivalent to solving problem (6) with the constraint replaced by ‖wi‖ ≤",5. Sample Complexity Analysis,[0],[0]
w,5. Sample Complexity Analysis,[0],[0]
"for all i. Assume there are m/T pairs per ranking function, then we can prove the following sample complexity based on standard analysis from (Kakade et al., 2009):
Lemma 4.",5. Sample Complexity Analysis,[0],[0]
"Under the same condition of Lemma 3, the RANKSVM SEPARATELY solution f̃ satisfies
R(f̃) =",5. Sample Complexity Analysis,[0],[0]
O( w√ m/T ),5. Sample Complexity Analysis,[0],[0]
"+O(B
√ log(1/δ)
m/T ).
",5. Sample Complexity Analysis,[0],[0]
"Note that we assumeW := ‖W ∗‖∗ and w := maxi ‖W ∗:,i‖ where W ∗ is the underlying matrix.",5. Sample Complexity Analysis,[0],[0]
"Clearly, if the nuclear norm W is small constant, our sample complexity (Lemma 3) is much better than the bound for RANKSVM SEPARATELY (Lemma 4), since our dependency to T is O(T 1/4) while it is O( √ T ) for rankSVM.",5. Sample Complexity Analysis,[0],[0]
"Moreover, in another setting (see, for example, (Shamir & Shalev-Shwartz, 2014)), if each element of W ∗ is bounded and rank of W ∗ is a constant,W = O( √ Td) and w =",5. Sample Complexity Analysis,[0],[0]
"O( √ d), our bound in Lemma 3 is still better than Lemma 4.",5. Sample Complexity Analysis,[0],[0]
"Although a better sample complexity upper bound doesnt directly imply our method is always better, however, by obtaining a smaller Rademacher complexity, it is clear that our formulation has benefits to achieve a tighter upper bounds, which leads to better performance in practice.",5. Sample Complexity Analysis,[0],[0]
"In this section, we show our method outperforms other algorithms on both synthetic and real datasets.",6. Experimental Results,[0],[0]
"All the experiments are conducted on a server with an Intel E7-4820 CPU and 256G memory.
",6. Experimental Results,[0],[0]
Experimental Setting.,6. Experimental Results,[0],[0]
"For each ranking task, we randomly split the items into training items and testing items.",6. Experimental Results,[0],[0]
"In the training phase, we use all the pairs between training items to train the model, and in the testing phase we evaluate the prediction accuracy for all the testing-testing item pairs and testing-training item pairs, which is similar with BPR (Rendle et al., 2009).",6. Experimental Results,[0],[0]
"The accuracy is defined to be the correctly predicted pairs divided by total number of predicted pairs.
",6. Experimental Results,[0],[0]
"We mainly compare our algorithm with RANKSVM JOINTLY (training a single rankSVM model), RANKSVM SEPARATELY (training an individual rankSVM model for each task), and RANKSVM VAR (the multi-task rankSVM model proposed in (Evgeniou & Pontil, 2004)).",6. Experimental Results,[0],[0]
All the algorithm above are using square hinge loss in the experiments.,6. Experimental Results,[0],[0]
"We choose the best regularization parameter for each method by a validation set.
",6. Experimental Results,[0],[0]
Synthetic Data.,6. Experimental Results,[0],[0]
"For synthetic dataset, we assume there are 1, 000 tasks, 10, 000 items and each item has 64 features.",6. Experimental Results,[0],[0]
"The underlying ranking models are generated by W ∗ = U∗(V ∗)T , where U∗ ∈ R64×20, V ∗ ∈ R1000,20, and U, V ∼ N (0, 1).",6. Experimental Results,[0],[0]
"The feature matrix is generated by X ∈ R64×10,000, X ∼ N (0, 1).",6. Experimental Results,[0],[0]
"We sample 800 pairs for each user as training data, with labels based on underlying
rating R = (W ∗)TX .
",6. Experimental Results,[0],[0]
Table 2 shows that our algorithms outperform other rankSVM algorithms on synthetic datasets.,6. Experimental Results,[0],[0]
"Also, as showed in Figure 1, We observe that RANKSVM JOINTLY suffers from under-fitting (low training and test accuracy).",6. Experimental Results,[0],[0]
"On the other hand, RANKSVM SEPARATELY has the over-fitting problem (high training accuracy but low test accuracy) since it does not have enough samples for learning each individual task.",6. Experimental Results,[0],[0]
"Since the underlying U, V have rank 20, our model with rank 20 performs the best.",6. Experimental Results,[0],[0]
"However, even if we choose rank to be 10 or 30, our model still significantly outperforms the other models.
",6. Experimental Results,[0],[0]
Real World Datasets.,6. Experimental Results,[0],[0]
We use recommender system as an application to compare our algorithm with other ranking algorithms.,6. Experimental Results,[0],[0]
"Each user is treated as a “ranking task”, and the observed pairs are generated from training ratings.",6. Experimental Results,[0],[0]
"Note that we are also given item features x1, . . .",6. Experimental Results,[0],[0]
",xn, and the goal is to learn a personalized ranking model wi for each user.",6. Experimental Results,[0],[0]
"The testing items are unseen in the training phase, which is different from classical matrix completion problem—the goal of classical matrix completion is to complete the matrix, while our goal is to learn the function that can generalize to unseen items.",6. Experimental Results,[0],[0]
"The only matrix completion work that can utilize the feature information to predict unseen items is inductive matrix completion (Jain & Dhillon, 2013) (IMC), which is a special case of factorization machine (Rendle, 2010).",6. Experimental Results,[0],[0]
"Although they do not allow pairwise comparisons as input, for the completeness of comparison, we still include them into comparison and give them the original rating data as input.
",6. Experimental Results,[0],[0]
We choose three datasets in our real-world application experiments: (1) Yahoo!,6. Experimental Results,[0],[0]
"Movies User Ratings and Descriptive Content Information V1 01 (2) HetRec2011-MovieLens-2K (Cantador et al., 2011).",6. Experimental Results,[0],[0]
"(3) MovieLens 20M Dataset (Harper
1http://research.yahoo.com/Academic Relations
& Konstan, 2016).",6. Experimental Results,[0],[0]
"For the first dataset, we use the title and abstract of each movie and combine them as the feature matrix X .",6. Experimental Results,[0],[0]
"For the second and third datasets, we take the genres information of each movie as features.",6. Experimental Results,[0],[0]
"See Table3 for more information.
",6. Experimental Results,[0],[0]
The results for datasets (1) and (2) are presented in Table4.,6. Experimental Results,[0],[0]
"Clearly, our method outperforms other algorithms both in accuracy and in speed.",6. Experimental Results,[0],[0]
"Note that dataset (1) has dense features and dataset (2) has sparse features, and our algorithm performs well in both cases.",6. Experimental Results,[0],[0]
"For dataset (3), there are more than 100,000 ranking tasks and other algorithms take more than 1000 seconds per epoch.",6. Experimental Results,[0],[0]
"However, our algorithm only takes about 100 seconds per epoch, and converges to a solution with 63.4% testing accuracy.
",6. Experimental Results,[0],[0]
We also plot the time vs accuracy curves in Figure Our algorithms consistently get better accuracy compared to all other methods.,6. Experimental Results,[0],[0]
"Note that sometimes RANKSVM JOINTLY is fast in the beginning, but eventually it cannot converge to a good solution.",6. Experimental Results,[0],[0]
Visualize basic ranking functions.,6.1. Feature Embedding,[0],[0]
"Finally, we visualize the basic ranking functions learned by our model.",6.1. Feature Embedding,[0],[0]
"We take the Yahoo! movie dataset, where each feature corresponds
to a word in movie title and abstract.",6.1. Feature Embedding,[0],[0]
"We select a basic ranking function (a column of U ) from our model and show the top 25 features with most positive weights and bottom 25 features with most negative weights in Figure 2, 3.",6.1. Feature Embedding,[0],[0]
The visualization of ranking function clearly demonstrates interesting common patterns of users’ tastes.,6.1. Feature Embedding,[0],[0]
We propose a new algorithm for learning multiple ranking functions based on the combination of RankSVM and matrix factorization.,7. Conclusions,[0],[0]
"We show that the model can be solved efficiently, has good statistical guarantee, and outperforms other methods on real datasets in both training time and prediction accuracy.",7. Conclusions,[0],[0]
Our algorithm can be used in many online personalized ranking systems.,7. Conclusions,[0],[0]
"An interesting direction is to introduce non-linearity (e.g., neural networks) in the feature side of our model and learn U, V with neural network weights jointly.",7. Conclusions,[0],[0]
Cho-Jui Hsieh and Minhao Cheng acknowledge the support of NSF via IIS-1719097 and the computing resources provided by Google cloud and Nvidia.,Acknowledgments,[0],[0]
We consider the setting where we wish to perform ranking for hundreds of thousands of users which is common in recommender systems and web search ranking.,abstractText,[0],[0]
Learning a single ranking function is unlikely to capture the variability across all users while learning a ranking function for each person is time-consuming and requires large amounts of data from each user.,abstractText,[0],[0]
"To address this situation, we propose a Factorization RankSVM algorithm which learns a series of k basic ranking functions and then constructs for each user a local ranking function that is a combination of them.",abstractText,[0],[0]
"We develop a fast algorithm to reduce the time complexity of gradient descent solver by exploiting the low-rank structure, and the resulting algorithm is much faster than existing methods.",abstractText,[0],[0]
"Furthermore, we prove that the generalization error of the proposed method can be significantly better than training individual RankSVMs.",abstractText,[0],[0]
"Finally, we present some interesting patterns in the principal ranking functions learned by our algorithms.",abstractText,[0],[0]
Extreme Learning to Rank via Low Rank Assumption,title,[0],[0]
"The success stories of deep learning form an ever lengthening list of practical breakthroughs and state-ofthe-art performances, ranging the fields of computer vision [23, 14, 25, 33], audio and natural language processing and generation [5, 15, 11, 34], as well as robotics [24, 26], to name just a few.",1 Introduction,[0],[0]
"The list of success stories can be matched and surpassed by a list of practical “tips and tricks”, from different optimization algorithms, parameter tuning methods [30, 22], initialization schemes [10], architecture designs [31], loss functions, data augmentation [23] and so on.
",1 Introduction,[0],[0]
The current theoretical understanding of deep learning is far from being sufficient for a rigorous analysis of the difficulties faced by practitioners.,1 Introduction,[0],[0]
"Progress must be made from both parties: from a practitioner’s perspective, emphasizing the difficulties provides practical insights to the theoretician, which in turn, supplies theoretical insights and guarantees, further strengthening and sharpening practical intuitions and wisdom.",1 Introduction,[0],[0]
"In particular, understanding failures of existing algorithms is as important as understanding where they succeed.
",1 Introduction,[0],[0]
Our goal in this paper is to present and discuss families of simple problems for which commonly used methods do not show as exceptional a performance as one might expect.,1 Introduction,[0],[0]
"We use empirical results and insights as a ground on which to build a theoretical analysis, characterising the sources of failure.",1 Introduction,[0],[0]
"Those understandings are aligned, and sometimes lead to, different approaches, either for an architecture, loss function, or an optimization scheme, and explain their superiority when applied to members of those families.",1 Introduction,[0],[0]
"Interestingly, the sources for failure in our experiment do not seem to relate to stationary point issues such as spurious local minima or a plethora of saddle points, a topic of much recent interest (e.g. [6, 3]),
1This paper was done with the support of the Intel Collaborative Research institute for Computational Intelligence (ICRI-CI) and is part of the “Why & When Deep Learning works – looking inside Deep Learning” ICRI-CI paper bundle
ar X
iv :1
70 3.
07 95
0v 2
[ cs
.L",1 Introduction,[0],[0]
"G
] 2
6 A
pr 2
but rather to more subtle issues, having to do with informativeness of the gradients, signal-to-noise ratios, conditioning etc.",1 Introduction,[0],[0]
"The code for running all our experiments is available online2.
",1 Introduction,[0],[0]
"We start off in Section 2 by discussing a class of simple learning problems for which the gradient information, central to deep learning algorithms, provably carries negligible information on the target function which we attempt to learn.",1 Introduction,[0],[0]
"This result is a property of the learning problems themselves, and holds for any specific network architecture one may choose for tackling the learning problem, implying that no gradientbased method is likely to succeed.",1 Introduction,[0],[0]
"Our analysis relies on tools and insights from the Statistical Queries literature, and underscores one of the main deficiencies of Deep Learning: its reliance on local properties of the loss function, with the objective being of a global nature.
",1 Introduction,[0],[0]
"Next, in Section 3, we tackle the ongoing dispute between two common approaches to learning.",1 Introduction,[0],[0]
"Most, if not all, learning and optimization problems can be viewed as some structured set of sub-problems.",1 Introduction,[0],[0]
"The first approach, which we refer to as the “end-to-end” approach, will tend to solve all of the sub-problems together in one shot, by optimizing a single primary objective.",1 Introduction,[0],[0]
"The second approach, which we refer to as the “decomposition” one, will tend to handle these sub-problems separately, solving each one by defining and optimizing additional objectives, and not rely solely on the primary objective.",1 Introduction,[0],[0]
"The benefits of the end-to-end approach, both in terms of requiring a smaller amount of labeling and prior knowledge, and perhaps enabling more expressive architectures, cannot be ignored.",1 Introduction,[0],[0]
"On the other hand, intuitively and empirically, the extra supervision injected through decomposition is helpful in the optimization process.",1 Introduction,[0],[0]
"We experiment with a simple problem in which application of the two approaches is possible, and the distinction between them is clear and intuitive.",1 Introduction,[0],[0]
"We observe that an end-to-end approach can be much slower than a decomposition method, to the extent that, as the scale of the problem grows, no progress is observed.",1 Introduction,[0],[0]
"We analyze this gap by showing, theoretically and empirically, that the gradients are much more noisy and less informative with the end-to-end approach, as opposed to the decomposition approach, explaining the disparity in practical performance.
",1 Introduction,[0],[0]
"In Section 4, we demonstrate the importance of both the network’s architecture and the optimization algorithm on the training time.",1 Introduction,[0],[0]
"While the choice of architecture is usually studied in the context of its expressive power, we show that even when two architectures have the same expressive power for a given task, there may be a tremendous difference in the ability to optimize them.",1 Introduction,[0],[0]
We analyze the required runtime of gradient descent for the two architectures through the lens of the condition number of the problem.,1 Introduction,[0],[0]
We further show that conditioning techniques can yield additional orders of magnitude speedups.,1 Introduction,[0],[0]
The experimental setup in this section is around a seemingly simple problem — encoding a piece-wise linear one-dimensional curve.,1 Introduction,[0],[0]
"Despite the simplicity of this problem, we show that following the common rule of “perhaps I should use a deeper/wider network”3 does not significantly help here.
",1 Introduction,[0],[0]
"Finally, in Section 5, we consider deep learning’s reliance on “vanilla” gradient information for the optimization process.",1 Introduction,[0],[0]
We previously discussed the deficiency of using a local property of the objective in directing global optimization.,1 Introduction,[0],[0]
"Here, we focus on a simple case in which it is possible to solve the optimization problem based on local information, but not in the form of a gradient.",1 Introduction,[0],[0]
"We experiment with architectures that contain activation functions with flat regions, which leads to the well known vanishing gradient problem.",1 Introduction,[0],[0]
"Practitioners take great care when working with such activation functions, and many heuristic tricks are applied in order to initialize the network’s weights in non-flat areas of its activations.",1 Introduction,[0],[0]
"Here, we show that by using a different update rule, we manage to solve the learning problem efficiently.",1 Introduction,[0],[0]
"Moreover, one can show convergence guarantees for a family of such functions.",1 Introduction,[0],[0]
"This provides a clean example where non-gradient-based optimization schemes can overcome the limitations of gradient-based
2 https://github.com/shakedshammah/failures_of_DL.",1 Introduction,[0],[0]
"See command lines in Appendix D. 3See http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/ for the inspiration behind this quote.
learning.",1 Introduction,[0],[0]
"Most existing deep learning algorithms are gradient-based methods; namely, algorithms which optimize an objective through access to its gradient w.r.t.",2 Parities and Linear-Periodic Functions,[0],[0]
"some weight vector w, or estimates of the gradient.",2 Parities and Linear-Periodic Functions,[0],[0]
"We consider a setting where the goal of this optimization process is to learn some underlying hypothesis class H, of which one member, h ∈ H, is responsible for labelling the data.",2 Parities and Linear-Periodic Functions,[0],[0]
"This yields an optimization problem of the form
min w Fh(w).
",2 Parities and Linear-Periodic Functions,[0],[0]
The underlying assumption is that the gradient of the objective w.r.t.,2 Parities and Linear-Periodic Functions,[0],[0]
"w, ∇Fh(w), contains useful information regarding the target function h, and will help us make progress.
",2 Parities and Linear-Periodic Functions,[0],[0]
"Below, we discuss a family of problems for which with high probability, at any fixed point, the gradient, ∇Fh(w), will be essentially the same regardless of the underlying target function h.",2 Parities and Linear-Periodic Functions,[0],[0]
"Furthermore, we prove that this holds independently of the choice of architecture or parametrization, and using a deeper/wider network will not help.",2 Parities and Linear-Periodic Functions,[0],[0]
"The family we study is that of compositions of linear and periodic functions, and we experiment with the classical problem of learning parities.",2 Parities and Linear-Periodic Functions,[0],[0]
"Our empirical and theoretical study shows that indeed, if there’s little information in the gradient, using it for learning cannot succeed.",2 Parities and Linear-Periodic Functions,[0],[0]
"We begin with the simple problem of learning random parities: After choosing some v∗ ∈ {0, 1}d uniformly at random, our goal is to train a predictor mapping x ∈ {0, 1}d to y = (−1)〈x,v∗〉, where x is uniformly distributed.",2.1 Experiment,[0],[0]
"In words, y indicates whether the number of 1’s in a certain subset of coordinates of x (indicated by v∗) is odd or even.
",2.1 Experiment,[0],[0]
"For our experiments, we use the hinge loss, and a simple network architecture of one fully connected layer of width 10d > 3d2 with ReLU activations, and a fully connected output layer with linear activation and a single unit.",2.1 Experiment,[0],[0]
"Note that this class realizes the parity function corresponding to any v∗ (see Lemma 5 in the appendix).
",2.1 Experiment,[0],[0]
"Empirically, as the dimension d increases, so does the difficulty of learning, which can be measured in the accuracy we arrive at after a fixed number of training iterations, to the point where around d = 30, no advance beyond random performance is observed after reasonable time.",2.1 Experiment,[0],[0]
Figure 1 illustrates the results.,2.1 Experiment,[0],[0]
"To formally explain the failure from a geometric perspective, consider the stochastic optimization problem associated with learning a target function h,
min w Fh(w) :",2.2 Analysis,[0],[0]
= E x,2.2 Analysis,[0],[0]
"[`(pw(x), h(x))] , (1)
where ` is a loss function, x are the stochastic inputs (assumed to be vectors in Euclidean space), and pw is some predictor parametrized by a parameter vector",2.2 Analysis,[0],[0]
w,2.2 Analysis,[0],[0]
(e.g. a neural network of a certain architecture).,2.2 Analysis,[0],[0]
We will assume that F is differentiable.,2.2 Analysis,[0],[0]
"A key quantity we will be interested in studying is the variance of the
gradient of F with respect to h, when h is drawn uniformly at random from a collection of candidate target functionsH:
Var(H, F,w) =",2.2 Analysis,[0],[0]
E h ∥∥∥∥∇Fh(w)− Eh′∇Fh′(w),2.2 Analysis,[0],[0]
"∥∥∥∥2 (2)
Intuitively, this measures the expected amount of “signal” about the underlying target function contained in the gradient.",2.2 Analysis,[0],[0]
"As we will see later, this variance correlates with the difficulty of solving (1) using gradientbased methods4.
",2.2 Analysis,[0],[0]
"The following theorem bounds this variance term.
",2.2 Analysis,[0],[0]
"Theorem 1 Suppose that
• H consists of real-valued functions h satisfying Ex[h2(x)]",2.2 Analysis,[0],[0]
"≤ 1, such that for any two distinct h, h′ ∈ H, Ex[h(x)h′(x)]",2.2 Analysis,[0],[0]
"= 0.
• pw(x) is differentiable w.r.t.",2.2 Analysis,[0],[0]
"w, and satisfies Ex [ ‖ ∂∂wpw(x)‖ 2 ] ≤",2.2 Analysis,[0],[0]
"G(w)2 for some scalar G(w).
",2.2 Analysis,[0],[0]
•,2.2 Analysis,[0],[0]
"The loss function ` in (1) is either the square loss `(ŷ, y) = 12(ŷ − y) 2 or a classification loss of the
form `(ŷ, y) =",2.2 Analysis,[0],[0]
"r(ŷ ·y) for some 1-Lipschitz function r, and the target function h takes values in {±1}.
",2.2 Analysis,[0],[0]
"Then
Var(H, F,w) ≤ G(w) 2
|H| .
",2.2 Analysis,[0],[0]
The proof is given in Appendix B.1.,2.2 Analysis,[0],[0]
"The theorem implies that if we try to learn an unknown target function, possibly coming from a large collection of uncorrelated functions, then the sensitivity of the gradient to the target function at any point decreases linearly with |H|.
",2.2 Analysis,[0],[0]
"Before we make a more general statement, let us return to the case of parities, and study it through the lens of this framework.",2.2 Analysis,[0],[0]
"Suppose that our target function is some parity function chosen uniformly at random, i.e. a random element from the set of 2d functions H = {x 7→",2.2 Analysis,[0],[0]
"(−1)〈x,v∗〉 : v∗ ∈ {0, 1}d}.",2.2 Analysis,[0],[0]
"These
4This should not be confused with the variance of gradient estimates used by SGD, which we discuss in Section 3.
",2.2 Analysis,[0],[0]
"are binary functions, which are easily seen to be mutually orthogonal:",2.2 Analysis,[0],[0]
"Indeed, for any v,v′,
E x
[ (−1)〈x,v〉(−1)〈x,v′〉 ] = E
x
[ (−1)〈x,v+v′〉 ] =
d∏ i=1",2.2 Analysis,[0],[0]
E [ (−1)xi(vi+v′i) ] = d∏ i=1,2.2 Analysis,[0],[0]
"(−1)vi+v′i + (−1)−(vi+v′i) 2
which is non-zero if and only if v = v′. Therefore, by Theorem 1, we get that Var(H, F,w) ≤ G(w)2/2d – that is, exponentially small in the dimension d. By Chebyshev’s inequality, this implies that the gradient at any point w will be extremely concentrated around a fixed point independent of h.
This phenomenon of exponentially-small variance can also be observed for other distributions, and learning problems other than parities.",2.2 Analysis,[0],[0]
"Indeed, in [29], it was shown that this also holds in a more general setup, when the output y corresponds to a linear function composed with a periodic one, and the input x is sampled from a smooth distribution:
Theorem 2 (Shamir 2016)",2.2 Analysis,[0],[0]
"Let ψ be a fixed periodic function, and let H = {x 7→ ψ(v∗>x) : ‖v∗‖ = r} for some r > 0.",2.2 Analysis,[0],[0]
"Suppose x ∈ Rd is sampled from an arbitrary mixture of distributions with the following property: The square root of the density function ϕ has a Fourier transform ϕ̂ satisfying ∫ x:‖x‖>r ϕ̂
2(x)dx∫ x ϕ̂ 2(x)dx ≤
exp(−Ω(r)).",2.2 Analysis,[0],[0]
"Then if F denotes the objective function with respect to the squared loss,
Var(H, F,w) ≤ O (exp(−Ω(d))",2.2 Analysis,[0],[0]
"+ exp(−Ω(r))) .
",2.2 Analysis,[0],[0]
"The condition on the Fourier transform of the density is generally satisfied for smooth distributions (e.g. arbitrary Gaussians whose covariance matrices are positive definite, with all eigenvalues at least Ω(1/r)).",2.2 Analysis,[0],[0]
"Thus, the bound is extremely small as long as the norm r and the dimension d are moderately large, and indicates that the gradients contains little signal on the underlying target function.
",2.2 Analysis,[0],[0]
"Based on these bounds, one can also formally prove that a gradient-based method, under a reasonable model, will fail in returning a reasonable predictor, unless the number of iterations is exponentially large in r and d 5 .",2.2 Analysis,[0],[0]
This provides strong evidence that gradient-based methods indeed cannot learn random parities and linear-periodic functions.,2.2 Analysis,[0],[0]
We emphasize that these results hold regardless of which class of predictors we use (e.g. they can be arbitrarily complex neural networks) – the problem lies in using a gradient-based method to train them.,2.2 Analysis,[0],[0]
"Also, we note that the difficulty lies in the random choice of v∗, and the problem is not difficult if v∗ is known and fixed in advance (for example, for a full parity v∗ = (1, . . .",2.2 Analysis,[0],[0]
", 1), this problem is known to be solvable with an appropriate LSTM network [17]).
",2.2 Analysis,[0],[0]
"Finally, we remark that the connection between parities, difficulty of learning and orthogonal functions is not new, and has already been made in the context of statistical query learning [21, 1].",2.2 Analysis,[0],[0]
"This refers to algorithms which are constrained to interact with data by receiving estimates of the expected value of some query over the underlying distribution (e.g. the expected value of the first coordinate), and it is well-known that parities cannot be learned with such algorithms.",2.2 Analysis,[0],[0]
"Recently, [8] have formally shown that gradient-based methods with an approximate gradient oracle can be implemented as a statistical query algorithm, which implies that gradient-based methods are indeed unlikely to solve learning problems which are known to be hard in the statistical queries framework, in particular parities.",2.2 Analysis,[0],[0]
"In the discussion on random parities above, we have simply made the connection between gradient-based methods and parities more explicit, by direct examination of gradients’ variance w.r.t.",2.2 Analysis,[0],[0]
"the target function.
",2.2 Analysis,[0],[0]
"5Formally, this requires an oracle-based model, where given a point w, the algorithm receives the gradient at w up to some arbitrary error much smaller than machine precision.",2.2 Analysis,[0],[0]
"See [29, Theorem 4] for details.",2.2 Analysis,[0],[0]
"Many practical learning problems, and more generally, algorithmic problems, can be viewed as a structured composition of sub-problems.",3 Decomposition vs. End-to-end,[0],[0]
"Applicable approaches for a solution can either be tackling the problem in an end-to-end manner, or by decomposition.",3 Decomposition vs. End-to-end,[0],[0]
"Whereas for a traditional algorithmic solution, the “divideand-conquer” strategy is an obvious choice, the ability of deep learning to utilize big data and expressive architectures has made “end-to-end training” an attractive alternative.",3 Decomposition vs. End-to-end,[0],[0]
"Prior results of end-to-end [24, 11] and decomposition and added feedback [13, 16, 32, 2] approaches show success in both directions.",3 Decomposition vs. End-to-end,[0],[0]
"Here, we try to address the following questions: What is the price of the rather appealing end-to-end approach?",3 Decomposition vs. End-to-end,[0],[0]
Is letting a network “learn by itself” such a bad idea?,3 Decomposition vs. End-to-end,[0],[0]
"When is it necessary, or worth the effort, to “help” it?
",3 Decomposition vs. End-to-end,[0],[0]
There are various aspects which can be considered in this context.,3 Decomposition vs. End-to-end,[0],[0]
"For example, [28] analyzed the difference between the approaches from the sample complexity point of view.",3 Decomposition vs. End-to-end,[0],[0]
"Here, we focus on the optimization aspect, showing that an end-to-end approach might suffer from non-informative or noisy gradients, which may significantly affect the training time.",3 Decomposition vs. End-to-end,[0],[0]
Helping the SGD process by decomposing the problem leads to much faster training.,3 Decomposition vs. End-to-end,[0],[0]
"We present a simple experiment, motivated by questions every practitioner must answer when facing a new, non trivial problem: What exactly is the required training data, what network architecture should be used, and what is the right distribution of development efforts.",3 Decomposition vs. End-to-end,[0],[0]
These are all correlated questions with no clear answer.,3 Decomposition vs. End-to-end,[0],[0]
Our experiments and analysis show that making the wrong choice can be expensive.,3 Decomposition vs. End-to-end,[0],[0]
"Our experiment compares the two approaches in a computer vision setting, where convolutional neural networks (CNN) have become the most widely used and successful algorithmic architectures.",3.1 Experiment,[0],[0]
"We define a family of problems, parameterized by k ∈ N, and show a gap (rapidly growing with k) between the performances of the end-to-end and decomposition approaches.
",3.1 Experiment,[0],[0]
"LetX denote the space of 28×28 binary images, with a distributionD defined by the following sampling procedure:
• Sample θ ∼ U([0, π]), l ∼ U([5, 28− 5]), (x, y) ∼ U([0, 27])2.
",3.1 Experiment,[0],[0]
"• The image xθ,l,(x,y) associated with the above sample is set to 0 everywhere, except for a straight line of length l, centered at (x, y), and rotated at an angle θ.",3.1 Experiment,[0],[0]
"Note that as the images space is discrete, we round the values corresponding to the points on the lines to the closest integer coordinate.
",3.1 Experiment,[0],[0]
"Let us define an “intermediate” labeling function y : X → {±1}, denoting whether the line in a given image slopes upwards or downwards, formally:
y(xθ,l,(x,y))",3.1 Experiment,[0],[0]
= { 1 if θ < π/2 −1,3.1 Experiment,[0],[0]
"otherwise .
",3.1 Experiment,[0],[0]
Figure 2 shows a few examples.,3.1 Experiment,[0],[0]
We can now define the problem for each k. Each input instance is a tuple xk1,3.1 Experiment,[0],[0]
":= (x1, . . .",3.1 Experiment,[0],[0]
",xk) of k images sampled i.i.d.",3.1 Experiment,[0],[0]
as above,3.1 Experiment,[0],[0]
.,3.1 Experiment,[0],[0]
"The target output is the parity over the image labels y(x1), . . .",3.1 Experiment,[0],[0]
", y(xk), namely ỹ(xk1) = ∏ j=1...k y(xj).
",3.1 Experiment,[0],[0]
Many architectures of DNN can be used for predicting ỹ(xk1) given x k 1 .,3.1 Experiment,[0],[0]
"A natural “high-level” choice
can be:
• Feed each of the images, separately, to a single CNN (of some standard specific architecture, for example, LeNet-like), denoted N (1)w1 and parameterized by its weights vector w1, outputting a single scalar, which can be regarded as a “score”.
",3.1 Experiment,[0],[0]
"• Concatenate the “scores” of a tuple’s entries, transform them to the range [0, 1] using a sigmoid function, and feed the resulting vector into another network, N (2)w2 , of a similar architecture to the one defined in Section 2, outputting a single “tuple-score”, which can then be thresholded for obtaining the binary prediction.
",3.1 Experiment,[0],[0]
Let the whole architecture be denoted Nw.,3.1 Experiment,[0],[0]
"Assuming that N (1) is expressive enough to provide, at least, a weak learner for y (a reasonable assumption), and that N (2) can express the relevant parity function (see Lemma 5 in the appendix), we obtain that this architecture has the potential for good performance.
",3.1 Experiment,[0],[0]
The final piece of the experimental setting is the choice of a loss function.,3.1 Experiment,[0],[0]
"Clearly, the primary loss which we’d like to minimize is the expected zero-one loss over the prediction, Nw(xk1), and the label, ỹ(xk1), namely:
L̃0−1(w) := E xk1
[ Nw(x k 1) 6= ỹ(xk1) ]",3.1 Experiment,[0],[0]
"A “secondary” loss which can be used in the decomposition approach is the zero-one loss over the
prediction of N (1)w1 (x k 1) and the respective y(x k 1) value:
L0−1(w1)",3.1 Experiment,[0],[0]
":= E xk1
[ N
(1) w1 (x k 1) 6= y(xk1) ]",3.1 Experiment,[0],[0]
"Let L̃, L be some differentiable surrogates for L̃0−1, L0−1.",3.1 Experiment,[0],[0]
"A classical end-to-end approach will be to minimize L̃, and only it; this is our “primary” objective.",3.1 Experiment,[0],[0]
"We have no explicit desire for N (1) to output any
specific value, and hence L is, a priori, irrelevant.",3.1 Experiment,[0],[0]
"A decomposition approach would be to minimize both losses, under the assumption that L can “direct” w1 towards an “area” in which we know that the resulting outputs of N (1) can be separated by N (2).",3.1 Experiment,[0],[0]
"Note that using L is only possible when the y values are known to us.
",3.1 Experiment,[0],[0]
"Empirically, when comparing performances based on the “primary” objective, we see that the end-to-end approach is significantly inferior to the decomposition approach (see Figure 3).",3.1 Experiment,[0],[0]
"Using decomposition, we quickly arrive at a good solution, regardless of the tuple’s length, k (as long as k is in the range where perfect input toN (2) is solvable by SGD, as described in Section 2).",3.1 Experiment,[0],[0]
"However, using the end-to-end approach works only for k = 1, 2, and completely fails already when k = 3 (or larger).",3.1 Experiment,[0],[0]
"This may be somewhat surprising, as the end-to-end approach optimizes exactly the primary objective, composed of two sub-problems each of which is easily solved on its own, and with no additional irrelevant objectives.",3.1 Experiment,[0],[0]
"We study the experiment from two directions: Theoretically, by analyzing the gradient variance (as in Section 2), for a somewhat idealized version of the experiment, and empirically, by estimating a signalto-noise ratio (SNR) measure of the stochastic gradients used by the algorithm.",3.2 Analysis,[0],[0]
"Both approaches point to a similar issue: With the end-to-end approach, the gradients do not seem to be sufficiently informative for the optimization process to succeed.
",3.2 Analysis,[0],[0]
"Before continuing, we note that a conceptually similar experiment to ours has been reported in [13] (also involving a composition of an image recognition task and a simple Boolean formula, and with qualitatively similar results).",3.2 Analysis,[0],[0]
"However, that experiment came without a formal analysis, and the failure was attributed to local minima.",3.2 Analysis,[0],[0]
"In contrast, our analysis indicates that the problem is not due to local-minima (or saddle points), but from the gradients being non-informative and noisy.
",3.2 Analysis,[0],[0]
"We begin with a theoretical result, which considers our experimental setup under two simplifying assumptions: First, the input is assumed to be standard Gaussian, and second, we assume the labels are generated by a target function of the form hu(xk1)",3.2 Analysis,[0],[0]
=,3.2 Analysis,[0],[0]
"∏k l=1 sign(u
>xl).",3.2 Analysis,[0],[0]
"The first assumption is merely to simplify the analysis (similar results can be shown more generally, but the argument becomes more involved).",3.2 Analysis,[0],[0]
"The second assumption is equivalent to assuming that the labels y(x) of individual images can be realized by a linear predictor, which is roughly the case for simple image labelling task such as ours.
",3.2 Analysis,[0],[0]
"Theorem 3 Let xk1 denote a k-tuple (x1, . . .",3.2 Analysis,[0],[0]
",xk) of input instances, and assume that each xl is i.i.d.",3.2 Analysis,[0],[0]
"stan-
dard Gaussian in Rd.",3.2 Analysis,[0],[0]
"Define
hu(x k 1) = k∏ l=1 sign(u>xl),
and the objective (w.r.t.",3.2 Analysis,[0],[0]
"some predictor pw parameterized by w)
",3.2 Analysis,[0],[0]
F (w) =,3.2 Analysis,[0],[0]
"E xk1
[ `(pw(x k 1), hu(x k 1) ] .
",3.2 Analysis,[0],[0]
"Where the loss function ` is either the square loss `(ŷ, y) =",3.2 Analysis,[0],[0]
"12(ŷ − y) 2 or a classification loss of the form `(ŷ, y) =",3.2 Analysis,[0],[0]
r(ŷ · y) for some 1-Lipschitz function r.,3.2 Analysis,[0],[0]
"Fix some w, and suppose that pw(x) is differentiable w.r.t.",3.2 Analysis,[0],[0]
w and satisfies Exk1,3.2 Analysis,[0],[0]
[ ‖ ∂∂wpw(x k 1‖2 ] ≤ G(w)2.,3.2 Analysis,[0],[0]
Then ifH = {hu :,3.2 Analysis,[0],[0]
"u ∈ Rd, ‖u‖ = 1}, then
Var(H, F,w) ≤",3.2 Analysis,[0],[0]
"G(w)2 ·O
(√ k log(d)
d
)k .
",3.2 Analysis,[0],[0]
The proof is given in Section B.2.,3.2 Analysis,[0],[0]
"The theorem shows that the “signal” regarding hu (or, if applying to our experiment, the signal for learning N (1), had y been drawn uniformly at random from some set of functions overX) decreases exponentially with k.",3.2 Analysis,[0],[0]
"This is similar to the parity result in Section 2, but with an important difference:",3.2 Analysis,[0],[0]
"Whereas the base of the exponent there was 1/2, here it is the much smaller quantity k log(d)/ √ d",3.2 Analysis,[0],[0]
"(e.g. in our experiment, we have k ≤ 4 and d = 282).",3.2 Analysis,[0],[0]
"This indicates that already for very small values of k, the information contained in the gradients about u can become extremely small, and prevent gradient-based methods from succeeding, fully according with our experiment.
",3.2 Analysis,[0],[0]
"To complement this analysis (which applies to an idealized version of our experiment), we consider a related “signal-to-noise” (SNR) quantity, which can be empirically estimated in our actual experiment.",3.2 Analysis,[0],[0]
"To motivate it, note that a key quantity used in the proof of Theorem 3, for estimating the amount of signal carried by the gradient, is the squared norm of the correlation between the gradient of the predictor pw, g(xk1) := ∂ ∂wpw(x k 1) and the target function hu, which we denote by Sigu:
Sigu := ∥∥∥∥∥Exk1",3.2 Analysis,[0],[0]
"[ hu(x k 1)g(x k 1) ]∥∥∥∥∥ 2 .
",3.2 Analysis,[0],[0]
"We will consider the ratio between this quantity and a “noise” term Noiu, i.e. the variance of this correlation over the samples:
",3.2 Analysis,[0],[0]
"Noiu := E xk1 ∥∥∥∥∥hu(xk1)g(xk1)− Exk1 [ hu(x k 1)g(x k 1) ]∥∥∥∥∥ 2 .
",3.2 Analysis,[0],[0]
"Since here the randomness is with respect to the data rather than the target function (as in Theorem 3), we can estimate this SNR ratio in our experiment.",3.2 Analysis,[0],[0]
It is well-known (e.g. [9]) that the amount of noise in the stochastic gradient estimates used by stochastic gradient descent crucially affects its convergence rate.,3.2 Analysis,[0],[0]
"Hence, smaller SNR should be correlated with worse performance.
",3.2 Analysis,[0],[0]
"We empirically estimated this SNR measure, Sigy/Noiy, for the gradients w.r.t.",3.2 Analysis,[0],[0]
the weights of the last layer of N (1) (which potentially learns our intermediate labeling function y) at the initialization point in parameter space.,3.2 Analysis,[0],[0]
The SNR estimate for various values of k are plotted in Figure 4.,3.2 Analysis,[0],[0]
"We indeed see that when k ≥ 3, the SNR appears to approach extremely small values, where the estimator’s noise, and the additional
noise introduced by a finite floating point representation, can completely mask the signal, which can explain the failure in this case.
",3.2 Analysis,[0],[0]
"In Section A in the Appendix, we also present a second, more synthetic, experiment, which demonstrates a case where the decomposition approach directly decreases the stochastic noise in the SGD optimization process, hence benefiting the convergence rate.",3.2 Analysis,[0],[0]
Network architecture choice is a crucial element in the success of deep learning.,4 Architecture and Conditioning,[0],[0]
"New variants and development of novel architectures are one of the main tools for achieving practical breakthroughs [14, 32].",4 Architecture and Conditioning,[0],[0]
"When choosing an architecture, one consideration is how to inject prior knowledge on the problem at hand, improving the network’s expressiveness for that problem, while not dramatically increasing sample complexity.",4 Architecture and Conditioning,[0],[0]
Another aspect involves improving the computational complexity of training.,4 Architecture and Conditioning,[0],[0]
"In this section we formally show how the choice of architecture affects the training time through the lens of the condition number of the problem.
",4 Architecture and Conditioning,[0],[0]
"The study and practice of conditioning techniques, for convex and non-convex problems, gained much attention recently (e.g., [18, 22, 7, 27]).",4 Architecture and Conditioning,[0],[0]
"Here we show how architectural choice may have a dramatic effect on the applicability of better conditioning techniques.
",4 Architecture and Conditioning,[0],[0]
"The learning problem we consider in this section is that of encoding one-dimensional, piecewise linear curves.",4 Architecture and Conditioning,[0],[0]
"We show how different architectures, all of them of sufficient expressive power for solving the problem, have orders-of-magnitude difference in their condition numbers.",4 Architecture and Conditioning,[0],[0]
"In particular, this becomes apparent when considering convolutional vs. fully connected layers.",4 Architecture and Conditioning,[0],[0]
"This sheds a new light over the success of convolutional neural networks, which is generally attributed to their sample complexity benefits.",4 Architecture and Conditioning,[0],[0]
"Moreover, we show how conditioning, applied in conjunction with a better architecture choice, can further decrease the condition number by orders of magnitude.",4 Architecture and Conditioning,[0],[0]
"The direct effect on the convergence rate is analyzed, and is aligned with the significant performance gaps observed empirically.",4 Architecture and Conditioning,[0],[0]
"We also demonstrate how performance may not significantly improve by employing deeper and more powerful architectures, as well as the price that comes with choosing a sub-optimal architecture.",4 Architecture and Conditioning,[0],[0]
"We experiment with various deep learning solutions for encoding the structure of one-dimensional, continuous, piecewise linear (PWL) curves.",4.1 Experiments and Analysis,[0],[0]
"Any PWL curve with k pieces can be written as: f(x) = b +∑k
i=1",4.1 Experiments and Analysis,[0],[0]
ai[x,4.1 Experiments and Analysis,[0],[0]
"− θi]+, where ai is the difference between the slope at the i’th segment and the (i − 1)’th segment.",4.1 Experiments and Analysis,[0],[0]
"For example, the curve below can be parametrized by b = 1, a = (1,−2, 3), θ = (0, 2, 6).
",4.1 Experiments and Analysis,[0],[0]
"The problem we consider is that of receiving a vector of the values of f at x ∈ {0, 1, . . .",4.1 Experiments and Analysis,[0],[0]
", n−1}, namely f := (f(0), f(1), . . .",4.1 Experiments and Analysis,[0],[0]
", f(n−1)), and outputting the values of b, {ai, θi}ki=1.",4.1 Experiments and Analysis,[0],[0]
"We can think of this problem as an encoding problem, since we would like to be able to rebuild f from the values of b, {ai, θi}ki=1.",4.1 Experiments and Analysis,[0],[0]
"Observe that b = f(0), so from now on, let us assume without loss of generality that b = 0.
",4.1 Experiments and Analysis,[0],[0]
"Throughout our experiments, we use n = 100, k = 3.",4.1 Experiments and Analysis,[0],[0]
"We sample {θi}i∈[k] uniformly without replacement from {0, 1, . . .",4.1 Experiments and Analysis,[0],[0]
", n− 1}, and sample each ai i.i.d.",4.1 Experiments and Analysis,[0],[0]
"uniformly from [−1, 1].",4.1 Experiments and Analysis,[0],[0]
"As we assume that each θi is an integer in {0, 1, . . .","4.1.1 Convex Problem, Large Condition Number",[0],[0]
", n","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"− 1}, we can represent {ai, θi}ki=1 as a vector p ∈","4.1.1 Convex Problem, Large Condition Number",[0],[0]
Rn such that pj = 0,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"unless there is some i such that θi = j, and in this case we set pj = ai.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"That is, pj = ∑k i=1 ai 1[θi=j−1].
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
This allows us to formalize the problem as a convex optimization problem.,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Define a matrix W ∈ Rn,n such that Wi,j =","4.1.1 Convex Problem, Large Condition Number",[0],[0]
[i − j + 1]+.,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
It is not difficult to show that f = Wp.,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Moreover, W can be shown to be invertible, so we can extract p from f by p = W−1f .
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"We hence start by attempting to learn this linear transformation directly, using a connected architecture of one layer, with n output channels.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
Let the weights of this layer be denoted Û .,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"We therefore minimize the objective:
min Û E f
[ 1
2 (W−1f − Û f)2
] (3)
where f is sampled according to some distribution.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"As a convex, realizable (by Û = W−1) problem, convergence is guaranteed, and we can explicitly analyze its rate.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"However, perhaps unexpectedly, we observe a very slow rate of convergence to a satisfactory solution, where significant inaccuracies are present at the non-smoothness points.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Figure 5a illustrates the results.
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"To analyze the convergence rate of this approach, and to benchmark the performance of the next set of experiments, we start off by giving an explicit expression for W−1:
Lemma 1 The inverse of W is the matrix U s.t.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Ui,i = Ui+2,i = 1, Ui+1,i = −2, and the rest of the coordinates of U are zero.
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
The proof is given in Appendix B.3.,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Next, we analyze the iteration complexity of SGD for learning the matrix U .","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"To that end, we give an explicit expression for the expected value of the learned weight matrix at each iteration t, denoted as Û t:
Lemma 2 Assume Û0 = 0, and that Ef [Uff>U>] = λI for some λ.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Then, running SGD with learning rate η over objective 3 for t iterations yields:
E Ût = ηλW> t−1∑ i=0 (I − ηλWW>)i
The proof is given in Appendix B.4.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Note that the assumption that Ef [Uff>U>] = λI holds under the distributional assumption over the curves, as changes of direction in the curve are independent, and are sampled each time from the same distribution.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"The following theorem establishes a lower bound on ‖E Ût+1 − U‖, which by Jensen’s inequality, implies a lower bound on E ‖Ût+1 − U‖, the expected distance of Ût+1 from U .","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Note that the lower bound holds even if we use all the data for updating (that is, gradient descent and not stochastic gradient descent).
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
Theorem 4 Let W = QSV > be the singular value decomposition of W .,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"If η λS21,1 ≥ 1 then E Ût+1 diverges.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Otherwise, we have
t+ 1 ≤ S21,1
2S2n,n ⇒ ‖E Ût+1 − U‖ ≥ 0.5 ,
where the norm is the spectral norm.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Furthermore, the condition number S21,1 S2n,n (where S1,1, Sn,n are the top and bottom singular values of W ) is Ω(n3.5).
","4.1.1 Convex Problem, Large Condition Number",[0],[0]
The proof is given in Appendix B.5.,"4.1.1 Convex Problem, Large Condition Number",[0],[0]
"The theorem implies that the condition number of W, and hence, the number of GD iterations required for convergence, scales quite poorly with n. In the next subsection, we will try to decrease the condition number of the problem.","4.1.1 Convex Problem, Large Condition Number",[0],[0]
"Examining the explicit expression for U given in Lemma 1, we see that U f can be written as a onedimensional convolution of f with the kernel [1,−2, 1].",4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
"Therefore, the mapping from f to p is realizable using a convolutional layer.
",4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
"Empirically, convergence to an accurate solution is faster using this architecture.",4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
Figure 5b illustrates a few examples.,4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
"To theoretically understand the benefit of using a convolution, from the perspective of the required number of iterations for training, we will consider the new problem’s condition number, providing understanding of the gap in training time.",4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
In the previous section we saw that GD requires Ω(n3.5) iterations to learn the full matrixU .,4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
"In the appendix (sections B.6 and B.7) we show that under some mild assumptions, the condition number is only Θ(n3), and GD requires only that order of iterations to learn the optimal filter [1,−2, 1].",4.1.2 Improved Condition Number through Convolutional Architecture,[0],[0]
"In Section 4.1.2, despite observing an improvement from the fully connected architecture, we saw that GD still requires Ω(n3) iterations even for the simple problem of learning the filter [1,−2, 1].",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"This motivates an application of additional conditioning techniques, in the hope for extra performance gains.
",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"First, let us explicitly represent the convolutional architecture as a linear regression problem.",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"We perform Vec2Row operation on f as follows: given a sample f , construct a matrix, F , of size n× 3, such that the t’th row of F is [ft−1, ft, ft+1].",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"Then, we obtain a vanilla linear regression problem in R3, with the filter [1,−2, 1]
as its solution.",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"Given a sample f , we can now approximate the correlation matrix of F , denotedC ∈ R3,3, by setting Ci,j = Ef ,t[ft−2+ift−2+j ].",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"We then calculate the matrix C−1/2 and replace every instance (namely, a row of F )",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"[ft−1, ft, ft+1] by the instance [ft−1, ft, ft+1]C−1/2.",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"By construction, the correlation matrix of the resulting instances is approximately the identity matrix, hence the condition number is approximately 1.",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"It follows (see again Appendix B.6) that SGD converges using order of log(1/ ) iterations, independently of n. Empirically, we quickly converge to extremely accurate results, illustrated in Figure 5c.
",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
"We note that the use of a convolution architecture is crucial for the efficiency of the conditioning; had the dimension of the problem not been reduced so dramatically, the difficulty of estimating a large n×n correlation matrix scales strongly with n, and furthermore, its inversion becomes a costly operation.",4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
The combined use of a better architecture and of conditioning is what allows us to gain this dramatic improvement.,4.1.3 Additional Improvement through Explicit Conditioning,[0],[0]
The solution arrived at in Section 4.1.3 indicates that a suitable architecture choice and conditioning scheme can provide training time speedups of multiple orders of magnitude.,4.1.4 Perhaps I should use a deeper network?,[0],[0]
"Moreover, the benefit of reducing the number of parameters, in the transition from a fully connected architecture to a convolutional one, is shown to be helpful in terms of convergence time.",4.1.4 Perhaps I should use a deeper network?,[0],[0]
"However, we should not rule out the possibility that a deeper, wider network will not suffer from the deficiencies analyzed above for the convex case.
",4.1.4 Perhaps I should use a deeper network?,[0],[0]
"Motivated by the success of deep auto-encoders, we experiment with a deeper architecture for encoding f .",4.1.4 Perhaps I should use a deeper network?,[0],[0]
"Namely, we minimize minv1,v2",4.1.4 Perhaps I should use a deeper network?,[0],[0]
Ef,4.1.4 Perhaps I should use a deeper network?,[0],[0]
"[(f −Mv2(Nv1(f)))2], Where Nv1 ,Mv2 are deep networks parametrized by their weight vectors v1,v2, with the output of N being of dimension 2k, enough for realization of the encoding problem.",4.1.4 Perhaps I should use a deeper network?,[0],[0]
"Each of the two networks has three layers with ReLU activations, except for the output layer of M having a linear activation.",4.1.4 Perhaps I should use a deeper network?,[0],[0]
"The dimensions of the layers are, 500, 100, 2k for N , and 100, 100, n for M .
Aligned with the intuition gained through the previous experiments, we observe that additional expressive power, when unnecessary, does not solve inherent optimization problems, as this stronger Auto-Encoder fails to capture the fine details of f at its non-smooth points.",4.1.4 Perhaps I should use a deeper network?,[0],[0]
See Figure 5d for examples.,4.1.4 Perhaps I should use a deeper network?,[0],[0]
"We now examine a different aspect of gradient-based learning which poses difficulties for optimization: namely, flatness of the loss surface due to saturation of the activation functions, leading to vanishing gradients and a slow-down of the training process.",5 Flat Activations,[0],[0]
"This problem is amplified in deeper architectures, since it is likely that the backpropagated message to lower layers in the architecture would vanish due to a saturated activation somewhere along the way.",5 Flat Activations,[0],[0]
"This is a major problem when using sigmoids as a gating mechanisms in Recurrent Neural Networks such as LSTMS and GRUs [12, 4].
",5 Flat Activations,[0],[0]
"While non-local search-based optimization for large scale problems seems to be beyond reach, variants on the gradient update, whether by adding momentum, higher order methods, or normalized gradients, are quite successful, leading to consideration of update schemes deviating from “vanilla” gradient updates.
",5 Flat Activations,[0],[0]
"In this section, we consider a family of activation functions which amplify the “vanishing gradient due to saturated activation” problem; they are piecewise flat.",5 Flat Activations,[0],[0]
"Using such activations in a neural network architecture will result in a gradient equal to 0, which will be completely useless.",5 Flat Activations,[0],[0]
"We consider different ways to implement, approximate or learn such activations, such that the error will effectively propagate through them.",5 Flat Activations,[0],[0]
"Using a different variant of a local search-based update, based on [20, 19] , we arrive at
an efficient solution.",5 Flat Activations,[0],[0]
Convergence guarantees exist for a one-layer architecture.,5 Flat Activations,[0],[0]
We leave further study of deeper networks to future work.,5 Flat Activations,[0],[0]
Consider the following optimization setup.,5.1 Experimental Setup,[0],[0]
The sample space X ⊂ Rd is symmetrically distributed.,5.1 Experimental Setup,[0],[0]
"The target function y : Rd → R is of the form y(x) = u(v∗>x + b∗), where v∗ ∈ Rd, b∗ ∈ R, and u : R → R is a monotonically non-decreasing function.",5.1 Experimental Setup,[0],[0]
"The objective of the optimization problem is given by:
min w E x",5.1 Experimental Setup,[0],[0]
"[` (u(Nw(x)), y(x))]
where Nw is some neural network parametrized by w, and ` is some loss function (for example, the squared or absolute difference).
",5.1 Experimental Setup,[0],[0]
"For the experiments, we use u of the form: u(r) = z0 + ∑ i∈[55] 1[r>zi] · (zi − zi−1) ,
where z0 < z1 < . . .",5.1 Experimental Setup,[0],[0]
< z55 are known.,5.1 Experimental Setup,[0],[0]
"In words, given r, the function rounds down to the nearest zi.",5.1 Experimental Setup,[0],[0]
We also experiment with normally distributed X .,5.1 Experimental Setup,[0],[0]
"Our theoretical analysis is not restricted to u of this specific form, nor to normal X .",5.1 Experimental Setup,[0],[0]
"All figures are found in Figure 6.
",5.1 Experimental Setup,[0],[0]
"Of course, applying gradient-based methods to solve this problem directly, is doomed to fail as the derivative of u is identically 0.",5.1 Experimental Setup,[0],[0]
Is there anything which can be done instead?,5.1 Experimental Setup,[0],[0]
"We start off by trying to approximate u using a non flat function ũ defined by ũ(r) = z0 + ∑ i∈[55] (zi − zi−1) · σ(c · (r − zi)),
where c is some constant, and σ is the sigmoid function σ(z) =",5.2 Non-Flat Approximation Experiment,[0],[0]
(1 + exp(−z))−1.,5.2 Non-Flat Approximation Experiment,[0],[0]
"Intuitively, we approximate the “steps” in u using a sum of sigmoids, each of amplitude corresponding to the step’s height, and centered at the step’s position.",5.2 Non-Flat Approximation Experiment,[0],[0]
This is similar to the motivation for using sigmoids as activation functions and as gates in LSTM cells — a non-flat approximation of the step function.,5.2 Non-Flat Approximation Experiment,[0],[0]
"Below is an example for u, and its approximation ũ.
u ũ
The objective is the expected squared loss, propagated through ũ, namely
min v,b E x
[( ũ(v>x + b)− y(x) )2] .
",5.2 Non-Flat Approximation Experiment,[0],[0]
"Although the objective is not completely flat, and is continuous, it suffers from the flatness and non continuity deficiencies of the original u, and training using this objective is much slower, and sometimes completely failing.",5.2 Non-Flat Approximation Experiment,[0],[0]
"In particular, sensitivity to the initialization of bias term is observed, where the wrong initialization can cause the starting point to be in a very wide flat region of u, and hence a very flat region of ũ.",5.2 Non-Flat Approximation Experiment,[0],[0]
"Next, we attempt to solve the problem using improper learning, with the objective now being:
min w E",5.3 End-to-End Experiment,[0],[0]
"x
[ (Nw(x)− y(x))2 ] where Nw is a network parametrized by its weight vector w.",5.3 End-to-End Experiment,[0],[0]
"We use a simple architecture of four fully connected layers, the first three with ReLU activations and 100 output channels, and the last, with only one output channel and no activation function.
",5.3 End-to-End Experiment,[0],[0]
"As covered in Section 4, difficulty arises when regressing to non smooth functions.",5.3 End-to-End Experiment,[0],[0]
"In this case, with u not even being continuous, the inaccuracies in capturing the non continuity points are brought to the forefront.",5.3 End-to-End Experiment,[0],[0]
"Moreover, this solution has its extra price in terms of sample complexity, training time, and test time, due to the use of a much larger than necessary network.",5.3 End-to-End Experiment,[0],[0]
An advantage is of course the minimal prior knowledge about u which is required.,5.3 End-to-End Experiment,[0],[0]
"While this approach manages to find a reasonable solution, it is far from being perfect.",5.3 End-to-End Experiment,[0],[0]
"In this experiment, we approach the problem as a general multi-class classification problem, with each value of the image of u is treated as a separate class.",5.4 Multi-Class Experiment,[0],[0]
"We use a similar architecture to that of the end-to-end experiment, with one less hidden layer, and with the final layer outputting 55 outputs, each corresponding to one of the steps defined by the zis.",5.4 Multi-Class Experiment,[0],[0]
"A problem here is the inaccuracies at the boundaries between classes, due to the lack of structure imposed over the predictor.",5.4 Multi-Class Experiment,[0],[0]
The fact that the linear connection between x and the input to u is not imposed through the architecture results in “blurry” boundaries.,5.4 Multi-Class Experiment,[0],[0]
"In addition, the fact that we rely on an “improper” approach, in the sense that we ignore the ordering imposed by u, results in higher sample complexity.",5.4 Multi-Class Experiment,[0],[0]
"Let us go back to a direct formulation of the problem, in the form of the objective function
min w F (w) = E",5.5 The “Forward-Only” Update Rule,[0],[0]
"x
[ (u(w>x)− y(x))2 ] where y(x) = u(v∗>x).",5.5 The “Forward-Only” Update Rule,[0],[0]
The gradient update rule in this case is w(t+1) = w(t),5.5 The “Forward-Only” Update Rule,[0],[0]
"− η∇F (w(t)), where for our objective we have
∇F (w) = E x
[ (u(w>x)− y(x))",5.5 The “Forward-Only” Update Rule,[0],[0]
"· u′(w>x) · x ] Since u′ is zero a.e., the gradient update is meaningless.",5.5 The “Forward-Only” Update Rule,[0],[0]
"[20, 19] proposed to replace the gradient with the following:
∇̃F (w) =",5.5 The “Forward-Only” Update Rule,[0],[0]
"E x
[ (u(w>x)− y(x))",5.5 The “Forward-Only” Update Rule,[0],[0]
"· x ] (4)
In terms of the backpropagation algorithm, this kind of update can be interpreted as replacing the backpropagation message for the activation function u with an identity message.",5.5 The “Forward-Only” Update Rule,[0],[0]
"For notation simplicity, we omitted the bias terms b, b∗, but the same Forward-only concept is applied to them too.
",5.5 The “Forward-Only” Update Rule,[0],[0]
"This method empirically achieves the best results, both in terms of final accuracy, training time, and test time cost.",5.5 The “Forward-Only” Update Rule,[0],[0]
"As mentioned before, the method is due to [20, 19], where it is proven to converge to an -optimal solution in O(L2/ 2), under the additional assumptions that the function u is L-Lipschitz, and that w is constrained to have bounded norm.",5.5 The “Forward-Only” Update Rule,[0],[0]
"For completeness, we provide a short proof in Appendix B.8.",5.5 The “Forward-Only” Update Rule,[0],[0]
"In this paper, we considered different families of problems, where standard gradient-based deep learning approaches appear to suffer from significant difficulties.",6 Summary,[0],[0]
"Our analysis indicates that these difficulties are not necessarily related to stationary point issues such as spurious local minima or a plethora of saddle points, but rather more subtle issues: Insufficient information in the gradients about the underlying target function; low SNR; bad conditioning; or flatness in the activations (see Figure 7 for a graphical illustration).",6 Summary,[0],[0]
"We consider it as a first step towards a better understanding of where standard deep learning methods might fail, as well as what approaches might overcome these failures.
",6 Summary,[0],[0]
Acknowledgements:,6 Summary,[0],[0]
"This research is supported in part by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI), and by the European Research Council (TheoryDL project).",6 Summary,[0],[0]
OS was also supported in part by an FP7 Marie Curie CIG grant and an Israel Science Foundation grant 425/13.,6 Summary,[0],[0]
"A.1 Experiment
For this experiment, consider the problem of training a predictor, which given a “positive media reference” x to a certain stock option, will distribute our assets between the k = 500 stocks in the S&P500 index in some manner.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"One can, again, come up with two rather different strategies for solving the problem.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
• An end-to-end approach: train a deep network Nw that given x outputs a distribution over the k stocks.,A Reduced Noise through Decomposition - Experiment,[0],[0]
"The objective for training is maximizing the gain obtained by allocating our money according to this distribution.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"• A decomposition approach: train a deep network Nw that given x outputs a single stock, y ∈",A Reduced Noise through Decomposition - Experiment,[0],[0]
"[k], whose future gains are the most positively correlated to x.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"Of course, we may need to gather extra labeling for training Nw based on this criterion.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
We make the (non-realistic) assumption that every instance of media reference is strongly and positively correlated to a single stock y ∈,A Reduced Noise through Decomposition - Experiment,[0],[0]
"[k], and it has no correlation with future performance of other stocks.",A Reduced Noise through Decomposition - Experiment,[0],[0]
This obviously makes our problem rather toyish; the stock exchange and media worlds have highly complicated correlations.,A Reduced Noise through Decomposition - Experiment,[0],[0]
"However, it indeed arises from, and is motivated by, practical problems.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"To examine the problem in a simple and theoretically clean manner, we design a synthetic experiment defined by the following optimization problem: Let X × Z ⊂",A Reduced Noise through Decomposition - Experiment,[0],[0]
Rd,A Reduced Noise through Decomposition - Experiment,[0],[0]
"× {±1}k be the sample space, and let y : X",A Reduced Noise through Decomposition - Experiment,[0],[0]
→ [k] be some labelling function.,A Reduced Noise through Decomposition - Experiment,[0],[0]
"We would like to learn a mapping Nw : X → Sk−1, with the objective being:
min w L(w) := E x,z∼X×Z
[ −z>Nw(x) ] .
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"To connect this to our story, Nw(x) is our asset distribution, z indicates the future performance of the stocks, and thus, we are seeking minimization of our expected future negative gains, or in other words, maximization of expected profit.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"We further assume that given x, the coordinate zy(x) equals 1, and the rest of the coordinates are sampled i.i.d from the uniform distribution over {±1}.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"Whereas in Section 3.1’s experiment, the difference between the end-to-end and decomposition approaches could be summarized by a different loss function choice, in this experiment, the difference boils down to the different gradient estimators we would use, where we are again taking as a given fact that exact gradient computations are expensive for large-scale problems, implying the method of choice to be SGD.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"For the purpose of the experimental discussion, let us write the two estimators explicitly as two unconnected update rules.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"We will later analyze their (equal) expectation.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"For an end-to-end approach, we sample a pair (x, z), and use ∇w(−z>Nw(x)) as a gradient estimate.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"It is clear that this is an unbiased estimator of the gradient.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"For a decomposition approach, we sample a pair (x, z), completely ignore z, and instead, pay the extra costs and gather the required labelling to get y(x).",A Reduced Noise through Decomposition - Experiment,[0],[0]
We will then use ∇w(−e>y(x)Nw(x)) as a gradient estimate.,A Reduced Noise through Decomposition - Experiment,[0],[0]
"It will be shown later that this too is an unbiased estimator of the gradient.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"Figure 8 clearly shows that optimizing using the end-to-end estimator is inferior to working with the decomposition one, in terms of training time and final accuracy, to the extent that for large k, the end-to-end estimator cannot close the gap in performance in reasonable time.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"A.2 Analysis
We examine the experiment from a SNR perspective.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"First, let us show that indeed, both estimators are unbiased estimators of the true gradient.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"As stated above, it is clear, by definition of L, that the end-toend estimator is an unbiased estimator of ∇wL(w).",A Reduced Noise through Decomposition - Experiment,[0],[0]
"To observe this is also the case for the decomposition estimator, we write:
∇wL(w) = ∇w E x,z
[−z>Nw(x)]
=E x",A Reduced Noise through Decomposition - Experiment,[0],[0]
"[ E z|x
[∇w(−z>Nw(x))",A Reduced Noise through Decomposition - Experiment,[0],[0]
"]]
(1) =",A Reduced Noise through Decomposition - Experiment,[0],[0]
"E
x",A Reduced Noise through Decomposition - Experiment,[0],[0]
"[ E z|x
[−z>∇w(Nw(x))",A Reduced Noise through Decomposition - Experiment,[0],[0]
]] (2) =,A Reduced Noise through Decomposition - Experiment,[0],[0]
E x,A Reduced Noise through Decomposition - Experiment,[0],[0]
[−e>y(x)∇w(Nw(x)),A Reduced Noise through Decomposition - Experiment,[0],[0]
"]
where (1) follows from the chain rule, and (2) from the assumption on the distribution of z given x.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"It is now easy to see that the decomposition estimator is indeed a (different) unbiased estimator of the gradient, hence the “signal” is the same.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"Intuition says that when a choice between two unbiased estimators is presented, we should choose the one with the lower variance.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"In our context, [9] showed that when running SGD (even on non-convex objectives), arriving at a point where ‖∇wL(w)‖2 ≤ requires order of ν̄2/ 2 iterations, where
ν̄2 = max t E x,q ‖∇tw(x, q)‖2 − ‖∇wL(w(t))‖2,
wt is the weight vector at time t, q is sampled along with x (where it can be replaced by z or y(x), in our
experiment), and ∇tw is the unbiased estimator for the gradient.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"This serves as a motivation for analyzing the problem through this lens.
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"Motivated by [9]’s result, and by our results regarding Section 3.1, we examine the quantity Ex,q ‖∇tw(x, q)‖2, or “noise”, explicitly.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"For the end-to-end estimator, this quantity equals
E x,z ‖",A Reduced Noise through Decomposition - Experiment,[0],[0]
"− z>∇wNw(x)‖2 = E x,z ‖ − k∑ i=1",A Reduced Noise through Decomposition - Experiment,[0],[0]
"zi∇wNw(x)i‖2
Denoting by Gi := ∇wNw(x)i, we get:
= E x E z|x ‖",A Reduced Noise through Decomposition - Experiment,[0],[0]
− k∑ i=1,A Reduced Noise through Decomposition - Experiment,[0],[0]
ziGi‖2 = E x k∑ i=1,A Reduced Noise through Decomposition - Experiment,[0],[0]
"‖Gi‖2 (5)
",A Reduced Noise through Decomposition - Experiment,[0],[0]
"where the last equality follows from expanding the squared sum, and taking expectation over z, while noting that mixed terms cancel out (from independence of z’s coordinates), and that z2i = 1 for all i.
As for the decomposition estimator, it is easy to see that
E x ‖",A Reduced Noise through Decomposition - Experiment,[0],[0]
− e>y(x)∇wNw(x)‖ 2 = E x ‖Gy(x)‖2.,A Reduced Noise through Decomposition - Experiment,[0],[0]
"(6)
Observe that in 5 we are summing up, per x, k summands, compared to the single element in 6.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"When randomly initializing a network it is likely that the values of ‖Gi‖2 are similar, hence we obtain that at the beginning of training, the variance of the end-to-end estimator is roughly k times larger than that of the decomposition estimator.",A Reduced Noise through Decomposition - Experiment,[0],[0]
"B.1 Proof of Theorem 1
",B Proofs,[0],[0]
"Proof Given two square-integrable functions f, g on an Euclidean space Rn, let 〈f, g〉L2 = Ex[f(x)g(x)] and ‖f‖L2 = √ Ex[f2(x)] denote inner product and norm in the L2 space of square-integrable functions (with respect to the relevant distribution).",B Proofs,[0],[0]
"Also, define the vector-valued function
g(x) = ∂
∂w pw(x),
and let g(x) =",B Proofs,[0],[0]
"(g1(x), g2(x), . . .",B Proofs,[0],[0]
", gn(x))",B Proofs,[0],[0]
"for real-valued functions g1, . . .",B Proofs,[0],[0]
", gn.",B Proofs,[0],[0]
"Finally, let Eh denote an expectation with respect to h chosen uniformly at random fromH. Let |H| = d.
We begin by proving the result for the squared loss.",B Proofs,[0],[0]
"To prove the bound, it is enough to show that Eh ‖∇Fh(w)−a‖2 ≤",B Proofs,[0],[0]
"G 2 |H| for any vector a independent of h. In particular, let us choose a = Ex [pw(x)g(x)].
",B Proofs,[0],[0]
"We thus bound the following:
E h ‖∇Fh(w)− E x",B Proofs,[0],[0]
[pw(x)g(x)],B Proofs,[0],[0]
‖2 = E h ‖E x,B Proofs,[0],[0]
[(pw(x)− h(x)),B Proofs,[0],[0]
g(x)]− E x,B Proofs,[0],[0]
"[pw(x)g(x)] ‖2
= E h",B Proofs,[0],[0]
‖E,B Proofs,[0],[0]
x,B Proofs,[0],[0]
[h(x)g(x)] ‖2 = E h n∑ j=1,B Proofs,[0],[0]
"( E x [h(x)gj(x)] )2
= E h n∑ j=1 〈h, gj〉2L2 = n∑ j=1
( 1
|H| d∑ i=1",B Proofs,[0],[0]
"〈hi, gj〉2L2 ) (∗) ≤
n∑ j=1",B Proofs,[0],[0]
( 1 |H| ‖gj‖2L2 ),B Proofs,[0],[0]
= 1 |H| n∑ j=1 E x,B Proofs,[0],[0]
"[g2j (x)]
= 1
|H| E x
[ ‖g(x)‖2 ] ≤ G(w) 2
|H| ,
where (∗) follows from the functions in H being mutually orthogonal, and satisfying ‖h‖L2 ≤ 1 for all h ∈ H.
To handle a classification loss, note that by its definition and the fact that h(x) ∈ {−1,+1},
∇Fh(w) =",B Proofs,[0],[0]
"E x
[ r′(h(x)pw(x)) · ∂
∂w pw(x) ]",B Proofs,[0],[0]
"= E
x
[( r′(pw(x))",B Proofs,[0],[0]
"+ r
′(−pw(x))",B Proofs,[0],[0]
2 + h(x) ·,B Proofs,[0],[0]
r ′(pw(x))− r′(−pw(x)) 2 ) · ∂ ∂w pw(x) ],B Proofs,[0],[0]
"= E
x
[ r′(pw(x))",B Proofs,[0],[0]
"+ r
′(−pw(x))",B Proofs,[0],[0]
"2 · ∂ ∂w pw(x)
]",B Proofs,[0],[0]
"+ E
x
[ h(x) · ( r′(pw(x))− r′(−pw(x))
2
) · ∂ ∂w pw(x) ] .
",B Proofs,[0],[0]
Letting g(x) =,B Proofs,[0],[0]
"( r′(pw(x))−r′(−pw(x))
2
) ·",B Proofs,[0],[0]
∂∂wpw(x) (which satisfies Ex[‖g(x)‖,B Proofs,[0],[0]
"2] ≤ G2 since r is 1-Lipschitz)
and a = Ex [ r′(pw(x))+r′(−pw(x)) 2 · ∂ ∂wpw(x) ]",B Proofs,[0],[0]
"(which does not depend on h), we get that
E h ‖∇Fh(w)− a‖2 = E h ‖E",B Proofs,[0],[0]
x,B Proofs,[0],[0]
"[h(x)g(x)]‖2.
",B Proofs,[0],[0]
"Proceeding now exactly in the same manner as the squared loss case, the result follows.
",B Proofs,[0],[0]
"B.2 Proof of Theorem 3
",B Proofs,[0],[0]
"Proof We first state and prove two auxiliary lemmas.
",B Proofs,[0],[0]
"Lemma 3 Let h1, . . .",B Proofs,[0],[0]
", hn be real-valued functions on some Euclidean space, which belong to some weighted L2 space.",B Proofs,[0],[0]
"Suppose that ‖hi‖L2 = 1 and maxi 6=j |〈hi, hj〉L2 | ≤ c.",B Proofs,[0],[0]
"Then for any function g on the same domain,
1
n n∑ i=1",B Proofs,[0],[0]
"〈hi, g〉2L2 ≤",B Proofs,[0],[0]
"‖g‖ 2 L2 ( 1 n + c ) .
",B Proofs,[0],[0]
"Proof For simplicity, suppose first that the functions are defined over some finite domain equipped with a uniform distribution, so that h1, . . .",B Proofs,[0],[0]
", hn and g can be thought of as finite-dimensional vectors, and the L2 inner product and norm reduce to the standard inner product and norm in Euclidean space.",B Proofs,[0],[0]
"Let H = (h1, . . .",B Proofs,[0],[0]
", hn) denote the matrix whose i-th column is hi.",B Proofs,[0],[0]
"Then
n∑ i=1
〈hi, g〉2 =",B Proofs,[0],[0]
"g> (
n∑ i=1",B Proofs,[0],[0]
hih >,B Proofs,[0],[0]
"i
)",B Proofs,[0],[0]
"g = g>HH>g ≤ ‖g‖2‖HH>‖ = ‖g‖2‖H>H‖,
where ‖·‖ for a matrix denotes the spectral norm.",B Proofs,[0],[0]
"SinceH>H is simply the n×nmatrix with entry 〈hi, hj〉 in location i, j, we can write it as I + M , where I is the n × n identity matrix, and M is a matrix with 0 along the main diagonal, and entries of absolute value at most c otherwise.",B Proofs,[0],[0]
"Therefore, letting ‖ · ‖F denote the Frobenius norm, we have that the above is at most
‖g‖2",B Proofs,[0],[0]
(‖I‖+ ‖M‖) ≤ ‖g‖2,B Proofs,[0],[0]
(1 + ‖M‖F ) = ‖g‖2,B Proofs,[0],[0]
"(1 + cn) ,
from which the result follows.",B Proofs,[0],[0]
"Finally, it is easily verified that the same proof holds even when h1, . . .",B Proofs,[0],[0]
", hn, g are functions over some Euclidean space, belonging to some weighted L2 space.",B Proofs,[0],[0]
"In that case, H is a bounded linear operator, and it holds that ‖H∗H‖ = ‖H‖2 = ‖H∗‖2 = ‖HH∗‖ where H∗ is the Hermitian adjoint of H and the norm is the operator norm.",B Proofs,[0],[0]
"The rest of the proof is essentially identical.
",B Proofs,[0],[0]
Lemma 4,B Proofs,[0],[0]
"If w,v are two unit vectors in Rd, and x is a standard Gaussian random vector, then∣∣∣E x [ sign(w>x)sign(v>x)",B Proofs,[0],[0]
"]∣∣∣ ≤ |〈w,v〉| Proof Note that w>x,v>x are jointly zero-mean Gaussian, each with variance 1 and with covariance E[w>xx>v] =",B Proofs,[0],[0]
"w>v. Therefore,
E x
[ sign(w>x)sign(v>x) ]",B Proofs,[0],[0]
"= Pr(w>x ≥ 0,v>x ≥ 0) + Pr(w>x ≤ 0,v>x ≤ 0)
",B Proofs,[0],[0]
"− Pr(w>x ≥ 0,v>x ≤ 0)− Pr(w>x ≤ 0,v>x ≥ 0) = 2",B Proofs,[0],[0]
"Pr(w>x ≥ 0,v>x ≥ 0)− 2",B Proofs,[0],[0]
"Pr(w>x ≥ 0,v>x ≤ 0),
which by a standard fact on the quadrant probability of bivariate normal distributions, equals
2
( 1
4 +
sin−1(w>v)
2π
)",B Proofs,[0],[0]
"− 2 ( cos−1(w>v)
2π
) = 1
2 +
1
π
( sin−1(w>v)− cos−1(w>v) )",B Proofs,[0],[0]
"= 1
2 +
1
π
( 2 sin−1(w>v)−",B Proofs,[0],[0]
"π
2
) = 2 sin−1(w>v)
π .
",B Proofs,[0],[0]
"The absolute value of the above can be easily verified to be upper bounded by |w>v|, from which the result follows.
",B Proofs,[0],[0]
"With these lemmas at hand, we turn to prove our theorem.",B Proofs,[0],[0]
"By a standard measure concentration argument, we can find dk unit vectors u1,u2, . . .",B Proofs,[0],[0]
",udk in Rd such that their inner product is at most
O( √ k log(d)/d) (where the O(·) notation is w.r.t. d).",B Proofs,[0],[0]
"This induces dk functions hu1 , hu2 , . . .",B Proofs,[0],[0]
", hudk where
hu(x1, . . .",B Proofs,[0],[0]
",xk) =",B Proofs,[0],[0]
"∏k l=1 sign(u
>xl).",B Proofs,[0],[0]
Their L2 norm (w.r.t.,B Proofs,[0],[0]
the distribution over xk1 =,B Proofs,[0],[0]
"(x1, . . .",B Proofs,[0],[0]
",xk)) is 1, as they take values in {−1,+1}.",B Proofs,[0],[0]
"Moreover, since x1, . . .",B Proofs,[0],[0]
",xk are i.i.d.",B Proofs,[0],[0]
"standard Gaussian, we have by Lemma 4 that for any i 6= j,
〈hui , huj 〉L2 = ∣∣∣∣∣E",B Proofs,[0],[0]
[ k∏ l=1 sign(u>i xl) k∏,B Proofs,[0],[0]
l=1 sign(u>j xl),B Proofs,[0],[0]
],B Proofs,[0],[0]
"∣∣∣∣∣ =
∣∣∣∣∣ k∏ l=1 E [ sign(u>i xl)sign(u > j xl) ]∣∣∣∣∣ = ∣∣∣E",B Proofs,[0],[0]
"[sign(u>i xl)sign(u>j xl)]∣∣∣k
≤ |u>i uj |k ≤",B Proofs,[0],[0]
"O
(√ k log(d)
d
)k .
",B Proofs,[0],[0]
"Using this and Lemma 3, we have that for any function g,
1
dk dk∑ i=1",B Proofs,[0],[0]
"〈hui , g〉2L2 ≤",B Proofs,[0],[0]
‖g‖ 2 L2 ·  1 dk +O (√ k log(d) d ),B Proofs,[0],[0]
"k ≤ ‖g‖2L2 ·O (√ k log(d) d )k .
",B Proofs,[0],[0]
"Moreover, since this bound is derived based only on an inner product condition between u1, . . .",B Proofs,[0],[0]
",udk , the same result would hold for Uu1, . . .",B Proofs,[0],[0]
", Uudk where U is an arbitrary orthogonal matrix, and in particular if we pick it uniformly at random:
E U  1 dk dk∑ i=1",B Proofs,[0],[0]
"〈hUui , g〉2L2  ≤ ‖g‖2L2 · ( 1 dk +O",B Proofs,[0],[0]
"(√ k log(d) d )) .
",B Proofs,[0],[0]
"Now, note that for any fixed i, Uui is uniformly distributed on the unit sphere, so the left hand side simply equals Eu [ 〈hu, g〉2L2 ] , and we get
E u",B Proofs,[0],[0]
"[ 〈hu, g〉2L2 ] ≤ ‖g‖2",B Proofs,[0],[0]
"·O
(√ k log(d)
d
)k .",B Proofs,[0],[0]
"(7)
With this key inequality at hand, the proof is now very similar to the one of Theorem 1.",B Proofs,[0],[0]
"Given the predictor pw(xk1), where w ∈ Rn, define the vector-valued function g(xk1) = ∂∂wpw(x k 1), and let g(x k 1) =",B Proofs,[0],[0]
"(g1(x k 1), g2(x k 1), . . .",B Proofs,[0],[0]
", gn(x k 1)) for real-valued functions g1, . . .",B Proofs,[0],[0]
", gn.",B Proofs,[0],[0]
"To prove the bound, it is enough to upper bound Eu ‖∇Fu(w)",B Proofs,[0],[0]
"− a‖2 for any vector a independent of u. In particular, let us choose a =
Exk1",B Proofs,[0],[0]
[ pw(x k 1)g(x k 1) ] .,B Proofs,[0],[0]
"We thus bound the following:
E u ‖∇Fu(w)− E
xk1
[ pw(x k 1)g(x k 1) ]",B Proofs,[0],[0]
"‖2 = E
u ‖ E xk1
",B Proofs,[0],[0]
[( pw(x k 1)− hu(xk1) ) g(xk1) ],B Proofs,[0],[0]
"− E
xk1
[ pw(x k 1)g(x k 1) ]",B Proofs,[0],[0]
"‖2
= E u ‖ E xk1
[ hu(x k 1)g(x k 1) ]",B Proofs,[0],[0]
"‖2 = E
u n∑ j=1 ( E xk1",B Proofs,[0],[0]
"[ hu(x k 1)gj(x k 1) ])2
= E u n∑ j=1 〈hu, gj〉2L2 = n∑ j=1 E u 〈hu, gj〉2L2
(∗) ≤ n∑ j=1 ‖gj‖2 ·O
(√ k log(d)
d
)",B Proofs,[0],[0]
"k =
n∑ j=1 E xk1",B Proofs,[0],[0]
"[g2j (x k 1)] ·O
(√ k log(d)
d
)k
= E xk1 ‖g(xk1)‖2 ·O
(√ k log(d)
d
)k ≤ G(w)2 ·O (√ k log(d)
d
)k ,
where (∗) follows from (7).",B Proofs,[0],[0]
"By definition of Var(H, F,w), the result follows.",B Proofs,[0],[0]
"Generalization for the classification loss is obtained in the exact same way to the one used in the proof of Theorem 1.
",B Proofs,[0],[0]
"B.3 Proof of lemma 1
Proof (UW )i,j = ∑ t Ui,tWt,j = Wi,j − 2Wi−1,j +Wi−2,j
",B Proofs,[0],[0]
"If i ≥ j + 1 then Wi,j+Wi−2,j2 = Wi−1,j and therefore the above is clearly zero.",B Proofs,[0],[0]
If i < j then all the values of W are zeros.,B Proofs,[0],[0]
"Finally, if i = j we obtain 1.",B Proofs,[0],[0]
"This concludes our proof.
",B Proofs,[0],[0]
B.4 Proof of lemma,B Proofs,[0],[0]
"2
Proof Given a sample f , and that our current weight matrix is Û , let p = W−1f .",B Proofs,[0],[0]
"The loss function on f is given by
1 2 ‖Û f − p‖2
The gradient w.r.t.",B Proofs,[0],[0]
Û is ∇ =,B Proofs,[0],[0]
"(Û f − p)f> = Ûff> − pf>
We obtain that the update rule is Ût+1 = Ût",B Proofs,[0],[0]
− η ( Ûtff > − pf> ) = Ût(I − ηff>),B Proofs,[0],[0]
"+ ηpf>
",B Proofs,[0],[0]
"Taking expectation with respect to the random choice of the pair, using again f = Wp, and assuming Epp> = λI , we obtain that the stochastic gradient update rule satisfies
E Ût+1 = Ût(I − ηλWW>) + ηλW>
Continuing recursively, we obtain
E Ût+1 = E Ût(I − ηλWW>) + ηλW> =",B Proofs,[0],[0]
[ E Ût−1(I − ηλWW>),B Proofs,[0],[0]
+ ηλW,B Proofs,[0],[0]
> ],B Proofs,[0],[0]
"(I − ηλWW>) + ηλW>
= E Ût−1(I",B Proofs,[0],[0]
− ηλWW>)2 + ηλW>(I,B Proofs,[0],[0]
− ηλWW>),B Proofs,[0],[0]
"+ ηλW>
= Û0(I",B Proofs,[0],[0]
− ηλWW>)t + ηλW>,B Proofs,[0],[0]
"t∑ i=0 (I − ηλWW>)i
We assume that Û0 = 0, and thus
E Ût+1 = ηλW> t∑ i=0 (I − ηλWW>)i
B.5 Proof of Theorem 4
",B Proofs,[0],[0]
"Proof Fix some i, we have that
(I − η λWW>)i = (QIQ> − η λQSV >V SQ>)i = Q(I − η λSS)iQ> = QΛiQ>
where Λi is diagonal with Λij,j = (1 − ηλS2j )",B Proofs,[0],[0]
"i. Therefore, by the properties of geometric series, E Ût+1 converges if and only if η λS21,1 < 1.",B Proofs,[0],[0]
"When this condition holds we have that
Û∞ = η λW > ∞∑ i=0 (I − η λWW>)i
= η λW>(η λWW>)−1 = W>(WW>)−1
= V SQ>(QSV >V SQ>)−1 = V SQ>QS−2Q> = V S−1Q> = U .
",B Proofs,[0],[0]
"Therefore,
E Ût+1",B Proofs,[0],[0]
"− U = η λW> ∞∑
i=t+1
(I − η λWW>)i
= η λV SQ> ∞∑
i=t+1
QΛiQ>
= V [ ∞∑ i=t+1 (η λS)Λi ] Q> .
",B Proofs,[0],[0]
"The matrix in the parentheses is diagonal, where the j’th diagonal element is
ηλSj,j · (1− ηλS2j,j)t+1
ηλS2j,j = S−1j,j (1− ηλS 2 j,j) t+1
It follows that ‖E Ût+1",B Proofs,[0],[0]
"− U‖ = max
j S−1j,j (1− ηλS 2 j,j) t+1
Using the inequality (1− a)t+1 ≥ 1− (t+ 1)a, that holds for every a ∈ (−1, 1), we obtain that
‖E Ût+1",B Proofs,[0],[0]
"− U‖ ≥ S−1n,n(1− (t+ 1)ηλS2n,n) ≥ S−1n,n(1− (t+ 1)",B Proofs,[0],[0]
"S2n,n S21,1 ) .
",B Proofs,[0],[0]
"It follows that whenever,
t+ 1 ≤ S21,1
2S2n,n ,
we have that ‖E Ût+1",B Proofs,[0],[0]
"− U‖ ≥ 0.5S−1n,n. Finally, observe that
S2n,n =",B Proofs,[0],[0]
min x:‖x‖=1,B Proofs,[0],[0]
"x>WW>x ≤ e>1 WW>e1 = 1 ,
hence S−1n,n ≥ 1.",B Proofs,[0],[0]
"We now prove the second part of the theorem, regarding the condition number of W>W , namely,
S21,1 2S2n,n ≥ Ω(n3.5).",B Proofs,[0],[0]
"We note that the condition number of W>W can be calculated through its inverse matrix’s, namely, U>U ’s condition number, as those are equal.
",B Proofs,[0],[0]
It is easy to verify that Uen = en.,B Proofs,[0],[0]
"Therefore, the maximal eigenvalue of U>U is at least 1.",B Proofs,[0],[0]
"To construct an upper bound on the minimal eigenvalue of U>U , consider v ∈",B Proofs,[0],[0]
Rn s.t. for i ≤,B Proofs,[0],[0]
√ n,B Proofs,[0],[0]
we have vi = −12(i/n) 2 and for i >,B Proofs,[0],[0]
√ n,B Proofs,[0],[0]
we have vi = 12n,B Proofs,[0],[0]
− i/n√ n .,B Proofs,[0],[0]
We have that |vi| = O(1/n) for i < √ n+ 2 and v is linear for i ≥,B Proofs,[0],[0]
√ n.,B Proofs,[0],[0]
This implies that (Uv)i = 0 for i ≥ √ n + 2.,B Proofs,[0],[0]
"We also have (Uv)1 = v1 = −0.5/n2, (Uv)2 = −2v1 +",B Proofs,[0],[0]
"v2 ≈ −1/n2, and for i ∈ {3, . . .",B Proofs,[0],[0]
", √ n}",B Proofs,[0],[0]
"we have
(Uv)i = vi−2 − 2vi−1 + vi = −3/n2
Finally, for i = √ n+ 1 we have
(Uv)i = vi−2 − 2vi−1 + vi = vi",B Proofs,[0],[0]
"− vi−1 − (vi−1 − vi−2)
",B Proofs,[0],[0]
= 1 n √ n,B Proofs,[0],[0]
− 1 2n2 ( (i− 1)2,B Proofs,[0],[0]
− (i− 2)2 ),B Proofs,[0],[0]
= 1 n √ n,B Proofs,[0],[0]
"− 1 2n2 (2i− 3) = 1 2n2 .
",B Proofs,[0],[0]
"This yields ‖Uv‖2 ≈ Θ( √ n/n4) = Θ(n−3.5)
",B Proofs,[0],[0]
"In addition,
‖v‖2 ≥ n∑
i=n/2
v2i ≥ n
2 v2n/2 =
n
2
( 1
2n",B Proofs,[0],[0]
"− 1 2 √ n
)2 = Ω(1) .
",B Proofs,[0],[0]
"Therefore, ‖Uv‖2
‖v‖2 = O(n−3.5) ,
which implies that the minimal eigenvalue of U>U is at most O(n−3.5).",B Proofs,[0],[0]
"All in all, we have shown that the condition number of U>U is Ω(n−3.5), implying the same over W>W .
",B Proofs,[0],[0]
"B.6 Gradient Descent for Linear Regression
The loss function is E x,y 1 2 (x>w − y)2
The gradient at w is ∇ = E
x,y x(x>w − y) =",B Proofs,[0],[0]
( E x xx> ),B Proofs,[0],[0]
w,B Proofs,[0],[0]
"− E x,y xy :=",B Proofs,[0],[0]
"Cw − z
For the optimal solution we have Cw∗",B Proofs,[0],[0]
"− z = 0, hence z = Cw∗.",B Proofs,[0],[0]
"The update is therefore
wt+1 =",B Proofs,[0],[0]
wt − η(Cwt − z) =,B Proofs,[0],[0]
(I − ηC)wt + ηz = . . .,B Proofs,[0],[0]
"= t∑ i=0 (I − ηC)iηz = t∑ i=0 (I − ηC)iηCw∗
Let C = V DV > be the eigenvalue decomposition of C. Observe that
wt+1 = V t∑ i=0 η(I − ηD)iDV >w∗
Hence
‖w∗",B Proofs,[0],[0]
− wt+1‖ = ‖(V V > − V t∑ i=0 η(I − ηD)iDV >),B Proofs,[0],[0]
"w∗‖
= ‖(I − t∑ i=0 η(I − ηD)iD)V >w∗‖ = ‖(I",B Proofs,[0],[0]
"− ηD)t+1 V >w∗‖ ,
where the last equality is because for every j we have
(I − t∑ i=0 η(I − ηD)iD)j,j = 1− t∑ i=0 η(1− ηDj,j)iDj,j = (1− ηDj,j)t+1 .
",B Proofs,[0],[0]
Denote v∗ = V >w∗.,B Proofs,[0],[0]
"We therefore obtain that
‖w∗",B Proofs,[0],[0]
"− wt+1‖2 = n∑ j=1 ( (1− ηDj,j)t+1v∗j )2",B Proofs,[0],[0]
"To obtain an upper bound, choose η = 1/D1,1 and t+ 1 ≥ D1,1Dn,n log(‖w
∗‖/ ), and then, using 1− a ≤ e−a, we get that
‖w∗",B Proofs,[0],[0]
"− wt+1‖2 ≤ n∑ j=1 ( exp(−ηDj,j(t+ 1))v∗j )2 ≤ 2 ‖w∗‖2 n∑ j=1 ( v∗j )2 = 2 .
",B Proofs,[0],[0]
"To obtain a lower bound, observe that if v∗1 is non-negligible then η must be at most 1/D1,1 (otherwise the process will diverge).",B Proofs,[0],[0]
"If in addition v∗n is a constant (for simplicity, say v ∗ n = 1), then
‖w∗",B Proofs,[0],[0]
"− wt+1‖ ≥ (1− ηDn,n)t+1 ≥ (1−Dn,n/D1,1)t+1 ≥ 1− (t+ 1)Dn,n/D1,1 ,
where we used (1− a)t+1 ≥ 1− (t+ 1)a for a ∈",B Proofs,[0],[0]
"[−1, 1].",B Proofs,[0],[0]
"It follows that if t+ 1 < 0.5Dn,n/",B Proofs,[0],[0]
"D1,1 then we have that ‖w∗",B Proofs,[0],[0]
"− wt+1‖ ≥ 0.5.
",B Proofs,[0],[0]
"B.7 The Covariance Matrix of Section 4.1.2
Denote by C ∈ R3,3 the covariance matrix, and let λi(C) denote the i’th eigenvalue of C (in a decreasing order).",B Proofs,[0],[0]
The condition number of C is λ1(C)/λ3(C).,B Proofs,[0],[0]
"Below we derive lower and upper bounds on the condition number under some assumptions.
",B Proofs,[0],[0]
"Lower bound We assume that Ef,t f2t = Ω(n2) (this would be the case in many typical cases, for example when the allowed slopes are in {±1}), that k (the number of pieces of the curve) is constant, and that the changes of slope are in [−1, 1].
",B Proofs,[0],[0]
"Now, take v =",B Proofs,[0],[0]
"[1, 1, 1]>, then
v>Cv = E f,t (ft−1 + ft + ft+1) 2 = Ω(n2)
",B Proofs,[0],[0]
This yields λ1(C) ≥ Ω(n2).,B Proofs,[0],[0]
"Next, take v =",B Proofs,[0],[0]
"[1,−2, 1]> we obtain
v>Cv = E f,t (ft−1 − ft + ft+1)2 = O(k/n)
",B Proofs,[0],[0]
This yields λ3(C) ≤ O(k/n).,B Proofs,[0],[0]
"All in all, we obtain that the condition number of C is Ω(n3).
",B Proofs,[0],[0]
"Upper bound We consider distribution over f s.t. for every f , at exactly k indices f changes slope from 1 to −1 or from −1 to 1 (with equal probability over the indices), and at the rest of the indices we have that f is linear with a slope of 1 or −1.",B Proofs,[0],[0]
"Denote p = k/n. Take any unit vector v, and denote v̄ = v1 + v2 + v3.",B Proofs,[0],[0]
"Then
v>Cv = E f,t (v1ft−1 + v2ft + v3ft+1) 2
= E f
[ 0.5(1− p) ( (v̄ft + v3 − v1)2 + (v̄ft + v1 − v3)2 ) + 0.5p ( (v̄ft + v3 + v1) 2 + (v̄ft − v3 − v1)2 )]
= v̄2 E f f2t + (1− p)(v1 − v3)2 + p(v1 + v3)2 .
",B Proofs,[0],[0]
"Since Ef,t f2t = Θ(n2), it is clear that v>Cv = O(n2).",B Proofs,[0],[0]
We next establish a lower bound of Ω(1/n).,B Proofs,[0],[0]
"Observe that if v̄2 ≥ Ω(1/n3), we are done.",B Proofs,[0],[0]
"If this is not the case, then −v2 ≈ v1 + v3.",B Proofs,[0],[0]
"If |v1 + v3| > 0.1, we are done.",B Proofs,[0],[0]
"Otherwise, 0.9 ≤ 1",B Proofs,[0],[0]
"− v22 = v21 + v23 , so we must have that v1 and v3 has opposite signs, and one of them is large, hence (v1 − v3)2 is larger than a constant.",B Proofs,[0],[0]
"This concludes our proof.
",B Proofs,[0],[0]
"B.8 Proof of Update Rule 4 Convergence in the Lipschitz Case
Proof Let B be an upper bound over ‖w(t)‖ for all time step t, and over ‖v∗‖.",B Proofs,[0],[0]
"Moreover, assume |u| ≤ c for some constant c. We denote the update rule by w(t) = w(t−1) + η∇̃, and bound from below:
‖w(t)",B Proofs,[0],[0]
− v∗‖2 − ‖w(t+1),B Proofs,[0],[0]
− v∗‖2 = 2〈w(t),B Proofs,[0],[0]
"− v∗, η∇̃〉 − η2‖∇̃‖2 = 2η E",B Proofs,[0],[0]
[ (u((w(t))>x)− u((v∗)>x))(w(t),B Proofs,[0],[0]
"− v∗)x ] − η2‖∇̃‖2
(1) ≥ 2η L
E [ (u((w(t))>x)− u((v∗)>x))2 ]",B Proofs,[0],[0]
"− η2‖∇̃‖2
(2) ≥ 2η L
E [ (u((w(t))>x)− u((v∗)>x))2 ]",B Proofs,[0],[0]
"− η2B2c2
where (1) follows from L-Lipschitzness and monotonicity of u, (2) follows from bounding ‖w‖, ‖x‖ and u. Let the expected error of the regressor parametrized by wt be denoted et.",B Proofs,[0],[0]
"We separate into cases:
• If ‖wt − v∗‖2 − ‖wt+1",B Proofs,[0],[0]
"− v∗‖2 ≥ η2B2c2, we can rewrite ‖wt − v∗‖2 − η2B2c2 ≥ ‖wt+1",B Proofs,[0],[0]
"− v∗‖2, and note that since ‖wt+1",B Proofs,[0],[0]
"− v∗‖2 ≥ 0, and ‖w0 − v∗‖2 ≤ B2, there can be at most B2
η2B2c2",B Proofs,[0],[0]
"= 1 η2c2
iterations where this condition will hold.
",B Proofs,[0],[0]
"• Otherwise, we get that et ≤ ηB2c2L.
Therefore, for a given , by taking T = c 4B4L2
2 , and setting η = √ 1 Tc2 , we obtain that after T iterations, the
first case is not holding anymore, and the second case implies eT ≤ .",B Proofs,[0],[0]
"Lemma 5 Any parity function over d variables is realizable by a network with one fully connected layer of width d̃ > 3d2 with ReLU activations, and a fully connected output layer with linear activation and a single unit.
",C Technical Lemmas,[0],[0]
"Proof Let the weights entering each of the first 3d2 hidden units be set to v ∗, and the rest to 0.",C Technical Lemmas,[0],[0]
Further assume that for i ∈,C Technical Lemmas,[0],[0]
"[d/2], the biases of the first 3i + {1, 2, 3} units are set to −(2i − 12), −2i, −(2i + 1 2) respectively, and that their weights in the output layer are 1,−2, and 1.",C Technical Lemmas,[0],[0]
"It is not hard to see that the weighted sum of those triads of neurons is 12 if 〈x,v
∗〉 = 2i, and 0 otherwise.",C Technical Lemmas,[0],[0]
Observe that there’s such a triad defined for each even number in the range [d].,C Technical Lemmas,[0],[0]
"Therefore, the output of this net is 0 if y = −1, and 12 otherwise.",C Technical Lemmas,[0],[0]
"It is easy to see that scaling of the output layer’s weights by 4, and introduction of a −1 bias value to it, results in a perfect predictor.",C Technical Lemmas,[0],[0]
Our experiments are implemented in a simple manner in python.,D Command Lines for Experiments,[0],[0]
We use the tensorflow package for optimization.,D Command Lines for Experiments,[0],[0]
"The following command lines can be used for viewing all optional arguments:
To run experiment 2.1, use:
python ./parity.py --help
To run experiment 3.1, use:
python ./tuple_rect.py --help
",D Command Lines for Experiments,[0],[0]
"For SNR estimations, use:
python ./tuple_rect_SNR.py --help
",D Command Lines for Experiments,[0],[0]
"To run experiment A, use:
python ./dec_vs_e2e_stocks.py --help
",D Command Lines for Experiments,[0],[0]
"For Section 4’s experiments, given below are the command lines used to generate the plots.",D Command Lines for Experiments,[0],[0]
"Additional arguments can be viewed by running:
python PWL_fail1.py --help
To run experiment 4.1.1, use:
python PWL_fail1.py --FtoK
To run experiment 4.1.2, use:
python PWL_fail1.py --FtoKConv
To run experiment 4.1.3, use:
python PWL_fail1.py --FtoKConvCond",D Command Lines for Experiments,[0],[0]
"--batch_size 10 --number_of_iterations 500 --learning_rate 0.99
To run experiment 4.1.4, use:
python PWL_fail1.py --FAutoEncoder
To run Section 5’s experiments, run:
python step_learn.py --help",D Command Lines for Experiments,[0],[0]
"In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art.",abstractText,[0],[0]
"However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms.",abstractText,[0],[0]
"We describe four types of simple problems, for which the gradient-based algorithms commonly used in deep learning either fail or suffer from significant difficulties.",abstractText,[0],[0]
"We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied1.",abstractText,[0],[0]
Failures of Gradient-Based Deep Learning,title,[0],[0]
"A problem facing many services – from search engines and news feeds to machine learning – is data summarization: how can one select a small but representative, i.e., diverse, subset from a large dataset.",1. Introduction,[0],[0]
"For instance, Google Images outputs a small subset of images from its enormous dataset given a user query.",1. Introduction,[0],[0]
"Similarly, in training a learning algorithm one may be required to choose a subset of data points to train on as training on the entire dataset may be costly.",1. Introduction,[0],[0]
"However, data summarization algorithms prevalent in the online world have been recently shown to be biased with respect to sensitive attributes such as gender, race or ethnicity.",1. Introduction,[0],[0]
"For instance, a recent study found evidence of systematic
1École Polytechnique Fédérale de Lausanne (EPFL), Switzerland 2Microsoft Research, India 3UC Berkeley.",1. Introduction,[0],[0]
"Correspondence to: L. Elisa Celis <elisa.celis@epfl.ch>, Nisheeth K. Vishnoi <nisheeth.vishnoi@epfl.ch>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
under-representation of women in search results (Kay et al., 2015).",1. Introduction,[0],[0]
"Concretely, the above work studied the output of Google Images for various search terms involving occupations and found, e.g., that for the search term “CEO”, the percentage of women in top 100 results was 11%, significantly lower than the ground truth of 27%.",1. Introduction,[0],[0]
"Through studies on human subjects, they also found that such misrepresentations have the power to influence people’s perception about reality.",1. Introduction,[0],[0]
"Beyond humans, since data summaries are used to train algorithms, there is a danger that these biases in the data might be passed on to the algorithms that use them; a phenomena that is being revealed more and more in automated data-driven processes in education, recruitment, banking, and judiciary systems, see (O’Neil, 2016).
",1. Introduction,[0],[0]
"A robust and widely deployed method for data summarization is to associate a diversity score to each subset and select a subset with probability proportional to this score; see (Hesabi et al., 2015).",1. Introduction,[0],[0]
"This paper focuses on a concrete geometric measure of diversity of a subset S of a dataset {vx}x∈X of vectors – the determinantal measure denoted by G(S) (Kulesza & Taskar, 2012); and the resulting probability distribution is called a determinantal point process (DPP).",1. Introduction,[0],[0]
"G(S) generalizes the correlation measure for two vectors to multiple vectors and, intuitively, the larger G(S), the more diverse is S in the feature space.",1. Introduction,[0],[0]
"Among benefits of G(·) are its overall simplicity, wide applicability – not depending on combinatorial properties of the data, and efficient computability.",1. Introduction,[0],[0]
"A potential downside might be the additional effort required in modeling, i.e., to represent the data in a suitable vector form so that the geometry of the dataset indeed corresponds to diversity.
",1. Introduction,[0],[0]
"Despite the well-acknowledged ability of DPPs to produce diverse subsets, unfortunately, there seems to be no obvious way to ensure that this also guarantees fairness in the DPP samples in the form of appropriate representation of sensitive attributes in the subset selected.",1. Introduction,[0],[0]
"Partially, this is due to the fact that fairness could mean different things in different contexts.",1. Introduction,[0],[0]
"For instance, consider a dataset in which each data point has a gender.",1. Introduction,[0],[0]
"One notion of fairness, useful in ensuring that the ground truth does not get distorted, is proportional representation: i.e., the distribution of sensitive characteristics in the output set should be identical to that of the input dataset (Kay et al., 2015).",1. Introduction,[0],[0]
"Another notion of fairness, argued to be necesseary to reverse the effect of
historical biases (Koriyama et al., 2013), could be equal representation – the representation of sensitive characteristics should be equal independent of the ratio in the input dataset.",1. Introduction,[0],[0]
"While these measures of fairness have natural generalizations to the case when the number of sensitive types is more than two, and can be refined in several ways, one thing remains common: they all operate in the combinatorial space of sensitive attributes of the data points.",1. Introduction,[0],[0]
"Simple examples (see, e.g., Figure 1 in the Supplementary File) show that, in certain settings, geometric diversity does not imply fairness and vice-versa; however, there seems to be no intrinsic barrier in attaining both.
",1. Introduction,[0],[0]
We initiate a rigorous study of the problem of incorporating fairness with respect to sensitive attributes of data in DPPbased sampling for data summarization.,1. Introduction,[0],[0]
"Our contributions are: A framework that can incorporate a wide class of notions of fairness with respect to disjoint sensitive attributes and, conditioned on being fair in the specified sense, outputs subsets where the probability of a set is still proportional to G()̇.",1. Introduction,[0],[0]
"In particular, we model the problem as sampling from a partition DPP – the parts correspond to different sensitive attributes and the goal is to select a specified number of points from each.",1. Introduction,[0],[0]
"Unfortunately, the problem of sampling from partition DPPs has been recently shown to be intractable in a strong sense (Celis et al., 2017) and the question of designing fast algorithms for it, at the expense of being approximate, has been open.",1. Introduction,[0],[0]
Our main technical result is a linear time algorithm (see Section 3.1) to sample from partition DPPs that is guaranteed to output samples from close to the DPP distribution under a natural condition on the data (see Definition 4).,1. Introduction,[0],[0]
We prove that random data matrices satisfy this condition in Section 3.3.,1. Introduction,[0],[0]
"We run our algorithm on the Adult dataset (Blake & Merz, 1998) and a curated image dataset with various parameter settings and observe a marked improvement in fairness without compromising geometric diversity by much.",1. Introduction,[0],[0]
"A theoretical justification of this low price of fairness is provided in Section 4; while there have been few works on controlling fairness, ours is the first to give a rigorous, quantitative price of fairness guarantee in any setting.",1. Introduction,[0],[0]
"Overall, our work gives a general and rigorous algorithmic solution to the problem of controlling bias in DPP-based sampling algorithms for data summarization while maximizing diversity.
",1. Introduction,[0],[0]
Related Work.,1. Introduction,[0],[0]
There are several data pre-processing approaches to reduce bias in training data.,1. Introduction,[0],[0]
"For example, in (Kamiran & Calders, 2012) or (He & Garcia, 2009), bias is removed from training data by over- or under-sampling from the dataset with appropriately defined cardinality constraints on the parts of a partition.",1. Introduction,[0],[0]
The sampling approach used is often either uniform or preferential (according to a problem-dependent ranking).,1. Introduction,[0],[0]
"We show that sampling using partition-DPPs has better results in ensuring diversity of the sampled subset than any such sampling method.
DPP-based sampling has been deployed for many data summarization tasks including text and images (Kulesza & Taskar, 2011), videos (Gong et al., 2014), documents (Lin & Bilmes, 2012), recommendation systems (Zhou et al., 2010), and sensors (Krause et al., 2008); and the study of DPPs with additional budget or resource constraints is of importance.",1. Introduction,[0],[0]
"While for unconstrained DPPs there are efficient algorithms to sample (Hough et al., 2006), the problem of sampling from constrained DPPs is intractable; see (Celis et al., 2017), where pseudopolynomial time algorithms for partition DPPs are presented.",1. Introduction,[0],[0]
"There is also work on approximate MCMC algorithms for sampling from various discrete point processes (see (Rebeschini & Karbasi, 2015; Anari et al., 2016) and the references therein), and algorithms that are efficient for constrained DPPs under certain restrictions on the data matrix and constraints (see (Li et al., 2016) and the references therein).",1. Introduction,[0],[0]
"To the best of our knowledge, ours is the first algorithm for constrained DPPs that is near-linear time.",1. Introduction,[0],[0]
"Our algorithm is a greedy, approximate algorithm, and can be considered an extension of a similar algorithm for unconstrained DPPs given by (Deshpande & Vempala, 2006).",1. Introduction,[0],[0]
"Finally, our work contributes towards an ongoing effort to measure, understand and incorporate fairness (e.g., see (Barocas & Selbst, 2015; Caliskan et al., 2017; Dwork et al., 2012; Zafar et al., 2017)) in fundamental algorithmic problems, including ranking (Celis et al., 2018b), voting (Celis et al., 2018a), and personalization (Celis & Vishnoi, 2017).",1. Introduction,[0],[0]
"In this section we present the formal notions, model and other theoretical constructs studied in this paper.",2. Our Model,[0],[0]
X will denote the dataset and we let m denote its size.,2. Our Model,[0],[0]
"We assume that for each x ∈ X , we are given a (feature) vector vx ∈ Rn, where n ≤ m is the dimension of the data.",2. Our Model,[0],[0]
Let V denote the m × n matrix whose rows correspond to the vectors vx for x ∈ X .,2. Our Model,[0],[0]
"For a set S ⊆ X , we use VS to denote the submatrix of V that is obtained by picking the rows of V corresponding to the elements of S. We can now describe geometric diversity formally.
Definition 1.",2. Our Model,[0],[0]
(Geometric Diversity),2. Our Model,[0],[0]
"Given a dataset X and the corresponding feature vectors V ∈ Rm×n, the geometric diversity of a subset S ⊆ X is defined as G(S)",2. Our Model,[0],[0]
":= det ( VSV > S ) , which is the squared volume of the parallelepiped spanned by the rows of VS .
",2. Our Model,[0],[0]
"This volume generalizes the correlation measure for two vectors to multiple vectors and, intuitively, the larger the volume, the more diverse is S in the feature space; see
Figure 2 in the Supplementary File for an illustration.",2. Our Model,[0],[0]
"Geometric diversity gives rise to the following distribution on subsets known as a determinantal point process (DPP).
",2. Our Model,[0],[0]
Definition 2.,2. Our Model,[0],[0]
(DPPs and k-DPPs),2. Our Model,[0],[0]
"Given a dataset X and the corresponding feature vectors V ∈ Rm×n, the DPP is a distribution over subsets S ⊆ X such that the probability
P[S] ∝",2. Our Model,[0],[0]
det ( VSV > S ) .,2. Our Model,[0],[0]
"The induced probability distribution over k-sized subsets is called k-DPP.
",2. Our Model,[0],[0]
A characteristic of a DPP measure is that the inclusion of one item makes including other similar items less likely.,2. Our Model,[0],[0]
"Consequently, DPPs assign greater probability to subsets of points that are diverse; for example, a DPP prefers search results that cover multiple aspects of a user’s query, rather than the most popular one.
",2. Our Model,[0],[0]
Our Algorithmic Framework: We are given a dataset X along with corresponding feature vectors V ∈ Rm×n and a positive number k ≤ m that denotes the size of the subset or summary that needs to be generated.,2. Our Model,[0],[0]
"The dataset X is partitioned into p disjoint classes X1 ∪X2 ∪ · · · ∪Xp, each corresponding to a sensitive class.",2. Our Model,[0],[0]
"A key feature of our model is that we do not fix one notion of fairness; rather, we allow for the specification of fairness constraints with respect to these sensitive classes.",2. Our Model,[0],[0]
"Formally, we do this by taking as input p natural numbers (k1, k2, . . .",2. Our Model,[0],[0]
", kp) such that ∑p j=1 kj = k is the sample size.",2. Our Model,[0],[0]
These numbers give rise to a fair family of allowed subsets defined to be B := {S ⊆ X : |S ∩,2. Our Model,[0],[0]
"Xj | = kj for all j = 1, 2, . . .",2. Our Model,[0],[0]
", p}.",2. Our Model,[0],[0]
"By setting (k1, . . .",2. Our Model,[0],[0]
", kp) appropriately, the user can ensure their desired notion of fairness.",2. Our Model,[0],[0]
"For example, if the dataset hasmi items with the i-th sensitive attribute, then we can set ki := kmi/m to obtain proportional representation.",2. Our Model,[0],[0]
"Similarly, equal representation can be implemented by setting ki = k/p for all i.
The fair data summarization problem is to sample from a distribution that is supported on B. However, there could be many such distributions; we pick one that is “closest” to the to the k-DPP described by V .",2. Our Model,[0],[0]
We use the Kullback-Leibler (KL) divergence between distributions q and q̃ defined as DKL(q||q̃) := ∑ S qS log qS q̃S .1,2. Our Model,[0],[0]
"The following lemma characterizes the distribution supported on B that has the least KL-divergence to a given distribution (see Appendix B.1 in the Supplementary File for the proof).
",2. Our Model,[0],[0]
Lemma 1.,2. Our Model,[0],[0]
"Given a distribution q̃ with support set C, let B ⊆ C and q be any distribution on B. Then the optimal value of minqDKL(q||q̃) is achieved by the distribution q?, such that q?S ∝ q̃S , for S ∈ B and 0 otherwise.",2. Our Model,[0],[0]
"Thus, the distribution above can be thought of as the most diverse while being fair; we call it partition DPP, or P -DPP.
Definition 3.",2. Our Model,[0],[0]
(P -DPP),2. Our Model,[0],[0]
"Given a dataset X , the corresponding feature vectors V ∈ Rm×n, a partition X = X1 ∪ X2 ∪ · · · ∪ Xp into p parts, and natural numbers k1, . . .",2. Our Model,[0],[0]
", kp, P -DPP defines a distribution q?",2. Our Model,[0],[0]
"over subsets S ⊆ X of size k = ∑p i=1 ki such that for all S ∈ B we
1Note that when there are only two parts, one can recover the percentages of elements from each part from the KL-distance.",2. Our Model,[0],[0]
"For multiple parts, the KL-distance is a natural (and general) singledimensional function of the percentage vector with which to measure the deviation from the target distribution.
",2. Our Model,[0],[0]
"have q?S := det(VSV
> S )∑
T∈B",2. Our Model,[0],[0]
"det(VTV > T ) , and q?S = 0",2. Our Model,[0],[0]
"otherwise.
",2. Our Model,[0],[0]
"Given the results of (Celis et al., 2017), we know that sampling from P -DPPs is #P-hard and exact sampling algorithm for P -DPPs are unlikely.",2. Our Model,[0],[0]
"Correspondingly, the flexibility that our framework provides in specifying the fairness constraints comes at a computational cost.",2. Our Model,[0],[0]
"In this paper, we give a fast, approximate sampling algorithm for P -DPPs.",2. Our Model,[0],[0]
Notions of Volume and Projection.,3. Our Algorithm,[0],[0]
Let us recall the interpretation of determinants in terms of volumes.,3. Our Algorithm,[0],[0]
"For S ⊆ X , VS is the set of vectors {vx}x∈S .",3. Our Algorithm,[0],[0]
"If the vectors in S are pairwise orthogonal, then the matrix VSV >S is diagonal with entries {‖vx‖2}x∈S on the diagonal and, hence, det(VSV > S ) = ∏",3. Our Algorithm,[0],[0]
"x∈S ‖vx‖
2.",3. Our Algorithm,[0],[0]
"In the general case, the determinant is not simply the (squared) product of the norms of vectors, however a similar formula still holds.",3. Our Algorithm,[0],[0]
"Let H ⊆ Rn be any linear subspace and H⊥ be its orthogonal complement, i.e., H⊥ := {y ∈",3. Our Algorithm,[0],[0]
"Rn | 〈x, y〉 = 0 for all x ∈ H}.",3. Our Algorithm,[0],[0]
"Let ΠH : Rn → Rn be the orthogonal projection operator on the subspace H⊥, i.e., whenever w ∈",3. Our Algorithm,[0],[0]
"Rn decomposes as w1+w2 forw1 ∈ H andw2 ∈ H⊥, then ΠH(w) = w2.",3. Our Algorithm,[0],[0]
"By a slight abuse of notation, we also denote by Πv the operator that projects a vector to another that is orthogonal to a given vector v ∈",3. Our Algorithm,[0],[0]
"Rn, i.e., Πv(w)",3. Our Algorithm,[0],[0]
":= w − 〈w, v〉 / ‖v‖2 .
",3. Our Algorithm,[0],[0]
The following lemma is a simple generalization of the formula derived above for orthogonal families of vectors and inspires our algorithm for P -DPPs.,3. Our Algorithm,[0],[0]
The proof of this lemma is presented in Section B.3 in the Supplementary File.,3. Our Algorithm,[0],[0]
Lemma 2 (Determinant Volume Lemma).,3. Our Algorithm,[0],[0]
"Let w1, . . .",3. Our Algorithm,[0],[0]
", wk ∈",3. Our Algorithm,[0],[0]
"Rn be the rows of a matrix W ∈ Rk×n, then det(WW>)",3. Our Algorithm,[0],[0]
=,3. Our Algorithm,[0],[0]
∏k i=1,3. Our Algorithm,[0],[0]
"‖ΠHiwi‖ 2 , whereHi is the subspace spanned by {w1, . . .",3. Our Algorithm,[0],[0]
", wi−1} for all i = 1, 2, . . .",3. Our Algorithm,[0],[0]
", k.",3. Our Algorithm,[0],[0]
"Before we describe our algorithms for sampling from P - DPPs, it is instructive to consider the special case of k-DPPs itself and the simple “orthogonal” scenario – where all the vectors vx, for x ∈ X , are pairwise orthogonal.",3.1. Our Sample and Project Algorithm,[0],[0]
"In such a case, there is a simple iterative algorithm: sample x ∈ X with probability ∝ ‖vx‖2, then add x to S and remove x from X; repeat until |S|",3.1. Our Sample and Project Algorithm,[0],[0]
= k.,3.1. Our Sample and Project Algorithm,[0],[0]
"It is intuitively clear, and not hard to prove, that the final probability of obtaining a given set S as a sample is proportional to ∏ x∈S ‖vx‖ 2 = det(VSV > S ) and, hence, recovers the k-DPP exactly.
",3.1. Our Sample and Project Algorithm,[0],[0]
"In case of P -DPPs where all the vectors are pairwise orthogonal, and we need to sample ki vectors from partition Xi, we can sample the required number of elements from each partition independently using the procedure in the previous paragraph.",3.1. Our Sample and Project Algorithm,[0],[0]
"The orthogonality of the vectors and the disjointness of the parts implies that this sampling procedure gives the right probability distribution.
",3.1. Our Sample and Project Algorithm,[0],[0]
"Algorithm 1 Sample-And-Project 1: Input: V, (X1, .., Xp), (k1, .., kp) 2: S ← ∅ 3: k ← k1 + k2 + · · ·+ kp 4: Let wx := vx for all x ∈ X 5: while |S| < k do 6: Pick any2 i ∈ {1, . . .",3.1. Our Sample and Project Algorithm,[0],[0]
", p} such that |S ∩Xi| < ki 7: Define q ∈ RXi by qx := ‖wx‖2 for x ∈ Xi 8: Sample x̃ ∈",3.1. Our Sample and Project Algorithm,[0],[0]
"Xi from distribution { qx∑
y∈Xi qy } x∈Xi
9: S ← S ∪ {x̃} 10: Let v := wx̃ 11: For all x ∈ X , set wx := Πv(wx) 12: end while However, when the vectors vx are no longer pairwise orthogonal, the above heuristic can fail miserably.",3.1. Our Sample and Project Algorithm,[0],[0]
This is where we invoke Lemma 2.,3.1. Our Sample and Project Algorithm,[0],[0]
"It suggests the following strategy: once we select a vector, then we should orthogonalize all the remaining vectors with respect to it before repeating the sampling procedure.",3.1. Our Sample and Project Algorithm,[0],[0]
"For the case of k-DPPs, it can be shown that this heuristic outputs a set S with probability no more than k! times its desired probability (Deshpande & Vempala, 2006).",3.1. Our Sample and Project Algorithm,[0],[0]
The k! term is primarily because the k vectors can be chosen in any of the k! orders.,3.1. Our Sample and Project Algorithm,[0],[0]
"Taking this simple heuristic as a starting point and incorporating an additional idea to deal with partition constraints, we arrive at our Sample and Project algorithm – see Algorithm 1.
",3.1. Our Sample and Project Algorithm,[0],[0]
Given that we have made several simplifications and informal “jumps” when deriving the algorithm one cannot expect that the distribution over sets S produced by Algorithm 1 to be exactly the same as P -DPP.,3.1. Our Sample and Project Algorithm,[0],[0]
"Later in this section we give evidence that in fact the distribution output by the “Sample and Project” heuristic can be formally related to the P -DPP distribution, and hence the constructed algorithm is provably an approximation to a P -DPP.",3.1. Our Sample and Project Algorithm,[0],[0]
"However, we first note an attractive feature of this algorithm – it is fast and practical.",3.1. Our Sample and Project Algorithm,[0],[0]
"For a V ∈ Rm×n matrix and k = ∑p i=1 ki, Algorithm 1 can be implemented in O(mnk) time.
",3.1. Our Sample and Project Algorithm,[0],[0]
"Note that the size of the data for this problem is already Θ(mn), hence, the algorithm does only linear work per sampled point.",3.1. Our Sample and Project Algorithm,[0],[0]
"For P -DPPs there is only one known exact algorithm which samples in time mO(p), which is polynomial only when p = O(1) (Celis et al., 2017).
",3.1. Our Sample and Project Algorithm,[0],[0]
Another possible approach for sampling from DPPs is the Markov Chain Monte Carlo method.,3.1. Our Sample and Project Algorithm,[0],[0]
"It was proved in (Anari et al., 2016) that Markov Chains can be used to sample from k-DPPs in time roughly Õ(mk4 + mn2) given a “warm start”, i.e., a set S0 of significant probability.",3.1. Our Sample and Project Algorithm,[0],[0]
"This approach does not extend to P -DPPs – indeed in (Anari et al., 2016)",3.1. Our Sample and Project Algorithm,[0],[0]
"the underlying probability distribution is required to be Strongly Rayleigh, a property which holds for k-DPPs, but fails for P -DPPs whenever the number of parts is at least
two.",3.1. Our Sample and Project Algorithm,[0],[0]
One can still formulate an analogous MCMC algorithm for the case of P -DPPs – it fails on specially crafted “bad instances” but seems to perform well on real world data.,3.1. Our Sample and Project Algorithm,[0],[0]
"However, even ignoring the lack of provable guarantees for this algorithm, it does not seem possible to reduce its running time below O(mk4",3.1. Our Sample and Project Algorithm,[0],[0]
+mn2),3.1. Our Sample and Project Algorithm,[0],[0]
", which significantly limits its practical applicability.",3.1. Our Sample and Project Algorithm,[0],[0]
We now present a theorem which connects the output distribution of Algorithm 1 to the corresponding P -DPP.,3.2. Provable Guarantees for Our Algorithm,[0],[0]
"To establish such a guarantee we require the following assumption on the singular values of the matrices VXi .
",3.2. Provable Guarantees for Our Algorithm,[0],[0]
Definition 4 (β-balance).,3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Let X be a set of m elements partitioned into p parts X1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", Xp and let V ∈",3.2. Provable Guarantees for Our Algorithm,[0],[0]
Rm×n be a matrix.,3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Denote by σ1 ≥ · · · ≥ σn the singular values of V and for each i ∈ {1, 2, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", p}, let σi,1 ≥ · · · ≥ σi,n denote the singular values of VXi .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"For β ≥ 1, the partition X1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", Xp is called β-balanced with respect to V if for all i ∈ {1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", p} and for all j ∈ {1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", n}, σi,j ≥ 1βσj .
",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"The β-balance property informally requires that the diversity within each of the partitions VXi , relative to V , is significant.",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"A more concrete geometric way to think about this condition is as follows: if one thinks of the positive semidefinite matrix V >V ∈ Rn×n as representing an ellipsoid in Rn whose axes are the singular values, then the β-balance condition essentially says that the ellipsoids corresponding to each of the partitions are a β-approximation to that of V (see Figure 4 in the Supplementary File).
",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Importantly, Algorithm 1 never outputs a set S /∈",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"B, hence the only way its output distribution could significantly differ from the P -DPP would be if certain sets S ∈ B appeared in the output with larger probabilities than specified by the P -DPP.",3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Our main theoretical result for Sample and Project is that for β-balanced instances we can control the scale at which such a violation can happen.
",3.2. Provable Guarantees for Our Algorithm,[0],[0]
Theorem 1 (Approximation Guarantee).,3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Let X be a set of m elements partitioned into p parts X1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", Xp, a matrix V ∈ Rm×n and integers k1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", kp, such that X1, . . .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
", Xp is a β-balanced partition with respect to V and ∑p j=1 kj .",3.2. Provable Guarantees for Our Algorithm,[0],[0]
Let B ⊆ 2X denote the following family of sets,3.2. Provable Guarantees for Our Algorithm,[0],[0]
"Then Algorithm 1, with V , (X1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", Xp) and (k1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", kp) as input, returns a subset S ∈ B with probability q̃(S) ≤ ηk · β2k · q?S where q?S = det(VSV > S )∑
T∈B","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"det(VTV > T )
, k = ∑p j=1 kj
and ηk = k1! · k2! · · · kp!.
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"The proof of the approximation guarantee uses techniques inspired by (Deshpande & Vempala, 2006) who prove a similar bound for k-DPP sampling.
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
We use the following lemmas in the proof of the theorem.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"The proof of these lemmas appear in Appendix B.4 and Appendix B.5 in the Supplementary File.
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
Lemma 3.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
For any matrix V ∈ Rm×n with m ≥ n ≥,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"k,∑ i1<i2<···<ik σ2i1σ 2 i2 · · ·σ 2 ik = ∑ S:|S|=k det(VSV > S )
where σ1, σ2, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", σn are the singular values of V and VS is the sub-matrix of V with rows corresponding to S. Lemma 4.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Given a β-balanced partition, Algorithm 1 returns a set S such that det(VSV >S ) is non-zero with probability one.
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
Proof of Theorem 1.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
Let π be the random variable representing the ordered output of the algorithm.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Suppose that the algorithm outputs the set S = {x1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", xk}.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Since the partition X1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", Xp is β-balanced with respect to V , by Lemma 4 the algorithm will always output a set which has non-zero determinant value, i.e, det(VSV >S ) 6= 0.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Consider any ordering of the set S, say, τ := (x1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", xk).","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Let Hj ⊆ Rn denote the linear subspace spanned by the vectors corresponding to the first j − 1 elements, i.e., {vx1 , . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", vxj−1}.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
We also define a mapping f :,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"X → {1, . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", p} such that f(x) =","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
i if x ∈ Xi.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
In the first iteration say we choose partition X1.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
Then the algorithm will sample an element from X1 with probability proportional to the squared norm of the vector.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"After (j − 1) iterations wx will be the orthogonal projection of vx onto the subspace orthogonal to span{vx1 , vx2 , . . .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
", vxj−1}.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"This is a consequence of the fact that (Πvx1 Πvx1 · · ·Πvxj−1 ) = ΠHj .
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Hence in the (j − 1)-th iteration, wx = ΠHj (vx) for all x ∈ X .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Therefore, the probability that the sequence τ is the output of the algorithm is
P(π = τ) = k∏ j=1 ∥∥ΠHj (vxj )∥∥2∑ x∈Xf(xj)
∥∥ΠHj (vx)∥∥2 .","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
(1) The numerator of (1) is det(VSV >S ) by Lemma 2.,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Let Dx1,...,xk denote the denominator.","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"For each term in the denominator
∑ x∈Xl ∥∥ΠHj (vx)∥∥2 = ∥∥VXl","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
− V ′Xl∥∥2F,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
where ‖·‖F denotes the Frobenius norm and V ′Xl is the rank j,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
− 1 matrix with rows {v′x}x∈Xl such that v′x is the projection of vector vx on Hj .,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"By a result on low rank approximations (see Theorem 1), we can bound the above quantity as
∑ x∈Xl ∥∥ΠHj (vx)∥∥2 ≥ n∑ t=j σ2l,t ≥ 1 β2 n∑ t=j σ2t
where σl,t is the t-th singular value of VXl and second inequality is due to the β-balanced property of the partition.
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Using above, the denominator of (1) becomes
Dx1,...,xk ≥ k∏ j=1 1 β2 n∑ t=j σ2t ≥ 1 β2k ∑ t1<···<tk σ2t1 · · ·σ 2 tk .
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"By applying Lemma 3, it then follows
Dx1,...,xk","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"≥ 1
β2k ∑ |S|=k","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
det(VSV > S ),"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"≥ 1 β2k ∑ S∈B det(VSV > S ).
","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Thus, P(π = τ) ≤ β2k","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"det(VSV > S )∑
T∈B","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
det(VTV > T ) .,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Since the order
in which the partitions are considered by the algorithm is fixed, the vectors of each Xi in τ can be permuted amongst themselves and the output set will still be S. Correspondingly there are ηk = k1! ·","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
k2! · · · kp! valid permutations of τ .,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"Let TS be the set of all valid permutations of elements of S, then q̃S =
∑ τ∈TS","B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
P(π = τ) ≤ ηk · β2k · q?S .,"B := {S ⊆ X : |S ∩Xj | = kj for all j = 1, 2, . . . , p}",[0],[0]
"For a given matrix V ∈ Rm×n, suppose we choose the partitions randomly.",3.3. β-balanced property for random data,[0],[0]
"For each element x ∈ X , we put x in Xi with probability 1/p.",3.3. β-balanced property for random data,[0],[0]
"Using the Matrix Chernoff bounds (Tropp, 2012), we prove the following theorem.",3.3. β-balanced property for random data,[0],[0]
Theorem 2.,3.3. β-balanced property for random data,[0],[0]
"Assume that all the rows vj (for j ∈ X = {1, 2, . . .",3.3. β-balanced property for random data,[0],[0]
",m}) of V ∈ Rm×n satisfy v>j",3.3. β-balanced property for random data,[0],[0]
"(V >V )−1vj ≤
δ2
8p log(np) , where δ ∈ (0, 1) is a constant.",3.3. β-balanced property for random data,[0],[0]
If X is randomly partitioned into X = X1 ∪X2 ∪ . . .,3.3. β-balanced property for random data,[0],[0]
"∪Xp then with probability at least 1e , the partition X1, . . .",3.3. β-balanced property for random data,[0],[0]
", Xp is β-balanced with respect to V , for β = √ (1 + δ)p.
",3.3. β-balanced property for random data,[0],[0]
The proof of this theorem is given in Appendix B.6 in the Supplementary File.,3.3. β-balanced property for random data,[0],[0]
"The quantity v>j (V
>V )−1vj is also called the statistical leverage score of vj with respect to V >V .",3.3. β-balanced property for random data,[0],[0]
"For two partitions, the theorem states that if the leverage score of all rows is O( 1logn ), then the partitions are β-balanced for β",3.3. β-balanced property for random data,[0],[0]
≈ √ 2.,3.3. β-balanced property for random data,[0],[0]
In this section we present conditions under which the k-DPP and P -DPP distributions are close to each other.,4. Price of Fairness,[0],[0]
Note that the support of a P -DPP is a subset of the support of the corresponding k-DPP.,4. Price of Fairness,[0],[0]
"Thus, a natural definition of the price of fairness is the KL-divergence between them.",4. Price of Fairness,[0],[0]
Definition 5 (Price of Fairness).,4. Price of Fairness,[0],[0]
"Given a matrix V ∈ Rm×n, partitions X1, . . .",4. Price of Fairness,[0],[0]
", Xp and integers k1, . . .",4. Price of Fairness,[0],[0]
", kp, let k = k1 + · · ·",4. Price of Fairness,[0],[0]
+ kp.,4. Price of Fairness,[0],[0]
Suppose q is the distribution defined by k-DPP over subsets of size k and q? is the distribution defined by P -DPP over subsets with ki elements from each Xi.,4. Price of Fairness,[0],[0]
"Then, the price of fairness is DKL(q?||q).
",4. Price of Fairness,[0],[0]
"We define the following property for the input data and analyze its price of fairness.
",4. Price of Fairness,[0],[0]
Definition 6 (δ-drop).,4. Price of Fairness,[0],[0]
"For 0 ≤ δ ≤ 1, the partition X1, . . .",4. Price of Fairness,[0],[0]
", Xp is called a δ-drop partition with respect to V and k1, . . .",4. Price of Fairness,[0],[0]
", kp if for all i ∈",4. Price of Fairness,[0],[0]
"{1, . . .",4. Price of Fairness,[0],[0]
", p}, σi,ki+1 ≤ δσi,ki .",4. Price of Fairness,[0],[0]
"Here σi,j is the j-th largest singular value of VXi .
",4. Price of Fairness,[0],[0]
"Roughly, this says that, if δ is small, then each of the matrices VXi is effectively a rank-ki matrix.",4. Price of Fairness,[0],[0]
"Such a notion of low effective rank appears frequently in the machine learning literature (Roy & Vetterli, 2007; Drineas et al., 1999).",4. Price of Fairness,[0],[0]
"We prove the following theorem that asserts that if the δdrop condition is satisfied, then we can be sure that most of the probability mass is concentrated on subsets which satisfy partition constraints.",4. Price of Fairness,[0],[0]
"In such a case, sampling a k sized subset using any k-DPP algorithm will output a subset which satisfies partition constraints with high probability.",4. Price of Fairness,[0],[0]
"The proof of the theorem is provided in the Appendix B.7 in the Supplementary File.
Theorem 3.",4. Price of Fairness,[0],[0]
"Let ε ∈ (0, 1) and suppose that the partition X1, . . .",4. Price of Fairness,[0],[0]
", Xp is δ-drop w.r.t.",4. Price of Fairness,[0],[0]
"V and k1, . . .",4. Price of Fairness,[0],[0]
", kp, with δ ≤ ε nN0 and N0 := ( k+p−1 p−1 ) .",4. Price of Fairness,[0],[0]
"If n ≥ √ 2k · ( γ σn )2 (with γ := max{σi,1}i, where σi,1 is the largest singular value of VXi and σn is the smallest non-zero singular value of V ) then the price of ensuring fairness is DKL(q?||q) ≤ log 1(1−ε) .",4. Price of Fairness,[0],[0]
"In each simulation, we compare several different probability distributions from which to select k samples from a dataset: As benchmarks we consider the (unconstrained) distributions, k-DPP (see Def 2), and UNIF, which selects a uniformly random subset of size k from the dataset X .",5.1. Algorithms and Baselines,[0],[0]
"We compare this against different methods which select from a fair family of allowed subsets, P -DPP (see Def 3), and ki-DPP (see Def 7 below).
",5.1. Algorithms and Baselines,[0],[0]
Definition 7.,5.1. Algorithms and Baselines,[0],[0]
(ki-DPP),5.1. Algorithms and Baselines,[0],[0]
"Given a dataset X , the corresponding feature vectors V ∈ Rm×n, a partition X = X1 ∪ · · · ∪ Xp into p parts, and numbers k1, . . .",5.1. Algorithms and Baselines,[0],[0]
", kp, kiDPP defines a distribution over k1 + · · ·+ kp-sized subsets S ⊆ X that is a product distribution: for each i, we obtain
a sample Si ⊆ Xi of size ki independently with probability proportional to P[Si]",5.1. Algorithms and Baselines,[0],[0]
"∝ det ( VSiV > Si ) , and combine these samples to output S = S1 ∪ · · · ∪ Sp.",5.1. Algorithms and Baselines,[0],[0]
Algorithms for ki-DPPs are simply obtained by independently using a k-DPP sampler with k = ki on each part Xi.,5.1. Algorithms and Baselines,[0],[0]
"For sampling from all the above listed distribution we use the Sample and Project algorithm as described in Section 3.1.
Metrics.",5.1. Algorithms and Baselines,[0],[0]
"In each simulation, we report the geometric diversity G(·) (see Def 1) and the fairness as measured by the KL-divergence from the desired frequency over parts.",5.1. Algorithms and Baselines,[0],[0]
"Formally, given a probability distribution q over the p parts of the dataset, we define the relative unfairness measure of a set S ⊆ X as Dq(S) := DKL(q||s), where s = (s1, . . .",5.1. Algorithms and Baselines,[0],[0]
", sp) denotes the vector of frequencies, i.e., si = |Xi∩S| |S| for i = 1, 2, . . .",5.1. Algorithms and Baselines,[0],[0]
", p.",5.1. Algorithms and Baselines,[0],[0]
"In particular, typically we want to have Dq(·) as small as possible – ideally equal to 0.",5.1. Algorithms and Baselines,[0],[0]
"When qi = 1/p for all i, we refer to Dq as Dun.",5.1. Algorithms and Baselines,[0],[0]
"When qi = |Xi|/m, we refer to Dq as Dprop.",5.1. Algorithms and Baselines,[0],[0]
Curated Dataset.,5.2. Empirical Results on the Image Dataset,[0],[0]
"We gathered a collection of images curated using Google image search as follows: Four search terms were used: (a) “Scientist Male”, (b) “Scientist Female”, (c) “Painter Male”, and (d) “Painter Female” (Imagedataset).
",5.2. Empirical Results on the Image Dataset,[0],[0]
"Following (Kulesza & Taskar, 2011), each image was processed with the vlfeat toolbox to obtain sets of 128- dimensional SIFT descriptors (Lowe, 1999; Vedaldi & Fulkerson, 2008).",5.2. Empirical Results on the Image Dataset,[0],[0]
All such descriptors are collected in a single set and subsampled to roughly 10% of its total size.,5.2. Empirical Results on the Image Dataset,[0],[0]
The resulting set of ≈ 104 descriptors was clustered using the k-means algorithm where k = 128 is the number of means.,5.2. Empirical Results on the Image Dataset,[0],[0]
"The feature vector for an image is the normalized histogram of the nearest clusters to the descriptors in the image.
",5.2. Empirical Results on the Image Dataset,[0],[0]
Empirical Results on the Biased Datasets.,5.2. Empirical Results on the Image Dataset,[0],[0]
"Our goal is to understand how the bias in the underlying dataset can affect the performance of the different sampling distributions with
respect to fairness and geometric diversity.",5.2. Empirical Results on the Image Dataset,[0],[0]
"We include all female (b and d) images, but vary how many of the male images (a and c) appear in the dataset in order to create biased sets that have between 10% to 50% male images.",5.2. Empirical Results on the Image Dataset,[0],[0]
The male images are selected uniformly at random from the set of all male scientists and male artists for each repetition of the simulation.,5.2. Empirical Results on the Image Dataset,[0],[0]
We sample 40 images from each biased dataset; roughly the number that fits on the first page of an image search result.,5.2. Empirical Results on the Image Dataset,[0],[0]
We conduct 200 repetitions.,5.2. Empirical Results on the Image Dataset,[0],[0]
"We place fairness constraints so that P -DPP and ki-DPP select exactly 50% of their samples from the male (a and c) images and female (b and d) images, regardless of the bias in the underlying dataset.",5.2. Empirical Results on the Image Dataset,[0],[0]
"Note that we do not enforce constraints across scientist (a and b) images and artist (c and d) images, but measure the unfariness Dun(·) with respect to all four attributes.
",5.2. Empirical Results on the Image Dataset,[0],[0]
Results.,5.2. Empirical Results on the Image Dataset,[0],[0]
"With respect to Dun(·), P -DPP significantly outperforms k-DPP, and UNIF (paired one-sided t-tests, p < 0.05), see Figure 1.",5.2. Empirical Results on the Image Dataset,[0],[0]
"As expected, the bias in the underlying dataset can dramatically affect the fairness of UNIF and k-DPP as neither approach is designed to correct for such biases.",5.2. Empirical Results on the Image Dataset,[0],[0]
"However, P -DPP and ki-DPP both enforce fairness constraints; note that this is despite the fact that the sampling was only equal with respect to gender and not profession.",5.2. Empirical Results on the Image Dataset,[0],[0]
"The latter does not appear to affect the outcome here.
",5.2. Empirical Results on the Image Dataset,[0],[0]
"With respect to the diversity G(·), P -DPP has significantly higher G(·) than UNIF and ki-DPP (paired one-sided ttests, p < 0.05).",5.2. Empirical Results on the Image Dataset,[0],[0]
"Moreover, P -DPP performs comparatively to k-DPP; the mean diversity of k-DPP is higher, but not significantly so.",5.2. Empirical Results on the Image Dataset,[0],[0]
"Thus, we observe that, when the underlying data is biased, there is a tradeoff between Dun(·) (for which P -DPP performs best) and G(·) (for which k-DPP performs best); however the differences in geometric diversity are negligible while differences in unfairness can be very large.",5.2. Empirical Results on the Image Dataset,[0],[0]
The Adult Dataset.,5.3. Empirical Results on Real-World Dataset,[0],[0]
"The Adult income dataset (Blake & Merz, 1998) consists of roughly 45000 records of subjects each with 14 features such as age, ethnicity, education and a binary label indicating whether a subject’s incomes is above or below 50K USD.3",5.3. Empirical Results on Real-World Dataset,[0],[0]
"This dataset has been widely studied in the context of fairness (see, (Yang & Stoyanovich, 2017; Zafar et al., 2017; Zemel et al., 2013; Zadrozny, 2004)).
",5.3. Empirical Results on Real-World Dataset,[0],[0]
"In preprocessing the data we filter out incomplete entries, and from the remaining ones we pick a random subset of 5000 records for our simulations.",5.3. Empirical Results on Real-World Dataset,[0],[0]
We vectorize the data as follows: Categorical fields (with a small number of possible values) we turn into sets of binary fields.,5.3. Empirical Results on Real-World Dataset,[0],[0]
As the dimension n of such feature vectors is quite small – 50 – the DPP framework allows sampling sets of cardinality at most k ≤ 50.,5.3. Empirical Results on Real-World Dataset,[0],[0]
"For this reason we enrich the feature vectors in a standard way – by adding pairwise products of all existing features as separate ones – this, after removing redundant columns, yields feature vectors of dimension 992.
",5.3. Empirical Results on Real-World Dataset,[0],[0]
Empirical Results on Equal and Proportional Representation.,5.3. Empirical Results on Real-World Dataset,[0],[0]
We conduct our simulations across either gender or ethnicity as the sensitive attribute.,5.3. Empirical Results on Real-World Dataset,[0],[0]
"For the former, we use the gender categories provided in the dataset; all entries were labeled either male (68.3%) or female (31.7%).",5.3. Empirical Results on Real-World Dataset,[0],[0]
"For the latter, we use the ethnicity categories provided in the dataset; we consider the partition Caucasian (85.7%) and non-Caucasian (14.3%).
",5.3. Empirical Results on Real-World Dataset,[0],[0]
"In addition to the algorithms mentioned above, we report the performance of an additional benchmark ki-UNIF, which selects a uniformly random subset of size ki fromXi.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"In our subsampling, we consider both equal representation, where
3Data downloaded from https://archive.ics.uci.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"edu/ml/datasets/adult.
",5.3. Empirical Results on Real-World Dataset,[0],[0]
"each attribute makes up of 50% of the selected points, and proportional representation, where each attribute is represented with the same ratio as in the original population.
",5.3. Empirical Results on Real-World Dataset,[0],[0]
Results.,5.3. Empirical Results on Real-World Dataset,[0],[0]
We observe that P -DPP has the highest diversity out of all constrained sampling methods regardless of the proportion of representation or sensitive attribute; see Table 1.,5.3. Empirical Results on Real-World Dataset,[0],[0]
"Surprisingly, the diversity of P -DPP matches that of the unconstrained k-DPP for Gender under proportional representation and for Ethnicity under equal representation.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"In the other two settings – Gender under equal representation and Ethnicity under proportional representation – the P - DPP score is lower than that of k-DPP, but minimally so, and outperforms ki-DPP by several standard deviations.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"We note that ki-UNIF, although it has very poor geometric diversity as a whole, performs better under equal representation than it does under proportional representation.",5.3. Empirical Results on Real-World Dataset,[0],[0]
This fact suggests that there could be value in selecting sensitive attributes equally beyond the consideration of fairness.,5.3. Empirical Results on Real-World Dataset,[0],[0]
"The fact that P -DPP performs so well, especially when significantly changing the distribution of sensitive attributes (e.g., for ethnicity, from 14.3% non-Caucasian to 50% nonCaucasian), is quite surprising.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"Overall, it appears that one can support very dramatic changes to the underlying distributions of attributes with minimal or even zero loss to geometric diversity by using our P -DPP algorithm.",5.3. Empirical Results on Real-World Dataset,[0],[0]
"We look at the effect of the scaling of singular values, suggested by Theorem 3, on the sampled subsets of our Algorithm.",5.4. Empirical Results on the Price of Fairness,[0],[0]
"In this simulation we take an instance of random vectors and use different sampling methods to sample a subset from the dataset, and report the Dun(·) and logG(·) value of the sampled subset.",5.4. Empirical Results on the Price of Fairness,[0],[0]
"Following this, we scale the tail singular values of the partition matrices by δ = O(1/n) and again report the Dun(·) and logG(·) values.
",5.4. Empirical Results on the Price of Fairness,[0],[0]
"We also present a heuristic approach, Scale-And-Sample, for constrained sampling which will use any k-DPP algorithm as a sub-routine.",5.4. Empirical Results on the Price of Fairness,[0],[0]
The algorithm is simple.,5.4. Empirical Results on the Price of Fairness,[0],[0]
"For each VXi , scale the smallest (n − ki) singular values by 1/n. Then sample a ∑p i=1 ki sized subset using any k-DPP algorithm.
Results.",5.4. Empirical Results on the Price of Fairness,[0],[0]
The results are presented in Table 2.,5.4. Empirical Results on the Price of Fairness,[0],[0]
"It can be seen that after scaling the tail singular values of the partition matrices, the mean Dun(·) value for k-DPP is very low, and resembles closely the constrained sampling case.",5.4. Empirical Results on the Price of Fairness,[0],[0]
We also note that the Scale-And-Sample approach to constrained sampling suggested earlier performs very well.,5.4. Empirical Results on the Price of Fairness,[0],[0]
The mean relative unfairness measure Dun(·) is almost zero.,5.4. Empirical Results on the Price of Fairness,[0],[0]
"Furthermore, the value of the geometric diversity parameter logG(·) is also similar to unscaled P -DPP.",5.4. Empirical Results on the Price of Fairness,[0],[0]
In this paper we initiated the study of fair and diverse DPPbased sampling for data summarization.,6. Conclusion and Future Work,[0],[0]
We provide a novel and fast algorithm that can sample from a DPP that satisfy fairness constraints based on the desired proportion of samples with a given attribute.,6. Conclusion and Future Work,[0],[0]
Our algorithm gives provably good guarantees when the data matrix satisfies a natural β-balance property.,6. Conclusion and Future Work,[0],[0]
We prove that a large class of datasets satisfy the β-balance condition.,6. Conclusion and Future Work,[0],[0]
"We define a notion of price of fairness, the KL-divergence between the fairness constrained distribution and the unconstrained distribution and theoretically show that, when the data satisfies reasonable properties, this price would be low.",6. Conclusion and Future Work,[0],[0]
"We further show in silico that adding fairness constraints results in minimal loss to diversity, even when the underlying dataset is very biased, or when the proportion of attributes is changed significantly.
",6. Conclusion and Future Work,[0],[0]
"Several challenging problems remain from a technical standpoint; naturally, a first question would be whether the theorems can be improved either by attaining better approximation guarantees, or by weakening the necessary conditions.",6. Conclusion and Future Work,[0],[0]
"Extending these results to arbitrary group structures (as opposed to partitions) would be very relevant, but appears to be significantly more challenging.
",6. Conclusion and Future Work,[0],[0]
"From a practical point of view, it remains to be seen what effect de-biasing a sampler",6. Conclusion and Future Work,[0],[0]
"has on the end result of an ML algorithm (e.g., classification), both on its accuracy and on the output bias.",6. Conclusion and Future Work,[0],[0]
"Indeed, this P -DPP model can be used to pre-process the training data by taking a fair subsample; evaluating the performance of ML algorithms in this regard would be an interesting direction for future research.",6. Conclusion and Future Work,[0],[0]
Sampling methods that choose a subset of the data proportional to its diversity in the feature space are popular for data summarization.,abstractText,[0],[0]
"However, recent studies have noted the occurrence of bias – e.g., under or over representation of a particular gender or ethnicity – in such data summarization methods.",abstractText,[0],[0]
In this paper we initiate a study of the problem of outputting a diverse and fair summary of a given dataset.,abstractText,[0],[0]
We work with a well-studied determinantal measure of diversity and corresponding distributions (DPPs) and present a framework that allows us to incorporate a general class of fairness constraints into such distributions.,abstractText,[0],[0]
"Designing efficient algorithms to sample from these constrained determinantal distributions, however, suffers from a complexity barrier; we present a fast sampler that is provably good when the input vectors satisfy a natural property.",abstractText,[0],[0]
Our empirical results on both real-world and synthetic datasets show that the diversity of the samples produced by adding fairness constraints is not too far from the unconstrained case.,abstractText,[0],[0]
Fair and Diverse DPP-Based Data Summarization,title,[0],[0]
Consider a speech recognizer that is deployed to millions of users.,1. Introduction,[1.0],['Consider a speech recognizer that is deployed to millions of users.']
"State-of-the art speech recognizers achieve high overall accuracy, yet it is well known that such systems have systematically high errors on minority accents (Amodei et al., 2016).",1. Introduction,[1.0],"['State-of-the art speech recognizers achieve high overall accuracy, yet it is well known that such systems have systematically high errors on minority accents (Amodei et al., 2016).']"
"We refer to this phenomenon of high overall accuracy but low minority accuracy as a representation disparity, which is the result of optimizing for average loss.",1. Introduction,[0],[0]
"This representation disparity forms our definition of unfairness, and has been observed in face recognition (Grother et al., 2011), language identification (Blodgett et al., 2016;
1Department of Computer Science, Stanford, USA 2Department of Statistics, Stanford, USA 3Management Science & Engineering, Stanford, USA.",1. Introduction,[0],[0]
"Correspondence to: Tatsunori Hashimoto <thashim@stanford.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"Jurgens et al., 2017), dependency parsing (Blodgett et al., 2016), part-of-speech tagging (Hovy & Sgaard, 2015), academic recommender systems (Sapiezynski et al., 2017), and automatic video captioning (Tatman, 2017).
",1. Introduction,[0],[0]
"Moreover, a minority user suffering from a higher error rate will become discouraged and more likely to stop using the system, thus no longer providing data to the system.",1. Introduction,[0],[0]
"As a result, the minority group will shrink and might suffer even higher error rates from a retrained model in a future time step.",1. Introduction,[1.0],"['As a result, the minority group will shrink and might suffer even higher error rates from a retrained model in a future time step.']"
"Machine learning driven feedback loops have been observed in predictive policing (Fuster et al., 2017) and credit markets (Fuster et al., 2017), and this problem of disparity amplification is a possibility in any deployed machine learning system that is retrained on user data.
",1. Introduction,[1.0000000754620277],"['Machine learning driven feedback loops have been observed in predictive policing (Fuster et al., 2017) and credit markets (Fuster et al., 2017), and this problem of disparity amplification is a possibility in any deployed machine learning system that is retrained on user data.']"
"In this paper, we aim to mitigate the representation disparity problem and its amplification through time.",1. Introduction,[0],[0]
"We focus on the following setting: at each time step, each user interacts with the current model and incurs some loss, based on which she decides to keep or quit using the service.",1. Introduction,[0],[0]
A model is trained on the resulting user data which is used at the next time step.,1. Introduction,[1.0],['A model is trained on the resulting user data which is used at the next time step.']
"We assume that each user comes from one of K groups, and our goal is to minimize the worst case risk of any group across time.",1. Introduction,[1.0],"['We assume that each user comes from one of K groups, and our goal is to minimize the worst case risk of any group across time.']"
"However, the group membership and number of groups K are both unknown, as full demographic information is likely missing in real online services.
",1. Introduction,[0.9999999818577616],"['However, the group membership and number of groups K are both unknown, as full demographic information is likely missing in real online services.']"
We first show that empirical risk minimization (ERM) does not control the worst-case risk over the disparate K groups and show examples where ERM turns initially fair models unfair (Section 3).,1. Introduction,[1.0],['We first show that empirical risk minimization (ERM) does not control the worst-case risk over the disparate K groups and show examples where ERM turns initially fair models unfair (Section 3).']
"To remedy this issue, we propose the use of distributionally robust optimization (DRO) (Section 4).",1. Introduction,[0],[0]
"Given a lower bound on the smallest group proportion, we show that optimizing the worst-case risk over an appropriate chi-square divergence ball bounds the worst-case risk over groups.",1. Introduction,[0],[0]
"Our approach is computationally efficient, and can be applied as a small modification to a wide class machine learning models trained by stochastic gradient descent methods.",1. Introduction,[0],[0]
"We show that DRO succeeds on the examples where ERM becomes unfair, and demonstrate higher average minority user satisfaction and lower disparity amplification on a Amazon Mechanical Turk based autocomplete task.",1. Introduction,[0],[0]
"Recently, there has been a surge of interest in fairness in machine learning (Barocas & Selbst, 2016).",1.1. Fairness in Machine Learning,[0],[0]
"Our work can be seen as a direct instantiation of John Rawls’ theory on distributive justice and stability, where we view predictive accuracy as a resource to be allocated.",1.1. Fairness in Machine Learning,[0],[0]
"Rawls argues that the difference principle, defined as maximizing the welfare of the worst-off group, is fair and stable over time since it ensures that minorities consent to and attempt to maintain the status quo (Rawls, 2001, p155).
",1.1. Fairness in Machine Learning,[0],[0]
"In this work, we assume the task is general loss minimization, and demographic data is unavailable.",1.1. Fairness in Machine Learning,[0],[0]
"This differs from the substantial body of existing research into fairness for classification problems involving protected labels such as the use of race in recidivism protection (Chouldechova, 2017).",1.1. Fairness in Machine Learning,[0],[0]
"There has been extensive work (Barocas & Selbst, 2016) on guaranteeing fairness for classification over a protected label through constraints such as equalized odds (Woodworth et al., 2017; Hardt et al., 2016), disparate impact (Feldman et al., 2015) and calibration (Kleinberg et al., 2017).",1.1. Fairness in Machine Learning,[1.0],"['There has been extensive work (Barocas & Selbst, 2016) on guaranteeing fairness for classification over a protected label through constraints such as equalized odds (Woodworth et al., 2017; Hardt et al., 2016), disparate impact (Feldman et al., 2015) and calibration (Kleinberg et al., 2017).']"
"However, these approaches require the use of demographic labels, and are designed for classification tasks.",1.1. Fairness in Machine Learning,[0],[0]
"This makes it difficult to apply such approaches to mitigate representation disparity in tasks such as speech recognition or natural language generation where full demographic information is often unavailable.
",1.1. Fairness in Machine Learning,[0],[0]
"A number of authors have also studied individual notions of fairness, either through a fixed similarity function (Dwork et al., 2012) or subgroups of a set of protected labels (Kearns et al., 2018; Hébert-Johnson et al., 2017).",1.1. Fairness in Machine Learning,[0],[0]
"Dwork et al. (2012) provides fairness guarantees without explicit groups, but requires a fixed distance function which is difficult to define for real-world tasks.",1.1. Fairness in Machine Learning,[0],[0]
"Kearns et al. (2018); HébertJohnson et al. (2017) consider subgroups of a set of protected features, but defining non-trivial protected features which cover the latent demographics in our setting is difficult.",1.1. Fairness in Machine Learning,[0],[0]
"Although these works generalize the demographic group structure, similarity and subgroup structure are both ill-defined for many real-world tasks.
",1.1. Fairness in Machine Learning,[0],[0]
"In the online setting, works on fairness in bandit learning (Joseph et al., 2016; Jabbari et al., 2017) propose algorithms compatible with Rawls’ principle on equality of opportunity—an action is preferred over another only if the true quality of the action is better.",1.1. Fairness in Machine Learning,[0],[0]
"Our work differs in considering Rawlsian fairness for distributive justice (Rawls, 2009).",1.1. Fairness in Machine Learning,[0],[0]
"Simultaneous with our work, Liu et al. (2018) analyzed fairness over time in the context of constraint based fairness criteria, and show that enforcing static fairness constraints do not ensure fairness over time.",1.1. Fairness in Machine Learning,[0],[0]
"In this paper, we consider latent demographic groups and study a loss-based approach to fairness and stability.",1.1. Fairness in Machine Learning,[0],[0]
"We begin by outlining the two parts of our motivation: representation disparity and disparity amplification.
",2. Problem setup,[0],[0]
"Representation disparity: Consider the standard lossminimization setting where a user makes a query Z ∼ P , a model θ ∈ Θ makes a prediction, and the user incurs loss `(θ;Z).",2. Problem setup,[1.0],"['Representation disparity: Consider the standard lossminimization setting where a user makes a query Z ∼ P , a model θ ∈ Θ makes a prediction, and the user incurs loss `(θ;Z).']"
We denote the expected loss as the risk R(θ) = EZ∼P,2. Problem setup,[0],[0]
[`(θ;Z)].,2. Problem setup,[0],[0]
The observations Z are assumed to arise from one of K latent groups such that Z ∼ P := ∑ k∈[K] αkPk.,2. Problem setup,[0],[0]
We assume that neither the population proportions {αk} nor the group distributions {Pk} are known.,2. Problem setup,[0],[0]
"The goal is to control the worst-case risk over all K groups:
Rmax(θ) = max k∈[K] Rk(θ), Rk(θ) := EPk",2. Problem setup,[0],[0]
[`(θ;Z)].,2. Problem setup,[0],[0]
"(1)
Representation disparity refers to the phenomenon of low R(θ) and highRmax(θ) due to a group with small αk.
",2. Problem setup,[0],[0]
"Disparity amplification: To understand the amplification of representation disparity over time, we will make several assumptions on the behavior of users in response to observed losses.",2. Problem setup,[0],[0]
These assumptions are primarily for clarity of exposition—we will indicate whenever the assumptions can be relaxed leave generalizations to the supplement.,2. Problem setup,[0],[0]
"Roughly speaking, minimizing the worst-case risk Rmax(θ) should mitigate disparity amplification as long as lower losses lead to higher user retention.",2. Problem setup,[0],[0]
"We now give assumptions that make this intuition precise.
",2. Problem setup,[0],[0]
"In the sequential setting, loss minimization proceeds over t = 1, 2, . . .",2. Problem setup,[0],[0]
"T rounds, where the group proportion α(t)k depends on t and varies according to past losses.",2. Problem setup,[1.0],"['T rounds, where the group proportion α(t)k depends on t and varies according to past losses.']"
"At each round λ(t+1)k is the expected number of users from group k, which is determined by ν(Rk(θ)), the fraction of users retained, and bk, the number of new users (see Definition 1).",2. Problem setup,[0],[0]
"Here, ν is a differentiable, strictly decreasing retention function which maps a risk levelR to the fraction of users who continue to use the system.",2. Problem setup,[0],[0]
"Modeling user retention as a decreasing function of the risk implies that each user makes an independent decision of whether to interact with the system at time t+ 1 based on their expected loss at time t. For example, selecting ν(x) = 1− x andRk equal to the expected zero-one loss implies that users leave proportional to the misclassification rates of their queries.
",2. Problem setup,[0],[0]
At each round we learn parameters θ(t+1) based on n(t+1),2. Problem setup,[0],[0]
∼ Pois( ∑ k λ (t+1) k ) users (data points).,2. Problem setup,[0],[0]
"While we define the sample size as a Poisson process for concreteness, our main results hold for any distribution fulfilling the strong law of large numbers, as we perform all stability analyses in the population limit.
",2. Problem setup,[0],[0]
Definition 1 (Dynamics).,2. Problem setup,[0],[0]
"Given a sequence θ(t), for each t = 1 . . .",2. Problem setup,[0],[0]
"T , the expected number of users λ and samples
Z (t) i starting at λ (0)",2. Problem setup,[0],[0]
k,2. Problem setup,[0],[0]
"= bk is governed by:
λ (t+1) k",2. Problem setup,[0],[0]
:= λ (t) k ν(Rk(θ,2. Problem setup,[0],[0]
(t))),2. Problem setup,[0],[0]
"+ bk
α (t+1) k",2. Problem setup,[0],[0]
":= λ (t+1) k∑
k′∈[K] λ (t+1) k′
n(t+1)",2. Problem setup,[0],[0]
":= Pois( ∑ k λ (t+1) k )
Z (t+1) 1 . . .",2. Problem setup,[0],[0]
"Z (t+1) n(t+1) i.i.d.∼ P (t+1) := ∑ k∈[K] α (t+1) k Pk.
",2. Problem setup,[0],[0]
"If we use ERM at each time step the parameter sequence is defined as θ(t) = arg minθ∈Θ ∑ i `(θ;Z (t) i ).
",2. Problem setup,[0],[0]
"Our goal is to control over all groups k = 1, . . .",2. Problem setup,[0],[0]
",K and time periods t = 1, . . .",2. Problem setup,[0],[0]
", T the group-wise riskRk(θ(t)),
RTmax(θ(0), · · · , θ(T ))",2. Problem setup,[0],[0]
"= max k,t
{ Rk(θ(t)) } .",2. Problem setup,[0],[0]
"(2)
Without knowledge of group membership labels, population proportions α(t)k , new user rate bk, and retention rate ν, minimizingRTmax gives rise to two major challenges.",2. Problem setup,[0],[0]
"First, without group membership labels there is no way to directly measure the worst-case risk RTmax, let alone minimize it.",2. Problem setup,[1.0],"['First, without group membership labels there is no way to directly measure the worst-case risk RTmax, let alone minimize it.']"
"Second, we must ensure that the group proportions α(t)k are stable, since if α(t)k → 0 as t→∞ for some group k ∈",2. Problem setup,[0],[0]
"[K], then no algorithm can controlRTmax when a group has near zero probability of appearing in our samples.
",2. Problem setup,[0],[0]
We begin by illustrating how models that are initially fair with low representation disparity may become unfair over time if we use ERM (Section 3).,2. Problem setup,[0],[0]
"We then propose a solution based on distributionally robust optimization (Section 4), and study examples where this approach mitigates representation disparity in our experimental section (Section 5).",2. Problem setup,[0],[0]
The standard approach to fitting a sequence of models θ(t) is to minimize an empirical approximation to the population risk at each time period.,3. Disparity amplification,[0],[0]
"In this section, we show that even minimizing the population risk fails to control minority risk over time, since expected loss (average case) leads to disparity amplification.",3. Disparity amplification,[0],[0]
"The decrease in user retention for the minority group is exacerbated over time since once a group shrinks sufficiently, it receives higher losses relative to others, leading to even fewer samples from the group.",3. Disparity amplification,[0],[0]
"Consider the two-class classification problem in Figure 1 where the two groups are drawn from Gaussians and the
optimal classification boundary is given along x2 = 0.",3.1. Motivating example,[0],[0]
"Assume that the sampling distribution evolves according to definition 1 with ν(x) = 1.0−x, ` equal to the zero one loss, and b0 = b1 = n (0) 0",3.1. Motivating example,[0],[0]
= n (0) 1 = 1000.,3.1. Motivating example,[0],[0]
"Initially, ERM has similar and high accuracy on both groups with the boundary x2 > 0, but over time random fluctuations in accuracy result in slightly fewer samples from the cluster on the right.",3.1. Motivating example,[0],[0]
This leads to disparity amplification since ERM will further improve the loss on the left cluster at the expense of the right cluster.,3.1. Motivating example,[0],[0]
"After 500 rounds, there are nearly no samples from the right cluster, and as a result, the right cluster ends up suffering high loss.",3.1. Motivating example,[0],[0]
The example above demonstrated that disparity amplification can occur easily even in a situation where the two groups have identical population size and initial risk.,3.2. Conditions for disparity amplification,[0],[0]
"In general if we view the expected user counts λ(t) as a dynamical system, the long-term fairness properties for any fairness criteria are controlled by two factors - whether λ has a fair fixed point (defined as a population fraction where risk minimization maintains the same population fraction over time) and whether this fixed point is stable.
",3.2. Conditions for disparity amplification,[0],[0]
"Fixed points of risk minimization are determined by a combination of user retention function ν and the models θ(t), and without knowledge of ν it is hard to ensure that a model has a fair fixed point.",3.2. Conditions for disparity amplification,[0],[0]
"Even if a fixed point is fair, such as when the population fraction and risk received by each group is equal, and we start at this fair fixed point, minimizing the empirical loss may deviate from this fair fixed point over time due to finite sample fluctuations or noise in the model estimation procedure.
",3.2. Conditions for disparity amplification,[0],[0]
"To show this result, we study the dynamical system Φ, which is defined by dynamics in Definition 1 with θ derived from minimizing the population, rather than empirical risk.
",3.2. Conditions for disparity amplification,[0],[0]
Definition 2.,3.2. Conditions for disparity amplification,[0],[0]
"Let Φ be the update for the expected population size
λ (t+1)",3.2. Conditions for disparity amplification,[0],[0]
k,3.2. Conditions for disparity amplification,[0],[0]
:= Φ(λ (t) k ),3.2. Conditions for disparity amplification,[0],[0]
= λ (t) k ν(Rk(θ(λ (t) k ))),3.2. Conditions for disparity amplification,[0],[0]
"+ bk,
θ(λ (t) k ) = arg",3.2. Conditions for disparity amplification,[0],[0]
min,3.2. Conditions for disparity amplification,[0],[0]
θ E∑,3.2. Conditions for disparity amplification,[0],[0]
k α (t) k,3.2. Conditions for disparity amplification,[0],[0]
Pk,3.2. Conditions for disparity amplification,[0],[0]
"[`(θ;Z)].
",3.2. Conditions for disparity amplification,[0],[0]
"The arrival intensity λ∗ is called a fixed point if λ∗ = Φ(λ∗).
",3.2. Conditions for disparity amplification,[0],[0]
"This fixed point is stable whenever the maximum modulus of the eigenvalues of the Jacobian of Φ is less than one and unstable whenever it is greater than one (Luo, 2012, Theorem 2.1).
",3.2. Conditions for disparity amplification,[0],[0]
Proposition 1 gives a precise statement of this phenomenon.,3.2. Conditions for disparity amplification,[0],[0]
"We prove the result in Section A.1, and further show a generalization to general dynamics Φ(λk) = h(λk,Rk) where h is differentiable and monotone in the second argument.",3.2. Conditions for disparity amplification,[0],[0]
"We denote by ρmax(A) the maximum modulus of the eigenvalues of A.
Proposition 1.",3.2. Conditions for disparity amplification,[0],[0]
"Let λ∗ = Φ(λ∗) be a fixed point, and θ∗ = arg minθ E∑
k α ∗ kPk
[`(θ;Z)] be the minimizer at λ∗.
Define HR(α∗) as the positive definite Hessian of the expected risk at θ∗, λ∗ and define∇L as the per-group parameter gradients at θ∗,
∇L = ∇θEP1",3.2. Conditions for disparity amplification,[0],[0]
"[`(θ ∗;Z)]
... ∇θEPk",3.2. Conditions for disparity amplification,[0],[0]
[`(θ∗;Z)]  .,3.2. Conditions for disparity amplification,[0],[0]
"The arrival intensity λ∗ is unstable whenever
ρmax
( diag(ν(R(θ(λ∗))))− diag(λ∗ν′(R(θ(λ∗))
",3.2. Conditions for disparity amplification,[0],[0]
"∇LHR(α∗)−1∇L> (
I∑ k λ ∗ k",3.2. Conditions for disparity amplification,[0],[0]
− 1λ ∗>,3.2. Conditions for disparity amplification,[0],[0]
"( ∑ k λ ∗ k) 2
))",3.2. Conditions for disparity amplification,[0],[0]
"> 1.
",3.2. Conditions for disparity amplification,[0],[0]
"We see that the major quantities which control risk are the retention rate ν and its derivative, as well as a K × K square matrix ∇LHR(α∗)−1∇L> which roughly encodes the changes in one group’s risk as a function of another.
",3.2. Conditions for disparity amplification,[0],[0]
We can specialize the stability condition to obtain an intuitive and negative result for the stability of risk minimization (average case).,3.2. Conditions for disparity amplification,[0],[0]
"Even if we start at a fair fixed point with λ∗1 = · · · = λ∗k and R1 = · · · = Rk, if decreasing the risk for one group increases the risk for others sufficiently, the fixed point is unstable and the model will eventually converge to a different, possibly unfair, fixed point.
",3.2. Conditions for disparity amplification,[0],[0]
Corollary 1 (Counterexample under symmetry).,3.2. Conditions for disparity amplification,[0],[0]
"Let λ∗1 = · · · = λ∗k be a fixed point with R1 = · · · = Rk, then for any strongly convex loss,
ρmax ( ∇LHR(α∗)−1∇L> )",3.2. Conditions for disparity amplification,[0],[0]
">
1− ν(R1) −ν′(R1)/k .",3.2. Conditions for disparity amplification,[0],[0]
"(3)
is a sufficient condition for instability.
",3.2. Conditions for disparity amplification,[0],[0]
"See Section A.2 for proof and generalizations.
",3.2. Conditions for disparity amplification,[0],[0]
The bound (3) has a straightforward interpretation.,3.2. Conditions for disparity amplification,[0],[0]
"The left hand side is the stability of the model, where maximal eigenvalue of the matrix∇LHR(α∗)−1∇L> represents the maximum excess risk that can be incurred due to a small
perturbation in the mixture weights α.",3.2. Conditions for disparity amplification,[0],[0]
"The right hand side represents the underlying stability of the dynamics and measures the sensitivity of λ with respect to risk.
",3.2. Conditions for disparity amplification,[0],[0]
"Mean and median estimation: Consider a simple mean estimation example where each user belongs to one of two groups, −1 or 1 and incurs loss (θ − Z)2. θ",3.2. Conditions for disparity amplification,[0],[0]
"= 0 is clearly a fair fixed point, since it equalizes losses to both groups, with Hrisk(α∗) = 1/2 and ∇L =",3.2. Conditions for disparity amplification,[0],[0]
"[2,−2] mak-
ing ρmax ( ∇LHR(α∗)−1∇L> )",3.2. Conditions for disparity amplification,[0],[0]
= 4.,3.2. Conditions for disparity amplification,[0],[0]
"If we select ν(x) =
exp(−x), the right hand side becomes 2(1− e−1)e ≈ 3.4, and thus any perturbation will eventually result in λ1 6= λ2.",3.2. Conditions for disparity amplification,[0],[0]
"In this case the only other fixed points are the unfair solutions of returning the mean of either one of the groups.
",3.2. Conditions for disparity amplification,[0],[0]
"The situation is even worse for models which are not strongly convex, such as median estimation.",3.2. Conditions for disparity amplification,[0],[0]
Replacing the squared loss above with the absolute value results in a loss which has a non-unique minimizer at 0 when λ1 = λ2 but immediately becomes −1 whenever λ1 > λ2.,3.2. Conditions for disparity amplification,[0],[0]
"In this case, no conditions on the retention function ν can induce stability.",3.2. Conditions for disparity amplification,[0],[0]
This fundamental degeneracy motivates us to search for loss minimization schemes with better stability properties than ERM (average case).,3.2. Conditions for disparity amplification,[0],[0]
Recall that our goal is to control the worst-case risk (2) over all groups and over all time steps t. We will proceed in two steps.,4. Distributionally robust optimization (DRO),[0],[0]
"First, we show that performing distributionally robust optimization controls the worst-case riskRmax(θ(t)) for a single time step.",4. Distributionally robust optimization (DRO),[0],[0]
"Then, we show that this results in a lower bound on group proportions {α(t)k }Kk=1, and thus ensures control over the worst-case risk for all time steps.",4. Distributionally robust optimization (DRO),[0],[0]
"As a result of the two steps, we show in Section 4.4 that our procedure mitigates disparity amplification over all time steps.",4. Distributionally robust optimization (DRO),[0],[0]
"For notational clarity, we omit the superscript t in Sections 4.1-4.3.",4. Distributionally robust optimization (DRO),[0],[0]
The fundamental difficulty in controlling the worst-case group risk over a single time-step Rmax(θ(t)) comes from not observing the group memberships from which the data was sampled.,4.1. Bounding the risk over unknown groups,[0],[0]
"For many machine learning systems such as speech recognition or machine translation, such situations are common since we either do not ask for sensitive demographic information, or it is unclear a priori which demographics should be protected.",4.1. Bounding the risk over unknown groups,[0],[0]
"To achieve reasonable performance across different groups, we postulate a formulation that protects against all directions around the data generating distribution.",4.1. Bounding the risk over unknown groups,[0],[0]
"We build on the distributionally robust formulation of Duchi et al. (2016) which will allow us to control the worst-case group riskRmax(θ(t)).
",4.1. Bounding the risk over unknown groups,[0],[0]
"To formally describe our approach, let Dχ2 (P ||Q) be the χ2-divergence between probability distributions P and
Q given by Dχ2 (P ||Q)",4.1. Bounding the risk over unknown groups,[0],[0]
":= ∫ ( dP dQ − 1 )2 dQ. If P is not absolutely continuous with respect to Q, we define Dχ2 (P ||Q)",4.1. Bounding the risk over unknown groups,[0],[0]
":=∞.
Let B(P, r) be the chi-squared ball around a probability distribution P of radius r so that B(P, r) := {Q P : Dχ2 (Q||P ) ≤",4.1. Bounding the risk over unknown groups,[0],[0]
r}.,4.1. Bounding the risk over unknown groups,[0],[0]
"We consider the worst-case loss over all r-perturbations around P ,
Rdro(θ; r) := sup Q∈B(P,r) EQ[`(θ;Z)].",4.1. Bounding the risk over unknown groups,[0],[0]
"(4)
Intuitively, the distributionally robust risk Rdro(θ; r) upweights examples Z with high loss `(θ;Z).",4.1. Bounding the risk over unknown groups,[0],[0]
"If there is a group suffering high loss, the corresponding mixture component will be over-represented (relative to the original mixture weights) in the distributionally robust risk Rdro(θ; r).",4.1. Bounding the risk over unknown groups,[0],[0]
"We show in the following proposition that Rdro(θ; r) bounds the risk of each group Rk(θ), and hence the group-wise worst-case risk (1), for an appropriate choice of the robustness radius r.
Proposition 2.",4.1. Bounding the risk over unknown groups,[0],[0]
"For P := ∑ k∈[K] αkPk, we haveRk(θ) ≤",4.1. Bounding the risk over unknown groups,[0],[0]
"Rdro(θ; rk) for all θ ∈ Θ where rk := (1/αk − 1)2 is the robustness radius.
",4.1. Bounding the risk over unknown groups,[0],[0]
We prove the result in Section A.4.,4.1. Bounding the risk over unknown groups,[0],[0]
"Roughly speaking, the above bound becomes tighter if the variation in the loss `(θ;Z) is substantially higher between groups than within each group.",4.1. Bounding the risk over unknown groups,[0],[0]
"In particular, this would be the case if the loss distribution for each group have distinct support with relatively well-concentrated components within each group.
",4.1. Bounding the risk over unknown groups,[0],[0]
"As a consequence of Proposition 2, if we have a lower bound on the group proportions αmin ≤ mink∈[K] αk, then we can control the worst-case group risk Rmax(θ) by minimizing the upper bound θ 7→ Rdro(θ; rmax) where rmax := (1/αmin − 1)2.
",4.1. Bounding the risk over unknown groups,[0],[0]
"Similar formulations for robustness around the empirical distribution with radius shrinking as r/n had been considered in (Ben-Tal et al., 2013; Lam & Zhou, 2015; Duchi & Namkoong, 2016).",4.1. Bounding the risk over unknown groups,[0],[0]
"While there are many possible robustness balls B which could provide upper bounds on group risk, we opt to use the chi-squared ball since it is straightforward to optimize (Ben-Tal et al., 2013; Namkoong & Duchi, 2016; 2017) and we found it empirically outperformed other f -divergence balls.",4.1. Bounding the risk over unknown groups,[0],[0]
"The dual of the maximization problem (4) provides additional intuition on the behavior of the robust risk.
",4.2. Interpreting the dual,[0.9999999712661495],['The dual of the maximization problem (4) provides additional intuition on the behavior of the robust risk.']
"Proposition 3 ((Duchi & Namkoong, 2018)).",4.2. Interpreting the dual,[0],[0]
"If `(θ; ·) is upper semi-continuous for any θ, then for rmax ≥ 0 and
any θ,Rdro(θ; rmax) is equal to the following expression
inf η∈R
{ F (θ; η) := C ( EP [ [`(θ, Z)− η]2+ ])",4.2. Interpreting the dual,[0],[0]
"1 2 + η } (5)
where C = ( 2(1/αmin − 1)2 + 1 )1/2 .
Denoting by η?",4.2. Interpreting the dual,[0],[0]
"the optimal dual variable (5), we see from the proposition that all examples suffering less than η?levels of loss are completely ignored, and large losses above η?",4.2. Interpreting the dual,[0],[0]
"are upweighted due to the squared term.
",4.2. Interpreting the dual,[0],[0]
"However, unlike standard parameter regularization techniques, which encourage θ to be close to some point, our objective biases the model to have fewer high loss examples which matches our goal of mitigating representation disparity.
",4.2. Interpreting the dual,[0],[0]
Median Estimation: Recall the median estimation problem over two groups mentioned in Section 3.2 where the loss is `(θ;Z) =,4.2. Interpreting the dual,[0.9947026347723936],['Median Estimation: Recall the median estimation problem over two groups mentioned in Section 3.2 where the loss is `(θ;Z) = ‖θ − Z‖1.']
‖θ − Z‖1.,4.2. Interpreting the dual,[0],[0]
Figure 2 shows the behavior of both ERM and DRO on this median estimation task with unbalanced (αmin = 0.1) groups.,4.2. Interpreting the dual,[0],[0]
The parameter estimate which minimizes Rmax for this problem is θfair = 0,4.2. Interpreting the dual,[0],[0]
since this is equidistant from both groups.,4.2. Interpreting the dual,[0],[0]
ERM on the other hand focuses entirely on the majority and returns θERM,4.2. Interpreting the dual,[0],[0]
"≈ −1.0.
DRO returns θ∗DRO which is close to θfair.",4.2. Interpreting the dual,[0],[0]
"Analyzing the risk, we find that the single-step worst-case group riskRmax(θ) in (1) is an upper bound on ERM, and DRO forms a tight upper bound this quantity (Figure 2b).",4.2. Interpreting the dual,[0],[0]
We can also understand the behavior of DRO through the worst-case distribution Q in Equation 4.,4.2. Interpreting the dual,[0],[0]
Figure 2a shows the worst-case distribution Q at the minimizer θ∗DRO which completely removes points within distance η∗.,4.2. Interpreting the dual,[1.0],['Figure 2a shows the worst-case distribution Q at the minimizer θ∗DRO which completely removes points within distance η∗.']
"Additionally, points far from θ∗DRO are upweighted, resulting in a large contribution to the loss from the minority group.
",4.2. Interpreting the dual,[0],[0]
We expect the bound to be tight when all individuals within a group receive the same loss.,4.2. Interpreting the dual,[0],[0]
"In this case, thresholding
by η∗ corresponds to selecting the single highest risk group which is equivalent to directly minimizingRmax(θ) (1).
",4.2. Interpreting the dual,[0.9999999695332883],"['In this case, thresholding by η∗ corresponds to selecting the single highest risk group which is equivalent to directly minimizingRmax(θ) (1).']"
"On the other hand, the worst case for our approach is if αmin is small, and a group with low expected loss has a high loss tail with population size αmin.",4.2. Interpreting the dual,[0],[0]
"In this case DRO is a loose upper bound and optimizes the losses of the group with already low expected loss.
",4.2. Interpreting the dual,[0],[0]
"This is closely related to recent observations that the DRO bound can be loose for classification losses such as the zeroone loss due to the worst-case distribution consisting purely of misclassified examples (Hu et al., 2018).",4.2. Interpreting the dual,[1.0],"['This is closely related to recent observations that the DRO bound can be loose for classification losses such as the zeroone loss due to the worst-case distribution consisting purely of misclassified examples (Hu et al., 2018).']"
"Even in this case, the estimated loss is still a valid upper bound on the worst case group risk, and as Figure 2 shows, there are examples where the DRO estimate is nearly tight.",4.2. Interpreting the dual,[1.0],"['Even in this case, the estimated loss is still a valid upper bound on the worst case group risk, and as Figure 2 shows, there are examples where the DRO estimate is nearly tight.']"
We now show how to minimize θ 7→ Rdro(θ; rmax) efficiently for a large class of problems.,4.3. Optimization,[0],[0]
"For models such as deep neural networks that rely on stochastic gradient descent, the dual objective F (θ; η) in (5) can be used directly since it only involves an expectation over the data generating distribution P .
",4.3. Optimization,[0],[0]
"Formally, the following procedure optimizes (4): for a given value of η, compute the approximate minimizer θ̂η
minimize θ∈Θ
EP [`(θ;Z)− η]2+ .",4.3. Optimization,[0],[0]
"(6)
From Propositions 2 and 3, we have
Rmax(θ̂η) ≤ Rdro(θ̂η; rmax) ≤",4.3. Optimization,[0],[0]
"F (θ̂η, η)
which implies that we can treat η as a hyperparameter.",4.3. Optimization,[0],[0]
"For convex losses θ 7→ `(θ;Z), the function η 7→ F (θ̂η, η) is convex, and thus we can perform a binary search over η to find the global optimum efficiently.
",4.3. Optimization,[0],[0]
"Alternatively, for models where we can compute θ∗(Q) ∈ argminθ∈Θ EQ[`(θ;Z)] efficiently, we can use existing primal solvers that compute the worst-case probability distribution Q∗(θ) ∈ argmaxQ∈B(P,r) EQ[`(θ;Z)] for a given θ based on projected gradient ascent on Q (Namkoong & Duchi, 2016).",4.3. Optimization,[1.0],"['Alternatively, for models where we can compute θ∗(Q) ∈ argminθ∈Θ EQ[`(θ;Z)] efficiently, we can use existing primal solvers that compute the worst-case probability distribution Q∗(θ) ∈ argmaxQ∈B(P,r) EQ[`(θ;Z)] for a given θ based on projected gradient ascent on Q (Namkoong & Duchi, 2016).']"
"By alternating between optimization on θ and Q, we can efficiently find the saddle point (θ∗, Q∗) that satisfies θ∗ = θ∗(Q∗) and Q∗ = Q∗(θ∗).",4.3. Optimization,[0],[0]
"We have thus far demonstrated that for a single time step, the worst-case risk over all groups Rmax(θ) = maxkRk(θ) can be controlled by the distributionally robust riskRdro(θ; rmax) where rmax := (1/αmin",4.4. Stability of minority loss minimization,[0],[0]
− 1)2 and αmin is the minority group proportion.,4.4. Stability of minority loss minimization,[0],[0]
"Now, we study how the individual group risk Rk(θ) affects user retention and
hence future risk.",4.4. Stability of minority loss minimization,[1.000000059587463],"['Now, we study how the individual group risk Rk(θ) affects user retention and hence future risk.']"
"By virtue of providing an upper bound toRmax(θ), optimizingRdro(θ; rmax) at each time step can thus control the future group riskRmax(θ).
",4.4. Stability of minority loss minimization,[1.00000002268224],"['By virtue of providing an upper bound toRmax(θ), optimizingRdro(θ; rmax) at each time step can thus control the future group riskRmax(θ).']"
"We show that if the initial group proportions satisfy α(0)k ≥ αmin and the worst-case riskRmax(θ(t)) is sufficiently small at each time t, then we can ensure α(t+1)k > αmin.",4.4. Stability of minority loss minimization,[0],[0]
"Thus, to controlRTmax, the worst-case group risk over all time steps, it suffices to control Rdro(θ(t); rmax) using the procedure in Section 4.3.
",4.4. Stability of minority loss minimization,[0],[0]
Proposition 4.,4.4. Stability of minority loss minimization,[0],[0]
Assume the retention model in Definition 1.,4.4. Stability of minority loss minimization,[0],[0]
Let α(t)k >,4.4. Stability of minority loss minimization,[0],[0]
"αmin, bk∑ k bk > αmin, λ(t) := ∑ k λ (t) k ≤",4.4. Stability of minority loss minimization,[0],[0]
∑,4.4. Stability of minority loss minimization,[0],[0]
"k bk 1−νmax , and ν(Rk(θ(t)))",4.4. Stability of minority loss minimization,[0],[0]
< νmax.,4.4. Stability of minority loss minimization,[0],[0]
"Then, whenever we have
Rk(θ(t)) ≤",4.4. Stability of minority loss minimization,[0],[0]
"ν−1 (
1− (1− νmax)bk αmin ∑ k bk
) ,
α (t+1) k = λ(t)α",4.4. Stability of minority loss minimization,[0],[0]
(t) k ν(Rk(θ(t))),4.4. Stability of minority loss minimization,[0],[0]
+,4.4. Stability of minority loss minimization,[0],[0]
"bk∑
l λ (t)α (t) l ν(Rl(θ(t)))",4.4. Stability of minority loss minimization,[0],[0]
"+ bl
> αmin.
",4.4. Stability of minority loss minimization,[0],[0]
"We conclude that as long as we can guarantee
Rdro(θ(t); rmax) ≤ ν−1 (
1− (1− νmax)bk αmin ∑ k bk
) , (7)
we can control RTmax(θ(0), . . .",4.4. Stability of minority loss minimization,[0],[0]
", θ(T )), the unknown worstcase group risk over all time steps by optimizing Rdro(θ(t); rmax) at each step t.",4.4. Stability of minority loss minimization,[0],[0]
"While the condition (7) is hard to verify in practice, we observe empirically in Section 5 that optimizing the distributionally robust risk Rdro(θ(t); rmax) at time step t indeed significantly reduces disparity amplification in comparison to using ERM.
",4.4. Stability of minority loss minimization,[0],[0]
Proposition 4 gives stronger fairness guarantees than the stability conditions for ERM in Proposition 1.,4.4. Stability of minority loss minimization,[0],[0]
In ERM the best one can do is to add strong convexity to the model to stabilize to a possibly unfair fixed point.,4.4. Stability of minority loss minimization,[0],[0]
"In contrast, Proposition 4 gives conditions for controlling Rmax over time without assuming that there exists a fair fixed point.
",4.4. Stability of minority loss minimization,[0],[0]
"Stability of median estimation: Returning to our running example of geometric median estimation, we can show that under the same dynamics, ERM is highly unstable while DRO is stable.",4.4. Stability of minority loss minimization,[0],[0]
"Consider a three Gaussian mixture on the corners of the simplex, with L2 loss, retention function ν(r) = exp(−r), and b1 = b2 = 50, n(t) = 1000.",4.4. Stability of minority loss minimization,[0],[0]
"By construction, (1/3, 1/3, 1/3) is the fair parameter estimate.
",4.4. Stability of minority loss minimization,[0],[0]
"Figure 3 shows that ERM is highly unstable, with the only stable fixed points being the corners, where a single group dominates all others.",4.4. Stability of minority loss minimization,[0],[0]
"The fair parameter estimate is an unstable fixed point for ERM, and any perturbation eventually results in a completely unfair parameter estimate.",4.4. Stability of minority loss minimization,[0],[0]
"On the other hand, DRO has the reverse behavior, with the fair parameter estimate being the unique stable fixed point.",4.4. Stability of minority loss minimization,[0],[0]
We demonstrate the effectiveness of DRO on our motivating example (Figure 1) and human evaluation of a text autocomplete system on Amazon Mechanical Turk.,5. Experiments,[0],[0]
"In both cases, DRO controls the worst-case riskRTmax",5. Experiments,[0],[0]
over time steps,5. Experiments,[0],[0]
and improves minority retention.,5. Experiments,[0],[0]
"Recall the motivating example in Figure 1 which shows that logistic regression applied to a two-class classification problem is unstable and becomes pathologically unfair.
",5.1. Simulated task,[0.9999999645410058],['Recall the motivating example in Figure 1 which shows that logistic regression applied to a two-class classification problem is unstable and becomes pathologically unfair.']
"The data is constructed by drawing from a mixture of two Gaussians (groups) centered at (−1.5, 0) and (0, 1.5).",5.1. Simulated task,[0],[0]
"The two groups are labeled according to the linear decision boundaries (−3/2, √ 32 − 1/3) and (3/2, √ 32 − 1/3) respectively such that classifying with x2 > 0 is accurate, but the optimal linear classifier on one group achieves 50% accuracy on the other.
",5.1. Simulated task,[0],[0]
"At each round we fit a logistic regression classifier using ERM or DRO and gradient descent, constraining the norm of the weight vector to 1.",5.1. Simulated task,[1.0],"['At each round we fit a logistic regression classifier using ERM or DRO and gradient descent, constraining the norm of the weight vector to 1.']"
"Our dynamics follow Definition 1 with ν(x) = 1− x,R as the zero-one loss, and bk = 1000.",5.1. Simulated task,[0],[0]
"The DRO model is trained using the dual objective with logistic loss, and η = 0.95, which was the optimal dual solution to αmin = 0.2.",5.1. Simulated task,[0],[0]
"The results do not qualitatively change for choices of αmin < 0.5, and we show that we obtain control even for group sizes substantially smaller than 0.2 (Figure 6).
",5.1. Simulated task,[0],[0]
Figure 5 shows that ERM is unstable and the minority group rapidly loses accuracy beyond 300 rounds on most runs.,5.1. Simulated task,[1.0],['Figure 5 shows that ERM is unstable and the minority group rapidly loses accuracy beyond 300 rounds on most runs.']
"In contrast, DRO is stable, and maintains an accuracy of 0.8.
",5.1. Simulated task,[0],[0]
"This stability is due to the fact that the regularized loss for DRO prevents small losses in the minority fraction from amplifying, as we discuss in Proposition 4.",5.1. Simulated task,[0],[0]
"Even when the minority fraction falls as low as 1%, the DRO loss ensures that the accuracy of this minority fraction remains at 75% accuracy (Figure 6).",5.1. Simulated task,[0],[0]
"We now present a real-world, human evaluation of user retention and satisfaction on a text autocomplete task.",5.2. Autocomplete task,[1.0],"['We now present a real-world, human evaluation of user retention and satisfaction on a text autocomplete task.']"
"The task consists of the prediction of next words in a corpus of tweets built from two estimated demographic groups, African Americans and White Americans (Blodgett et al., 2016).",5.2. Autocomplete task,[0],[0]
"There are several distinguishing linguistic patterns between tweets from these groups, whose language dialects we henceforth refer to as African-American English (AAE) and Standard-American English (SAE), respectively, following the nomenclature in Blodgett et al. (2016).",5.2. Autocomplete task,[0],[0]
"Our overall experimental design is to measure the retention rate ν and riskR for various choices of demographic proportions (αAAE, αSAE) and simulate the implied dynamics, since running a fully online experiment would be prohibitively expensive.
",5.2. Autocomplete task,[0],[0]
"For both ERM and DRO, we train a set of five maximum likelihood bigram language models on a corpus with 366,361 tweets total and a f ∈ {0.1, 0.4, 0.5, 0.6, 0.9} fraction of the tweets labeled as AAE.",5.2. Autocomplete task,[0],[0]
"This results in 10 possible autocomplete systems a given Mechanical Turk user can be assigned to during a task.
",5.2. Autocomplete task,[0],[0]
"To evaluate the retention and loss for AAE and SAE separately, a turk user is assigned 10 tweets from either the held out AAE tweets or SAE tweets, which they must replicate using a web-based keyboard augmented by the autocomplete system.",5.2. Autocomplete task,[1.0],"['To evaluate the retention and loss for AAE and SAE separately, a turk user is assigned 10 tweets from either the held out AAE tweets or SAE tweets, which they must replicate using a web-based keyboard augmented by the autocomplete system.']"
This assignment of a turk user to a demographic group simulates the situation where a user from a particular demographic group attempts to use the autocomplete system to write a tweet.,5.2. Autocomplete task,[0],[0]
"Details of the autocomplete task are included in the supplement.
",5.2. Autocomplete task,[0],[0]
"After completing the task, users were asked to fill out a survey which included a rank from 1 to 5 on their satisfaction with the task, and a yes/no question asking whether they would continue to use such a system.",5.2. Autocomplete task,[0],[0]
"We assign 50 users to each of the two held out set types and each of the 10 autocomplete models, resulting in 1,000 users’ feedback across autocomplete models and assigned demographics.
",5.2. Autocomplete task,[0],[0]
The response to whether a user would continue to use the autocomplete system provides samples ν(RK(α)) with n = 366361 and each of possible demographic proportions α.,5.2. Autocomplete task,[0],[0]
The user satisfaction survey provides a surrogate forRK(α) at these same points.,5.2. Autocomplete task,[0],[0]
We interpolate ν andRK to α ∈,5.2. Autocomplete task,[0],[0]
"[0, 1] via isotone regression which then allows us to simulate the user dynamics and satisfaction over time using Definition 1.",5.2. Autocomplete task,[0],[0]
"We estimate variability in these estimates via bootstrap replicates on the survey responses.
",5.2. Autocomplete task,[0],[0]
"Our results in Figure 4 show an improvement in both minority satisfaction and retention rate due to DRO: we improve the median user satisfaction from 3.7 to 4.0 and retention from 0.7 to 0.85, while only slightly decreasing the SAE
satisfaction and retention.",5.2. Autocomplete task,[0],[0]
"Implied user counts follow the same trend with larger differences between groups due to compounding.
",5.2. Autocomplete task,[0],[0]
"Counterintuitively, the minority group has higher satisfaction and retention under DRO.",5.2. Autocomplete task,[0],[0]
Analysis of long-form comments from Turkers suggest this is likely due to users valuing the model’s ability to complete slang more highly than completion of common words and indicates a slight mismatch between our training loss and human satisfaction with an autocomplete system.,5.2. Autocomplete task,[0],[0]
In this work we argued for a view of loss minimization as a distributive justice problem and showed that ERM often results in disparity amplification and unfairness.,6. Discussion,[0],[0]
"We demonstrate that DRO provides a upper bound on the risk incurred by minority groups and performs well in practice.
",6. Discussion,[0],[0]
"Our proposed algorithm is straightforward to implement, and induces distributional robustness, which can be viewed as a benefit in and of itself.
",6. Discussion,[0],[0]
"Our arguments against ERM and in favor of minority risk minimization mirror Rawls’ arguments against utilitarianism, and thus inherit the critiques of Rawlsian distributive justice.",6. Discussion,[0],[0]
"Examples of such critiques are the focus on an abstract worst-off group rather than demographic groups or individuals (Altham, 1973), extreme risk-aversion (Mueller et al., 1974), and utilitarianism with diminishing returns as an alternative (Harsanyi, 1975).",6. Discussion,[0],[0]
"In this work, we do not address the debate on the correctness of Rawlsian justice (Rawls, 2001), and leave finding a suitable philosophical framework for loss minimization to future work.
",6. Discussion,[1.0000000436512757],"['In this work, we do not address the debate on the correctness of Rawlsian justice (Rawls, 2001), and leave finding a suitable philosophical framework for loss minimization to future work.']"
There are two large open questions from our work.,6. Discussion,[0],[0]
"First, as fairness is fundamentally a causal question, observational approaches such as DRO can only hope to control limited aspects of fairness.",6. Discussion,[1.0],"['First, as fairness is fundamentally a causal question, observational approaches such as DRO can only hope to control limited aspects of fairness.']"
"The generality with which our algorithm can be applied also limits its ability to enforce fairness as a constraint, and thus our approach here is unsuitable for high-stakes fairness applications such as classifiers for loans, criminality, or admissions.",6. Discussion,[0],[0]
In such problems the implied minorities from DRO may differ from well-specified demographic groups who are known to suffer from historical and societal biases.,6. Discussion,[1.0],['In such problems the implied minorities from DRO may differ from well-specified demographic groups who are known to suffer from historical and societal biases.']
"This gap arises due to looseness in the DRO bound (Hu et al., 2018), and could be mitigated using smoothness assumptions (Dwork et al., 2012).
",6. Discussion,[0],[0]
"Second, distributional robustness proposed here runs counter to classical robust estimation for rejecting outlier samples, as high loss groups created by an adversary can easily resemble a minority group.",6. Discussion,[0],[0]
"Adversarial or high-noise settings loosen the DRO upper bound substantially, and it is an open question whether it is possible to design algorithms which are both fair to unknown latent groups and robust.
",6. Discussion,[0],[0]
"Reproducibility: Code to generate results available on the CodaLab platform at https://bit.ly/2sFkDpE.
Acknowledgements: This work was funded by an Open Philanthropy Project Award.",6. Discussion,[0],[0]
"Machine learning models (e.g., speech recognizers) are usually trained to minimize average loss, which results in representation disparity— minority groups (e.g., non-native speakers) contribute less to the training objective and thus tend to suffer higher loss.",abstractText,[0],[0]
"Worse, as model accuracy affects user retention, a minority group can shrink over time.",abstractText,[0],[0]
"In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even make initially fair models unfair.",abstractText,[0],[0]
"To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution.",abstractText,[0],[0]
"We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups.",abstractText,[0],[0]
"We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.",abstractText,[0],[0]
Fairness Without Demographics in Repeated Loss Minimization,title,[0],[0]

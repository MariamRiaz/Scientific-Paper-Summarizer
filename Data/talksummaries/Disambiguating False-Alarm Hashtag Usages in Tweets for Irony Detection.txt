1	16	Metadata such as tags and emoticons given by users are considered as labels for training and testing learning-based models, which usually benefit from large amount of data.
3	13	In a tweet, the author can tag the short text with some hashtags such as #excited, #happy, #UnbornLivesMatter, and #Hillary4President to express their emotion or opinion.
4	18	The tweets with a certain types of hashtags are collected as self-label data in a variety of research works including sentiment analysis (Qadir and Riloff, 2014), stance detection (Mohammad et al., 2016; Sobhani et al., 2017), fi- nancial opinion mining (Cortis et al., 2017), and irony detection (Ghosh et al., 2015; Peled and Reichart, 2017; Hee et al., 2018).
5	38	In the case of irony detection, it is impractical to manually annotate the ironic sentences from randomly sampled data due to the relatively low occurrences of irony (Davidov et al., 2010).
7	20	As shown in (S1), the tweet with the hashtag #not is treated as a positive (ironic) instance by removing #not from the text.
9	11	#Disgrace #OngoingProblem http://t.co/FQZUUwKSoN However, the reliability of the self-labeled data is an important issue.
11	12	For instance, (S2) is tagged with #irony by the writer, but it is just witty and amusing.
15	9	That is, a hashtag in a tweet may also function as a content word in its word form.
16	11	For example, the hashtag #irony in (S3) is a part of the sentence “the irony of taking a break...”, in contrast to the hashtag #not in (S1), which can be removed without a change of meaning.
21	25	Compared to general training data cleaning approaches (Malik and Bhardwaj, 2011; Esuli and Sebastiani, 2013; Fukumoto and Suzuki, 2004) such as boostingbased learning, this work leverages the characteristics of hashtag usages in tweets.
22	14	With small amount of golden labeled data, we propose a neural network classifier for pruning the self-labeled tweets, and train an ironic detector on the less but cleaner instances.
47	12	Thus, we recover the original tweets by using Twitter search.
48	19	As shown in Table 1, a total of 1,359 tweets with hashtags information are adopted as the ground-truth.
60	14	We experiments with convolution neural network (CNN) (Kim, 2014), gated recurrent unit (GRU) (Cho et al., 2014), and attentive-GRU for sentence encoding.
75	9	(9) Position of the targeting hashtag in all hashtags in the tweet.
82	14	Our idea is that a tweet will be more grammatical complete with only the hash symbol removed if the hashtag is also a content word.
83	13	On the other hand, the tweet will be more grammatical complete with the whole hashtag removed since the hashtag is a metadata.
104	13	By integrating various kinds of information, our method outperforms all baseline models no matter which encoder is used.
105	14	The best model is the one integrating the attentive GRU encoder, which is significantly superior to all baseline models (p < 0.05), achieves an F-score of 88.49%, To confirm the effectiveness of the language modeling of POS sequence, we also try to exclude the GRU language model from our best model.
112	26	As prior work did, we collect a set of tweets that contain indication hashtags as (pseudo) positive instances and also collect a set of tweets that do not contain indication hashtags as negative instances.
119	9	The test data is made by the procedure as follows.
120	12	The positive instances in the test data are taken from the 1,072 human-verified ironic tweets that are reserved for irony detection as mentioned in Section 2.
124	11	As shown in Table 3, the irony detection model trained on the less, but cleaner data significantly outperforms the model that is trained on all data (p < 0.05).
130	14	The calibrated confidence output by the sigmoid layer of our hashtag disambiguation model can be regarded as a measurement of the reliability of an instance (Niculescu-Mizil and Caruana, 2005; Guo et al., 2017).
131	10	Thus, we can sort all self-labeled data by their calibrated confidence and control the size of training set by adjusting the threshold.
137	10	Self-labeled data is an accessible and economical resource for a variety of learning-based applications.
138	20	However, directly using the labels made by the crowd as ground-truth for training and testing may lead to inaccurate performance due to the reliability issue.
139	42	This paper addresses this issue in the case of irony detection by proposing a model to remove two kinds of false-alarm tweets from the training data.
140	23	Experimental results confirm that the irony detection model benefits from the less, but cleaner training data.
141	51	Our approach can be applied to other topics that rely on self-labeled data.

1	50	Early cross-lingual word embedding models relied on large amounts of parallel data (Klementiev et al., 2012; Mikolov et al., 2013a), but more recent approaches have tried to minimize the amount of supervision necessary (Vulić and Korhonen, 2016; Levy et al., 2017; Artetxe et al., 2017).
3	37	Unsupervised cross-lingual word embeddings hold promise to induce bilingual lexicons and machine translation models in the absence of dictionaries and translations (Barone, 2016; Zhang et al., 2017; Lample et al., 2018a), and would therefore be a major step toward machine translation to, from, or even between low-resource languages.
4	115	Unsupervised approaches to learning crosslingual word embeddings are based on the assumption that monolingual word embedding graphs are approximately isomorphic, that is, after removing a small set of vertices (words) (Mikolov et al., 2013b; Barone, 2016; Zhang et al., 2017; Conneau et al., 2018).
21	82	Word embeddings are particularly good at capturing relations between nouns, but even if we consider the top k most frequent English nouns and their translations, the graphs are not isomorphic; see Figure 1c-d. We take this as evidence that word embeddings are not approximately isomorphic across languages.
23	30	Eigenvector similarity Since the nearest neighbor graphs are not isomorphic, even for frequent translation pairs in neighboring languages, we want to quantify the potential for unsupervised BDI using a metric that captures varying degrees of graph similarity.
27	36	Let L1 = D1−A1 and L2 = D2−A2 be the Laplacians of the nearest neighbor graphs, where D1 and D2 are the corresponding diagonal matrices of degrees.
29	39	compute the eigensimilarity of the Laplacians of the nearest neighbor graphs, L1 and L2.
31	38	We take the smallest k of the two, and use the sum of the squared differences between the largest k Laplacian eigenvalues ∆ as our similarity metric.
32	37	min j { ∑k i=1 λji∑n i=1 λji > 0.9} Note that ∆ = 0 means the graphs are isospectral, and the metric goes to infinite.
36	23	The work of Conneau et al. (2018), which we focus on here, also makes several implicit assumptions that may or may not be necessary to achieve such isomorphism, and which may or may not scale to low-resource languages.
50	20	Finally, in §4.6, we investigate the impact of different types of query test words on performance, including how performance varies across part-of-speech word classes and on shared vocabulary items.
51	30	We now introduce the method of Conneau et al. (2018).4 The approach builds on existing work on learning a mapping between monolingual word embeddings (Mikolov et al., 2013b; Xing et al., 2015) and consists of the following steps: 1) Monolingual word embeddings: An off-the-shelf word embedding algorithm (Bojanowski et al., 2017) is used to learn source and target language spaces X and Y .
53	19	A discriminator is trained to discriminate samples from the translated source space WX from the target space Y , while W is trained to prevent this.
57	38	UΣV > = SVD(Y X>) (1) This step can be used iteratively by using the new matrix W to create new seed translation pairs.
60	19	4) Cross-domain similarity local scaling (CSLS) is used to expand high-density areas and condense low-density ones, for more accurate nearest neighbor calculation, CSLS reduces the hubness problem in high-dimensional spaces (Radovanović et al., 2010; Dinu et al., 2015).
66	33	Using this seed dictionary, we then run the refinement step using Procrustes analysis of Conneau et al. (2018).
90	23	The approach achieves impressive performance for Spanish, one of the languages Conneau et al. (2018) include in their paper.
91	30	For the languages we add here, performance is less impressive.
101	32	On the other hand, a similar distribution of embeddings requires languages to be similar.
103	43	In fact, our supervised method that relies on very naive supervision in the form of identically spelled words leads to competitive performance for similar language pairs and better results for dissimilar pairs.
104	25	The fact that we can reach competitive and more robust performance with such a simple heuristic questions the true applicability of fully unsupervised approaches and suggests that it might often be better to rely on available weak supervision.
106	26	In order to assess the sensitivity of unsupervised BDI to the comparability and domain similarity of the monolingual corpora, we replicate the experiments in Conneau et al. (2018) using combinations of word embeddings extracted from three different domains: 1) parliamentary proceedings from EuroParl.v7 (Koehn, 2005), 2) Wikipedia (Al-Rfou et al., 2013), and 3) the EMEA corpus in the medical domain (Tiedemann, 2009).
114	34	This is in sharp contrast with the results of our minimally supervised approach (Figures 2d–f) based on identical words, which achieves decent performance in many set-ups.
118	44	Conneau et al. (2018) use the same hyperparameters for inducing embeddings for all languages.
124	33	Our main finding here is that unsupervised BDI fails (even) for EN-ES when the two monolingual embedding spaces are induced by two different algorithms (see the results of the entire Spanish cbow column).9 In sum, this means that the unsupervised approach is unlikely to work on pre-trained word embeddings unless they are induced on same- or comparable-domain, reasonably-sized training data using the same underlying algorithm.
139	41	Homographs Since we use identical word forms (homographs) for supervision, we investigated whether these are representative or harder to align than other words.
140	87	Table 5 lists performance for three sets of query words: (a) source words that have homographs (words that are spelled the same way) with the same meaning (homonyms) in the target language, e.g., many proper names; (b) source words that have homographs that are not homonyms in the target language, e.g., many short words; and (c) other words.
141	21	Somewhat surprisingly, words which have translations that are homographs, are associated with lower precision than other words.
142	106	This is probably due to loan words and proper names, but note that using homographs as supervision for alignment, we achieve high precision for this part of the vocabulary for free.
143	95	Finally, in order to get a better understanding of the limitations of unsupervised BDI, we correlate the graph similarity metric described in §2 (right column of Table 2) with performance across languages (left column).

{"sections": [{"heading": "1. Introduction", "text": "Bayesian optimization (BO) has become a popular and effective way for black-box optimization of nonconvex, expensive functions in robotics, machine learning, computer vision, and many other areas of science and engineering (Brochu et al., 2009; Calandra et al., 2014; Krause & Ong, 2011; Lizotte et al., 2007; Snoek et al., 2012; Thornton et al., 2013; Wang et al., 2017). In BO, a prior is posed on the (unknown) objective function, and the uncertainty given by the associated posterior is the basis for an acquisition function that guides the selection of the next point to query the function. The selection of queries and hence the acquisition function is critical for the success of the method.\nDifferent BO techniques differ in this acquisition function.\n1Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA. Correspondence to: Zi Wang <ziw@csail.mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nAmong the most popular ones range the Gaussian process upper confidence bound (GP-UCB) (Auer, 2002; Srinivas et al., 2010), probability of improvement (PI) (Kushner, 1964), and expected improvement (EI) (Moc\u0306kus, 1974). Particularly successful recent additions are entropy search (ES) (Hennig & Schuler, 2012) and predictive entropy search (PES) (Herna\u0301ndez-Lobato et al., 2014), which aim to maximize the mutual information between the queried points and the location of the global optimum.\nES and PES are effective in the sense that they are queryefficient and identify a good point within competitively few iterations, but determining the next query point involves very expensive computations. As a result, these methods are most useful if the black-box function requires a lot of effort to evaluate, and are relatively slow otherwise. Moreover, they rely on estimating the entropy of the arg max of the function. In high dimensions, this estimation demands a large number of samples from the input space, which can quickly become inefficient.\nWe propose a twist to the viewpoint of ES and PES that retains the information-theoretic motivation and empirically successful query-efficiency of those methods, but at a much reduced computational cost. The key insight is to replace the uncertainty about the arg max with the uncertainty about the maximum function value. As a result, we refer to our new method as Max-value Entropy Search (MES). As opposed to the arg max, the maximum function value lives in a one-dimensional space, which greatly facilitates the estimation of the mutual information via sampling. We explore two strategies to make the entropy estimation efficient: an approximation by a Gumbel distribution, and a Monte Carlo approach that uses random features.\nOur contributions are as follows: (1) MES, a variant of the entropy search methods, which enjoys efficient computation and simple implementation; (2) an intuitive analysis which establishes the first connection between ES/PES and the previously proposed criteria GP-UCB, PI and EST (Wang et al., 2016), where the bridge is formed by MES; (3) a regret bound for a variant of MES, which, to our knowledge, is the first regret bound established for any variant of the entropy search methods; (4) an extension of MES to the high dimensional settings via additive Gaussian processes; and (5) empirical evaluations which demon-\nstrate that MES identifies good points as quickly or better than ES/PES, but is much more efficient and robust in estimating the mutual information, and therefore much faster than its input-space counterparts.\nAfter acceptance of this work, we learned that Hoffman & Ghahramani (2015) independently arrived at the acquisition function in Eq. (5). Yet, our approximation (Eq. (6)) is different, and hence the actual acquisition function we evaluate and analyze is different."}, {"heading": "2. Background", "text": "Our goal is to maximize a black-box function f : X \u2192 R where X \u2282 Rd and X is compact. At time step t, we select point xt and observe a possibly noisy function evaluation yt = f(xt) + t, where t \u223c N (0, \u03c32) are i.i.d. Gaussian variables. We use Gaussian processes (Rasmussen & Williams, 2006) to build a probabilistic model of the blackbox function to be optimized. For high dimensional cases, we use a variant of the additive Gaussian process (Duvenaud et al., 2011; Kandasamy et al., 2015). For completeness, we here introduce some basics of GP and add-GP."}, {"heading": "2.1. Gaussian Processes", "text": "Gaussian processes (GPs) are distributions over functions, and popular priors for Bayesian nonparametric regression. In a GP, any finite set of function values has a multivariate Gaussian distribution. A Gaussian process GP (\u00b5, k) is fully specified by a mean function \u00b5(x) and covariance (kernel) function k(x,x\u2032). Let f be a function sampled from GP (\u00b5, k). Given the observations Dt = {(x\u03c4 , y\u03c4 )}t\u03c4=1, we obtain the posterior mean \u00b5t(x) = kt(x) T(Kt+\u03c3 2I)\u22121yt and posterior covariance kt(x,x \u2032) = k(x,x\u2032)\u2212kt(x)T(Kt+\u03c32I)\u22121kt(x\u2032) of the function via the kernel matrix Kt = [k(xi,xj)]xi,xj\u2208Dt and kt(x) = [k(xi,x)]xi\u2208Dt (Rasmussen & Williams, 2006). The posterior variance is \u03c32t (x) = kt(x,x)."}, {"heading": "2.2. Additive Gaussian Processes", "text": "Additive Gaussian processes (add-GP) were proposed in (Duvenaud et al., 2011), and analyzed in the BO setting in (Kandasamy et al., 2015). Following the latter, we assume that the function f is a sum of independent functions sampled from Gaussian processes that are active on disjoint sets Am of input dimensions. Precisely, f(x) = \u2211M m=1 f\n(m)(xAm), with Ai \u2229 Aj = \u2205 for all i 6= j, | \u222aMi=1 Ai| = d, and f (m) \u223c GP (\u00b5(m), k(m)), for all m \u2264 M (M \u2264 d < \u221e). As a result of this decomposition, the function f is distributed according to GP ( \u2211M m=1 \u00b5 (m), \u2211M m=1 k\n(m)). Given a set of noisy observations Dt = {(x\u03c4 , y\u03c4 )}t\u03c4=1 where y\u03c4 \u223c N (f(x\u03c4 ), \u03c32), the posterior mean and\ncovariance of the function component f (m) can be inferred as \u00b5(m)t (x) = k (m) t (x) T(Kt + \u03c3 2I)\u22121yt and k(m)t (x,x \u2032) = k(m)(x,x\u2032) \u2212 k(m)t (x)T(Kt + \u03c32I)\u22121k (m) t (x \u2032), where k(m)t (x) = [k (m)(xi,x)]xi\u2208Dt\nandKt = [\u2211M m=1 k (m)(xi,xj) ] xi,xj\u2208Dt . For simplicity, we use the shorthand k(m)(x,x\u2032) = k(m)(xAm ,x\u2032Am)."}, {"heading": "2.3. Evaluation Criteria", "text": "We use two types of evaluation criteria for BO, simple regret and inference regret. In each iteration, we choose to evaluate one input xt to \u201clearn\u201d where the arg max of the function is. The simple regret rT = maxx\u2208X f(x) \u2212 maxt\u2208[1,T ] f(xt) measures the value of the best queried point so far. After all queries, we may infer an arg max of the function, which is usually chosen as x\u0303T = arg maxx\u2208X \u00b5T (x) (Hennig & Schuler, 2012; Herna\u0301ndez-Lobato et al., 2014). We denote the inference regret as RT = maxx\u2208X f(x) \u2212 f(x\u0303T ) which characterizes how satisfying our inference of the arg max is."}, {"heading": "3. Max-value Entropy Search", "text": "Entropy search methods use an information-theoretic perspective to select where to evaluate. They find a query point that maximizes the information about the location x\u2217 = arg maxx\u2208X f(x) whose value y\u2217 = f(x\u2217) achieves the global maximum of the function f . Using the negative differential entropy of p(x\u2217|Dt) to characterize the uncertainty about x\u2217, ES and PES use the acquisition functions\n\u03b1t(x) = I({x, y};x\u2217 | Dt) (1) = H (p(x\u2217 | Dt))\u2212 E [H(p(x\u2217 | Dt \u222a {x, y}))] (2) = H(p(y | Dt,x))\u2212 E [H(p(y | Dt,x,x\u2217))] . (3)\nES uses formulation (2), in which the expectation is over p(y|Dt,x), while PES uses the equivalent, symmetric formulation (3), where the expectation is over p(x\u2217|Dt). Unfortunately, both p(x\u2217|Dt) and its entropy is analytically intractable and have to be approximated via expensive computations. Moreover, the optimum may not be unique, adding further complexity to this distribution.\nWe follow the same information-theoretic idea but propose a much cheaper and more robust objective to compute. Instead of measuring the information about the argmax x\u2217, we use the information about the maximum value y\u2217 = f(x\u2217). Our acquisition function is the gain in mutual information between the maximum y\u2217 and the next point we query, which can be approximated analytically by evaluating the entropy of the predictive distribution:\n\u03b1t(x) = I({x, y}; y\u2217 | Dt) (4) = H(p(y | Dt,x))\u2212 E[H(p(y | Dt,x, y\u2217))] (5)\n\u2248 1 K \u2211 y\u2217\u2208Y\u2217 [ \u03b3y\u2217(x)\u03c8(\u03b3y\u2217(x)) 2\u03a8(\u03b3y\u2217(x)) \u2212 log(\u03a8(\u03b3y\u2217(x))) ] (6)\nwhere \u03c8 is the probability density function and \u03a8 the cumulative density function of a normal distribution, and \u03b3y\u2217(x) = y\u2217\u2212\u00b5t(x) \u03c3t(x)\n. The expectation in Eq. (5) is over p(y\u2217|Dn), which is approximated using Monte Carlo estimation by sampling a set of K function maxima. Notice that the probability in the first term p(y|Dt,x) is a Gaussian distribution with mean \u00b5t(x) and variance kt(x,x). The probability in the second term p(y|Dn,x, y\u2217) is a truncated Gaussian distribution: given y\u2217, the distribution of y needs to satisfy y < y\u2217. Importantly, while ES and PES rely on the expensive, d-dimensional distribution p(x\u2217|Dt), here, we use the one-dimensional p(y\u2217|Dn), which is computationally much easier.\nIt may not be immediately intuitive that the value should bear sufficient information for a good search strategy. Yet, the empirical results in Section 5 will demonstrate that this strategy is typically at least as good as ES/PES. From a formal perspective, Wang et al. (2016) showed how an estimate of the maximum value implies a good search strategy (EST). Indeed, Lemma 3.1 will make the relation between EST and a simpler, degenerate version of MES explicit.\nHence, it remains to determine how to sample y\u2217. We propose two strategies: (1) sampling from an approximation via a Gumbel distribution; and (2) sampling functions from the posterior Gaussian distribution and maximizing the functions to obtain samples of y\u2217. We present the MES algorithm in Alg. 1."}, {"heading": "3.1. Gumbel Sampling", "text": "The marginal distribution of f(x) for any x is a onedimensional Gaussian, and hence the distribution of y\u2217 may be viewed as the maximum of an infinite collection of dependent Gaussian random variables. Since this distribution is difficult to compute, we make two simplifications. First, we replace the continuous set X by a discrete (finite), dense subset X\u0302 of representative points. If we select X\u0302 to be an - cover of X and the function f is Lipschitz continuous with constant L, then we obtain a valid upper bound on f(X) by adding L to any upper bound on f(X\u0302).\nSecond, we use a \u201cmean field\u201d approximation and treat the function values at the points in X\u0302 as independent. This approximation tends to over-estimate the maximum; this follows from Slepian\u2019s lemma if k(x, x\u2032) \u2265 0. Such upper bounds still lead to optimization strategies with vanishing regret, whereas lower bounds may not (Wang et al., 2016).\nWe sample from the approximation p\u0302(y\u2217|Dn) via its cumulative distribution function (CDF) P\u0302r[y\u2217 < z] =\u220f\nx\u2208X\u0302 \u03a8(\u03b3z(x)). That means we sample r uniformly from\nAlgorithm 1 Max-value Entropy Search (MES) 1: function MES (f,D0) 2: for t = 1, \u00b7 \u00b7 \u00b7 , T do 3: \u03b1t\u22121(\u00b7)\u2190APPROX-MI (Dt\u22121) 4: xt \u2190 arg maxx\u2208X \u03b1t\u22121(x) 5: yt \u2190 f(xt) + t, t \u223c N (0, \u03c32) 6: Dt \u2190 Dt\u22121 \u222a {xt, yt} 7: end for 8: end function\n9: function Approx-MI (Dt) 10: if Sample with Gumbel then 11: approximate Pr[y\u0302\u2217 < y] with G(a, b) 12: sample a K-length vector r \u223c Unif([0, 1]) 13: y\u2217 \u2190 a\u2212 b log(\u2212 log r) 14: else 15: for i = 1, \u00b7 \u00b7 \u00b7 ,K do 16: sample f\u0303 \u223c GP (\u00b5t, kt | Dt) 17: y\u2217(i) \u2190 maxx\u2208X f\u0303(x) 18: end for 19: y\u2217 \u2190 [y\u2217(i)]Ki=1 20: end if 21: return \u03b1t(\u00b7) in Eq. (6) 22: end function\n[0, 1] and find z such that Pr[y\u2217 < z] = r. A binary search for z to accuracy \u03b4 requires O(log 1\u03b4 ) queries to the CDF, and each query takes O(|X\u0302|) \u2248 O(nd) time, so we obtain an overall time of O(M |X\u0302| log 1\u03b4 ) for drawing M samples.\nTo sample more efficiently, we propose a O(M + |X\u0302| log 1\u03b4 )-time strategy, by approximating the CDF by a Gumbel distribution: P\u0302r[y\u2217 < z] \u2248 G(a, b) = e\u2212e \u2212 z\u2212a\nb . This choice is motivated by the Fisher-Tippett-Gnedenko theorem (Fisher, 1930), which states that the maximum of a set of i.i.d. Gaussian variables is asymptotically described by a Gumbel distribution (see the appendix for further details). This does not in general extend to non-i.i.d. Gaussian variables, but we nevertheless observe that in practice, this approach yields a good and fast approximation.\nWe sample from the Gumbel distribution via the Gumbel quantile function: we sample r uniformly from [0, 1], and let the sample be y = G\u22121(a, b) = a \u2212 b log(\u2212 log r). We set the appropriate Gumbel distribution parameters a and b by percentile matching and solve the two-variable linear equations a \u2212 b log(\u2212 log r1) = y1 and a \u2212 b log(\u2212 log r2) = y2, where Pr[y\u2217 < y1] = r1 and Pr[y\u2217 < y2] = r2. In practice, we use r1 = 0.25 and r2 = 0.75 so that the scale of the approximated Gumbel distribution is proportional to the interquartile range of the CDF P\u0302r[y\u2217 < z]."}, {"heading": "3.2. Sampling y\u2217 via Posterior Functions", "text": "For an alternative sampling strategy we follow (Herna\u0301ndezLobato et al., 2014): we draw functions from the posterior GP and then maximize each of the sampled functions. Given the observations Dt = {(x\u03c4 , y\u03c4 )t\u03c4=1}, we can approximate the posterior Gaussian process using a 1-hiddenlayer neural network f\u0303(x) = aTt\u03c6(x) where \u03c6(x) \u2208 RD is a vector of feature functions (Neal, 1996; Rahimi et al., 2007) and the Gaussian weight at \u2208 RD is distributed according to a multivariate Gaussian N (\u03bdt,\u03a3t).\nComputing \u03c6(x). By Bochner\u2019s theorem (Rudin, 2011), the Fourier transform k\u0302 of a continuous and translation-invariant kernel k is guaranteed to be a probability distribution. Hence we can write the kernel of the GP to be k(x,x\u2032) = E\u03c9\u223ck\u0302(\u03c9)[e i\u03c9T(x\u2212x\u2032)] = Ec\u223cU [0,2\u03c0]Ek\u0302[2 cos(\u03c9 Tx + c) cos(\u03c9Tx\u2032 + c)] and approximate the expectation by k(x,x\u2032) \u2248 \u03c6T(x)\u03c6(x\u2032) where \u03c6i(x) = \u221a 2 D cos(\u03c9 T i x + ci), \u03c9i \u223c \u03ba\u0302(\u03c9), and ci \u223c U [0, 2\u03c0] for i = 1, . . . , D.\nComputing \u03bdt,\u03a3t. By writing the GP as a random linear combination of feature functions aTt \u03c6(x), we are defining the mean and covariance of the GP to be \u00b5t(x) = \u03bdT\u03c6(x) and k(x,x\u2032) = \u03c6(x)T\u03a3t\u03c6(x\u2032). Let Z = [z1, \u00b7 \u00b7 \u00b7 , zt] \u2208 RD\u00d7t, where z\u03c4 := \u03c6(x\u03c4 ) \u2208 RD. The GP posterior mean and covariance in Section 2.1 become \u00b5t(x) = z TZ(ZTZ + \u03c32I)\u22121yt and kt(x,x \u2032) = zTz\u2032 \u2212 zTZ(ZTZ + \u03c32I)\u22121ZTz\u2032. Because Z(ZTZ + \u03c32I)\u22121 = (ZZT+\u03c32I)\u22121Z, we can simplify the above equations and obtain \u03bdt = \u03c3\u22122\u03a3tZtyt and \u03a3t = (ZZ T\u03c3\u22122 + I)\u22121.\nTo sample a function from this random 1-hidden-layer neural network, we sample a\u0303 from N (\u03bdt,\u03a3t) and construct the sampled function f\u0303 = a\u0303T\u03c6(x). Then we optimize f\u0303 with respect to its input to get a sample of the maximum of the function maxx\u2208X f\u0303(x)."}, {"heading": "3.3. Relation to Other BO Methods", "text": "As a side effect, our new acquisition function draws connections between ES/PES and other popular BO methods. The connection between MES and ES/PES follows from the information-theoretic viewpoint; the following lemma makes the connections to other methods explicit. Lemma 3.1. The following methods are equivalent:\n1. MES, where we only use a single sample y\u2217 for \u03b1t(x); 2. EST with m = y\u2217; 3. GP-UCB with \u03b2 1 2 = minx\u2208X\ny\u2217\u2212\u00b5t(x) \u03c3t(x) ;\n4. PI with \u03b8 = y\u2217.\nThis equivalence no longer holds if we useM > 1 samples of y\u2217 in MES.\nProof. The equivalence among 2,3,4 is stated in Lemma 2.1 in (Wang et al., 2016). What remains to be shown is the equivalence between 1 and 2. When using a single y\u2217 in MES, the next point to evaluate is chosen by maximizing \u03b1t(x) = \u03b3y\u2217(x)\n\u03c8(\u03b3y\u2217 (x)) 2\u03a8(\u03b3y\u2217 (x)) \u2212 log(\u03a8(\u03b3y\u2217(x))) and \u03b3y\u2217 = y\u2217\u2212\u00b5t(x) \u03c3t(x)\n. For EST with m = y\u2217, the next point to evaluate is chosen by minimizing \u03b3y\u2217(x). Let us define a function g(u) = u \u03c8(u)2\u03a8(u) \u2212 log(\u03a8(u)). Clearly, \u03b1t(x) = g(\u03b3y\u2217(x)). Because g(u) is a monotonically decreasing function, maximizing g(\u03b3y\u2217(x)) is equivalent to minimizing \u03b3y\u2217(x). Hence 1 and 2 are equivalent."}, {"heading": "3.4. Regret Bound", "text": "The connection with EST directly leads to a bound on the simple regret of MES, when using only one sample of y\u2217. We prove Theorem 3.2 in the appendix.\nTheorem 3.2. Let F be the cumulative probability distribution for the maximum of any function f sampled from GP (\u00b5, k) over the compact search space X \u2282 Rd, where k(x,x\u2032) \u2264 1,\u2200x,x\u2032 \u2208 X. Let f\u2217 = maxx\u2208X f(x) and w = F (f\u2217) \u2208 (0, 1), and assume the observation noise is iidN (0, \u03c3). If in each iteration t, the query point is chosen as xt = arg maxx\u2208X \u03b3yt\u2217(x) \u03c8(\u03b3yt\u2217 (x))\n2\u03a8(\u03b3yt\u2217 (x))\u2212 log(\u03a8(\u03b3yt\u2217(x))),\nwhere \u03b3yt\u2217(x) = yt\u2217\u2212\u00b5t(x) \u03c3t(x) and yt\u2217 is drawn from F , then with probability at least 1 \u2212 \u03b4, in T \u2032 = \u2211T i=1 logw \u03b4 2\u03c0i number of iterations, the simple regret satisfies\nrT \u2032 \u2264 \u221a C\u03c1T T (\u03bdt\u2217 + \u03b6T ) (7)\nwhere C = 2/ log(1 + \u03c3\u22122) and \u03b6T = (2 log(\u03c0T\u03b4 )) 1 2 ; \u03c0 satisfies \u2211T i=1 \u03c0 \u22121 i \u2264 1 and \u03c0t > 0, and t\u2217 = arg maxt \u03bdt with \u03bdt , minx\u2208X,yt\u2217>f\u2217 \u03b3yt\u2217(x), and \u03c1T is the maximum information gain of at most T selected points."}, {"heading": "3.5. Model Adaptation", "text": "In practice we do not know the hyper-parameters of the GP, so we must adapt our GP model as we observe more data. A standard way to learn the GP hyper-parameters is to optimize the marginal data likelihood with respect to the hyperparameters. As a full Bayesian treatment, we can also draw samples of the hyper-parameters using slice sampling (Vanhatalo et al., 2013), and then marginalize out the hyperparameters in our acquisition function in Eq. (6). Namely, if we use E to denote the set of sampled settings for the GP hyper-parameters, our acquisition function becomes \u03b1t(x) = \u2211 \u03b7\u2208E \u2211 y\u2217\u2208Y\u2217 [ \u03b3\u03b7y\u2217(x)\u03c8(\u03b3 \u03b7 y\u2217(x)) 2\u03a8(\u03b3\u03b7y\u2217(x)) \u2212 log(\u03a8(\u03b3\u03b7y\u2217(x))) ] ,\nwhere \u03b3\u03b7y\u2217(x) = y\u2217\u2212\u00b5\u03b7t (x) \u03c3\u03b7t (x)\nand the posterior inference on the mean function \u00b5\u03b7t and \u03c3 \u03b7 t depends on the GP hyperparameter setting \u03b7. Similar approaches have been used in (Herna\u0301ndez-Lobato et al., 2014; Snoek et al., 2012)."}, {"heading": "4. High Dimensional MES with Add-GP", "text": "The high-dimensional input setting has been a challenge for many BO methods. We extend MES to this setting via additive Gaussian processes (Add-GP). In the past, AddGP has been used and analyzed for GP-UCB (Kandasamy et al., 2015), which assumed the high dimensional blackbox function is a summation of several disjoint lower dimensional functions. Utilizing this special additive structure, we overcome the statistical problem of having insufficient data to recover a complex function, and the difficulty of optimizing acquisition functions in high dimensions.\nSince the function components f (m) are independent, we can maximize the mutual information between the input in the active dimensions Am and maximum of f (m) for each component separately. Hence, we have a separate acquisition function for each component, where y(m) is the evaluation of f (m):\n\u03b1 (m) t (x) = I({xAm , y(m)}; y (m) \u2217 | Dt) (8)\n= H(p(y(m) | Dt,xAm))\n\u2212 E[H(p(y(m) | Dt,xAm , y(m)\u2217 ))] (9)\n\u2248 \u2211 y (m) \u2217 \u03b3(m)y\u2217 (x) \u03c8(\u03b3 (m) y\u2217 (x)) 2\u03a8(\u03b3 (m) y\u2217 (x)) \u2212 log(\u03a8(\u03b3(m)y\u2217 (x))) (10)\nwhere \u03b3(m)y\u2217 (x) = y(m)\u2217 \u2212\u00b5 (m) t (x)\n\u03c3 (m) t (x)\n. Analogously to the non-\nadditive case, we sample y(m)\u2217 , separately for each function component. We select the final xt by choosing a sub-vector x\n(m) t \u2208 arg maxx(m)\u2208Am \u03b1 (m) t (x (m)) and concatenating the components.\nSampling y(m)\u2217 with a Gumbel distribution. The Gumbel sampling from Section 3.1 directly extends to sampling y(m)\u2217 , approximately. We simply need to sample from the component-wise CDF P\u0302r[y(m)\u2217 < z] =\u220f\nx\u2208X\u0302 \u03a8(\u03b3 (m) y (x))), and use the same Gumbel approxi-\nmation.\nSampling y(m)\u2217 via posterior functions. The additive structure removes some connections on the input-to-hidden layer of our 1-hidden-layer neural network approximation f\u0303(x) = aTt\u03c6(x). Namely, for each feature function \u03c6 there exists a unique group m such that \u03c6 is only active on xAm ,\nand \u03c6(x) = \u221a\n2 D cos(\u03c9 TxAm + c) where R|Am| 3 \u03c9 \u223c\n\u03ba\u0302(m)(\u03c9) and c \u223c U [0, 2\u03c0]. Similar to the non-additive case, we may draw a posterior sample at \u223c N (\u03bdt,\u03a3t) where \u03bdt = \u03c3\u22122\u03a3tZtyt and \u03a3t = (ZZ\nT\u03c3\u22122 + I)\u22121. Let Bm = {i : \u03c6i(x) is active on xAm}. The posterior sample for the function component f (m) is f\u0303 (m)(x) = (aBmt )\nT\u03c6Bm(xAm). Then we can maximize f\u0303 (m) to obtain a sample for y(m)\u2217 .\nThe algorithm for the additive max-value entropy search method (add-MES) is shown in Algorithm 2. The function APPROX-MI does the pre-computation for approximating the mutual information in a similar way as in Algorithm 1, except that it only acts on the active dimensions in them-th group.\nAlgorithm 2 Additive Max-value Entropy Search 1: function Add-MES (f,D0) 2: for t = 1, \u00b7 \u00b7 \u00b7 , T do 3: for m = 1, \u00b7 \u00b7 \u00b7 ,M do 4: \u03b1(m)t\u22121(\u00b7)\u2190APPROX-MI (Dt\u22121) 5: xAmt \u2190 arg maxxAm\u2208XAm \u03b1 (m) t\u22121(x)\n6: end for 7: yt \u2190 f(xt) + t, t \u223c N (0, \u03c32) 8: Dt \u2190 Dt\u22121 \u222a {xt, yt} 9: end for\n10: end function"}, {"heading": "5. Experiments", "text": "In this section, we probe the empirical performance of MES and add-MES on a variety of tasks. Here, MES-G denotes MES with y\u2217 sampled from the approximate Gumbel distribution, and MES-R denotes MES with y\u2217 computed by maximizing a sampled function represented by random features. Following (Hennig & Schuler, 2012; Herna\u0301ndezLobato et al., 2014), we adopt the zero mean function and non-isotropic squared exponential kernel as the prior for the GP. We compare to methods from the entropy search family, i.e., ES and PES, and to other popular Bayesian optimization methods including GP-UCB (denoted by UCB), PI, EI and EST. The parameter for GP-UCB was set according to Theorem 2 in (Srinivas et al., 2010); the parameter for PI was set to be the observation noise \u03c3. For the functions with unknown GP hyper-parameters, every 10 iterations, we learn the GP hyper-parameters using the same approach as was used by PES (Herna\u0301ndez-Lobato et al., 2014). For the high dimensional tasks, we follow (Kandasamy et al., 2015) and sample the additive structure/GP parameters with the highest data likelihood when they are unknown. We evaluate performance according to the simple regret and inference regret as defined in Section 2.3. We used the open source Matlab implementation of PES, ES and EST (Hennig & Schuler, 2012; Herna\u0301ndez-Lobato\n50 100 150 200\net al., 2014; Wang et al., 2016). Our Matlab code and test functions are available at https://github.com/ zi-w/Max-value-Entropy-Search/."}, {"heading": "5.1. Synthetic Functions", "text": "We begin with a comparison on synthetic functions sampled from a 3-dimensional GP, to probe our conjecture that MES is much more robust to the number of y\u2217 sampled to estimate the acquisition function than PES is to the number of x\u2217 samples. For PES, we sample 100 (PES 100), 10 (PES 10) and 1 (PES 1) argmaxes for the acquisition function. Similarly, we sample 100, 10, 1 y\u2217 values for MES-R and MES-G. We average the results on 100 functions sampled from the same Gaussian kernel with scale parameter 5.0 and bandwidth parameter 0.0625, and observation noise N (0, 0.012).\nFigure 1 shows the simple and inference regrets. For both regret measures, PES is very sensitive to the the number of x\u2217 sampled for the acquisition function: 100 samples lead to much better results than 10 or 1. In contrast, both MES-G and MES-R perform competitively even with 1 or 10 samples. Overall, MES-G is slightly better than MESR, and both MES methods performed better than other ES methods. MES methods performed better than all other methods with respect to simple regret. For inference regret, MES methods performed similarly to EST, and much better than all other methods including PES and ES.\nIn Table 1, we show the runtime of selecting the next input per iteration1 using GP-UCB, PI, EI, EST, ES, PES, MES-R and MES-G on the synthetic data with fixed GP hyper-parameters. For PES and MES-R, every x\u2217 or y\u2217 requires running an optimization sub-procedure, so their running time grows noticeably with the number of samples. MES-G avoids this optimization, and competes with the fastest methods EI and UCB.\nIn the following experiments, we set the number of x\u2217 sampled for PES to be 200, and the number of y\u2217 sampled for MES-R and MES-G to be 100 unless otherwise mentioned."}, {"heading": "5.2. Optimization Test Functions", "text": "We test on three challenging optimization test functions: the 2-dimensional eggholder function, the 10-dimensional Shekel function and the 10-dimensional Michalewicz function. All of these functions have many local optima. We randomly sample 1000 points to learn a good GP hyperparameter setting, and then run the BO methods with the same hyper-parameters. The first observation is the same for all methods. We repeat the experiments 10 times. The averaged simple regret is shown in the appendix, and the inference regret is shown in Table 2. On the 2-d eggholder function, PES was able to achieve better function values faster than all other methods, which verified the good performance of PES when sufficiently many x\u2217 are sampled. However, for higher-dimensional test functions, the 10-d Shekel and 10-d Michalewicz function, MES methods performed much better than PES and ES, and MES-G performed better than all other methods."}, {"heading": "5.3. Tuning Hyper-parameters for Neural Networks", "text": "Next, we experiment with Levenberg-Marquardt optimization for training a 1-hidden-layer neural network. The 4 parameters we tune with BO are the number of neurons, the damping factor \u00b5, the \u00b5-decrease factor, and the \u00b5-increase factor. We test regression on the Boston housing dataset\n1All the timing experiments were run exclusively on an Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz. The function evaluation time is excluded.\nand classification on the breast cancer dataset (Bache & Lichman, 2013). The experiments are repeated 20 times, and the neural network\u2019s weight initialization and all other parameters are set to be the same to ensure a fair comparison. Both of the datasets were randomly split into train/validation/test sets. We initialize the observation set to have 10 random function evaluations which were set to be the same across all the methods. The averaged simple regret for the regression L2-loss on the validation set of the Boston housing dataset is shown in Fig. 2(a), and the classification accuracy on the validation set of the breast cancer dataset is shown in Fig. 2(b). For the classification problem on the breast cancer dataset, MES-G, PES and UCB achieved a similar simple regret. On the Boston housing dataset, MES methods achieved a lower simple regret. We also show the inference regrets for both datasets in Table 3."}, {"heading": "5.4. Active Learning for Robot Pushing", "text": "We use BO to do active learning for the pre-image learning problem for pushing (Kaelbling & Lozano-Pe\u0301rez, 2017). The function we optimize takes as input the pushing action of the robot, and outputs the distance of the pushed object to the goal location. We use BO to minimize the function in\norder to find a good pre-image for pushing the object to the designated goal location. The first function we tested has a 3-dimensional input: robot location (rx, ry) and pushing duration tr. We initialize the observation size to be one, the same across all methods. The second function has a 4-dimensional input: robot location and angle (rx, ry, r\u03b8), and pushing duration tr. We initialize the observation to be 50 random points and set them the same for all the methods. We select 20 random goal locations for each function to test if BO can learn where to push for these locations. We show the simple regret in Fig. 4 and the inference regret in Table 4. MES methods performed on a par with or better than their competitors."}, {"heading": "5.5. High Dimensional BO with Add-MES", "text": "In this section, we test our add-MES algorithm on high dimensional black-box function optimization problems. First we compare add-MES and add-GP-UCB (Kandasamy et al., 2015) on a set of synthetic additive functions with known additive structure and GP hyper-parameters. Each function component of the synthetic additive function is active on at most three input dimensions, and is sampled from a GP with zero mean and Gaussian kernel (bandwidth = 0.1 and scale = 5). For the parameter of addGP-UCB, we follow (Kandasamy et al., 2015) and set \u03b2\n(m) t = |Am| log 2t/5. We set the number of y (m) \u2217 sampled for each function component in add-MES-R and addMES-G to be 1. We repeat each experiment for 50 times\nfor each dimension setting. The results for simple regret are shown in Fig. 3. Add-MES methods perform much better than add-GP-UCB in terms of simple regret. Interestingly, add-MES-G works better in lower dimensional cases where d = 10, 20, 30, while add-MES-R outperforms both add-MES-G and add-GP-UCB for higher dimensions where d = 50, 100. In general, MES-G tends to overestimate the maximum of the function because of the independence assumption, and MES-R tends to underestimate the maximum of the function because of the imperfect global optimization of the posterior function samples. We conjecture that MES-R is better for settings where exploitation is preferred over exploration (e.g., not too many local optima), and MES-G works better if exploration is preferred.\nTo further verify the performance of add-MES in high dimensional problems, we test on two real-world high dimensional experiments. One is a function that returns the distance between a goal location and two objects being pushed\nby a robot which has 14 parameters2. The other function returns the walking speed of a planar bipedal robot, with 25 parameters to tune (Westervelt et al., 2007). In Fig. 5, we show the simple regrets achieved by add-GP-UCB and addMES. Add-MES methods performed competitively compared to add-GP-UCB on both tasks."}, {"heading": "6. Conclusion", "text": "We proposed a new information-theoretic approach, maxvalue entropy search (MES), for optimizing expensive black-box functions. MES is competitive with or better than previous entropy search methods, but at a much lower computational cost. Via additive GPs, MES is adaptable to high-dimensional settings. We theoretically connected MES to other popular Bayesian optimization methods including entropy search, GP-UCB, PI, and EST, and showed a bound on the simple regret for a variant of MES. Empirically, MES performs well on a variety of tasks.\n2We implemented the function in (Catto, 2011)."}, {"heading": "Acknowledgements", "text": "We thank Prof. Leslie Pack Kaelbling and Prof. Toma\u0301s Lozano-Pe\u0301rez for discussions on active learning and Dr. William Huber for his solution to \u201cExtreme Value Theory - Show: Normal to Gumbel\u201d at stats. stackexchange.com, which leads to our Gumbel approximation in Section 3.1. We gratefully acknowledge support from NSF CAREER award 1553284, NSF grants 1420927 and 1523767, from ONR grant N00014-14-10486, and from ARO grant W911NF1410433. We thank MIT Supercloud and the Lincoln Laboratory Supercomputing Center for providing computational resources. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors."}], "year": 2017, "references": [{"title": "Using confidence bounds for exploitation-exploration tradeoffs", "authors": ["Auer", "Peter"], "venue": "Journal of Machine Learning Research,", "year": 2002}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "authors": ["Brochu", "Eric", "Cora", "Vlad M", "De Freitas", "Nando"], "venue": "Technical Report TR-2009-023,", "year": 2009}, {"title": "An experimental comparison of Bayesian optimization for bipedal locomotion", "authors": ["Calandra", "Roberto", "Seyfarth", "Andr\u00e9", "Peters", "Jan", "Deisenroth", "Marc Peter"], "venue": "In International Conference on Robotics and Automation (ICRA),", "year": 2014}, {"title": "Box2D, a 2D physics engine for games", "authors": ["Catto", "Erin"], "venue": "http: //box2d.org,", "year": 2011}, {"title": "Additive Gaussian processes", "authors": ["Duvenaud", "David K", "Nickisch", "Hannes", "Rasmussen", "Carl E"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2011}, {"title": "The genetical theory of natural selection: a complete variorum edition", "authors": ["Fisher", "Ronald Aylmer"], "year": 1930}, {"title": "Entropy search for information-efficient global optimization", "authors": ["Hennig", "Philipp", "Schuler", "Christian J"], "venue": "Journal of Machine Learning Research,", "year": 2012}, {"title": "Predictive entropy search for efficient global optimization of black-box functions", "authors": ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", "Hoffman", "Matthew W", "Ghahramani", "Zoubin"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2014}, {"title": "Output-space predictive entropy search for flexible global optimization", "authors": ["Hoffman", "Matthew W", "Ghahramani", "Zoubin"], "venue": "In NIPS workshop on Bayesian Optimization,", "year": 2015}, {"title": "Learning composable models of primitive actions", "authors": ["Kaelbling", "Leslie Pack", "Lozano-P\u00e9rez", "Tom\u00e1s"], "venue": "In International Conference on Robotics and Automation (ICRA),", "year": 2017}, {"title": "High dimensional Bayesian optimisation and bandits via additive models", "authors": ["Kandasamy", "Kirthevasan", "Schneider", "Jeff", "Poczos", "Barnabas"], "venue": "In International Conference on Machine Learning (ICML),", "year": 2015}, {"title": "Contextual Gaussian process bandit optimization", "authors": ["Krause", "Andreas", "Ong", "Cheng S"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2011}, {"title": "A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise", "authors": ["Kushner", "Harold J"], "venue": "Journal of Fluids Engineering,", "year": 1964}, {"title": "Automatic gait optimization with Gaussian process regression", "authors": ["Lizotte", "Daniel J", "Wang", "Tao", "Bowling", "Michael H", "Schuurmans", "Dale"], "venue": "In International Conference on Artificial Intelligence (IJCAI),", "year": 2007}, {"title": "On Bayesian methods for seeking the extremum", "authors": ["J. Moc\u0306kus"], "venue": "In Optimization Techniques IFIP Technical Conference,", "year": 1974}, {"title": "Bayesian Learning for Neural networks", "authors": ["R.M. Neal"], "venue": "Lecture Notes in Statistics 118. Springer,", "year": 1996}, {"title": "Random features for largescale kernel machines", "authors": ["Rahimi", "Ali", "Recht", "Benjamin"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2007}, {"title": "Gaussian processes for machine learning", "authors": ["Rasmussen", "Carl Edward", "Williams", "Christopher KI"], "year": 2006}, {"title": "Fourier analysis on groups", "authors": ["Rudin", "Walter"], "year": 2011}, {"title": "Practical Bayesian optimization of machine learning algorithms", "authors": ["Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "year": 2012}, {"title": "Gaussian process optimization in the bandit setting: no regret and experimental design", "authors": ["Srinivas", "Niranjan", "Krause", "Andreas", "Kakade", "Sham M", "Seeger", "Matthias"], "venue": "In International Conference on Machine Learning (ICML),", "year": 2010}, {"title": "Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms", "authors": ["Thornton", "Chris", "Hutter", "Frank", "Hoos", "Holger H", "LeytonBrown", "Kevin"], "venue": "In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),", "year": 2013}, {"title": "Gpstuff: Bayesian modeling with gaussian processes", "authors": ["Vanhatalo", "Jarno", "Riihim\u00e4ki", "Jaakko", "Hartikainen", "Jouni", "Jyl\u00e4nki", "Pasi", "Tolvanen", "Ville", "Vehtari", "Aki"], "venue": "Journal of Machine Learning Research,", "year": 2013}, {"title": "Optimization as estimation with Gaussian processes in bandit settings", "authors": ["Wang", "Zi", "Zhou", "Bolei", "Jegelka", "Stefanie"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "year": 2016}, {"title": "Focused model-learning and planning for nonGaussian continuous state-action systems", "authors": ["Wang", "Zi", "Jegelka", "Stefanie", "Kaelbling", "Leslie Pack", "LozanoP\u00e9rez", "Tom\u00e1s"], "venue": "In International Conference on Robotics and Automation (ICRA),", "year": 2017}, {"title": "Feedback control of dynamic bipedal robot locomotion, volume 28", "authors": ["Westervelt", "Eric R", "Grizzle", "Jessy W", "Chevallereau", "Christine", "Choi", "Jun Ho", "Morris", "Benjamin"], "venue": "CRC press,", "year": 2007}], "id": "SP:7608eac3df45b8f8bc151b4e64faba182549070c", "authors": [{"name": "Zi Wang", "affiliations": []}, {"name": "Stefanie Jegelka", "affiliations": []}], "abstractText": "Entropy Search (ES) and Predictive Entropy Search (PES) are popular and empirically successful Bayesian Optimization techniques. Both rely on a compelling information-theoretic motivation, and maximize the information gained about the arg max of the unknown function; yet, both are plagued by the expensive computation for estimating entropies. We propose a new criterion, Max-value Entropy Search (MES), that instead uses the information about the maximum function value. We show relations of MES to other Bayesian optimization methods, and establish a regret bound. We observe that MES maintains or improves the good empirical performance of ES/PES, while tremendously lightening the computational burden. In particular, MES is much more robust to the number of samples used for computing the entropy, and hence more efficient for higher dimensional problems.", "title": "Max-value Entropy Search for Efficient Bayesian Optimization"}
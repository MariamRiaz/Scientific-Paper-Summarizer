0,1,label2,summary_sentences
"Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 93–102, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics",text,[0],[0]
"Authorship Attribution (AA) tackles the problem of determining who, among a set of authors, wrote the document at hand.",1 Introduction,[0],[0]
"AA has relevant applications ranging from plagiarism detection (Stamatatos, 2011) to Forensic Linguistics, such as identifying authorship of threatening emails or malicious code.",1 Introduction,[0],[0]
"Applied areas such as law and journalism can also benefit from authorship attribution, where identifying the true author of a piece of text (such as a ransom note) may help save lives or catch the offenders.
",1 Introduction,[0],[0]
"We know from state of the art research in AA that the length of the documents and the number of po-
tential candidate authors have an important effect on the accuracy of AA approaches (Moore, 2001; Luyckx and Daelemans, 2008; Luyckx and Daelemans, 2010).",1 Introduction,[0],[0]
"We can also point out the most common features that have been used successfully in AA work, including: bag-of-words (Madigan et al., 2005; Stamatatos, 2006), stylistic features (Zheng et al., 2006; Stamatatos et al., 2000), and word and character level n-grams (Kjell et al., 1994; Keselj et al., 2003; Peng et al., 2003; Juola, 2006).
",1 Introduction,[0],[0]
"The utility of bag-of-words features is well understood: they effectively capture correlations between authors and topics (Madigan et al., 2005; Kaster et al., 2005).",1 Introduction,[0],[0]
"The discriminative value of these features is thus directly related to the level of content divergence among authors and among train and test sets.
",1 Introduction,[0],[0]
"The utility of stylistic features is also well understood: they model author preferences for the use of punctuation marks, emoticons, white spaces, and other traces of writing style.",1 Introduction,[0],[0]
"Such preferences are less influenced by topic, and directly reflect some of the unique writing patterns of an author.
",1 Introduction,[0],[0]
Character n,1 Introduction,[0],[0]
"-grams are the single most successful feature in authorship attribution (Koppel et al., 2009; Frantzeskou et al., 2007; Koppel et al., 2011), but the reason for their success is not well understood.",1 Introduction,[0],[0]
"One hypothesis is that character n-grams carry a little bit of everything: lexical content, syntactic content, and even style by means of punctuation and white spaces (Koppel et al., 2011).",1 Introduction,[1.0],"['One hypothesis is that character n-grams carry a little bit of everything: lexical content, syntactic content, and even style by means of punctuation and white spaces (Koppel et al., 2011).']"
"While this argument seems plausible, it falls short of a rigorous explanation.
",1 Introduction,[0],[0]
"In this paper, we investigate what in the make-up
93
of these small units of text makes them so powerful.",1 Introduction,[0],[0]
"Our goal is two-fold: on the one hand we want to have a principled understanding of character ngrams that will inform their use as features for AA and other tasks; on the other hand we want to make AA approaches more accessible to non-experts so that, for example, they could be acceptable pieces of evidence in criminal cases.
",1 Introduction,[0],[0]
"The research questions we aim to answer are:
• Are all character n-grams equally important?",1 Introduction,[1.0000000552605854],['The research questions we aim to answer are: • Are all character n-grams equally important?']
"For example, are the prefix of ‘there’, the suffix of ‘breathe’ and the whole word ‘the’ all equivalent?",1 Introduction,[0],[0]
"More generally, are character n-grams that capture morpho-syntactic information, thematic information and style information equally important?
",1 Introduction,[0],[0]
• Are the character n-grams that are most important for single-domain settings also the most important for cross-domain settings?,1 Introduction,[0],[0]
"Which character n-grams are more like bag-of-words features (which tend to track topics), and which are more like stylistic features (which tend to track authors)?
",1 Introduction,[0],[0]
• Do different classifiers agree on the importance of the different types of character n-grams?,1 Introduction,[1.0],['• Do different classifiers agree on the importance of the different types of character n-grams?']
"Are some character n-grams consistently the best regardless of the learning algorithm?
",1 Introduction,[0],[0]
• Are some types of character n-grams irrelevant in AA tasks?,1 Introduction,[0],[0]
Are there categories of character n-grams that we can exclude and get similar (or better) performance than using all n-grams?,1 Introduction,[0],[0]
"If there are, are they the same for both singledomain and cross-domain AA settings?
",1 Introduction,[0],[0]
"Our study shows that using the default bag-ofwords representation of char n-grams results in collapsing sequences of characters that correspond to different linguistic aspects, and that this yields suboptimal prediction performance.",1 Introduction,[0.9544195115789125],['Our findings on the value of selecting n-grams according to the linguistic aspect they represent may also be beneficial in other classification tasks where character n-grams are commonly used.']
We further show that we can boost accuracy by loosing some categories of n-grams.,1 Introduction,[0],[0]
"Char n-grams closely related to thematic content can be completely removed without loss of accuracy, even in cases where the train and test sets have the same topics represented, a counter-intuitive argument.",1 Introduction,[0],[0]
"Given the wide spread use of char n-grams
in text classification tasks, our findings have significant implications for future work in related areas.",1 Introduction,[0],[0]
"To answer our research questions and explore the value of character n-grams in authorship attribution, we propose to separate character n-grams into ten distinct categories.",2 Categories of Character N -grams,[1.0],"['To answer our research questions and explore the value of character n-grams in authorship attribution, we propose to separate character n-grams into ten distinct categories.']"
"Unlike previous AA work where all character n-grams were combined into a single bagof-n-grams, we evaluate each category separately to understand its behavior and effectiveness in AA tasks.",2 Categories of Character N -grams,[0],[0]
"These categories are related to the three linguistic aspects hypothesized to be represented by character n-grams: morpho-syntax (as represented by affix-like n-grams), thematic content (as represented by word-like n-grams) and style (as represented by punctuation-based n-grams).",2 Categories of Character N -grams,[0],[0]
"We refer to these three aspects as super categories (SC).
",2 Categories of Character N -grams,[0.9999999899533182],['We refer to these three aspects as super categories (SC).']
The following sections describe the different types of n-grams.,2 Categories of Character N -grams,[0],[0]
We use the sentence in Table 1 as a running example for the classes and in Table 2 we show the resulting n-grams in that sentence.,2 Categories of Character N -grams,[0],[0]
"For ease of understanding, we replace spaces in n-grams with underscores ( ).
2.1 Affix n-grams Character n-grams are generally too short to represent any deep syntax, but some of them can reflect morphology to some degree.",2 Categories of Character N -grams,[0],[0]
"In particular, we consider the following affix-like features by looking at n-grams that begin or end a word:
prefix A character n-gram that covers the first n characters of a word that is at least n+ 1 characters long.
suffix A character n-gram that covers the last n characters of a word that is at least n + 1 characters long.
space-prefix A character n-gram that begins with a space.
space-suffix A character n-gram that ends with a space.
",2 Categories of Character N -grams,[0.9643255030695295],['suffix A character n-gram that covers the last n characters of a word that is at least n + 1 characters long.']
"2.2 Word n-grams While character n-grams are often too short to capture entire words, some types can capture partial words and other word-relevant tokens.",2 Categories of Character N -grams,[0],[0]
"We consider the following such features:
whole-word A character n-gram that covers all characters of a word that is exactly n characters long.
",2 Categories of Character N -grams,[0],[0]
mid-word,2 Categories of Character N -grams,[0],[0]
"A character n-gram that covers n characters of a word that is at least n + 2 characters long, and that covers neither the first nor the last character of the word.
",2 Categories of Character N -grams,[0.994862865319945],"['mid-word A character n-gram that covers n characters of a word that is at least n + 2 characters long, and that covers neither the first nor the last character of the word.']"
"multi-word N -grams that span multiple words, identified by the presence of a space in the middle of the n-gram.
",2 Categories of Character N -grams,[0],[0]
2.3 Punctuation n-grams,2 Categories of Character N -grams,[0],[0]
The main stylistic choices that character n-grams can capture are the author’s preferences for particular patterns of punctuation.,2 Categories of Character N -grams,[0],[0]
"The following features characterize punctuation by its location in the n-gram.
beg-punct A character n-gram",2 Categories of Character N -grams,[0],[0]
"whose first character is punctuation, but middle characters are not.
",2 Categories of Character N -grams,[0],[0]
"mid-punct A character n-gram with at least one punctuation character that is neither the first nor the last character.
end-punct A character n-gram whose last character is punctuation, but middle characters are not.
",2 Categories of Character N -grams,[0],[0]
"The above ten categories are intended to be disjoint, so that a character n-gram belongs to exactly one of the categories.",2 Categories of Character N -grams,[0],[0]
"For n-grams that contain both spaces and punctuation, we first categorize by punctuation and then by spaces.",2 Categories of Character N -grams,[0],[0]
"For example, ‘e, ’ is assigned to the mid-punct category, not the spacesuffix category.
",2 Categories of Character N -grams,[0],[0]
We have observed that in our data almost 80% of the n-grams in the punct-beg and punct-mid categories contain a space.,2 Categories of Character N -grams,[0],[0]
This tight coupling of punctuation and spaces is due to the rules of English orthography: most punctuation marks require a space following them.,2 Categories of Character N -grams,[0],[0]
"The 20% of n-grams that have punctuation but no spaces correspond mostly to the exceptions to this rule: quotation marks, mid-word hyphens, etc.",2 Categories of Character N -grams,[0],[0]
An interesting experiment for future work would be to split out these two types of punctuation into separate feature categories.,2 Categories of Character N -grams,[0],[0]
"We consider two corpora, a single-domain corpus, where there is only one topic that all authors are writing about, and a multi-domain corpus, where there are multiple different topics.",3 Datasets,[0],[0]
"The latter allows us to test the generalization of AA models, by testing them on a different topic from that used for training.
",3 Datasets,[0],[0]
"The first collection is the CCAT topic class, a subset of the Reuters Corpus Volume 1 (Lewis et al., 2004).",3 Datasets,[0],[0]
"Although this collection was not gathered for the goal of doing authorship attribution studies, previous work has reported results for AA with 10 and 50 authors (Stamatatos, 2008; Plakias and Stamatatos, 2008; Escalante et al., 2011).",3 Datasets,[0],[0]
"We refer to these as CCAT 10 and CCAT 50, respectively.",3 Datasets,[0],[0]
"Both CCAT 10 and CCAT 50 belong to CCAT category (about corporate/industrial news) and are balanced across authors, with 100 documents sampled for each author.",3 Datasets,[0],[0]
Manual inspection of the dataset revealed that some of the authors in this collection consistently used signatures at the end of documents.,3 Datasets,[0],[0]
"Also, we noticed some writers use quotations a lot.",3 Datasets,[0],[0]
"Con-
sidering these parts of text for measuring the frequencies of character n-grams is not a good idea because signatures provide direct clues about the authorship of document and quotations do not reflect the author’s writing style.",3 Datasets,[0],[0]
"Therefore, to clean up the CCAT collection, we preprocessed it to remove signatures and quotations from each document.",3 Datasets,[0],[0]
"Since the CCAT collection contains documents belonging to only corporate/industrial topic category, this will be our single-domain collection.
",3 Datasets,[0],[0]
"The other collection consists of texts published in The Guardian daily newspaper written by 13 authors in four different topics (Stamatatos, 2013).",3 Datasets,[0],[0]
"This dataset contains opinion articles on the topics: World, U.K., Society, and Politics.",3 Datasets,[0],[0]
"Following prior work, to make the collection balanced across authors, we choose at most ten documents per author for each of the four topics.",3 Datasets,[1.0],"['Following prior work, to make the collection balanced across authors, we choose at most ten documents per author for each of the four topics.']"
We refer to this corpus as Guardian1.,3 Datasets,[0],[0]
"We also consider a variation of this corpus that makes it more challenging but that more closely matches realistic scenarios of forensic investigation that deal with short texts such as tweets, SMS, and emails.",3 Datasets,[0],[0]
We chunk each of the documents by sentence boundaries into five new short documents.,3 Datasets,[0],[0]
"We refer to this corpus as Guardian2.
",3 Datasets,[0],[0]
"Table 3 shows some of the statistics of the CCAT and Guardian corpora and Table 4 presents some of the top character n-grams for each category (taken from an author in the Guardian data, but the top ngrams look qualitatively similar for other authors).",3 Datasets,[0],[0]
We performed various experiments using different categories of character n-grams.,4 Experimental Settings,[0],[0]
We chose n=3 since our preliminary experiments found character 3-grams to be more effective than other higher level character n-grams.,4 Experimental Settings,[0],[0]
"For each category, we considered only those 3-grams that occur at least five times in the training documents.
",4 Experimental Settings,[0],[0]
"The performance of different authorship attribu-
tion models was measured in terms of accuracy.",4 Experimental Settings,[0],[0]
"In the single-domain CCAT experiments, accuracy was measured using the train/test partition of prior work.",4 Experimental Settings,[0],[0]
"In the cross-domain Guardian experiments, accuracy was measured by considering all 12 possible pairings of the 4 topics, treating one topic as training data and the other as testing data, and averaging accuracy over these 12 scenarios.",4 Experimental Settings,[1.0],"['In the cross-domain Guardian experiments, accuracy was measured by considering all 12 possible pairings of the 4 topics, treating one topic as training data and the other as testing data, and averaging accuracy over these 12 scenarios.']"
"This ensured that in the crossdomain experiments, the topics of the training data were always different from that of the test data.
",4 Experimental Settings,[0],[0]
"We trained support vector machine (SVM) classifiers using the Weka implementation (Witten and Frank, 2005) with default parameters.",4 Experimental Settings,[1.0],"['We trained support vector machine (SVM) classifiers using the Weka implementation (Witten and Frank, 2005) with default parameters.']"
We also ran some comparative experiments with the Weka implementation of naive Bayes classifiers and the LibSVM implementation of SVMs.,4 Experimental Settings,[0],[0]
"In the results below, when performance of a single classifier is presented, it is the result of Weka’s SVM, which generally gave the best performance.",4 Experimental Settings,[1.0],"['In the results below, when performance of a single classifier is presented, it is the result of Weka’s SVM, which generally gave the best performance.']"
"When performance of other classifiers are presented, the classifiers are explicitly indicated.",4 Experimental Settings,[0.953498036552253],"['Across the different classifiers, the pattern of feature rankings are similar.']"
"In this section, we present various results on authorship attribution tasks using both single as well as cross-domain datasets.",5 Experimental Results and Evaluation,[0],[0]
"We will explore character ngrams in depth and try to understand why they are so effective in discriminating authors.
5.1 Which n-gram Categories are Most Author-Discriminative?
After breaking character n-grams into ten disjoint categories, we empirically illustrate what categories are
Single Domain (CCAT)
most discriminative.",5 Experimental Results and Evaluation,[0],[0]
"Table 5 shows the accuracy of each type of n-gram for each of the different corpora.
",5 Experimental Results and Evaluation,[0],[0]
"Table 5(a) shows that the top four categories for single-domain AA are: prefix, suffix, space-prefix, and mid-word.",5 Experimental Results and Evaluation,[1.0],"['Table 5(a) shows that the top four categories for single-domain AA are: prefix, suffix, space-prefix, and mid-word.']"
These four categories have the best performance on both CCAT 10 and CCAT 50.,5 Experimental Results and Evaluation,[0],[0]
"In contrast, Table 5(b) shows that the top four categories for cross-domain AA are: prefix, space-prefix, beg-
punct, and mid-punct.",5 Experimental Results and Evaluation,[0],[0]
"For both single-domain and cross-domain AA, prefix and space-prefix are strong features, and are generally better than the suffix features, perhaps because authors have more control over prefixes in English, while suffixes are often obligatory for grammatical reasons.",5 Experimental Results and Evaluation,[0],[0]
"For cross-domain AA, beg-punct and midpunct are the top features, likely because an author’s
use of punctuation is consistent even when the topic changes.",5 Experimental Results and Evaluation,[0],[0]
"For single-domain AA, mid-word was also a good feature, probably because it captured lexical information that correlates with authors’ preferences towards writing about specific topics.
",5 Experimental Results and Evaluation,[0],[0]
"Figure 1 shows an alternate view of these results, graphing the rank of each n-gram type.",5 Experimental Results and Evaluation,[0],[0]
"For computing the rank, the accuracies of the ten different n-gram type classifiers are sorted in decreasing order and ranked from 1 to 10 respectively with ties getting the same rank.",5 Experimental Results and Evaluation,[0],[0]
"For the Guardian corpora, the average rank of each n-gram category was computed by averaging its rank across the 12 possible test/train cross-domain combinations.",5 Experimental Results and Evaluation,[0],[0]
"In both of the single-domain CCAT corpora, the classifier based on prefix n-grams had the top accuracy (rank 1), and the classifier based on mid-punct had the worst accuracy (rank 10).",5 Experimental Results and Evaluation,[1.0],"['In both of the single-domain CCAT corpora, the classifier based on prefix n-grams had the top accuracy (rank 1), and the classifier based on mid-punct had the worst accuracy (rank 10).']"
"In both of the cross-domain Guardian corpora, on the other hand, mid-punct was among the top-ranked n-gram categories.",5 Experimental Results and Evaluation,[0],[0]
"This suggests that punctuation features generalize the best across topic, but if AA is more of a topic classification task (as in the single-domain CCAT corpora), then punctuation adds little over other features that more directly capture the topic.
",5 Experimental Results and Evaluation,[0],[0]
"Since our cross-domain datasets are small, we performed a small number of planned comparisons using a two-tailed t-test over the accuracies on the Guardian1 and Guardian2 corpora.",5 Experimental Results and Evaluation,[0],[0]
"We found that in both corpora, the best punctuation category (punctmid) is better than the best word category (wholeword) with p < 0.001.",5 Experimental Results and Evaluation,[0],[0]
"In the Guardian2 corpus, the best affix category (space-prefix) is also better than the best word category (whole-word) with p < 0.05, but this does not hold in the Guardian1 corpus (p = 0.14).",5 Experimental Results and Evaluation,[0],[0]
"Also, we observed that in both Guardian1 and Guardian2 datasets, both punct-mid and spaceprefix are better than multi-word (p < 0.01).
",5 Experimental Results and Evaluation,[0],[0]
"Overall, we see that affix n-grams are generally effective in both single-domain and cross-domain settings, punctuation n-grams are effective in crossdomain settings, and mid-word is the only effective word n-gram, and only in the single-domain setting.",5 Experimental Results and Evaluation,[0.9777042594576666],"['In the previous sections, we have seen that some types of character n-grams are more predictive than others - affix n-grams performed well in both single domain and cross-domain settings and punctuation n-grams performed well in cross-domain settings.']"
"Importance of Different n-gram Types?
",5.2 Do Different Classifiers Agree on the,[0],[0]
"The previous experiments have shown, for example, that prefix n-grams are universally predictive in AA
tasks, that mid-word n-grams are good predictors in single-domain settings, and that beg-punct n-grams are good predictors in cross-domain settings.",5.2 Do Different Classifiers Agree on the,[0],[0]
"But are these facts about the n-gram types themselves, or are these results only true for the specific SVM classifiers we trained?
",5.2 Do Different Classifiers Agree on the,[0],[0]
"To see whether certain types of n-grams are fundamentally good or bad, regardless of the classifier, we compare performance of the different n-gram types for three classifiers: Weka SVM classifiers (as used in our other experiments), LibSVM classifiers and Weka’s naive Bayes classifiers1.",5.2 Do Different Classifiers Agree on the,[1.0],"['To see whether certain types of n-grams are fundamentally good or bad, regardless of the classifier, we compare performance of the different n-gram types for three classifiers: Weka SVM classifiers (as used in our other experiments), LibSVM classifiers and Weka’s naive Bayes classifiers1.']"
"Figure 2 shows the n-gram category rankings for all these classifiers2 for both the single-domain CCAT and the cross-domain Guardian settings.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"Across the different classifiers, the pattern of feature rankings are similar.",5.2 Do Different Classifiers Agree on the,[0],[0]
Table 6 shows the Spearman’s rank correlation coefficient (ρ) for the per-ngram-type accuracies of each pair of classifiers.,5.2 Do Different Classifiers Agree on the,[0],[0]
"We observe fairly high correlations, with ρ above 0.70 for all single-domain pairings, and between 0.44 and 0.81 for cross-domain pairings.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"As in Section 5.1, prefix and space-prefix are among the most predictive n-gram types.",5.2 Do Different Classifiers Agree on the,[0],[0]
"In the single-domain settings, we again see that suffix and mid-word are also highly predictive, while in the cross-domain settings, we again see that beg-punct and mid-punct are highly predictive.",5.2 Do Different Classifiers Agree on the,[0],[0]
"These results all confirm that some types of n-grams are fundamentally more predictive than others, and our results are not specific to the particular type of classifier used.
",5.2 Do Different Classifiers Agree on the,[0],[0]
"1Weka SVM and LibSVM are both support vector machine classifiers, but Weka uses Platt’s sequential minimal optimization algorithm while LibSVM uses working set selection with second order information.",5.2 Do Different Classifiers Agree on the,[0],[0]
"The result is that they achieve different performance on our AA tasks.
2We also tried a decision tree classifier, C4.5 (J48) from WEKA, and it produced similar patterns (not shown).
",5.2 Do Different Classifiers Agree on the,[0],[0]
Single Domain (CCAT),5.2 Do Different Classifiers Agree on the,[0],[0]
"In the previous sections, we have seen that some types of character n-grams are more predictive than others - affix n-grams performed well in both single domain and cross-domain settings and punctuation n-grams performed well in cross-domain settings.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"In general, word n-grams were not as predictive as other types of n-grams (with the one exception being mid-word n-grams in the single domain setting).",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"Given this poor performance of word n-grams, a natural question is: could we exclude these features entirely and achieve similar performance?
",5.3 Are Some Character N -grams Irrelevant?,[1.0000000066630526],"['Given this poor performance of word n-grams, a natural question is: could we exclude these features entirely and achieve similar performance?']"
Our goal then is to compare a model trained on affix n-grams and punct n-grams against a model trained on “all” n-grams.,5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"We consider two definitions of “all”:
all-untyped The traditional approach to extracting n-grams where n-gram types are ignored (e.g., ‘the’ as a whole word is no different from ‘the’ in the middle of a word)
all-typed The approach discussed in this paper, where n-grams of different types are distinguished (equivalent to the set of all affix+punct+word n-grams).
",5.3 Are Some Character N -grams Irrelevant?,[1.0000000202110324],"['We consider two definitions of “all”: all-untyped The traditional approach to extracting n-grams where n-gram types are ignored (e.g., ‘the’ as a whole word is no different from ‘the’ in the middle of a word) all-typed The approach discussed in this paper, where n-grams of different types are distinguished (equivalent to the set of all affix+punct+word n-grams).']"
"We compare these models trained on all the n-grams to our affix+punct model.
",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
Table 7 shows this analysis.,5.3 Are Some Character N -grams Irrelevant?,[0],[0]
"For either definition of “all”, the model that discards all word features achieves performance as high or higher than the model with all of the features, and does so with only about two thirds of the features.",5.3 Are Some Character N -grams Irrelevant?,[1.0],"['For either definition of “all”, the model that discards all word features achieves performance as high or higher than the model with all of the features, and does so with only about two thirds of the features.']"
"This is not too surprising in the cross-domain Guardian tasks, where the word n-grams were among the worst features.",5.3 Are Some Character N -grams Irrelevant?,[1.0],"['This is not too surprising in the cross-domain Guardian tasks, where the word n-grams were among the worst features.']"
"On the single-domain CCAT tasks this result is more surprising, since we have discarded the mid-word n-grams, which was one of the best single-domain n-gram types.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
This indicates that whatever information mid-word is capturing it is also being captured in other ways via affix and punct n-grams.,5.3 Are Some Character N -grams Irrelevant?,[1.0],['This indicates that whatever information mid-word is capturing it is also being captured in other ways via affix and punct n-grams.']
"Of all 1024 possible combinations of features, we tried a
number of different combinations and were unable to identify one that outperformed affix+punct.",5.3 Are Some Character N -grams Irrelevant?,[0.9999999767246782],"['Of all 1024 possible combinations of features, we tried a number of different combinations and were unable to identify one that outperformed affix+punct.']"
"Overall, this experiment gives compelling evidence that affix and punct n-grams are more important than word n-grams.",5.3 Are Some Character N -grams Irrelevant?,[0],[0]
We did a manual exploration of our datasets.,6 Analysis,[0],[0]
"In our cross-domain dataset, the character 3-gram ‘sti’ shows up as both prefix and mid-word.",6 Analysis,[0],[0]
"All 13 authors use ‘sti’ frequently as a mid-word n-gram in words such as institution, existing, justice, and distinction.",6 Analysis,[0],[0]
"For example:
• The government’s story is that the existing warheads might be deteriorating.
",6 Analysis,[0],[0]
"• For all the justice of many of his accusations, the result is occasionally as dreadful as his title suggests.
",6 Analysis,[0],[0]
"But only six authors use ‘sti’ as a prefix, in examples like:
• Their mission was to convince tourists that Britain was still open for business.
",6 Analysis,[0],[0]
"• There aren’t even any dead people on it, since by the very act of being dead and still famous, they assert their long-term impact.
",6 Analysis,[0],[0]
Thus ‘sti’ as a prefix is predictive of authorship even though ‘sti’ as a mid-word n-gram is not.,6 Analysis,[0],[0]
"Notably, under the traditional untyped bag-of-n-grams approach, both versions of ‘sti’ would have been treated the same, and this discriminative power would have been lost.
",6 Analysis,[0],[0]
"As already demonstrated in Section 5 that affix+punct features perform better than using all the features, we would like to use an example from our dataset to visualize the text when features in SC word are discarded.",6 Analysis,[1.0],"['As already demonstrated in Section 5 that affix+punct features perform better than using all the features, we would like to use an example from our dataset to visualize the text when features in SC word are discarded.']"
Out of seven categories in affix and punct,6 Analysis,[0],[0]
", we computed in how many of them each character belongs to, three being the maximum possible value.",6 Analysis,[0],[0]
"Therefore, we show each character with different opacity level depending on number of categories it belongs to: zero will get white color (word related n-grams), one will get 33% black, two will get 67% black, and three will get 100% black.",6 Analysis,[1.0],"['Therefore, we show each character with different opacity level depending on number of categories it belongs to: zero will get white color (word related n-grams), one will get 33% black, two will get 67% black, and three will get 100% black.']"
"In Table 8, we show an example sentence before (first row of Table 8) and after (second row of Table 8) showing the opacity level of each character.",6 Analysis,[0],[0]
"It is clear that the darkest characters are those around the punctuation characters and those around spaces are second darkest, while the lightest (with 0% darkness) are the ones in the middle of long words.",6 Analysis,[0],[0]
This gives us an idea about the characters in a text that are important for AA tasks.,6 Analysis,[0],[0]
"Various hypotheses have been put forth to explain the “black magic” (Kestemont, 2014) behind the success of character n-gram features in authorship attribution.",7 Discussion,[0],[0]
Kestemont (2014) conjectured that their utility was in capturing function words and morphology.,7 Discussion,[0],[0]
"Koppel et al. (2009) suggested that they were capturing topic information in single domain settings, and style and syntactic information in cross-domain settings.",7 Discussion,[0],[0]
Our study provides empirical evidence for testing these claims.,7 Discussion,[0],[0]
"We did indeed find that the ability of character n-grams to capture morphology is useful, as reflected in the high prediction performance of af-
fix n-grams in both single-domain and cross-domain settings.",7 Discussion,[0],[0]
"And we found that word n-grams (capturing topic information) were useful in single domain settings, while puct n-grams (capturing style information) were useful in cross-domain settings.",7 Discussion,[1.0],"['And we found that word n-grams (capturing topic information) were useful in single domain settings, while puct n-grams (capturing style information) were useful in cross-domain settings.']"
"We further found that word n-grams are unnecessary, even in single-domain settings.",7 Discussion,[0],[0]
"Models based only on affix and punct n-grams performed as well as models with all n-grams regardless of whether it was a single-domain or cross-domain authorship attribution task.
",7 Discussion,[0],[0]
Our findings on the value of selecting n-grams according to the linguistic aspect they represent may also be beneficial in other classification tasks where character n-grams are commonly used.,7 Discussion,[0],[0]
"Promising tasks are those related to the stylistic analysis of texts, such as native language identification, document similarity and plagiarism detection.
",7 Discussion,[0.9999999998926994],"['Promising tasks are those related to the stylistic analysis of texts, such as native language identification, document similarity and plagiarism detection.']"
"Morphologically speaking, English is a poor language.",7 Discussion,[0],[0]
The fact that we identified significant differences in performance by selecting n-gram categories that are related to affixation in this poorly inflected language suggests that we may find even larger differences in performance in morphologically richer languages.,7 Discussion,[0],[0]
We leave this research question for future work.,7 Discussion,[1.0],['We leave this research question for future work.']
This research was partially supported by NSF awards 1462141 and 1254108.,Acknowledgements,[0],[0]
It was also supported in part by the CONACYT grant 134186 and the WIQ-EI IRSES project (grant no. 269180) within the FP 7 Marie Curie.,Acknowledgements,[0],[0]
"Character n-grams have been identified as the most successful feature in both singledomain and cross-domain Authorship Attribution (AA), but the reasons for their discriminative value were not fully understood.",abstractText,[0],[0]
"We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style.",abstractText,[0],[0]
We evaluate the predictiveness of each of these groups in two AA settings: a single domain setting and a cross-domain setting where multiple topics are present.,abstractText,[0],[0]
We demonstrate that character ngrams that capture information about affixes and punctuation account for almost all of the power of character n-grams as features.,abstractText,[0],[0]
Our study contributes new insights into the use of n-grams for future AA work and other classification tasks.,abstractText,[0],[0]
Not All Character N -grams Are Created Equal: A Study in Authorship Attribution,title,[0],[0]

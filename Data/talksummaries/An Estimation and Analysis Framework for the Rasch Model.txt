19	1	However, an exact analysis of the estimation error of the Rasch model is critical to ensure the a certain degree of reliability of assessment scores in tests (Thompson, 2002).
40	1	In contrast to such well-established, nonlinear estimators, we build our framework on the family of linear estimators recently proposed in (Lan et al., 2018).
56	1	We note that the linear estimator developed in (Lan et al., 2018, Thm.
57	1	1) is a special case of our result with x̄ = 0 and m = 0.
62	1	The MSE of the PM estimator is upperbounded as follows: MSE(xPM) ≤ MSE(x̂L-MMSE).
66	1	Due to symmetry in the Rasch model, we will present our results with unknown/known item difficulties while the user abilities are unknown and to be estimated; a corresponding analysis on the estimation error of item parameters follows immediately.
76	1	From (7), we see that if σ2x is held constant, then the relationship between MSEa and the numbers of users (U ) and items (Q) is given by the ratio of two second-order polynomials.
85	1	Thus, Theorem 3 provides guidelines on how many items to include and how many users to recruit for a study, given a desired MSE level on the user ability and item difficulty parameter estimates.
95	1	We then use several real-world collaborative filtering datasets to show that the L-MMSE estimator achieves comparable predictive performance to that of the PM and MAP estimators.
103	1	We also calculate the empirical parameter estimation MSEs of the L-MMSE and PM estimators.
117	1	We also see that the L-MMSE-based upper bound on the MSE is tighter than the Fisher information-based lower bound at low SNR levels (−10 dB and 1 dB), and especially when the problem size is small (less than 50 items).
119	1	We now test the performance of the proposed L-MMSE estimator using a variety of real-world datasets.
121	1	Datasets We perform our experiments using a range of collaborative filtering datasets.
124	1	The datasets include (i) “MT”, which consists of students’ binary-valued (correct/incorrect) graded responses to questions in a highschool algebra test, with U = 99 students’ 3, 366 responses to Q = 34 questions, (ii) “SS”, which consists of student responses in a signals and systems course, with U = 92 students’ 5, 692 responses to Q = 203 questions, (iii) “edX”, which consists of student responses in an edX course, with U = 3241 students’ 177, 181 responses to Q = 191 questions, and (iv) “ML”, a processed version of the ml-100k dataset from the Movielens project (Herlocker et al., 1999), with 37, 175 integer-valued ratings by U = 943 users to Q = 1152 movies.
126	1	Experimental Setup We evaluate the prediction performance of the L-MMSE, MAP, PM, and Logit-MAP estimators using ten-fold cross validation.
127	1	We randomly divide the entire dataset into ten equally-partitioned folds (of user-item response pairs), leave out one fold as the held-out testing set and use the other folds as the training set.
128	1	We then use the training set to estimate the learner abilities au and item difficulties di, and use these estimates to predict user responses on the test set.
131	1	Both metrics have range in [0, 1], with larger values indicating better predictive performance.
132	1	Results and Discussion Tables 1 and 2 show the mean and standard deviation of the performance of each estimator on both metrics across each fold.
139	1	We have shown that the L-MMSE estimator enables an exact, closed-form, and nonasymptotic MSE analysis, which is in stark contrast to existing analytical results which are asymptotic, probabilis- L-MMSE MAP PM Logit-MAP MT 0.840± 0.016 0.843± 0.015 0.843± 0.015 0.842± 0.015 SS 0.800± 0.014 0.803± 0.013 0.803± 0.013 0.802± 0.013 edX 0.900± 0.004 0.909± 0.004 0.909± 0.004 0.909± 0.004 ML 0.755± 0.005 0.756± 0.004 0.756± 0.004 0.756± 0.004 tic, or loose.
142	1	The L-MMSE estimator for x has the general form of x̂L-MMSE = Wy + b, where W = EC−1y and b = x̄−Wȳ, with Cy =E [ (y−ȳ)(y−ȳ)T ] =E [ yyT ] −ȳȳT :=C̃y−ȳȳT and E = E [ (y − ȳ)(x− x̄)T ] =E [ yxT ] −ȳx̄T :=Ẽ−ȳx̄T .
145	1	Its (i, j)th entry is given by [C̃y]i,j =∫ ∞ −∞ ∫ ∞ −∞ sign(zi) sign(zj)N ([ zi zj ] ;[ z̄i z̄j ] , [ [Cz]i,i [Cz]i,j [Cz]j,i [Cz]j,j ]) dzjdzi (a) = ∫ ∞ −∞ ∫ ∞ −∞ sign ( zi + z̄i√ [Cz]i,i ) sign ( zj + z̄j√ [Cz]j,j ) N ([ zi zj ] ;0, [ 1 ρ ρ 1 ]) dzjdzi = ∫ − z̄i√ [Cz]i,i −∞ ∫ − z̄j√ [Cz]j,j −∞ N ([ zi zj ] ;0, [ 1 ρ ρ 1 ]) dzjdzi︸ ︷︷ ︸ v1 + ∫ ∞ − z̄i√ [Cz]i,i ∫ ∞ − z̄j√ [Cz]j,j N ([ zi zj ] ;0, [ 1 ρ ρ 1 ]) dzjdzi︸ ︷︷ ︸ v2 − ∫ − z̄i√ [Cz]i,i −∞ ∫ ∞ − z̄j√ [Cz]j,j N ([ zi zj ] ;0, [ 1 ρ ρ 1 ]) dzjdzi︸ ︷︷ ︸ v3 − ∫ ∞ − z̄i√ [Cz]i,i ∫ − z̄j√ [Cz]j,j −∞ N ([ zi zj ] ;0, [ 1 ρ ρ 1 ]) dzjdzi︸ ︷︷ ︸ v4 (b) = 2(v1 + v2)− 1 = 2 ( Φ2 ( z̄i√ [Cz]i,i , z̄j√ [Cz]j,j , ρ ) + Φ2 ( − z̄i√ [Cz]i,i ,− z̄j√ [Cz]j,j , ρ )) − 1, where we have used (a) change of variable zi−z̄i√ [Cz]i,i → zi and (b) the fact that v1 +v2 +v3 +v4 = 1.
154	1	We next compute a, b, c, and d. The first column of C−1y is given by [a, b11×U−1, c, d11×U−1, c, d11×U−1, .
158	22	Now, let A be the N ×N matrix with c on its diagonal and d everywhere else, B denote the matrix with a − c on its diagonal and b− d everywhere else, we can write C−1y as C−1y = 1Q×Q⊗A + IQ×Q⊗B.
159	95	(10) Our second task is to evaluate E. Since E = √ 2 π diag(diag(Cz) −1/2)DCx = √ 2 π σ2x√ 2σ2x + 1 D = σ2x√ 2σ2x + 1 [1Q⊗ IU×U IQ×Q⊗1U ], we have ETC−1y E = 2 π σ4x 2σ2x + 1 [ 1TQ⊗ IU×U IQ×Q⊗1TU ] × (1Q×Q⊗A + IQ×Q⊗B)[1Q⊗ IU×U IQ×Q⊗1U ] = 2 π σ4x 2σ2x + 1 Q(QA + B), where we have used (X⊗Y)(U⊗V) = (XU)⊗(YV).
160	91	Therefore, the value of entry (1, 1) in ETC−1y E, i.e., the MSE of the user ability parameter estimates, is given by 2 π σ4x 2σ2x + 1 Q(a+ (Q− 1)c) = σ2x ( 1− 2 π σ2x 2σ2x + 1 sQ(Q+ U − 3) + 1 (s(Q− 2) + 1)(s(Q+ U − 2) + 1) ) , where we have used (9), thus completing the proof.

{"sections": [{"text": "ar X\niv :1\n61 0.\n05 12\n0v 4\n[ cs\n.D S]\n5 S"}, {"heading": "1 Introduction", "text": "Convex optimization is an important technique both from a theoretical and an applications perspective. Gradient descent based methods are widely used due to their simplicity and easy applicability to many real-world problems. We are interested in solving constraint convex optimization problems of the form\nmin x\u2208P\nf (x), (1)\nwhere f is a smooth convex function and P is a polytope, with access to f being limited to first-order information, i.e., we can obtain \u2207 f (x) and f (x) for a given x \u2208 P and access to P via a linear minimization oracle, which returns LPP(c) = argminx\u2208P cx for a given linear objective c.\nAlgorithm 1 Frank-Wolfe Algorithm [Frank and Wolfe, 1956] Input: smooth convex function f with curvature C, start vertex x1 \u2208 P, linear minimization oracle LPP Output: points xt in P\n1: for t = 1 to T \u2212 1 do 2: vt \u2190 LPP(\u2207 f (xt )) 3: xt+1 \u2190 (1 \u2212 \u03b3t )xt + \u03b3tvt with \u03b3t \u2254 2t+2 4: end for\nWhen solving Problem (1) using gradient descent approaches in order to maintain feasibility, typically a projection step is required. This projection back into the feasible region P is potentially computationally\n1\nexpensive, especially for complex feasible regions in very large dimensions. As such, projection-freemethods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012] due to their simplicity. We recall the basic Frank-Wolfe algorithm in Algorithm 1. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradient algorithms being used for e.g., online optimization and more generally machine learning. Also the property that these algorithms naturally generate sparse distributions over the extreme points of the feasible region is often helpful. Further increasing the relevance of these methods, it was shown recently that conditional gradient methods can also achieve linear convergence (see e.g., Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016]) as well as that the number of total gradient evaluations can be reduced while maintaining the optimal number of oracle calls as shown in Lan and Zhou [2014].\nUnfortunately, for complex feasible regions even solving the linear optimization problem might be timeconsuming and as such the cost of solving the LP might be non-negligible. This could be the case, e.g., when linear optimization over the feasible region is a hard problem or when solving large-scale optimization or learning problems. As such it is natural to ask the following questions:\n(i) Does the linear optimization oracle have to be called in every iteration?\n(ii) Does one need approximately optimal solutions for convergence?\n(iii) Can one reuse information across iterations?\nWe will answer these questions in this work, showing that (i) the LP oracle is not required to be called in every iteration, (ii) much weaker guarantees are sufficient, and (iii) we can reuse information. To significantly reduce the cost of oracle calls while maintaining identical convergence rates up to small constant factors, we replace the linear optimization oracle by a (weak) separation oracle (Oracle 1) which approximately solves\nOracle 1 Weak Separation Oracle LPsepP(c, x,\u03a6,K) Input: linear objective c \u2208 Rn, point x \u2208 P, accuracy K \u2265 1, objective value \u03a6 > 0; Output: Either (1) vertex y \u2208 P with c(x \u2212 y) > \u03a6/K , or (2) false: c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P.\na separation problem within a multiplicative factor and returns improving vertices. We stress that the weak separation oracle is significantly weaker than approximate minimization, which has been already considered in Jaggi [2013]. In fact, there is no guarantee that the improving vertices returned by the oracle are near to the optimal solution to the linear minimization problem. It is this relaxation of dual bounds and approximate optimality that will provide a significant speedup as we will see later. However, if the oracle does not return an improving vertex (returns false), then this fact can be used to derive a reasonably small dual bound of the form: f (xt ) \u2212 f (x\u2217) \u2264 \u2207 f (xt )(xt \u2212 x\u2217) \u2264 \u03a6t for some \u03a6t > 0. While the accuracy K is presented here as a formal argument of the oracle, an oracle implementation might restrict to a fixed value K > 1, which often makes implementation easier. We point out that the cases (1) and (2) potentially overlap if K > 1. This is intentional and in this case it is unspecified which of the cases the oracle should choose (and it does not matter for the algorithms).\nThis new oracle encapsulates the smart use of the original linear optimization oracle, even though for some problems it could potentially be implemented directly without relying on a linear programming oracle.\n2\nConcretely, a weak separation oracle can be realized by a single call to a linear optimization oracle and as such is no more complex than the original oracle. However it has two important advantages: it allows for caching and early termination. Caching refers to storing previous solutions, and first searching among them to satisfy the oracle\u2019s separation condition. The underlying linear optimization oracle is called only, when none of the cached solutions satisfy the condition. Algorithm 2 formalizes this process. Early termination is the technique to stop the linear optimization algorithm before it finishes at an appropriate stage, when from its internal data a suitable oracle answer can be easily recovered; this is clearly an implementation dependent technique. The two techniques can be combined, e.g., Algorithm 2 could use an early terminating linear oracle or other implementation of the weak separation oracle in line 4.\nAlgorithm 2 LPsepP(c, x,\u03a6,K) via LP oracle Input: linear objective c \u2208 Rn, point x \u2208 P, accuracy K \u2265 1, objective value \u03a6 > 0; Output: Either (1) vertex y \u2208 P with c(x \u2212 y) > \u03a6/K , or (2) false: c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P.\n1: if y \u2208 P cached with c(x \u2212 y) > \u03a6/K exists then 2: return y {Cache call} 3: else 4: y \u2190 argmaxx\u2208P cx {LP call} 5: if c(x \u2212 y) > \u03a6/K then 6: add y to cache 7: return y\n8: else\n9: return false\n10: end if\n11: end if\nWe call lazification the technique of replacing a linear programming oracle with a much weaker one, and we will demonstrate significant speedups in wall-clock performance (see e.g., Figure 25), while maintaining identical theoretical convergence rates.\nTo exemplify our approachwe provide conditional gradient algorithmsemploying the weak separation oracle for the standard Frank-Wolfe algorithm as well as the variants in [Hazan and Kale, 2012, Garber and Meshi, 2016, Garber and Hazan, 2013], which have been chosen due to requiring modified convergence arguments that go beyond those required for the vanilla Frank-Wolfe algorithm. Complementing the theoretical analysis we report computational results demonstrating effectiveness of our approach via a significant reduction in wall-clock time compared to their linear optimization counterparts.\nRelated Work\nThere has been extensive work on Frank-Wolfe algorithms and conditional gradient algorithms, so we will restrict to review work most closely related to ours. The Frank-Wolfe algorithm was originally introduced in [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966] and has been intensely studied in particular in terms of achieving stronger convergence guarantees as well as affineinvariant versions. We demonstrate our approach for the vanilla Frank-Wolfe algorithm [Frank and Wolfe, 1956] (see also [Jaggi, 2013]) as an introductory example. We then consider more complicated variants that require non-trivial changes to the respective convergence proofs to demonstrate the versatility of our approach. This includes the linearly convergent variant via local linear optimization [Garber and Hazan, 2013] as well as the pairwise conditional gradient variant of Garber and Meshi [2016], which is especially\n3\nefficient in terms of implementation. However, our technique also applies to the Away-Step Frank-Wolfe algorithm, the Fully-Corrective Frank-Wolfe algorithm, the Pairwise Conditional Gradient algorithm, as well as the Block-Coordinate Frank-Wolfe algorithm. Recently, in Freund and Grigas [2016] guarantees for arbitrary step-size rules were provided and an analogous analysis can be also performed for our approach. On the other hand, the analysis of the inexact variants, e.g., with approximate linear minimization does not apply to our case as our oracle is significantly weaker than approximate minimization as pointed out earlier. For more information, we refer the interested reader to the excellent overview in [Jaggi, 2013] for Frank-Wolfe methods in general as well as Lacoste-Julien and Jaggi [2015] for an overview with respect to global linear convergence.\nIt was also recently shown in Hazan and Kale [2012] that the Frank-Wolfe algorithm can be adjusted to the online learning setting and in this work we provide a lazy version of this algorithm. Combinatorial convex online optimization has been investigated in a long line of work (see e.g., [Kalai and Vempala, 2005, Audibert et al., 2013, Neu and Bart\u00f3k, 2013]). It is important to note that our regret bounds hold in the structured online learning setting, i.e., our bounds depend on the \u21131-diameter or sparsity of the polytope, rather than its ambient dimension for arbitrary convex functions (see e.g., [Cohen and Hazan, 2015, Gupta et al., 2016]). We refer the interested reader to [Hazan, 2016] for an extensive overview.\nA key component of the new oracle is the ability to cache and reuse old solutions, which accounts for the majority of the observed speed up. The idea of caching of oracle calls was already explored in various other contexts such as cutting plane methods (see e.g., Joachims et al. [2009]) as well as the Block-Coordinate Frank-Wolfe algorithm in Shah et al. [2015], Osokin et al. [2016]. Our lazification approach (which uses caching) is however much more lazy, requiring no multiplicative approximation guarantee; see [Osokin et al., 2016, Proof of Theorem 3. Appendix F] and Lacoste-Julien et al. [2013] for comparison to our setup.\nContribution\nThe main technical contribution of this paper is a new approach, whereby instead of finding the optimal solution, the oracle is used only to find a good enough solution or a certificate that such a solution does not exist, both ensuring the desired convergence rate of the conditional gradient algorithms.\nOur contribution can be summarized as follows:\n(i) Lazifying approach. We provide a general method to lazify conditional gradient algorithms. For this we replace the linear optimization oracle with a weak separation oracle, which allows us to reuse feasible solutions from previous oracle calls, so that in many cases the oracle call can be skipped. In fact, once a simple representation of the underlying feasible region is learned no further oracle calls are needed. We also demonstrate how parameter-free variants can be obtained.\n(ii) Lazified conditional gradient algorithms. We exemplify our approach by providing lazy versions of the vanilla Frank-Wolfe algorithm as well as of the conditional gradient methods in [Hazan and Kale, 2012, Garber and Hazan, 2013, Garber and Meshi, 2016].\n(iii) Weak separation through augmentation. We show in the case of 0/1 polytopes how to implement a weak separation oracle with at most k calls to an augmentation oracle that on input c \u2208 Rn and x \u2208 P provides either an improving solution x \u2208 P with cx < cx or ensures optimality, where k denotes the \u21131-diameter of P. This is useful when the solution space is sparse.\n(iv) Computational experiments. We demonstrate computational superiority by extensive comparisons of the weak separation based versions with their original versions. In all cases we report significant speedups in wall-clock time often of several orders of magnitude.\n4\nIt is important to note that in all cases, we inherit the same requirements, assumptions, and properties of the baseline algorithm that we lazify. This includes applicable function classes, norm requirements, as well as smoothness and (strong) convexity requirements. We also maintain identical convergence rates up to (small) constant factors.\nA previous version of this work appeared as extended abstract in Braun et al. [2017]; this version has been significantly revised over the conference version including a representative subset of more extensive computational results, full proofs for all described variants, as well as a variant that uses an augmentation oracle instead of linear optimization oracle (see Section 6).\nOutline\nWe briefly recall notation and notions in Section 2 and consider conditional gradient algorithms in Section 3. In Section 4 we consider parameter-free variants of the proposed algorithms, and in Section 5 we examine online versions. Finally, in Section 6 we show a realization of a weak separation oracle with an even weaker oracle in the case of combinatorial problem and we provide extensive computational results in Section 7."}, {"heading": "2 Preliminaries", "text": "Let \u2016\u00b7\u2016 be an arbitrary norm on Rn, and let \u2016\u00b7\u2016\u2217 denote the dual norm of \u2016\u00b7\u2016. A function f is L-Lipschitz if | f (y) \u2212 f (x)| \u2264 L\u2016y \u2212 x\u2016 for all x, y \u2208 dom f . A convex function f is smooth with curvature at most C if\nf (\u03b3y + (1 \u2212 \u03b3)x) \u2264 f (x) + \u03b3\u2207 f (x)(y \u2212 x) + C\u03b32/2\nfor all x, y \u2208 dom f and 0 \u2264 \u03b3 \u2264 1. A function f is S-strongly convex if\nf (y) \u2212 f (x) \u2265 \u2207 f (x)(y \u2212 x) + S 2 \u2016y \u2212 x\u20162\nfor all x, y \u2208 dom f . Unless stated otherwise Lipschitz continuity and strong convexity will be measured in the norm \u2016\u00b7\u2016. Moreover, let Br (x) \u2254 {y | \u2016x \u2212 y\u2016 \u2264 r} be the ball around x with radius r with respect to \u2016.\u2016. In the following, P will denote the feasible region, a polytope and the vertices of P will be denoted by v1, . . . , vN ."}, {"heading": "3 Lazy Conditional Gradient", "text": "We start with the most basic Frank-Wolfe algorithm as a simple example for lazifying by means of a weak separation oracle. We then lazify more complex Frank-Wolfe algorithms in Garber and Hazan [2013] and Garber and Meshi [2016]. Throughout this section \u2016\u00b7\u2016 denotes the \u21132-norm."}, {"heading": "3.1 Lazy Conditional Gradient: a basic example", "text": "We start with lazifying the original Frank-Wolfe algorithm (arguably the simplest Conditional Gradient algorithm), adapting the baseline argument from [Jaggi, 2013, Theorem 1]. While the vanilla version has suboptimal convergence rate O(1/T ), its simplicity makes it an illustrative example of the main idea of lazification. The lazy algorithm (Algorithm 3) maintains an upper bound\u03a6t on the convergence rate, guiding its eagerness for progress when searching for an improving vertex vt . If the weak separation oracle provides\n5\nAlgorithm 3 Lazy Conditional Gradient Input: smooth convex function f with curvature C, start vertex x1 \u2208 P, weak linear separation oracle LPsepP, accuracy K \u2265 1, step sizes \u03b3t , initial upper bound \u03a60 Output: points xt in P 1: for t = 1 to T \u2212 1 do 2: \u03a6t \u2190 \u03a6t\u22121+ C\u03b32t 2\n1+ \u03b3t K\n3: vt \u2190 LPsepP(\u2207 f (xt ), xt,\u03a6t,K) 4: if vt = false then 5: xt+1 \u2190 xt 6: else 7: xt+1 \u2190 (1 \u2212 \u03b3t )xt + \u03b3tvt 8: end if\n9: end for\nan improving vertex vt we refer to this as a positive call and if the oracle claims there are no improving vertices we call it a negative call.\nThe step size \u03b3t is chosen to (approximately) minimize \u03a6t in Line 2; roughly \u03a6t\u22121/KC.\nTheorem 3.1. Assume f is convex and smooth with curvature C. Then Algorithm 3 with \u03b3t = 2(K2+1)\nK(t+K2+2) and\nf (x1) \u2212 f (x\u2217) \u2264 \u03a60 has convergence rate\nf (xt ) \u2212 f (x\u2217) \u2264 2 max{C,\u03a60}(K2 + 1)\nt + K2 + 2 ,\nwhere x\u2217 is a minimum point of f over P.\nProof. We prove by induction that f (xt ) \u2212 f (x\u2217) \u2264 \u03a6t\u22121.\nThe claim is clear for t = 1 by the choice of \u03a60. Assuming the claim is true for t, we prove it for t + 1. We distinguish two cases depending on the return value of the weak separation oracle in Line 3.\nIn case of a positive call, i.e., when the oracle returns an improving solution vt , then \u2207 f (xt )(xt \u2212 vt ) \u2265 \u03a6t/K , which is used in the second inequality below. The first inequality follows by smoothness of f , and the second inequality by the induction hypothesis and the fact that vt is an improving solution:\nf (xt+1) \u2212 f (x\u2217) \u2264 f (xt ) \u2212 f (x\u2217)\ufe38 \ufe37\ufe37 \ufe38 \u2264\u03a6t\u22121 +\u03b3t \u2207 f (xt )(vt \u2212 xt )\ufe38 \ufe37\ufe37 \ufe38 \u2264\u2212\u03a6t /K +\nC\u03b32t\n2\n\u2264 \u03a6t\u22121 \u2212 \u03b3t \u03a6t\nK +\nC\u03b32t\n2 = \u03a6t,\nIn case of a negative call, i.e., when the oracle returns no improving solution, then in particular\u2207 f (xt )(xt\u2212 x\u2217) \u2264 \u03a6t , hence by Line 5\nf (xt+1) \u2212 f (x\u2217) = f (xt ) \u2212 f (x\u2217) \u2264 \u2207 f (xt )(xt \u2212 x\u2217) \u2264 \u03a6t .\n6\nFinally, using the specific values of \u03b3t we prove the upper bound\n\u03a6t\u22121 \u2264 2 max{C,\u03a60}(K2 + 1)\nt + K2 + 2\nby induction on t. The claim is obvious for t = 1. The induction step is an easy computation relying on the definition of \u03a6t on Line 2:\n\u03a6t = \u03a6t\u22121 +\nC\u03b32t 2\n1 + \u03b3t K\n\u2264 2 max{C,\u03a60 }(K2+1) t+K2+2 + max{C,\u03a60 }\u03b32t 2\n1 + \u03b3t K\n\u2264 2 max{C,\u03a60}(K 2 + 1)\nt + K2 + 3 .\nHere the last inequality follows from the concrete value of \u03b3t .\nNote that by design, the algorithm converges at the worst-case rate that we postulate due to the negative calls when it does not move. Clearly, this is highly undesirable, therefore the algorithm should be understood as the textbook variant of lazy conditional gradient. We will present an improved, parameter-free variant of Algorithm 3 in Section 4 that converges at the best possible rate that the non-lazy variant would achieve (up to a small constant factor)."}, {"heading": "3.2 Lazy Pairwise Conditional Gradient", "text": "In this section we provide a lazy variant (Algorithm 4) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization. We make identical assumptions: the feasible region is a 0/1 polytope, i.e., all vertices of P have only 0/1 entries, and moreover it is given in the form P = {x \u2208 Rn | 0 \u2264 x \u2264 1, Ax = b}, where 1 denotes the all-one vector.\nAlgorithm 4 Lazy Pairwise Conditional Gradient (LPCG) Input: polytope P, smooth and S-strongly convex function f with curvature C, accuracy K \u2265 1, nonincreasing step-sizes \u03b7t , eagerness \u2206t Output: points xt 1: x1 \u2208 P arbitrary and \u03a60 \u2265 f (x1) \u2212 f (x\u2217) 2: for t = 1, . . . ,T do\n3: \u2207\u0303 f (xt )i \u2254 { \u2207 f (xt )i if xt,i > 0 \u2212\u221e if xt,i = 0 4: \u03a6t \u2190 2\u03a6t\u22121+\u03b7 2 tC\n2+ \u03b7tK\u2206t\n5: ct \u2190 ( \u2207 f (xt ),\u2212\u2207\u0303 f (xt ) ) 6: (v+t , v\u2212t ) \u2190 LPsepP\u00d7P ( ct, (xt, xt ), \u03a6t\u2206t , K ) 7: if (v+t , v\u2212t ) = false then 8: xt+1 \u2190 xt 9: else\n10: \u03b7\u0303t \u2190 max{2\u2212\u03b4 | \u03b4 \u2208 Z\u22650, 2\u2212\u03b4 \u2264 \u03b7t } 11: xt+1 \u2190 xt + \u03b7\u0303t (v+t \u2212 v\u2212t ) 12: end if\n13: end for\n7\nObserve that Algorithm 4 calls the linear separation oracle LPsep on the cartesian product of P with itself. Choosing the objective function as in Line 5 allows us to simultaneously find an improving direction and an away-step direction.\nLet card x denote the number of non-zero entries of the vector x.\nTheorem 3.2. Let x\u2217 be a minimum point of f in P, and \u03a60 an upper bound of f (x1) \u2212 f (x\u2217). Furthermore, let card(x\u2217) \u2264 \u03b1, M1 \u2254 \u221a S 8\u03b1 , \u03ba \u2254 min { M1 KC , 1/ \u221a \u03a60 } , \u03b7t \u2254 \u03ba \u221a \u03a6t\u22121 and \u2206t \u2254 \u221a 2\u03b1\u03a6t\u22121 S , then Algorithm 4 has convergence rate\nf (xt+1) \u2212 f (x\u2217) \u2264 \u03a6t \u2264 \u03a60 ( 1 + B\n1 + 2B\n) t ,\nwhere B \u2254 \u03ba \u00b7 M12K .\nWe recall a technical lemma for the proof.\nLemma 3.3 ([Garber and Meshi, 2016, Lemma 2]). Let x, y \u2208 P. Then x is a liner combination x = \u2211ki=1 \u03bbivi of some vertices vi of P (in particular, \u2211k i=1 \u03bbi = 1) with x \u2212 y = \u2211k i=1 \u03b3i(vi \u2212 z) for some 0 \u2264 \u03b3i \u2264 \u03bbi and\nz \u2208 P such that \u2211ki=1 \u03b3i \u2264 \u221a card(y)\u2016x \u2212 y\u2016.\nProof of Theorem 3.2. The feasibility of the iterates xt is ensured by Line 10 and the monotonicity of the sequence {\u03b7t }t\u22651 with the same argument as in [Garber and Meshi, 2016, Lemma 1 and Observation 2].\nWe first show by induction that f (xt+1) \u2212 f (x\u2217) \u2264 \u03a6t .\nFor t = 0 we have \u03a60 \u2265 f (x1) \u2212 f (x\u2217). Now assume the statement for some t \u2265 0. In case of a negative call (Line 8), we use the guarantee of Oracle 1 to get\nct [(xt, xt ) \u2212 (z1, z2)] \u2264 \u03a6t\n\u2206t\nfor all z1, z2 \u2208 P, which is equivalent to (as ct (xt, xt ) = 0)\n\u2207\u0303 f (xt )z2 \u2212 \u2207 f (xt )z1 \u2264 \u03a6t\n\u2206t\nand therefore\n\u2207 f (xt )(z\u03032 \u2212 z1) \u2264 \u03a6t\n\u2206t , (2)\nfor all z\u03032, z1 \u2208 P with supp(z\u03032) \u2286 supp(xt ), where supp(x) denotes the set of non-zero coordinates of x. We use Lemma 3.3 for the decompositions xt = \u2211k i=1 \u03bbivi and xt \u2212 x\u2217 = \u2211k i=1 \u03b3i(vi \u2212 z) with 0 \u2264 \u03b3i \u2264 \u03bbi, z \u2208 P and k\u2211\ni=1\n\u03b3i \u2264 \u221a card(x\u2217)\u2016xt \u2212 x\u2217\u2016 \u2264 \u221a\n2 card(x\u2217)\u03a6t\u22121 S \u2264 \u2206t,\nusing the induction hypothesis and strong convexity in the second inequality. Then\nf (xt+1) \u2212 f (x\u2217) = f (xt ) \u2212 f (x\u2217) \u2264 \u2207 f (xt )(xt \u2212 x\u2217) = k\u2211\ni=1 \u03b3i \u00b7 \u2207 f (xt )(vi \u2212 z)\ufe38 \ufe37\ufe37 \ufe38 \u2264\u03a6t /\u2206t \u2264 \u03a6t,\n8\nwhere we used Equation (2) for the last inequality. In case of a positive call (Lines 10 and 11) we get, using first smoothness of f , then \u03b7t/2 < \u03b7\u0303t \u2264 \u03b7t and \u2207 f (xt )(v+t \u2212 v\u2212t ) \u2264 \u2212\u03a6t/(K\u2206t ), and finally the definition of \u03a6t :\nf (xt+1) \u2212 f (x\u2217) = f (xt ) \u2212 f (x\u2217) + f (xt + \u03b7\u0303t (v+t \u2212 v\u2212t )) \u2212 f (xt )\n\u2264 \u03a6t\u22121 + \u03b7\u0303t\u2207 f (xt )(v+t \u2212 v\u2212t ) + \u03b7\u03032t C\n2\n\u2264 \u03a6t\u22121 \u2212 \u03b7t 2 \u00b7 \u03a6t K\u2206t +\n\u03b72t C\n2 = \u03a6t .\nPlugging in the values of \u03b7t and \u2206t to the definition of \u03a6t gives the desired bound.\n\u03a6t = 2\u03a6t\u22121 + \u03b72t C\n2 + \u03b7t K\u2206t\n= \u03a6t\u22121 1 + \u03ba2C/2 1 + \u03baM1/K \u2264 \u03a6t\u22121 1 + B 1 + 2B \u2264 \u03a60\n( 1 + B\n1 + 2B\n) t ."}, {"heading": "3.3 Lazy Local Conditional Gradient", "text": "In this section we provide a lazy version (Algorithm 5) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P \u2286 Rn be any polytope, D denote an upper bound on the \u21132-diameter of P, and \u00b5 \u2265 1 be an affine invariant parameter of P satisfying Lemma 3.4 below, see [Garber and Hazan, 2013, Section 2] for a possible definition. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is \u03b2-smooth if\nf (y) \u2212 f (x) \u2264 \u2207 f (x)(y \u2212 x) + \u03b2\u2016y \u2212 x\u20162/2.\nAlgorithm 5 Lazy Local Conditional Gradient (LLCG)\nInput: feasible polytope P, \u03b2-smooth and S-strongly convex function f , parameters K , S, \u03b2, \u00b5; diameter D Output: points xt\n1: x1 \u2208 P arbitrary and \u03a60 \u2265 f (x1) \u2212 f (x\u2217) 2: \u03b1\u2190 S\n2K\u03b2n\u00b52\n3: for t = 1, . . . ,T do 4: rt \u2190 \u221a 2\u03a6t\u22121 S\n5: \u03a6t \u2190 \u03a6t\u22121+\n\u03b2 2 \u03b1 2 min{n\u00b52r2t ,D2 } 1+\u03b1/K\n6: pt \u2190 LLPsepP (\u2207 f (xt ), xt, rt,\u03a6t,K) 7: if pt = false then 8: xt+1 \u2190 xt 9: else\n10: xt+1 \u2190 xt + \u03b1(pt \u2212 xt ) 11: end if\n12: end for\nAs an intermediary step, we first implement a local weak separation oracle in Algorithm 6, a local version of Oracle 1, which finds improving points only in a small neighbourhood of the original point, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013].\n9\nAlgorithm 6 Weak Local Separation LLPsepP(c, x, r,\u03a6,K) Input: polytope P together with invariant \u00b5, linear objective c \u2208 Rn, point x \u2208 P, radius r > 0, objective\nvalue \u03a6 > 0, accuracy K \u2265 1 Output: Either (1) y \u2208 P with \u2016x \u2212 y\u2016 \u2264 \u221a n\u00b5r and c(x \u2212 y) > \u03a6/K , or (2) false: c(x \u2212 z) \u2264 \u03a6 for all\nz \u2208 P \u2229 Br (x). 1: \u2206\u2190 min {\u221a n\u00b5\nD r, 1\n}\n2: Decompose x: x = \u2211M j=1 \u03bbjvj , \u03bbj > 0, \u2211\nj \u03bbj = 1. 3: Sort vertices: i1, . . . , iM cvi1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 cviM . 4: k \u2190 min{k : \u2211kj=1 \u03bbij \u2265 \u2206} 5: p\u2212 \u2190 \u2211k\u22121 j=1 \u03bbij vij + ( \u2206 \u2212\u2211k\u22121j=1 \u03bbij ) vik 6: v\u2217 \u2190 LPsepP ( c, p\u2212 \u2206 , \u03a6 \u2206 ) 7: if v\u2217 = false then 8: return false\n9: else\n10: return y \u2190 x \u2212 p\u2212 + \u2206v\u2217 11: end if\nLemma 3.4. [Garber and Hazan, 2013, Lemma 7] Let P \u2286 Rn be a polytope and v1, . . . , vN be its vertices. Let x, y \u2208 P and x = \u2211Ni=1 \u03bbivi a convex combination of the vertices of P. Then there are numbers 0 \u2264 \u03b3i \u2264 \u03bbi and z \u2208 P satisfying\nx \u2212 y = \u2211\ni\u2208[N] \u03b3i(z \u2212 vi)\n\u2211\ni\u2208[N] \u03b3i \u2264\n\u221a n\u00b5\nD \u2016x \u2212 y\u2016.\nNow we prove the correctness of the weak local separation algorithm.\nLemma 3.5. Algorithm 6 is correct. In particular LLPsepP(c, x, r,\u03a6,K)\n(i) returns either an y \u2208 P with \u2016x \u2212 y\u2016 \u2264 \u221a n\u00b5r and c(x \u2212 y) \u2265 \u03a6/K ,\n(ii) or returns false, and then c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P \u2229 Br (x).\nProof. We first consider the case when the algorithm exits in Line 10. Observe that y \u2208 P since y is a convex combination of vertices of by construction: y = \u2211M j=1(\u03bbij \u2212 \u03b3j )vij + \u2206v\u2217 with \u2206 = \u2211M j=1 \u03b3j \u2264 \u221a n\u00b5 D r, where \u03b3j = \u03bbij for j < k, and \u03b3k = \u2206 \u2212 \u2211k\u22121 j=1 \u03bbij , and \u03b3j = 0 for j > k. Therefore\n\u2016x \u2212 y\u2016 =\nM\u2211\nj=1\n\u03b3j (vij \u2212 v\u2217) \u2264\nM\u2211\nj=1\n\u03b3j \u2016vij \u2212 v\u2217\u2016 \u2264 \u221a n\u00b5r .\nFinally using the guarantee of LPsepP we get\nc(x \u2212 y) = \u2206c ( p\u2212 \u2206 \u2212 v\u2217 ) \u2265 \u03a6 K .\n10\nIf the algorithm exits in Line 8, we use Lemma 3.4 to decompose any y \u2208 P \u2229 Br (x):\nx \u2212 y = M\u2211\ni=1\n\u03b3i(vi \u2212 z),\nwith z \u2208 P and \u2211Mi=1 \u03b3i \u2264 \u221a n\u00b5 D \u2016x \u2212 y\u2016 \u2264 \u2206. Since \u2211Mi=1 \u03bbi = 1 \u2265 \u2206, there are numbers \u03b3i \u2264 \u03b7\u2212i \u2264 \u03bbi with\u2211M\ni=1 \u03b7 \u2212 i = \u2206. Let\np\u0303\u2212 \u2254 M\u2211\ni=1\n\u03b7\u2212i vi,\np\u0303+ \u2254 y \u2212 x + p\u0303\u2212 = M\u2211\ni=1\n(\u03b7\u2212i \u2212 \u03b3i)vi + M\u2211\ni=1\n\u03b3iz,\nso that p\u0303+/\u2206 \u2208 P. To bound the function value we first observe that the choice of p\u2212 in the algorithm assures that cu \u2264 cp\u2212 for all u = \u2211M i=1 \u03b7ivi with \u2211M i=1 \u03b7i = \u2206 and all 0 \u2264 \u03b7i \u2264 \u03bbi. In particular, cp\u0303\u2212 \u2264 cp\u2212. The function value of the positive part p\u0303+ can be bounded with the guarantee of LPsepP:\nc ( p\u2212 \u2206 \u2212 p\u0303+ \u2206 ) \u2264 \u03a6 \u2206 ,\ni.e., c(p\u2212 \u2212 p\u0303+) \u2264 \u03a6. Finally combining these bounds gives\nc(x \u2212 y) = c (p\u0303\u2212 \u2212 p\u0303+) \u2264 c(p\u2212 \u2212 p\u0303+) \u2264 \u03a6\nas desired.\nWe are ready to examine the Conditional Gradient Algorithm based on LLPsepP:\nTheorem 3.6. Algorithm 5 converges with the following rate:\nf (xt+1) \u2212 f (x\u2217) \u2264 \u03a6t \u2264 \u03a60 ( 1 + \u03b1/(2K)\n1 + \u03b1/K\n) t .\nProof. The proof is similar to the proof of Theorem 3.2. We prove this rate by induction. For t = 0 the choice of \u03a60 guarantees that f (x1) \u2212 f (x\u2217) \u2264 \u03a60. Now assume the theorem holds for t \u2265 0. With strong convexity and the induction hypothesis we get\n\u2016xt \u2212 x\u2217\u20162 \u2264 2\nS ( f (xt ) \u2212 f (x\u2217)) \u2264\n2 S \u03a6t\u22121 = r 2 t ,\ni.e., x\u2217 \u2208 P \u2229 Brt (xt ). In case of a negative call, i.e., when pt = false, then case (ii) of Lemma 3.5 applies:\nf (xt+1) \u2212 f (x\u2217) = f (xt ) \u2212 f (x\u2217) \u2264 \u2207 f (xt )(xt \u2212 x\u2217) \u2264 \u03a6t .\nIn case of a positive call, i.e., when Line 10 is executed, we get the same inequality via:\nf (xt+1) \u2212 f (x\u2217) \u2264 \u03a6t\u22121 + \u03b1\u2207 f (xt )(pt \u2212 xt ) + \u03b2\n2 \u03b12\u2016xt \u2212 pt \u20162\n\u2264 \u03a6t\u22121 \u2212 \u03b1 \u03a6t\nK +\n\u03b2 2 \u03b12 min{n\u00b52r2t ,D2}\n= \u03a6t .\n11\nTherefore using the definition of \u03b1 and rt we get the desired bound:\n\u03a6t \u2264 \u03a6t\u22121 +\n\u03b2 2\u03b1 2r2t n\u00b5 2 1 + \u03b1/K = \u03a6t\u22121 ( 1 + \u03b1/(2K) 1 + \u03b1/K ) \u2264 \u03a60 ( 1 + \u03b1/(2K) 1 + \u03b1/K ) t ."}, {"heading": "4 Parameter-free Conditional Gradient via Weak Separation", "text": "In this section we provide a parameter-free variant of the Lazy Frank-Wolfe Algorithm, which is inspired by Pokutta [2017] and which exhibits a very favorable behavior in computations; the same technique applies to all other variants from Section 3 as well. The idea is that instead of using predetermined values for progress parameters, like \u03a6t and \u03b3t in Algorithm 3, to optimize worst-case progress, the parameters are adjusted adaptively, using data encountered by the algorithm, and avoiding hard-to-estimate parameters, like the curvature C. In practice, this leads to faster convergence, as usual for adaptive methods, while the theoretical convergence rate is worse only by a small constant factor. See Figures 26 and 28 for a comparison and Section 7.1.1 for more experimental results.\nThe occasional halving of the \u03a6t is reminiscent of an adaptive restart strategy, considering successive iterates with the same \u03a6t as an epoch. It ensures that \u03a6t is always at least half of the primal gap, while quickly reducing it if it is too large for the algorithm to make progress, and as such it represents a reasonable amount of expected progress throughout the whole run of the algorithm, not just at the initial iterates.\nAlgorithm 7 Parameter-free Lazy Conditional Gradient (LCG) Input: smooth convex function f , start vertex x1 \u2208 P, weak linear separation oracle LPsepP, accuracy K \u2265 1 Output: points xt in P 1: \u03a60 \u2190 maxx\u2208P \u2207 f (x1)(x1 \u2212 x)/2 {Initial bound} 2: for t = 1 to T \u2212 1 do 3: vt \u2190 LPsepP(\u2207 f (xt ), xt,\u03a6t\u22121,K) 4: if vt = false then\n5: xt+1 \u2190 xt 6: \u03a6t \u2190 \u03a6t\u221212 {Update\u03a6} 7: else 8: \u03b3t \u2190 argmin0\u2264\u03b3\u22641 f ((1 \u2212 \u03b3)xt + \u03b3vt ) {Line search} 9: xt+1 \u2190 (1 \u2212 \u03b3t )xt + \u03b3tvt {Update iterate}\n10: \u03a6t \u2190 \u03a6t\u22121 11: end if\n12: end for\nRemark 4.1 (Additional LP call for initial bound). Note that Algorithm 7 finds a tight initial bound \u03a60 with a single extra LP call. If this is undesired, this can be also done approximately as long as \u03a60 is a valid upper bound, for example by means of binary search via the weak separation oracle.\nTheorem 4.2. Let f be a smooth convex function with curvature C. Algorithm 7 converges at a rate proportional to 1/t. In particular to achieve a bound f (xt ) \u2212 f (x\u2217) \u2264 \u03b5, given an initial upper bound f (x1) \u2212 f (x\u2217) \u2264 2\u03a60, the number of required steps is upper bounded by\nt \u2264 \u2308 log \u03a60\n\u03b5\n\u2309 + 1 + 4K \u2308 log \u03a60\nKC\n\u2309 + 16K2C\n\u03b5 .\n12\nProof. The main idea of the proof is to maintain an approximate upper bound on the optimality gap. We then show that negative calls halve the upper bound 2\u03a6t and positive oracle calls make significant objective function improvement.\nWe analyze iteration t of the algorithm. If Oracle 1 in Line 3 returns a negative answer (i.e., false, case (2)), then this guarantees\u2207 f (xt )(xt\u2212 x) \u2264 \u03a6t\u22121 for all x \u2208 P, in particular, using convexity, f (xt+1)\u2212 f (x\u2217) = f (xt ) \u2212 f (x\u2217) \u2264 \u2207 f (xt )(xt \u2212 x\u2217) \u2264 \u03a6t\u22121 = 2\u03a6t .\nIf Oracle 1 returns a positive answer (case (1)), then we have f (xt ) \u2212 f (xt+1) \u2265 \u03b3t\u03a6t\u22121/K \u2212 (C/2)\u03b32t by smoothness of f . By minimality of \u03b3t , therefore f (xt ) \u2212 f (xt+1) \u2265 min0\u2264\u03b3\u22641(\u03b3\u03a6t\u22121/K \u2212 (C/2)\u03b32), which is \u03a62\nt\u22121/(2CK2) if \u03a6t\u22121 < KC, and \u03a6t\u22121/K \u2212 C/2 \u2265 C 2 if \u03a6t\u22121 \u2265 KC.\nNow we bound the number t \u2032 of consecutive positive oracle calls immediately following an iteration t with a negative oracle call. Note that the same argument bounds the number of initial consecutive positive oracle calls with the choice t = 0, as we only use f (xt+1) \u2212 f (x\u2217) \u2264 2\u03a6t below.\nNote that \u03a6t = \u03a6t+1 = \u00b7 \u00b7 \u00b7 = \u03a6t+t\u2032. Therefore\n2\u03a6t \u2265 f (xt+1) \u2212 f (x\u2217) \u2265 t+t\u2032\u2211\n\u03c4=t+1 ( f (x\u03c4) \u2212 f (x\u03c4+1)) \u2265   t \u2032 \u03a6 2 t 2CK2 if \u03a6t < KC t \u2032 ( \u03a6t K \u2212 C2 ) if \u03a6t \u2265 KC ,\nwhich gives in the case \u03a6t < KC that t \u2032 \u2264 4CK2/\u03a6t , and in the case \u03a6t \u2265 KC that\nt \u2032 \u2264 2\u03a6t \u03a6t\nK \u2212 C2\n= 4K\u03a6t 2\u03a6t \u2212 KC \u2264 4K\u03a6t 2\u03a6t \u2212\u03a6t = 4K .\nThus iteration t is followed by at most 4K consecutive positive oracle calls as long as \u03a6t \u2265 KC, and 4CK2/\u03a6t < 2\u2113+1 \u00b7 4K ones for 2\u2212\u2113\u22121KC < \u03a6t \u2264 2\u2212\u2113KC with \u2113 \u2265 0.\nAdding up the number of oracle calls gives the desired rate: in addition to the positive oracle calls we also have at most \u2308log(\u03a60/\u03b5)\u2309 + 1 negative oracle calls, where log(\u00b7) is the binary logarithm and \u03b5 is the (additive) accuracy. Thus after a total of\n\u2308 log \u03a60\n\u03b5\n\u2309 + 1 + 4K \u2308 log \u03a60\nKC\n\u2309 + \u2308log(KC/\u03b5)\u2309\u2211\n\u2113=0\n2\u2113+1 \u00b7 4K \u2264 \u2308 log \u03a60\n\u03b5\n\u2309 + 1 + 4K \u2308 log \u03a60\nKC\n\u2309 + 16K2C\n\u03b5\niterations (or equivalently oracle calls) we have f (xt ) \u2212 f (x\u2217) \u2264 \u03b5.\nAs seen from the proof, the algorithm receives few negative oracle calls by design; these are usually more expensive than positive ones as the oracle has to compute a certificate by, e.g., executing a full linear optimization oracle call.\nCorollary 4.3. Algorithm 7 receives at most \u2308log\u03a60/\u03b5\u2309 + 1 negative oracle answers.\nRemark 4.4 (Improved use of Linear Optimization oracle). A possible improvement to Line 6 is \u03a6t \u2190 maxx\u2208P \u2207 f (xt )(xt\u2212x)/2, assuming that at a negative call the oracle also provides the dual gap maxx\u2208P \u2207 f (xt )(xt\u2212 x) as well as the minimizer x\u0304 \u2208 P of the oracle call. This is the case e.g., when the weak separation oracle is implemented as in Algorithm 2. Clearly, the minimizer x\u0304 can be also used to perform a progress step; albeit without guarantee w.r.t. to \u03a6t .\nRemark 4.5 (Line Search). If line search is too expensive we can choose \u03b3t = min{1,\u03a6t/KC} in Algorithm 7. In this case an estimate of the curvature C is required.\n13"}, {"heading": "5 Lazy Online Conditional Gradient", "text": "In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x \u2208 Rn | Ax \u2264 b}, resulting in Algorithm 8. We slightly improve constant factors by replacing [Hazan and Kale, 2012, Lemma 3.1] with a better estimation via solving a quadratic inequality arising from strong convexity. In this section the norm \u2016\u00b7\u2016 can be arbitrary.\nAlgorithm 8 Lazy Online Conditional Gradient (LOCG) Input: functions ft , start vertex x1 \u2208 P, weak linear separation oracle LPsepP, parameters K , C, b, S, s; diameter D Output: points xt 1: for t = 1 to T \u2212 1 do 2: \u2207t \u2190 \u2207 ft (xt ) 3: if t = 1 then 4: h1 \u2190 min{\u2016\u22071\u2016\u2217 D, 2 \u2016\u22071\u2016\u22172 /S} 5: else\n6: ht \u2190 \u03a6t\u22121 +min { \u2016\u2207t \u2016\u2217 D, \u2016\u2207t \u2016 \u22172\nSt1\u2212s + 2 \u221a \u2016\u2207t \u2016\u22172 2St1\u2212s ( \u2016\u2207t \u2016\u22172 2St1\u2212s + \u03a6t\u22121 )}\n7: end if\n8: \u03a6t \u2190 ht+\nCt1\u2212b\u03b32t 2(1\u2212b) 1+ \u03b3t K\n9: vt \u2190 LPsepP( \u2211t\ni=1 \u2207 fi(xt ), xt,\u03a6t,K) 10: if vt = false then 11: xt+1 \u2190 xt 12: else 13: xt+1 \u2190 (1 \u2212 \u03b3t )xt + \u03b3tvt 14: \u03a6t \u2190 ht \u2212 \u2211t i=1 fi(xt ) + \u2211t i=1 fi(xt+1) 15: end if\n16: end for\nTheorem 5.1. Let 0 \u2264 b, s < 1. Let K \u2265 1 be an accuracy parameter. Assume ft is L-Lipschitz, and smooth with curvature at most Ct\u2212b. Let D \u2254 maxy1,y2\u2208P \u2016y1 \u2212 y2\u2016 denote the diameter of P in norm \u2016\u00b7\u2016. Then the following hold for the points xt computed by Algorithm 8 where x \u2217 T is the minimizer of \u2211T t=1 ft :\n(i) With the choice\n\u03b3t = t \u2212(1\u2212b)/2,\nthe xt satisfy\n1\nT\nT\u2211\nt=1\n( ft (xT ) \u2212 ft (x\u2217T )) \u2264 AT\u2212(1\u2212b)/2,\nwhere\nA \u2254 CK\n2(1 \u2212 b) + L(K + 1)D.\n(ii) Moreover, if all the ft are St \u2212s-strongly convex, then with the choice\n\u03b3t = t (b+s\u22122)/3,\n14\nthe xt satisfy\n1\nT\nT\u2211\nt=1\n( ft (xT ) \u2212 ft (x\u2217T )) \u2264 AT\u2212(2(1+b)\u2212s)/3, (3)\nwhere\nA \u2254 2 ( (K + 1)(K + 2) L 2\nS +\nCK\n2(1 \u2212 b)\n) .\nProof. We prove only Claim (ii), as the proof of Claim (i) is similar and simpler. Let FT \u2254 \u2211T t=1 ft . Furthermore, let hT \u2254 AT1\u2212(2(1+b)\u2212s)/3 be T times the right-hand side of Equation (3). In particular, FT is ST -strongly convex, and smooth with curvature at most CFT where\nCFT \u2254 CT1\u2212b 1 \u2212 b \u2265 C T\u2211\nt=1\nt\u2212b, ST \u2254 ST 1\u2212s \u2264 S\nT\u2211\nt=1\nt\u2212s .\nWe prove Ft (xt ) \u2212 Ft (x\u2217t ) \u2264 ht \u2264 ht by induction on t. The case t = 1 is clear. Let \u03a6t denote the value of \u03a6t in Line 8, while we reserve\u03a6t to denote its value as used in Line 6. We start by showing Ft (xt+1) \u2212 Ft (x\u2217t ) \u2264 \u03a6t \u2264 \u03a6t . We distinguish two cases depending on the oracle answer vt from Line 9. For a negative oracle answer (vt = false), we have \u03a6t = \u03a6t and the weak separation oracle asserts maxy\u2208P \u2207Ft (xt )(xt \u2212 y) \u2264 \u03a6t , which combined with the convexity of Ft provides\nFt (xt+1) \u2212 Ft (x\u2217t ) = Ft (xt ) \u2212 Ft (x\u2217t ) \u2264 \u2207Ft (xt )(xt \u2212 xt\u2217) \u2264 \u03a6t = \u03a6t .\nOtherwise, for a positive oracle answer, Line 14 and the induction hypothesis provides Ft (xt+1) \u2212 Ft (x\u2217t ) \u2264 ht + Ft (xt+1) \u2212 Ft (xt ) = \u03a6t . To prove \u03a6t \u2264 \u03a6t , we apply the smoothness of Ft followed by the inequality provided by the choice of vt :\nFt (xt+1) \u2212 Ft (xt ) \u2212 CFt \u03b3\n2 t\n2 \u2264 \u2207Ft (xt )(xt+1 \u2212 xt ) = \u03b3t\u2207Ft (xt )(vt \u2212 xt ) \u2264 \u2212\n\u03b3t\u03a6t\nK .\nRearranging provides the inequality:\n\u03a6t = ht + Ft (xt+1) \u2212 Ft (xt ) \u2264 ht \u2212 \u03b3t\u03a6t\nK +\nCFt \u03b3 2 t\n2 = \u03a6t .\nFor later use, we bound the difference between ht and \u03a6t using the value of parameters, ht \u2264 ht , and \u03b3t \u2264 1:\nht \u2212\u03a6t \u2265 ht \u2212 ht +\nCFt \u03b3 2 t\n2\n1 + \u03b3t K\n=\nht\u03b3t K \u2212 CFt \u03b3\n2 t\n2\n1 + \u03b3t K\n\u2265 ht\u03b3t K \u2212 CFt \u03b3\n2 t\n2\n1 + 1 K\n= A \u2212 CK2(1\u2212b) K + 1 t[2s\u2212(1+b)]/3.\nWe now apply Ft (xt+1) \u2212 Ft (x\u2217t ) \u2264 \u03a6t , together with convexity of ft+1, and the minimality Ft (x\u2217t ) \u2264 Ft (x\u2217t+1) of x\u2217t , followed by strong convexity of Ft+1:\nFt+1(xt+1) \u2212 Ft+1(x\u2217t+1) \u2264 (Ft (xt+1) \u2212 Ft (x \u2217 t )) + ( ft+1(xt+1) \u2212 ft+1(x\u2217t+1))\n\u2264 \u03a6t + \u2016\u2207t+1\u2016\u2217 \u00b7 \u2016xt+1 \u2212 x\u2217t+1\u2016 \u2264 \u03a6t + \u2016\u2207t+1\u2016\u2217 \u221a 2\nSt+1 (Ft+1(xt+1) \u2212 Ft+1(x\u2217t+1)).\n(4)\n15\nSolving the quadratic inequality provides\nFt+1(xt+1) \u2212 Ft+1(x\u2217t+1) \u2264 \u03a6t + \u2016\u2207t+1\u2016\u22172\nSt+1 + 2\n\u221a\u221a \u2016\u2207t+1\u2016\u22172\n2St+1\n( \u2016\u2207t+1\u2016\u22172\n2St+1 +\u03a6t\n) . (5)\nFrom Equation (4), ignoring the last line, we also obtain Ft+1(xt+1) \u2212 Ft+1(x\u2217t+1) \u2264 \u03a6t + \u2016\u2207t+1\u2016 \u2217\nD via the estimate \u2016xt+1 \u2212 x\u2217t+1\u2016 \u2264 D. Thus Ft+1(xt+1) \u2212 Ft+1(x \u2217 t+1) \u2264 ht+1, by Line 6, as claimed.\nNow we estimate the right-hand side of Equation (5) by using the actual value of the parameters, the estimate \u2016\u2207t+1\u2016\u2217 \u2264 L, and the inequality s+ b \u2264 2. In fact, we estimate a proxy for the right-hand side. Note that A was chosen to satisfy the second inequality:\nL2\nSt+1 + 2\n\u221a L2\n2St+1 ht \u2264\nL2\nSt1\u2212s + 2\n\u221a L2\n2St1\u2212s ht \u2264\nL2\nS t[2s\u2212(1+b)]/3 + 2\n\u221a L2\n2St1\u2212s ht\n=\n( L2\nS +\n\u221a 2 L2\nS A\n) t[2s\u2212(1+b)]/3 \u2264\nA \u2212 CK2(1\u2212b) K + 1 t[2s\u2212(1+b)]/3\n\u2264 ht \u2212\u03a6t \u2264 ht \u2212\u03a6t .\nIn particular, L 2\n2St+1 + \u03a6t \u2264 ht hence combining with Equation (5) we obtain\nht+1 \u2264 \u03a6t + L2\nSt+1 + 2\n\u221a L2\n2St+1\n( L2\n2St+1 + \u03a6t\n)\n\u2264 \u03a6t + L2\nSt+1 + 2\n\u221a L2\n2St+1 ht\n\u2264 ht \u2264 ht+1."}, {"heading": "5.1 Stochastic and Adversarial Versions", "text": "Complementing the offline algorithms from Section 3, we will now derive various online versions. The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.\nFor stochastic cost functions ft , we obtain bounds from Theorem 5.1 (i) similar to [Hazan and Kale, 2012, Theorems 4.1 and 4.3] (with \u03b4 replaced by \u03b4/T in the bound to correct an inaccuracy in the original argument). The proof is analogous and hence omitted, but note that \u2016y1 \u2212 y2\u20162 \u2264 \u221a \u2016y1 \u2212 y2\u20161\u2016y1 \u2212 y2\u2016\u221e \u2264 \u221a k for all y1, y2 \u2208 P.\nCorollary 5.2. Let ft be convex functions sampled i.i.d. with expectation E [ ft ] = f \u2217, and \u03b4 > 0. Assume that the ft are L-Lipschitz in the 2-norm.\n(i) If all the ft are smooth with curvature at most C, then Algorithm 8 applied to the ft (with b = 0) yields with probability 1 \u2212 \u03b4\nT\u2211\nt=1\nf \u2217(xt ) \u2212min x\u2208P\nT\u2211\nt=1\nf \u2217(x) \u2264 O ( C \u221a T + Lk \u221a nT log(nT2/\u03b4) logT ) .\n16\n(ii) Without any smoothness assumption, Algorithm 8 (applied to smoothenings of the ft ) provides with\nprobability 1 \u2212 \u03b4\nT\u2211\nt=1\nf \u2217(xt ) \u2212min x\u2208P\nT\u2211\nt=1\nf \u2217(x) \u2264 O (\u221a nLkT2/3 + Lk \u221a nT log(nT2/\u03b4) logT ) .\nSimilar to [Hazan and Kale, 2012, Theorem 4.4], from Theorem 5.1 (ii) we obtain the following regret bound for adversarial cost functions with an analogous proof.\nCorollary 5.3. For any L-Lipschitz convex cost functions ft , Algorithm 8 applied to the functions f\u0303t (x) \u2254 \u2207 ft (xt )x + 2L\u221a\nk t\u22121/4\u2016x \u2212 x1\u201622 (with b = s = 1/4, C = L\n\u221a k, S = L/ \u221a k, and Lipschitz constant 3L) achieving\nregret T\u2211\nt=1\nft (xt ) \u2212min x\u2208P\nT\u2211\nt=1\nft (x) \u2264 O(L \u221a kT3/4)\nwith at most T calls to the weak separation oracle.\nNote that the gradient of the f\u0303t are easily computed via the formula\u2207 f\u0303t (x) = \u2207 ft (xt )+4Lt\u22121/4(x\u2212x1)/ \u221a\nk , particularly because the gradient of the ft need not be recomputed, so that we obtain a weak separation-based stochastic gradient descent algorithm, where we only have access to the ft through a stochastic gradient oracle, while retaining all the favorable properties of the Frank-Wolfe algorithm with a convergence rate O(T\u22121/4) (c.f., Garber and Hazan [2013])."}, {"heading": "6 Weak Separation through Augmentation", "text": "So far we realized the weak separation oracle via lazy optimization. We will now create a (weak) separation oracle for integral polytopes, employing an even weaker, so-called augmentation oracle, which only provides an improving solution but provides no guarantee with respect to optimality. We call this approach lazy augmentation. This is especially useful when a fast augmentation oracle is available or the vertices of the underlying polytope P are particularly sparse, i.e., \u2016y1 \u2212 y2\u20161 \u2264 k \u226a n for all y1, y2 \u2208 P, where n is the ambient dimension of P. As before theoretical convergence rates are maintained.\nFor simplicity of exposition we restrict to 0/1 polytopes P here. For general integral polytopes, one considers a so-called directed augmentation oracle, which can be similarly linearized after splitting variables in positive and negative parts; we refer the interested reader to see [Schulz and Weismantel, 2002, Bodic et al., 2015] for an in-depth discussion.\nLet k denote the \u21131-diameter of P. Upon presentation with a 0/1 solution x and a linear objective c \u2208 Rn, an augmentation oracle either provides an improving 0/1 solution x\u0304 with cx\u0304 < cx or asserts optimality for c:\nOracle 2 Linear Augmentation Oracle AUGP(c, x) Input: linear objective c \u2208 Rn, vertex x \u2208 P Output: vertex x\u0304 \u2208 P with cx\u0304 < cx when exists, otherwise x\u0304 = x\nSuch an oracle is significantly weaker than a linear optimization oracle but also significantly easier to implement and much faster; we refer the interested reader to [Gr\u00f6tschel and Lov\u00e1sz, 1993, Schulz et al., 1995, Schulz and Weismantel, 2002] for an extensive list of examples. While augmentation and optimization are\n17\npolynomially equivalent (even for convex integer programming [Oertel et al., 2014]) the current best linear optimization algorithms based on an augmentation oracle are slow for general objectives. While optimizing an integral objective c \u2208 Rn needs O(k log\u2016c\u2016\u221e) calls to an augmentation oracle (see [Schulz et al., 1995, Schulz and Weismantel, 2002, Bodic et al., 2015]), a general objective function, such as the gradient in Frank\u2013Wolfe algorithms has only an O(kn3) guarantee in terms of required oracle calls (e.g., via simultaneous diophantine approximations [Frank and Tardos, 1987]), which is not desirable for large n. In contrast, here we use an augmentation oracle to perform separation, without finding the optimal solution. Allowing a multiplicative error K > 1, we realize an augmentation-based weak separation oracle (see Algorithm 9), which decides given a linear objective function c \u2208 Rn, an objective value \u03a6 > 0, and a starting point x \u2208 P, whether there is a y \u2208 P with c(x \u2212 y) > \u03a6/K or c(x \u2212 y) \u2264 \u03a6 for all y \u2208 P. In the former case, it actually provides a certifying y \u2208 P, i.e., with c(x \u2212 y) > \u03a6/K . Note that a constant accuracy K requires a linear number of oracle calls in the diameter k, e.g., K = (1 \u2212 1/e)\u22121 \u2248 1.582 needs at most N \u2264 k oracle calls, which can be much smaller than the ambient dimension of the polytope.\nAt the beginning, in Line 2, the algorithm has to replace the input point x with an integral point x0. If the point x is given as a convex combination of integral points, then a possible solution is to evaluate the objective c on these integral points, and choose x0 the first one with cx0 \u2264 cx. This can be easily arranged for Frank\u2013Wolfe algorithms as they maintain convex combinations.\nAlgorithm 9 Augmenting Weak Separation LPsepP(c, x,\u03a6,K) Input: linear objective c \u2208 Rn, point x \u2208 P, objective value \u03a6 > 0; accuracy K > 1 Output: Either (1) y \u2208 P vertex with c(x \u2212 y) > \u03a6/K , or (2) false: c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P.\n1: N \u2190 \u2308log(1 \u2212 1/K)/log(1 \u2212 1/k)\u2309 2: Choose x0 \u2208 P vertex with cx0 \u2264 cx. 3: for i = 1 to N do 4: if c(x \u2212 xi\u22121) \u2265 \u03a6 then 5: return xi\u22121 6: end if 7: xi \u2190 AUGP(c + \u03a6\u2212c(x\u2212xi\u22121)k (1 \u2212 2xi\u22121), xi\u22121) 8: if xi = xi\u22121 then 9: return false\n10: end if\n11: end for\n12: return xN\nProposition 6.1. Assume \u2016y1 \u2212 y2\u20161 \u2264 k for all y1, y2 \u2208 P. Then Algorithm 9 is correct, i.e., it outputs either (1) y \u2208 P with c(x \u2212 y) > \u03a6/K , or (2) false. In the latter case c(x \u2212 y) \u2264 \u03a6 for all y \u2208 P holds. The algorithm calls AUGP at most N \u2264 \u2308log(1 \u2212 1/K)/log(1 \u2212 1/k)\u2309 many times.\nProof. First note that (1 \u2212 2x)v + \u2016x\u20161 = \u2016v \u2212 x\u20161 for x, v \u2208 {0, 1}n, hence Line 7 is equivalent to xi \u2190 AUGP(c + \u03a6\u2212c(x\u2212xi\u22121)k \u2016\u00b7 \u2212 xi\u22121\u20161, xi\u22121).\nThe algorithm obviously calls the oracle at most N times by design, and always returns a value, so we need to verify only the correctness of the returned value. We distinguish cases according to the output.\nClearly, Line 5 always returns an xi\u22121 with c(x \u2212 xi\u22121) \u2265 \u03a6 > [1 \u2212 (1 \u2212 1/k)N ]\u03a6. When Line 9 is executed, the augmentation oracle just returned xi = xi\u22121, i.e., for all y \u2208 P\ncxi\u22121 \u2264 cy + \u03a6 \u2212 c(x \u2212 xi\u22121)\nk \u2016y \u2212 xi\u22121\u20161 \u2264 cy + \u03a6 \u2212 c(x \u2212 xi\u22121) k k = c(y \u2212 x) + cxi\u22121 +\u03a6,\n18\nso that c(x \u2212 y) \u2264 \u03a6, as claimed. Finally, when Line 12 is executed, the augmentation oracle has found an improving vertex xi at every iteration, i.e.,\ncxi\u22121 > cxi + \u03a6 \u2212 c(x \u2212 xi\u22121)\nk \u2016xi \u2212 xi\u22121\u20161 \u2265 cxi + \u03a6 \u2212 c(x \u2212 xi\u22121) k ,\nusing \u2016xi \u2212 xi\u22121\u20161 \u2265 1 by integrality. Rearranging provides the convenient form\n\u03a6 \u2212 c(x \u2212 xi) < ( 1 \u2212 1\nk\n) [\u03a6 \u2212 c(x \u2212 xi\u22121)],\nwhich by an easy induction provides\n\u03a6 \u2212 c(x \u2212 xN ) < ( 1 \u2212 1\nk\n)N [\u03a6 \u2212 c(x \u2212 x0)] \u2264 ( 1 \u2212 1\nK\n) \u03a6,\ni.e., c(x \u2212 xN ) \u2265 \u03a6K , finishing the proof."}, {"heading": "7 Experiments", "text": "We implemented and compared the parameter-free variant of LCG (Algorithm 7) to the standard FrankWolfe algorithm (CG), then Algorithm 4 (LPCG) to the Pairwise Conditional Gradient algorithm (PCG) of Garber and Meshi [2016], as well as Algorithm 8 (LOCG) to the Online Frank-Wolfe algorithm (OCG) of Hazan and Kale [2012]. While we did implement the Local Conditional Gradient algorithm ofGarber and Hazan [2013] as well, the very large constants in the original algorithms made it impractical to run. Unless stated otherwise the weak separation oracle is implemented as sketched in Algorithm 2 through caching and early termination of the original LP oracle.\nWe have used K = 1.1 and K = 1 as multiplicative factors for the weak separation oracle; for the impact of the choice of K see Section 7.2.2. For the baseline algorithms we use inexact variants, i.e., we solve linear optimization problems only approximately. This is a significant speedup in favor of non-lazy algorithms at the (potential) cost of accuracy, while neutral to lazy optimization as it solves an even more relaxed problem anyways. To put things in perspective, the non-lazy baselines could not complete even a single iteration for a significant fraction of the considered problems in the given time frame if we were to exactly solve the linear optimization problems. In terms of using line search, for all tests we treated all algorithms equally: either all or none used line search. If not stated otherwise, we used (simple backtracking) line search.\nThe linear optimization oracle over P \u00d7 P for LPCG was implemented by calling the respective oracle over P twice: once for either component. Contrary to the non-lazy version, the lazy algorithms depend on the initial upper bound \u03a60. For the instances that need a very long time to solve the (approximate) linear optimization even once, we used a binary search for \u03a60 for the lazy algorithms: starting from a conservative initial value, using the update rule \u03a60 \u2190 \u03a60/2 until the separation oracle returns an improvement for the first time and then we start the algorithm with 2\u03a60, which is an upper bound on the Wolfe gap and hence also on the primal gap. This initial phase is also included in the reported wall-clock time. Alternatively, if the linear optimization was less time consuming we used a single (approximate) linear optimization at the start to obtain an initial bound on \u03a60 (see e.g., Section 4).\nIn some cases, especially when the underlying feasible region has a high dimension and the (approximate) linear optimization can be solved relatively fast compared to the cost of computing an inner product, we observed that the costs of maintaining the cache was very high. In these cases we reduced the cache size\n19\nevery 100 steps by keeping only the 100 points that were used the most so far. Both the number of steps and the approximate size of the cache were chosen arbitrarily, however 100 for both worked very well for all our examples. Of course there are many different strategies for maintaining the cache, which could be used here and which could lead to further improvements in performance.\nThe stopping criteria for each of the experiments was a given wall clock time limit in seconds. The time limit was enforced separately for the main code and the oracle code, so in some cases the actual time used can be larger, when the last oracle call started before the time limit was reached and took longer than the time left.\nWe implemented all algorithms in Python 2.7 with critical functions cythonized for performance employing Numpy. We used these packages from the Anaconda 4.2.0 distribution as well as Gurobi 7.0 [Gurobi Optimization, 2016] as a black box solver for the linear optimization oracle. The weak separation oracle was implemented via a callback function to stop linear optimization as soon as a good enough feasible solution has been found in a schema as outlined in Algorithm 2. The parameters for Gurobi were kept at their default settings except for enforcing the time limit of the tests and setting the acceptable duality gap to 10%, allowing Gurobi to terminate the linear optimization early avoiding the expensive proof of optimality. This is used to realize the inexact versions of the baseline algorithms. All experiments were performed on a 16-core machine with Intel Xeon E5-2630 v3 @ 2.40GHz CPUs and 128GB of main memory. While our code does not explicitly use multiple threads, both Gurobi and the numerical libraries use multiple threads internally."}, {"heading": "7.1 Computational results", "text": "We performed computational tests on a large variety of different problems that are instances of the three machine learning tasks video colocalization, matrix completion, and structured regression.\nVideo colocalization. Video colocalization is the problem of identifying objects in a sequence of multiple frames in a video. In Joulin et al. [2014] it is shown that video colocalization can be reduced to optimizing a quadratic objective function over a flow or a path polytope, which is the problem we are going to solve. The resulting linear program is an instance of the minimum-cost network flow problem, see [Joulin et al., 2014, Eq. (3)] for the concrete linear program and more details. The quadratic functions are of the form \u2016Ax \u2212 b\u20162 where we choose the non-zero entries in A according to a density parameter at random and then each of these entries to be [0, 1]-uniformly distributed, while b is chosen as a linear combination of the columns of A with random multipliers from [0, 1]. For some of the instances we also use \u2016x \u2212 b\u20162 as the objective function with bi \u2208 [0, 1] uniformly at random.\nMatrix completion. The formulationof the matrix completion problem we are going to use is the following:\nmin X\n\u2211\n(i, j)\u2208\u2126 |Xi, j \u2212 Ai, j |2 s.t. \u2016X \u2016\u2217 \u2264 R, (6)\nwhere \u2016\u00b7\u2016\u2217 denotes the nuclear norm, i.e., \u2016A\u2016\u2217 = Tr( \u221a\nAt A). The set \u2126, the matrix A and R are given parameters. Similarly to Lan and Zhou [2014] we generate the m \u00d7 n matrix A as the product of AL of size m \u00d7 r and AR of size r \u00d7 n. The entries in AL and AR are chosen from a standard Gaussian distribution. The set \u2126 is chosen uniformly of size s = min{5r(m + n \u2212 r), \u23080.99mn\u2309}. The linear optimization oracle is implemented in this case by a singular value decomposition of the linear objective function and we essentially solve the LP to (approximate) optimality. The matrix completion tests will only demonstrate the impact of\n20\ncaching solutions. Note that this test is also informative as due to the \u2018roundness\u2019 of the feasible region the solution of the actual LP oracle will induce a direction that is equal to the true gradient and as such it provides insight into how much per-iteration progress is lost due to working with gradient approximations from the weak separation oracle.\nStructured regression. The structured regression problem consists of solving a quadratic function of the form \u2016Ax \u2212 b\u20162 over some structured feasible set or a polytope P, i.e., we solve minx\u2208P \u2016Ax \u2212 b\u20162. We construct the objective functions in the same way as for the video colocalization problem.\nTests. In the following two sections we will present our results for various problems grouped by the versions of the considered algorithms. Every figure contains two columns, each containing one experiment. We use different measures to report performance: we report progress of loss or function value in wall-clock time in the first row (including time spent by the oracle), in the number of iterations in the second row, and in the number of linear optimization calls in the last row. Obviously, the latter only makes sense for the lazy algorithms. In some other cases we report in another row the dual bound or Wolfe gap in wall-clock time. The red line denotes the non-lazy algorithm and the green line denotes the lazy variants. For each experiment we also report the cache hit rate, which is the number of oracle calls answered with a point from the cache over all oracle calls given in percent.\nWhile we found convergence rates in the number of iterations quite similar (as expected!), we consistently observe a significant speedup in wall-clock time. In particular for many large-scale or hard combinatorial problems, lazy algorithms performed several thousand iterations whereas the non-lazy versions completed only a handful of iterations due to the large time spent approximately solving the linear optimization problem. The observed cache hit rate was at least 90% in most cases, and often even above 99%."}, {"heading": "7.1.1 Offline Results", "text": "We describe the considered instances in the offline case separately for the vanilla Frank-Wolfe method and the Pairwise Conditional Gradient method.\nVanilla Frank-Wolfe Method We tested the vanilla Frank-Wolfe algorithm on the six video colocalization instances with underlying path polytopes from http://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ (Figures 1, 2 and 3). In these instances we additionally report the dual bound or Wolfe gap in wall clock time. We further tested the vanilla Frank-Wolfe algorithm on eight instances of the matrix completion problem generated as described above, for which we did not use line search; the parameter-free lazy variant is run with approximate minimization as described in Remark 4.5, the others use their respective standard step sizes. We provide the used parameters for each example in the figures below (Figures 4, 5, 6 and 7). The last tests for this version were performed on three instances of the structured regression problem, two with the feasible region containing flow-based formulations of Hamiltonian cycles in graphs (Figure 8), and further tests on two cut polytope instances (Figure 9) and on two spanning tree instances of different size (Figure 10).\nWe observed a significant speedup of LCG compared to CG, due to the faster iteration of the lazy algorithm.\nPairwise Conditional Gradient Algorithm As we inherit structural restrictions of PCG on the feasible region, the problem repertoire is limited in this case. We tested the Pairwise Conditional Gradient algorithm on the structured regression problem with feasible regions from the MIPLIB instances eil33-2, air04, eilB101, nw04, disctom, m100n500k4r1 (Figures 11, 12 and 13).\n21\nAgain similarly to the vanilla Frank-Wolfe algorihtm, we observed a significant improvement in wall-clock time of LPCG compared to CG, due to the faster iteration of the lazy algorithm."}, {"heading": "7.1.2 Online Results", "text": "Additionally to the quadratic objective functions above we tested the online version on random linear functions cx + b with c \u2208 [\u22121,+1]n and b \u2208 [0, 1]. For online algorithms, each experiment used a random sequence of 100 different random loss functions. In every figure the left column uses linear loss functions, while the right one uses quadratic loss functions over the same polytope. As customary, we did not use line search here but used the respective prescribed step sizes.\nAs an instance of the structured regression problem we used the flow-based formulation for Hamiltonian cycles in graphs, i.e., the traveling salesman problem (TSP) for graphs with 11 and 16 nodes (Figures 14 and 15). For these small instances, the oracle problem can be solved in reasonable time. Another instance of the structured regression problem uses the standard formulation of the cut polytope for graphs with 23 and 28 nodes as the feasible region (Figures 16 and 17). We also tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.watson.ibm.com/researcher/files/us-sanjeebd/chimera-data.zip. The instances are relatively hard albeit their rather small size and in general the problem is NP-hard. (Figure 18 and 19).\nOne instance of the video colocalization problem uses a path polytope fromhttp://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ that was generated with the netgen graph generator (Figure 20). Most of these instances are very large-scale minimum cost flow instances with several tens of thousands nodes in the underlying graphs, therefore solving still takes considerable time despite the problem being in P. We tested on the structured regression problems with the MIPLIB [Achterberg et al., 2006, Koch et al., 2011]) instances eil33-2 (Figure 21) and air04 (Figure 22) as feasible regions. Finally, for the spanning tree problem, we used the well-known extended formulation with O(n3) inequalities for an n-node graph. We considered graphs with 10 and 25 nodes (Figures 23 and 24).\nWe observed that similarly to the offline case while OCG and LOCG converge comparably in the number of iterations, the lazy LOCG performed significantly more iterations; for hard problems, where linear optimization is costly and convergence requires a large number of iterations, this led LOCG converging much faster in wall-clock time. In extreme cases OCG could not complete even a single iteration. This is due to LOCG only requiring some good enough solution, whereas OCG requires a stronger guarantee. This is reflected in faster oracle calls for LOCG."}, {"heading": "7.2 Performance improvements, parameter sensitivity, and tuning", "text": ""}, {"heading": "7.2.1 Effect of caching", "text": "As mentioned before, lazy algorithms have two improvements: caching and early termination. Here we depict the effect of caching in Figure 25, comparing OCG (no caching, no early termination), LOCG (caching and early termination) and LOCG (only early termination) (see Algorithm 8). We did not include a caching-only OCG variant, because caching without early termination does not make much sense: in each iteration a new linear optimization problem has to be solved; previous solutions can hardly be reused as they are unlikely to be optimal for the new linear optimization problem.\n22"}, {"heading": "7.2.2 Effect of K", "text": "If the parameter K of the oracle can be chosen, which depends on the actual oracle implementation, then we can increase K to bias the algorithm towards performing more positive calls. At the same time the steps get shorter. As such there is a natural trade-off between the cost of many positive calls vs. a negative call. We depict the impact of the parameter choice for K in Figure 30."}, {"heading": "7.2.3 Paramter-free vs. textbook variant", "text": "For illustrative purposes, we compare the textbook variant of the lazy conditional gradient (Algorithm 3) with its parameter-free counterpart (Algorithm 7) in Figure 31. The parameter-free variant outperforms the textbook variant due to the active management of \u03a6 combined with line search.\nSimilar parameter-free variants can be derived for the other algorithms; see discussion in Section 4."}, {"heading": "8 Final Remarks", "text": "If a given baseline algorithm works over general compact convex sets P, then so does the lazified version. In fact, as the lazified algorithm runs, it produces a polyhedral approximation of the set P with very few vertices (subject to optimality vs. sparsity tradeoffs; see [Jaggi, 2013, Appendix C]).\nMoreover, the weak separation oracle does not need to return extreme points. All algorithms also work with maximal solutions that are not necessarily extremal (e.g., lying in a higher-dimensional face). However, in that case we lose the desirable property that the final solution is a sparse convex combination of extreme points (typically vertices in the polyhedral setup).\nWe would also like to briefly address potential downsides of our approach. In fact, we believe the right perspective is the following: when using the lazy oracle over the LP oracle, we obtain potentially weaker approximations vt \u2212 xt of the true gradient \u2207 f (xt ) compared to solving the actual LP, but the computation might be much faster. This is the tradeoff that one has to consider: working with weaker approximations (which implies potentially less progress per iteration) vs. potentially significantly faster computation of the approximations. If solving the LP is expensive than lazification will be usually very beneficial, if the LP is very cheap as in the case of P = [0, 1]n or P = \u2206n being the probability simplex, then lazification might be slower.\nA related remark in this context is that once the lazified algorithm has obtained vertices x1, . . . , xm of P, so that the minimizer x\u2217 of f satisfies x\u2217 \u2208 conv{x1, . . . , xm}, then from that point onwards no actual calls to the true LP oracle have to be performed anymore for primal progress and the algorithm will only use cache calls; the only remaining true LP calls are at most a logarithmic number for dual progress updates of the \u03a6t ."}, {"heading": "Acknowledgements", "text": "We are indebted to Alexandre D\u2019Aspremont,Simon Lacoste-Julien, and George Lan for the helpful discussions and for providing us with relevant references. Research reported in this paper was partially supported by NSF CAREER award CMMI-1452463.\n23"}], "year": 2018, "references": [{"title": "Operations Research Letters, 34(4):361\u2013372, 2006", "authors": ["T. Achterberg", "T. Koch", "A. Martin. MIPLIB"], "venue": "doi: 10.1016/j.orl.2005.07.009. URL http://www.zib.de/Publications/abstracts/ZR-05-28/.", "year": 2003}, {"title": "Regret in online combinatorial optimization", "authors": ["J.-Y. Audibert", "S. Bubeck", "G. Lugosi"], "venue": "Mathematics of Operations Research,", "year": 2013}, {"title": "Solving MIPs via scaling-based augmentation", "authors": ["P.L. Bodic", "J.W. Pavelka", "M.E. Pfetsch", "S. Pokutta"], "venue": "arXiv preprint arXiv:1509.03206,", "year": 2015}, {"title": "Lazifying Conditional Gradient Algorithms", "authors": ["G. Braun", "S. Pokutta", "D. Zink"], "venue": "Proceedings of ICML,", "year": 2017}, {"title": "Following the perturbed leader for online structured learning", "authors": ["A. Cohen", "T. Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "year": 2015}, {"title": "A note on QUBO instances defined on", "authors": ["S. Dash"], "venue": "Chimera graphs. preprint arXiv:1306.1202,", "year": 2013}, {"title": "An application of simultaneous Diophantine approximation in combinatorial optimization", "authors": ["A. Frank", "\u00c9. Tardos"], "year": 1987}, {"title": "An algorithm for quadratic programming", "authors": ["M. Frank", "P. Wolfe"], "venue": "Naval research logistics quarterly,", "year": 1956}, {"title": "New analysis and results for the Frank\u2013Wolfe method", "authors": ["R.M. Freund", "P. Grigas"], "venue": "Mathematical Programming,", "year": 2016}, {"title": "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization", "authors": ["D. Garber", "E. Hazan"], "venue": "arXiv preprint arXiv:1301.4666,", "year": 2013}, {"title": "Linear-memory and decomposition-invariant linearly convergent conditional gradient algorithm for structured polytopes", "authors": ["D. Garber", "O. Meshi"], "venue": "arXiv preprint,", "year": 2016}, {"title": "Solving combinatorial games using products, projections and lexicographically optimal bases", "authors": ["S. Gupta", "M. Goemans", "P. Jaillet"], "venue": "arXiv preprint arXiv:1603.00522,", "year": 2016}, {"title": "Introduction to online convex optimization", "authors": ["E. Hazan"], "venue": "Foundations and Trends in Optimization,", "year": 2016}, {"title": "Projection-free online learning", "authors": ["E. Hazan", "S. Kale"], "venue": "arXiv preprint arXiv:1206.4657,", "year": 2012}, {"title": "Revisiting Frank\u2013Wolfe: Projection-free sparse convex optimization", "authors": ["M. Jaggi"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "year": 2013}, {"title": "Cutting-plane training of structural SVMs", "authors": ["T. Joachims", "T. Finley", "C.-N.J. Yu"], "venue": "Machine Learning,", "year": 2009}, {"title": "Efficient image and video co-localization with Frank-Wolfe algorithm", "authors": ["A. Joulin", "K. Tang", "L. Fei-Fei"], "venue": "In European Conference on Computer Vision,", "year": 2014}, {"title": "Efficient algorithms for online decision problems", "authors": ["A. Kalai", "S. Vempala"], "venue": "Journal of Computer and System Sciences,", "year": 2005}, {"title": "Mathematical Programming Computation, 3(2):103\u2013163, 2011", "authors": ["T. Koch", "T. Achterberg", "E. Andersen", "O. Bastert", "T. Berthold", "R.E. Bixby", "E. Danna", "G. Gamrath", "A.M. Gleixner", "S. Heinz", "A. Lodi", "H. Mittelmann", "T. Ralphs", "D. Salvagnin", "D.E. Steffy", "K. Wolter. MIPLIB"], "venue": "doi: 10.1007/s12532-011-0025-9. URL http://mpc.zib.de/index.php/MPC/article/view/56/28.", "year": 2010}, {"title": "On the global linear convergence of Frank\u2013Wolfe optimization variants", "authors": ["S. Lacoste-Julien", "M. Jaggi"], "venue": "Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "Block-coordinate Frank\u2013Wolfe optimization for structural SVMs", "authors": ["S. Lacoste-Julien", "M. Jaggi", "M. Schmidt", "P. Pletscher"], "venue": "In ICML 2013 International Conference on Machine Learning,", "year": 2013}, {"title": "Conditional gradient sliding for convex optimization", "authors": ["G. Lan", "Y. Zhou"], "venue": "Optimization-Online preprint (4605),", "year": 2014}, {"title": "Constrained minimization methods", "authors": ["E.S. Levitin", "B.T. Polyak"], "venue": "USSR Computational mathematics and mathematical physics,", "year": 1966}, {"title": "An efficient algorithm for learning with semi-bandit feedback", "authors": ["G. Neu", "G. Bart\u00f3k"], "venue": "In Algorithmic Learning Theory,", "year": 2013}, {"title": "Integer convex minimization by mixed integer linear optimization", "authors": ["T. Oertel", "C. Wagner", "R. Weismantel"], "venue": "Oper. Res. Lett.,", "year": 2014}, {"title": "Minding the gaps for block Frank\u2013Wolfe optimization of structured SVMs", "authors": ["A. Osokin", "J.-B. Alayrac", "I. Lukasewitz", "P.K. Dokania", "S. Lacoste-Julien"], "venue": "ICML 2016 International Conference on Machine Learning / arXiv preprint arXiv:1605.09346,", "year": 2016}, {"title": "Smooth convex optimization via geometric scaling", "authors": ["S. Pokutta"], "year": 2017}, {"title": "The complexity of generic primal algorithms for solving general integer programs", "authors": ["A.S. Schulz", "R. Weismantel"], "venue": "Mathematics of Operations Research,", "year": 2002}, {"title": "0/1-integer programming: Optimization and augmentation are equivalent", "authors": ["A.S. Schulz", "R. Weismantel", "G.M. Ziegler"], "venue": "In Algorithms \u2013 ESA \u201995,", "year": 1995}, {"title": "A multi-plane block-coordinate Frank\u2013Wolfe algorithm for training structural SVMs with a costly max-oracle", "authors": ["N. Shah", "V. Kolmogorov", "C.H. Lampert"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "year": 2015}], "id": "SP:bdc3f9ff1e205fb53599859a913888e906b69ba4", "authors": [{"name": "G\u00e1bor Braun", "affiliations": []}, {"name": "Sebastian Pokutta", "affiliations": []}], "abstractText": "Conditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, in many cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls.", "title": "Lazifying Conditional Gradient Algorithms"}
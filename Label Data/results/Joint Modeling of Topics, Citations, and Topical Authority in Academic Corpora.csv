0,1,label2,summary_sentences
Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location.,1. Introduction,[0],[0]
"It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing.",1. Introduction,[0],[0]
"In a distributed setting, multiple entities/nodes collaboratively work toward a common optimization objective through an
1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Xueru Zhang <xueru@umich.edu>, Mohammad Mahdi Khalili <khalili@umich.edu>, Mingyan Liu <mingyan@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
interactive process of local computation and message passing, which ideally should result in all nodes converging to a global optimum.",1. Introduction,[0],[0]
"Existing approaches to decentralizing an optimization problem primarily consist of subgradientbased algorithms (Nedic et al., 2008; Nedic & Ozdaglar, 2009; Lobel & Ozdaglar, 2011), ADMM-based algorithms (Wei & Ozdaglar, 2012; Ling & Ribeiro, 2014; Shi et al., 2014; Zhang & Kwok, 2014; Ling et al., 2016), and composite of subgradient and ADMM (Bianchi et al., 2014).",1. Introduction,[0],[0]
"It has been shown that ADMM-based algorithms can converge at the rate of O( 1k ) while subgradient-based algorithms typically converge at the rate of O( 1√
k ), where k is the number
of iterations (Wei & Ozdaglar, 2012).",1. Introduction,[0],[0]
"In this study, we will solely focus on ADMM-based algorithms.
",1. Introduction,[0],[0]
"The information exchanged over the iterative process gives rise to privacy concerns if the local training data is proprietary to each node, especially when it contains sensitive information such as medical or financial records, web search history, and so on.",1. Introduction,[0],[0]
"It is therefore highly desirable to ensure such iterative processes are privacy-preserving.
",1. Introduction,[0],[0]
"A widely used notion of privacy is the ε-differential privacy; it is generally achieved by perturbing the algorithm such that the probability distribution of its output is relatively insensitive to any change to a single record in the input (Dwork, 2006).",1. Introduction,[0],[0]
"Several differentially private distributed algorithms have been proposed, including (Hale & Egerstedty, 2015; Huang et al., 2015; Han et al., 2017; Zhang & Zhu, 2017; Bellet et al., 2017).",1. Introduction,[0],[0]
"While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration.",1. Introduction,[0],[0]
"To the best of our knowledge, only (Zhang & Zhu, 2017) applies differential privacy to ADMM, where the noise is either added to the dual variable (dual variable perturbation) or the primal variable (primal variable perturbation) in ADMM updates.",1. Introduction,[0],[0]
"However, (Zhang & Zhu, 2017) could only bound the privacy loss of a single iteration.",1. Introduction,[0],[0]
"Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process.",1. Introduction,[0],[0]
It turns out that the tradeoff between the utility of the algorithm and its privacy preservation over the entire computational process becomes hard using the existing method.,1. Introduction,[0],[0]
"ar X iv :1 80 6.
",1. Introduction,[0],[0]
"02 24
6v 1
[ cs
.L",1. Introduction,[0],[0]
"G
] 6
J un
2 01
8
In this study we propose a perturbation method that could simultaneously improve the accuracy and privacy for ADMM.",1. Introduction,[0],[0]
We start with a modified version of ADMM whereby each node independently decides its own penalty parameter in each iteration; it may also differ from the dual updating step size.,1. Introduction,[0],[0]
For this modified ADMM we establish conditions for convergence and quantify the lower bound of the convergence rate.,1. Introduction,[0],[0]
We then present a penalty perturbation method to provide differential privacy.,1. Introduction,[0],[0]
"Our numerical results show that under this method, by increasing the penalty parameter over iterations, we can achieve stronger privacy guarantee as well as better algorithmic performance, i.e., more stable convergence and higher accuracy.
",1. Introduction,[0],[0]
The remainder of the paper is organized as follows.,1. Introduction,[0],[0]
We present problem formulation and definition of differential privacy and ADMM in Section 2 and a modified ADMM algorithm along with its convergence analysis in Section 3.,1. Introduction,[0],[0]
A private version of this ADMM algorithm is then introduced in Section 4 and numerical results in Section 5.,1. Introduction,[0],[0]
Discussions are given in Section 6 and Section 7 concludes the paper.,1. Introduction,[0],[0]
"Consider a connected network1 given by an undirected graph G(N ,E ), which consists of a set of nodes N = {1, 2, · · · , N} and a set of edges E = {1, 2, · · · , E}.",2.1. Problem Formulation,[0],[0]
Two nodes can exchange information if and only if they are connected by an edge.,2.1. Problem Formulation,[0],[0]
"Let Vi denote node i’s set of neighbors, excluding itself.",2.1. Problem Formulation,[0],[0]
"A node i contains a dataset Di = {(xni , yni )",2.1. Problem Formulation,[0],[0]
"|n = 1, 2, · · · , Bi}, where xni ∈ Rd is the feature vector representing the n-th sample belonging to i, yni ∈ {−1, 1} the corresponding label, and Bi the size of Di.
Consider the regularized empirical risk minimization (ERM) problems for binary classification defined as follows:
",2.1. Problem Formulation,[0],[0]
"min fc OERM (fc, Dall) =",2.1. Problem Formulation,[0],[0]
N∑ i=1,2.1. Problem Formulation,[0],[0]
C Bi Bi∑ n=1 L (yni,2.1. Problem Formulation,[0],[0]
f T c,2.1. Problem Formulation,[0],[0]
x n,2.1. Problem Formulation,[0],[0]
"i )+ρR(fc) (1) where C ≤ Bi and ρ > 0 are constant parameters of the algorithm, the loss function L (·) measures the accuracy of classifier, and the regularizer R(·) helps to prevent overfitting.",2.1. Problem Formulation,[0],[0]
The goal is to train a (centralized) classifier fc ∈ Rd over the union of all local datasets Dall = ∪i∈N,2.1. Problem Formulation,[0],[0]
"Di in a distributed manner using ADMM, while providing privacy guarantee for each data sample 2.
",2.1. Problem Formulation,[0],[0]
"1A connected network is one in which every node is reachable (via a path) from every other node.
2The proposed penalty perturbation method is not limited to classification problems.",2.1. Problem Formulation,[0],[0]
It can be applied to general ADMM-based distributed algorithms since the convergence and privacy analysis,2.1. Problem Formulation,[0],[0]
"To decentralize (1), let fi be the local classifier of each node i. To achieve consensus, i.e., f1 = f2 = · · · = fN , a set of auxiliary variables {wij |i ∈ N , j ∈ Vi} are introduced for every pair of connected nodes.",2.2. Conventional ADMM,[0],[0]
"As a result, (1) is reformulated equivalently as:
min {fi},{wij} ÕERM ({fi}Ni=1, Dall) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
",2.2. Conventional ADMM,[0],[0]
"s.t. fi = wij , wij = fj , i ∈ N ,",2.2. Conventional ADMM,[0],[0]
"j ∈ Vi
(2)
where O(fi, Di) = C
Bi
∑Bi n=1 L (y n",2.2. Conventional ADMM,[0],[0]
i f T,2.2. Conventional ADMM,[0],[0]
"i x n i ) + ρ
N R(fi).
",2.2. Conventional ADMM,[0],[0]
The objective in (2) can be solved using ADMM.,2.2. Conventional ADMM,[0],[0]
"Let {fi} be the shorthand for {fi}i∈N ; let {wij , λkij} be the shorthand for {wij , λkij}i∈N ,j∈Vi,k∈{a,b}, where λaij , λbij are dual variables corresponding to equality constraints fi = wij and wij = fj respectively.",2.2. Conventional ADMM,[0],[0]
"Then the augmented Lagrangian is as follows:
Lη({fi}, {wij , λkij}) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
+ N∑ i=1",2.2. Conventional ADMM,[0],[0]
∑ j∈Vi (λaij) T (fi − wij) +,2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"∑ j∈Vi (λbij) T (wij − fj) (3)
+ N∑ i=1 ∑",2.2. Conventional ADMM,[0],[0]
j∈Vi η 2 (||fi − wij ||22 + ||wij,2.2. Conventional ADMM,[0],[0]
"− fj ||22) .
",2.2. Conventional ADMM,[0],[0]
"In the (t + 1)-th iteration, the ADMM updates consist of the following:
fi(t+ 1) = argmin fi Lη({fi}, {wij(t), λkij(t)}) ; (4)
wij(t+ 1) = argmin wij Lη({fi(t+ 1)}, {wij , λkij(t)}) ; (5)
λaij(t+ 1) = λ a ij(t) + η(fi(t+",2.2. Conventional ADMM,[0],[0]
1)− wij(t+ 1)),2.2. Conventional ADMM,[0],[0]
"; (6)
λbij(t+ 1) = λ b ij(t) +",2.2. Conventional ADMM,[0],[0]
η(wij(t+ 1)− fj(t+ 1)) .,2.2. Conventional ADMM,[0],[0]
"(7)
Using Lemma 3 in (Forero et al., 2010), if dual variables λaij(t) and λ b ij(t) are initialized to zero for all node pairs (i, j), then λaij(t) = λ b ij(t) and λ k ij(t) = −λkji(t) will hold for all iterations with k ∈ {a, b}, i ∈ N , j ∈ Vi.
",2.2. Conventional ADMM,[0],[0]
Let λi(t) = ∑,2.2. Conventional ADMM,[0],[0]
"j∈Vi λ a ij(t) = ∑ j∈Vi λ b ij(t), then the ADMM iterations (4)-(7) can be simplified as:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+η ∑ j∈Vi ||1 2 (fi(t) + fj(t))− fi||22 } ; (8)
λi(t+ 1) = λi(t) + η
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .",2.2. Conventional ADMM,[0],[0]
"(9)
in Section 3 & 4 remain valid.",2.2. Conventional ADMM,[0],[0]
"Differential privacy (Dwork, 2006) can be used to measure the privacy risk of each individual sample in the dataset quantitatively.",2.3. Differential Privacy,[0],[0]
"Mathematically, a randomized algorithm A (·) taking a dataset as input satisfies ε-differential privacy if for any two datasets D, D̂ differing in at most one data point, and for any set of possible outputs S ⊆ range(A ), Pr(A (D) ∈ S) ≤",2.3. Differential Privacy,[0],[0]
exp(ε)Pr(A (D̂) ∈ S) holds.,2.3. Differential Privacy,[0],[0]
We call two datasets differing in at most one data point as neighboring datasets.,2.3. Differential Privacy,[0],[0]
"The above definition suggests that for a sufficiently small ε, an adversary will observe almost the same output regardless of the presence (or value change) of any one individual in the dataset; this is what provides privacy protection for that individual.",2.3. Differential Privacy,[0],[0]
"Two randomizations were proposed in (Zhang & Zhu, 2017): (i) dual variable perturbation, where each node i adds a random noise to its dual variable λi(t) before updating its primal variable fi(t) using (8) in each iteration; and (ii) primal variable perturbation, where after updating primal variable fi(t), each node adds a random noise to it before broadcasting to its neighbors.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
Both were evaluated for a single iteration for a fixed privacy constraint.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"As we will see later in numerical experiments, the privacy loss accumulates significantly when inspected over multiple iterations.
","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"In contrast, in this study we will explore the use of the penalty parameter η to provide privacy.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"In particular, we will allow this to be private information to every node, i.e., each decides its own η in every iteration and it is not exchanged among the nodes.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
Below we will begin by modifying the ADMM to accommodate private penalty terms.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"Conventional ADMM (Boyd et al., 2011) requires that the penalty parameter η be fixed and equal to the dual updating step size for all nodes in all iterations.",3.1. Making η a node’s private information,[0],[0]
Varying the penalty parameter to accelerate convergence in ADMM has been proposed in the literature.,3.1. Making η a node’s private information,[0],[0]
"For instance, (He et al., 2002; Magnússon et al., 2014; Aybat & Iyengar, 2015; Xu et al., 2016) vary this penalty parameter in every iteration but keep it the same for different equality constraints in (2).",3.1. Making η a node’s private information,[0],[0]
"In (Song et al., 2016; Zhang & Wang, 2017) this parameter varies in each iteration and is allowed to differ for different equality constraints.",3.1. Making η a node’s private information,[0],[0]
"However, all of these modifications are based on the original ADMM (Eqn. (4)-(7)) and not on the simplified version (Eqn. (8)-(9)); the significance of this difference is discussed below in the context of privacy requirement.",3.1. Making η a node’s private information,[0],[0]
"Moreover, we will decouple ηi(t+1) from the dual updating step size, denoted as θ below.",3.1. Making η a node’s private information,[0],[0]
"For simplicity, θ is fixed for
all nodes in our analysis, but can also be private information as we show in numerical experiments.
",3.1. Making η a node’s private information,[0],[0]
First consider replacing η with ηij(t+ 1) in Eqn.,3.1. Making η a node’s private information,[0],[0]
"(4)-(5) of the original ADMM (as is done in (Song et al., 2016; Zhang & Wang, 2017))",3.1. Making η a node’s private information,[0],[0]
"and replacing η with θ in Eqn. (6)-(7); we obtain the following:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ ∑ j∈Vi ηij(t+ 1) + ηji(t+ 1) 2 ||1 2 (fi(t) + fj(t))− fi||22} ;
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .
",3.1. Making η a node’s private information,[0],[0]
This however violates our requirement that ηji(t) be node j’s private information since this is needed by node i to perform the above computation.,3.1. Making η a node’s private information,[0],[0]
"To resolve this, we instead start from the simplified ADMM, modifying Eqn. (8)-(9):
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 } ; (10)
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) , (11)
where ηi(t+ 1) is now node i’s private information.",3.1. Making η a node’s private information,[0],[0]
Indeed ηi(t+ 1) is no longer purely a penalty parameter related to any equality constraint in the original sense.,3.1. Making η a node’s private information,[0],[0]
We will however refer to it as the private penalty parameter for simplicity.,3.1. Making η a node’s private information,[0],[0]
The above constitutes the M-ADMM algorithm.,3.1. Making η a node’s private information,[0],[0]
We next show that the M-ADMM (Eqn. (10)-(11)) converges to the optimal solution under a set of common technical assumptions.,3.2. Convergence Analysis,[0],[0]
"Our proof is based on the method given in (Ling et al., 2016).
",3.2. Convergence Analysis,[0],[0]
"Assumption 1: Function O(fi, Di) is convex and continuously differentiable in fi, ∀i.
",3.2. Convergence Analysis,[0],[0]
Assumption 2:,3.2. Convergence Analysis,[0],[0]
"The solution set to the original ERM problem (1) is nonempty and there exists at least one bounded element.
",3.2. Convergence Analysis,[0],[0]
"The KKT optimality condition of the primal update (10) is:
0 = ∇O(fi(t+ 1), Di) + 2λi(t)",3.2. Convergence Analysis,[0],[0]
+ηi(t+ 1) ∑ j∈Vi (2fi(t+ 1)− (fi(t) + fj(t))) .,3.2. Convergence Analysis,[0],[0]
"(12)
We next rewrite (11)-(12) in matrix form.",3.2. Convergence Analysis,[0],[0]
"Define the adjacency matrix of the network A ∈ RN×N as
aij = { 1, if node i and node j are connected 0, otherwise .
",3.2. Convergence Analysis,[0],[0]
"Stack the variables fi(t), λi(t) and ∇O(fi(t), Di) for i ∈ N into matrices, i.e.,
f̂(t) =  f1(t) T f2(t) T
...",3.2. Convergence Analysis,[0],[0]
"fN (t) T
 ∈ RN×d , Λ(t) =  λ1(t) T λ2(t) T
... λN",3.2. Convergence Analysis,[0],[0]
"(t) T
 ∈ RN×d
∇Ô(f̂(t), Dall) =  ∇O(f1(t), D1)T ∇O(f2(t), D2)T
...",3.2. Convergence Analysis,[0],[0]
"∇O(fN (t), DN )T  ∈ RN×d",3.2. Convergence Analysis,[0],[0]
"Let Vi = |Vi| be the number of neighbors of node i, and define the degree matrix D = diag([V1;V2; · · · ;VN ]) ∈ RN×N .",3.2. Convergence Analysis,[0],[0]
Define for the t-th iteration a penalty-weighted matrix W (t) = diag([η1(t); η2(t); · · · ; ηN (t)]) ∈ RN×N .,3.2. Convergence Analysis,[0],[0]
"Then the matrix form of (11)-(12) are:
∇Ô(f̂(t+ 1), Dall) + 2Λ(t) + 2W (t+ 1)Df̂(t+ 1) −W (t+ 1)(D +A)f̂(t) = 0N×d ; (13)
2Λ(t+ 1) = 2Λ(t) + θ(D −A)f̂(t+ 1) .",3.2. Convergence Analysis,[0],[0]
"(14)
Note that D −A is the Laplacian matrix and D +A is the signless Laplacian matrix of the network, with the following properties if the network is connected: (i) D ±",3.2. Convergence Analysis,[0],[0]
A 0 is positive semi-definite; (ii),3.2. Convergence Analysis,[0],[0]
Null(D,3.2. Convergence Analysis,[0],[0]
"− A) = c1, i.e., every member in the null space of D −A is a scalar multiple of 1 with 1 being the vector of all 1’s (Kelner, 2007).",3.2. Convergence Analysis,[0],[0]
"Let √ X denote the square root of a symmetric positive semi-definite (PSD) matrix X that is also symmetric PSD, i.e., √ X √ X = X .",3.2. Convergence Analysis,[0],[0]
"Define matrix Y (t) such that 2Λ(t) =√
D −AY (t).",3.2. Convergence Analysis,[0],[0]
"Since Λ(0) = zeros(N, d), which is in the column space of D −A, this together with (14) imply that Λ(t) is in the column space of D − A and √ D −A.",3.2. Convergence Analysis,[0],[0]
This guarantees the existence of Y (t).,3.2. Convergence Analysis,[0],[0]
"This allows us to rewrite (13)-(14) as:
∇Ô(f̂(t+ 1), Dall) + √ D −AY (t+ 1)
+(W (t+ 1)− θI)(D −A)f̂(t+ 1) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))",3.2. Convergence Analysis,[0],[0]
"= 0N×d ; (15)
Y (t+ 1) = Y (t) + θ",3.2. Convergence Analysis,[0],[0]
√ D −Af̂(t+ 1) .,3.2. Convergence Analysis,[0],[0]
"(16)
Lemma 3.1 [First-order Optimality Condition (Ling et al., 2016)]",3.2. Convergence Analysis,[0],[0]
"Under Assumptions 1 and 2, the following two statements are equivalent:
• f̂∗ =",3.2. Convergence Analysis,[0],[0]
"[(f∗1 )T ; (f∗2 )T ; · · · ; (f∗N )T ] ∈ RN×d is consensual, i.e., f∗1 = f ∗ 2 = · · · = f∗N = f∗c where f∗c is the
optimal solution to (1).
",3.2. Convergence Analysis,[0],[0]
"• There exists a pair (f̂∗, Y ∗) with Y ∗ = √ D −AX
for some X ∈ RN×d such that
∇Ô(f̂∗, Dall) + √ D −AY ∗ = 0N×d ; (17)√ D −Af̂∗ = 0N×d .",3.2. Convergence Analysis,[0],[0]
"(18)
Lemma 3.1 shows that a pair (Y ∗, f̂∗) satisfying (17)(18) is equivalent to the optimal solution of our problem, hence the convergence of M-ADMM is proved by showing that (Y (t), f̂(t)) converges to a pair (Y ∗, f̂∗) satisfying (17)(18).
",3.2. Convergence Analysis,[0],[0]
Theorem 3.1 Consider the modified ADMM defined by (10)-(11).,3.2. Convergence Analysis,[0],[0]
"Let {Y (t), f̂(t)} be outputs in each iteration and (Y ∗, f̂∗) a pair satisfying (17)-(18).",3.2. Convergence Analysis,[0],[0]
"Denote
Z(t) =
[ Y (t)
f̂(t)
] ∈ R2N×d, Z∗ =",3.2. Convergence Analysis,[0],[0]
"[ Y ∗
f̂∗
] ∈ R2N×d
J(t)",3.2. Convergence Analysis,[0],[0]
=,3.2. Convergence Analysis,[0],[0]
"[ IN×N θ 0 0 W (t)(D +A) ] ∈ R2N×2N
Let 〈·, ·〉F be the Frobenius inner product of two matrices.",3.2. Convergence Analysis,[0],[0]
"We have
〈Z(t+ 1)−Z∗, J(t+ 1)(Z(t+ 1)−Z(t))〉F ≤ 0 .",3.2. Convergence Analysis,[0],[0]
(19),3.2. Convergence Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"To further establish the convergence rate of modified ADMM, an additional assumption is used:
Assumption 3:",3.3. Convergence Rate Analysis,[0],[0]
"For all i ∈ N , O(fi, Di) is strongly convex in fi and has Lipschitz continues gradients, i.e., for any f1i and f 2",3.3. Convergence Rate Analysis,[0],[0]
"i , we have:
(f1i −f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",3.3. Convergence Rate Analysis,[0],[0]
"≥ mi||f1i −f2i ||22
||∇O(f1i , Di)−∇O(f2i , Di)||2 ≤Mi||f1i",3.3. Convergence Rate Analysis,[0],[0]
"− f2i ||2 (20)
where mi > 0 is the strong convexity constant and 0",3.3. Convergence Rate Analysis,[0],[0]
<,3.3. Convergence Rate Analysis,[0],[0]
Mi,3.3. Convergence Rate Analysis,[0],[0]
"< +∞ is the Lipschitz constant.
",3.3. Convergence Rate Analysis,[0],[0]
Theorem 3.2 Define Dm = diag([m1;m2; · · · ;mN ]) ∈,3.3. Convergence Rate Analysis,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈ RN×N with mi > 0,3.3. Convergence Rate Analysis,[0],[0]
and 0 <,3.3. Convergence Rate Analysis,[0],[0]
Mi < +∞ as given in Assumption 3.,3.3. Convergence Rate Analysis,[0],[0]
"Denote by ||X||2J = 〈X, JX〉F the Frobenius inner product of any matrix X and JX; denote by σmin(·) and σmax(·) the smallest nonzero, and the largest, singular values of a matrix, respectively.
",3.3. Convergence Rate Analysis,[0],[0]
Let σ̃max(t) =,3.3. Convergence Rate Analysis,[0],[0]
"σmax(W (t)(D +A)), σ̄max/min(t) = σmax/min((W",3.3. Convergence Rate Analysis,[0],[0]
(t)− θI)(D −A)) and µ > 1 be an arbitrary constant.,3.3. Convergence Rate Analysis,[0],[0]
"Consider any δ(t) that satisfies (21)(22):
δ(t)µ2σ̃max(t) θσmin(D −A) ≤ 1 (21)
and
δ(t)( µσ̄max(t) 2IN + µ2DM θσmin(D",3.3. Convergence Rate Analysis,[0],[0]
−A)(µ− 1),3.3. Convergence Rate Analysis,[0],[0]
"+W (t)(D +A))
",3.3. Convergence Rate Analysis,[0],[0]
2(W (t)− θI)(D −A) + 2Dm .,3.3. Convergence Rate Analysis,[0],[0]
(22),3.3. Convergence Rate Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗) in the following sense:
(1 + δ(t))||Z(t)− Z∗||2J(t) ≤","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
||Z(t−,"If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"1)− Z ∗||2J(t) .
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Furthermore, a lower bound on δ(t) is:
min{θσmin(D −A) µ2σ̃max(t) , 2mo + 2σ̄min(t) µ2M2O+µσ̄max(t) 2
θσmin(D−A)(µ−1) + σ̃max(t) } (23)
where mo = mini∈N {mi} and MO = maxi∈N {Mi}.
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Although Theorem 3.2 only gives a lower bound on the convergence rate (1 + δ(t)) of the M-ADMM, it reflects the impact of penalty {ηi(t)}Ni=1 on the convergence.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Since σ̄max(t) = σmax((W (t)− θI)(D −A)) and σ̃max(t) = σmax(W (t)(D +A)), larger penalty results in larger σ̄max(t) and σ̃max(t).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"By (23), the first term,
θσmin(D−A) µ2σ̃max(t)
is smaller when σ̃max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"The second term is bounded by θσmin(D−A)(µ−1)(2mo+2σ̄min(t))µσ̄max(t)2 , which is smaller when σ̄max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Therefore, the convergence rate 1 + δ(t) decreases as {ηi(t)}Ni=1 increase.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
In this section we present a privacy preserving version of MADMM.,4. Private M-ADMM,[0],[0]
"To begin, a random noise i(t+1) with probability density proportional to exp{−αi(t + 1)|| i(t + 1)||2} is added to penalty term in the objective function of (10):
Lprivi (t+ 1) =",4. Private M-ADMM,[0],[0]
"O(fi, Di) + 2λi(t)",4. Private M-ADMM,[0],[0]
T fi +ηi(t+ 1) ∑ j∈Vi ||fi + i(t+,4. Private M-ADMM,[0],[0]
"1)− 1 2 (fi(t) + fj(t))||22
(24)
",4. Private M-ADMM,[0],[0]
"To generate this noisy vector, choose the norm from the gamma distribution with shape d and scale 1αi(t+1) and the direction uniformly, where d is the dimension of the feature space.",4. Private M-ADMM,[0],[0]
"Then node i’s local result is obtained by finding the optimal solution to the private objective function:
fi(t+ 1) = argmin fi
Lprivi (t+ 1), i ∈ N .",4. Private M-ADMM,[0],[0]
"(25)
It is equivalent to (26) below when noise ηi(t+1)Vi i(t+1)
",4. Private M-ADMM,[0],[0]
Algorithm 1 Penalty perturbation (PP) method,4. Private M-ADMM,[0],[0]
Parameter:,4. Private M-ADMM,[0],[0]
"Determine θ such that 2c1 < BiC ( ρ N + 2θVi)
holds for all i. Initialize: Generate fi(0) randomly and λi(0) = 0d×1 for every node i ∈ N , t = 0",4. Private M-ADMM,[0],[0]
"Input: {Di}Ni=1, {αi(1), · · · , αi(T )}Ni=1 for t = 0 to T − 1 do
for i = 1 to N do Generate noise i(t+ 1) ∼ exp(−αi(t+ 1)|| ||2)",4. Private M-ADMM,[0],[0]
"Perturb the penalty term according to (24) Update primal variable via (25) end for for i = 1 to N do
Broadcast fi(t+ 1) to all neighbors",4. Private M-ADMM,[0],[0]
"j ∈ Vi end for for i = 1 to N do
Update dual variable according to (11) end for
end for Output: upper bound of the total privacy loss β
is added to the dual variable λi(t):
argmin fi
L̃privi (",4. Private M-ADMM,[0],[0]
"t+ 1) = C
Bi Bi∑ n=1 L",4. Private M-ADMM,[0],[0]
(,4. Private M-ADMM,[0],[0]
yni f T i x n,4. Private M-ADMM,[0],[0]
i ),4. Private M-ADMM,[0],[0]
"+ ρ N R(fi)
",4. Private M-ADMM,[0],[0]
+2(λi(t) +,4. Private M-ADMM,[0],[0]
ηi(t+,4. Private M-ADMM,[0],[0]
1)Vi i(t+ 1)),4. Private M-ADMM,[0],[0]
"T fi +ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 .
",4. Private M-ADMM,[0],[0]
"Further, if ηi(t+1) = η = θ,∀i, t, then the above is reduced to the dual variable perturbation in (Zhang & Zhu, 2017)3.
",4. Private M-ADMM,[0],[0]
"The complete procedure is shown in Algorithm 1, where the condition used to generate θ helps bound the worst-case privacy loss but is not necessary in guaranteeing convergence.
",4. Private M-ADMM,[0],[0]
"In a distributed and iterative setting, the “output” of the algorithm is not merely the end result, but includes all intermediate results generated and exchanged during the iterative process.",4. Private M-ADMM,[0],[0]
"For this reason, we formally state the differential privacy definition in this setting below.
",4. Private M-ADMM,[0],[0]
"Definition 4.1 Consider a connected network G(N ,E ) with a set of nodes N = {1, 2, · · · , N}.",4. Private M-ADMM,[0],[0]
Let f(t) =,4. Private M-ADMM,[0],[0]
{fi(t)}Ni=1 denote the information exchange of all nodes in the t-th iteration.,4. Private M-ADMM,[0],[0]
"A distributed algorithm is said to satisfy β-differential privacy during T iterations if for any two datasets Dall = ∪iDi and D̂all = ∪iD̂i, differing in at
3Only a single iteration is considered in (Zhang & Zhu, 2017) while imposing a privacy constraint.",4. Private M-ADMM,[0],[0]
"Since we consider the entire iterative process, we don’t impose per-iteration privacy constraint but calculate the total privacy loss.
",4. Private M-ADMM,[0],[0]
"most one data point, and for any set of possible outputs S during T iterations, the following holds:
Pr({f(t)}Tt=0 ∈ S|Dall)",4. Private M-ADMM,[0],[0]
Pr({f(t)}Tt=0 ∈ S|D̂all) ≤,4. Private M-ADMM,[0],[0]
"exp(β)
We now state our main result on the privacy property of the penalty perturbation algorithm using the above definition.",4. Private M-ADMM,[0],[0]
"Additional assumptions on L (·) and R(·) are used.
",4. Private M-ADMM,[0],[0]
Assumption 4: The loss function L is strictly convex and twice differentiable.,4. Private M-ADMM,[0],[0]
|L,4. Private M-ADMM,[0],[0]
"′| ≤ 1 and 0 < L ′′ ≤ c1 with c1 being a constant.
",4. Private M-ADMM,[0],[0]
"Assumption 5: The regularizer R is 1-strongly convex and twice continuously differentiable.
",4. Private M-ADMM,[0],[0]
Theorem 4.1 Normalize feature vectors in the training set such that ||xni ||2 ≤ 1 for all i ∈ N and,4. Private M-ADMM,[0],[0]
"n. Then the private M-ADMM algorithm (PP) satisfies the β-differential privacy with
β ≥ max i∈N { T∑ t=1 C(1.4c1 + αi(t)) ηi(t)ViBi } .",4. Private M-ADMM,[0],[0]
(26),4. Private M-ADMM,[0],[0]
"We use the same dataset as (Zhang & Zhu, 2017), i.e., the Adult dataset from the UCI Machine Learning Repository (Lichman, 2013).",5. Numerical Experiments,[0],[0]
"It consists of personal information of around 48,842 individuals, including age, sex, race, education, occupation, income, etc.",5. Numerical Experiments,[0],[0]
"The goal is to predict whether the annual income of an individual is above $50,000.
",5. Numerical Experiments,[0],[0]
"To preprocess the data, we (1) remove all individuals with missing values; (2) convert each categorical attribute (with m categories) to a binary vector of length m; (3) normalize columns (features) such that the maximum value of each column is 1; (4) normalize rows (individuals) such that its l2 norm is at most 1; and (5) convert labels {≥ 50k,≤ 50k} to {+1,−1}.",5. Numerical Experiments,[0],[0]
"After this preprocessing, the final data includes 45,223 individuals, each represented as a 105-dimensional vector of norm at most 1.
",5. Numerical Experiments,[0],[0]
"We will use as loss function the logistic loss L (z) = log(1 + exp(−z)), with |L ′| ≤ 1 and L ′′ ≤ c1 = 14 .",5. Numerical Experiments,[0],[0]
The regularizer is R(fi),5. Numerical Experiments,[0],[0]
= 12 ||fi|| 2 2.,5. Numerical Experiments,[0],[0]
We will measure the accuracy of the algorithm by the average loss L(t) := 1 N ∑N i=1 1,5. Numerical Experiments,[0],[0]
"Bi ∑Bi n=1 L (y n i fi(t)
",5. Numerical Experiments,[0],[0]
Txni ) over the training set.,5. Numerical Experiments,[0],[0]
"We will measure the privacy of the algorithm by the upper bound P (t) := max i∈N { ∑t r=1 C(1.4c1+αi(r)) ηi(r)ViBi
}.",5. Numerical Experiments,[0],[0]
"The smaller L(t) and P (t), the higher accuracy and stronger privacy guarantee.",5. Numerical Experiments,[0],[0]
"We consider a five-node network and assign each node the following private penalty parameters: ηi(t) = ηi(1)q t−1 i for node i, where [η1(1), · · · , η5(1)] =",5.1. Convergence of M-ADMM,[0],[0]
"[0.55, 0.65, 0.6, 0.55, 0.6] and [q1, · · · , q5] =",5.1. Convergence of M-ADMM,[0],[0]
"[1.01, 1.03, 1.1, 1.2, 1.02].
Figure 1(a) shows the convergence of M-ADMM under these parameters while using a fixed dual updating step size θ = 0.5 across all nodes (blue curve).",5.1. Convergence of M-ADMM,[0],[0]
This is consistent with Theorem 3.1.,5.1. Convergence of M-ADMM,[0],[0]
"As mentioned earlier, this step size can also be non-fixed (black) and different (red) for different nodes.",5.1. Convergence of M-ADMM,[0],[0]
"In
Figure 1(b) we let each node use the same penalty ηi(t) = η(t) = 0.5qt−11 and compare the results by increasing q1, q1 ≥ 1.",5.1. Convergence of M-ADMM,[0],[0]
"We see that increasing penalty slows down the convergence, and larger increase in q1 slows it down even more, which is consistent with Theorem 3.2.",5.1. Convergence of M-ADMM,[0],[0]
"We next inspect the accuracy and privacy of the penalty perturbation (PP) based private M-ADMM (Algorithm 1) and compare it with the dual variable perturbation (DVP) method proposed in (Zhang & Zhu, 2017).",5.2. Private M-ADMM,[0],[0]
"In this set of experiments, for simplicity of presentation we shall fix θ = 0.5, let ηi(t) = η(t) = θqt−11 , and noise αi(t) = α(t) = α(1)qt−12 for all nodes.",5.2. Private M-ADMM,[0],[0]
"We observe similar results when ηi(t) and αi(t) vary from node to node.
",5.2. Private M-ADMM,[0],[0]
"For each parameter setting, we perform 10 independent runs of the algorithm, and record both the mean and the range of their accuracy.",5.2. Private M-ADMM,[0],[0]
"Specifically, Ll(t) denotes the average loss over the training dataset in the t-th iteration of the l-th experiment (1 ≤ l ≤ 10).",5.2. Private M-ADMM,[0],[0]
The mean of average loss is then given by Lmean(t) = 110 ∑10 l=1,5.2. Private M-ADMM,[0],[0]
"L
l(t), and the range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"= max
1≤l≤10 Ll(t)",5.2. Private M-ADMM,[0],[0]
− min 1≤l≤10 Ll(t).,5.2. Private M-ADMM,[0],[0]
"The larger the
range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"the less stable the algorithm, i.e., under the same parameter setting, the difference in performances (convergence curves) of every two experiments is larger.",5.2. Private M-ADMM,[0],[0]
Each parameter setting also has a corresponding upper bound on the privacy loss denoted by P (t).,5.2. Private M-ADMM,[0],[0]
Figures 2(a)2(b) show both Lmean(t) and Lrange(t),5.2. Private M-ADMM,[0],[0]
as vertical bars centered at Lmean(t),5.2. Private M-ADMM,[0],[0]
.,5.2. Private M-ADMM,[0],[0]
Their corresponding privacy upper bound is given in Figures 2(c)2(d).,5.2. Private M-ADMM,[0],[0]
"The pair 2(a)-2(c) (resp. 2(b)2(d)) is for the same parameter setting.
",5.2. Private M-ADMM,[0],[0]
"Figure 2 compares PP (blue & red, with ηi(t) increasing geometrically) with DVP (black & magenta, with ηi(t) = θ, ∀i, t).",5.2. Private M-ADMM,[0],[0]
"We see that in both cases improved accuracy comes at the expense of higher privacy loss (from magenta to black under DVP, from red to blue under PP).",5.2. Private M-ADMM,[0],[0]
"However, we also see that with suitable choices of q1, q2, PP can outperform DVP significantly both in accuracy and in privacy (e.g., red outperforms magenta in both accuracy and privacy, and blue outperforms black in both accuracy and privacy).
",5.2. Private M-ADMM,[0],[0]
We also performed experiments with the same dataset on larger networks with tens and hundreds of nodes and with samples evenly and unevenly spread across nodes.,5.2. Private M-ADMM,[0],[0]
"In both cases, convergence is attained and our algorithm continues to outperform (Zhang & Zhu, 2017) in a large network (see Figures 3 & 4).",5.2. Private M-ADMM,[0],[0]
"Since the privacy loss of the network is dominated by the node with the largest privacy loss and it increases as the number of samples in a node decreases (Theorem 4.1), the loss of privacy in a network with uneven sample size distributions is higher; note that this is a common issue with this type of analysis.",5.2. Private M-ADMM,[0],[0]
Our numerical results show that increasing the penalty {ηi(t)}Ni=1 over iterations can improve the algorithm’s accuracy and privacy simultaneously.,6. Discussion,[0],[0]
Below we provide some insight on why this is the case and discuss possible generalizations of our method.,6. Discussion,[0],[0]
"When the algorithm is perturbed by random noise, which is necessary to achieve privacy, increasing the penalty parameters over iterations makes the algorithm more noise resistant.",6.1. Higher accuracy,[0],[0]
"In particular, for the minimization in (25), larger ηi(t+ 1) results in smaller updates of variables, i.e., smaller distance between fi(t + 1) and fi(t).",6.1. Higher accuracy,[0],[0]
"In the non-private case, since fi(t) always moves toward the optimum, smaller update slows down the process.",6.1. Higher accuracy,[0],[0]
"In the private case, on the other hand, since a random noise is added to each update, fi(t) does not always move toward the optimum in each step.",6.1. Higher accuracy,[0],[0]
"When the overall perturbation has a larger variance, it is more likely that fi(t) could move further away from the optimum in some iterations.",6.1. Higher accuracy,[0],[0]
"Because larger ηi(t) leads to smaller update, it helps prevent fi(t) from moving too far away from the optimum, thus stabilizing the algorithm (smaller Lrange(t)).",6.1. Higher accuracy,[0],[0]
"First of all, more added noise means stronger privacy guarantee.",6.2. Stronger privacy,[0],[0]
"Increasing ηi(t) and αi(t) in such a way that the overall perturbation 2ηi(t)Vi i(t)T fi(t) in (26) is increasing leads to less privacy loss, as shown in Figure 2.",6.2. Stronger privacy,[0],[0]
"The noise resistance provided by an increasing ηi(t) indeed allows larger noises to be added under PP without jeopardizing convergence as observed in Section 6.1.
More interestingly, keeping ηi(t) private further strengthens privacy protection.",6.2. Stronger privacy,[0],[0]
"Consider the following threat model: An attacker knows {(xni , yni )}",6.2. Stronger privacy,[0],[0]
"Bi n=2 and {fj(t)}j∈Vi∪i for all t, i.e., all data points except for the first data point of node i, as well as all intermediate results of node i and its neighbors.",6.2. Stronger privacy,[0],[0]
"If the attacker also knows the dual updating step size θ and penalty parameter {ηi(t)}Tt=1 of node i, it can then infer the unknown data point (x1i , y 1 i ) with high confidence by combining the KKT optimality conditions from all iterations (see supplementary material for details).",6.2. Stronger privacy,[0],[0]
"However, if the penalty parameters {ηi(t)}Tt=1 are private to each node, then it is impossible for the attacker to infer the unknown data.",6.2. Stronger privacy,[0],[0]
"Even if the attacker knows the participation of an individual, it remains hard to infer its features.",6.2. Stronger privacy,[0],[0]
"The main contribution of this paper is the finding that increasing {ηi}Ni=1 improves the algorithm’s ability to resist
noise: even though we increase noise in each iteration to improve privacy, the accuracy does not degrade significantly due to this increasing robustness, which improves the privacy-utility tradeoff.",6.3. Generalization & comparison,[0],[0]
This property holds regardless of the noise distribution.,6.3. Generalization & comparison,[0],[0]
"While the present privacy analysis uses a similar framework as in (Chaudhuri et al., 2011; Zhang & Zhu, 2017) (objective perturbation with added Gamma noise), we can also use methods from other existing (centralized) ERM differentially private algorithms to every iteration in ADMM.",6.3. Generalization & comparison,[0],[0]
"For example, if we allow some probability (δ > 0) of violating -differential privacy and adopt a weaker variant ( , δ)-differential privacy, we can adopt methods from works such as (Kifer et al., 2012; Jain & Thakurta, 2014; Bassily et al., 2014), by adding Gaussian noise to achieve tighter bounds on privacy loss.",6.3. Generalization & comparison,[0],[0]
"However, as noted above, the robustness is improved as {ηi}Ni=1 increases; thus the same conclusion can be reached that both privacy and accuracy can be improved.
",6.3. Generalization & comparison,[0],[0]
This idea can also be generalized to other differentially private iterative algorithms.,6.3. Generalization & comparison,[0],[0]
A key observation of our algorithm is that the overall perturbation (2ηi(t)Vi i(t)T fi(t)) is related to the parameter that controls the updating step size (ηi(t)).,6.3. Generalization & comparison,[0],[0]
"In general, if the algorithm is perturbed in each iteration with a quantity φ( , ξ), which is a function of added noise and some parameter ξ that controls the step size, such that the resulting step size and φ( , ξ) move in opposite directions (i.e., decreasing step size increases the φ( , ξ)), then it is possible to simultaneously improve both accuracy and privacy by varying ξ to decrease the step size over time.
",6.3. Generalization & comparison,[0],[0]
"Interestingly, in a differentially private (sub)gradient-based distributed algorithm (Huang et al., 2015), the step size
and the overall perturbation move in the same direction (i.e., decreasing step size decreases perturbation).",6.3. Generalization & comparison,[0],[0]
"The reason for this difference is that under this subgradient-based algorithm, the sensitivity of the algorithm decreases with decreasing step size, which in turn leads to privacy constraint being satisfied with smaller perturbation.",6.3. Generalization & comparison,[0],[0]
"In contrast, for ADMM the sensitivity of the algorithm is independent of the step size, and the perturbation actually needs to increase to improve privacy guarantee; the decreasing step size acts to compensate for this increase in noise to maintain accuracy, as discussed in Section 6.1.
",6.3. Generalization & comparison,[0],[0]
"This issue of step size never arises in the study of (Zhang & Zhu, 2017) because the analysis is only for a single iteration; however, as we have seen doing so leads to significant total privacy loss over many iterations.",6.3. Generalization & comparison,[0],[0]
This paper presents a penalty-perturbation idea to introduce privacy preservation in iterative algorithms.,7. Conclusions,[0],[0]
We showed how to modify an ADMM-based distributed algorithm to improve privacy without compromising accuracy.,7. Conclusions,[0],[0]
The key idea is to add a perturbation correlated to the step size so that they change in opposite directions.,7. Conclusions,[0],[0]
Applying this idea to other iterative algorithms can be part of the future work.,7. Conclusions,[0],[0]
"This work is supported by the NSF under grants CNS1422211, CNS-1646019, CNS-1739517.",Acknowledgements,[0],[0]
"By KKT condition of (5), there is:
0 =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λbij(t)− λaij(t) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η(2wij(t+ 1)− fi(t+ 1)− fj(t+ 1))
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Implies:
wij(t+ 1) = 1
2η (λaij(t)− λbij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
1 2 (fi(t+ 1) + fj(t+ 1)) (27)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Plug (27) into (6)(7):
λaij(t+ 1) = 1
2 (λaij(t) + λ b ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (28)
λbij(t+ 1) = 1
2 (λbij(t) + λ a ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (29)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"If initialize λaij(0) = λ b ij(0) to be zero vectors for all node pairs (i, j), (28)(29) imply that λ a ij(t) = λ b ij(t) and λ k ji(t) = −λkij(t), k ∈ {a, b} will hold for all t. (27) becomes:
wij(t+ 1)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"= 1
2 (fi(t+ 1) + fj(t+ 1)) (30)
Let λij(t) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λaij(t),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
= λ,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"b ij(t), (6)(7) can be simplified as:
λij(t+ 1) = λij(t) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η
2 (fi(t+ 1)− fj(t+ 1))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"(31)
Plug (30) into the augmented Lagrangian (3) to simplify it:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T (fi − fj)
+ N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||fi − 1 2 (fi(t) + fj(t))||22) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22)
(32)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Since ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi λij(t)fj = ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi λji(t)fi and λij(t) = −λji(t), the second term in (32) can be simplified:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
T (fi − fj) = 2,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi
The last term can be expressed as:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22) =,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fi||22)
Therefore, (32) is simplified as:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
2 N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi λij(t) T fi + N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"∑ j∈Vi η(||fi − 1 2 (fi(t) + fj(t))||22) (33)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Define λi(t) = ∑ j∈Vi λij(t).,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Based on (31)(33), the original ADMM updates (4)-(7) are simplified as:
fi(t+ 1) = argmin fi O(fi, Di) + 2λi(t)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi + η ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22
λi(t+ 1) = λi(t) + η
2","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (fi(t+ 1)− fj(t+ 1)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Subtract (17) from (15) and (18) from (16):
∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) + √ D −A(Y (t+ 1)− Y ∗)",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂(t+ 1)
+W (t+ 1)(D +",B. Proof of Theorem 3.1,[0],[0]
A)(f̂(t+ 1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d (34)
Y (t+ 1) = Y (t) + θ √ D −A(f̂(t+",B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗) (35)
",B. Proof of Theorem 3.1,[0],[0]
"By convexity of O(fi, Di), for any f1i and f 2 i , there is:
(f1i − f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Let 〈·, ·〉F be frobenius inner product of two matrices, there is:
〈f̂(t+ 1)− f̂∗,∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Substitute ∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) from (34):
0 ≤ 〈f̂(t+ 1)− f̂∗,−",B. Proof of Theorem 3.1,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)〉F + 〈f̂(t+ 1)− f̂∗,−(W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F +〈f̂(t+ 1)− f̂∗,−W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))〉F",B. Proof of Theorem 3.1,[0],[0]
"(36)
Consider the right hand side of (36).",B. Proof of Theorem 3.1,[0],[0]
"Since D−A is symmetric and PSD, √ D −A is also a symmetric matrix and by (35),
〈f̂(t+ 1)− f̂∗,− √ D −A(Y (t+ 1)− Y ∗)〉F",B. Proof of Theorem 3.1,[0],[0]
= 〈− √ D −A(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗), (Y (t+ 1)− Y ∗)〉F
= −〈1 θ
(Y (t+ 1)− Y (t)), Y (t+ 1)− Y ∗〉F",B. Proof of Theorem 3.1,[0],[0]
"(37)
Rearrange (36) and use (D −A)f̂∗ = 0N×d
0",B. Proof of Theorem 3.1,[0],[0]
"≥ 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F +",B. Proof of Theorem 3.1,[0],[0]
"〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"(38)
Suppose ηi(t) ≥ θ for all t, i, i.e., the diagonal matrix W (t)− θI 0 for all t. Since D−A 0, whose eigenvalues are all non-negative, the eigenvalues of (W (t+ 1)− θI)(D −A) are thus also non-negative, i.e., (W (t+ 1)− θI)(D −A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Then for the second term of the RHS of (38), there is:
〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Therefore, 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F",B. Proof of Theorem 3.1,[0],[0]
≤ 0,B. Proof of Theorem 3.1,[0],[0]
"(39)
To simplify the notation, for a matrix X , let ||X||2J = 〈X, JX〉F , then (39) can be represented as:
1 2 ||Z(t+ 1)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
+ 1 2 ||Z(t+ 1)− Z(t)||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− 1 2 ||Z(t)− Z∗||2J(t+1) ≤ 0
implies
||Z(t+ 1)− Z(t)||2J(t+1) ≤ −||Z(t+",B. Proof of Theorem 3.1,[0],[0]
1)− Z ∗||2J(t+1) + ||Z(t)− Z ∗||2J(t) + ||Z(t)− Z ∗||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t)− Z ∗||2J(t) (40)
",B. Proof of Theorem 3.1,[0],[0]
"Suppose ηi(t+ 1) ≥ ηi(t) for all t and i, i.e., the diagonal matrix W (t+ 1)−W (t) 0 for all t. Since D+A 0, implies (W (t+ 1)−W (t))(D +A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Let U = sup
i,t,k |(fi(t)− f∗c )k| ∈ R be the finite upper bound of all nodes i, all iterations t
and all components k, then
||Z(t)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
− ||Z(t)− Z ∗||2J(t) = Tr((Z(t)− Z ∗)T,B. Proof of Theorem 3.1,[0],[0]
"(J(t+ 1)− J(t))(Z(t)− Z∗))
= Tr((f̂(t)− f̂∗)T (W (t+ 1)−W (t))(D +A)(f̂(t)− f̂∗))",B. Proof of Theorem 3.1,[0],[0]
"≤ U2(||ones(N, d)||2W (t+1)(D+A)",B. Proof of Theorem 3.1,[0],[0]
"− ones(N, d)|| 2 W (t)(D+A))
(41)
where ones(N, d) is all one’s matrix of size N × d.",B. Proof of Theorem 3.1,[0],[0]
"By (40)(41):
||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(t)− Z ∗||2J(t)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t+ 1)− Z ∗||2J(t+1) +U2(||ones(N, d)||2W",B. Proof of Theorem 3.1,[0],[0]
"(t+1)(D+A) − ||ones(N, d)|| 2 W (t)(D+A))
",B. Proof of Theorem 3.1,[0],[0]
"(42)
Sum up (42) over t from 0 to +∞ leads to:
+∞∑ t=0 ||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(0)− Z ∗||2J(0)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(+∞)− Z ∗||2J(+∞)
+U2(||ones(N, d)||2W (+∞)(D+A) − ||ones(N, d)|| 2 W (0)(D+A))
(43)
Since ηi(t) <",B. Proof of Theorem 3.1,[0],[0]
"+∞, the RHS of (43) is finite, implies that limt→+∞ ||Z(t+ 1)− Z(t)||2J(t+1) = 0 must hold.
",B. Proof of Theorem 3.1,[0],[0]
"By the definition of Z(t), J(t) and ||X||2J = 〈X, JX〉F , the following must hold
lim t→+∞
||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) = 0",B. Proof of Theorem 3.1,[0],[0]
"(44)
lim t→+∞
||Y (t+ 1)− Y (t)||2F = 0 (45)
(45) shows that Y (t) converges to a stationary point Y s, along with (16) imply limt→+∞ √ D −Af̂(t + 1) = 0.",B. Proof of Theorem 3.1,[0],[0]
"Since Null( √ D −A) = c1, f̂(t+ 1) must lie in the subspace spanned by 1 as t→∞. To satisfy (44), either of the following two statements must hold:
",B. Proof of Theorem 3.1,[0],[0]
• limt→+∞(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d
• limt→+∞W (t+ 1)(D +A)1 = limt→+∞W (t+ 1)A1 + limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
"1)Vi = 0N×1
",B. Proof of Theorem 3.1,[0],[0]
Since ηi(t) ≥,B. Proof of Theorem 3.1,[0],[0]
θ > 0,B. Proof of Theorem 3.1,[0],[0]
"for all t, implies limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
1)Vi > 0.,B. Proof of Theorem 3.1,[0],[0]
The second statement can never be true because all elements of A and W (t+ 1) are non-negative.,B. Proof of Theorem 3.1,[0],[0]
"Hence, f̂(t) should also converge to a stationary point f̂s.
",B. Proof of Theorem 3.1,[0],[0]
"Now show that the stationary point (Y s, f̂s) is (Y ∗, f̂∗).
",B. Proof of Theorem 3.1,[0],[0]
"Take limit of both sides of (15) (16), substitute f̂s, Y s yields
∇Ô(f̂s, Dall) + √ D −AY s",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂s = 0N×d (46)
",B. Proof of Theorem 3.1,[0],[0]
"√ D −Af̂s = 0N×d (47)
",B. Proof of Theorem 3.1,[0],[0]
"By (47), (46) turns into: ∇Ô(f̂s, Dall) + √ D −AY s = 0N×d",B. Proof of Theorem 3.1,[0],[0]
"(48)
Compare (47)(48) with (17)(18) in Lemma 3.1 and observe that (Y s, f̂s) satisfies the optimality condition (17)(18) and is thus the optimal point.",B. Proof of Theorem 3.1,[0],[0]
"Therefore, f(t) converges to f̂∗ and Y (t) converges to Y ∗.",B. Proof of Theorem 3.1,[0],[0]
"According to the Assumption 3 that O(fi, Di) is strongly convex and has Lipschitz continues gradients for all i ∈ N , define diagonal matrices Dm = diag([m1;m2; · · · ;mN ]) ∈",C. Proof of Theorem 3.2,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈,C. Proof of Theorem 3.2,[0],[0]
"RN×N , (20) yield:
〈f̂1 − f̂2,∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)〉F",C. Proof of Theorem 3.2,[0],[0]
"≥ 〈f̂1 − f̂2, Dm(f̂1",C. Proof of Theorem 3.2,[0],[0]
"− f̂2)〉F (49)
||∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)||2F ≤ 〈f̂1 − f̂2, DM (f̂1 − f̂2)〉F (50)
",C. Proof of Theorem 3.2,[0],[0]
"Since for any µ > 1 and any matrices C1, C2 with the same dimensions, there is:
||C1 +",C. Proof of Theorem 3.2,[0],[0]
"C2||2F ≤ µ||C1||2F + µ
µ− 1 ||C2||2F
From (34), there is:
||",C. Proof of Theorem 3.2,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)||2F ≤ µ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F
+ µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F ≤
µ2
µ− 1 ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)||2F
+µ2||W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F + µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F
(51)
Let σmin(·), σmax(·) denote the smallest nonzero singular value and the largest singular value of a matrix respectively.
",C. Proof of Theorem 3.2,[0],[0]
"For any matrices C1, C2, let C1 = UΣV T be SVD of C1, there is:
||C1C2||2F ≤ σmax(C1)||C2||2CT1
σmin(C1)",C. Proof of Theorem 3.2,[0],[0]
2||C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
||C1C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
"σmax(C1)2||C2||2F
Denote σ̄max(t+ 1) = σmax((W (t+ 1)− θI)(D −A))",C. Proof of Theorem 3.2,[0],[0]
"σ̄min(t+ 1) = σmin((W (t+ 1)− θI)(D −A))
",C. Proof of Theorem 3.2,[0],[0]
"σ̃max(t+ 1) = σmax(W (t+ 1)(D +A))
",C. Proof of Theorem 3.2,[0],[0]
"Using (50) and (D −A)f̂∗ = 0, (51) is turned into:
1 θ ||Y (t+ 1)− Y ∗||2F ≤
µ2
θσmin(D −A)(µ− 1) ||f̂(t+ 1)− f̂∗||2DM
+ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) +
µσ̄max(t+ 1) 2
θσmin(D",C. Proof of Theorem 3.2,[0],[0]
−A)(µ− 1),C. Proof of Theorem 3.2,[0],[0]
"||(f̂(t+ 1)− f̂∗)||2F
Adding ||f̂(t+ 1)− f̂∗||2W (t+1)(D+A) at both sides leads to:
||Z(t+ 1)− Z∗||2J(t+1) ≤ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A)
+||f̂(t+ 1)− f̂∗||2µ2DM+µσ̄max(t+1)2IN θσmin(D−A)(µ−1)",C. Proof of Theorem 3.2,[0],[0]
"+W (t+1)(D+A)
(52)
",C. Proof of Theorem 3.2,[0],[0]
"Since δ(t+ 1)µ2σ̃max(t+ 1)
θσmin(D −A) ≤ 1 (53)
and
δ(t+ 1)( µσ̄max(t+ 1) 2IN + µ2DM θσmin(D −A)(µ− 1)",C. Proof of Theorem 3.2,[0],[0]
+W (t+ 1)(D +A)),C. Proof of Theorem 3.2,[0],[0]
"2(W (t+ 1)− θI)(D −A) + 2Dm (54)
",C. Proof of Theorem 3.2,[0],[0]
"It implies from (52) that:
δ(t+ 1)||Z(t+ 1)− Z∗||2J(t+1) ≤ ||f̂(t+ 1)− f̂(t)||",C. Proof of Theorem 3.2,[0],[0]
"2 W (t+1)(D+A) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm ≤ ||Z(t+ 1)− Z(t)||2J(t+1) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm (55)
",C. Proof of Theorem 3.2,[0],[0]
"Substituting f̂1 with f̂(t+ 1) and f̂2 with f̂∗ and the gradient difference from (34) in (49) leads to:
〈f̂(t+ 1)− f̂∗, √ D −A(Y (t+ 1)− Y ∗)〉F",C. Proof of Theorem 3.2,[0],[0]
"+ 〈f̂(t+ 1)− f̂∗,W (t+ 1)(D +",C. Proof of Theorem 3.2,[0],[0]
"A)(f̂(t+ 1)− f̂(t))〉F
+〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F ≤",C. Proof of Theorem 3.2,[0],[0]
"−〈f̂(t+ 1)− f̂∗, Dm(f̂(t+ 1)− f̂∗)〉F
Similar to the proof of Theorem 3.1, using the definition of Z(t+ 1), Z∗, J(t+ 1) and (D −A)f̂∗ = 0, there is:
||Z(t+ 1)− Z∗||2J(t+1) ≤ −||Z(t+",C. Proof of Theorem 3.2,[0],[0]
1)− Z(t)|| 2 J(t+1) + ||Z(t)− Z ∗||2J(t+1),C. Proof of Theorem 3.2,[0],[0]
"− ||f̂(t+ 1)− f̂ ∗||22Dm+2(W (t+1)−θI)(D−A)
(56)
",C. Proof of Theorem 3.2,[0],[0]
"Sum up (55) and (56) gives:
(1 + δ(t+ 1))||Z(t+ 1)− Z∗||2J(t+1) ≤ ||Z(t)−",C. Proof of Theorem 3.2,[0],[0]
"Z ∗||2J(t+1)
",C. Proof of Theorem 3.2,[0],[0]
"Let mo = mini∈N {mi}, MO = maxi∈N {Mi}.",C. Proof of Theorem 3.2,[0],[0]
"One δ(t+ 1) that satisfies (53) and (54) could be:
min{θσmin(D −A) µ2σ̃max(t+",C. Proof of Theorem 3.2,[0],[0]
"1) , 2mo + 2σ̄min(t+ 1) µ2M2O+µσ̄max(t+1) 2
θσmin(D−A)(µ−1) + σ̃max(t+ 1) }",C. Proof of Theorem 3.2,[0],[0]
"In the following proof, use the uppercase letters and lowercase letters to denote random variables and the corresponding realizations.
",D. Proof of Theorem 4.1,[0],[0]
"Since the modified ADMM is randomized, denote Fi(t) as the random variable of the result that node i broadcasts in t-th iteration, of which the realization is fi(t).",D. Proof of Theorem 4.1,[0],[0]
"Define F (t) = {Fi(t)}Ni=1 whose realization is {fi(t)}Ni=1.
",D. Proof of Theorem 4.1,[0],[0]
"Let FF (0:t)(·) be the joint probability distribution of F (0 : t) = {F (r)}tr=0, and FF (t)(·) be the distribution of F (t), by chain rule:
FF (0:T )({f(r)}Tr=0) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0:T−1)({f(r)}T−1r=0 ) ·FF (T )(f(T )|{f(r)} T−1 r=0 ) = · · ·
= FF (0)(f(0)) · T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0)
For two neighboring datasets Dall and D̂all of the network, the ratio of joint probabilities is given by:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) =",D. Proof of Theorem 4.1,[0],[0]
FF (0)(f(0)|Dall) FF (0)(f(0)|D̂all) · T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all)
(57)
Since fi(0) is randomly selected for all i, which is independent of dataset, there is FF (0)(f(0)|Dall) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0)(f(0)|D̂all).
",D. Proof of Theorem 4.1,[0],[0]
"First only consider t-th iteration, since the primal variable is updated according to (25), by KKT optimality condition, ∇fiL priv i (t)|fi=fi(t) = 0, implies:
i(t) =",D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 yni L ′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i −
1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
"+ 2λi(t− 1))
",D. Proof of Theorem 4.1,[0],[0]
− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)),D. Proof of Theorem 4.1,[0],[0]
"(58)
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, Fi(t) and Ei(t) will be bijective:
• For any Fi(t) with the realization fi(t), ∃ an unique Ei(t) = i(t) having the form of (58) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"• Since the Lagrangian Lprivi (t) is strictly convex (by Assumption 4,5), its minimizer is unique, implies that for any Ei(t) with the realization i(t), ∃ an unique Fi(t) = fi(t) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"Since each node i generates i(t) independently, fi(t) is also independent from each other.",D. Proof of Theorem 4.1,[0],[0]
"Let FFi(t)(·) be the distribution of Fi(t), there is:
FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all) = N∏ v=1 FFv(t)(fv(t)|{fv(r)} t−1 r=0, Dv) FFv(t)(fv(t)|{fv(r)} t−1 r=0, D̂v) = FFi(t)(fi(t)|{fi(r)}",D. Proof of Theorem 4.1,[0],[0]
"t−1 r=0, Di) FFi(t)(fi(t)|{fi(r)} t−1 r=0, D̂i)
(59)
",D. Proof of Theorem 4.1,[0],[0]
"Since two neighboring datasets Dall and D̂all only have at most one data point that is different, the second equality holds is because of the fact that this different data point could only be possessed by one node, say node i.",D. Proof of Theorem 4.1,[0],[0]
"Then there is Dj = D̂j for j 6= i.
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, let gt(·, Di) :",D. Proof of Theorem 4.1,[0],[0]
Rd → Rd denote the one-to-one mapping from Ei(t) to Fi(t) using dataset Di.,D. Proof of Theorem 4.1,[0],[0]
"Let FEi(t)(·) be the probability density of Ei(t), by Jacobian transformation, there is4:
FFi(t)(fi(t)|Di)",D. Proof of Theorem 4.1,[0],[0]
"= FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))| (60)
where g−1t (fi(t), Di) is the mapping from Fi(t) to Ei(t) using data Di as shown in (58) and J(g −1 t (fi(t), Di)) is the Jacobian matrix of it.
",D. Proof of Theorem 4.1,[0],[0]
"Without loss of generality, let Di and D̂i be only different in the first data point, say (x1i , y 1 i ) and (x̂ 1",D. Proof of Theorem 4.1,[0],[0]
"i , ŷ 1 i ) respectively.",D. Proof of Theorem 4.1,[0],[0]
"Then by (59)(60), (57) yields:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) = T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i)) ·",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))|
(61)
4We believe that there is a critical mistake in (Zhang & Zhu, 2017) and the original paper (Chaudhuri et al., 2011) where the objective perturbation method was proposed.",D. Proof of Theorem 4.1,[0],[0]
"A wrong mapping is used in both work:
FFi(t)(fi(t)|Di) = FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))|−1
Consider the first part, Ei(t) ∼ exp{−αi(t)|| ||}, let ̂i(t) = g−1t (fi(t), D̂i) and i(t) =",D. Proof of Theorem 4.1,[0],[0]
"g−1t (fi(t), Di)
T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
= T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
exp(αi(t)(||̂i(t)||,D. Proof of Theorem 4.1,[0],[0]
− || i(t)||)),D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 αi(t)||̂i(t)− i(t)||) (62)
",D. Proof of Theorem 4.1,[0],[0]
"By (58), Assumptions 4 and the facts that ||xni ||2 ≤ 1 (pre-normalization), yni ∈ {+1,−1}.
",D. Proof of Theorem 4.1,[0],[0]
"||̂i(t)− i(t)|| = 1
2ηi(t)Vi
C Bi · ||y1iL ′(y1i fi(t)Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x1i,D. Proof of Theorem 4.1,[0],[0]
− ŷ1iL ′(ŷ1i fi(t)T x̂1i ),D. Proof of Theorem 4.1,[0],[0]
"x̂1i || ≤
C
ηi(t)ViBi
(62) can be bounded: T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 Cαi(t) ηi(t)ViBi ) (63)
Consider the second part, the Jacobian matrix J(g−1t (fi(t), Di)) is:
J(g−1t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
=,D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 L ′′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
i (x n i ) T,D. Proof of Theorem 4.1,[0],[0]
− 1 2ηi(t)Vi ρ N ∇2R(fi(t))−,D. Proof of Theorem 4.1,[0],[0]
"Id
Let G(t) =",D. Proof of Theorem 4.1,[0],[0]
C2ηi(t)ViBi (L ′′(ŷ1i fi(t) T x̂1i )x̂ 1,D. Proof of Theorem 4.1,[0],[0]
i (x̂ 1 i ) T −L ′′(y1i fi(t)Tx1i ),D. Proof of Theorem 4.1,[0],[0]
x1i (x1i )T ) and H(t) =,D. Proof of Theorem 4.1,[0],[0]
"−J(g −1 t (fi(t), Di)), there is:
|det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| = |det(H(t))| |det(H(t) +G(t))| =
1
|det(I +H(t)−1G(t))| =
1 | ∏r j=1(1 + λj(H(t) −1G(t)))|
where λj(H(t)−1G(t)) denotes the j-th largest eigenvalue of H(t)−1G(t).",D. Proof of Theorem 4.1,[0],[0]
"Since G(t) has rank at most 2, implies H(t)−1G(t) also has rank at most 2.
",D. Proof of Theorem 4.1,[0],[0]
"Because θ is determined such that 2c1 < BiC ( ρ N + 2θVi), and θ ≤ ηi(t) holds for all node i and iteration t, which implies:
c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
"< 1 2 (64)
",D. Proof of Theorem 4.1,[0],[0]
"By Assumptions 4 and 5, the eigenvalue of H(t) and G(t) satisfy:
λj(H(t))",D. Proof of Theorem 4.1,[0],[0]
"≥ ρ
2ηi(t)ViN + 1 > 0
",D. Proof of Theorem 4.1,[0],[0]
− Cc1 2ηi(t)ViBi ≤,D. Proof of Theorem 4.1,[0],[0]
λj(G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ Cc1 2ηi(t)ViBi
",D. Proof of Theorem 4.1,[0],[0]
"Implies:
− c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
≤ λj(H(t)−1G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ c1 Bi C ( ρ N + 2ηi(t)Vi)
",D. Proof of Theorem 4.1,[0],[0]
"By (64):
−1 2 ≤ λj(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 2
Since λmin(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"> −1, there is:
1 |1 + λmax(H(t)−1G(t))|2",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 |det(I +H(t)−1G(t))| ≤ 1 |1 + λmin(H(t)−1G(t))|2
Therefore,
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1
1
|1− c1Bi",D. Proof of Theorem 4.1,[0],[0]
"C ( ρ N +2ηi(t)Vi)
|2 = exp(− T∑ t=1 2 ln(1− c1 Bi C",D. Proof of Theorem 4.1,[0],[0]
( ρ N + 2ηi(t)Vi) )),D. Proof of Theorem 4.1,[0],[0]
"(65)
Since for any real number x ∈",D. Proof of Theorem 4.1,[0],[0]
"[0, 0.5], − ln(1 − x) < 1.4x.",D. Proof of Theorem 4.1,[0],[0]
"By condition (64), (65) can be bounded with a simper expression:
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤ exp",D. Proof of Theorem 4.1,[0],[0]
( T∑ t=1 2.8c1 Bi C ( ρ N + 2ηi(t)Vi) ),D. Proof of Theorem 4.1,[0],[0]
≤ exp( T∑ t=1 1.4Cc1 ηi(t)ViBi ),D. Proof of Theorem 4.1,[0],[0]
"(66)
Combine (63)(66), (61) can be bounded:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) ≤ exp( T∑ t=1 ( 1.4Cc1 ηi(t)ViBi + Cαi(t) ηi(t)ViBi ))",D. Proof of Theorem 4.1,[0],[0]
"= exp( T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t)))
",D. Proof of Theorem 4.1,[0],[0]
"Therefore, the total privacy loss during T iterations can be bounded by any β:
β ≥ max i∈N { T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t))}
E. Inference of Attackers when ηi(t) is Non-private By KKT optimality condition in each iteration, we have:
i(t) +",D. Proof of Theorem 4.1,[0],[0]
"1
2ηi(t)Vi
C Bi y1iL ′(y1i fi(t) Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x 1,D. Proof of Theorem 4.1,[0],[0]
"i = −
1
2ηi(t)Vi
C
Bi",D. Proof of Theorem 4.1,[0],[0]
Bi∑ n=2 yni L ′(yni fi(t),D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i
− 1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
+,D. Proof of Theorem 4.1,[0],[0]
"2λi(t− 1))− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)) .
",D. Proof of Theorem 4.1,[0],[0]
In this case the attacker can compute the RHS of (67) completely.,D. Proof of Theorem 4.1,[0],[0]
"Furthermore, since Ei(t) is zero-mean, over a large number of iterations we will have 1T ∑T t=1 i(t)",D. Proof of Theorem 4.1,[0],[0]
"≈ 0 with high probability, which then allows the attacker to determine the features of the unknown individual up to a scaling factor, i.e., it can determine the second term on the LHS as a scalar multiplied with x1i .",D. Proof of Theorem 4.1,[0],[0]
"Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion.",abstractText,[0],[0]
During this iterative process the leakage of data privacy arises.,abstractText,[0],[0]
"A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process.",abstractText,[0],[0]
We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously.,abstractText,[0],[0]
The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size.,abstractText,[0],[0]
The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.,abstractText,[0],[0]
Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms ,title,[0],[0]
"Topic modeling algorithms, such as Latent Dirichlet Allocation (Blei et al., 2003) and related methods (Blei, 2012), are often used to learn a set of latent topics for a corpus, and predict the probabilities of each word in each document belonging to each topic (Teh et al., 2006; Newman et al., 2006; Toutanova and Johnson, 2008; Porteous et al., 2008; Johnson, 2010; Xie and Xing, 2013; Hingmire et al., 2013).
",1 Introduction,[0],[0]
Conventional topic modeling algorithms such as these infer document-to-topic and topic-to-word distributions from the co-occurrence of words within documents.,1 Introduction,[0],[0]
"But when the training corpus of documents is small or when the documents are short, the resulting distributions might be based on little evidence.",1 Introduction,[0],[0]
"Sahami and Heilman (2006) and Phan et al.
(2011) show that it helps to exploit external knowledge to improve the topic representations.",1 Introduction,[0],[0]
Sahami and Heilman (2006) employed web search results to improve the information in short texts.,1 Introduction,[0],[0]
"Phan et al. (2011) assumed that the small corpus is a sample of topics from a larger corpus like Wikipedia, and then use the topics discovered in the larger corpus to help shape the topic representations in the small corpus.",1 Introduction,[0],[0]
"However, if the larger corpus has many irrelevant topics, this will “use up” the topic space of the model.",1 Introduction,[0],[0]
"In addition, Petterson et al. (2010) proposed an extension of LDA that uses external information about word similarity, such as thesauri and dictionaries, to smooth the topic-to-word distribution.
",1 Introduction,[0],[0]
"Topic models have also been constructed using latent features (Salakhutdinov and Hinton, 2009; Srivastava et al., 2013; Cao et al., 2015).",1 Introduction,[0],[0]
"Latent feature (LF) vectors have been used for a wide range of NLP tasks (Glorot et al., 2011; Socher et al., 2013; Pennington et al., 2014).",1 Introduction,[0],[0]
"The combination of values permitted by latent features forms a high dimensional space which makes it is well suited to model topics of very large corpora.
",1 Introduction,[0],[0]
"Rather than relying solely on a multinomial or latent feature model, as in Salakhutdinov and Hinton (2009), Srivastava et al. (2013)",1 Introduction,[0],[0]
"and Cao et al. (2015), we explore how to take advantage of both latent feature and multinomial models by using a latent feature representation trained on a large external corpus to supplement a multinomial topic model estimated from a smaller corpus.
",1 Introduction,[0],[0]
"Our main contribution is that we propose two new latent feature topic models which integrate latent feature word representations into two Dirichlet
ar X
iv :1
81 0.
06 30
6v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
5 O
ct 2
multinomial topic models: a Latent Dirichlet Allocation (LDA) model (Blei et al., 2003) and a onetopic-per-document Dirichlet Multinomial Mixture (DMM) model (Nigam et al., 2000).",1 Introduction,[0],[0]
"Specifically, we replace the topic-to-word Dirichlet multinomial component which generates the words from topics in each Dirichlet multinomial topic model by a twocomponent mixture of a Dirichlet multinomial component and a latent feature component.
",1 Introduction,[0],[0]
"In addition to presenting a sampling procedure for the new models, we also compare using two different sets of pre-trained latent feature word vectors with our models.",1 Introduction,[0],[0]
"We achieve significant improvements on topic coherence evaluation, document clustering and document classification tasks, especially on corpora of short documents and corpora with few documents.",1 Introduction,[0],[0]
"The Latent Dirichlet Allocation (LDA) topic model (Blei et al., 2003) represents each document d as a probability distribution θd over topics, where each topic z is modeled by a probability distribution φz over words in a fixed vocabulary W .
",2.1 LDA model,[0],[0]
"As presented in Figure 1, where α and β are hyper-parameters and T is number of topics, the generative process for LDA is described as follows:
θd ∼ Dir(α) zdi ∼ Cat(θd) φz ∼ Dir(β) wdi ∼ Cat(φzdi )
where Dir and Cat stand for a Dirichlet distribution and a categorical distribution, and zdi is the topic indicator for the ith word wdi in document d. Here, the topic-to-word Dirichlet multinomial component generates the word wdi by drawing it from the categorical distribution Cat(φzdi ) for topic zdi .
",2.1 LDA model,[0],[0]
We follow the Gibbs sampling algorithm for estimating LDA topic models as described by Griffiths and Steyvers (2004).,2.1 LDA model,[0],[0]
"By integrating out θ and φ, the algorithm samples the topic zdi for the current i th
word wdi in document d using the conditional distribution P(zdi | Z¬di), where Z¬di denotes the topic assignments of all the other words in the document collection D, so:
P(zdi = t | Z¬di) ∝",2.1 LDA model,[0],[0]
"(N td¬i + α) N t,wdi ¬di +",2.1 LDA model,[0],[0]
"β
N t¬di + V β (",2.1 LDA model,[0],[0]
"1)
Notation: N t,wd is the rank-3 tensor that counts the number of times that word w is generated from topic t in document d by the Dirichlet multinomial component, which in section 2.1 belongs to the LDA model, while in section 2.2 belongs to the DMM model.",2.1 LDA model,[0],[0]
"When an index is omitted, it indicates summation over that index (so Nd is the number of words in document d).
",2.1 LDA model,[0],[0]
"We write the subscript ¬d for the document collection D with document d removed, and the subscript ¬di for D with just the ith word in document d removed, while the subscript d¬i represents document d without its ith word.",2.1 LDA model,[0],[0]
"For example, N t¬di is the number of words labelled a topic t, ignoring the ith word of document d. V is the size of the vocabulary, V = |W",2.1 LDA model,[0],[0]
|.,2.1 LDA model,[0],[0]
Applying topic models for short or few documents for text clustering is more challenging because of data sparsity and the limited contexts in such texts.,2.2 DMM model for short texts,[0],[0]
"One approach is to combine short texts into long pseudo-documents before training LDA (Hong and Davison, 2010; Weng et al., 2010; Mehrotra et al., 2013).",2.2 DMM model for short texts,[0],[0]
"Another approach is to assume that there is only one topic per document (Nigam et al., 2000; Zhao et al., 2011; Yin and Wang, 2014).
",2.2 DMM model for short texts,[0],[0]
"In the Dirichlet Multinomial Mixture (DMM) model (Nigam et al., 2000), each document is assumed to only have one topic.",2.2 DMM model for short texts,[0],[0]
"The process of generating a document d in the collection D, as shown in Figure 1, is to first select a topic assignment for the document, and then the topic-to-word Dirichlet multinomial component generates all the words in the document from the same selected topic:
θ ∼ Dir(α) zd ∼ Cat(θ) φz ∼ Dir(β) wdi ∼ Cat(φzd)
Yin and Wang (2014) introduced a collapsed Gibbs sampling algorithm for the DMM model in
which a topic zd is sampled for the document d using the conditional probability P(zd | Z¬d), where Z¬d denotes the topic assignments of all the other documents, so:
",2.2 DMM model for short texts,[0],[0]
P(zd = t | Z¬d) ∝,2.2 DMM model for short texts,[0],[0]
(Mt¬d + α) Γ(Nt¬d,2.2 DMM model for short texts,[0],[0]
"+ V β)
Γ(Nt¬d",2.2 DMM model for short texts,[0],[0]
"+Nd + V β) ∏ w∈W Γ(Nt,w¬d +N w d + β) Γ(Nt,w¬d + β) (2)
Notation: M t¬d is the number of documents assigned to topic t excluding the current document d; Γ is the Gamma function.",2.2 DMM model for short texts,[0],[0]
"Traditional count-based methods (Deerwester et al., 1990; Lund and Burgess, 1996; Bullinaria and Levy, 2007) for learning real-valued latent feature (LF) vectors rely on co-occurrence counts.",2.3 Latent feature vector models,[0],[0]
"Recent approaches based on deep neural networks learn vectors by predicting words given their window-based context (Collobert and Weston, 2008; Mikolov et al., 2013; Pennington et al., 2014; Liu et al., 2015).
",2.3 Latent feature vector models,[0],[0]
Mikolov et al. (2013)’s method maximizes the log likelihood of each word given its context.,2.3 Latent feature vector models,[0],[0]
Pennington et al. (2014) used back-propagation to minimize the squared error of a prediction of the logfrequency of context words within a fixed window of each word.,2.3 Latent feature vector models,[0],[0]
Word vectors can be trained directly on a new corpus.,2.3 Latent feature vector models,[0],[0]
"In our new models, however, in order to incorporate the rich information from very large datasets, we utilize pre-trained word vectors that were trained on external billion-word corpora.",2.3 Latent feature vector models,[0],[0]
"In this section, we propose two novel probabilistic topic models, which we call the LF-LDA and the LFDMM, that combine a latent feature model with either an LDA or DMM model.",3 New latent feature topic models,[0],[0]
"We also present Gibbs sampling procedures for our new models.
",3 New latent feature topic models,[0],[0]
"In general, LF-LDA and LF-DMM are formed by taking the original Dirichlet multinomial topic models LDA and DMM, and replacing their topic-to-
word Dirichlet multinomial component that generates words from topics with a two-component mixture of a topic-to-word Dirichlet multinomial component and a latent feature component.
",3 New latent feature topic models,[0],[0]
"Informally, the new models have the structure of the original Dirichlet multinomial topic models, as shown in Figure 2, with the addition of two matrices τ and ω of latent feature weights, where τ t and ωw are the latent-feature vectors associated with topic t and word w respectively.
",3 New latent feature topic models,[0],[0]
"Our latent feature model defines the probability that it generates a word given the topic as the categorical distribution CatE with:
CatE(w | τ tω>) = exp(τ t · ωw)∑
w′∈W exp(τ t · ωw′) (3)
CatE is a categorical distribution with log-space parameters, i.e. CatE(w | u) ∝ exp(uw).",3 New latent feature topic models,[0],[0]
"As τ t and ωw are (row) vectors of latent feature weights, so τ tω> is a vector of “scores” indexed by words.",3 New latent feature topic models,[0],[0]
"ω is fixed because we use pre-trained word vectors.
",3 New latent feature topic models,[0],[0]
"In the next two sections 3.1 and 3.2, we explain the generative processes of our new models LF-LDA and LF-DMM.",3 New latent feature topic models,[0],[0]
"We then present our Gibbs sampling procedures for the models LF-LDA and LF-DMM in the sections 3.3 and 3.4, respectively, and explain how we estimate τ in section 3.5.",3 New latent feature topic models,[0],[0]
"The LF-LDA model generates a document as follows: a distribution over topics θd is drawn for document d; then for each ith word wdi (in sequential order that words appear in the document), the model chooses a topic indicator zdi , a binary indicator variable sdi is sampled from a Bernoulli distribution to determine whether the word wdi is to be generated by the Dirichlet multinomial or latent feature component, and finally the word is generated from the chosen topic by the determined topic-toword model.",3.1 Generative process for the LF-LDA model,[0],[0]
"The generative process is:
θd ∼ Dir(α) zdi ∼ Cat(θd) φz ∼ Dir(β) sdi ∼ Ber(λ) wdi ∼ (1− sdi)Cat(φzdi ) + sdiCatE(τ zdi ω >)
where the hyper-parameter λ is the probability of a word being generated by the latent feature topic-toword model and Ber(λ) is a Bernoulli distribution with success probability λ.",3.1 Generative process for the LF-LDA model,[0],[0]
Our LF-DMM model uses the DMM model assumption that all the words in a document share the same topic.,3.2 Generative process for the LF-DMM model,[0],[0]
"Thus, the process of generating a document in a document collection with our LF-DMM is as follows: a distribution over topics θ is drawn for the document collection; then the model draws a topic indicator zd for the entire document d; for every ith word wdi in the document d, a binary indicator variable sdi is sampled from a Bernoulli distribution to determine whether the Dirichlet multinomial or latent feature component will be used to generate the word wdi , and finally the word is generated from the same topic zd by the determined component.",3.2 Generative process for the LF-DMM model,[0],[0]
"The generative process is summarized as:
θ ∼ Dir(α) zd ∼ Cat(θ) φz ∼ Dir(β) sdi ∼ Ber(λ) wdi ∼ (1− sdi)Cat(φzd) + sdiCatE(τ",3.2 Generative process for the LF-DMM model,[0],[0]
zd ω >),3.2 Generative process for the LF-DMM model,[0],[0]
"From the generative model of LF-LDA in Figure 2, by integrating out θ and φ, we use the Gibbs sampling algorithm (Robert and Casella, 2004) to perform inference to calculate the conditional topic assignment probabilities for each word.",3.3 Inference in LF-LDA model,[0],[0]
"The outline of the Gibbs sampling algorithm for the LF-LDA model is detailed in Algorithm 1.
",3.3 Inference in LF-LDA model,[0],[0]
"Algorithm 1: An approximate Gibbs sampling algorithm for the LF-LDA model
Initialize the word-topic variables zdi using the LDA sampling algorithm for iteration iter = 1, 2, ... do for topic t = 1, 2, ..., T do
τ",3.3 Inference in LF-LDA model,[0],[0]
"t = arg maxτ t P(τ t | Z,S) for document d = 1, 2, ..., |D| do
for word index i = 1, 2, ...,",3.3 Inference in LF-LDA model,[0],[0]
"Nd do sample zdi and sdi from P(zdi = t, sdi | Z¬di ,S¬di , τ ,ω)
Here, S denotes the distribution indicator variables for the whole document collection D. Instead of sampling τ",3.3 Inference in LF-LDA model,[0],[0]
"t from the posterior, we perform MAP estimation as described in the section 3.5.
",3.3 Inference in LF-LDA model,[0],[0]
"For sampling the topic zdi and the binary indicator variable sdi of the i
th word wdi in the document d, we integrate out sdi in order to sample zdi and then
sample sdi given zdi .",3.3 Inference in LF-LDA model,[0],[0]
"We sample the topic zdi using the conditional distribution as follows:
P(zdi = t | Z¬di , τ ,ω) ∝",3.3 Inference in LF-LDA model,[0],[0]
"(N td¬i +K
t d¬i + α)(
(1− λ) N t,wdi ¬di + β
N t¬di + V β +",3.3 Inference in LF-LDA model,[0],[0]
λCatE(wdi,3.3 Inference in LF-LDA model,[0],[0]
| τ t ω>) ),3.3 Inference in LF-LDA model,[0],[0]
"(4) Then we sample sdi conditional on zdi = t with:
P(sdi=s | zdi=t) ∝  (1− λ)N t,wdi ¬di +β Nt¬di",3.3 Inference in LF-LDA model,[0],[0]
+V β for s,3.3 Inference in LF-LDA model,[0],[0]
"= 0
λ CatE(wdi |τ t ω>)",3.3 Inference in LF-LDA model,[0],[0]
"for s = 1 (5)
Notation: Due to the new models’ mixture architecture, we separate out the counts for each of the two components of each model.",3.3 Inference in LF-LDA model,[0],[0]
"We define the rank3 tensor Kt,wd as the number of times a word w in document d is generated from topic t by the latent feature component of the generative LF-LDA or LFDMM model.
",3.3 Inference in LF-LDA model,[0],[0]
"We also extend the earlier definition of the tensor N t,wd as the number of times a word w in document d is generated from topic t by the Dirichlet multinomial component of our combined models, which in section 3.3 refers to the LF-LDA model, while in section 3.4 refers to the LF-DMM model.",3.3 Inference in LF-LDA model,[0],[0]
"For both tensors K and N , omitting an index refers to summation over that index and negation ¬ indicates exclusion as before.",3.3 Inference in LF-LDA model,[0],[0]
So Nwd +K w d is the total number of times the word type w appears in the document d.,3.3 Inference in LF-LDA model,[0],[0]
"For the LF-DMM model, we integrate out θ and φ, and then sample the topic zd and the distribution selection variables sd for document d using Gibbs sampling as outlined in Algorithm 2.
",3.4 Inference in LF-DMM model,[0],[0]
"Algorithm 2: An approximate Gibbs sampling algorithm for the LF-DMM model
Initialize the word-topic variables zdi using the DMM sampling algorithm for iteration iter = 1, 2, ... do for topic t = 1, 2, ..., T do
τ",3.4 Inference in LF-DMM model,[0],[0]
"t = arg maxτ t P(τ t | Z,S) for document d = 1, 2, ..., |D| do
sample zd and sd from P(zd = t, sd | Z¬d,S¬d, τ ,ω)
",3.4 Inference in LF-DMM model,[0],[0]
"As before in Algorithm 1, we also use MAP estimation of τ as detailed in section 3.5 rather than
sampling from the posterior.",3.4 Inference in LF-DMM model,[0],[0]
"The conditional distribution of topic variable and selection variables for document d is:
P(zd = t, sd | Z¬d,S¬d, τ ,ω)
∝",3.4 Inference in LF-DMM model,[0],[0]
"λKd (1− λ)Nd (M t¬d + α) Γ(N t¬d + V β)
Γ(N t¬d",3.4 Inference in LF-DMM model,[0],[0]
+,3.4 Inference in LF-DMM model,[0],[0]
"Nd + V β)∏ w∈W Γ(N t,w¬d +N w d + β) Γ(N t,w¬d + β) ∏ w∈W",3.4 Inference in LF-DMM model,[0],[0]
CatE(w | τ t ω>)K,3.4 Inference in LF-DMM model,[0],[0]
"w d (6)
Unfortunately the ratios of Gamma functions makes it difficult to integrate out sd in this distribution P. As zd and sd are not independent, it is computationally expensive to directly sample from this distribution, as there are 2(N w d +K w d ) different values of sd.",3.4 Inference in LF-DMM model,[0],[0]
"So we approximate P with a distribution Q that factorizes across words as follows:
Q(zd = t, sd | Z¬d,S¬d, τ ,ω) ∝",3.4 Inference in LF-DMM model,[0],[0]
"λKd (1− λ)Nd (M t¬d + α) (7)∏
w∈W
( N t,w¬d + β
N t¬d + V β )",3.4 Inference in LF-DMM model,[0],[0]
Nwd ∏,3.4 Inference in LF-DMM model,[0],[0]
w∈W CatE(w | τ t ω>)K,3.4 Inference in LF-DMM model,[0],[0]
"w d
This simpler distribution Q can be viewed as an approximation to P in which the topic-word “counts” are “frozen” within a document.",3.4 Inference in LF-DMM model,[0],[0]
This approximation is reasonably accurate for short documents.,3.4 Inference in LF-DMM model,[0],[0]
This distribution Q simplifies the coupling between zd and sd.,3.4 Inference in LF-DMM model,[0],[0]
This enables us to integrate out sd in Q.,3.4 Inference in LF-DMM model,[0],[0]
"We first sample the document topic zd for document d using Q(zd), marginalizing over sd:
Q(zd = t | Z¬d, τ ,ω)
∝",3.4 Inference in LF-DMM model,[0],[0]
(M t¬d + α),3.4 Inference in LF-DMM model,[0],[0]
∏,3.4 Inference in LF-DMM model,[0],[0]
"w∈W
( (1− λ) N t,w ¬d +β
Nt¬d+V β
+ λ",3.4 Inference in LF-DMM model,[0],[0]
"CatE(w | τ t ω>)
)(Nwd +Kwd ) (8)
Then we sample the binary indicator variable sdi for each ith word wdi in document d conditional on zd = t from the following distribution:
Q(sdi=s | zd = t) ∝
{ (1− λ)N t,wdi ¬d +β
Nt¬d+V β for s = 0
λ CatE(wdi | τ t ω>) for s = 1 (9)",3.4 Inference in LF-DMM model,[0],[0]
"To estimate the topic vectors after each Gibbs sampling iteration through the data, we apply regularized maximum likelihood estimation.",3.5 Learning latent feature vectors for topics,[0],[0]
"Applying MAP estimation to learn log-linear models for topic models is also used in SAGE (Eisenstein et al., 2011) and SPRITE (Paul and Dredze, 2015).",3.5 Learning latent feature vectors for topics,[0],[0]
"How-
ever, unlike our models, those models do not use latent feature word vectors to characterize topic-word distributions.",3.5 Learning latent feature vectors for topics,[0],[0]
The negative log likelihood of the corpus L under our model factorizes topic-wise into factors Lt for each topic.,3.5 Learning latent feature vectors for topics,[0],[0]
"With L2 regularization1 for topic t, these are:
Lt = − ∑ w∈W Kt,w ( τ t · ωw − log ( ∑ w′∈W exp(τ t · ωw′) ))
",3.5 Learning latent feature vectors for topics,[0],[0]
"+ µ ‖ τ t ‖22 (10)
",3.5 Learning latent feature vectors for topics,[0],[0]
The MAP estimate of topic vectors τ t is obtained by minimizing the regularized negative log likelihood.,3.5 Learning latent feature vectors for topics,[0],[0]
"The derivative with respect to the jth element of the vector for topic t is: ∂Lt ∂τ t,j = − ∑ w∈W Kt,w ( ωw,j − ∑ w′∈W ωw′,jCatE(w ′",3.5 Learning latent feature vectors for topics,[0],[0]
"| τ tω>)
)",3.5 Learning latent feature vectors for topics,[0],[0]
"+ 2µτ t,j (11)
",3.5 Learning latent feature vectors for topics,[0],[0]
"We used L-BFGS2(Liu and Nocedal, 1989) to find the topic vector τ t that minimizes Lt.",3.5 Learning latent feature vectors for topics,[0],[0]
"To investigate the performance of our new LF-LDA and LF-DMM models, we compared their performance against baseline LDA and DMM models on topic coherence, document clustering and document classification evaluations.",4 Experiments,[0],[0]
"The topic coherence evaluation measures the coherence of topic-word associations, i.e. it directly evaluates how coherent the assignment of words to topics is.",4 Experiments,[0],[0]
"The document clustering and document classification tasks evaluate how useful the topics assigned to documents are in clustering and classification tasks.
",4 Experiments,[0],[0]
"Because we expect our new models to perform comparatively well in situations where there is little data about topic-to-word distributions, our experiments focus on corpora with few or short documents.",4 Experiments,[0],[0]
"We also investigated which values of λ perform well, and compared the performance when using two different sets of pre-trained word vectors in these new models.",4 Experiments,[0],[0]
"We experimented with two state-of-the-art sets of pre-trained word vectors here.
",4.1.1 Distributed word representations,[0],[0]
1The L2 regularizer constant was set to µ = 0.01.,4.1.1 Distributed word representations,[0],[0]
"2We used the L-BFGS implementation from the Mallet
toolkit (McCallum, 2002).
",4.1.1 Distributed word representations,[0],[0]
Google word vectors3 are pre-trained 300- dimensional vectors for 3 million words and phrases.,4.1.1 Distributed word representations,[0],[0]
"These vectors were trained on a 100 billion word subset of the Google News corpus by using the Google Word2Vec toolkit (Mikolov et al., 2013).",4.1.1 Distributed word representations,[0],[0]
Stanford vectors4 are pre-trained 300-dimensional vectors for 2 million words.,4.1.1 Distributed word representations,[0],[0]
"These vectors were learned from 42-billion tokens of Common Crawl web data using the Stanford GloVe toolkit (Pennington et al., 2014).
",4.1.1 Distributed word representations,[0],[0]
"We refer to our LF-LDA and LF-DMM models using Google and Stanford word vectors as w2v-LDA, glove-LDA, w2v-DMM and glove-DMM.",4.1.1 Distributed word representations,[0],[0]
"We conducted experiments on the 20-Newsgroups dataset, the TagMyNews news dataset and the Sanders Twitter corpus.
",4.1.2 Experimental datasets,[0],[0]
"The 20-Newsgroups dataset5 contains about 19,000 newsgroup documents evenly grouped into 20 different categories.",4.1.2 Experimental datasets,[0],[0]
The TagMyNews news dataset6,4.1.2 Experimental datasets,[0],[0]
"(Vitale et al., 2012) consists of about 32,600 English RSS news items grouped into 7 categories, where each news document has a news title and a short description.",4.1.2 Experimental datasets,[0],[0]
"In our experiments, we also used a news title dataset which consists of just the news titles from the TagMyNews news dataset.
",4.1.2 Experimental datasets,[0],[0]
"Each dataset was down-cased, and we removed non-alphabetic characters and stop-words found in the stop-word list in the Mallet toolkit (McCallum, 2002).",4.1.2 Experimental datasets,[0],[0]
"We also removed words shorter than 3 characters and words appearing less than 10 times in the 20-Newsgroups corpus, and under 5 times in the TagMyNews news and news titles datasets.",4.1.2 Experimental datasets,[0],[0]
"In addition, words not found in both Google and Stanford vector representations were also removed.7 We refer to the cleaned 20-Newsgroups, TagMyNews news
3 Download at: https://code.google.com/p/word2vec/ 4 Download at: http://www-nlp.stanford.edu/projects/glove/ 5We used the “all-terms” version of the 20-Newsgroups dataset available at http://web.ist.utl.pt/acardoso/datasets/ (Cardoso-Cachopo, 2007).
",4.1.2 Experimental datasets,[0],[0]
"6The TagMyNews news dataset is unbalanced, where the largest category contains 8,200 news items while the smallest category contains about 1,800 items.",4.1.2 Experimental datasets,[0],[0]
"Download at: http: //acube.di.unipi.it/tmn-dataset/
71366, 27 and 12 words were correspondingly removed out of the 20-Newsgroups, TagMyNews news and news title datasets.
and news title datasets as N20, TMN and TMNtitle, respectively.
",4.1.2 Experimental datasets,[0],[0]
We also performed experiments on two subsets of the N20 dataset.,4.1.2 Experimental datasets,[0],[0]
The N20short dataset consists of all documents from the N20 dataset with less than 21 words.,4.1.2 Experimental datasets,[0],[0]
"The N20small dataset contains 400 documents consisting of 20 randomly selected documents from each group of the N20 dataset.
",4.1.2 Experimental datasets,[0],[0]
"Finally, we also experimented on the publicly available Sanders Twitter corpus.8",4.1.2 Experimental datasets,[0],[0]
"This corpus consists of 5,512 Tweets grouped into four different topics (Apple, Google, Microsoft, and Twitter).",4.1.2 Experimental datasets,[0],[0]
"Due to restrictions in Twitter’s Terms of Service, the actual Tweets need to be downloaded using 5,512 Tweet IDs.",4.1.2 Experimental datasets,[0],[0]
There are 850 Tweets not available to download.,4.1.2 Experimental datasets,[0],[0]
"After removing the non-English Tweets, 3,115 Tweets remain.",4.1.2 Experimental datasets,[0],[0]
"In addition to converting into lowercase and removing non-alphabetic characters, words were normalized by using a lexical normalization dictionary for microblogs (Han et al., 2012).",4.1.2 Experimental datasets,[0],[0]
"We then removed stop-words, words shorter than 3 characters or appearing less than 3 times in the corpus.",4.1.2 Experimental datasets,[0],[0]
"The four words apple, google, microsoft and twitter were removed as these four words occur in every Tweet in the corresponding topic.",4.1.2 Experimental datasets,[0],[0]
"Moreover, words not found in both Google and Stanford vector lists were also removed.9",4.1.2 Experimental datasets,[0],[0]
"In all our experiments, after removing words from documents, any document with a zero word count was also removed from the corpus.",4.1.2 Experimental datasets,[0],[0]
"For the Twitter corpus, this resulted in just 2,520 remaining Tweets.",4.1.2 Experimental datasets,[0],[0]
"The hyper-parameter β used in baseline LDA and DMM models was set to 0.01, as this is a common setting in the literature (Griffiths and Steyvers,
8Download at: http://www.sananalytics.com/lab/index.php 9There are 91 removed words.
2004).",4.1.3 General settings,[0],[0]
"We set the hyper-parameter α = 0.1, as this can improve performance relative to the standard setting α = 50T , as noted by Lu et al. (2011) and Yin and Wang (2014).
",4.1.3 General settings,[0],[0]
We ran each baseline model for 2000 iterations and evaluated the topics assigned to words in the last sample.,4.1.3 General settings,[0],[0]
"For our models, we ran the baseline models for 1500 iterations, then used the outputs from the last sample to initialize our models, which we ran for 500 further iterations.
",4.1.3 General settings,[0],[0]
"We report the mean and standard deviation of the results of ten repetitions of each experiment (so the standard deviation is approximately 3 standard errors, or a 99% confidence interval).",4.1.3 General settings,[0],[0]
This section examines the quality of the topic-word mappings induced by our models.,4.2 Topic coherence evaluation,[0],[0]
"In our models, topics are distributions over words.",4.2 Topic coherence evaluation,[0],[0]
"The topic coherence evaluation measures to what extent the highprobability words in each topic are semantically coherent (Chang et al., 2009; Stevens et al., 2012).",4.2 Topic coherence evaluation,[0],[0]
"Newman et al. (2010), Mimno et al. (2011) and Lau et al. (2014) describe methods for automatically evaluating the semantic coherence of sets of words.",4.2.1 Quantitative analysis,[0],[0]
The method presented in Lau et al. (2014) uses the normalized pointwise mutual information (NPMI) score and has a strong correlation with humanjudged coherence.,4.2.1 Quantitative analysis,[0],[0]
A higher NPMI score indicates that the topic distributions are semantically more coherent.,4.2.1 Quantitative analysis,[0],[0]
"Given a topic t represented by its top-N topic words w1, w2, ..., wN , the NPMI score for t is:
NPMI-Score(t) = ∑
16i<j6N
log P(wi,wj)
P(wi)P(wj)
− log P(wi, wj) (12)
where the probabilities in equation (12) are derived from a 10-word sliding window over an external corpus.
",4.2.1 Quantitative analysis,[0],[0]
The NPMI score for a topic model is the average score for all topics.,4.2.1 Quantitative analysis,[0],[0]
"We compute the NPMI score based on top-15 most probable words of each topic and use the English Wikipedia10 of 4.6 million articles as our external corpus.
Figures 3 and 4 show NPMI scores computed for the LDA, w2v-LDA and glove-LDA models on the
10We used the Wikipedia-articles dump of July 8, 2014.
N20short dataset for 20 and 40 topics.",4.2.1 Quantitative analysis,[0],[0]
We see that λ = 1.0 gives the highest NPMI score.,4.2.1 Quantitative analysis,[0],[0]
"In other words, using only the latent feature model produces the most coherent topic distributions.
",4.2.1 Quantitative analysis,[0],[0]
"Tables 2, 3 and 4 present the NPMI scores produced by the models on the other experimental datasets, where we vary11 the number of topics in steps from 4 to 80.",4.2.1 Quantitative analysis,[0],[0]
"Tables 3 and 4 show that the DMM model performs better than the LDA model on
11 We perform with T",4.2.1 Quantitative analysis,[0],[0]
"= 6 on the N20 and N20small datasets as the 20-Newsgroups dataset could be also grouped into 6 larger topics instead of 20 fine-grained categories.
",4.2.1 Quantitative analysis,[0],[0]
"the TMN, TMNtitle and Twitter datasets.",4.2.1 Quantitative analysis,[0],[0]
"These results show that our latent feature models produce significantly higher scores than the baseline models on all the experimental datasets.
",4.2.1 Quantitative analysis,[0],[0]
"Google word2vec vs. Stanford glove word vectors: In general, our latent feature models obtain competitive NPMI results in using pre-trained Google word2vec and Stanford glove word vectors for a large value of T , for example T = 80.",4.2.1 Quantitative analysis,[0],[0]
"With small values of T , for example T ≤ 7 , using Google word vectors produces better scores than using Stanford word vectors on the small N20small dataset of normal texts and on the short text TMN and TMNtitle datasets.",4.2.1 Quantitative analysis,[0],[0]
"However, the opposite pattern holds on the full N20 dataset.",4.2.1 Quantitative analysis,[0],[0]
Both sets of the pre-trained word vectors produce similar scores on the small and short Twitter dataset.,4.2.1 Quantitative analysis,[0],[0]
This section provides an example of how our models improve topic coherence.,4.2.2 Qualitative analysis,[0],[0]
"Table 5 compares the top15 words12 produced by the baseline DMM model
12In the baseline model, the top-15 topical words output from the 1500th sample are similar to top-15 words from the 2000th
and our w2v-DMM model with λ = 1.0 on the TMNtitle dataset with T = 20 topics.
",4.2.2 Qualitative analysis,[0],[0]
"In table 5, topic 1 of the DMM model consists of words related to “nuclear crisis in Japan” together with other unrelated words.",4.2.2 Qualitative analysis,[0],[0]
"The w2v-DMM model produced a purer topic 1 focused on “Japan earthquake and nuclear crisis,” presumably related to the “Fukushima Daiichi nuclear disaster.”",4.2.2 Qualitative analysis,[0],[0]
Topic 3 is about “oil prices” in both models.,4.2.2 Qualitative analysis,[0],[0]
"However, all top15 words are qualitatively more coherent in the w2vDMM model.",4.2.2 Qualitative analysis,[0],[0]
"While topic 4 of the DMM model is difficult to manually label, topic 4 of the w2v-DMM model is about the “Arab Spring” event.
",4.2.2 Qualitative analysis,[0],[0]
"Topics 5, 19 and 14 of the DMM model are not easy to label.",4.2.2 Qualitative analysis,[0],[0]
"Topic 5 relates to “entertainment”, topic 19 is generally a mixture of “entertainment” and “sport”, and topic 14 is about “sport” and “politics.”",4.2.2 Qualitative analysis,[0],[0]
"However, the w2v-DMM model more clearly distinguishes these topics: topic 5 is about “entertainment”, topic 19 is only about “sport” and topic 14 is only about “politics.”",4.2.2 Qualitative analysis,[0],[0]
We compared our models to the baseline models in a document clustering task.,4.3 Document clustering evaluation,[0],[0]
"After using a topic model to calculate the topic probabilities of a document, we assign every document the topic with the highest probability given the document (Cai et al., 2008; Lu et al., 2011; Xie and Xing, 2013; Yan et al., 2013).",4.3 Document clustering evaluation,[0],[0]
"We use two common metrics to evaluate clustering performance: Purity and normalized mutual information (NMI): see (Manning et al., 2008, Section 16.3) for details of these evaluations.",4.3 Document clustering evaluation,[0],[0]
"Purity and NMI scores always range from 0.0 to 1.0, and higher scores reflect better clustering performance.
",4.3 Document clustering evaluation,[0],[0]
"Figures 5 and 6 present Purity and NMI results obtained by the LDA, w2v-LDA and glove-LDA models on the N20short dataset with the numbers of topics T set to either 20 or 40, and the value of the mixture weight λ varied from 0.0 to 1.0.
",4.3 Document clustering evaluation,[0],[0]
"We found that setting λ to 1.0 (i.e. using only the latent features to model words), the glove-LDA produced 1%+ higher scores on both Purity and NMI results than the w2v-LDA when using 20 topics.",4.3 Document clustering evaluation,[0],[0]
"However, the two models glove-LDA and w2v-LDA returned equivalent results with 40 topics where they
sample if we do not take the order of the most probable words into account.
gain 2%+ absolute improvement13 on the two Purity and NMI against the baseline LDA model.
",4.3 Document clustering evaluation,[0],[0]
"By varying λ, as shown in Figures 5 and 6, the w2v-LDA and glove-LDA models obtain their best results at λ = 0.6 where the w2v-LDA model does slightly better than the glove-LDA.",4.3 Document clustering evaluation,[0],[0]
"Both models sig-
13Using the Student’s t-Test, the improvement is significant (p < 0.01).
nificantly outperform their baseline LDA models; for example with 40 topics, the w2v-LDA model attains 4.4% and 4.3% over the LDA model on Purity and NMI metrics, respectively.
",4.3 Document clustering evaluation,[0],[0]
"We fix the mixture weight λ at 0.6, and report experimental results based on this value for the rest of this section.",4.3 Document clustering evaluation,[0],[0]
"Tables 6, 7 and 8 show clustering results produced by our models and the baseline models on the remaining datasets with different numbers
of topics.",4.3 Document clustering evaluation,[0],[0]
"As expected, the DMM model is better than the LDA model on the short datasets of TMN, TMNtitle and Twitter.",4.3 Document clustering evaluation,[0],[0]
"For example with 80 topics on the TMNtitle dataset, the DMM achieves about 7+% higher Purity and NMI scores than LDA.
",4.3 Document clustering evaluation,[0],[0]
"New models vs. baseline models: On most tests, our models score higher than the baseline models, particularly on the small N20small dataset where we get 6.0% improvement on NMI at T = 6, and on the short text TMN and TMNtitle datasets we obtain 6.1% and 2.5% higher Purity at T = 80.",4.3 Document clustering evaluation,[0],[0]
"In addition, on the short and small Twitter dataset with T = 4, we achieve 3.9% and 5.3% improvements in Purity and NMI scores, respectively.",4.3 Document clustering evaluation,[0],[0]
"Those results show that an improved model of topic-word mappings also
improves the document-topic assignments.",4.3 Document clustering evaluation,[0],[0]
"For the small value of T ≤ 7, on the large datasets of N20, TMN and TMNtitle, our models and baseline models obtain similar clustering results.",4.3 Document clustering evaluation,[0],[0]
"However, with higher values of T , our models perform better than the baselines on the short TMN and TMNtitle datasets, while on the N20 dataset, the baseline LDA model attains a slightly higher clustering results than ours.",4.3 Document clustering evaluation,[0],[0]
"In contrast, on the short and small Twitter dataset, our models obtain considerably better clustering results than the baseline models with a small value of T .
",4.3 Document clustering evaluation,[0],[0]
"Google word2vec vs. Stanford glove word vectors: On the small N20short and N20small datasets, using the Google pre-trained word vectors produces
higher clustering scores than using Stanford pretrained word vectors.",4.3 Document clustering evaluation,[0],[0]
"However, on the large datasets N20, TMN and TMNtitle, using Stanford word vectors produces higher scores than using Google word vectors when using a smaller number of topics, for example T ≤ 20.",4.3 Document clustering evaluation,[0],[0]
"With more topics, for instance T = 80, the pre-trained Google and Stanford word vectors produce similar clustering results.",4.3 Document clustering evaluation,[0],[0]
"In addition, on the Twitter dataset, both sets of pre-trained word vectors produce similar results.",4.3 Document clustering evaluation,[0],[0]
"Unlike the document clustering task, the document classification task evaluates the distribution over topics for each document.",4.4 Document classification evaluation,[0],[0]
"Following Lacoste-Julien et al. (2009), Lu et al. (2011), Huh and Fienberg (2012) and Zhai and Boyd-graber (2013), we used Support Vector Machines (SVM) to predict the ground truth labels from the topic-proportion vector of each document.",4.4 Document classification evaluation,[0],[0]
"We used the WEKA’s implementation (Hall et al., 2009) of the fast Sequential Minimal Optimization algorithm (Platt, 1999) for learning a classifier with ten-fold cross-validation and WEKA’s default parameters.",4.4 Document classification evaluation,[0],[0]
"We present the macroaveraged F1 score (Manning et al., 2008, Section 13.6) as the evaluation metric for this task.
",4.4 Document classification evaluation,[0],[0]
"Just as in the document clustering task, the mixture weight λ = 0.6 obtains the highest classification performances on the N20short dataset.",4.4 Document classification evaluation,[0],[0]
"For example with T = 40, our w2v-LDA and gloveLDA obtain F1 scores at 40.0% and 38.9% which are 4.5% and 3.4% higher than F1 score at 35.5% obtained by the LDA model, respectively.
",4.4 Document classification evaluation,[0],[0]
"We report classification results on the remaining experimental datasets with mixture weight λ = 0.6 in tables 9, 10 and 11.",4.4 Document classification evaluation,[0],[0]
"Unlike the clustering results, the LDA model does better than the DMM model for classification on the TMN dataset.
",4.4 Document classification evaluation,[0],[0]
"New models vs. baseline models: On most eval-
uations, our models perform better than the baseline models.",4.4 Document classification evaluation,[0],[0]
"In particular, on the small N20small and Twitter datasets, when the number of topics T is equal to number of ground truth labels (i.e. 20 and 4 correspondingly), our w2v-LDA obtains 5+% higher F1 score than the LDA model.",4.4 Document classification evaluation,[0],[0]
"In addition, our w2v-DMM model achieves 5.4% and 2.9% higher F1 score than the DMM model on short TMN and TMNtitle datasets with T = 80, respectively.
",4.4 Document classification evaluation,[0],[0]
Google word2vec vs. Stanford glove word vectors: The comparison of the Google and Stanford pre-trained word vectors for classification is similar to the one for clustering.,4.4 Document classification evaluation,[0],[0]
"We found that the topic coherence evaluation produced the best results with a mixture weight λ = 1, which corresponds to using topic-word distributions defined in terms of the latent-feature word vectors.",4.5 Discussion,[0],[0]
"This is not surprising, since the topic coherence evaluation we used (Lau et al., 2014) is based on word co-occurrences in an external corpus (here, Wikipedia), and it is reasonable that the billion-word corpora used to train the latent feature word vectors are more useful for this task than the much smaller topic-modeling corpora, from which the topic-word multinomial distributions are trained.
",4.5 Discussion,[0],[0]
"On the other hand, the document clustering and document classification tasks depend more strongly on possibly idiosyncratic properties of the smaller topic-modeling corpora, since these evaluations reflect how well the document-topic assignments can group or distinguish documents within the topicmodeling corpus.",4.5 Discussion,[0],[0]
"Smaller values of λ enable the models to learn topic-word distributions that include an arbitrary multinomial topic-word distribution, enabling the models to capture idiosyncratic properties of the topic-modeling corpus.",4.5 Discussion,[0],[0]
"Even in these evaluations we found that an intermediate value of λ = 0.6 produced the best results, indicating that better word-topic distributions were produced when information from the large external corpus is combined with corpus-specific topic-word multinomials.",4.5 Discussion,[0],[0]
"We found that using the latent feature word vectors produced significant performance improvements even when the domain of the topic-modeling corpus was quite different to that of the external corpus from which the word vectors were derived, as was the case in our experiments on Twitter data.
",4.5 Discussion,[0],[0]
We found that using either the Google or the Stanford latent feature word vectors produced very similar results.,4.5 Discussion,[0],[0]
"As far as we could tell, there is no reason to prefer either one of these in our topic modeling applications.",4.5 Discussion,[0],[0]
"In this paper, we have shown that latent feature representations can be used to improve topic models.",5 Conclusion and future work,[0],[0]
"We proposed two novel latent feature topic models, namely LF-LDA and LF-DMM, that integrate a latent feature model within two topic models LDA and DMM.",5 Conclusion and future work,[0],[0]
"We compared the performance of our models LF-LDA and LF-DMM to the baseline LDA and DMM models on topic coherence, document clustering and document classification evaluations.",5 Conclusion and future work,[0],[0]
"In the topic coherence evaluation, our model outperformed the baseline models on all 6 experimental datasets, showing that our method for exploiting external information from very large corpora helps improve the topic-to-word mapping.",5 Conclusion and future work,[0],[0]
"Meanwhile, document clustering and document classification results show that our models improve the document-topic assignments compared to the baseline models, especially on datasets with few or short documents.
",5 Conclusion and future work,[0],[0]
"As an anonymous reviewer suggested, it would be interesting to identify exactly how the latent feature word vectors improve topic modeling performance.",5 Conclusion and future work,[0],[0]
"We believe that they provide useful information about word meaning extracted from the large corpora that they are trained on, but as the reviewer suggested, it is possible that the performance improvements arise because the word vectors are trained on context windows of size 5 or 10, while the LDA and DMM models view documents as bags of words, and effectively use a context window that encompasses the entire document.",5 Conclusion and future work,[0],[0]
"In preliminary experiments where we train latent feature word vectors from the topic-modeling corpus alone using context windows of size 10 we found that performance was degraded relative to the results presented here, suggesting that the use of a context window alone is not responsible for the performance improvements we reported here.",5 Conclusion and future work,[0],[0]
"Clearly it would be valuable to investigate this further.
",5 Conclusion and future work,[0],[0]
"In order to use a Gibbs sampler in section 3.4, the conditional distributions needed to be distributions we can sample from cheaply, which is not the case for the ratios of Gamma functions.",5 Conclusion and future work,[0],[0]
"While we used a simple approximation, it is worth exploring other sampling techniques that can avoid approximations, such as Metropolis-Hastings sampling (Bishop, 2006, Section 11.2.2).
",5 Conclusion and future work,[0],[0]
"In order to compare the pre-trained Google and Stanford word vectors, we excluded words that did not appear in both sets of vectors.",5 Conclusion and future work,[0],[0]
"As suggested by anonymous reviewers, it would be interesting to learn vectors for these unseen words.",5 Conclusion and future work,[0],[0]
"In addition, it is worth fine-tuning the seen-word vectors on the dataset of interest.
",5 Conclusion and future work,[0],[0]
"Although we have not evaluated our approach on very large corpora, the corpora we have evaluated on do vary in size, and we showed that the gains from our approach are greatest when the corpora are small.",5 Conclusion and future work,[0],[0]
A drawback of our approach is that it is slow on very large corpora.,5 Conclusion and future work,[0],[0]
"Variational Bayesian inference may provide an efficient solution to this problem (Jordan et al., 1999; Blei et al., 2003).",5 Conclusion and future work,[0],[0]
"This research was supported by a Google award through the Natural Language Understanding
Focused Program, and under the Australian Research Council’s Discovery Projects funding scheme (project numbers DP110102506 and DP110102593).",Acknowledgments,[0],[0]
"The authors would like to thank the three anonymous reviewers, the action editor and Dr. John Pate at the Macquarie University, Australia for helpful comments and suggestions.",Acknowledgments,[0],[0]
"Probabilistic topic models are widely used to discover latent topics in document collections, while latent feature vector representations of words have been used to obtain high performance in many NLP tasks.",abstractText,[0],[0]
"In this paper, we extend two different Dirichlet multinomial topic models by incorporating latent feature vector representations of words trained on very large corpora to improve the word-topic mapping learnt on a smaller corpus.",abstractText,[0],[0]
"Experimental results show that by using information from the external corpora, our new models produce significant improvements on topic coherence, document clustering and document classification tasks, especially on datasets with few or short documents.",abstractText,[0],[0]
Improving Topic Models with Latent Feature Word Representations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 862–868 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
862",text,[0],[0]
Building a machine translation (MT) system requires lots of bilingual data.,1 Introduction,[0],[0]
"Neural MT models (Bahdanau et al., 2015), which become the current standard, are even more difficult to train without huge bilingual supervision (Koehn and Knowles, 2017).",1 Introduction,[0],[0]
"However, bilingual resources are still limited to some of the selected language pairs—mostly from or to English.
",1 Introduction,[0],[0]
A workaround for zero-resource language pairs is translating via an intermediate (pivot) language.,1 Introduction,[0],[0]
"To do so, we need to collect parallel data and train MT models for source-to-pivot and pivot-to-target individually; it takes a double effort and the decoding is twice as slow.
",1 Introduction,[0],[0]
"Unsupervised learning is another alternative, where we can train an MT system with only monolingual corpora.",1 Introduction,[0],[0]
"Decipherment methods (Ravi and Knight, 2011; Nuhn et al., 2013) are the first work in this direction, but they often suffer from a huge latent hypothesis space (Kim et al., 2017).
",1 Introduction,[0],[0]
Recent work by Artetxe et al. (2018) and Lample et al. (2018) train sequence-to-sequence MT models of both translation directions together in an unsupervised way.,1 Introduction,[0],[0]
"They do back-translation (Sennrich et al., 2016a) back and forth for every iteration or batch, which needs an immensely long time and careful tuning of hyperparameters for massive monolingual data.
",1 Introduction,[0],[0]
"Here we suggest rather simple methods to build an unsupervised MT system quickly, based on word translation using cross-lingual word embeddings.",1 Introduction,[0],[0]
"The contributions of this paper are:
• We formulate a straightforward way to combine a language model with cross-lingual word similarities, effectively considering context in lexical choices.
",1 Introduction,[0],[0]
"• We develop a postprocessing method for word-by-word translation outputs using a denoising autoencoder, handling local reordering and multi-aligned words.
",1 Introduction,[0],[0]
"• We analyze the effect of different artificial noises for the denoising model and propose a novel noise type.
",1 Introduction,[0],[0]
"• We verify that cross-lingual embedding on subword units performs poorly in translation.
",1 Introduction,[0],[0]
"• We empirically show that cross-lingual mapping can be learned using a small vocabulary without losing the translation performance.
",1 Introduction,[0],[0]
"The proposed models can be efficiently trained with off-the-shelf softwares with little or no changes in the implementation, using only monolingual data.",1 Introduction,[0],[0]
The provided analyses help for better learning of cross-lingual word embeddings for translation purpose.,1 Introduction,[0],[0]
"Altogether, our unsupervised MT system outperforms the sequence-to-sequence neural models even without training signals from the opposite translation direction, i.e. via backtranslation.",1 Introduction,[0],[0]
"As a basic step for unsupervised MT, we learn a word translation model from monolingual corpora of each language.",2 Cross-lingual Word Embedding,[0],[0]
"In this work, we exploit crosslingual word embedding for word-by-word translation, which is state-of-the-art in terms of type translation quality (Artetxe et al., 2017; Conneau et al., 2018).
",2 Cross-lingual Word Embedding,[0],[0]
Cross-lingual word embedding is a continuous representation of words whose vector space is shared across multiple languages.,2 Cross-lingual Word Embedding,[0],[0]
"This enables distance calculation between word embeddings across languages, which is actually finding translation candidates.
",2 Cross-lingual Word Embedding,[0],[0]
"We train cross-lingual word embedding in a fully unsupervised manner:
1.",2 Cross-lingual Word Embedding,[0],[0]
Learn monolingual source and target embeddings independently.,2 Cross-lingual Word Embedding,[0],[0]
"For this, we run skipgram algorithm augmented with character ngram (Bojanowski et al., 2017).
2.",2 Cross-lingual Word Embedding,[0],[0]
"Find a linear mapping from source embedding space to target embedding space by adversarial training (Conneau et al., 2018).",2 Cross-lingual Word Embedding,[0],[0]
"We do not pre-train the discriminator with a seed dictionary, and consider only the top Vcross-train words of each language as input to the discriminator.
",2 Cross-lingual Word Embedding,[0],[0]
"Once we have the cross-lingual mapping, we can transform the embedding of a given source word and find a target word with the closest embedding, i.e. nearest neighbor search.",2 Cross-lingual Word Embedding,[0],[0]
"Here, we apply cross-domain similarity local scaling (Conneau et al., 2018) to penalize the word similarities in dense areas of the embedding distribution.
",2 Cross-lingual Word Embedding,[0],[0]
"We further refine the mapping obtained from Step 2 as follows (Artetxe et al., 2017):
3.",2 Cross-lingual Word Embedding,[0],[0]
"Build a synthetic dictionary by finding mutual nearest neighbors for both translation directions in vocabularies of Vcross-train words.
4.",2 Cross-lingual Word Embedding,[0],[0]
"Run a Procrustes problem solver with the dictionary from Step 3 to re-train the mapping (Smith et al., 2017).
5.",2 Cross-lingual Word Embedding,[0],[0]
Repeat Step 3 and 4 for a fixed number of iterations to update the mapping further.,2 Cross-lingual Word Embedding,[0],[0]
"In translating sentences, cross-lingual word embedding has several drawbacks.",3 Sentence Translation,[0],[0]
We describe each of them and our corresponding solutions.,3 Sentence Translation,[0],[0]
The word translation using nearest neighbor search does not consider context around the current word.,3.1 Context-aware Beam Search,[0],[0]
"In many cases, the correct translation is not the nearest target word but other close words with morphological variations or synonyms, depending on the context.
",3.1 Context-aware Beam Search,[0],[0]
"The reasons are in two-fold: 1) Word embedding is trained to place semantically related words nearby, even though they have opposite meanings.",3.1 Context-aware Beam Search,[0],[0]
"2) A hubness problem of high-dimensional embedding space hinders a correct search, where lots of different words happen to be close to each other (Radovanović et al., 2010).
",3.1 Context-aware Beam Search,[0],[0]
"In this paper, we integrate context information into word-by-word translation by combining a language model (LM) with cross-lingual word embedding.",3.1 Context-aware Beam Search,[0],[0]
Let f be a source word in the current position and e a possible target word.,3.1 Context-aware Beam Search,[0],[0]
"Given a history h of target words before e, the score of e to be the translation of f would be:
L(e; f, h) = λemb log q(f, e) + λLM log p(e|h)
Here, q(f, e) is a lexical score defined as:
q(f, e) = d(f, e) + 1
2
where d(f, e) ∈",3.1 Context-aware Beam Search,[0],[0]
"[−1, 1] is a cosine similarity between f and e.",3.1 Context-aware Beam Search,[0],[0]
"It is transformed to the range [0, 1] to make it similar in scale with the LM probability.",3.1 Context-aware Beam Search,[0],[0]
"In our experiments, we found that this simple linear scaling is better than sigmoid or softmax functions in the final translation performance.
",3.1 Context-aware Beam Search,[0],[0]
"Accumulating the scores per position, we perform a beam search to allow only reasonable translation hypotheses.",3.1 Context-aware Beam Search,[0],[0]
"Even when we have correctly translated words for each position, the output is still far from an acceptable translation.",3.2 Denoising,[0],[0]
"We adopt sequence denoising autoencoder (Hill et al., 2016) to improve the translation output of Section 3.1.",3.2 Denoising,[0],[0]
"The main idea is to train a sequence-to-sequence neural network model that takes a noisy sentence as input and produces a (denoised) clean sentence as output, both of which are of the same (target) language.",3.2 Denoising,[0],[0]
"The model was originally proposed to learn sentence embeddings, but here we use it directly to actually remove noise in a sentence.
",3.2 Denoising,[0],[0]
"Training label sequences for the denoising network would be target monolingual sentences, but
we do not have their noisy versions at hand.",3.2 Denoising,[0],[0]
"Given a clean target sentence, the noisy input should be ideally word-by-word translation of the corresponding source sentence.",3.2 Denoising,[0],[0]
"However, such bilingual sentence alignment is not available in our unsupervised setup.
",3.2 Denoising,[0],[0]
"Instead, we inject artificial noise into a clean sentence to simulate the noise of word-by-word translation.",3.2 Denoising,[0],[0]
We design different noise types after the following aspects of word-by-word translation.,3.2 Denoising,[0],[0]
Word-by-word translation always outputs a target word for every position.,3.2.1 Insertion,[0],[0]
"However, there are a plenty of cases that multiple source words should be translated to a single target word, or that some source words are rather not translated to any word to make a fluent output.",3.2.1 Insertion,[0],[0]
"For example, a German sentence “Ich höre zu.” would be translated to “I’m listening to.”",3.2.1 Insertion,[0],[0]
"by a word-by-word translator, but “I’m listening.” is more natural in English (Figure 1).
",3.2.1 Insertion,[0],[0]
"We pretend to have extra target words which might be translation of redundant source words, by inserting random target words to a clean sentence:
1.",3.2.1 Insertion,[0],[0]
"For each position i, sample a probability pi ∼ Uniform(0, 1).
2.",3.2.1 Insertion,[0],[0]
"If pi < pins, sample a word e from the most frequent Vins target words and insert it before position i.
We limit the inserted words by Vins because target insertion occurs mostly with common words, e.g. prepositions or articles, as the example above.",3.2.1 Insertion,[0],[0]
"We insert words only before—not after—a position, since an extra word after the ending word (usually a punctuation) is not probable.",3.2.1 Insertion,[0],[0]
"Similarly, word-by-word translation cannot handle the contrary case: when a source word should be translated into more than one target words, or a
target word should be generated from no source words for fluency.",3.2.2 Deletion,[0],[0]
"For example, a German word “im” must be “in the” in English, but word translation generates only one of the two English words.",3.2.2 Deletion,[0],[0]
"Another example is shown in Figure 2.
",3.2.2 Deletion,[0],[0]
"To simulate such situations, we drop some words randomly from a clean target sentence (Hill et al., 2016):
1.",3.2.2 Deletion,[0],[0]
"For each position i, sample a probability pi ∼ Uniform(0, 1).
2.",3.2.2 Deletion,[0],[0]
"If pi < pdel, drop the word in the position i.",3.2.2 Deletion,[0],[0]
"Also, translations generated word-by-word are not in an order of the target language.",3.2.3 Reordering,[0],[0]
"In our beam search, LM only assists in choosing the right word in context but does not modify the word order.",3.2.3 Reordering,[0],[0]
"A common reordering problem of German→English is illustrated in Figure 3.
",3.2.3 Reordering,[0],[0]
"From a clean target sentence, we corrupt its word order by random permutations.",3.2.3 Reordering,[0],[0]
"We limit the maximum distance between an original position and its new position like Lample et al. (2018):
1.",3.2.3 Reordering,[0],[0]
"For each position i, sample an integer δi from [0, dper].
2.",3.2.3 Reordering,[0],[0]
"Add δi to index i and sort the incremented indices i+ δi in an increasing order.
3.",3.2.3 Reordering,[0],[0]
"Rearrange the words to be in the new positions, to which their original indices have moved by Step 2.
",3.2.3 Reordering,[0],[0]
"This is a generalized version of swapping two neighboring words (Hill et al., 2016).",3.2.3 Reordering,[0],[0]
"Reordering is highly dependent of each language, but we found that this noise is generally close to wordby-word translation outputs.
",3.2.3 Reordering,[0],[0]
"Insertion, deletion, and reordering noises were applied to each mini-batch with different random seeds, allowing the model to see various noisy versions of the same clean sentence over the epochs.
",3.2.3 Reordering,[0],[0]
Note that the deletion and permutation noises are integrated in the neural MT training of Artetxe et al. (2018) and Lample et al. (2018) as additional training objectives.,3.2.3 Reordering,[0],[0]
Whereas we optimize an independent model solely for denoising without architecture change.,3.2.3 Reordering,[0],[0]
It allows us to easily train a larger network with a larger data.,3.2.3 Reordering,[0],[0]
"Insertion noise is of our original design, which we found to be the most effective (Section 4.1).",3.2.3 Reordering,[0],[0]
We applied the proposed methods on WMT 2016 German↔English task and WMT 2014 French↔English task.,4 Experiments,[0],[0]
"For German/English, we trained word embeddings with 100M sentences sampled from News Crawl 2014-2017 monolingual corpora.",4 Experiments,[0],[0]
"For French, we used News Crawl 2007-2014 (around 42M sentences).",4 Experiments,[0],[0]
The data was lowercased and filtered to have a maximum sentence length 100.,4 Experiments,[0],[0]
German compound words were splitted beforehand.,4 Experiments,[0],[0]
Numbers were replaced with category labels and recovered back after decoding by looking at the source sentence.,4 Experiments,[0],[0]
"Also, frequent casing was applied to the translation output.
",4 Experiments,[0],[0]
"fasttext (Bojanowski et al., 2017) was used to learn monolingual embeddings for only the words with minimum count 10.",4 Experiments,[0],[0]
"MUSE (Conneau et al., 2018) was used for cross-lingual mappings with Vcross-train = 100k and 10 refinement iterations
(Step 3-5 in Section 2).",4 Experiments,[0],[0]
Other parameters follow the values in Conneau et al. (2018).,4 Experiments,[0],[0]
"With the same data, we trained 5-gram count-based LMs using KenLM (Heafield, 2011) with its default setting.
",4 Experiments,[0],[0]
"Denoising autoencoders were trained using Sockeye (Hieber et al., 2017) on News Crawl 2016 for German/English and News Crawl 2014 for French.",4 Experiments,[0],[0]
We considered only top 50k frequent words for each language and mapped other words to <unk>.,4 Experiments,[0],[0]
"The unknowns in the denoised output were replaced with missing words from the noisy input by a simple line search.
",4 Experiments,[0],[0]
"We used 6-layer Transformer encoder/decoder (Vaswani et al., 2017) for denoisers, with embedding/hidden layer size 512, feedforward sublayer size 2048 and 8 attention heads.
",4 Experiments,[0],[0]
"As a validation set for the denoiser training, we used newstest2015 (German ↔ English) or newstest2013 (French↔ English), where the input/output sides both have the same clean target sentences, encouraging a denoiser to keep at least clean part of word-by-word translations.",4 Experiments,[0],[0]
"Here, the noisy input showed a slight degradation of performance; the model seemed to overfit to specific noises in the small validation set.
",4 Experiments,[0],[0]
"Optimization of the denoising models was done with Adam (Kingma and Ba, 2015): initial learning rate 0.0001, checkpoint frequency 4000, no learning rate warmup, multiplying 0.7 to the learning rate when the perplexity on the validation set did not improve for 3 checkpoints.",4 Experiments,[0],[0]
"We stopped the training if it was not improved for 8 checkpoints.
",4 Experiments,[0],[0]
Table 1 shows the results.,4 Experiments,[0],[0]
"LM improves wordby-word baselines consistently in all four tasks, giving at least +3% BLEU.",4 Experiments,[0],[0]
"When our denoising model is applied on top of it, we have additional gain around +3% BLEU.",4 Experiments,[0],[0]
"Note that our methods do not involve any decoding steps to generate pseudo-parallel training data, but still perform
better than unsupervised MT systems that rely on repetitive back-translations (Artetxe et al., 2018; Lample et al., 2018) by up to +3.9% BLEU.",4 Experiments,[0],[0]
The total training time of our method is only 1-2 days with a single GPU.,4 Experiments,[0],[0]
"To examine the effect of each noise type in denoising autoencoder, we tuned each parameter of the noise and combined them incrementally (Table 2).",4.1 Ablation Study: Denoising,[0],[0]
"Firstly, for permutations, a significant improvement is achieved from dper = 3, since a local reordering usually involves a sequence of 3 to 4 words.",4.1 Ablation Study: Denoising,[0],[0]
"With dper > 5, it shuffles too many consecutive words together, yielding no further improvement.",4.1 Ablation Study: Denoising,[0],[0]
"This noise cannot handle long-range reordering, which is usually a swap of words that are far from each other, keeping the words in the middle as they are.
",4.1 Ablation Study: Denoising,[0],[0]
"Secondly, we applied the deletion noise with different values of pdel. 0.1 gives +0.8% BLEU, but we immediately see a degradation with a larger value; it is hard to observe one-to-many translations more than once in each sentence pair.
",4.1 Ablation Study: Denoising,[0],[0]
"Finally, we optimized Vins for the insertion noise, fixing pins = 0.1.",4.1 Ablation Study: Denoising,[0],[0]
"Increasing Vins is generally not beneficial, since it provides too much variations in the inserted word; it might not be related to its neighboring words.",4.1 Ablation Study: Denoising,[0],[0]
"Overall, we observe the best result (+1.5% BLEU) with Vins = 50.",4.1 Ablation Study: Denoising,[0],[0]
We also examined how the translation performance varies with different vocabularies of crosslingual word embedding in Table 3.,4.2 Ablation Study: Vocabulary,[0],[0]
"The first three rows show that BPE embeddings performs worse
than word embeddings, especially with smaller vocabulary size.",4.2 Ablation Study: Vocabulary,[0],[0]
"For small BPE tokens (1-3 characters), the context they meet during the embedding training is much more various than a complete word, and a direct translation of such small token to a BPE token of another language would be very ambiguous.
",4.2 Ablation Study: Vocabulary,[0],[0]
"For word level embeddings, we compared different vocabulary sizes used for training the cross-lingual mapping (the second step in Section 2).",4.2 Ablation Study: Vocabulary,[0],[0]
"Surprisingly, cross-lingual word embedding learned only on top 20k words is comparable to that of 200k words in the translation quality.",4.2 Ablation Study: Vocabulary,[0],[0]
We also increased the search vocabulary to more than 200k but the performance only degrades.,4.2 Ablation Study: Vocabulary,[0],[0]
"This means that word-by-word translation with crosslingual embedding depends highly on the frequent word mappings, and learning the mapping between rare words does not have a positive effect.",4.2 Ablation Study: Vocabulary,[0],[0]
"In this paper, we proposed a simple pipeline to greatly improve sentence translation based on cross-lingual word embedding.",5 Conclusion,[0],[0]
"We achieved context-aware lexical choices using beam search with LM, and solved insertion/deletion/reordering problems using denoising autoencoder.",5 Conclusion,[0],[0]
Our novel insertion noise shows a promising performance even combined with other noise types.,5 Conclusion,[0],[0]
Our methods do not need back-translation steps but still outperforms costly unsupervised neural MT systems.,5 Conclusion,[0],[0]
"In addition, we proved that for general translation purpose, an effective cross-lingual mapping can be learned using only a small set of frequent words, not on subword units.",5 Conclusion,[0],[0]
"This work has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation
programme, grant agreement No. 694537 (SEQCLAS).",Acknowledgments,[0],[0]
The GPU computing cluster was partially funded by Deutsche Forschungsgemeinschaft (DFG) under grant INST 222/1168-1 FUGG.,Acknowledgments,[0],[0]
The work reflects only the authors’ views and neither ERC nor DFG is responsible for any use that may be made of the information it contains.,Acknowledgments,[0],[0]
"Unsupervised learning of cross-lingual word embedding offers elegant matching of words across languages, but has fundamental limitations in translating sentences.",abstractText,[0],[0]
"In this paper, we propose simple yet effective methods to improve word-by-word translation of crosslingual embeddings, using only monolingual corpora but without any back-translation.",abstractText,[0],[0]
"We integrate a language model for context-aware search, and use a novel denoising autoencoder to handle reordering.",abstractText,[0],[0]
Our system surpasses state-of-the-art unsupervised neural translation systems without costly iterative training.,abstractText,[0],[0]
"We also analyze the effect of vocabulary size and denoising type on the translation performance, which provides better understanding of learning the cross-lingual word embedding and its usage in translation.",abstractText,[0],[0]
Improving Unsupervised Word-by-Word Translation with Language Model and Denoising Autoencoder,title,[0],[0]
"√ logn) speedup for
the Viterbi algorithm when there are few distinct transition probabilities in the HMM.",text,[0],[0]
A Hidden Markov Model (HMM) is a simple model that describes a random process for generating a sequence of observations.,1. Introduction,[0],[0]
"A random walk is performed on an underlying graph (Markov Chain) and, at each step, an observation is drawn from a probability distribution that depends only on the current state (the node in the graph).
",1. Introduction,[0],[0]
HMMs are a fundamental statistical tool and one of the most important questions in the applications of HMMs is computing the most likely sequence of states visited by the random walk in the HMM given the sequence of observations.,1. Introduction,[0],[0]
"Andrew Viterbi proposed an algorithm (Viterbi, 1967) for this problem that computes the solution in
Authors ordered alphabetically.",1. Introduction,[0],[0]
"1MIT, US.",1. Introduction,[0],[0]
"Correspondence to: Arturs Backurs <backurs@mit.edu>, Christos Tzamos <tzamos@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
O(Tn2) time for any HMM with n states and an observation sequence of length T .,1. Introduction,[0],[0]
"This algorithm is known as the Viterbi algorithm and the problem of computing the most likely sequence of states is also known as the Viterbi Path problem.
",1. Introduction,[0],[0]
The Viterbi algorithm has found wide applicability in machine learning.,1. Introduction,[0],[0]
"It is an important tool for structured prediction, used e.g., for structured perceptrons (Collins, 2002).",1. Introduction,[0],[0]
"Other applications include speech recognition (Rabiner, 1989; Nefian et al., 2002; Bengio, 2003), part-of-speech tagging (Collins, 2002), action planning (Attias, 2003), emotion recognition (Cohen et al., 2000), human activity classification (Mannini & Sabatini, 2010), and waveform classification (Kim & Smyth, 2006).",1. Introduction,[0],[0]
"Furthermore, it is often combined with other methods.",1. Introduction,[0],[0]
"For example, a combination of the Viterbi algorithm and neural networks is used for speech recognition (Mohamed et al., 2012; AbdelHamid et al., 2012; Bourlard & Morgan, 2012), handwriting recognition and protein secondary structure prediction (Lin et al., 2005; Peng et al., 2009).",1. Introduction,[0],[0]
"It also can be combined with Support Vector Machines (Altun et al., 2003).",1. Introduction,[0],[0]
"Finally, the Viterbi algorithm is used as a module in Graph Transformer Networks, with applications to speech recognition (LeCun et al., 1998; Collobert, 2011).
",1. Introduction,[0],[0]
"The quadratic dependence of the algorithm’s runtime on the number of states is a long-standing bottleneck that limits its applicability to problems with large state spaces, particularly when the number of observations is large.",1. Introduction,[0],[0]
A lot of effort has been put into improving the Viterbi algorithm to lower either the time or space complexity.,1. Introduction,[0],[0]
"Many works achieve speedups by requiring structure in the input, either explicitly by considering restricted classes of HMMs (Felzenszwalb et al., 2004; Siddiqi & Moore, 2005) or implicitly by using heuristics that improve runtime in certain cases (Esposito & Radicioni, 2009; Kaji et al., 2010).",1. Introduction,[0],[0]
"For the general case, in (Lifshits et al., 2009; Mahmud & Schliep, 2011) it is shown how to speed up the Viterbi algorithm by O(log n) when the number of distinct observations is constant using the Four Russians method or similar ideas.",1. Introduction,[0],[0]
"More recently, in (Cairo et al., 2016), the same logarithmic speed-up was shown to be possible for the general case.",1. Introduction,[0],[0]
"Despite significant effort, only log-
arithmic improvements are known other than in very special cases.",1. Introduction,[0],[0]
"In contrast, the memory complexity can be reduced to almost linear in the number of states without significant overhead in the runtime (Grice et al., 1997; Tarnas & Hughey, 1998; Churbanov & Winters-Hilt, 2008).
",1. Introduction,[0],[0]
"In this work, we attempt to explain this apparent barrier for faster runtimes by giving evidence of the inherent hardness of the Viterbi Path problem.",1. Introduction,[0],[0]
"In particular, we show that getting a polynomial speedup1 would imply a breakthrough for fundamental graph problems.",1. Introduction,[0],[0]
"Our lower bounds are based on standard hardness assumptions for the All-Pairs Shortest Paths and the Min-Weight k-Clique problems and apply even in cases where the number of distinct observations is small.
",1. Introduction,[0],[0]
"Before formally stating our results, let us give some background on the Min-Weight k-Clique problem.",1. Introduction,[0],[0]
This fundamental graph problem asks to find the minimum weight k-clique in the given undirected weighted graph on n nodes and O(n2) weighted edges.,1. Introduction,[0],[0]
"This is the parameterized version of the NP-hard Min-Weight Clique problem (Karp, 1972).",1. Introduction,[0],[0]
"The Min-Weight k-Clique is amongst the most wellstudied problems in theoretical computer science, and it is the canonical intractable problem in parameterized complexity.
",1. Introduction,[0],[0]
"A naive algorithm solves the Min-Weight k-Clique in O(nk) time and the best known algorithm still runs in O(nk−o(1)) for any constant k. Obtaining a significantly faster algorithm for this problem is a longstanding open question.
",1. Introduction,[0],[0]
A conjecture in graph algorithms and parameterized complexity is that it there is no O(nk−ε) algorithm for any constant ε > 0.,1. Introduction,[0],[0]
The special case of the conjecture with k = 3 says that finding the minimum weight triangle in a weighted graph cannot be solved in O(n3−δ) time for any constant δ > 0.,1. Introduction,[0],[0]
"There are many negative results that intuitively support this conjecture: a truly sub-
1Getting an algorithm running in time, say O(Tn1.99).
cubic algorithm for Min-Weight 3-Clique implies such algorithm for the All-Pairs Shortest Paths as well (Williams & Williams, 2010).",1. Introduction,[0],[0]
"The latter is a well studied problem and no truly subcubic algorithm is known for it despite significant effort (Williams, 2014).",1. Introduction,[0],[0]
"Unconditional lower bounds for k-Clique are known for various computational models, such as Ω(nk) for monotone circuits (Alon & Boppana, 1987).",1. Introduction,[0],[0]
"The planted Clique problem has also proven to be very challenging (e.g. (Alon et al., 2007; 1998; Hazan & Krauthgamer, 2011; Jerrum, 1992)).",1. Introduction,[0],[0]
"Max-Clique is also known to be hard to efficiently approximate within nontrivial factors (Håstad, 1999).
",1. Introduction,[0],[0]
We complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM.,1. Introduction,[0],[0]
"We summarize our results in Table 1.
",1. Introduction,[0],[0]
Our results and techniques Our first lower bound shows that the Viterbi Path problem cannot be computed in time O(Tn2)1−ε for a constant ε > 0,1. Introduction,[0],[0]
unless the APSP conjecture is false.,1. Introduction,[0],[0]
The APSP conjecture states that there is no algorithm for the All-Pairs Shortest Paths problem that runs in truly subcubic2 time in the number of vertices of the graph.,1. Introduction,[0],[0]
"We obtain the following theorem:
Theorem 1.",1. Introduction,[0],[0]
"The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.
",1. Introduction,[0],[0]
The proof of the theorem gives a reduction from All-Pairs Shortest Paths to the Viterbi Path problem.,1. Introduction,[0],[0]
This is done by encoding the weights of the graph of the APSP instance as transition probabilities of the HMM or as probabilities of seeing observations from different states.,1. Introduction,[0],[0]
"The proof requires a large alphabet size, i.e. a large number of distinct observations, which can be as large as the number of total steps T .
",1. Introduction,[0],[0]
"A natural question question to ask is whether there is a faster algorithm that solves the Viterbi Path problem when
2Truly subcubic means O(n3−δ) for constant δ > 0.
",1. Introduction,[0],[0]
"the alphabet size is much smaller than T , say when T = n2 and the alphabet size is n. We observe that in such a case, the input size to the Viterbi Path problem is only O(n2): we only need to specify the transition probabilities of the HMM, the probabilities of each observation in each state and the sequence of observations.",1. Introduction,[0],[0]
The Viterbi algorithm in this setting runs in Θ(Tn2) = Θ(n4) time.,1. Introduction,[0],[0]
Showing a matching APSP based lower bound seems difficult because the runtime in this setting is quadratic in the input size while the APSP conjecture gives only N1.5 hardness for input size N .,1. Introduction,[0],[0]
"To our best knowledge, all existing reduction techniques based on the APSP conjecture do not achieve such an amplification of hardness.",1. Introduction,[0],[0]
"In order to get a lower bound for smaller alphabet sizes, we need to use a different hardness assumption.
",1. Introduction,[0],[0]
"For this purpose, we consider the k-Clique conjecture.",1. Introduction,[0],[0]
It is a popular hardness assumption which states that it is not possible to compute a minimum weight k-clique on an edge-weighted graph with n vertices in time O(nk−ε) for constant k and ε > 0.,1. Introduction,[0],[0]
"With this assumption, we are able to extend Theorem 1 and get the following lower bound for the Viterbi Path problem on very small alphabets:
Theorem 2.",1. Introduction,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.
",1. Introduction,[0],[0]
"To show the theorem, we perform a reduction from the Min-Weight k-Clique problem.",1. Introduction,[0],[0]
"Given a Min-Weight kClique instance, we create an HMM with two special nodes, a start node and an end node, and enforce the following behavior of the optimal Viterbi path: Most of the time it stays in the start or end node, except for a small number of steps, during which it traverses the rest of the graph to move from the start to the end node.",1. Introduction,[0],[0]
The time at which the traversal happens corresponds to a clique in the original graph of the Min-Weight k-Clique instance.,1. Introduction,[0],[0]
We penalize the traversal according to the weight of the corresponding k-clique and thus the optimal path will find the minimum weight k-clique.,1. Introduction,[0],[0]
Transition probabilities of the HMM and probabilities of seeing observations from different states encode edge-weights of the Min-Weight k-Clique instance.,1. Introduction,[0],[0]
"Further, we encode the weights of smaller cliques into the sequence of observations according to the binary expansion of the weights.
",1. Introduction,[0],[0]
Our results of Theorems 1 and 2 imply that the Viterbi algorithm is essentially optimal even for small alphabets.,1. Introduction,[0],[0]
We also study the extreme case of the Viterbi Path problem with unary alphabet where the only information available is the total number of steps T .,1. Introduction,[0],[0]
We show a surprising behavior: when T ≤ n,1. Introduction,[0],[0]
"the Viterbi algorithm is essentially optimal, while there is a simple much faster algorithm",1. Introduction,[0],[0]
when T > n.,1. Introduction,[0],[0]
"See Section 5 for more details.
",1. Introduction,[0],[0]
We complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM.,1. Introduction,[0],[0]
"Such a restriction is mild in applications where one can round the transition probabilities to a small number of distinct values.
",1. Introduction,[0],[0]
Theorem 3.,1. Introduction,[0],[0]
"When there are fewer than 2ε √
logn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.
",1. Introduction,[0],[0]
"We achieve this result by developing an algorithm for online (min,+) matrix-vector multiplication for the case when the matrix has few distinct values.",1. Introduction,[0],[0]
"Our algorithm is presented in Section 7 and is based on a recent result for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017).
",1. Introduction,[0],[0]
The results we presented above hold for dense HMMs.,1. Introduction,[0],[0]
"For sparse HMMs that have at most m edges out of the n2 possible ones, i.e. the transition matrix has at most m nonzero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time.",1. Introduction,[0],[0]
The lower bounds that we presented above can be adapted directly for this case to show that no faster algorithm exists that runs in timeO(Tm)1−ε.,1. Introduction,[0],[0]
See the corresponding discussion in Section 6.,1. Introduction,[0],[0]
"Notation For an integer m, we denote the set {1, 2, . . .",2. Preliminaries,[0],[0]
",m} by [m].
",2. Preliminaries,[0],[0]
Definition 1 (Hidden Markov Model).,2. Preliminaries,[0],[0]
"A Hidden Markov Model (HMM) consists of a directed graph with n distinct hidden states [n] with transition probabilities Ã(u, v) of going from state u to state v.",2. Preliminaries,[0],[0]
"In any given state, there is a probability distribution of symbols that can be observed and B̃(u, s) gives the probability of seeing symbol s on",2. Preliminaries,[0],[0]
state u.,2. Preliminaries,[0],[0]
The symbols come from an alphabet [σ] of size σ.,2. Preliminaries,[0],[0]
"An HMM can thus be represented by a tuple (Ã, B̃).",2. Preliminaries,[0],[0]
"Given an HMM and a sequence of T observations, the Viterbi algorithm (Viterbi, 1967) outputs a sequence of T states that is most likely given the T observations.",2.1. The Viterbi Path Problem,[0],[0]
"More precisely, let S = (s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ) be the given sequence of T observations where symbol st ∈",2.1. The Viterbi Path Problem,[0],[0]
"[σ] is observed at time t = 1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", T .",2.1. The Viterbi Path Problem,[0],[0]
Let ut ∈,2.1. The Viterbi Path Problem,[0],[0]
"[n] be the state of the HMM at time t = 1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", T .",2.1. The Viterbi Path Problem,[0],[0]
"The Viterbi algorithm finds a state sequence U = (u0, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ) starting at u0 = 1 that maximizes Pr[U |S].",2.1. The Viterbi Path Problem,[0],[0]
The problem of finding the sequence U is known as the Viterbi Path problem.,2.1. The Viterbi Path Problem,[0],[0]
"In particular, the Viterbi Path
problem solves the optimization problem
arg max u0=1,u1,...,uT T∏ t=1",2.1. The Viterbi Path Problem,[0],[0]
"[ Ã(ut−1, ut) · B̃(ut, st) ] .
",2.1. The Viterbi Path Problem,[0],[0]
The Viterbi algorithm solves this problem in O(Tn2) by computing for t = 1 . . .,2.1. The Viterbi Path Problem,[0],[0]
T the best sequence of length t that ends in a given state in a dynamic programming fashion.,2.1. The Viterbi Path Problem,[0],[0]
"When run in a word RAM model with O(log n) bit words, this algorithm is numerically unstable because even representing the probability of reaching a state requires linear number of bits.",2.1. The Viterbi Path Problem,[0],[0]
"Therefore, log probabilities are used for numerical stability since that allows to avoid underflows (Young et al., 1997; Amengual & Vidal, 1998; Li & Tang, 2009; Lee et al., 2007; Huang et al., 2001).",2.1. The Viterbi Path Problem,[0],[0]
"To maintain numerical stability and understand the underlying combinatorial structure of the problem, we assume that the input is given in the form of log-probabilities, i.e. the input to the problem is A(u, v) =",2.1. The Viterbi Path Problem,[0],[0]
"− log Ã(u, v) and B(u, s) =",2.1. The Viterbi Path Problem,[0],[0]
"− log B̃(u, s) and focus our attention on the Viterbi Path problem defined by matrices A and B.
Definition 2 (Viterbi Path Problem).",2.1. The Viterbi Path Problem,[0],[0]
"The VITERBI PATH problem is specified by a tuple (A,B, S) where A and B are n × n",2.1. The Viterbi Path Problem,[0],[0]
and n × σ,2.1. The Viterbi Path Problem,[0],[0]
"matrices, respectively, and S = (s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ) is a sequence of T = nΘ(1) observations s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ∈",2.1. The Viterbi Path Problem,[0],[0]
[σ] over an alphabet of size σ.,2.1. The Viterbi Path Problem,[0],[0]
"Given an instance (A,B, S) of the VITERBI PATH problem, our goal is to output a sequence of vertices u0, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ∈",2.1. The Viterbi Path Problem,[0],[0]
"[n] with u0 = 1 that solves
arg min u0=1,u1,...,uT T∑ t=1",2.1. The Viterbi Path Problem,[0],[0]
"[A(ut−1, ut) +B(ut, st)] .
We can assume that log probabilities in matrices A and B are arbitrary positive numbers without the restriction that the corresponding probabilities must sum to 1.",2.1. The Viterbi Path Problem,[0],[0]
"See Appendix C for a discussion.
",2.1. The Viterbi Path Problem,[0],[0]
"A simpler special case of the VITERBI PATH problem asks to compute the most likely path of length T without any observations.
",2.1. The Viterbi Path Problem,[0],[0]
Definition 3 (Shortest Walk Problem).,2.1. The Viterbi Path Problem,[0],[0]
"Given an integer T and a weighted directed graph (with possible self-loops) on n vertices with edge weights specified by a matrixA, the SHORTEST WALK problem asks to compute a sequence of vertices u0 = 1, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ∈",2.1. The Viterbi Path Problem,[0],[0]
"[n] that solves
arg min u0=1,u1,...,uT T∑ t=1 A(ut−1, ut).
",2.1. The Viterbi Path Problem,[0],[0]
"It is easy to see that the SHORTEST WALK problem corresponds to the VITERBI PATH problem when σ = 1 and B(u, 1) = 0 for all u ∈",2.1. The Viterbi Path Problem,[0],[0]
[n].,2.1. The Viterbi Path Problem,[0],[0]
"We use the hardness assumptions of the following problems.
",2.2. Hardness assumptions,[0],[0]
Definition 4 (ALL-PAIRS SHORTEST PATHS (APSP) problem).,2.2. Hardness assumptions,[0],[0]
"Given an undirected graph G = (V,E) with n vertices and positive integer weights on the edges, find the shortest path between u and v for every u, v ∈ V .
",2.2. Hardness assumptions,[0],[0]
"The APSP conjecture states that the ALL-PAIRS SHORTEST PATHS problem requires Ω(n3)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
Conjecture 1 (APSP conjecture).,2.2. Hardness assumptions,[0],[0]
"The ALL-PAIRS SHORTEST PATHS problem on a graph with n vertices and positive integer edge-weights bounded by nO(1) requires Ω(n3)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
"There is a long list of works showing conditional hardness for various problems based on the All-Pairs Shortest Paths conjecture (Roditty & Zwick, 2004; Williams & Williams, 2010; Abboud & Williams, 2014; Abboud et al., 2015b;c).
",2.2. Hardness assumptions,[0],[0]
Definition 5 (MIN-WEIGHT k-CLIQUE problem).,2.2. Hardness assumptions,[0],[0]
"Given a complete graphG = (V,E) with n vertices and positive integer edge-weights, output the minimum total edge-weight of a k-clique in the graph.
",2.2. Hardness assumptions,[0],[0]
"This is a very well studied computational problem and despite serious efforts, the best known algorithm for this problem still runs in time O(nk−o(1)), which matches the runtime of the trivial algorithm up to subpolynomial factors.",2.2. Hardness assumptions,[0],[0]
"The k-Clique conjecture states that this problem requires Ω(nk)1−o(1) time and it has served as a basis for showing conditional hardness results for several problems on sequences (Abboud et al., 2015a; 2014; Bringmann et al., 2016) and computational geometry (Backurs et al., 2016).
",2.2. Hardness assumptions,[0],[0]
Conjecture 2 (k-Clique conjecture).,2.2. Hardness assumptions,[0],[0]
"The MIN-WEIGHT k-CLIQUE problem on a graph with n vertices and positive integer edge-weights bounded by nO(k) requires Ω(nk)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
"For k = 3, the MIN-WEIGHT 3-CLIQUE problem asks to find the minimum weight triangle in a graph.",2.2. Hardness assumptions,[0],[0]
This problem is also known as the MINIMUM TRIANGLE problem and under the 3-Clique conjecture it requires Ω(n3)1−o(1) time.,2.2. Hardness assumptions,[0],[0]
"The latter conjecture is equivalent to the APSP conjecture (Williams & Williams, 2010).
",2.2. Hardness assumptions,[0],[0]
"We often use the following variant of the MIN-WEIGHT k-CLIQUE problem:
Definition 6 (MIN-WEIGHT k-CLIQUE problem for k-partite graphs).",2.2. Hardness assumptions,[0],[0]
Given a complete k-partite graph G = (V1 ∪ . . .,2.2. Hardness assumptions,[0],[0]
"∪ Vk, E) with |Vi| = ni and positive integer weights on the edges, output the minimum total edgeweight of a k-clique in the graph.
",2.2. Hardness assumptions,[0],[0]
"If for all i, j we have that ni = n Θ(1)",2.2. Hardness assumptions,[0],[0]
"j , it can be shown that the MIN-WEIGHT k-CLIQUE problem for k-partite graphs
requires Ω (∏k
i=1",2.2. Hardness assumptions,[0],[0]
"ni
)1−o(1) time assuming the k-Clique
conjecture.",2.2. Hardness assumptions,[0],[0]
We provide a simple proof of this statement in the appendix.,2.2. Hardness assumptions,[0],[0]
"We begin by presenting our main hardness result for the VITERBI PATH problem.
",3. Hardness of VITERBI PATH,[0],[0]
Theorem 1.,3. Hardness of VITERBI PATH,[0],[0]
"The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.
",3. Hardness of VITERBI PATH,[0],[0]
"To show APSP hardness, we will perform a reduction from the MINIMUM TRIANGLE problem (described in Section 2.2) to the VITERBI PATH problem.",3. Hardness of VITERBI PATH,[0],[0]
"In the instance of the MINIMUM TRIANGLE problem, we are given a 3- partite graph G = (V1 ∪ V2 ∪ U, E) such that |V1| = |V2| = n, |U | = m.",3. Hardness of VITERBI PATH,[0],[0]
"We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed graph G′ = ({1, 2} ∪ V1 ∪ V2, E′).",3. Hardness of VITERBI PATH,[0],[0]
"E′ contains all the edges of G between V1 and V2, directed from V1 towards V2, edges from 1 towards all nodes of V1 of weight 0 and edges from all nodes of V2 towards 2 of weight 0.",3. Hardness of VITERBI PATH,[0],[0]
"We also add a self-loops at nodes 1 and 2 of weight 0.
",3. Hardness of VITERBI PATH,[0],[0]
"We create an instance of the VITERBI PATH problem (A,B, S) as described below.",3. Hardness of VITERBI PATH,[0],[0]
"Figure 1 illustrates the construction of the instance.
",3. Hardness of VITERBI PATH,[0],[0]
"• Matrix A is the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and non-existent self-loops.
",3. Hardness of VITERBI PATH,[0],[0]
"• The alphabet of the HMM is U ∪ {⊥,⊥F } and thus matrix B has 2n + 2 rows and σ",3. Hardness of VITERBI PATH,[0],[0]
= m + 2 columns.,3. Hardness of VITERBI PATH,[0],[0]
"For all v ∈ V1 ∪V2 and u ∈ U , B(v, u) is equal to the weight of the edge (v, u) in graphG.",3. Hardness of VITERBI PATH,[0],[0]
"Moreover, for all v ∈ V1 ∪ V2, B(v,⊥)",3. Hardness of VITERBI PATH,[0],[0]
=,3. Hardness of VITERBI PATH,[0],[0]
"+∞ (or a sufficiently large number) and for all v ∈ V1 ∪ V2 ∪ {1}, B(v,⊥F )",3. Hardness of VITERBI PATH,[0],[0]
"= +∞. Finally, all remaining entries corresponding to nodes 1 and 2 are 0.
",3. Hardness of VITERBI PATH,[0],[0]
"• Sequence S of length T = 3m + 1 is generated by appending the observations u, u and ⊥ for all u ∈ U and adding a ⊥F observation at the end.
",3. Hardness of VITERBI PATH,[0],[0]
"Given the above construction, the theorem statement follows directly from the following claim.
",3. Hardness of VITERBI PATH,[0],[0]
Claim 1.,3. Hardness of VITERBI PATH,[0],[0]
"The weight of the solution to the VITERBI PATH instance is equal to the weight of the minimum triangle in the graph G.
Proof.",3. Hardness of VITERBI PATH,[0],[0]
The optimal path for the VITERBI PATH instance begins at node 1.,3. Hardness of VITERBI PATH,[0],[0]
"It must end in node 2 since otherwise when observation ⊥F arrives we collect cost +∞. Similarly, whenever an observation ⊥ arrives the path must be either on node 1 or 2.",3. Hardness of VITERBI PATH,[0],[0]
"Thus, the path first loops in node 1 and then goes from node 1 to node 2 during three consecutive observations u, u and ⊥ for some u ∈ U and stays in node 2 until the end.",3. Hardness of VITERBI PATH,[0],[0]
Let v1 ∈ V1 and v2 ∈ V2 be the two nodes visited when moving from node 1 to node 2.,3. Hardness of VITERBI PATH,[0],[0]
"The only two steps of non-zero cost are:
1.",3. Hardness of VITERBI PATH,[0],[0]
Moving from node 1 to node v1 at the first observation u.,3. Hardness of VITERBI PATH,[0],[0]
"This costs A(1, v1) +B(v1, u) = B(v1, u).
2.",3. Hardness of VITERBI PATH,[0],[0]
Moving from node v1 to node v2 at the second observation u.,3. Hardness of VITERBI PATH,[0],[0]
"This costs A(v1, v2) +B(v2, u).
",3. Hardness of VITERBI PATH,[0],[0]
"Thus, the overall cost of the path is equal to B(v1, u) + A(v1, v2) +",3. Hardness of VITERBI PATH,[0],[0]
"B(v2, u), which is equal to the weight of the triangle (v1, v2, u) in G. Minimizing the cost of the path in this instance is therefore the same as finding the minimum weight triangle in G.",3. Hardness of VITERBI PATH,[0],[0]
"The proof of Theorem 1 requires a large alphabet size, which can be as large as the number of total steps T .",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"In the appendix, we show how to get a lower bound for the VITERBI PATH problem on alphabets of small size by using a different hardness assumption.
",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
Theorem 2.,4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"In this section, we focus on the extreme case of VITERBI PATH with unary alphabet.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Theorem 4.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
The VITERBI PATH problem requires Ω(Tn2)1−o(1) time when T ≤ n,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"even if the size of the alphabet is σ = 1, assuming the APSP Conjecture.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The above theorem follows from APSP-hardness of the SHORTEST WALK problem that we present next.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Theorem 5.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The SHORTEST WALK problem requires Ω(Tn2)1−o(1) time when T ≤ n, assuming the APSP Conjecture.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Proof.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We will perform a reduction from the MINIMUM TRIANGLE problem to the VITERBI PATH
problem.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"In the instance of the MINIMUM TRIANGLE problem, we are given a 3-partite undirected graph G = (V1 ∪ V2 ∪ U, E) with positive edge weights such that |V1| = |V2| = n, |U | = m.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed and acyclic graph G′ = ({1, 2} ∪ V1 ∪ V2 ∪ U ∪ U ′, E′).",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Nodes in U ′ are in one-to-one correspondence with nodes in U and |U ′| = m. E′ is defined as follows.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We add all edges of G between nodes in U and V1 directed from U towards V1 and similarly, we add all edges of G between nodes in V1 and V2 directed from V1 towards V2.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Instead of having edges between nodes in V2 and U , we add the corresponding edges of G between nodes in V2 and U ′ directed from V2 towards U ′.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Moreover, we add additional edges of weight 0 to create a path P of m + 1 nodes, starting from node 1 and going through all nodes in U in some order.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Finally, we create another path P ′ of m + 1 nodes going through all nodes in U ′",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
in the same order as their counterparts on path P and ending at node 2.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"These edges have weight 0 apart from the last one, entering node 2, which has weight −C (a sufficiently large negative constant)3.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We create an instance of the SHORTEST WALK problem by setting T = m+ 4 and A to be the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and self-loops.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
The optimal walk of the SHORTEST WALK instance must include the edge of weight −C entering node 2 since otherwise the cost will be non-negative.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Moreover, the walk
3Since the definition of SHORTEST WALK doesn’t allow negative weights, we can equivalently set its weight to be 0 and add C to all the other edge weights.
must reach node 2 exactly at the last step since otherwise the cost will be +∞ as there are no outgoing edges from node 2.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"By the choice of T , the walk leaves path P at some node u ∈ U , then visits nodes v1 and v2 in V1 and V2, respectively, and subsequently moves to node u′ ∈ U ′ where u′ is the counterpart of u on path P ′. The total cost of the walk is thus the weight of the triangle (u, v1, v2) in G, minus C. Therefore, the optimal walk has cost equal to the weight of the minimum triangle up to the additive constant C.
Notice that when T > n, the runtime of the Viterbi algorithm is no longer optimal.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We now present a faster algorithm with a total running time log T · n3/2Ω( √ logn).
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"As we show in Section 7, the general VITERBI PATH problem reduces, according to Equation 2, to computing (min,+) matrix-vector products.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"In the case of unary alphabet, it corresponds to computing (min,+) matrixvector product T times as follows: A ⊕ A ⊕ ... ⊕",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
A ⊕ z.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"This can be equivalently performed by first computing all (min,+) matrix-matrix products A⊕T = A⊕A⊕ ...⊕A using exponentiation with repeated squaring and then multiplying the resulting matrix with the vector z.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"This requires only O(log T ) matrix (min,+)-multiplications.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Using the currently best algorithm for (min,+) matrix product (Williams, 2014), we get an algorithm with total running time log T · n3/2Ω( √ logn).",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The VITERBI PATH lower-bounds we have provided apply to the case where the HMM has all n2 possible edges.
",6. Hardness for sparse HMMs,[0],[0]
"For sparse HMMs that have at most m edges out of the
n2 possible ones, i.e. the transition matrix has at most m non-zero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time.",6. Hardness for sparse HMMs,[0],[0]
The lower bounds that we presented in the paper can be adapted directly for this case to show that no faster algorithm exists that runs in time O(Tm)1−ε.,6. Hardness for sparse HMMs,[0],[0]
This can be easily seen via a padding argument.,6. Hardness for sparse HMMs,[0],[0]
Consider a hard instance for VITERBI PATH on a dense HMM with √ m states andm edges.,6. Hardness for sparse HMMs,[0],[0]
"Adding n− √ m additional states with self-loops, we obtain a sparse instance with n states and m + n",6. Hardness for sparse HMMs,[0],[0]
− √ m = O(m) edges.,6. Hardness for sparse HMMs,[0],[0]
"Thus, any algorithm that computes the optimal Viterbi Path in O(Tm)1−ε time for the resulting instance would solve the original instance with √ m states in O ( T ( √ m)2
)1−ε time contradicting the corresponding lower bound.
",6. Hardness for sparse HMMs,[0],[0]
"This observation directly gives the following lower bounds for VITERBI PATH problem, parametrized by the number m of edges in an HMM with n states.
",6. Hardness for sparse HMMs,[0],[0]
Theorem 6.,6. Hardness for sparse HMMs,[0],[0]
"The VITERBI PATH problem requires Ω(Tm)1−o(1) time for an HMM with m edges and n states, assuming the APSP Conjecture.
",6. Hardness for sparse HMMs,[0],[0]
Theorem 7.,6. Hardness for sparse HMMs,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(mC) observations from an alphabet of size Θ(mε) requires Ω(Tm)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.",6. Hardness for sparse HMMs,[0],[0]
Theorem 8.,6. Hardness for sparse HMMs,[0],[0]
The VITERBI PATH problem requires Ω(Tm)1−o(1) time when T ≤,6. Hardness for sparse HMMs,[0],[0]
√ m even if the size of the alphabet is σ,6. Hardness for sparse HMMs,[0],[0]
= 1,6. Hardness for sparse HMMs,[0],[0]
", assuming the APSP Conjecture.",6. Hardness for sparse HMMs,[0],[0]
"In this section, we present a faster algorithm for the VITERBI PATH problem, when there are only few distinct transition probabilities in the underlying HMM.",7. A faster VITERBI PATH algorithm,[0],[0]
Theorem 3.,7. A faster VITERBI PATH algorithm,[0],[0]
"When there are fewer than 2ε √
logn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.
",7. A faster VITERBI PATH algorithm,[0],[0]
The number of distinct transition probabilities is equal to the number of distinct entries in matrix Ã in Definition 1.,7. A faster VITERBI PATH algorithm,[0],[0]
"The same is true for matrix A in the additive version of VITERBI PATH, in Definition 2.",7. A faster VITERBI PATH algorithm,[0],[0]
"So, from the theorem statement we can assume that matrixA has at most 2ε √ logn different entries for some constant ε > 0.
",7. A faster VITERBI PATH algorithm,[0],[0]
"To present our algorithm, we revisit the definition of VITERBI PATH.",7. A faster VITERBI PATH algorithm,[0],[0]
"We want to compute a path u0 = 1, u1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", uT that minimizes the quantity:
min u0=1,u1,...,uT T∑ t=1",7. A faster VITERBI PATH algorithm,[0],[0]
"[A(ut−1, ut) +B(ut, st)] .",7. A faster VITERBI PATH algorithm,[0],[0]
"(1)
Defining the vectors bt = B(·, st), we note that (1) is equal
to the minimum entry in the vector obtained by a sequence of T (min,+) matrix-vector products4 as follows:
A⊕ (. . .",7. A faster VITERBI PATH algorithm,[0],[0]
(A⊕ (A⊕ (A⊕z+ b1)+ b2)+ b3) . .,7. A faster VITERBI PATH algorithm,[0],[0]
.)+,7. A faster VITERBI PATH algorithm,[0],[0]
"bT (2)
where z is a vector with entries",7. A faster VITERBI PATH algorithm,[0],[0]
z1 = 0 and zi = ∞ for all i 6= 1.,7. A faster VITERBI PATH algorithm,[0],[0]
Vector z represents the cost of being at node i at time 0.,7. A faster VITERBI PATH algorithm,[0],[0]
Vector (A ⊕ z + b1) represents the minimum cost of reaching each node at time 1 after seeing observation s1.,7. A faster VITERBI PATH algorithm,[0],[0]
"After T steps, every entry i of vector (2) represents the minimum minimum cost of a path that starts at u0 = 1 and ends at uT = i after T observations.",7. A faster VITERBI PATH algorithm,[0],[0]
"Taking the minimum of all entries gives the cost of the solution to the VITERBI PATH instance.
",7. A faster VITERBI PATH algorithm,[0],[0]
"To evaluate (2), we design an online (min,+) matrixvector multiplication algorithm.",7. A faster VITERBI PATH algorithm,[0],[0]
"In the online matrix-vector multiplication problem, we are given a matrix and a sequence of vectors in online fashion.",7. A faster VITERBI PATH algorithm,[0],[0]
We are required to output the result of every matrix-vector product before receiving the next vector.,7. A faster VITERBI PATH algorithm,[0],[0]
"Our algorithm for online (min,+) matrix-vector multiplication is based on a recent algorithm for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017):
Theorem 9 (Green Larsen and Williams (Larsen & Williams, 2017)).",7. A faster VITERBI PATH algorithm,[0],[0]
"For any matrix M ∈ {0, 1}n×n and any sequence of T = 2ω( √ logn) vectors v1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", vT ∈ {0, 1}n, online Boolean matrix-vector multiplication of M and vi can be performed in n2/2Ω( √ logn) amortized time whp.",7. A faster VITERBI PATH algorithm,[0],[0]
"No preprocessing is required.
",7. A faster VITERBI PATH algorithm,[0],[0]
"We show the following theorem for online (min,+) matrix-vector multiplication, which gives the promised runtime for the VITERBI PATH problem5 since we are interested in the case where T and n are polynomially related, i.e. T = nΘ(1).
",7. A faster VITERBI PATH algorithm,[0],[0]
Theorem 10.,7. A faster VITERBI PATH algorithm,[0],[0]
"Let A ∈ Rn×n be a matrix with at most 2ε √
logn distinct entries for a constant ε > 0.",7. A faster VITERBI PATH algorithm,[0],[0]
"For any sequence of T = 2ω( √ logn) vectors v1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", vT ∈ Rn, online (min,+) matrix-vector multiplication of A and vi can be performed in n2/2Ω( √ logn) amortized time whp.",7. A faster VITERBI PATH algorithm,[0],[0]
"No preprocessing is required.
",7. A faster VITERBI PATH algorithm,[0],[0]
Proof.,7. A faster VITERBI PATH algorithm,[0],[0]
"We will show the theorem for the case where A ∈ {0,+∞}n×n.",7. A faster VITERBI PATH algorithm,[0],[0]
The general case where matrix A has d ≤,7. A faster VITERBI PATH algorithm,[0],[0]
2ε,7. A faster VITERBI PATH algorithm,[0],[0]
"√
logn distinct values a1, ..., ad can be handled by creating d matrices A1, ..., Ad, where each matrix Ak has entries Akij = 0",7. A faster VITERBI PATH algorithm,[0],[0]
"if Aij = a
k and +∞ otherwise.",7. A faster VITERBI PATH algorithm,[0],[0]
"Then, vector 4A (min,+) product between a matrix M and a vector v is denoted by M ⊕ v and is equal to a vector u where ui = minj(Mi,j + vj).
",7. A faster VITERBI PATH algorithm,[0],[0]
"5Even though computing all (min,+) products does not directly give a path for the VITERBI PATH problem, we can obtain one at no additional cost by storing back pointers.",7. A faster VITERBI PATH algorithm,[0],[0]
"This is standard and we omit the details.
",7. A faster VITERBI PATH algorithm,[0],[0]
r = A⊕v can be computed by computing rk =,7. A faster VITERBI PATH algorithm,[0],[0]
"Ak⊕v for every k and setting ri = mink(rki + a
k).",7. A faster VITERBI PATH algorithm,[0],[0]
"This introduces a factor of 2ε √ logn in amortized runtime but the final amortized runtime remains n2/2Ω( √
logn)",7. A faster VITERBI PATH algorithm,[0],[0]
if ε > 0 is sufficiently small.,7. A faster VITERBI PATH algorithm,[0],[0]
"From now on we assume thatA ∈ {0,+∞}n×n and define the matrix Ā ∈ {0, 1}n×n whose every entry is 1 if the corresponding entry at matrix A is 0 and 0 otherwise.
",7. A faster VITERBI PATH algorithm,[0],[0]
"For every query vector v, we perform the following:
– Sort indices i1, ..., in such that vi1 ≤ ...",7. A faster VITERBI PATH algorithm,[0],[0]
≤ vin in O(n log n) time.,7. A faster VITERBI PATH algorithm,[0],[0]
"– Partition the indices into p = 2α √
logn sets, where set Sk contains indices i(k−1)dnp e+1, ..., ikdnp e.
–",7. A faster VITERBI PATH algorithm,[0],[0]
"Set r = (⊥, ...,⊥)T , where ⊥ indicates an undefined value.
– For k = 1...p fill the entries of r as follows:
- Let ISk be the indicator vector of Sk that takes value 1 at index",7. A faster VITERBI PATH algorithm,[0],[0]
i if i ∈ Sk and 0 otherwise.,7. A faster VITERBI PATH algorithm,[0],[0]
- Compute the Boolean matrix-vector product πk = Ā,7. A faster VITERBI PATH algorithm,[0],[0]
"ISk using the algorithm from Theorem 9.
- Set rj =",7. A faster VITERBI PATH algorithm,[0],[0]
"mini∈Sk(Aj,i + vi) for all j ∈",7. A faster VITERBI PATH algorithm,[0],[0]
"[n] such that rj = ⊥ and πkj = 1.
– Return vector r.
Runtime of the algorithm per query The algorithm performs p = 2α √ logn Boolean matrix-vector multiplications, for a total amortized cost of p · n2/2Ω( √ logn) = n2/2Ω( √
logn) for a small enough constant α > 0.",7. A faster VITERBI PATH algorithm,[0],[0]
"Moreover, to fill an entry rj the algorithm requires going through all elements in some set Sk for a total runtime ofO(|Sk|) = n/2Ω( √ logn).",7. A faster VITERBI PATH algorithm,[0],[0]
"Thus, for all entries pj the total time required is n2/2Ω( √
logn).",7. A faster VITERBI PATH algorithm,[0],[0]
"The runtime of the other steps is dominated by these two operations so the algorithm takes n2/2Ω( √ logn) amortized time per query.
",7. A faster VITERBI PATH algorithm,[0],[0]
"Correctness of the algorithm To see that the algorithm correctly computes the (min,+) product A ⊕ v, observe that the algorithm fills in the entries of vector r from smallest to largest.",7. A faster VITERBI PATH algorithm,[0],[0]
"Thus, when we set a value to entry rj we never have to change it again.",7. A faster VITERBI PATH algorithm,[0],[0]
"Moreover, if the value rj gets filled at step k, it must be the case that πk ′
j = 0 for all k′",7. A faster VITERBI PATH algorithm,[0],[0]
< k.,7. A faster VITERBI PATH algorithm,[0],[0]
"This means that for all indices i ∈ S1 ∪ ... ∪ Sk−1 the corresponding entry Aj,i was always +∞.",7. A faster VITERBI PATH algorithm,[0],[0]
"We thank Piotr Indyk for many helpful discussions, for comments on an earlier version of the writeup and for suggestion on how to improve the presentation.",Acknowledgments,[0],[0]
"We also thank
the anonymous reviewers for their careful reviews.",Acknowledgments,[0],[0]
"This work was supported in part by an IBM PhD Fellowship, the NSF and the Simons Foundation.",Acknowledgments,[0],[0]
The classic algorithm of Viterbi computes the most likely path in a Hidden Markov Model (HMM) that results in a given sequence of observations.,abstractText,[0],[0]
It runs in time O(Tn) given a sequence of T observations from a HMM with n states.,abstractText,[0],[0]
"Despite significant interest in the problem and prolonged effort by different communities, no known algorithm achieves more than a polylogarithmic speedup.",abstractText,[0],[0]
"In this paper, we explain this difficulty by providing matching conditional lower bounds.",abstractText,[0],[0]
Our lower bounds are based on assumptions that the best known algorithms for the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight k-Clique problem in edge-weighted graphs are essentially tight.,abstractText,[0],[0]
"Finally, using a recent algorithm by Green Larsen and Williams for online Boolean matrix-vector multiplication, we get a 2 √ logn) speedup for the Viterbi algorithm when there are few distinct transition probabilities in the HMM.",abstractText,[0],[0]
Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 51–57 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2009",text,[0],[0]
Language identification (LID) is an essential first step for NLP on multilingual text.,1 Introduction,[0],[0]
"In global settings like Twitter, this text is written by authors from diverse linguistic backgrounds, who may communicate with regional dialects (Gonçalves and Sánchez, 2014) or even include parallel translations in the same message to address different audiences (Ling et al., 2013, 2016).",1 Introduction,[0],[0]
"Such dialectal variation is frequent in all languages and even macro-dialects such as American and British English are composed of local dialects that vary across city and socioeconomic development level (Labov, 1964; Orton et al., 1998).",1 Introduction,[0],[0]
"Yet current systems for broad-coverage LID—trained on dozens of languages—have largely leveraged Europeancentric corpora and not taken into account demo-
graphic and dialectal variation.",1 Introduction,[0],[0]
"As a result, these systems systematically misclassify texts from populations with millions of speakers whose local speech differs from the majority dialects (Hovy and Spruit, 2016; Blodgett et al., 2016).
",1 Introduction,[0],[0]
"Multiple systems have been proposed for broadcoverage LID at the global level (McCandless, 2010; Lui and Baldwin, 2012; Brown, 2014; Jaech et al., 2016).",1 Introduction,[0],[0]
"However, only a handful of techniques have addressed the challenge of linguistic variability of global data, such as the dialectal variability and multilingual text seen in Figure 1.",1 Introduction,[0],[0]
"These techniques have typically focused only on limited aspects of variability, e.g., individual dialects like African American Vernacular English (Blodgett et al., 2016), online speech (Nguyen and Doğruöz, 2013), similar languages (Bergsma et al., 2012; Zampieri et al., 2014a), or word-level code switching (Solorio et al., 2014; Rijhwani et al., 2017).
",1 Introduction,[0],[0]
"In this work, our goal is to devise a socially equitable LID, that will enable a massively multilingual, broad-coverage identification of populations speaking underrepresented dialects, multilingual messages, and other linguistic varieties.",1 Introduction,[0],[0]
We first construct a large-scale dataset of Twitter posts across the world (§2).,1 Introduction,[0],[0]
"Then, we introduce an LID system, EQUILID, that produces pertoken language assignments and obtains state-ofthe-art performance on four LID tasks (§3), outperforming broad-coverage LID benchmarks by
51
up to 300%.",1 Introduction,[0],[0]
"Finally, we present a case study on using Twitter for health monitoring and show that (1) current widely-used systems suffer from lower recall rates for texts from developing countries, and (2) our system substantially reduces this disparity and enables socially-equitable LID.",1 Introduction,[0],[0]
"Despite known linguistic variation in languages, current broad-coverage LID systems are trained primarily on European-centric sources (e.g., Lui and Baldwin, 2014), often due to data availability.",2 Curating Socially-Representative Text,[0],[0]
"Further, even when training incorporates seemingly-global texts from Wikipedia, their authors are still primarily from highly-developed countries (Graham et al., 2014).",2 Curating Socially-Representative Text,[0],[0]
"This latent bias can significantly affect downstream applications (as we later show in §4), since language ID is often assumed to be a solved problem (McNamee, 2005) and most studies employ off-the-shelf LID systems without considering how they were trained.
",2 Curating Socially-Representative Text,[0],[0]
"We aim to create a socially-representative corpus for LID that captures the variation within a language, such as orthography, dialect, formality, topic, and spelling.",2 Curating Socially-Representative Text,[0],[0]
"Motivated by the recent language survey of Twitter (Trampus, 2016), we next describe how we construct this corpus for 70 languages along three dimensions: geography, social and topical diversity, and multilinguality.",2 Curating Socially-Representative Text,[0],[0]
"Geographic Diversity We create a large-scale dataset of geographically-diverse text by bootstrapping with a people-centric approach (Bamman, 2015) that treats location and languagesspoken as demographic attributes to be inferred for authors.",2 Curating Socially-Representative Text,[0],[0]
"By inferring both for Twitter users and then collecting documents from monolingual users, we ensure that we capture regional variation in a language, rather than focusing on a particular aspect of linguistic variety.
",2 Curating Socially-Representative Text,[0],[0]
Individuals’ locations are inferred using the method of Compton et al. (2014) as implemented by Jurgens et al. (2015).,2 Curating Socially-Representative Text,[0],[0]
"The method first identifies the individuals who have reliable ground truth locations from geotagged tweets and then infers the locations of other individuals as the geographic center of their friends’ locations, iteratively applying this inference method to the whole social network.",2 Curating Socially-Representative Text,[0],[0]
"The method is accurate to within tens of kilometers on urban and rural users (Johnson et al., 2017), which is sufficient for the city-level analysis we use here.",2 Curating Socially-Representative Text,[0],[0]
"We use a network of 2.3B edges
from reciprocal mentions to locate 132M users.",2 Curating Socially-Representative Text,[0],[0]
"To identify monolingual users, we classify multiple tweets by the same individual and consider an author monolingual if they had at least 20 tweets and 95% were labeled with one language `.",2 Curating Socially-Representative Text,[0],[0]
All tweets by that author are then treated as being `.,2 Curating Socially-Representative Text,[0],[0]
"We use this relabeling process to automatically identify misclassified tweets, which when aggregated geographically, can potentially capture regional dialects and topics.1 We construct separate sets of monolinguals using langid.py and CLD2 as classifiers to mitigate the biases of each.",2 Curating Socially-Representative Text,[0],[0]
"Social and Topical Diversity Authors modulate their writing style for different social registers (Eisenstein, 2015; Tatman, 2015).",2 Curating Socially-Representative Text,[0],[0]
"Therefore, we include corpora from different levels of formality across a wide range of topics.",2 Curating Socially-Representative Text,[0],[0]
"Texts were gathered for all of the 70 languages from (1) Wikipedia articles and their more informal Talk pages, (2) Bible and Quran translations (3) JRC-Acquis (Steinberger et al., 2006), a collection of European legislation, (4) the UN Declaration of Human Rights, (5) the Watchtower online magazines, (6) the 2014 and 2015 iterations of the Distinguishing Similar Languages shared task (Zampieri et al., 2014b, 2015), and (7) the Twitter70 dataset (Trampus, 2016).",2 Curating Socially-Representative Text,[0],[0]
"We also include single-language corpora drawn from slang websites (e.g., Urban Dictionary) and the African American Vernacular English data from Blodgett et al. (2016).",2 Curating Socially-Representative Text,[0],[0]
"For all sources, we extract instances sequentially by aggregating sentences up to 140 characters.",2 Curating Socially-Representative Text,[0],[0]
"Multilingual Diversity Authors are known to generate multilingual texts on Twitter (Ling et al., 2013, 2014), with Rijhwani et al. (2017) estimating that 3.5% of tweets are code-switched.",2 Curating Socially-Representative Text,[0],[0]
"To capture the potential diversity in multilingual documents, we perform data augmentation to synthetically construct multilingual documents of tweet length by (1) sampling texts for two languages from arbitrary sources, (2) with 50% chance for each, truncating a text at the first occurrence of phrasal punctuation, and (3) concatenating the two texts together and adding it to the dataset (if ≤ 140 characters).",2 Curating Socially-Representative Text,[0],[0]
"We create only sentence-level or phrase-level code-switching rather than wordlevel switches to avoid classifier ambiguity for loan words, which is known to be a significant challenge (Çetinoğlu et al., 2016).
",2 Curating Socially-Representative Text,[0],[0]
"1A manual analysis of 500 tweets confirmed that nearly all cases (98.6%) where the classifier’s label differed from the author’s inferred language were misclassifications.
",2 Curating Socially-Representative Text,[0],[0]
Corpus Summary The geographically-diverse corpus was constructed from two Twitter datasets: 1.3B tweets drawn from a 10% sample of all tweets from March 2014 and 14.2M tweets drawn from 1% sample of all geotagged tweets from November 2016.,2 Curating Socially-Representative Text,[0],[0]
"Ultimately, we collected 97.8M tweets from 1.5M users across 197 countries and in 53 languages.",2 Curating Socially-Representative Text,[0],[0]
"After identifying monolingual authors in the dataset, 9.4% of the instances (9.1M) were labeled by CLD2 or langid.py with a different language than that spoken by its author; since nearly all are misclassifications, we view these posts as valuable data to correct systematic bias.
",2 Curating Socially-Representative Text,[0],[0]
A total of 258M instances were collected for the topically and socially-diverse corpora.,2 Curating Socially-Representative Text,[0],[0]
Multilingual instances were created by sampling text from all language pairs; a total of 3.2M synthetic instances were created.,2 Curating Socially-Representative Text,[0],[0]
Full details are reported in Supplementary Material.,2 Curating Socially-Representative Text,[0],[0]
"We introduce EQUILID, and evaluate it on monolingual and multilingual tweet-length text.",3 Equitable LID Classifier,[0],[0]
"Model Character-based neural network architectures are particularly suitable for LID, as they facilitate modeling nuanced orthographic and phonological properties of languages (Jaech et al., 2016; Samih et al., 2016), e.g., capturing regular morpheme occurrences within the words of a language.",3 Equitable LID Classifier,[0],[0]
"Further, character-based methods significantly reduce the model complexity compared to word-based methods; the latter require separate neural representations for each word form and therefore are prohibitive in multilingual environments that easily contain tens of millions of unique words.",3 Equitable LID Classifier,[0],[0]
"We use an encoder–decoder architecture (Cho et al., 2014; Sutskever et al., 2014) with an attention mechanism (Bahdanau et al., 2015).",3 Equitable LID Classifier,[0],[0]
"The encoder and the decoder are 3-layer recurrent neural networks with 512 gated recurrent units (Chung et al., 2014).",3 Equitable LID Classifier,[0],[0]
"The model is trained to tokenize character sequence input based on white space and output a sequence with each token’s language, with extra token types for punctuation, hashtags, and user mentions.",3 Equitable LID Classifier,[0],[0]
"Setup The data from our socially-representative corpus (§2) was split into training, development, and test sets (80%/10%/10%, respectively), separately partitioning the data from each source (e.g., Wikipedia).",3 Equitable LID Classifier,[0],[0]
"Due to different sizes, we imposed
a maximum of 50K instances per source and language to reduce training bias.",3 Equitable LID Classifier,[0],[0]
A total 52.3M instances were used for the final datasets.,3 Equitable LID Classifier,[0],[0]
Multilingual instances were generated from texts within their respective split to prevent test-train leakage.,3 Equitable LID Classifier,[0],[0]
"For the Twitter70 dataset, we use identical training, development, and test splits as Jaech et al. (2016).",3 Equitable LID Classifier,[0],[0]
The same trained model is used for all evaluations.,3 Equitable LID Classifier,[0],[0]
"All parameter optimization was performed on the development set using adadelta (Zeiler, 2012) with mini-batches of size 64 to train the models.",3 Equitable LID Classifier,[0],[0]
"The model was trained for 2.7M steps, which is roughly three epochs.
",3 Equitable LID Classifier,[0],[0]
"Comparison Systems We compare against two broad-coverage LID systems, langid.py (Lui and Baldwin, 2012) and CLD2 (McCandless, 2010), both of which have been widely used for Twitter within in the NLP community.",3 Equitable LID Classifier,[0],[0]
"CLD2 is trained on web page text, while langid.py was trained on newswire, JRC-Acquis, web pages, and Wikipedia.",3 Equitable LID Classifier,[0],[0]
"As neither was designed for Twitter, we preprocess text to remove user mentions, hashtags, and URLs for a more fair comparison.",3 Equitable LID Classifier,[0],[0]
"For multilingual documents, we substitute langid.py (Lui and Baldwin, 2012) with its extension, Polyglot, described in Lui et al. (2014) and designed for that particular task.
",3 Equitable LID Classifier,[0],[0]
"We also include the results reported in Jaech et al. (2016), who trained separate models for two benchmarks used here.",3 Equitable LID Classifier,[0],[0]
Their architecture uses a convolutional network to transform each input word into a vector using its characters and then feed the word vectors to an LSTM encoder that decodes to per-word soft-max distributions over languages.,3 Equitable LID Classifier,[0],[0]
These word-language distributions are averaged to identify the most-probable language for the input text.,3 Equitable LID Classifier,[0],[0]
"In contrast, our architecture uses only character-based representations and produces per-token language assignments.
",3 Equitable LID Classifier,[0],[0]
"Benchmarks We test the monolingual setting with three datasets: (1) the test portion of the geographically-diverse corpus from §2, which covers 53 languages (2) the test portion of the Twitter70 dataset, which covers 70 languages and (3) the TweetLID shared task (Zubiaga et al., 2016), which covers 6 languages.",3 Equitable LID Classifier,[0],[0]
"The TweetLID data includes Galician, which is not one of the 70 languages we include due to its relative infrequency.",3 Equitable LID Classifier,[0],[0]
"Therefore, we report results only on the non-Galician portions of the data.",3 Equitable LID Classifier,[0],[0]
"Multilingual LID is tested using the test data portion of the
synthetically-constructed multilingual data from 70 languages.",3 Equitable LID Classifier,[0],[0]
Models are evaluated using macroaveraged and micro-averaged F1.,3 Equitable LID Classifier,[0],[0]
"Macro-averaged F1 denotes the average F1 for each language, independent of how many instances were seen for that language.",3 Equitable LID Classifier,[0],[0]
Micro-averaged F1 denotes the F1 measured from all instances and is sensitive to the skew in the distribution of languages in the dataset.,3 Equitable LID Classifier,[0],[0]
Results EQUILID attains state-of-the-art performance over the other broad-coverage LID systems on all benchmarks.,3 Equitable LID Classifier,[0],[0]
"We attribute this increase to more representative training data; indeed, Jaech et al. (2016) reported langid.py obtains a substantially higher F1 of 0.879 when retrained only on Twitter70 data, underscoring the fact that broadcoverage systems are typically not trained on data as linguistically diverse as seen in social media.",3 Equitable LID Classifier,[0],[0]
"Despite being trained for general-purpose, EQUILID also outperformed the benchmark-optimized models of Jaech et al. (2016).
",3 Equitable LID Classifier,[0],[0]
"In the multilingual setting, EQUILID substantially outperforms both Polyglot and CLD2, with over a 300% increase in Macro-F1 over the former.",3 Equitable LID Classifier,[0],[0]
"Further, because our model can also identify the spans in each language, we view its performance as an important step towards an all-languages solution for detecting sentence and phrase-level switching between languages.",3 Equitable LID Classifier,[0],[0]
"Indeed, in the Twitter70 dataset, EQUILID found roughly 5% of the test data are unmarked instances of codeswitching, one of which is the third example in Figure 1.",3 Equitable LID Classifier,[0],[0]
"Error Analysis To identify main sources of classification errors, we manually analyzed the outputs of EQUILID on the test set of Twitter70.",3 Equitable LID Classifier,[0],[0]
"The dataset contains 9,572 test instances, 90.5% of which were classified correctly by our system; we discuss below sources of errors in the remaining 909 misclassified instances.
",3 Equitable LID Classifier,[0],[0]
"Classification of closely related languages with overlapping vocabularies written in a same script is the biggest source of errors (374 misclassified instances, 41.1% of all errors).",3 Equitable LID Classifier,[0],[0]
"Slavic languages
are the most challenging, with 177 Bosnian and 65 Slovenian tweets classified as Croatian.",3 Equitable LID Classifier,[0],[0]
"This is unsurprising, considering that even for a human annotator this task is challenging (or impossible).",3 Equitable LID Classifier,[0],[0]
"For example, a misclassified Bosnian tweet Sočni čokoladni biskvit recept (“juicy chocolate biscuit recipe”) would be the same in Croatian.",3 Equitable LID Classifier,[0],[0]
"IndoIranian languages contribute 39 errors, with Bengali, Marathi, Nepali, Punjabi, and Urdu tweets classified as Hindi.",3 Equitable LID Classifier,[0],[0]
"Among Germanic languages, Danish, Norwegian, and Swedish are frequently confused, contributing 22 errors.
",3 Equitable LID Classifier,[0],[0]
"Another major source of errors is due to transliteration and code switching with English: 328 messages in Hindi, Urdu, Tagalog, Telugu, and Punjabi were classified as English, contributing 36.1% of errors.",3 Equitable LID Classifier,[0],[0]
"A Hindi-labeled tweet dost tha or rahega ... dont wory ... but dherya rakhe (“he was and will remain a friend ... don’t worry ... but have faith”) is a characteristic example, misclassified by our system as English.",3 Equitable LID Classifier,[0],[0]
Reducing these types of errors is currently difficult due to the lack of transliterated examples for these languages.,3 Equitable LID Classifier,[0],[0]
"We conclude with a real-world case study on using Twitter posts as a real-time source of information for tracking health and well-being trends (Paul and Dredze, 2011; Achrekar et al., 2011; Aramaki et al., 2011).",4 Case Study: Health Monitoring,[0],[0]
This information is especially critical for regions where local authorities may not have sufficient resources to identify trends otherwise.,4 Case Study: Health Monitoring,[0],[0]
"Commonly, trend-tracking approaches first apply language identification to select language-specific content, and then apply sophisticated NLP techniques to identify content related to their target phenomena, e.g., distinguishing a flu comment from a hangover-related one.",4 Case Study: Health Monitoring,[0],[0]
"This setting is where socially-inclusive LID systems can make real, practical impact: LID systems that effectively classify languages of underrepresented dialects can substantially increase the re-
call of data for trend-tracking approaches, and thus help reveal dangerous trends in infectious diseases in the areas that need it most.
",4 Case Study: Health Monitoring,[0],[0]
"Language varieties are associated, among other factors, with social class (Labov, 1964; Ash, 2002) and ethnic identity (Rose, 2006; Mendoza-Denton, 1997; Dubois and Horvath, 1998).",4 Case Study: Health Monitoring,[0],[0]
"As a case study, we evaluate the efficacy of LID systems in identifying English tweets containing health lexicons, across regions with varying Human Development Index (HDI).2 We compare EQUILID against langid.py and CLD2.",4 Case Study: Health Monitoring,[0],[0]
"Setup A list of health-related terms was compiled from lexicons for influenza (Lamb et al., 2013); psychological well-being (Smith et al., 2016; Preoţiuc-Pietro et al., 2015); and temporal orientation lexica correlated with age, gender and personality traits (Park et al., 2016).",4 Case Study: Health Monitoring,[0],[0]
"We incorporate the 100 highest-weighted alphanumeric terms from each lexicon, for a total of 385 unique terms.
",4 Case Study: Health Monitoring,[0],[0]
"To analyze the possible effect of regional language, we selected 25 countries with Englishspeaking populations and constructed 62 bounding boxes for major cities therein for study (listed in Supplementary Material).",4 Case Study: Health Monitoring,[0],[0]
"Using the Gnip API, a total of 984K tweets were collected during January 2016 which used at least one term and were authored within one of the bounding boxes.",4 Case Study: Health Monitoring,[0],[0]
"As these tweets are required to contain domain-specific terms, the vast majority are English.3 We therefore measure each system’s performance according to what percent of these tweets they classify as English, which estimates their Recall.",4 Case Study: Health Monitoring,[0],[0]
"Results To understand how Human Development Index relates to LID performance, we train a Logit Regression to predict whether a tweet with one of the target terms will be recognized as English according to the HDI of the tweet’s origin country.",4 Case Study: Health Monitoring,[0],[0]
Figure 2 reveals increasing disparity in LID accuracy for developing countries by the two baseline models.,4 Case Study: Health Monitoring,[0],[0]
"In contrast, EQUILID outperforms both systems at all levels of HDI and provides 30% more observations for countries with the lowest development levels.",4 Case Study: Health Monitoring,[0],[0]
"This performance improvement is increasingly critical in the global environment as more English text is generated from populous developing countries such as Nigeria (HDI
2HDI is a composite of life expectancy, education, and income per capita indicators, used to rank countries into tiers of human development.
",4 Case Study: Health Monitoring,[0],[0]
"3A manual analysis of a random sample of 1000 tweets showed that 99.4% were in English.
0.527) and India (HDI 0.624), which have tens of millions of anglophones each.",4 Case Study: Health Monitoring,[0],[0]
"EQUILID provides a 23.9% and 17.4% improvement in recall of English tweets for each country, respectively.",4 Case Study: Health Monitoring,[0],[0]
This study corroborates our hypothesis that sociallyequitable training corpora are an essential first step towards socially-equitable NLP.,4 Case Study: Health Monitoring,[0],[0]
"Globally-spoken languages often vary in how they are spoken according to regional dialects, topics, or sociolinguistic factors.",5 Conclusion,[0],[0]
"However, most LID systems are not designed and trained for this linguistic diversity, which has downstream consequences for what types of text are considered a part of the language.",5 Conclusion,[0],[0]
"In this work, we introduce a sociallyequitable LID system, EQUILID, built by (1) creating a dataset representative of the types of diversity within languages and (2) explicitly modeling multilingual and codes-switched communication for arbitrary language pairs.",5 Conclusion,[0],[0]
"We demonstrate that EQUILID significantly outperforms current broad-coverage LID systems and, in a realworld case study on tracking health-related content, show that EQUILID substantially reduces the LID performance disparity between developing and developed countries.",5 Conclusion,[0],[0]
Our work continues a recent emphasis on NLP for social good by ensuring NLP tools fully represent all people.,5 Conclusion,[0],[0]
The EQUILID system is publicly available at https: //github.com/davidjurgens/equilid and data is available upon request.,5 Conclusion,[0],[0]
"We thank the anonymous reviewers, the Stanford Data Science Initiative, and Twitter and Gnip for providing access to part of data used in this study.",Acknowledgments,[0],[0]
"This work was supported by the National Science Foundation through awards IIS-1514268, IIS-1159679, and IIS-1526745.",Acknowledgments,[0],[0]
Language identification (LID) is a critical first step for processing multilingual text.,abstractText,[0],[0]
"Yet most LID systems are not designed to handle the linguistic diversity of global platforms like Twitter, where local dialects and rampant code-switching lead language classifiers to systematically miss minority dialect speakers and multilingual speakers.",abstractText,[0],[0]
We propose a new dataset and a character-based sequence-tosequence model for LID designed to support dialectal and multilingual language varieties.,abstractText,[0],[0]
Our model achieves state-of-theart performance on multiple LID benchmarks.,abstractText,[0],[0]
"Furthermore, in a case study using Twitter for health tracking, our method substantially increases the availability of texts written by underrepresented populations, enabling the development of “socially inclusive” NLP tools.",abstractText,[0],[0]
Incorporating Dialectal Variability for Socially Equitable Language Identification,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1232–1242 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1232",text,[0],[0]
"Word embedding, which is also termed distributed word representation, has been a hot topic in the area of Natural Language Processing (NLP).",1 Introduction,[0],[0]
"The derived word embeddings have been used in plenty of tasks such as text classification (Liu
∗This is the corresponding author.
",1 Introduction,[0],[0]
"et al., 2015), information retrieval (Manning et al., 2008), sentiment analysis (Shin et al., 2016), machine translation (Cho et al., 2014) and so on.",1 Introduction,[0],[0]
"Recently, some classic word embedding methods have been proposed, like Continuous Bag-ofWord (CBOW), Skip-gram (Mikolov et al., 2013a), Global Vectors (GloVe) (Pennington et al., 2014).",1 Introduction,[0],[0]
"These methods can usually capture word-level semantic information but ignore the meaningful inner structures of words like English morphemes or Chinese characters.
",1 Introduction,[0],[0]
"The effectiveness of exploiting the internal compositions of words has been validated by some previous work (Luong et al., 2013; Botha and Blunsom, 2014; Chen et al., 2015; Cotterell et al., 2016).",1 Introduction,[0],[0]
"Some of them compute the word embeddings by directly adding the representations of morphemes/characters to context words or optimizing a joint objective over distributional statistics and morphological properties (Qiu et al., 2014; Botha and Blunsom, 2014; Chen et al., 2015; Luong et al., 2013; Lazaridou et al., 2013), while others introduce some probabilistic graphical models to build relationship between words and their internal compositions.",1 Introduction,[0],[0]
"e.g., Bhatia et al. (2016) treat word embeddings as latent variables for a prior distribution, which reflects words’ morphological properties, and feed the latent variables into a neural sequence model to obtain final word embeddings.",1 Introduction,[0],[0]
"Cotterell et al. (2016) construct a Gaussian graphical model that binds the morphological analysis to pre-trained word embeddings, which can help to smooth the noisy embeddings.",1 Introduction,[0],[0]
"Besides, these two methods also have the ability to predict embeddings for unseen words.
",1 Introduction,[0],[0]
"Different from all the above models (we regard them as Explicit models in Fig. 1) where internal compositions are directly used to encode morphological regularities into words and the
composition embeddings like morpheme embeddings are generated as by-products, we explore a new way to employ the latent meanings of morphological compositions rather than the compositions themselves to train word embeddings.",1 Introduction,[0],[0]
"As shown in Fig. 1, according to the distributional semantics hypothesis (Sahlgren, 2008), incredible and unbelievable probably have similar word embeddings because they have similar context.",1 Introduction,[0],[0]
"As a matter of fact, incredible is a synonym of unbelievable and their embeddings are expected to be close enough.",1 Introduction,[0],[0]
"Since the morphemes of the two words are different, especially the roots cred and believ, the explicit models may not significantly shorten the distance between the words in the vector space.",1 Introduction,[0],[0]
"Fortunately, the latent meanings of the different morphemes are the same (e.g., the latent meanings of roots cred, believ are “believe”) as listed in the lookup table (derived from the resources provided by Michigan State University),1 which evidently implies that incredible and unbelievable share the same meanings.",1 Introduction,[0],[0]
"In addition, by replacing morphemes with their latent meanings, we can directly and simply quantize the similarities between words and their sub-compositions with the same metrics used in most NLP tasks, e.g., cosine similarity.",1 Introduction,[0],[0]
"Subsequently, the similarities are utilized to calculate the weights of latent meanings of morphemes for each word.
",1 Introduction,[0],[0]
"In this paper, we try different strategies to
1https://msu.edu/˜defores1/gre/roots/ gre_rts_afx1.htm
modify the input layer and update rules of a neural language model, e.g., CBOW, Skipgram, and propose three lightweight and efficient models, which are termed Latent Meaning Models (LMMs), to not only encode morphological properties into words but also enhance the semantic similarities among word embeddings.",1 Introduction,[0],[0]
"Usually, the vocabulary derived from the corpus contains vast majority or even all of the latent meanings.",1 Introduction,[0],[0]
"Rather than generating and training extra embeddings for latent meanings, we directly override the embeddings of the corresponding words in the vocabulary.",1 Introduction,[0],[0]
"Moreover, a word map is created to describe the relations between words and the latent meanings of their morphemes.
",1 Introduction,[0],[0]
"For comparison, our models together with the state-of-the-art baselines are tested on two basic NLP tasks, which are word similarity and syntactic analogy, and one downstream text classification task.",1 Introduction,[0],[0]
The results show that LMMs outperform the baselines and get satisfactory improvement on these tasks.,1 Introduction,[0],[0]
"In all, the main contributions of this paper are summarized as follows.
",1 Introduction,[0],[0]
"• Rather than directly incorporating the morphological compositions (surface forms) of words, we decide to employ the latent meanings of the compositions (underlying forms) to train the word embeddings.",1 Introduction,[0],[0]
"To validate the feasibility of our purpose, three specific models, named LMMs, are proposed with different strategies to incorporate the latent meanings.
",1 Introduction,[0],[0]
"• We utilize a medium-sized English corpus to train LMMs and the state-of-the-art baselines, and evaluate their performance on two basic NLP tasks, i.e., word similarity and syntactic analogy, and one downstream text classification task.",1 Introduction,[0],[0]
The results show that LMMs outperform the baselines on five word similarity datasets.,1 Introduction,[0],[0]
"On the golden standard Wordsim-353 and RG-65, LMMs approximately achieve 5% and 7% gains over CBOW, respectively.",1 Introduction,[0],[0]
"For the syntactic analogy and text classification tasks, LMMs also surpass all the baselines.
",1 Introduction,[0],[0]
"• We conduct experiments to analyze the impacts of parameter settings, and the results demonstrate that the performance of LMMs on the smallest corpus is similar to the performance of CBOW on the corpus that is five times as large, which convinces us that LMMs are of great advantages to enhance word embeddings compared with traditional methods.",1 Introduction,[0],[0]
"Considering the high efficiency of CBOW proposed by Mikolov et al. (2013a), our LMMs are built upon CBOW.",2 Background and Related Work,[0],[0]
"Here, we first review some backgrounds of CBOW, and then present some related work on recent word-level and morphology-based word embedding methods.
",2 Background and Related Work,[0],[0]
"CBOW with Negative Sampling With a sliding window, CBOW utilizes the context words in the window to predict the target word.",2 Background and Related Work,[0],[0]
"Given a sequence of tokens T = {t1, t2, · · · , tn}, where n is the size of a training corpus, the objective of CBOW is to maximize the following average log probability equation:
L = 1
n n∑ i=1",2 Background and Related Work,[0],[0]
"log p ( ti|context(ti) ) , (1)
where context(ti) represents the context words of ti in the slide window, p ( ti|context(ti) ) is derived by softmax.",2 Background and Related Work,[0],[0]
"Due to huge size of English vocabulary, p ( ti|context(ti) ) can not be calculated in a tolerable time.",2 Background and Related Work,[0],[0]
"Therefore, negative sampling and hierarchical softmax are proposed to solve this problem.",2 Background and Related Work,[0],[0]
"Owing to the efficiency of negative sampling, all our models are trained based on it.",2 Background and Related Work,[0],[0]
"In terms of negative sampling, the log
probability log p(tO|tI) is transformed as: log δ ( vec′(tO) T vec(tI) )",2 Background and Related Work,[0],[0]
"+
m∑ i=1 log [ 1− δ",2 Background and Related Work,[0],[0]
( vec′(ti) T vec(tI) ),2 Background and Related Work,[0],[0]
],2 Background and Related Work,[0],[0]
",
(2)
where m denotes the number of negative samples, and δ(·) is the sigmoid function.",2 Background and Related Work,[0],[0]
The first item of Eq.,2 Background and Related Work,[0],[0]
(2) is the probability of target word when its context is given.,2 Background and Related Work,[0],[0]
"The second item indicates the probability that negative samples do not share the same context as the target word.
",2 Background and Related Work,[0],[0]
"Word-level Word Embedding In general, word embedding models can mainly be divided into two branches.",2 Background and Related Work,[0],[0]
"One is based on neural network like the classic CBOW model (Mikolov et al., 2013a), while the other is based on matrix factorization.",2 Background and Related Work,[0],[0]
"Besides CBOW, Skip-gram (Mikolov et al., 2013a) is another widely used neuralnetwork-based model, which predicts the context by using the target word (Mikolov et al., 2013a).",2 Background and Related Work,[0],[0]
"As for matrix factorization, Dhillon et al. (2015) proposed a spectral word embedding method to measure the correlation between word information matrix and context information matrix.",2 Background and Related Work,[0],[0]
"In order to combine the advantages of models based on neural network and matrix factorization, Pennington et al. (2014) proposed a famous word embedding model named GloVe, which is reported to outperform the CBOW and Skip-gram models on some tasks.",2 Background and Related Work,[0],[0]
These models are effective to capture word-level semantic information while neglecting inner structures of words.,2 Background and Related Work,[0],[0]
"In contrast, the unheeded inner structures are utilized in both our LMMs and other morphology-based models.
",2 Background and Related Work,[0],[0]
"Morphology-based Word Embedding Recently, some more fine-grained word embedding models are proposed by exploiting the morphological compositions of words, e.g., root and affixes.",2 Background and Related Work,[0],[0]
"These morphology-based models can be divided into two main categories.
",2 Background and Related Work,[0],[0]
"The first category directly adds the representations of internal structures to word embeddings or optimizes a joint objective over distributional statistics and morphological properties (Luong et al., 2013; Qiu et al., 2014; Botha and Blunsom, 2014; Lazaridou et al., 2013; Chen et al., 2015; Kim et al., 2016; Cotterell and Schütze, 2015).",2 Background and Related Work,[0],[0]
"Chen et al. (2015) proposed a character-enhanced Chinese word embedding model, which splits a Chinese word into several characters and add the characters into the input layer of their models.
",2 Background and Related Work,[0],[0]
"Luong et al. (2013) utilized the morpheme segments produced by Morfessor (Creutz and Lagus, 2007) and constructed morpheme trees for words to learn morphologically-aware word embeddings by the recursive neural network.",2 Background and Related Work,[0],[0]
Kim et al. (2016) incorporated the convolutional character information into English words.,2 Background and Related Work,[0],[0]
"Their model can learn character-level semantic information for embeddings, which is proved to be effective for some morpheme-rich languages.",2 Background and Related Work,[0],[0]
"However, with a huge size architecture, it’s very time-consuming.",2 Background and Related Work,[0],[0]
"Cotterell et al. (2015) augmented the log linear model to make the words, which share similar morphemes, gather together in vector space.
",2 Background and Related Work,[0],[0]
"The other category tries to use probabilistic graphical models to connect words with their morphological compositions, and further learns word embeddings (Bhatia et al., 2016; Cotterell et al., 2016).",2 Background and Related Work,[0],[0]
"Bhatia et al. (2016) employed morphemes and made them as prior knowledge of the latent word embeddings, then fed the latent variables into a neural sequence model to obtain final word embeddings.",2 Background and Related Work,[0],[0]
Cotterell et al. (2016) proposed a morpheme-based post-processor for pre-trained word embeddings.,2 Background and Related Work,[0],[0]
"They constructed a Gaussian graphical model which can extrapolate continuous representations for unknown words.
",2 Background and Related Work,[0],[0]
"However, these morphology-based models directly exploit the internal compositions of words to encode morphological regularities into word embeddings, and some by-products are also produced like morpheme embeddings.",2 Background and Related Work,[0],[0]
"In contrast, we employ the latent meanings of morphological compositions to provide deeper insights for training better word embeddings.",2 Background and Related Work,[0],[0]
"Furthermore, since the latent meanings are included in the vocabulary, there is no extra embedding being generated.",2 Background and Related Work,[0],[0]
We leverage different strategies to modify the input layer and update rules of CBOW when incorporating the latent meanings of morphemes.,3 Our Latent Meaning Models,[0],[0]
"Three specific models, named Latent Meaning Model-Average (LMM-A), LMM-Similarity (LMM-S) and LMM-Max (LMM-M), are proposed.",3 Our Latent Meaning Models,[0],[0]
"It should be stated that, for now, our models mainly concern the derivational morphemes, which can be interpreted to some meaningful words or phrases (i.e., latent meanings), not the inflectional morphemes like tense, number,
gender, etc.",3 Our Latent Meaning Models,[0],[0]
LMM-A assumes that all latent meanings of morphemes of a word have equal contributions to the word.,3 Our Latent Meaning Models,[0],[0]
LMM-A is applicable to the condition where words are correctly segmented into morphemes and each morpheme is interpreted to appropriate latent meanings.,3 Our Latent Meaning Models,[0],[0]
"However, refining the latent meanings for morphemes is timeconsuming and needs vast human annotations.",3 Our Latent Meaning Models,[0],[0]
"To address this concern, LMM-S is proposed.",3 Our Latent Meaning Models,[0],[0]
"Motivated by the attention scheme, LMM-S holds the assumption that all latent meanings have different contributions, and assigns the outliers small weights to let them have little impact on the representation of the target word.",3 Our Latent Meaning Models,[0],[0]
"Furthermore, in LMM-M, we only keep the latent meanings which have the greatest contributions to the corresponding word.",3 Our Latent Meaning Models,[0],[0]
"In what follows, we are going to introduce each of our LMMs in detail.",3 Our Latent Meaning Models,[0],[0]
"At the end of this section, we will introduce the update rules of the models.",3 Our Latent Meaning Models,[0],[0]
"Given a sequence of tokens T = {t1, t2, · · · , tn}, LMM-A assumes that morphemes’ latent meanings of token ti (i ∈",3.1 LMM-A,[0],[0]
"[1, n]) have equal contributions to ti, as shown in Fig. 2.",3.1 LMM-A,[0],[0]
The item for ti in the word map is ti 7→ Mi.,3.1 LMM-A,[0],[0]
"Mi is a set of latent meanings of ti’s morphemes, and it consists of three sub-parts Pi, Ri and Si corresponding to the latent meanings of prefixes, roots and suffixes of ti, respectively.",3.1 LMM-A,[0],[0]
"Hence, at the input layer, the
modified embedding of ti can be expressed as
v̂ti = 1
2
( vti + 1
Ni ∑ w∈Mi vw ) , (3)
where vti is the original word embedding of ti, Ni denotes the length of Mi and vw indicates the embedding of latent meaning",3.1 LMM-A,[0],[0]
"w. Meanwhile, we assume the original word embedding and the average embeddings of vw (w ∈ Mi) have equal weights, i.e., 0.5.",3.1 LMM-A,[0],[0]
"Eventually, v̂ti rather than vti is utilized for training in CBOW.",3.1 LMM-A,[0],[0]
This model is proposed based on the attention scheme.,3.2 LMM-S,[0],[0]
We observe that many morphemes have more than one latent meaning.,3.2 LMM-S,[0],[0]
"For instance, prefix in- means “in” and “not”, and suffix -ible means “able” and “capable”.2 As Fig. 3 shows, for the item incredible 7→ {",3.2 LMM-S,[0],[0]
"[in, not],
[believe], [able, capable] }
in the word map, the latent meanings have different biases towards “incredible”.",3.2 LMM-S,[0],[0]
"Therefore, we assign different weights to latent meanings.",3.2 LMM-S,[0],[0]
We measure the weights of latent meanings by calculating the normalized similarities between token ti and the corresponding latent meanings.,3.2 LMM-S,[0],[0]
"For LMM-S, the modified embedding of ti can be rewritten as
v̂ti = 1
2
[ vti + ∑ w∈Mi ω<ti,w> · vw ] , (4)
where vti is the original vector of ti, and ω<ti,w> denotes the weight between ti and the latent meaning w (w ∈Mi).",3.2 LMM-S,[0],[0]
"We use cos(va, vb) to denote the
2All the latent meanings of roots and affixes are referred to the resources we mentioned before.
",3.2 LMM-S,[0],[0]
"cosine similarity between va and vb, then ω<ti,w> is expressed as follows:
ω<ti,w> = cos(vti , vw)∑
x∈Mi cos(vti , vx)
.",3.2 LMM-S,[0],[0]
(5),3.2 LMM-S,[0],[0]
"To further eliminate the impacts of some uncorrelated latent meanings to a word, in LMM-M, we only select the latent meanings that have maximum similarities to the token ti from Pi, Ri and Si.",3.3 LMM-M,[0],[0]
"As is shown in Fig. 4, the latent meaning “not” of prefix in is finally selected since the similarity between “not” and “incredible” is larger than that between “in” and “incredible”.",3.3 LMM-M,[0],[0]
"For token ti, LMM-M is mathematically defined as
v̂ti = 1
2
[ vti + ∑ w∈M imax ω<ti,w> · vw ] , (6)
where M imax = {P imax, Rimax, Simax} is the set of latent meanings with maximum similarities towards token ti, and P imax, R i max, S",3.3 LMM-M,[0],[0]
"i max are obtained by the following equations:
P imax = argmaxw cos(vti , vw), w ∈ Pi, Rimax = argmaxw cos(vti , vw),",3.3 LMM-M,[0],[0]
"w ∈ Ri, (7) Simax = argmaxw cos(vti , vw), w ∈ Si.
",3.3 LMM-M,[0],[0]
"The normalized weight ω<ti,w> (w ∈ M imax) can similarly be derived like Eq.",3.3 LMM-M,[0],[0]
(5).,3.3 LMM-M,[0],[0]
"After modifying the input layer of CBOW, Eq. (1) can be rewritten as
L̂ = 1
n n∑ i=1",3.4 Update Rules for LMMs,[0],[0]
"log p ( vti | ∑ tj∈context(ti) v̂tj ) , (8)
where v̂tj is the modified vector of vtj (tj ∈ context(ti)).",3.4 Update Rules for LMMs,[0],[0]
"Since the word map describes top-level relations between words and the latent meanings, these relations don’t change during the training period.",3.4 Update Rules for LMMs,[0],[0]
"All parameters introduced by our models can be directly derived using the word map and word vectors, thus no extra parameter needs to be trained.",3.4 Update Rules for LMMs,[0],[0]
"When the gradient is propagated back to the input layer, we update not just the word vector vtj (tj ∈ context(ti)) but the vectors of the latent meanings in the vocabulary with the same weights as they are added to the vector vtj .",3.4 Update Rules for LMMs,[0],[0]
"Before conducting experiments, some experimental settings are firstly introduced in this section.",4 Experimental Setup,[0],[0]
We utilize a medium-sized English corpus to train all word embedding models.,4.1 Corpus and Word Map,[0],[0]
"The corpus stems from the website of the 2013 ACL Workshop on Machine Translation3 and is used in (Kim et al., 2016).",4.1 Corpus and Word Map,[0],[0]
We choose the news corpus of 2009 whose size is about 1.7GB.,4.1 Corpus and Word Map,[0],[0]
"It contains approximately 500 million tokens and 600,000 words in the vocabulary.",4.1 Corpus and Word Map,[0],[0]
"To get better quality of the word embeddings, we filter all digits and some punctuation marks out of the corpus.
",4.1 Corpus and Word Map,[0],[0]
"For many languages, there exist large morphological lexicons or morphological tools that can analyze any word form (Cotterell and Schütze, 2015).",4.1 Corpus and Word Map,[0],[0]
"To create the word map, we need to obtain the morphemes of each word and interpret them with the lookup table mentioned above to get the latent meanings.",4.1 Corpus and Word Map,[0],[0]
"Usually, the lookup table can also be derived from the morphological lexicons for different languages, although it costs some time and manpower, we can create the lookup table once for all since it represents the common knowledge with respect to a certain language.",4.1 Corpus and Word Map,[0],[0]
"Specifically, we first perform an
3http://www.statmt.org/wmt13/ translation-task.html
unsupervised morpheme segmentation using Morefessor (Creutz and Lagus, 2007) for the vocabularies.",4.1 Corpus and Word Map,[0],[0]
"Then we execute matching between the segmentation results and the morphological compositions in the lookup table, and the character sequence with largest overlap ratio will be viewed as a final morpheme and further be replaced by its latent meanings.",4.1 Corpus and Word Map,[0],[0]
"Although the lookup table employed in this paper contains latent meanings for only 90 prefixes, 382 roots and 67 suffixes, we focus on validating the feasibility of enhancing word embeddings with the latent meanings of morphemes, and expending the lookup table is left as future work.",4.1 Corpus and Word Map,[0],[0]
"For comparison, we choose three word-level state-of-the-art word embedding models including CBOW, Skip-gram (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014), and we also implement an Explicitly Morpheme-related Model (EMM), which is a variant version of the previous work (Qiu et al., 2014).",4.2 Baselines,[0],[0]
"The architecture of EMM is based on our LMM-A, where latent meanings are replaced back to morphemes and the embeddings of morphemes are also learned when training word embeddings.",4.2 Baselines,[0],[0]
"This enables our evaluation to focus on the critical difference between our models and the explicit model (Bhatia et al., 2016).",4.2 Baselines,[0],[0]
We utilize the source code of word2vec4 to train CBOW and Skip-gram.,4.2 Baselines,[0],[0]
GloVe is trained based on the code5 provided by Pennington et al. (2014).,4.2 Baselines,[0],[0]
We modify the source of word2vec and train our models and EMM.,4.2 Baselines,[0],[0]
"Parameter settings have a great effect on the performance of word embeddings (Levy et al., 2015).",4.3 Parameter Settings,[0],[0]
"For fairness, all models are trained based on equal parameter settings.",4.3 Parameter Settings,[0],[0]
"In order to accelerate the training process, CBOW, Skip-gram and EMM together with our models are trained by using the negative sampling technique.",4.3 Parameter Settings,[0],[0]
"It is suggested that the number of negative samples in the range 5-20 is useful for small corpus (Mikolov et al., 2013b).",4.3 Parameter Settings,[0],[0]
"If large corpus is used, the number of negative samples can be as small as 2-5.",4.3 Parameter Settings,[0],[0]
"According to the size of corpus we used, the number of negative samples is empirically set to be 20 in this paper.
",4.3 Parameter Settings,[0],[0]
"4https://github.com/dav/word2vec 5http://nlp.stanford.edu/projects/
glove
The dimension of word embedding is set as 200 like that in (Dhillon et al., 2015).",4.3 Parameter Settings,[0],[0]
"We set the context window size as 5 which is equal to the setting in (Mikolov et al., 2013b).",4.3 Parameter Settings,[0],[0]
This experiment is conducted to evaluate the ability of word embeddings to capture semantic information from corpus.,4.4.1 Word Similarity,[0],[0]
"For English word similarity, we employ two gold standard datasets including Wordsim-353 (Finkelstein et al., 2001) and RG-65 (Rubenstein and Goodenough, 1965) as well as some other widely-used datasets including Rare-Word (Luong et al., 2013), SCWS (Huang et al., 2012), Men-3k (Bruni et al., 2014) and WS-353-Related (Agirre et al., 2009).",4.4.1 Word Similarity,[0],[0]
More details of these datasets are shown in Table 1.,4.4.1 Word Similarity,[0],[0]
Each dataset consists of three columns.,4.4.1 Word Similarity,[0],[0]
The first two columns stand for word pairs and the last column is human score.,4.4.1 Word Similarity,[0],[0]
"We utilize the cosine similarity, which is used in many previous works (Mikolov et al., 2013b; Pennington et al., 2014), as the metric to measure the distance between two words.",4.4.1 Word Similarity,[0],[0]
The Spearman’s rank correlation coefficient (ρ) is employed to evaluate the similarity between our results and human scores.,4.4.1 Word Similarity,[0],[0]
Higher ρ means better performance.,4.4.1 Word Similarity,[0],[0]
"Based on the learned word embeddings, the core task of syntactic analogy is to answer the analogy question “a is to b as c is to ”.",4.4.2 Syntactic Analogy,[0],[0]
"We utilize the Microsoft Research Syntactic Analogies dataset, which is created by Mikolov (Mikolov et al., 2013c) with size of 8000.",4.4.2 Syntactic Analogy,[0],[0]
"To answer the syntactic analogy question “a is to b as c is to d” where d is unknown, we assume that the word representations of a, b, c, d are va, vb, vc, vd, respectively.",4.4.2 Syntactic Analogy,[0],[0]
"To get d, we first calculate v̂d = vb − va + vc.",4.4.2 Syntactic Analogy,[0],[0]
"Then, we find out the word d′ whose cosine similarity to v̂d is the largest.",4.4.2 Syntactic Analogy,[0],[0]
"Finally, we set d as d′.",4.4.2 Syntactic Analogy,[0],[0]
"To further evaluate the learned word embeddings, we also conduct 4 text classification tasks using the 20 Newsgroups dataset.6",4.4.3 Text Classification,[0],[0]
"The dataset totally contains around 19000 documents of 20 different newsgroups, and each corresponding to a different topic, such as guns, motorcycles, electronics and so on.",4.4.3 Text Classification,[0],[0]
"For each task, we randomly select the documents of 10 topics and split them into training/validation/test subsets at the ratio of 6:2:2, which are emplyed to train, validate and test an L2-regularized 10-categorization logistic regression (LR) classifier.",4.4.3 Text Classification,[0],[0]
"As mentioned in (Tsvetkov et al., 2015), here we also regard the average word embedding of words (excluding stop words and out-of-vocabulary words) in each document as the feature vector (the input of the classifier) of that document.",4.4.3 Text Classification,[0],[0]
"The LR classifier is implemented with the scikit-learn toolkit (Pedregosa et al., 2011), which is an open-source Python module integrating many state-of-the-art machine learning algorithms.",4.4.3 Text Classification,[0],[0]
"Word similarity is conducted to test the semantic information which is encoded in word embeddings, and the results are listed in Table 2 (first 6 rows).",5.1 The Results on Word Similarity,[0],[0]
We observe that our models surpass the comparative baselines on five datasets.,5.1 The Results on Word Similarity,[0],[0]
"Compared with the base model CBOW, it is remarkable that our models approximately achieve improvements of more than 5% and 7%, respectively, in the performance on the golden standard Wordsim-353 and RG-65.",5.1 The Results on Word Similarity,[0],[0]
"On WS-353-REL, the difference between CBOW and LMM-S even reaches 8%.",5.1 The Results on Word Similarity,[0],[0]
The advantage demonstrates the effectiveness of our methods.,5.1 The Results on Word Similarity,[0],[0]
"Based on our strategy, more semantic information will be captured in corpus when adding more latent meanings in the context window.",5.1 The Results on Word Similarity,[0],[0]
"By incorporating mophemes, EMM also performs better than other baselines but fails to get the performance as well as ours.",5.1 The Results on Word Similarity,[0],[0]
"Actually, EMM mainly tunes the distributions of words in vector space to let the morpheme-similar words gather closer, which means it just encodes more morphological properties into word embeddings but lacks the ability to capture more semantic information.",5.1 The Results on Word Similarity,[0],[0]
"Specially, because of the medium-
6http://qwone.com/˜jason/20Newsgroups
size corpus and the experimental settings, GloVe doesn’t perform as well as that described in (Pennington et al., 2014).",5.1 The Results on Word Similarity,[0],[0]
"In (Mikolov et al., 2013c), the dataset is divided into adjectives, nouns and verbs.",5.2 The Results on Syntactic Analogy,[0],[0]
"For brevity, we only report performance on the whole dataset.",5.2 The Results on Syntactic Analogy,[0],[0]
"As the middle row of Table 2 shows, all of our models outperform the comparative baselines to a great extent.",5.2 The Results on Syntactic Analogy,[0],[0]
"Compared with CBOW, the advantage of LMM-A even reaches to 7%.",5.2 The Results on Syntactic Analogy,[0],[0]
"Besides, we observe that the suffix of “b” usually is the same as the suffix of “d” when answering question “a is to b as c is to d”.",5.2 The Results on Syntactic Analogy,[0],[0]
"Based on our strategy, morphemesimilar words will not only gather closer but have a trend to group near the latent meanings of their morphemes, which makes our embeddings have the advantage to deal with the syntactic analogy problem.",5.2 The Results on Syntactic Analogy,[0],[0]
EMM also performs well on this task but is still weaker than our models.,5.2 The Results on Syntactic Analogy,[0],[0]
"Actually, syntactic analogy is also a semantics-related task because “c” and “d” are with similar meanings.",5.2 The Results on Syntactic Analogy,[0],[0]
"Since our models are better to capture semantic information, they lead to higher performance than the explicitly morphology-based models.",5.2 The Results on Syntactic Analogy,[0],[0]
"For each one of the 4 text classification tasks, we report the classification accuracy over the test set.",5.3 The Results on Text Classification,[0],[0]
The average classification accuracy across the 4 tasks is utilized as the evaluation metric for different models.,5.3 The Results on Text Classification,[0],[0]
The results are displayed in the bottom row of Table 2.,5.3 The Results on Text Classification,[0],[0]
"Since we simply use the average embedding of words as the feature vector for 10-categorization classification, the overall classification accuracies of all models are merely aroud 80%.",5.3 The Results on Text Classification,[0],[0]
"However, the classification accuracies of our LMMs still surpass all the baselines, especailly CBOW and GloVe.
",5.3 The Results on Text Classification,[0],[0]
"Moreover, it can be found that incorporating morphological knowledge (morphemes or latent meanings of morphemes) into word embeddings can contribute to enhancing the performance of word embeddings in the downstream NLP tasks.",5.3 The Results on Text Classification,[0],[0]
Parameter settings can affect the performance of word embeddings.,5.4 The Impacts of Parameter Settings,[0],[0]
"For example, the corpus with larger corpus size (the ratio of tokens used for training) contains more semantic information, which can improve the performance on word similarity.",5.4 The Impacts of Parameter Settings,[0],[0]
We analyze the impacts of corpus size and window size on the performance of word embeddings.,5.4 The Impacts of Parameter Settings,[0],[0]
"In the analysis of corpus size, we hold the same parameter settings as before.",5.4 The Impacts of Parameter Settings,[0],[0]
"The sizes of tokens used for training are separately 1/5, 2/5, 3/5, 4/5 and 5/5 of the entire corpus mentioned above.",5.4 The Impacts of Parameter Settings,[0],[0]
We utilize the result of word similarity on Wordsim-353 as the evaluation criterion.,5.4 The Impacts of Parameter Settings,[0],[0]
"From Fig. 5, we observe several phenomena.",5.4 The Impacts of Parameter Settings,[0],[0]
"Firstly, the performance of our LMMs is better than CBOW at each corpus size.",5.4 The Impacts of Parameter Settings,[0],[0]
"Secondly, the performance of CBOW is sensitive to the corpus size.",5.4 The Impacts of Parameter Settings,[0],[0]
"In contrast, LMMs’ performance is more stable than CBOW.",5.4 The Impacts of Parameter Settings,[0],[0]
"As we analyzed in word similarity experiment, LMMs can increase the semantic information of word embeddings.",5.4 The Impacts of Parameter Settings,[0],[0]
It is worth noting that the performance of LMMs on the smallest corpus is even better than CBOW’s performance on the largest corpus.,5.4 The Impacts of Parameter Settings,[0],[0]
"In the analysis of window size, we observe that the performance of all word embeddings trained by different models has a trend to ascend with the increasing of window size as illustrated in Fig. 6.",5.4 The Impacts of Parameter Settings,[0],[0]
Our LMMs outperform CBOW under all the pre-set conditions.,5.4 The Impacts of Parameter Settings,[0],[0]
"Besides, the worst performance of LMMs is nearly equal to the best performance of CBOW.",5.4 The Impacts of Parameter Settings,[0],[0]
"To visualize the embeddings of our models, we randomly select several words from the results of LMM-A. The dimensions of the selected word embeddings are reduced from 200 to 2 using Principal Component Analysis (PCA), and the 2-D word embeddings are illustrated in Fig. 7.",5.5 Word Embedding Visualization,[0],[0]
The words with different colors reflect that they have different morphemes.,5.5 Word Embedding Visualization,[0],[0]
It is apparent that words with similar morphemes have a trend to group together and stay near the latent meanings of their morphemes.,5.5 Word Embedding Visualization,[0],[0]
"In addition, we can also find some syntactic regularities in Fig. 7, for example, “physics” is to “physicist” as “science” is to “scientist”, and “physicist” and “scientist” stay near the latent meaning, i.e., “human”, of the suffix -ist.",5.5 Word Embedding Visualization,[0],[0]
"In this paper, we explored a new direction to employ the latent meanings of morphological compositions rather than the internal compositions themselves to train word embeddings.",6 Conclusion,[0],[0]
"Three specific models named LMM-A, LMM-S and LMM-M were proposed by modifying the input layer and update rules of CBOW.",6 Conclusion,[0],[0]
"The source code of LMMs is avaliable at https: //github.com/Y-Xu/lmm.
",6 Conclusion,[0],[0]
"To test the performance of our models, we chose three word-level word embedding models and implemented an Explicitly Morpheme-related Model (EMM) as comparative baselines, and tested them on two basic NLP tasks of word similarity and syntactic analogy, and one downstream text classification task.",6 Conclusion,[0],[0]
The experimental results demonstrate that our models outperform the baselines on five word similarity datasets.,6 Conclusion,[0],[0]
"On the syntactic analogy as well as the text classification tasks, our models also surpass all the baselines including the EMM.",6 Conclusion,[0],[0]
"In the future, we intend to evaluate our models for some morpheme-rich languages like Russian, German and so on.",6 Conclusion,[0],[0]
The authors are grateful to the reviewers for constructive feedback.,Acknowledgments,[0],[0]
"This work was supported by the National Natural Science Foundation of China (No.61572456), the Anhui Province Guidance Funds for Quantum Communication and Quantum Computers and the Natural Science Foundation of Jiangsu Province of China (No.BK20151241).",Acknowledgments,[0],[0]
Traditional word embedding approaches learn semantic information at word level while ignoring the meaningful internal structures of words like morphemes.,abstractText,[0],[0]
"Furthermore, existing morphology-based models directly incorporate morphemes to train word embeddings, but still neglect the latent meanings of morphemes.",abstractText,[0],[0]
"In this paper, we explore to employ the latent meanings of morphological compositions of words to train and enhance word embeddings.",abstractText,[0],[0]
"Based on this purpose, we propose three Latent Meaning Models (LMMs), named LMM-A, LMM-S and LMM-M respectively, which adopt different strategies to incorporate the latent meanings of morphemes during the training process.",abstractText,[0],[0]
"Experiments on word similarity, syntactic analogy and text classification are conducted to validate the feasibility of our models.",abstractText,[0],[0]
The results demonstrate that our models outperform the baselines on five word similarity datasets.,abstractText,[0],[0]
"On Wordsim-353 and RG-65 datasets, our models nearly achieve 5% and 7% gains over the classic CBOW model, respectively.",abstractText,[0],[0]
"For the syntactic analogy and text classification tasks, our models also surpass all the baselines including a morphology-based model.",abstractText,[0],[0]
Incorporating Latent Meanings of Morphological Compositions to Enhance Word Embeddings,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 45–50 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2008",text,[0],[0]
Systems for automatic assessment of spontaneous spoken language proficiency (Fig. 1) are becoming increasingly important to meet the demand for English second language learning.,1 Introduction,[0],[0]
"Such systems are able to provide throughput and consistency
which are unachievable with human examiners.",1 Introduction,[0],[0]
This is a challenging task.,1 Introduction,[0],[0]
"There is a large vari-
ation in the quality of spoken English across all proficiency levels.",1 Introduction,[0],[0]
"In addition, candidates of the same skill level will have different accents, voices, mispronunciations, and sentence construction errors.",1 Introduction,[0],[0]
All of which are heavily influenced by the candidate’s L1 language and compounded by ASR errors.,1 Introduction,[0],[0]
It is therefore impossible in practice to observe all these variants in training.,1 Introduction,[0],[0]
"At test time, the predicted grade’s validity will decrease the more the candidate is mismatched to the data used to train the system.",1 Introduction,[0],[0]
For deployment of these systems to high-stakes tests the performance on all candidates needs to be consistent and highly correlated with human graders.,1 Introduction,[0],[0]
"To achieve this it is important that these systems can detect outlier speakers who need to be examined by, for example, human graders.
",1 Introduction,[0],[0]
"Previously, separate models were used to filter out ”non-scorable” candidates (Yoon and Xie, 2014; Zechner et al., 2009; Higgins et al., 2011; Xie et al., 2012).",1 Introduction,[0],[0]
"However, such models reject candidates based on whether they can be scored at all, rather than an automatic grader’s uncertainty 1 in its predictions.",1 Introduction,[0],[0]
"It was shown by van Dalen et al. (2015) that Gaussian Process (GP) graders give
1Uncertainty is used in the sense of the inverse of confidence to be consistent with Gal and Ghahramani (2016) and van Dalen et al. (2015).
45
state-of-the-art performance for automatic assessment and yield meaningful uncertainty estimates for rejection of candidates.",1 Introduction,[0],[0]
"There are, however, computational constraints on training set sizes for GPs.",1 Introduction,[0],[0]
"In contrast, Deep Neural Networks (DNNs) are able to scale to large data sets, but lack a native measure of uncertainty.",1 Introduction,[0],[0]
"However, Gal and Ghahramani (2016) have shown that Monte-Carlo Dropout (MCD) can be used to derive an uncertainty estimate for a DNN.
",1 Introduction,[0],[0]
"Alternatively, a Deep Density Network (DDN), which is a Mixture Density Network (Bishop, 1994) with only one mixture component, may be used to yield a mean and variance corresponding to the predicted grade and the uncertainty in the prediction.",1 Introduction,[0],[0]
"Similar to GP and DNNs with MCD, a standard DDN provides an implicit modelling of uncertainty in its prediction.",1 Introduction,[0],[0]
This implicit model may not be optimal for the task at hand.,1 Introduction,[0],[0]
"Hence, a novel approach to explicitly model uncertainty is proposed in which the DDN is trained in a multitask fashion to model a low variance real data distribution and a high variance artificial data distribution which represents candidates with unseen characteristics.",1 Introduction,[0],[0]
"The principled method for dealing with uncertainty in statistical modelling is the Bayesian approach, where a conditional posterior distribution over grades, g, given inputs, x, and training data D = {ĝ, x̂} is computed by marginalizing over all models:
p(g|x, D) = ∫ p(g|x,M)p(M|D)dM (1)
where p(M|D) is a prior over a model given the data.",2 Prediction Uncertainty,[0],[0]
"Given the posterior, the predictive mean and the variance (uncertainty) can be computed using:
µg(x) =
∫ p(g|x, D)gdg
σ2g(x) = ∫ p(g|x, D)g2dg − µ2g(x)
(2)
(3)",2 Prediction Uncertainty,[0],[0]
"Eq. 2, 3 can be analytically solved for a class of models called Gaussian Processes (GP) (Rasmussen and Williams, 2006), a powerful nonparametric model for regression.",2.1 Gaussian Processes,[0],[0]
"The GP induces
a conditional posterior in the form of a normal distribution over grades g given an input x and training data D:
p(g|x; D) = N",2.1 Gaussian Processes,[0],[0]
"(g; µg(x|D), σ2g(x|D))",2.1 Gaussian Processes,[0],[0]
"(4)
With mean function µg(x|D) and variance function σ2g(x|D), which is a function of the similarity of an input x to the training data inputs x̂, where the similarity metric is defined by a covariance function k(., .).",2.1 Gaussian Processes,[0],[0]
"The nature of GP variance means that the model is uncertain in predictions for inputs far away from the training data, given appropriate choice of k(., .).",2.1 Gaussian Processes,[0],[0]
"Unfortunately, without sparsification approaches, the computational and memory requirements of GPs become prohibitively expensive for large data sets.",2.1 Gaussian Processes,[0],[0]
"Furthermore, GPs are known to scale poorly to higher dimensional features (Rasmussen and Williams, 2006).",2.1 Gaussian Processes,[0],[0]
"Alternatively, a grader can be constructed using Deep Neural Networks (DNNs) which have a very flexible architecture and scale well to large data sets.",2.2 Monte-Carlo Dropout,[0],[0]
"DNNs, however, lack a native measure of uncertainty.",2.2 Monte-Carlo Dropout,[0],[0]
"Uncertainty estimates for DNNs can be computed using a Monte-Carlo ensemble approximation to Eq. 2, 3:
µ̂g(x) = 1
N
N∑
i=1
f(x;M(i))
σ̂2g(x) = 1
N
N∑
i=1
( f(x; M(i)) )",2.2 Monte-Carlo Dropout,[0],[0]
"2 − µ̂2g(x)
(5)
(6)
where there are N DNN models in the ensemble, M(i) is a DNN with a particular architecture and parameters sampled from p(M|D) using Monte Carlo Dropout (MCD) (Srivastava et al., 2014), and f(x; M(i)) are the DNN predictions.",2.2 Monte-Carlo Dropout,[0],[0]
"Recent work by Gal and Ghahramani (2016) showed that MCD is equivalent to approximate variational inference in GPs, and can be used to yield meaningful uncertainty estimates for DNNs.",2.2 Monte-Carlo Dropout,[0],[0]
"Furthermore, Gal and Ghahramani (2016) show that different choices of DNN activation functions correspond to different GP covariance functions.",2.2 Monte-Carlo Dropout,[0],[0]
"MCD uncertainty assumes that for inputs further from the training data, different subnets will produce increasingly differing outputs, leading to larger variances.",2.2 Monte-Carlo Dropout,[0],[0]
"Unfortunately, it is difficult to know beforehand which activation functions accomplish this in practice.",2.2 Monte-Carlo Dropout,[0],[0]
"Instead of relying on a Monte Carlo approximation to Eq. 1, a DNN can be modified to produce a prediction of both a mean and a variance:
µg(x) = fµ(x; M) σ2g(x) = fσ2(x; M)
(7)
(8)
parametrising a normal distribution over grades conditioned on the input, similar to a GP.",3 Deep Density Networks,[0],[0]
"This architecture is a Deep Density Network (DDN), which is a Mixture Density Network (MDN) (Bishop, 1994) with only one mixture component.",3 Deep Density Networks,[0],[0]
DDNs are trained by maximizing the likelihood of the training data.,3 Deep Density Networks,[0],[0]
The variance of the DDN represents the natural spread of grades at a given input.,3 Deep Density Networks,[0],[0]
"This is an implicit measure of uncertainty, like GP and MCD variance, because it is learned automatically as part of the model.",3 Deep Density Networks,[0],[0]
"However, this doesn’t enforce higher variance further away from training points in DDNs.",3 Deep Density Networks,[0],[0]
"It is possible to explic-
itly teach a DDN to predict a high or low variance for inputs which are unlike or similar to the training data, respectively (Fig. 2).",3 Deep Density Networks,[0],[0]
This requires a novel training procedure.,3 Deep Density Networks,[0],[0]
"Two normal distributions are constructed: a low-variance real (training) data distribution pD and a high-variance artificial data distribution pN, which models data outside the real training data region.",3 Deep Density Networks,[0],[0]
The DDN needs to model both distributions in a multi-task (MT) fashion.,3 Deep Density Networks,[0],[0]
"The loss function for training the DDN with explicitly specified uncertainty is the expectation over the training data of the KL divergence between the distribution it parametrizes and both the real and artificial data distributions:
L = Ex̂[KL(pD||p(g|x̂; M)]",3 Deep Density Networks,[0],[0]
"+ α · Ex̃[KL(pN||p(g|x̃; M)]
(9)
where α is the multi-task weight.",3 Deep Density Networks,[0],[0]
The DDN with explicit uncertainty is trained in a two stage fashion.,3 Deep Density Networks,[0],[0]
"First, a standard DDN M0
is trained, then a DDN M is instantiated using the parameters of M0 and trained in a multi-task fashion.",3 Deep Density Networks,[0],[0]
"The real data distribution pD is defined by M0 (Eq. 7, 8).",3 Deep Density Networks,[0],[0]
"The artificial data distribution pN is constructed by generating artificial inputs x̃ and the associated mean and variance targets µ(x̃), σ2(x̃):
pN = N (g; fµ(x̃; M0), σ2(x̃)) (10)
",3 Deep Density Networks,[0],[0]
The predictions of M0 are used as the targets for µ(x̃).,3 Deep Density Networks,[0],[0]
The target variance σ2(x̃) should depend on the similarity of x̃ to the training data.,3 Deep Density Networks,[0],[0]
"Here, this variance is modelled by the squared normalized Euclidean distance from the mean of x̂, with a diagonal covariance matrix, scaled by a hyperparameter λ.",3 Deep Density Networks,[0],[0]
"The artificial inputs x̃ need to be different to, but related to the real data x̂. Ideally, they should represent candidates with unseen characteristics, such as L1, accent and proficiency.",3 Deep Density Networks,[0],[0]
"A simple approach to generating x̃ is to use a Factor Analysis (FA) (Murphy, 2012) model trained on x̂.",3 Deep Density Networks,[0],[0]
"The generative model of FA is:
x̃ ∼ N",3 Deep Density Networks,[0],[0]
"(Wz + µ, γΨ), z ∼ N (0, γI) (11)
where W is the loading matrix, Ψ the diagonal residual noise variance, µ the mean, all derived from x̂, and γ is used to control the distance of the generated data from the real training data region.",3 Deep Density Networks,[0],[0]
During training the artificial inputs are sampled from the FA model.,3 Deep Density Networks,[0],[0]
"AUCRR = AUCvar
AUCmax (12)
As previously stated, the operating scenario is to use a model’s estimate of the uncertainty in
its prediction to reject candidates to be assessed by human graders for high-stakes tests, maximizing the increase in performance while rejecting the least number of candidates.",4 Experimental Results,[0],[0]
The rejection process is illustrated using a rejection plot (Fig. 3).,4 Experimental Results,[0],[0]
"As the rejection fraction is increased, model predictions are replaced with human scores in some particular order, increasing overall correlation with human graders.",4 Experimental Results,[0],[0]
"Fig. 3 has 3 curves representing different orderings: expected random rejection, optimal rejection and model rejection.",4 Experimental Results,[0],[0]
"The expected random performance curve is a straight line from the base predictive performance to 1.0, representing rejection in a random order.",4 Experimental Results,[0],[0]
The optimal rejection curve is constructed by rejecting predictions in order of decreasing mean square error relative to human graders.,4 Experimental Results,[0],[0]
A rejection curve derived from a model should sit between the random and optimal curves.,4 Experimental Results,[0],[0]
"In this work, model rejection is in order of decreasing predicted variance.
",4 Experimental Results,[0],[0]
"The following metrics are used to assess and compare models: Pearson Correlation Coefficient (PCC) with human graders, the standard performance metric in assessment (Zechner et al., 2009; Higgins et al., 2011); 10% rejection PCC, which illustrates the predictive performance at a partic-
ular operating point, i.e. rejecting 10% of candidates; and Area under a model’s rejection curve (AUC) (Fig 3).",4 Experimental Results,[0],[0]
"However, AUC is influenced by the base PCC of a model, making it difficult to compare the rejection performance.",4 Experimental Results,[0],[0]
"Thus, a metric independent of predictive performance is needed.",4 Experimental Results,[0],[0]
"The proposed metric, AUCRR (Eq. 12), is the ratio of the areas under the actual (AUCvar) and optimal (AUCmax) rejection curves relative to the random rejection curve.",4 Experimental Results,[0],[0]
"Ratios of 1.0 and 0.0 correspond to perfect and random rejection, respectively.
",4 Experimental Results,[0],[0]
"All experiments were done using 33- dimensional pronunciation, fluency and acoustic features derived from audio and ASR transcriptions of responses to questions from the BULATS exam (Chambers and Ingham, 2011).",4 Experimental Results,[0],[0]
The ASR system has a WER of 32% on a development set.,4 Experimental Results,[0],[0]
"The training and test sets have 4300 and 224 candidates, respectively.",4 Experimental Results,[0],[0]
"Each candidate provided a response to 21 questions, and the features used are aggregated over all 21 questions into a single feature vector.",4 Experimental Results,[0],[0]
The test data was graded by expert graders at Cambridge English.,4 Experimental Results,[0],[0]
These experts have inter-grader PCCs in the range 0.95-0.97.,4 Experimental Results,[0],[0]
"Candidates are equally distributed across CEFR grade levels (Europe, 2001).
",4 Experimental Results,[0],[0]
The input features where whitened by subtracting the mean and dividing by the standard deviation for each dimension computed on all training speakers.,4 Experimental Results,[0],[0]
"The Adam optimizer (Kingma and Ba, 2015), dropout (Srivastava et al., 2014) regularization with a dropout keep probability of 0.6 and an exponentially decaying learning rate are used with decay factor of 0.86 per epoch, batch size 50.",4 Experimental Results,[0],[0]
All networks have 2 hidden layers with 180 rectified linear units (ReLU) in each layer.,4 Experimental Results,[0],[0]
"DNN and DDN models were implemented in Tensorflow (Abadi et al., 2015).",4 Experimental Results,[0],[0]
"Models were initialized using the Xavier Initializer (Glorot and Bengio, 2010).",4 Experimental Results,[0],[0]
A validation set of 100 candidates was selected from the training data to tune the model and hyperparameters.,4 Experimental Results,[0],[0]
"GPs were run using Scikit-Learn (Pedregosa et al., 2011) using a squared exponential covariance function.
",4 Experimental Results,[0],[0]
"The Gaussian Process grader, GP, is a competitive baseline (Tab. 1).",4 Experimental Results,[0],[0]
GP variance clearly yields uncertainty which is useful for rejection.,4 Experimental Results,[0],[0]
"A DNN with ReLU activation, MCD, achieves grading performance similar to the GP.",4 Experimental Results,[0],[0]
"However, MCD fails to yield an informative uncertainty for rejection, with performance barely above random.",4 Experimental Results,[0],[0]
"If the tanh activation function, MCDtanh, is used instead, then a DNN is able to provide a meaningful measure of uncertainty using MCD, at the cost of grading performance.",4 Experimental Results,[0],[0]
"It is likely that ReLU activations correspond to a GP covariance function which is not suited for rejection on this data.
",4 Experimental Results,[0],[0]
The standard DDN has comparable grading performance to the GP and DNNs.,4 Experimental Results,[0],[0]
"AUCRR of the DDN is on par with the GP, but the 10% rejection PCC is lower, indicating that the DDN is not as effective at rejecting the worst outlier candidates.",4 Experimental Results,[0],[0]
"The approach proposed in this work, a DDN trained in a multi-task fashion (DDN+MT), achieves significantly higher rejection performance, resulting in the best AUCRR and 10% rejection PCC, showing its better capability to detect outlier candidates.",4 Experimental Results,[0],[0]
"Note, AUC reflects similar trends to AUCRR, but not
as clearly, which is demonstrated by Fig. 4.",4 Experimental Results,[0],[0]
"The model was found to be insensitive to the choice of hyper-parameters α and γ, but λ needed to be set to produce target noise variances σ2(x̃) larger than data variances σ2(x̂).",4 Experimental Results,[0],[0]
A novel method for explicitly training DDNs to yield uncertainty estimates is proposed.,5 Conclusions and Future Work,[0],[0]
A DDN is a density estimator which is trained to model two distributions in a multi-task fashion (1) the low variance (uncertainty) true data distribution and (2) a generated high variance artificial data distribution.,5 Conclusions and Future Work,[0],[0]
The model is trained by minimizing the KL divergence between the DDN and the true data distribution (1) and between the DDN and the artificial data distribution (2).,5 Conclusions and Future Work,[0],[0]
The DDN should assign its prediction of low or high variance (uncertainty) if the input is similar or dissimilar to the true data respectively.,5 Conclusions and Future Work,[0],[0]
The artificial data distribution is given by a factor analysis model trained on the real data.,5 Conclusions and Future Work,[0],[0]
"During training the artificial data is sampled from this distribution.
",5 Conclusions and Future Work,[0],[0]
This method outperforms GPs and Monte-Carlo Dropout in uncertainty based rejection for automatic assessment.,5 Conclusions and Future Work,[0],[0]
"However, the effect of the nature of artificial data on rejection performance should be further investigated and other data generation methods, such as Variational AutoEncoders (Kingma and Welling, 2014), and metrics to assess similarity between artificial and real training data should be examined.",5 Conclusions and Future Work,[0],[0]
The proposed approach must also be assessed on other tasks and datasets.,5 Conclusions and Future Work,[0],[0]
"This research was funded under the ALTA Institute, University of Cambridge as well as the Engineering and Physical Sciences Research Council.",Acknowledgments,[0],[0]
"Thanks to Cambridge English, University of Cambridge, for support and access to the BULATS data.",Acknowledgments,[0],[0]
There is a growing demand for automatic assessment of spoken English proficiency.,abstractText,[0],[0]
"These systems need to handle large variations in input data owing to the wide range of candidate skill levels and L1s, and errors from ASR.",abstractText,[0],[0]
"Some candidates will be a poor match to the training data set, undermining the validity of the predicted grade.",abstractText,[0],[0]
"For high stakes tests it is essential for such systems not only to grade well, but also to provide a measure of their uncertainty in their predictions, enabling rejection to human graders.",abstractText,[0],[0]
"Previous work examined Gaussian Process (GP) graders which, though successful, do not scale well with large data sets.",abstractText,[0],[0]
Deep Neural Networks (DNN) may also be used to provide uncertainty using Monte-Carlo Dropout (MCD).,abstractText,[0],[0]
This paper proposes a novel method to yield uncertainty and compares it to GPs and DNNs with MCD.,abstractText,[0],[0]
The proposed approach explicitly teaches a DNN to have low uncertainty on training data and high uncertainty on generated artificial data.,abstractText,[0],[0]
"On experiments conducted on data from the Business Language Testing Service (BULATS), the proposed approach is found to outperform GPs and DNNs with MCD in uncertainty-based rejection whilst achieving comparable grading performance.",abstractText,[0],[0]
Incorporating Uncertainty into Deep Learning for Spoken Language Assessment,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1833–1843 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Temporal information extraction is becoming an active research field in natural language processing (NLP) due to the rapidly growing need for NLP applications such as timeline generation and question answering (Llorens et al., 2015; Meng et al., 2017).",1 Introduction,[0],[0]
It has great potential to create many practical applications.,1 Introduction,[0],[0]
"For example, SemEval2015 Task 4 (Minard et al., 2015) collects news articles about a target entity and the task required participants automatically ordering the events in-
volving that entity in a timeline.",1 Introduction,[0],[0]
The timeline representation of news can help people more easily comprehend a mass of information.,1 Introduction,[0],[0]
"This work aims to contribute to such timeline applications by extracting temporal information in specific domains like news articles.
",1 Introduction,[0],[0]
"TimeBank1 (Pustejovsky et al., 2003) is the first widely used corpus with temporal information annotated in the NLP community.",1 Introduction,[0],[0]
"It contains 183 news articles that have been annotated with events, time expressions and temporal relations between events and time expressions.",1 Introduction,[0],[0]
"The annotation follows the TimeML2 specification (Saurı et al., 2006).",1 Introduction,[0],[0]
"Along with the TimeBank and other temporal information corpora, a series of competitions on temporal information extraction (TempEval-1,2,3) (Verhagen et al., 2009, 2010; UzZaman et al., 2012) are attracting growing research efforts.
",1 Introduction,[0],[0]
A majority of temporal information corpora adopt temporal links (TLINKs) to encode temporal information in documents.,1 Introduction,[0],[0]
"A TLINK denotes a temporal relation between mentions, i.e., events, time expressions and document creation time (DCT) (Setzer, 2002).",1 Introduction,[0],[0]
"However, annotating TLINKs is a painful work, because annotation candidates are quadratic to the number of mentions in a document.",1 Introduction,[0],[0]
"The original TimeBank only annotated those “salient” mention pairs judged by annotators, while the definition of “salient” is not necessarily clear.",1 Introduction,[0],[0]
"Annotators had to face a complicated task; identify “salient” mention pairs, and label temporal relations.",1 Introduction,[0],[0]
"For solving this, many dense annotation schemata are proposed to force annotators to annotate more or even complete graph pairs.",1 Introduction,[0],[0]
"However, dense annotation is time-consuming and unstable human judgments
1https://catalog.ldc.upenn.edu/LDC2006T08 2http://www.timeml.org/
1833
on “salient” pairs are not improved at all.",1 Introduction,[0],[0]
"As a consequence, a high proportion of “vague” or “nolink” pairs appears in these dense corpora such as TimeBank-Dense (Cassidy et al., 2014).
",1 Introduction,[0],[0]
"In this work, we propose a new approach to obtain temporal relations from time anchors, i.e. absolute time value, of all mentions.",1 Introduction,[0],[0]
We assume that a temporal relation can be induced by comparing the relative temporal order of two time anchors (e.g. YYYY-MM-DD) in a time axis.,1 Introduction,[0],[0]
"We use pre-defined rules (Section 3) to generate temporal order (TORDER) relations (e.g. BEFORE, AFTER, SAME DAY, etc.) by taking two annotated time anchors as input.",1 Introduction,[0],[0]
"This proposal requires the annotation of time anchors, of which the annotation effort is linear with the number of mentions.",1 Introduction,[0],[0]
"This is the first work to obtain temporal relations shifted from the annotation of individual mentions, which is distinguished from most annotation work of manually annotating mention pairs.
",1 Introduction,[0],[0]
This approach brings several advantages over the current temporal relation annotation.,1 Introduction,[0],[0]
"First, as long as time anchors of all mentions in a document are given, our pre-defined rules can induce the temporal relations for all the quadratic pairs.",1 Introduction,[0],[0]
This skips the step of identifying “salient” pairs.,1 Introduction,[0],[0]
"Second, annotating the time anchors is relatively easy, as the annotation work is linear to the number of mentions.",1 Introduction,[0],[0]
"Third, the automatic generation rules can provide flexible relation types based on our definition and this increased informativeness might contribute positively to downstream tasks.
",1 Introduction,[0],[0]
"In our first evaluation (Section 4), we compare the correspondence and difference between the new TORDERs and conventional TLINKs.",1 Introduction,[0],[0]
"The comparison of empirical statistics shows the new data is label balanced, contains informative relations and reduces “vague” relations.",1 Introduction,[0],[0]
"Besides, the classification performance suggests the new data achieve reasonable accuracy, although accuracy numbers are not directly comparable.
",1 Introduction,[0],[0]
Many text processing tasks are often requiring to know time anchors when events occurred in a timeline.,1 Introduction,[0],[0]
"In Section 5, we evaluate the data in a downstream time anchor prediction task (Reimers et al., 2016) by using the temporal relation recognizers separately trained with TORDERs or TLINKs.",1 Introduction,[0],[0]
The main results show that the recognizer trained with our TORDERs significantly outperforms the recognizer trained with the TLINKs by 14.1 point exact match accuracy.,1 Introduction,[0],[0]
TimeBank started a wave of data-driven temporal information extraction research in the NLP community.,2.1 Temporal Relation Annotation,[0],[0]
The original TimeBank only annotated relations judged to be salient by annotators and resulted in sparse annotations.,2.1 Temporal Relation Annotation,[0],[0]
"Subsequent TempEval-1,2,3 competitions (Verhagen et al., 2009, 2010; UzZaman et al., 2012) mostly relied on TimeBank, but also aimed to improve coverage by annotating relations between all events and time expressions in the same sentence.",2.1 Temporal Relation Annotation,[0],[0]
"However, most missing relations between mentions in different sentences are not considered.
",2.1 Temporal Relation Annotation,[0],[0]
"In order to solve the sparsity issue, researchers started the work towards denser annotation schema.",2.1 Temporal Relation Annotation,[0],[0]
Bramsen et al. (2006) annotated multi-sentence segments of text to build directed acyclic graphs.,2.1 Temporal Relation Annotation,[0],[0]
"Kolomiyets et al. (2012) annotated temporal dependency structures, though they only focused on relations between pairs of events.",2.1 Temporal Relation Annotation,[0],[0]
Do et al. (2012) produced the densest annotation and the annotator was required to annotate pairs “as many as possible”.,2.1 Temporal Relation Annotation,[0],[0]
Cassidy et al. (2014) proposed a compulsory mechanism to force annotators to label every pair in a given sentence window.,2.1 Temporal Relation Annotation,[0],[0]
"They performed the annotation (TimeBankDense) on a subset (36 documents) of TimeBank, which achieved a denser corpus with 6.3 TLINKs per event and time expression, comparing to 0.7 in the original TimeBank corpus.",2.1 Temporal Relation Annotation,[0],[0]
"However, it raises the issue that hand-labeling all dense TLINKs is extremely time-consuming and the unclear definition of “salient” is not improved at all.",2.1 Temporal Relation Annotation,[0],[0]
The majority of the temporal relation classifiers focus on exploiting a variety of features to improve the performance in TimeBank.,2.2 Temporal Relation Classification,[0],[0]
Laokulrat et al. (2013) extracted lexical and morphological features derived from WordNet synsets.,2.2 Temporal Relation Classification,[0],[0]
"Mani et al. (2006); D’Souza and Ng (2013) incorporated semantic relations between verbs from VerbOcean.
",2.2 Temporal Relation Classification,[0],[0]
"Recently, more researchers move on to diverse approaches on the TimeBank-Dense corpus.",2.2 Temporal Relation Classification,[0],[0]
Chambers et al. (2014) proposed a multi-sieve classifier composed of several rule-based and machine learning based sieves ranked by their precision.,2.2 Temporal Relation Classification,[0],[0]
"Mirza and Tonelli (2016) started to mine the value of low-dimensional word embeddings by concatenating them with traditional sparse feature
vectors to improve their classifier.",2.2 Temporal Relation Classification,[0],[0]
"Inspired by the success of the deep learning work in the similar task: relation extraction, Cheng and Miyao (2017) proposed the shortest dependency path based Bi-directional Long short-term memory (Hochreiter and Schmidhuber, 1997)",2.2 Temporal Relation Classification,[0],[0]
"(Bi-LSTM) to achieve state-of-the-art performance in the TimeBank-Dense corpus, which is adopted for the experiments in this paper.",2.2 Temporal Relation Classification,[0],[0]
There are two reasons to use this classifier: 1) intersentence temporal relations are well treated.,2.2 Temporal Relation Classification,[0],[0]
"2) only word, part-of-speech and dependency relation embeddings are required as input.",2.2 Temporal Relation Classification,[0],[0]
"A related task: Cross-Document Event Ordering (Minard et al., 2015) aims to order the events involving a target entity in a timeline given written news in English.",2.3 Time Anchor Annotation,[0],[0]
"Compared to traditional TLINKs, annotating time anchors of events is intuitively more straightforward in such tasks.
",2.3 Time Anchor Annotation,[0],[0]
"Reimers et al. (2016) proposed an annotation scheme, which requires annotators to infer the exact time of each individual event.",2.3 Time Anchor Annotation,[0],[0]
They distinguished events that occur at a Single-Day from that span over Multi-Day by setting the granularity as one day.,2.3 Time Anchor Annotation,[0],[0]
"For Single-Day events, the event time is written in the format ‘YYYY-MM-DD’ when the precise event time can be determined.",2.3 Time Anchor Annotation,[0],[0]
"Otherwise, they required annotators to narrow down the possible time as precisely as possible.",2.3 Time Anchor Annotation,[0],[0]
"An imprecise Single-Day event can be annotated as a tuple (after, before), e.g. ‘(after 1998-10-02, )’, ‘(, before 2000-01-31)’ or ‘(after 1998-10-02, before 2000- 01-31)’.",2.3 Time Anchor Annotation,[0],[0]
"In the case of Multi-Day, an event is annotated as a tuple (begin, end), where begin and end are represented with Single-Day.",2.3 Time Anchor Annotation,[0],[0]
"For instance of a sentence:
The economy created jobs at a surprisingly robust pace in January, the government reported on Friday, evidence that America’s economic stamina has withstood any disruption caused so far by the financial tumult in Asia.
",2.3 Time Anchor Annotation,[0],[0]
"The Multi-Day event created is annotated as (begin=1998-01-01, end=1998-01-31).",2.3 Time Anchor Annotation,[0],[0]
The Single-Day event reported is annotated as the same day as DCT (1998-02-06).,2.3 Time Anchor Annotation,[0],[0]
"The imprecise Multi-Day event disruption is annotated as (begin=(, before1998-02-06), end=(, before1998-0206))",2.3 Time Anchor Annotation,[0],[0]
"as the event must have occurred before the
time of this news, but the precise begin and end dates cannot be inferred from the text.",2.3 Time Anchor Annotation,[0],[0]
Time anchors have the capability of anchoring all the events from a document into the same timeline as shown in Figure 1.,2.3 Time Anchor Annotation,[0],[0]
"They annotated the time anchors of total 1,498 events from 36 documents of TimeBank-Dense.
",2.3 Time Anchor Annotation,[0],[0]
"In temporal information retrieval, Berberich et al. (2010) proposed a four-tuple representation (‘earliest begin’, ‘latest begin’, ‘earliest end’, ‘latest end’) for uncertain time expression (e.g. ‘1990s’) in order to integrate such temporal information into language model.",2.3 Time Anchor Annotation,[0],[0]
"In the time anchor annotation, an event ‘in 1990s’ will be annotated as a Multi-Day event with imprecise begin and end points, i.e. (begin=(after 1990-01-01, before199912-31), end=(after 1990-01-01, before1999-1231)), which is quite similar to their four-tuple representation.",2.3 Time Anchor Annotation,[0],[0]
"TimeML states that TLINKs present a temporal relation between event to event, event to time expression, and event to DCT.",3 Automatic generation of TORDERs,[0],[0]
The sparse TLINK coverage in the majority of temporal information corpora is attributed to the unstable identification of “salient” pairs by human annotators.,3 Automatic generation of TORDERs,[0],[0]
"Denser annotation schemata somehow improved sparseness, but the annotation work became very timeconsuming.",3 Automatic generation of TORDERs,[0],[0]
"These issues plague the development of temporal information extraction work.
",3 Automatic generation of TORDERs,[0],[0]
Our temporal order (TORDER) proposal is designed with the goal of solving unstable recognition of “salient” pairs and reducing annotation effort.,3 Automatic generation of TORDERs,[0],[0]
We hypothesize that a temporal relation can be automatically computed by comparing the relative temporal order between two time anchors (e.g. YYYY-MM-DD) in a time axis.,3 Automatic generation of TORDERs,[0],[0]
"We propose a set of pre-defined generation rules, which have the capability to rigorously induce a TORDER by taking the two annotated time anchors as input.",3 Automatic generation of TORDERs,[0],[0]
"Annotat-
ing time anchors of individual mentions extremely reduces annotation effort, as it is linear with mention numbers.",3 Automatic generation of TORDERs,[0],[0]
"As long as time anchors are given, our pre-defined rules can induce the temporal relations for all the quadratic pairs, which skips the step of identifying “salient” pairs.
",3 Automatic generation of TORDERs,[0],[0]
"TimeBank contains the normalized date ‘YYYYMM-DD’ of time expressions and DCT, but does not include events’ time.",3 Automatic generation of TORDERs,[0],[0]
Our proposal of inducing a TORDER by comparing two time anchors requires the time anchor annotation of events in the same granularity as time expressions and DCT.,3 Automatic generation of TORDERs,[0],[0]
"Therefore, annotating the events with ‘YYYY-MMDD’ is a reasonable setting and one day is used as the minimal granularity of annotation.",3 Automatic generation of TORDERs,[0],[0]
"We choose the annotation (Reimers et al., 2016) of the daylevel time anchors of events as the source of our automatic TORDER generator.",3 Automatic generation of TORDERs,[0],[0]
"In the case that a corpus can provide more specific time information ‘YYYY-MM-DD, hh-mm-ss’ (e.g. this morning, three o’clock in the afternoon), our TORDER generator can be flexible to handle this information as long as the time anchors of all mentions are annotated in the same granularity.
",3 Automatic generation of TORDERs,[0],[0]
"For the clear demonstration of the definition of the auto-generated temporal order, we separately describe the generation of the pairs with two Single-Day mentions, and the pairs involving Multi-Day mentions.",3 Automatic generation of TORDERs,[0],[0]
"In this paper, TORDER labels are written in the upper-case bold font to be distinguished from TLINK labels written in the lower-case italic font.",3 Automatic generation of TORDERs,[0],[0]
Table 1 introduces the definition of temporal orders between two Single-Day pairs S1 and S2.,3 Automatic generation of TORDERs,[0],[0]
PVAGUE (i.e. partially vague) denotes that two imprecise time anchors are equivalent.,3 Automatic generation of TORDERs,[0],[0]
"For instance, we cannot induce a clear temporal relation between two events both occur-
ring on (,before1998-02-06), but nevertheless both events provide partially equivalent date information ‘1998-02-06’.",3 Automatic generation of TORDERs,[0],[0]
It can possibly provide useful information for the future processes of classification or time inference.,3 Automatic generation of TORDERs,[0],[0]
"PVAGUE in the Multi-Day definition takes the same consideration.
",3 Automatic generation of TORDERs,[0],[0]
"In order to introduce the temporal orders involving Multi-Day events, a Multi-Day event M is denoted as a tuple of two Single-Day dates (begin, end).",3 Automatic generation of TORDERs,[0],[0]
"A temporal order between a SingleDay S1 and Multi-Day M2 (begin2, end2) can be derived by computing the temporal order of two Single-Day S1 and begin2, or S1 and end2 first.",3 Automatic generation of TORDERs,[0],[0]
All the types of temporal orders involving MultiDay events are defined in Table 2.,3 Automatic generation of TORDERs,[0],[0]
"One additional INCLUDES relation that Multi-Day event includes a Single-Day event can be obtained by reversing the symmetric IS INCLUDED.
",3 Automatic generation of TORDERs,[0],[0]
The example of automatically computing temporal orders can be demonstrated by using the events in Figure 1.,3 Automatic generation of TORDERs,[0],[0]
"Both Multi-Day created and disruption are clearly BEFORE the Single-Day reported, because reported is AFTER the end dates of created and disruption.",3 Automatic generation of TORDERs,[0],[0]
"The relation between created and disruption is induced as VAGUE, as the imprecise begin, end of disruption cannot be determined with a relation to created.
",3 Automatic generation of TORDERs,[0],[0]
"In this paper, the definition adopts a similar relation set to TLINK for the purpose that we can perform fair comparison and evaluation in the next two sections.",3 Automatic generation of TORDERs,[0],[0]
"However, our inducing proposal can be very scalable to introduce more temporal relations.",3 Automatic generation of TORDERs,[0],[0]
"For instance, Allen’s interval algebra (Allen, 1990) defines ‘starts’, ‘finish’ relations, which are not included in our current defini-
tion.",3 Automatic generation of TORDERs,[0],[0]
"We can easily extend our definition by detecting whether two time anchors have the equivalent begin or end points.
",3 Automatic generation of TORDERs,[0],[0]
Our inducing proposal takes human annotated time expressions and normalized values as inputs to generate TORDER relations as the training data of the next processes (e.g. classification).,3 Automatic generation of TORDERs,[0],[0]
"In the case of processing raw texts, we can perform detection and normalization of time expressions by using existing temporal taggers, e.g. HeidelTime (Strötgen and Gertz, 2015), SUTime (Chang and Manning, 2012), etc.",3 Automatic generation of TORDERs,[0],[0]
Fairly evaluating the TORDER’s capability of encoding temporal order information compared to the existing data is difficult but necessary work.,4 Comparison of TORDERs and TLINKs,[0],[0]
"This section provides empirical statistics of TORDER and TLINK annotations, and compare the performance of automatic recognition.",4 Comparison of TORDERs and TLINKs,[0],[0]
"Additionally, we evaluate these two frameworks in a downstream task performance in Section 5.",4 Comparison of TORDERs and TLINKs,[0],[0]
"Our new TORDERs are formally similar to the conventional TLINKs, as both state a temporal relation between two mentions.",4.1 Correspondences and Differences,[0],[0]
"BEFORE and AFTER represent that one mention occurs before or after in a timeline, which is close to before and after.",4.1 Correspondences and Differences,[0],[0]
"INCLUDES and IS INCLUDED are more clearly conditioned as a Single-Day or MultiDay mention occurs during the other Multi-Day mention, compared to includes and is included.",4.1 Correspondences and Differences,[0],[0]
SAME DAY and SAME SPAN are designed for the one-day minimal granularity.,4.1 Correspondences and Differences,[0],[0]
"Ideally, these two relations will include simultaneous and other TLINKs with two mentions occurring in the same day.",4.1 Correspondences and Differences,[0],[0]
"VAGUE and PVAGUE state that our generation rules cannot induce the relations, similar to vague (i.e. annotators cannot judge the relations).
",4.1 Correspondences and Differences,[0],[0]
The one-day minimal granularity is the main reason causing the difference between TORDER and TLINK types.,4.1 Correspondences and Differences,[0],[0]
"For a sentence:
I went to sleep after taking a bath.
",4.1 Correspondences and Differences,[0],[0]
"According to the TimeML specification, sleep is obviously after bath.",4.1 Correspondences and Differences,[0],[0]
"But in the one-day granularity, the relation is shifted to SAME DAY.",4.1 Correspondences and Differences,[0],[0]
"This brings the obstacle that we cannot measure whether the temporal information encoded in
TORDERs is more informative than TLINKs by directly comparing the classification results.
",4.1 Correspondences and Differences,[0],[0]
Our TORDER definition shows the capability of capturing some relations which cannot be encoded by TLINK.,4.1 Correspondences and Differences,[0],[0]
"For instance:
Stocks rose, pushing the Dow Jones industrial average up 72.24 points, to 8,189.49, leaving the index within 70 points of its record.
",4.1 Correspondences and Differences,[0],[0]
"These TLINKs among the three events are annotated as vague in TimeBank-Dense, as the annotators cannot state their temporal orders.",4.1 Correspondences and Differences,[0],[0]
"However, we can easily obtain SAME DAY relations, since their day-level time anchors are the same.
",4.1 Correspondences and Differences,[0],[0]
Imprecisely represented time anchors (e.g. after YYYY-MM-DD) are the major drawback of losing temporal order information.,4.1 Correspondences and Differences,[0],[0]
"For instance:
America’s economic stamina has withstood any disruption...
The TLINK between withstood and disruption is annotated as after.",4.1 Correspondences and Differences,[0],[0]
"While both of them were annotated as the same time anchor (begin=before 1998- 02-06, end= before 1998-02-06), our TORDER generator induced a PVAGUE relation and temporal order information is lost.
",4.1 Correspondences and Differences,[0],[0]
The hypothesis that our proposal skipping the unstable manual identification of “salient” pairs can reduce the VAGUE relations in the new data.,4.1 Correspondences and Differences,[0],[0]
This can be measured by comparing the numbers of the TORDER and TLINK relations on the same mention pairs.,4.1 Correspondences and Differences,[0],[0]
"If the observation of a part of vague TLINKs induced as non-VAGUE TORDERs in the new data can be found, it will be the evidence.
",4.1 Correspondences and Differences,[0],[0]
"Depending on the text domain, TLINKs or TORDERs can be advantageous in different scenarios.",4.1 Correspondences and Differences,[0],[0]
"TLINKs can capture the temporal ordering information between events, when time expressions are often absent in the documents such as novels and narratives.",4.1 Correspondences and Differences,[0],[0]
But the annotation work is time consuming and a part of relations will be neglected by the unstable human identification of “salient” pairs.,4.1 Correspondences and Differences,[0],[0]
TORDERs have the capability of capturing more informative relations by skipping the “salient” pairs recognition and need less annotation effort.,4.1 Correspondences and Differences,[0],[0]
But they require that the events can be anchored in a timeline from a document (e.g. often the case of news articles) and imprecise time anchors cause some information loss.,4.1 Correspondences and Differences,[0],[0]
Investigating the quality of auto-generated TORDERs is important to demonstrate the value of this research.,4.2 Empirical Comparison,[0],[0]
"In this section, we empirically compare the statistics of the auto-generated TORDERs and human-annotated TLINKs.",4.2 Empirical Comparison,[0],[0]
"Theoretically, a TORDER between two mentions with any distance in a document can be automatically computed.",4.2 Empirical Comparison,[0],[0]
"However, it is important to make the new data in a comparable manner to the existing data.",4.2 Empirical Comparison,[0],[0]
"In this paper, we follow the process of TimeBank-Dense (Cassidy et al., 2014) to generate the complete graph of the 10,007 mention pairs in the same and adjacent sentences.",4.2 Empirical Comparison,[0],[0]
"The TORDER data used in this paper are publicly available3 and our scalable generation method can be easily applied for inducing relations of longer distance pairs.
",4.2 Empirical Comparison,[0],[0]
Table 3 shows the comparison between the numbers of the TimeBank-Dense TLINKs and the new TORDERs.,4.2 Empirical Comparison,[0],[0]
"One observation as we expected is that our approach captures new relations for a considerable part of the mention pairs that were judged as v (vague) in the human-annotated
3https://github.com/racerandom/temporalorder
TLINKs.",4.2 Empirical Comparison,[0],[0]
"542 vague relations are induced as AFTER in the new TORDERs, as well as other relation types.",4.2 Empirical Comparison,[0],[0]
"However, a part of non-vague TLINKs are shifted to VAGUE TORDERs.",4.2 Empirical Comparison,[0],[0]
This matches our description of the imprecise time anchor issue.,4.2 Empirical Comparison,[0],[0]
It is a trade-off between the part of mention pairs obtaining richer temporal information and the part of pairs losing information.,4.2 Empirical Comparison,[0],[0]
That is the reason why we need a downstream task (i.e. Time Anchors Prediction in Section 5) to measure how much temporal order information is encoded in TORDERs and TLINKs.,4.2 Empirical Comparison,[0],[0]
"The shift of TLINK relations to SAME DAY due to the one-day minimal granularity setting can also be clearly observed.
",4.2 Empirical Comparison,[0],[0]
Figure 2 shows the label distributions of the auto-generated TORDERs and the TimeBankDense TLINKs.,4.2 Empirical Comparison,[0],[0]
"We investigate the statistics of Event-Event, Event-Time, and Event-DCT pairs.",4.2 Empirical Comparison,[0],[0]
The TimeBank-Dense corpus is obviously sparser due to the high proportion of vague in all three types of pairs.,4.2 Empirical Comparison,[0],[0]
"Our TORDERs show a more balanced distribution of labels, which suggests that this method possibly encodes more informative temporal orders compared to the traditional TLINKs.",4.2 Empirical Comparison,[0],[0]
"In particular, TORDERs show extremely rare VAGUE labels in Event-DCT pairs.",4.2 Empirical Comparison,[0],[0]
"When given the precise Single-Day DCT of a document, our proposal to compare the temporal order between the time anchor of a event and the DCT manages to avoid the most unstable judgments made by the human annotators in the EventDCT pairs.",4.2 Empirical Comparison,[0],[0]
"Although the different definition of TORDERs from TLINKs makes direct comparison difficult, the more balanced distribution of TORDERs can possibly provide more informative classification results to benefit the downstream tasks.",4.2 Empirical Comparison,[0],[0]
"Although the classification results of TORDERs and TLINKs are not directly comparable, they can show some evidence whether TORDERs is functional to provide temporal order information.",4.3 Classification Results,[0],[0]
"Table 4 shows the Bi-LSTM classification results with the data split4(Chambers et al., 2014) (27 training/validation documents, 9 testing documents).
",4.3 Classification Results,[0],[0]
"The classification system achieves fairly high F1 0.631 in Event-DCT and 0.485 in Event-Time on the SAME DAY temporal orders, which are the main information source to predict the precise time of events.",4.3 Classification Results,[0],[0]
"The performance on AFTER, BEFORE temporal orders are close to the TLINKs in number, but not meaningfully comparable.",4.3 Classification Results,[0],[0]
The high proportion of vague in the TLINKs results in biased predictions.,4.3 Classification Results,[0],[0]
"When we use a more meaningful evaluation ‘Non-vague’ overall, the TLINKs performance drops sharply.",4.3 Classification Results,[0],[0]
"Generally, the classification results suggest that our proposal of autogenerated TORDERs has sufficient capability to encode temporal information, which can be well
4https://github.com/nchambers/caevo/blob/master/src/mai n/java/caevo/Evaluate.java
classified from the textual inputs.",4.3 Classification Results,[0],[0]
"In this section, we describe a two-step system trained with the existing TLINKs and our data to challenge a downstream time anchor prediction task.",5 Evaluation in Time Anchor Prediction,[0],[0]
The different performance can be seen as the evidence whether our auto-generated TORDERs can capture comparable temporal information to the human-annotated TLINKs.,5 Evaluation in Time Anchor Prediction,[0],[0]
"Predicting the time of events from the news articles is an attractive goal, which is a necessary step towards automatic event timeline extraction.",5.1 Task Definition,[0],[0]
"Reimers et al. (2016) bring the task of time anchor prediction, which aims to predict the time anchor of each Single-Day event given a document.",5.1 Task Definition,[0],[0]
They use a general two-step process to determine the event anchors as shown in Figure 3.,5.1 Task Definition,[0],[0]
"Given a set of documents with events and time expressions already annotated, the system first obtains a list of possible times for each event.",5.1 Task Definition,[0],[0]
"Then, the most precise time is selected for each event.
",5.1 Task Definition,[0],[0]
A serious issue is that their baseline system still depends on the TimeBank-Dense TLINK classifier and the time anchor annotation is only used for the final evaluation.,5.1 Task Definition,[0],[0]
That leaves the space to consider a new method without relying on the human-annotated TLINKs.,5.1 Task Definition,[0],[0]
"Our auto-generated TORDERs are a natural alternative to TLINKs to provide the similar temporal order information of mention pairs, but with less annotation efforts.",5.1 Task Definition,[0],[0]
The second-step selection rules just need a slight modification to replace the previous TLINK types with the new TORDER types.,5.1 Task Definition,[0],[0]
"In this work, we adopt a similar two-step architecture.",5.2 The Two-step System in Experiments,[0],[0]
"The first-step temporal order classifier is designed to provide the temporal relations of the mention pairs in a document.
",5.2 The Two-step System in Experiments,[0],[0]
The second-step selects the most precise time by taking all Event-Time and Event-DCT relations of a target event as input.,5.2 The Two-step System in Experiments,[0],[0]
"For instance in Figure 3, the second-step received a set of relations e.g. (is included,DCT ), (is included, Friday) and (vague, January) of reported.",5.2 The Two-step System in Experiments,[0],[0]
"For the system trained with the TimeBank-Dense TLINKs, we adopt the same selection algorithm as described in (Reimers et al., 2016).",5.2 The Two-step System in Experiments,[0],[0]
"When the system is trained
with the TORDERs, we slightly modified the algorithm by replacing the TLINK relations with similar TORDER relations.",5.2 The Two-step System in Experiments,[0],[0]
"SAME DAY replaces simultaneous to predict precise dates, although their definition is quite different.",5.2 The Two-step System in Experiments,[0],[0]
We perform a 6-fold cross-validation strategy to predict all the TORDERs and TLINKs of the mention pairs in the 36 documents of the TimeBankDense corpus.,5.3 Experiment Settings,[0],[0]
"In each run, we split 30 documents for training and validation to predict the other 6 test documents.
",5.3 Experiment Settings,[0],[0]
"We define two evaluation metrics, i.e. Exact Match accuracy and Partial Match accuracy to measure the performance in this task as follows:
exact match = #Number of the exact match predictions
#Total number of the test samples
partial match = #Number of the partial match predictions
#Total number of the test samples
We define two partial match cases: 1) a precise (1998-02-06) is partial match with an imprecise (after 1998-02-06), if the date values are the same.",5.3 Experiment Settings,[0],[0]
"2) (after 1998-02-06) is partial match with (after 1998-02-06, before 1998-02-21), if one is a part of the other.",5.3 Experiment Settings,[0],[0]
Table 5 summarizes the main results of the twostep time anchor prediction system trained with TORDER and TLINK data.,5.4 Main Results,[0],[0]
"‘Precise’, ‘Imprecise’ and ‘Overall’ denote the results of predicting time anchors of precise events, imprecise events, and overall performance.",5.4 Main Results,[0],[0]
"‘Event-DCT’ or ‘EventTime’ denotes the second-step selection takes only Event-DCT or Event-Time pairs as input, which helps us to investigate how much information is provided by the different types of pairs for predicting the final time anchors.",5.4 Main Results,[0],[0]
"The new TORDERs show significantly superior out-performance in all three settings (i.e. only Event-DCT pairs, only Event-Time pairs, or Event-DCT +",5.4 Main Results,[0],[0]
"Event-Time), compared to the TLINKs.",5.4 Main Results,[0],[0]
"With both Event-DCT and Event-Time temporal order information, the system achieves the highest overall exact match and partial match accuracy.
",5.4 Main Results,[0],[0]
"The Event-DCT, Event-Time pairs are the source of temporal information for predicting time anchors.",5.4 Main Results,[0],[0]
"The system only using the Event-DCT achieves surprisingly high accuracy, particularly on the TORDER partial match accuracy of the
precise events.",5.4 Main Results,[0],[0]
The reason is that most events reported in news articles usually occur in precisely the same day as DCT.,5.4 Main Results,[0],[0]
"Therefore, the TORDER Event-DCT is benefited from the low proportion of vague relations, which sharply outperforms the TLINK Event-DCT by 16.3% overall exact match.",5.4 Main Results,[0],[0]
"However, the contribution of the EventTime to the overall might be underestimated in this task somehow.",5.4 Main Results,[0],[0]
The TORDER Event-Time still beats the TLINKs by 11% overall exact match and 16.4% overall partial match.,5.4 Main Results,[0],[0]
"Furthermore, the Event-Time encoding the temporal information within 1-sentence window in our experiments can be easily strengthen by our TORDER proposal to introduce more inter-sentence pairs.",5.4 Main Results,[0],[0]
"In this section, we perform an additional experiment to make a comparison to a system with the first-step replaced by a state-of-the-art dense TLINK classifier CAEVO (Chambers et al., 2014).",5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
"We adopt the data split setting in Section 4.3 for three classifiers: CAEVO, Bi-LSTM classifier trained with TLINKs and Bi-LSTM classifier trained with TORDERs.
",5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
The results are summarized in Table 6.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
CAEVO achieves the exact match accuracy slightly better than the Bi-LSTM model trained with the TLINKs.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
The Bi-LSTM model trained with the TORDERs sharply outperforms the other two systems by approximate 14% exact match accuracy and approximate 26% in partial match accuracy.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
"In this paper, we propose a new approach to obtain temporal relations based on time anchors (i.e. absolute time value) of mentions in news articles.",6 Conclusion,[0],[0]
Our pre-defined generation rules can automatically induce TORDER relations by comparing the temporal order of two time anchors in a timeline.,6 Conclusion,[0],[0]
"The requirement of our proposal for annotating time anchors is much easier compared to conventional methods, as the annotation effort is linear
with the number of mentions.",6 Conclusion,[0],[0]
The TORDER data used in this paper are publicly available.,6 Conclusion,[0],[0]
"The analysis, empirical comparison and classification results of the new TORDERs and the TimeBankDense TLINKs show our new data achieve the low VAGUE proportion, the informative relation types and the balanced label distribution.",6 Conclusion,[0],[0]
We perform the second evaluation of using the temporal relation classifier to complete the downstream task of time anchor prediction in news articles.,6 Conclusion,[0],[0]
"The main results show our TORDERs significantly outperform the TLINKs in this task, which suggests our proposal has the capability to encode informative temporal order information with less annotation effort.
",6 Conclusion,[0],[0]
The main limitation of TORDER is that events are required to be anchored in a timeline.,6 Conclusion,[0],[0]
Strötgen and Gertz (2016) introduce the highly different characteristics of time expressions in four domains of text.,6 Conclusion,[0],[0]
It suggests that our proposal is difficult to be applied in some domains.,6 Conclusion,[0],[0]
"One possible solution is to adopt a hybrid annotation method to annotate a target event towards the most relevant event (TLINK-style), when temporal information is absent in its context.",6 Conclusion,[0],[0]
"Although this work is motivated for contributing to timeline applications, evaluating this proposal in the temporal question answering is also valuable.",6 Conclusion,[0],[0]
SAME DAY could be harmful because this task possibly requires to know the exact order between two events occurring on the same day.,6 Conclusion,[0],[0]
It is worth conceiving a more general solution to improve the limitations of TORDER in the future work.,6 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable comments and thank Jason Bennett for useful discussions and proofreading.,Acknowledgments,[0],[0]
Recognizing temporal relations among events and time expressions has been an essential but challenging task in natural language processing.,abstractText,[0],[0]
Conventional annotation of judging temporal relations puts a heavy load on annotators.,abstractText,[0],[0]
"In reality, the existing annotated corpora include annotations on only ”salient” event pairs, or on pairs in a fixed window of sentences.",abstractText,[0],[0]
"In this paper, we propose a new approach to obtain temporal relations from absolute time value (a.k.a. time anchors), which is suitable for texts containing rich temporal information such as news articles.",abstractText,[0],[0]
"We start from time anchors for events and time expressions, and temporal relation annotations are induced automatically by computing relative order of two time anchors.",abstractText,[0],[0]
"This proposal shows several advantages over the current methods for temporal relation annotation: it requires less annotation effort, can induce inter-sentence relations easily, and increases informativeness of temporal relations.",abstractText,[0],[0]
We compare the empirical statistics and automatic recognition results with our data against a previous temporal relation corpus.,abstractText,[0],[0]
"We also reveal that our data contributes to a significant improvement of the downstream time anchor prediction task, demonstrating 14.1 point increase in overall accuracy.",abstractText,[0],[0]
Inducing Temporal Relations from Time Anchor Annotation,title,[0],[0]
"The past decade has witnessed advances of deep learning in a broad range of application areas such as game playing (Silver et al., 2016), natural language processing (Sutskever et al., 2014), image processing and computer vision (He et al., 2016).",1. Introduction,[0],[0]
"Its effectiveness is often attributed to the automated learning of latent representations, in that salient and discriminative features are highly beneficial for the overall learning task.",1. Introduction,[0],[0]
"With abstract and semantic features synthesized, the predictive relations between observations can be captured with more ease despite the possible complications in the correlation.",1. Introduction,[0],[0]
"In unsupervised learning, latent models have been widely used for clustering (Banerjee et al., 2005), dimensionality reduction (Lawrence, 2005), and transformation-invariant visual data analysis (Ranzato et al., 2012).
1Department of Computer Science, University of Illinois at Chicago, USA 2School of Computer Science, University of Waterloo, Canada.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Xinhua Zhang <zhangx@uic.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"The focus of this paper is conditional modeling for supervised learning, where latent variables are learned in the context of output information, so that accurate reconstruction of outputs can be facilitated through predictive intervening features.",1. Introduction,[0],[0]
"Such features can characterize latent clusters (Tishby et al., 1999), sparse coding (Elad & Aharon, 2006), invariant representation (Rifai et al., 2011), amongst others.
",1. Introduction,[0],[0]
"Despite their advantages in modeling and success in applications, latent models remain hard to train.",1. Introduction,[0],[0]
"The key challenge originates from the coupling of model parameter learning and latent variable inference, which in general leads to a nonconvex optimization problem.",1. Introduction,[0],[0]
"Although empirical performance has been the major focus of deep learning, recently substantial progress has been made towards the analysis of global training and the structure of the optimization problem.",1. Introduction,[0],[0]
"For example, Choromanska et al. (2014) and Dauphin et al. (2014) showed that the lowest critical values of the random loss function are close to the global minimum, and Kawaguchi (2016) showed, under certain assumptions, that every local minimum is a global minimum for an expected loss function of a deep nonlinear neural network.",1. Introduction,[0],[0]
"Similar global trainability results have been derived for gradient descent on two-node ReLU networks (Tian, 2017), quadratic activations (Soltanolkotabi et al., 2017), and one-hidden-layer non-overlapping convolution nets (Brutzkus & Globerson, 2017).",1. Introduction,[0],[0]
"The global minima in over-parameterized settings were characterized on deep and wide nets and convolutional nets (Nguyen & Hein, 2017a;b).",1. Introduction,[0],[0]
"However most analyses are still limited, especially with assumptions on the model and data distribution that are hard to verify in practice.
",1. Introduction,[0],[0]
"Along a different line of methodology, reformulations of latent models have been studied which admit tractable global solutions.",1. Introduction,[0],[0]
"Examples include boosting (Bengio et al., 2005), spectral methods (Anandkumar et al., 2014; Zhong et al., 2017), kernel methods (Zhang et al., 2016; 2017), polynomial networks and sum-product networks (Livni et al., 2014; Gens & Domingos, 2012), and semidefinite relaxations (Fogel et al., 2015).",1. Introduction,[0],[0]
"Unfortunately, they either impose restrictions on the model space (e.g. polynomial network, recursive inverse kernels), or require tractability of underlying oracles, or rely on realizability assumptions.
",1. Introduction,[0],[0]
"A framework based on reformulation that accommodates more general latent variable structures was proposed by Aslan et al. (2013; 2014), where each pair of adjacent layers are conjoined through a prediction loss that favors nonlinear connections.",1. Introduction,[0],[0]
"A similar approach was designed by Carreira-Perpinnan & Wang (2014), which introduced “auxiliary coordinates” to allow deviation from layer-wise outputs with a penalty.",1. Introduction,[0],[0]
"In order to achieve a convex model, Aslan et al. (2013; 2014) further represent each layer’s output as a kernel matrix, and the loss over adjacent kernels is relaxed in a jointly convex fashion, retaining nonlinear transformations that allow a rich set of salient latent features to be captured.
",1. Introduction,[0],[0]
"However, these models assume that all latent layers behave as a multi-label classifier, and the latent kernels are learned nonparametrically, i.e. there is no explicit parametric transfer function and nonlinear relations are introduced only through the loss functions between layers.",1. Introduction,[0],[0]
"This is more restrictive than state-of-the-art deep learners where the activation functions are parametric and continuously valued, with popular choices such as ReLU.",1. Introduction,[0],[0]
"As a result the model is restricted to a transductive setting, in that training examples are required to establish the data-dependent context of nonparametric kernel learning.",1. Introduction,[0],[0]
"This restriction significantly slows down predictions at test time, which is more important than the training cost.
",1. Introduction,[0],[0]
"Such a challenge in efficiency is exacerbated as the kernelbased learning leads to an expensive semi-definite programming (SDP), whose computational cost limited their experiments to only 200 examples.
",1. Introduction,[0],[0]
"The goal of this paper, therefore, is to develop an inductive and efficient learning strategy for two-layer conditional models with global optimality guarantees.",1. Introduction,[0],[0]
"This allows predictions to be made as efficiently as a feedforward neural network (FFNN) does, obviating retraining at test time.",1. Introduction,[0],[0]
It is achieved by directly constructing a convex relaxation based on a parametric transfer function (e.g. ReLU) specified a priori.,1. Introduction,[0],[0]
"In particular, we first make a new observation that no inter-layer loss satisfying nonlinear recovery and grounding can be jointly convex (§2).",1. Introduction,[0],[0]
"However by using the matching loss, the non-convexity can be encapsulated entirely by a bilinear term, facilitating a convex relaxation for ReLU based on completely positive (CP) cones (§3).",1. Introduction,[0],[0]
"The result provides a direct initialization of FFNN for finer tuning, which yields, inductively, more accurate predictions than baseline training methods (§5).",1. Introduction,[0],[0]
"Different from the SDP used by Aslan et al. (2013; 2014), our CP-based model allowed us to develop a new efficient algorithm using low-rank approximation, scaling up the size of solvable problems by an order of magnitude (§4).",1. Introduction,[0],[0]
A new constant approximation guarantee is also proved.,1. Introduction,[0],[0]
Two-layer neural networks are composed of two nonlinear conditional models.,2. Matching Loss for Transfer Functions,[0],[0]
The latent layer is characterized by a nonlinear transfer function f :,2. Matching Loss for Transfer Functions,[0],[0]
"Rh → Rh, which converts the linear transformation Wx into φ = f(Wx).",2. Matching Loss for Transfer Functions,[0],[0]
"Here x ∈ Rn is the raw input feature, and W ∈ Rh×n is the hidden layer weights.",2. Matching Loss for Transfer Functions,[0],[0]
"We use regular lowercase letters for scalar, bold lowercase letters for vector, and capital letters for matrix.",2. Matching Loss for Transfer Functions,[0],[0]
"The resulting φ is further multiplied with the output layer weights U ∈ Rh×m, and the product is measured against the given label y ∈ Rm via a loss function `(U ′φ,y).",2. Matching Loss for Transfer Functions,[0],[0]
Here U ′ is the transpose of U .,2. Matching Loss for Transfer Functions,[0],[0]
"Typical losses include binary hinge loss `(z, y) =",2. Matching Loss for Transfer Functions,[0],[0]
"[1− yz]+ with m = 1, where y ∈ {−1, 1} and [z]+ := max{0, z}.",2. Matching Loss for Transfer Functions,[0],[0]
"For multiclass problems with C classes, y encodes a class c with the canonical vector ec.",2. Matching Loss for Transfer Functions,[0],[0]
"Then m = C and the hinge loss `(z,y) =",2. Matching Loss for Transfer Functions,[0],[0]
max{1 − y + z,2. Matching Loss for Transfer Functions,[0],[0]
"− (y′z)1}, where 1 is a vector of all one’s.",2. Matching Loss for Transfer Functions,[0],[0]
"The logistic loss is −z′y + log ∑ c exp(zc).
",2. Matching Loss for Transfer Functions,[0],[0]
There are several popularly used transfer functions.,2. Matching Loss for Transfer Functions,[0],[0]
"The simplest options are elementwise, i.e. f(z) = (f(z1), . . .",2. Matching Loss for Transfer Functions,[0],[0]
", f(zh))
′, where all zi are applied separately to the same function f : R → R. ReLU uses fr(z) =",2. Matching Loss for Transfer Functions,[0],[0]
"[z]+, and variants include the leaky rectifier which uses fl(z) = max{z, az} where a > 0 is a small positive number, and the bounded hard tanh which uses fh(z) = max{−1,min{z, 1}}.",2. Matching Loss for Transfer Functions,[0],[0]
"Transfers that are not piecewise linear are also available, e.g. the sigmoid fs(z) =",2. Matching Loss for Transfer Functions,[0],[0]
(1 + e−z)−1.,2. Matching Loss for Transfer Functions,[0],[0]
These transfers are illustrated in Figure 1.,2. Matching Loss for Transfer Functions,[0],[0]
"Nonelementwise transfers are also available, e.g. the soft-max function with f(z) = (ez1 , . . .",2. Matching Loss for Transfer Functions,[0],[0]
", ezh)′/ ∑h k=1 e zk .
",2. Matching Loss for Transfer Functions,[0],[0]
A major source of non-convexity in neural network is the nonlinear transfer function.,2. Matching Loss for Transfer Functions,[0],[0]
"To cope with it, a natural approach is to replace the exact connection of φ = f(z) by a loss function that penalizes the deviation between φ and f(z).",2. Matching Loss for Transfer Functions,[0],[0]
"Formally, it attempts to construct a loss L(φ, z) that would (ideally) satisfy three conditions:
• Unique recovery: arg minφ L(φ, z) = f(z) for all z, with the arg min attained uniquely.
",2. Matching Loss for Transfer Functions,[0],[0]
• Joint convexity: L is jointly convex over φ and z.,2. Matching Loss for Transfer Functions,[0],[0]
"This is required if we choose to build a jointly convex deep model by directly usingL to connect the input and output of adjacent layers.
",2. Matching Loss for Transfer Functions,[0],[0]
•,2. Matching Loss for Transfer Functions,[0],[0]
"Grounding: minφ L(φ, z) = 0 for all z, so that there is no bias towards any value of z.
Unfortunately, it can be shown that such a loss does not exist, unless f is affine (see the proof in Appendix A):
Theorem 1.",2. Matching Loss for Transfer Functions,[0],[0]
"There exists a loss L that satisfies all the three conditions if, and only if, f is affine.
",2. Matching Loss for Transfer Functions,[0],[0]
This result motivates us to resort to weaker versions of loss.,2. Matching Loss for Transfer Functions,[0],[0]
"Interestingly, the matching loss (Auer et al., 1996) meets
the first and third conditions, and satisfies a weakened version of convexity by imposing a very mild condition on f .",2. Matching Loss for Transfer Functions,[0],[0]
"In particular, we assume that the transfer function is the gradient of a strictly convex function F : f = ∇F , with F : Rh → R. If f is elementwise, this just means the constituent f is continuous and strictly increasing.",2. Matching Loss for Transfer Functions,[0],[0]
"As a result, the inverse of f also exists, and it is well known that f−1 = ∇F ∗, where F ∗ is the Fenchel conjugate of F .
",2. Matching Loss for Transfer Functions,[0],[0]
"Although the ReLU fr(z) is not strictly increasing in the negative hallf line, it can be approximated arbitrarily closely via max{ z, z} for infinitesimally small > 0.",2. Matching Loss for Transfer Functions,[0],[0]
Similar alterations can be applied to hard tanh fh(z) by allowing a tiny slope for |z| ≥ 1.,2. Matching Loss for Transfer Functions,[0],[0]
"The F corresponding to the abovementioned transfers f are also shown in Figure 1.
",2. Matching Loss for Transfer Functions,[0],[0]
"In the case that f is not elementwise, this assumption of F implies: 1) f is strictly increasing in the vector sense: (x − y)′(f(x)",2. Matching Loss for Transfer Functions,[0],[0]
"− f(y)) > 0, and 2) The Jabobian of f is symmetric (as the Hessian of F ):",2. Matching Loss for Transfer Functions,[0],[0]
"Jf = (Jf)′, provided f is differentiable.",2. Matching Loss for Transfer Functions,[0],[0]
"Under this assumption, we adopt the following loss function based on Bregman divergence:
L(φ, z) = DF∗(φ, f(z))",2. Matching Loss for Transfer Functions,[0],[0]
"= F ∗(φ) + F (z)− φ′z, (1) whereDF∗ is the Bregman divergence induced by F ∗.",2. Matching Loss for Transfer Functions,[0],[0]
"Obviously L meets the conditions of recovery and grounding, but is not jointly convex.",2. Matching Loss for Transfer Functions,[0],[0]
"However, the only nonconvex part is the bilinear term φ′z, while both F ∗ and F are convex.",2. Matching Loss for Transfer Functions,[0],[0]
Such a decoupling of nonconvex terms from the transfer functions is the key enabler for our convex reformulation.,2. Matching Loss for Transfer Functions,[0],[0]
"Suppose we have t training pairs {(xj ,yj)}tj=1, stacked in two matrices X = (x1, . . .",3. Convex Two-layer Modeling,[0],[0]
",xt) ∈ Rn×t and Y = (y1, . . .",3. Convex Two-layer Modeling,[0],[0]
",yt) ∈Rm×t.",3. Convex Two-layer Modeling,[0],[0]
"The corresponding set of latent layer outputs are stacked into Φ = (φ1, . . .",3. Convex Two-layer Modeling,[0],[0]
",φt) ∈ Rh×t.",3. Convex Two-layer Modeling,[0],[0]
"The regularized risk minimization objective can be written as
min W,Φ U,b t∑ j=1 DF∗(φj , f(Wxj))",3. Convex Two-layer Modeling,[0],[0]
"+ `(U ′φj+b,yj)+ ‖W‖2+‖U‖2 2
= min W,U,b,Φ t∑ j=1 {F ∗(φj)−",3. Convex Two-layer Modeling,[0],[0]
φ′jWxj,3. Convex Two-layer Modeling,[0],[0]
+,3. Convex Two-layer Modeling,[0],[0]
"F (Wxj) (2)
+ `j(U ′φj + b)}+ 12 ‖W‖ 2 + 12 ‖U‖ 2 ,
where `j(U ′φj + b) := `(U ′φj + b,yj).",3. Convex Two-layer Modeling,[0],[0]
We introduced regularizations via Frobenius norms.,3. Convex Two-layer Modeling,[0],[0]
"The weight of both regularization terms can be tuned by any model selection method, e.g. cross validation, and here we put 1 to simplify the presentation.",3. Convex Two-layer Modeling,[0],[0]
We also assume that dom `j is the entire space.,3. Convex Two-layer Modeling,[0],[0]
"To keep our notation neat we write vector-input functions on matrices, representing the sum of the function values applied to each column, e.g. F ∗(Φ) = ∑ j F ∗(φj).",3. Convex Two-layer Modeling,[0],[0]
"Now we can rewrite the objective compactly as
min Φ,W,U,b
F ∗(Φ)− tr(Φ′WX) + F (WX) + `(U ′Φ + b1′)
+ 12 ‖W‖ 2 + 12 ‖U‖ 2 .",3. Convex Two-layer Modeling,[0],[0]
"(3)
It is bi-convex in two groups of variables (Φ,b) and (W,U), i.e. fixing one group it is convex in the other.",3. Convex Two-layer Modeling,[0],[0]
"In order to derive a jointly convex reformulation, we first note that `(U ′Φ + b1′) = maxR{tr(R′(U ′Φ + b1′))",3. Convex Two-layer Modeling,[0],[0]
"− `∗(R)}, where `∗ is the Fenchel conjugate of `, and R ∈ Rm×t.",3. Convex Two-layer Modeling,[0],[0]
"For binary hinge loss, `∗(r) =",3. Convex Two-layer Modeling,[0],[0]
yr over r ∈,3. Convex Two-layer Modeling,[0],[0]
"[min{0,−y},max{0,−y}], and ∞ else.",3. Convex Two-layer Modeling,[0],[0]
"For multiclass hinge loss, `∗(r) = y′r",3. Convex Two-layer Modeling,[0],[0]
if r + y ∈,3. Convex Two-layer Modeling,[0],[0]
∆m,3. Convex Two-layer Modeling,[0],[0]
":= {x ∈ Rm+ : 1′x = 1}, and ∞ else.",3. Convex Two-layer Modeling,[0],[0]
"For multiclass logistic loss, `∗(r) = ∑ i(ri + yi) log(ri + yi) if r + y ∈ ∆m, and∞ else.",3. Convex Two-layer Modeling,[0],[0]
"Similarly, F (WX) = maxΛ{tr(Λ′WX)",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ)}.,3. Convex Two-layer Modeling,[0],[0]
"So we can rewrite (2) into
min W,U,b,Φ max R,Λ
F ∗(Φ)− tr(Φ′WX) + tr(Λ′WX)
",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ) + tr(R′(U ′Φ + b1′))− `∗(R) + ‖W‖,3. Convex Two-layer Modeling,[0],[0]
"2+‖U‖2 2
=",3. Convex Two-layer Modeling,[0],[0]
"min Φ max R,Λ min W,U,b
F ∗(Φ)− tr(Φ′WX) + tr(Λ′WX)
",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ) + tr(R′(U ′Φ + b1′))− `∗(R) + ‖W‖,3. Convex Two-layer Modeling,[0],[0]
"2+‖U‖2 2
=",3. Convex Two-layer Modeling,[0],[0]
"min Φ max R1=0,Λ
F ∗(Φ)− 12 ‖(Φ− Λ)X ′‖2",3. Convex Two-layer Modeling,[0],[0]
"− 12 ‖ΦR ′‖2
− F ∗(Λ)− `∗(R).",3. Convex Two-layer Modeling,[0],[0]
"(4)
The optimal W and U for the last equality is W = (Φ + Λ)X ′",3. Convex Two-layer Modeling,[0],[0]
and U = −ΦR′.,3. Convex Two-layer Modeling,[0],[0]
"The first equality swaps minW,U,b with maxR,Λ. Such a strong duality is indeed not trivial because the celebrated Sion’s minimax lemma requires that the domain of (W,U) be compact, which is not assumed here.",3. Convex Two-layer Modeling,[0],[0]
"However the conclusion is still correct as we formalize here.
",3. Convex Two-layer Modeling,[0],[0]
Theorem 2.,3. Convex Two-layer Modeling,[0],[0]
"For any W,U,b, denote L(Φ, R) = F ∗(Φ)− tr(Φ′WX) + tr(R′(U ′Φ + b1′))− `∗(R).",3. Convex Two-layer Modeling,[0],[0]
"Then
min Φ max R L(Φ, R) = max R min Φ L(Φ, R).
",3. Convex Two-layer Modeling,[0],[0]
"To prove it, just use Proposition 2.2 (p173) of (Ekeland & Témam, 1999).",3. Convex Two-layer Modeling,[0],[0]
"There, take R = Λ = 0",3. Convex Two-layer Modeling,[0],[0]
"(i.e. p0 = 0), and then L diverges when (W,U) diverges.",3. Convex Two-layer Modeling,[0],[0]
Note b disappears as R = 0.,3. Convex Two-layer Modeling,[0],[0]
We now derive a convex relaxation for (4).,3.1. Convex relaxation,[0],[0]
"To be concrete, consider the ReLU transfer with Fr(Z)",3.1. Convex relaxation,[0],[0]
"= 12 ‖[Z]+‖
2.",3.1. Convex relaxation,[0],[0]
"Its Fenchel dual is F ∗r (Φ) = 1 2 ‖Φ‖
2 for Φ ≥ 0",3.1. Convex relaxation,[0],[0]
"(elementwise), and +∞ otherwise.",3.1. Convex relaxation,[0],[0]
"Therefore (4) can be specialized into
min Φ≥0 max R1=0,Λ≥0
1 2 ‖Φ‖ 2 − 12 ‖(Φ− Λ)X ′‖2 (5)
",3.1. Convex relaxation,[0],[0]
"− 12 ‖ΦR ′‖2 − 12 ‖Λ‖ 2 − `∗(R).
",3.1. Convex relaxation,[0],[0]
"Notice that both Φ and Λ are constrained to the positive orthant, and they are both sized h×t.",3.1. Convex relaxation,[0],[0]
"Since t h in general, their ranks are h and their column spaces have full rank.",3.1. Convex relaxation,[0],[0]
"As a result, we may perform change of variable via Λ = ΦA, where A ∈ Rt×t+ and is not necessarily symmetric.",3.1. Convex relaxation,[0],[0]
"So we can rewrite (5) as min Φ≥0 max R1=0,A≥0 1 2 ‖Φ‖ 2 − 12 tr(Φ ′Φ(I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
"− 12 tr(Φ ′ΦR′R)− 12 tr(Φ ′ΦAA′)− `∗(R).
",3.1. Convex relaxation,[0],[0]
"Although this is still not convex, all occurrences of Φ are now in the form of Φ′Φ, leading to the natural idea of optimizing over Φ′Φ directly.",3.1. Convex relaxation,[0],[0]
"Denote T := Φ′Φ ∈ Rt×t, and then we finally arrive at
min T∈Th max R1=0,A≥0
1 2 tr(T )",3.1. Convex relaxation,[0],[0]
"− 1 2 tr(T (I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
"− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R),
where Th := { Φ′Φ : Φ ∈ Rh×t+ } ⊆ { T ∈ Rt×t+ : T 0 } .",3.1. Convex relaxation,[0],[0]
T 0 means T is positive semi-definite (PSD).,3.1. Convex relaxation,[0],[0]
"Now given T , the maximization over R and A is concave because T 0.",3.1. Convex relaxation,[0],[0]
"Indeed A and R are decoupled, making the inner optimization efficient.",3.1. Convex relaxation,[0],[0]
"The objective function is also convex in T , because maximization over linear terms gives a convex function.",3.1. Convex relaxation,[0],[0]
"The only challenge left is the nonconvexity of Th.
",3.1. Convex relaxation,[0],[0]
The set Th is obviously a cone.,3.1. Convex relaxation,[0],[0]
"In fact, if we relax the fixed value of h, then T∞ is the well-known completely positive (CP) matrix cone (Berman & Shaked-Monderer, 2003).",3.1. Convex relaxation,[0],[0]
"More interestingly, it is not hard to show that T∞ is the tightest convex relaxation of Th, i.e. the convex hull of Th for any h. Letting T := T∞ yields our final objective
min T∈T max R1=0,A≥0
1 2 tr(T )",3.1. Convex relaxation,[0],[0]
"− 1 2 tr(T (I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R).,3.1. Convex relaxation,[0],[0]
"(6)
It turns out that the convex relaxation does not require prespecifying the number of hidden nodes; h can be figured out automatically through the rank of the optimal T .",3.1. Convex relaxation,[0],[0]
"We will see in the sequel that the formulation does implicitly favor a low-rank solution through a gauge regularizer (Lemma 1), although a manual assignment of h can always be incorporated through truncation after optimization.
",3.1. Convex relaxation,[0],[0]
Generality of the convexification scheme.,3.1. Convex relaxation,[0],[0]
"We note in passing that the above technique is general, and can be extended beyond ReLU.",3.1. Convex relaxation,[0],[0]
"For example, when using the hard tanh transfer, we have F ∗h (Φ) = 1 2 ‖Φ‖
2 if the L∞ norm ‖Φ‖∞",3.1. Convex relaxation,[0],[0]
":= maxij |Φij | ≤ 1, and∞ otherwise.",3.1. Convex relaxation,[0],[0]
"Then we get the same objective function as in (6), only with Th changed into {Φ′Φ : ‖Φ‖∞ ≤ 1} and the domain of A changed into {A : ∑",3.1. Convex relaxation,[0],[0]
i |Aij,3.1. Convex relaxation,[0],[0]
"| ≤ 1, ∀ j}.
",3.1. Convex relaxation,[0],[0]
Even more general extensions to non-elementwise transfer functions can also be developed in our framework.,3.1. Convex relaxation,[0],[0]
"The details on convexifying the soft-max transfer (and hard tanh) are deferred to Appendix B, and the space saved will be devoted to the more important issue of efficiently optimizing the model, hence overcoming the key bottleneck that has much confined the applicability of (Aslan et al., 2014).",3.1. Convex relaxation,[0],[0]
"Although the problem (6) is convex, the set T lacks a compact characterization in terms of linear/quadratic, PSD, or second-order conic constraints.",4. Optimization,[0],[0]
"Optimization over completely positive matrices is known hard (Berman & ShakedMonderer, 2003), and even projection to T is NP-hard (Dickinson & Gijben, 2014).1 Therefore we resort to conditional gradient (Frank-Wolfe) methods that are free of projection (CG, Jaggi, 2013; Harchaoui et al., 2015).",4. Optimization,[0],[0]
The key benefit of CG lies in the efficiency of optimizing a linear function over T (a.k.a.,4. Optimization,[0],[0]
"the polar operator), robustness in its inaccuracy (Freund & Grigas, 2016), and the low rank of intermediate solutions due to its greedy and progressive nature (hence efficient intermediate updates).
",4. Optimization,[0],[0]
"In practice, however, CG still suffers from slow convergence, and its linearly-converging variants are typically subject to a large condition number (Lacoste-Julien & Jaggi, 2015).",4. Optimization,[0],[0]
"This is partly because at each step only the weights on the existing bases are optimized, while the bases themselves are not.",4. Optimization,[0],[0]
"To alleviate this problem, Zhang et al. (2012) proposed the Generalized Conditional Gradient algorithm (GCG) which simultaneously optimizes the bases.",4. Optimization,[0],[0]
"Despite the lack of theoretical proof, it is much faster in practice.",4. Optimization,[0],[0]
"Furthermore, GCG is robust to inexactness in polar operators, and one of our key contributions below is to
1In spite of the “convexity”, a convex function may itself be NP-hard to evaluate, or it can be NP-hard to project to a convex set, or optimize a linear function over it.
show that it can efficiently solve (6) with a multiplicative approximation bound of 14 .
",4. Optimization,[0],[0]
"Since GCG operates on gauge regularized objectives, our first step is to take a nontrivial path of rewriting (6).",4. Optimization,[0],[0]
"Recall that given a convex bounded set C containing the origin, the gauge function induced by C evaluated at T is defined as γC(T )",4. Optimization,[0],[0]
":= min{γ ≥ 0 : γX = T, X ∈ C}.",4. Optimization,[0],[0]
"If no such (γ,X) meets the condition, then γC(T )",4. Optimization,[0],[0]
":= ∞. Since (6) does not contain a gauge function induced by a bounded set (T is unbounded), we first recast it into this framework.
",4. Optimization,[0],[0]
"The simplest way to add bound to T is via the trace norm, which is exactly tr(T ) since T 0:
S := T ∩ {T : tr(T ) ≤ 1} (7) = convT1 ∩ {T : tr(T ) ≤ 1}",4. Optimization,[0],[0]
"(8) = conv { xx′ : x ∈ Rt+, ‖x‖ ≤ 1 } .",4. Optimization,[0],[0]
"(9)
Our key observation is the following lemma which allows us to rewrite the problem in terms of gauge regularized objective.",4. Optimization,[0],[0]
"In particular, the domain of the gauge implicitly enforces the constraint on T .
",4. Optimization,[0],[0]
Lemma 1.,4. Optimization,[0],[0]
"S is convex, bounded, and closed.",4. Optimization,[0],[0]
"In addition
γS(T ) =",4. Optimization,[0],[0]
{ tr(T ) T ∈ T +∞ otherwise .,4. Optimization,[0],[0]
"(10)
",4. Optimization,[0],[0]
The proof is relegated to Appendix A.,4. Optimization,[0],[0]
"In fact, it is easy to show that for any convex cone C, the gauge function of its intersection with a half-space tr(A′T )",4. Optimization,[0],[0]
≤ 1 is exactly tr(A′T ) overC.,4. Optimization,[0],[0]
The significance of Lemma 1 is that it provides the cornerstone for solving the problem (6) by GCG.,4. Optimization,[0],[0]
"Indeed, (6) can be equivalently rewritten as
min T
J(T )",4. Optimization,[0],[0]
:= 12γS(T ) + g(T ),4. Optimization,[0],[0]
"where (11)
g(T )",4. Optimization,[0],[0]
":= max R1=0,A≥0
− 12 tr(T (I −A)X ′X(I −A′)) (12)
− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R).
",4. Optimization,[0],[0]
"This objective finally falls into the framework of GCG sketched in Algorithm 1 (Zhang et al., 2012; Harchaoui et al., 2015).",4. Optimization,[0],[0]
GCG proceeds in iterations and at each step it seeks the steepest descent extreme point T new (a.k.a. basis) of the set S with respect to the objective gradient (steps 3-4).,4. Optimization,[0],[0]
"After finding the optimal conic combination with the existing solution (step 5), it directly optimizes the underlying factor Φ, initialized by the value that corresponds to the current solution T (step 6).",4. Optimization,[0],[0]
"Although this last step is not convex (hence called “local optimization”), it offers significant practical efficiency because it allows all existing bases to be optimized along with their weights.
",4. Optimization,[0],[0]
"We next provide details on the efficient computational strategies for the above operations in our problem.
",4. Optimization,[0],[0]
Algorithm 1: General GCG algorithm 1 Randomly sample Φ1 ∈,4. Optimization,[0],[0]
"[0, 1]t, and set T1 = Φ′1Φ1.",4. Optimization,[0],[0]
"2 while k = 1, 2, . .",4. Optimization,[0],[0]
.,4. Optimization,[0],[0]
"do 3 Find ∇g(Tk) with Tk = Φ′kΦk by solving the inner
maximization problem in g(Tk) of (12).",4. Optimization,[0],[0]
"4 Polar operator: find a new basis via T new = arg maxT∈S 〈T,−∇g(Tk)〉.",4. Optimization,[0],[0]
"5 Compute the optimal combination weight
(α, β) := arg minα≥0,β≥0 J(αTk + βT",4. Optimization,[0],[0]
"new).
6 Locally optimize T : Φk+1 =arg minΦ≥0 J(Φ′Φ) with Φ initialized by the value corresponding to Φ′Φ",4. Optimization,[0],[0]
"= αTk + βT
new (see Section 4.1).",4. Optimization,[0],[0]
7 Return Tk+1,4. Optimization,[0],[0]
"Given the negative gradient G = −∇g(Tk) ∈ Rt×t, the polar operator of S tries to solve the following optimization problem by using the characterization of S in (9):
max T∈S tr(G′T ) ⇐⇒ max x∈Rt+, ‖x‖≤1 tr(x′Gx).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"(13) Unfortunately, this problem is NP-hard.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"If this were solvable for any G, then we could use it to answer whether minx≥0 x
′(−G)x ≥ 0.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"But the latter is to check the copositivity of −G, which is known to be co-NP-complete (Murty & Kabadi, 1987).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Usually problems like (13) are approached by semi-definite relaxations (SDP), and Nemirovski et al. (1999) showed that it can be approximately solved with a multiplicative bound of O(1/ log t).
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"As one of our major contributions, we next show that when G 0, this bound can be tightened into constant for (13) with a computational procedure that is much more efficient than SDP.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Furthermore, our problem does satisfy G 0.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Before proceeding, we first recall the definition of a multiplicative α-approximate solution.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Definition 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Let α ∈ (0, 1] and assume an optimization problem maxx∈X f(x) has nonnegative optimal value.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
A solution x∗ ∈ X is called α-approximate if f(x∗) ≥ αmaxx∈X f(x) ≥ 0.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Similarly, the condition becomes 0 ≤ f(x∗) ≤",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
1α minx∈X f(x) for minimization problems.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Theorem 3.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Assume G 0.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Then a 14 -approximate solution to (13) can be found in O(t2) time.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Proof.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Since G 0, it can be decomposed into G = H ′H and the problem (13) becomes maxx∈Rt+,‖x‖≤1 ‖Hx‖
2.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Let v be top eigenvector ofG that corresponds to the greatest eigenvalue.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Then v maximizes ‖Hx‖ over ‖x‖ ≤ 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Decompose v = v+ − v−, where v+ =",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"[v]+ collects the nonnegative components, and v− collects the negative components.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Apparently we have ‖v+‖ ≤ 1 and ‖v−‖ ≤ 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Without loss of generality assume ‖Hv+‖2 ≥ ‖Hv−‖2 and consequently let us use v+ as an approximate minimizer, which we demonstrate is 14 -approximate:
maxx∈Rt+,‖x‖≤1‖Hx‖ 2≤ ‖Hv‖2",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"= ‖Hv+ −Hv−‖2
≤ 2(‖Hv+‖2+‖Hv−‖2) ≤4 ‖Hv+‖2.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Obviously v+‖v+‖ is an even better solution, which can also be used as an initializer for further local optimization.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"The computational bottleneck lies in the top eigenvector v of G, which costs O(t2).
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"In the case that G is not PSD, it turns out very hard to extend this technique while retaining a constant bound.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"However the SDP-based technique in (Nemirovski et al., 1999) still applies, and the bound remains 1/ log t.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"In hindsight, our choice of the adding Frobenius norm constraint on Φ when defining S in (7) is not arbitrary.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
It constitutes the most straightforward path that allows the polar operator to be approximated in a tractable fashion.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Other choices, such as structured Frobenius norms, could be possible if we would like to enforce structured decompositions in the hidden representation.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"We leave the extension of tractable approximation for future exploration.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Finally, although our algorithm for the polar operator requires G be positive semi-definite—which is not satisfied in general—it happens to be fulfilled by our particular problem (11).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Notice the gradient of g is simply
− 12 (I −A)X ′X(I −A′)−",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
12R ′R−,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"12AA ′, (14)
where the R and A are the optimal solution to the inner maximization.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"This is obviously negative semi-definite, providing the key cornerstone for the constant approximation bound of our approach.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Optimality of GCG and rates of convergence We finally translate the bound on the polar operator to that of the original objective (11).,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"As shown by Theorem 1 of (Cheng et al., 2016), any α-approximate polar operator allows GCG to converge to an α-approximate solution to the original problem, and the convergence rate is O(1/ ).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Hence we are guaranteed to find a 14 -approximate solution to (11).,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
The overall method is summarized in Algorithm 2.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"The computational bottleneck of applying GCG to our problem (11) is the step of local optimization: minΦ J(Φ
′Φ) over Φ ∈ Rh×t+ .",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Owing to the Φ′Φ term, this objective is not convex.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"However, it is often observed in practice that the overall optimization can be much accelerated if we solve it just locally (e.g. by BFGS), with Φ initialized based on the value of the convex optimization variable T (step 6 of Algorithm 1 or step 11 of Algorithm 2).
",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Unfortunately, since g defined in (12) employs a nested maximization, we are now faced with a min-max problem.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Different from min-min optimizations minx miny f(x, y)
Algorithm 2: Solve (6) for T by the GCG algorithm 1 Randomly sample Φ1 ∈",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"[0, 1]t, and set T1 = Φ′1Φ1.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"2 while k = 1, 2, . .",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
.,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"do 3 if k = 1 then 4 (Uk,bk) = optimal U and b in (15) for Φ1.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
5 Mk = optimal M in (15) for Φ1.,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
6 Recover the optimal R: Rk=∇`(U ′kΦk+bk1′).,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
7 Recover the optimal A by (17).,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"8 Compute the gradient Gk of gµ at Tk = Φ′kΦk via
(14), with R and A served by Rk and Ak, resp 9 Compute a new basis xk by approximately solving
arg maxx∈Rt+,‖x‖≤1 x ′(−Gk)x (c.f. Theorem 3).",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"(α, β) := arg minα≥0,β≥0 J(αTk + βxkx ′ k).
11 Set Φtmp = ( √ αΦ′k, √ βxk)
′. 12 Local search: (Φk+1, Uk+1,bk+1,Mk+1) := Local Opt(Φtmp, Uk,bk,Mk) by Algorithm 3.",10 Line search:,[0],[0]
"13 Return Tk+1
Algorithm 3: Local optimization used by GCG 1 Require (Φtmp, Uk,bk,Mk) from the current step 2 Initialize : Φ = Φtmp, U = Uk, b = bk, M = Mk. 3 for t = 1, 2, . . .",10 Line search:,[0],[0]
"do // till the change is small 4 (U,b) = arg minU,b{`(U ′Φ + b1′) + 12 ‖U‖
2}.",10 Line search:,[0],[0]
"5 M = arg minM≥0 h(M,Φ).",10 Line search:,[0],[0]
6,10 Line search:,[0],[0]
"Φ = arg minΦ≥0 {`(U ′Φ + b1′) + h(M,Φ)}.",10 Line search:,[0],[0]
"7 Return (Φ, U,b,M).
",10 Line search:,[0],[0]
"which can be solved very efficiently by alternating between optimizing x and y, a min-max problem like minx maxy f(x, y) cannot be solved by alternating: fixing x solve y, and fixing y solve x. Instead, one needs to treat the objective as a function of x, and for each x solve the inner maximization in y exactly, before obtaining a gradient in x that is supplied to standard solvers such as BFGS.",10 Line search:,[0],[0]
"This is often much slower than alternating.
",10 Line search:,[0],[0]
"To enable an efficient solution by alternating, we next develop a novel reformulation of g as a minimization, such that minimizing g becomes a min-min problem:
g(Φ′Φ) = max R1=0 { − 12 ‖ΦR ′‖2 − `∗(R) }
+ max A≥0
{ − 12 ‖Φ(I −A)X ′‖2",10 Line search:,[0],[0]
"− 12 ‖ΦA‖ 2 }
= max R min b
{ b′R1−`∗(R)−max
U − tr(U ′ΦR′)− ‖U‖
2
2 } + max
A min M≥0
{ −‖Φ(I−A)X
′‖2 2 − ‖ΦA‖2 2 + tr(M ′A) }",10 Line search:,[0],[0]
"= min
U,b
{ `(U ′Φ + b1′) + 12 ‖U‖ 2 }
+",10 Line search:,[0],[0]
"min M≥0 h(M,Φ), (15)
where h(M,Φ) := max",10 Line search:,[0],[0]
"A
{ − 12 ‖Φ(I −A)X ′‖2 (16)
− 12 ‖ΦA‖ 2
+ tr(M ′A) } .
",10 Line search:,[0],[0]
"As the key advantage achieved here, the local optimization minΦ≥0 J(Φ ′Φ) = minΦ≥0 1 2 ‖Φ‖ 2 + g(Φ′Φ) can now be solved by alternating between (U,b), M , and Φ. The details are shown in Algorithm 3.",10 Line search:,[0],[0]
"The optimization over (U,b) is the standard supervised learning.",10 Line search:,[0],[0]
"However, the optimization over M and Φ is trickier because they require evaluating h which in turn involves a nested optimization on A.",10 Line search:,[0],[0]
"Fortunately h is quadratic in A, which allows us to design an efficient closed-form scheme by leveraging the celebrated Woodbury formula (Woodbury, 1950).
",10 Line search:,[0],[0]
"Given (M,Φ), the optimal A can be found by setting its gradient to zero: Φ′ΦA(X",10 Line search:,[0],[0]
′X,10 Line search:,[0],[0]
+ I) = M + Φ′ΦX ′X .,10 Line search:,[0],[0]
"Unfortunately, the rank of Φ′ΦA (hence the left-hand side) is at most h < t.",10 Line search:,[0],[0]
"So noA can satisfy the equality if the rank of the right-hand side is greater than h, and hence h(M,Φ) is finite only if the column space of (M + Φ′ΦX ′X)(X ′X+ I)−1 is contained in that of Φ′. Such an implicit constraint between variables precludes the application of alternating.
",10 Line search:,[0],[0]
"To address this problem, we introduce a small strongly convex regularizer on A in the definition of h(M,Φ) in (16), akin to the standard smoothing technique (Nesterov, 2005):
hµ(M,Φ) := max A
{ − 12 ‖Φ(I −A)X ′‖2 − 12 ‖ΦA‖ 2
+ tr(M ′A)− µ2 tr(A(X ′X + I)A′)
} ,
where µ > 0 is small.",10 Line search:,[0],[0]
"The new term µ2 tr(A(X ′X + I)A′) also needs to be added to the definition of g in (12), which we will denote as gµ. Then the optimal A can be found by setting the gradient to zero: A = (Φ′Φ + µI)−1(M + Φ′ΦX ′X)(X ′X +",10 Line search:,[0],[0]
I)−1.,10 Line search:,[0],[0]
"(17)
To efficiently computeA, we apply the Woodbury formula: µA",10 Line search:,[0],[0]
= (M + Φ′ΦX ′X)(X ′X +,10 Line search:,[0],[0]
"I)−1
− Φ′(µI + ΦΦ′)−1Φ(M + Φ′ΦX ′X)(X ′X+I)−1.
",10 Line search:,[0],[0]
Computational complexity.,10 Line search:,[0],[0]
Here (µI + ΦΦ′)−1 ∈ Rh×h can be computed efficiently as h is not large (it is exactly the iteration index k in GCG Algorithm 2).,10 Line search:,[0],[0]
Then the second line can be computed inO(ht2) time as we can precompute (X ′X + I)−1.,10 Line search:,[0],[0]
"So the only challenge in computing A is the term M(X ′X+ I)−1, which costs O(t3) time.",10 Line search:,[0],[0]
"However, if n t, then we may again save computations by applying the Woodbury formula: M(X ′X + I)−1 = M −MX ′(I +XX ′)−1X, which costs O(nt2) time.
",10 Line search:,[0],[0]
"Overall, the complexity is 1 ·nt 2 multiplied with: i) #round of alternating in Algorithm 3, and ii) #iteration of LBFGS in steps 4-6.",10 Line search:,[0],[0]
"In practice, with warm start these two numbers are about 10 before the relative change becomes small.",10 Line search:,[0],[0]
"We evaluated the proposed inductive training of convexified two-layer model (CVX-IN) by comparing the generalization accuracy with 4 other baselines: FFNN: a two-layer
feedforward neural network; Ker-CVX: the kernel-based convex model proposed by Aslan et al. (2014); LOCAL: a model obtained by alternative minimization of the twolayer objective (3); and CVX-TR: our model learned transductively (see below).",5. Experiment,[0],[0]
"SVM was not included since it was already shown inferior to Ker-CVX by Aslan et al. (2014).
",5. Experiment,[0],[0]
Inductive learning.,5. Experiment,[0],[0]
"A key advantage of our method is the purely inductive setting, which obviates any retraining during test time, as opposed to a transductive setting.",5. Experiment,[0],[0]
"After completing the GCG optimization, CVX-IN directly obtains the optimal U and b thanks to the local minimization in Algorithm 3.",5. Experiment,[0],[0]
"The optimal W can be recovered by solving (3) with fixed (Φ, U,b), and it is a simple convex problem.",5. Experiment,[0],[0]
"With this initialization, we finely tuned all parameters by backpropagation.
",5. Experiment,[0],[0]
Transductive learning.,5. Experiment,[0],[0]
"As Ker-CVX is transductive, we also considered the following transductive variant of CVXIN.",5. Experiment,[0],[0]
"The objective (11) was first trained with X being the combination of (Xtrain, Xtest), and accordingly the intermediate representation Φ (along with the corresponding T ) also consisted of the combination of (Φtrain,Φtest).",5. Experiment,[0],[0]
"Since only Ytrain was available for training, the loss function `(U ′Φ + b1′) was applied only to the training data.",5. Experiment,[0],[0]
"As a result, Φtest was learned largely from the matching loss in the latent layer given by (16).",5. Experiment,[0],[0]
"After recovering the optimal U and b by local minimization (same as in CVX-IN), test data were labeled by Ŷtest = U ′Φtest +b1′. Although CVX-TR bypasses the recovery of W , optimization has to be redone from scratch when new test data arrives.
",5. Experiment,[0],[0]
Comparison on smaller datasets.,5. Experiment,[0],[0]
"To enable comparison with Ker-CVX which is highly expensive in computation, we first used smaller datasets including a synthetic XOR dataset and three “real world” datasets for binary classification: Letter (Lichman, 2013), CIFAR-SM, a binary classification dataset from (Aslan et al., 2013) based on CIFAR100 (Krizhevsky & Hinton, 2009), and G241N (Chapelle).
",5. Experiment,[0],[0]
"All methods were applied to two different sizes of training and test data (Xtrain and Xtest): 100/100 and 200/200, and the resulting test error, averaged over 10 trials, were presented in Table 1 and 2 respectively.",5. Experiment,[0],[0]
"CVX-IN outperforms FFNN on G241N, Letter, and CIFAR-SM, and they both delivered perfect classification on XOR.",5. Experiment,[0],[0]
"This corroborates the advantage of convex models, suggesting that predictive structures are preserved by the relaxation.",5. Experiment,[0],[0]
"CVX-IN also marginally outperforms or is comparable to CVX-TR on all the datasets, confirming that inductive learning saves computation at test time without sacrificing the accuracy.",5. Experiment,[0],[0]
"Consistently poor performance is observed on the LOCAL method (used in a transductive fashion), and it does not work even for XOR.",5. Experiment,[0],[0]
This implies that it does suffer seriously from local optimality.,5. Experiment,[0],[0]
"Ker-CVX (transductive only) performs competitively on 200 examples especially on the Letter dataset, but its error on 100 examples is significantly
higher than CVX-IN and CVX-TR.",5. Experiment,[0],[0]
"It ran into computational issues on G241N, hence marked by N/A.
On the CIFAR-SM dataset all methods produced a slightly higher error with 200 training examples than 100 examples, probably due to the small size of training set and high variance.",5. Experiment,[0],[0]
"However the comparative results between algorithms remain similar to other datasets.
",5. Experiment,[0],[0]
Comparison on larger datasets.,5. Experiment,[0],[0]
"Thanks to the fast local optimization enabled by the new min-min alternating (§4.2), our model enjoys significant speedup compared with Aslan et al. (2013; 2014).",5. Experiment,[0],[0]
"To demonstrate this, we applied CVX-IN to Letter, XOR, and CIFAR-10 (Krizhevsky & Hinton, 2009) with 1000/1000 and 2000/2000 train/test examples, and to G241N with 1000/500 examples (the entire dataset only has 1500 examples).",5. Experiment,[0],[0]
"Details on data preprocessing are available in Appendix C.
As Table 3 and 4 show, CVX-IN again achieves significantly lower test error on these larger datasets over FFNN, CVX-TR, and LOCAL.",5. Experiment,[0],[0]
"The training time of CVX-IN is summarized in Table 6, and it took 2.5 hours on CIFAR-10 with 2000 examples and 256 features.",5. Experiment,[0],[0]
"Although still expensive, it is substantially faster than Ker-CVX which is completely incapable of scaling here (hence omitted).",5. Experiment,[0],[0]
"In contrast, the run time of FFNN and LOCAL is much lower.",5. Experiment,[0],[0]
"These are shown for comparison in Appendix D. Overall CVX-IN scales quadratically in #examples (t), which is consistent with our analysis in §4.2.
",5. Experiment,[0],[0]
Intermediate representation.,5. Experiment,[0],[0]
One of the key merits of our two-layer model is that the relaxation retains the necessary structure in the input data to make accurate predictions.,5. Experiment,[0],[0]
"To test this feature, we tried to visualize the latent representation learned by our CVX-IN.",5. Experiment,[0],[0]
"Figure 2 demonstrates the original features in the input data Xtrain and the learned intermediate representation Φtrain, for two datasets Box and XOR which both employ a rich latent structure.",5. Experiment,[0],[0]
Clearly the convex relaxation was able to separate the two classes and preserve sufficient structures that allows it to outperform single-layer models.,5. Experiment,[0],[0]
We developed a convex relaxation for parametric transfer functions such as ReLU based on matching loss.,6. Conclusions and Future Work,[0],[0]
An efficient optimization method was designed with a constant approximation bound.,6. Conclusions and Future Work,[0],[0]
For future work we will explore other transfer functions and their influence.,6. Conclusions and Future Work,[0],[0]
"To the best of our knowledge, no nontrivial recovery properties are known about nonlinear CP or SDP relaxation.",6. Conclusions and Future Work,[0],[0]
"Although our empirical results demonstrate compelling promise, it will be interesting to rigorously establish its theoretical guarantees.",6. Conclusions and Future Work,[0],[0]
"Latent prediction models, exemplified by multilayer networks, employ hidden variables that automate abstract feature discovery.",abstractText,[0],[0]
"They typically pose nonconvex optimization problems and effective semi-definite programming (SDP) relaxations have been developed to enable global solutions (Aslan et al., 2014).",abstractText,[0],[0]
"However, these models rely on nonparametric training of layer-wise kernel representations, and are therefore restricted to transductive learning which slows down test prediction.",abstractText,[0],[0]
"In this paper, we develop a new inductive learning framework for parametric transfer functions using matching losses.",abstractText,[0],[0]
"The result for ReLU utilizes completely positive matrices, and the inductive learner not only delivers superior accuracy but also offers an order of magnitude speedup over SDP with constant approximation guarantees.",abstractText,[0],[0]
Inductive Two-layer Modeling with Parametric Bregman Transfer,title,[0],[0]
"In this paper, we analyze inference suboptimality: the mismatch between the true and approximate posterior.",1. Introduction,[0],[0]
"More specifically, we are interested in understanding what factors cause the gap between the marginal log-likelihood and the evidence lower bound (ELBO) in variational autoencoders (VAEs, Kingma & Welling (2014); Rezende et al. (2014)).",1. Introduction,[0],[0]
We refer to this as the inference gap.,1. Introduction,[0],[0]
"Moreover, we break down the inference gap into two components: the approximation gap and the amortization gap.",1. Introduction,[0],[0]
The approximation gap comes from the inability of the variational distribution family to exactly match the true posterior.,1. Introduction,[0],[0]
"The amortization gap refers to the difference caused by amortizing the variational parameters over the entire training set, instead of optimizing for each training example individually.",1. Introduction,[0],[0]
"We refer the reader to Table 1 for the definitions of the gaps and to
1Department of Computer Science, University of Toronto, Toronto, Canada.",1. Introduction,[0],[0]
"Correspondence to: Chris Cremer <ccremer@cs.toronto.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
Fig. 1 for a simple illustration of the gaps.,1. Introduction,[0],[0]
"In Fig. 1, L[q] refers to the ELBO evaluated using an amortized distribution q, as is typical of VAE training.",1. Introduction,[0],[0]
"In contrast, L[q⇤] is the ELBO evaluated using the optimal approximation within its variational family.
",1. Introduction,[0],[0]
"There has been significant work on improving variational inference in VAEs through the development of expressive approximate posteriors (Rezende & Mohamed, 2015; Kingma et al., 2016; Ranganath et al., 2016; Tomczak & Welling, 2016; 2017).",1. Introduction,[0],[0]
"These works have shown that with more expressive approximate posteriors, the model learns a better distribution over the data.",1. Introduction,[0],[0]
"Our study aims to gain a better understanding of the relationship between expressive approximations and improved generative models.
",1. Introduction,[0],[0]
"Our experiments investigate how the choice of encoder, posterior approximation, decoder, and optimization affect the approximation and amortization gaps.",1. Introduction,[0],[0]
"We train VAE models in a number of settings on the MNIST (LeCun et al., 1998), Fashion-MNIST (Xiao et al., 2017), and CIFAR-10 (Krizhevsky & Hinton, 2009) datasets.
",1. Introduction,[0],[0]
"Our contributions are: a) we investigate inference suboptimality in terms of the approximation and amortization gaps, providing insight to guide future improvements in VAE inference, b) we quantitatively demonstrate that the learned generative model accommodates the choice of approximation, and c) we demonstrate that parameterized functions that improve the expressiveness of the approximation play a significant role in reducing amortization error.",1. Introduction,[0],[0]
"Let x be the observed variable, z the latent variable, and p(x, z) be their joint distribution.",2.1. Inference in Variational Autoencoders,[0],[0]
"Given a dataset X = {x1, x2, ..., xN}, we would like to maximize the marginal log-likelihood with respect to the model parameters ✓:
log p✓(X) = NX
i=1
log p✓(xi) = NX
i=1
log Z p✓(xi, zi)dzi.
",2.1. Inference in Variational Autoencoders,[0],[0]
"In practice, the marginal log-likelihood is computationally intractable due to the integration over the latent variable z. Instead, VAEs introduce an inference network q (z|x) to approximate the true posterior p(z|x) and optimize the ELBO with respect to model parameters ✓ and inference network parameters (parameterization subscripts omitted for brevity): log p(x) = Eq(z|x)  log ✓ p(x, z)
q(z|x)
◆ + KL (q(z|x)||p(z|x))
(1)
Eq(z|x)  ",2.1. Inference in Variational Autoencoders,[0],[0]
"log ✓ p(x, z)
q(z|x)
◆ = LVAE[q].",2.1. Inference in Variational Autoencoders,[0],[0]
"(2)
From the above equation, we see that the ELBO is tight when q(z|x) = p(z|x).",2.1. Inference in Variational Autoencoders,[0],[0]
The choice of q(z|x) is often a factorized Gaussian distribution for its simplicity and efficiency.,2.1. Inference in Variational Autoencoders,[0],[0]
"By utilizing the inference network (also referred to as encoder or recognition network), VAEs amortize inference over the entire dataset.",2.1. Inference in Variational Autoencoders,[0],[0]
"Furthermore, the overall model is trained by stochastically optimizing the ELBO using the reparametrization trick (Kingma & Welling, 2014).",2.1. Inference in Variational Autoencoders,[0],[0]
"There are a number of strategies for increasing the expressiveness of approximate posteriors, going beyond the original factorized-Gaussian.",2.2. Expressive Approximate Posteriors,[0],[0]
We briefly summarize normalizing flows and auxiliary variables.,2.2. Expressive Approximate Posteriors,[0],[0]
"Normalizing flow (Rezende & Mohamed, 2015) is a change of variables procedure for constructing complex distributions by transforming probability densities through a series of invertible mappings.",2.2.1. NORMALIZING FLOWS,[0],[0]
"Specifically, if we transform
a random variable z0 with distribution q0(z), the resulting random variable zT = T (z0) has a distribution:
qT (zT ) = q0(z0) det @zT @z0
1
.",2.2.1. NORMALIZING FLOWS,[0],[0]
"(3)
By successively applying these transformations, we can build arbitrarily complex distributions.",2.2.1. NORMALIZING FLOWS,[0],[0]
Stacking these transformations remains tractable due to the determinant being decomposable: det(AB) = det(A)det(B).,2.2.1. NORMALIZING FLOWS,[0],[0]
"An important property of these transformations is that we can take expectations with respect to the transformed density qT (zT ) without explicitly knowing its formula due to the law of the unconscious statistician (LOTUS):
EqT",2.2.1. NORMALIZING FLOWS,[0],[0]
[h(zT )],2.2.1. NORMALIZING FLOWS,[0],[0]
= Eq0,2.2.1. NORMALIZING FLOWS,[0],[0]
[h(fT (fT 1(...f1(z0))))].,2.2.1. NORMALIZING FLOWS,[0],[0]
"(4)
Using equations (3) and (4), the lower bound with the transformed approximation can be written as:
Ez0⇠q0(z|x)
2
64log
0
B@ p(x, zT )
q0(z0|x) QT
t=1 det @zt@zt 1 1
1
CA
3
75 .
(5)
",2.2.1. NORMALIZING FLOWS,[0],[0]
The main constraint on these transformations is that the determinant of their Jacobian needs to be easily computable.,2.2.1. NORMALIZING FLOWS,[0],[0]
Deep generative models can be extended with auxiliary variables which leave the generative model unchanged but make the variational distribution more expressive.,2.2.2. AUXILIARY VARIABLES,[0],[0]
"Just as hierarchical Bayesian models induce dependencies between data, hierarchical variational models can induce dependencies between latent variables.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"The addition of the auxiliary variable changes the lower bound to:
Ez,v⇠q(z,v|x)  log ✓ p(x, z)r(v|x, z)
q(z, v|x)
◆ (6)
= Eq(z|x)  log ✓ p(x, z)
q(z|x)
◆ KL ⇣ q(v|z, x)kr(v|x, z) ⌘
(7)
where r(v|x, z) is called the reverse model.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"From Eqn. 7, we see that this bound is looser than the regular ELBO,
however the extra flexibility provided by the auxiliary variable can result in a higher lower bound.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"This idea has been employed in works such as auxiliary deep generative models (ADGM, (Maaløe et al., 2016)), hierarchical variational models (HVM, (Ranganath et al., 2016)) and Hamiltonian variational inference (HVI, (Salimans et al., 2015)).",2.2.2. AUXILIARY VARIABLES,[0],[0]
The inference gap G is the difference between the marginal log-likelihood log p(x) and a lower bound L[q].,3.1. Approximation and Amortization Gaps,[0],[0]
"Given the distribution in the family that maximizes the bound, q⇤(z|x) = argmaxq2Q",3.1. Approximation and Amortization Gaps,[0],[0]
"L[q], the inference gap decomposes as the sum of approximation and amortization gaps:
G = log p(x) L[q] = log p(x) L[q⇤]| {z } Approximation +L[q⇤] L[q]| {z } Amortization .
",3.1. Approximation and Amortization Gaps,[0],[0]
"For VAEs, we can translate the gaps to KL divergences by rearranging Eqn.",3.1. Approximation and Amortization Gaps,[0],[0]
"(1):
GVAE = KL q⇤(z|x)||p(z|x)
",3.1. Approximation and Amortization Gaps,[0],[0]
"| {z }
Approximation
+ KL q(z|x)||p(z|x)
KL q⇤(z|x)||p(z|x)
| {z }
Amortization
.
(8)",3.1. Approximation and Amortization Gaps,[0],[0]
Our experiments involve expressive approximations which use flow transformations and auxiliary variables.,3.2. Flexible Approximate Posteriors,[0],[0]
"The flow transformation that we employ is of the same type as the transformations of Real NVP (Dinh et al., 2017).",3.2. Flexible Approximate Posteriors,[0],[0]
"We partition the latent variable z into two, z1 and z2, then perform the following transformations:
z01 = z1 1(z2) + µ1(z2) (9) z02 = z2 2(z01) + µ2(z01) (10)
where 1, 2, µ1, µ2 : Rn !",3.2. Flexible Approximate Posteriors,[0],[0]
Rn are differentiable mappings parameterized by neural nets and takes the Hadamard or element-wise product.,3.2. Flexible Approximate Posteriors,[0],[0]
We partition the latent variable by simply indexing the elements of the first half and the second half.,3.2. Flexible Approximate Posteriors,[0],[0]
"The determinant of the combined transformation’s Jacobian, det ⇣ @z0
@z ⌘ , can be easily evaluated.",3.2. Flexible Approximate Posteriors,[0],[0]
See section 7.3 of the Supplementary material for a derivation.,3.2. Flexible Approximate Posteriors,[0],[0]
The lower bound of this approximation is the same as Eqn.,3.2. Flexible Approximate Posteriors,[0],[0]
(5).,3.2. Flexible Approximate Posteriors,[0],[0]
"We refer to this approximation as qFlow.
",3.2. Flexible Approximate Posteriors,[0],[0]
We also experiment with an approximation that combines flow transformations and auxiliary variables.,3.2. Flexible Approximate Posteriors,[0],[0]
Let z 2 Rn be the variable of interest and v 2 Rn the auxiliary variable.,3.2. Flexible Approximate Posteriors,[0],[0]
"The flow is the same as equations (9) and (10), where z1 is
replaced with z and z2 with v.",3.2. Flexible Approximate Posteriors,[0],[0]
"We refer to this approximate distribution as qAF , where AF stands for auxiliary flow.",3.2. Flexible Approximate Posteriors,[0],[0]
"We train this model by optimizing the following bound:
Eq0(z,v|x)
2
64log
0
B@ p(x, zT )",3.2. Flexible Approximate Posteriors,[0],[0]
"r(vT |x, zT )
qT (zT , vT |x)",3.2. Flexible Approximate Posteriors,[0],[0]
"det
⇣ @ztvt
@zt 1vt 1
⌘ 1
1
CA
3
75
= L[qAF ].",3.2. Flexible Approximate Posteriors,[0],[0]
"(11)
Note that this lower bound is looser as explained in Section 2.2.2.",3.2. Flexible Approximate Posteriors,[0],[0]
We refer readers to Section 7.0.2 in the Supplementary material for specific details of the flow configuration adopted in the experiments.,3.2. Flexible Approximate Posteriors,[0],[0]
"In this section, we describe the estimates we use to compute the bounds of the inference gaps: log p(x), L[q⇤], and L[q].",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"We use two bounds to estimate the marginal log-likelihood, log p(x): IWAE (Burda et al., 2016) and AIS (Neal, 2001).
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
The IWAE bound takes multiple importance weighted samples from the variational q distribution resulting in a tighter lower bound than the VAE bound.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"The IWAE bound is computed as:
log p(x) Ez1...zk⇠q(z|x)
"" log 1
k
kX
i=1
p(x, zi) q(zi|x)
!",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"# (12)
= LIWAE[q].
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"As the number of importance samples approaches infinity, the bound approaches the marginal log-likelihood.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"It is often used as an evaluation metric for generative models (Burda et al., 2016; Kingma et al., 2016).",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
AIS is potentially an even tighter lower bound.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
AIS weights samples from distributions which are sequentially annealed from an initial proposal distribution to the true posterior.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
See Section 7.4 in the Supplementary material for further details regarding AIS.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"To compute the AIS bound, we use 100 chains, each with 10000 intermediate distributions, where each transition consists of one HMC trajectory with 10 leapfrog steps.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"The initial distribution for AIS is the prior, so that it is encoderindependent.
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"We estimate the marginal log-likelihood by independently computing our tightest lower bounds then take the maximum of the two:
log p̂(x) = max(LAIS,LIWAE).
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"The L[q⇤] and L[q] bounds are the standard ELBOs, LVAE, from Eqn.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"(2), computed with either the amortized q or the optimal q⇤ (see below).",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"When computing LVAE and LIWAE, we use 5000 samples.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"To compute LVAE[q⇤], we optimize the parameters of the variational distribution for every datapoint.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
"For the local optimization of qFFG, we initialize the mean and variance as the prior, i.e. N (0, I).",3.4. Local Optimization of the Approximate Distribution,[0],[0]
We optimize the mean and variance using the Adam optimizer with a learning rate of 10 3.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
"To determine convergence, after every 100 optimization steps, we compute the average of the previous 100 ELBO values and compare it to the best achieved average.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
If it does not improve for 10 consecutive iterations then the optimization is terminated.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
"For qFlow and qAF , the same process is used to optimize all of its parameters.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
"All neural nets for the flow were initialized with a variant of the Xavier initilization (Glorot & Bengio, 2010).",3.4. Local Optimization of the Approximate Distribution,[0],[0]
We use 100 Monte Carlo samples to compute the ELBO to reduce variance.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
The soundness of our empirical analysis depends on the reliability of the marginal log-likelihood estimator.,3.5. Validation of Bounds,[0],[0]
"For general importance sampling based estimators, the sample variance of the normalized importance weights can serve as an indicator of accuracy (Geweke, 1989; Neal, 2001).",3.5. Validation of Bounds,[0],[0]
"This quantitative measure, however, can also be unreliable, e.g. when the proposal misses an important mode of the target distribution (Neal, 2001).
",3.5. Validation of Bounds,[0],[0]
"In this work, we follow (Wu et al., 2017) to empirically validate our AIS estimates with Bidirectional Monte Carlo (BDMC, Grosse et al. (2015; 2016)).",3.5. Validation of Bounds,[0],[0]
"In addition to a lower bound provided by AIS, BDMC runs AIS chains backward from exact posterior samples to obtain an upper bound on the marginal log-likelihood.",3.5. Validation of Bounds,[0],[0]
It should be noted that BDMC relies on the assumption that the distribution of the simulated data from the model roughly matches that of the real data.,3.5. Validation of Bounds,[0],[0]
"This is due to the backward chain initializes from exact posterior samples (Grosse et al., 2015).
",3.5. Validation of Bounds,[0],[0]
"For the MNIST and Fashion datasets, BDMC gives a gap within 0.1 nat for a linear schedule AIS with 104 intermediate distributions and 100 importance samples on 103 simulated datapoints.",3.5. Validation of Bounds,[0],[0]
"For 3-BIT CIFAR, the same AIS setting gives a gap within 1 nat with the sigmoidial annealing schedule (Grosse et al., 2015) on 100 simulated datapoints.",3.5. Validation of Bounds,[0],[0]
"Loosely speaking, this should give us confidence in how well our AIS lower bounds reflect the marginal loglikelihood computed on the real data.",3.5. Validation of Bounds,[0],[0]
"Much of the earlier work on variational inference focused on optimizing the variational parameters locally for each datapoint, e.g. the original Stochastic Variational Inference scheme (SVI, Hoffman et al. (2013)).",4. Related Work,[0],[0]
"To scale inference to large datasets, most related works utilize inference networks to amortize the cost of inference over the entire dataset.
",4. Related Work,[0],[0]
"Our work analyses the error that these inference networks introduce.
",4. Related Work,[0],[0]
"Most relevant to our work is the recent work of Krishnan et al. (2017), which explicitly remarks on two sources of error in variational learning with inference networks, and proposes to optimize approximate inference locally from an initialization output by the inference network.",4. Related Work,[0],[0]
"They show improved training on high-dimensional, sparse data with the hybrid method, claiming that local optimization reduces the negative effects of random initialization in the inference network early on in training.",4. Related Work,[0],[0]
Thus their work focuses on reducing the amortization gap early on in training.,4. Related Work,[0],[0]
"Similar to this idea, Hoffman (2017) proposes to perform approximate inference during model training with MCMC at an initialization given by a variational distribution.",4. Related Work,[0],[0]
Our work provides a means of explaining these improvements in terms of the sources of inference suboptimality that they reduce.,4. Related Work,[0],[0]
"To begin, we would like to gain an intuitive visualization of the gaps presented in Section 3.1.",5.1. Intuition through Visualization,[0],[0]
"To this end, we trained a VAE with a two-dimensional latent space on MNIST and in Fig. 2 we show contour plots of various distributions in the latent space.",5.1. Intuition through Visualization,[0],[0]
The first row contains contour plots of the true posteriors p(z|x) for four different training datapoints (columns).,5.1. Intuition through Visualization,[0],[0]
We have selected these four examples to highlight different inference phenomena.,5.1. Intuition through Visualization,[0],[0]
"The amortized fully-factorized Gaussian (FFG) row refers to the output of the recognition net, in this case, a FFG approximation.",5.1. Intuition through Visualization,[0],[0]
Optimal FFG is the FFG that best fits the posterior of the datapoint.,5.1. Intuition through Visualization,[0],[0]
"Optimal Flow is the optimal fit of a flexible distribution to the same posterior, where the flexible distribution we use is described in Section 3.2.
",5.1. Intuition through Visualization,[0],[0]
Posterior A is an example of a distribution where a FFG can fit relatively well.,5.1. Intuition through Visualization,[0],[0]
"Posterior B is an example of a posterior with dependence between dimensions, demonstrating the
limitation of having a factorized approximation.",5.1. Intuition through Visualization,[0],[0]
"Posterior C highlights a shortcoming of performing amortization with a limited-capacity recognition network, where the amortized FFG shares little support with the true posterior.",5.1. Intuition through Visualization,[0],[0]
"Posterior D is a bi-modal distribution which demonstrates the ability of the flexible approximation to fit to complex distributions, in contrast to the simple FFG approximation.",5.1. Intuition through Visualization,[0],[0]
"These observations raise the following question: in more typical VAEs, is the amortization of inference the leading cause of the distribution mismatch, or is it the limited expressiveness of the approximation?",5.1. Intuition through Visualization,[0],[0]
"In this section, we compare how much the approximation and amortization gaps each contribute to the total inference gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"Table 2 are results of inference on the training set of MNIST, Fashion-MNIST and 3-BIT CIFAR (a binarized version of CIFAR-10, see Section 7.0.3 for details).",5.2. Amortization vs Approximation Gap,[0],[0]
"For each dataset, we trained models with two different approximate posterior distributions: a fully-factorized Gaussian, qFFG, and the flexible distribution, qAF .",5.2. Amortization vs Approximation Gap,[0],[0]
"Due to the computational cost of optimizing the local parameters for each datapoint, our evaluation is performed on a subset of 1000 datapoints for MNIST and Fashion-MNIST and a subset of 100 datapoints for 3-BIT CIFAR.
",5.2. Amortization vs Approximation Gap,[0],[0]
"For MNIST, we see that the amortization and approximation gaps each account for nearly half of the inference gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"On the more difficult Fashion-MNIST dataset, the amortization gap is larger than the approximation gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"For CIFAR, we see that the amortization gap is much more significant compared to the approximation gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"Thus, for the three datasets and model architectures that we consider, the amortization gap is likely to be the more prominent cause of inference suboptimality, especially when the dataset becomes more challenging to model.",5.2. Amortization vs Approximation Gap,[0],[0]
"This indicates that improvements in inference will likely be a result of reducing amortization error, rather than approximation errors.
",5.2. Amortization vs Approximation Gap,[0],[0]
"With these results in mind, would simply increasing the capacity of the encoder improve the amortization gap?",5.2. Amortization vs Approximation Gap,[0],[0]
"We
examined this by training the MNIST and Fashion-MNIST models from above but with larger encoders.",5.2. Amortization vs Approximation Gap,[0],[0]
See Section 7.0.2 for implementation details.,5.2. Amortization vs Approximation Gap,[0],[0]
Table 3 (left) are the results of this experiment.,5.2. Amortization vs Approximation Gap,[0],[0]
"Comparing to Table 2, we see that, for both datasets and both variational distributions, using a larger encoder results in the inference gap decreasing and the decrease is mainly due to a reduction in the amortization gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"The common reasoning for increasing the expressiveness of the approximate posterior is to minimize the difference between the true and approximate distributions, i.e. reduce the approximation gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"However, given that the expressive approximation is often accompanied by many additional parameters, we would like to know how much influence it has on the amortization error.
",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"To investigate this, we trained a VAE on MNIST, discarded the encoder, then retrained encoders with different approximate distributions on the fixed decoder.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
We fixed the decoder so that the true posterior is constant for all the retrained encoders.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
The initial encoder was a two-layer MLP with a factorized Gaussian distribution.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"In order to emphasize a large amortization gap, the retrained encoders had no hidden layers (ie. just linear transformations).",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"For the retraiend encoders, we tested three approximate distributions: fully factorized Gaussian (qFFG), auxiliary flow (qAV ), and Flow (qFlow).",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"See Section 3.2 for the details of these distributions.
",5.3. Influence of Flows on the Amortization Gap,[0],[0]
The inference gaps of the retrained encoders on the training set are shown in Table 4.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"As expected, we observe that the small encoder with qFFG has a very large amortization gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"However, when we use qAF or qFlow as the approximate distribution, we see the approximation gap decrease, but more importantly, there is a significant decrease in the amortization gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"This indicates that the parameters used for increasing the complexity of the approximation also play a large role in diminishing the amortization error.
",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"These results are expected given that the parameterization of the Flow distribution can be interpreted as an instance of the RevNet (Gomez et al., 2017) which has demonstrated that Real-NVP transformations (Dinh et al., 2017) can model complex functions similar to typical MLPs.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
Thus the flow transformations we employ should also be expected to increase the expressiveness while also increasing the capacity of the encoder.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"The implication of this observation is that models which improve the flexibility of their variational approximation, and attribute their improved results to the increased expressiveness, may have actually been due to the reduction in amortization error.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
To what extent does the posterior approximation affect the learned model?,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
Turner & Sahani (2011) studied the biases in parameter learning induced by the variational approximation when learning via variational Expectation-Maximization.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Similarly, we ask whether a factorized Gaussian approximation causes the true posterior to be more like a factorized Gaussian?",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Burda et al. (2016) visually demonstrate that when trained with an importance-weighted approximate posterior, the resulting true posterior is more complex than those trained with factorized Gaussian approximations.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Just as it is hard to evaluate a generative model by visually inspecting samples, it is hard to judge how “Gaussian” the true posterior is by visual inspection.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"We can quantitatively determine
how close the posterior is to a fully-factorized Gaussian (FFG) by comparing the marginal log-likelihood estimate log p̂(x) and the Optimal FFG bound LVAE[q⇤FFG].",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This is equivalent to estimating the KL divergence between the optimal Gaussian and the true posterior, KL (q⇤(z|x)||p(z|x)).
",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"In Table 2 on MNIST, for the FFG trained model, KL (q⇤(z|x)||p(z|x)) is nearly the same for both q⇤FFG and q⇤AF .",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"In contrast, on the model trained with qAF , KL (q⇤(z|x)||p(z|x)) is much larger for q⇤FFG than q⇤AF .",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
This suggests that the true posterior of a FFG-trained model is closer to FFG than the true posterior of the Flow-trained model.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
The same observation can be made on the FashionMNIST dataset.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This implies that the decoder can learn to have a true posterior that fits better to the approximation.
",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
These observations justify our results of Section 5.2.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
which showed that the amortization error is often the main cause of inference suboptimality.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"One reason for this is that the generator accommodates the choice of approximation, thus reducing the approximation error.
",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Given that we have seen that the generator can accommodate the choice of approximation, our next question is whether a generator with more capacity increases its ability to fit to the approximation.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"To this end, we trained VAEs with decoders of different sizes and measured the approximation gaps on
the training set.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Specifically, we trained decoders with 0, 2, and 4 hidden layers on MNIST.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
See Table 5 for the results.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"We see that as the capacity of the decoder increases, the approximation gap decreases.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This result implies that the more flexible the generator is, the less flexible the approximate distribution needs to be to ensure accurate inference.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
How well does amortized inference generalize at test time?,5.5. Inference Generalization,[0],[0]
We address this question by visualizing the gaps on training and validation datapoints across the training epochs.,5.5. Inference Generalization,[0],[0]
"In Fig. 3, the models are trained on 50000 binarized FashionMNIST datapoints and the gaps are computed on a subset of a 100 training and validation datapoints.",5.5. Inference Generalization,[0],[0]
The top and bottom boundaries of the blue region represent log p̂(x) and L[q⇤].,5.5. Inference Generalization,[0],[0]
The bottom boundary of the orange region represents L[q].,5.5. Inference Generalization,[0],[0]
"In other words, the blue region is the approximation gap and the orange is the amortization gap.
",5.5. Inference Generalization,[0],[0]
"In Fig. 3, the Standard model (top left) refers to a VAE of latent size 20 trained with a factorized Gaussian approximate posterior.",5.5. Inference Generalization,[0],[0]
"In this case, the encoder and decoder both have two hidden layers each consisting of 200 hidden units.",5.5. Inference Generalization,[0],[0]
The Flow model (top right) augments the Standard model with a qFlow variational distribution.,5.5. Inference Generalization,[0],[0]
"Larger Decoder and Larger Encoder models have factorized Gaussian distributions and increase the number of hidden layers to three and the number of units in each layer to 500.
",5.5. Inference Generalization,[0],[0]
"Firstly, we observe that for all models, the approximation gap on the training and validation sets are roughly equivalent.",5.5. Inference Generalization,[0],[0]
This indicates that the true posteriors of the held-out data are similar to that of the training data.,5.5. Inference Generalization,[0],[0]
"Secondly, we note that for all models, the encoder overfits more than the decoder.
",5.5. Inference Generalization,[0],[0]
"These observations resonate with the encoder overfitting findings by Wu et al. (2017).
",5.5. Inference Generalization,[0],[0]
How does increasing decoder capacity affect inference on held-out data?,5.5. Inference Generalization,[0],[0]
We know from Section 5.4 that increasing generator capacity results in a posterior that better fits the approximation making posterior inference easier.,5.5. Inference Generalization,[0],[0]
"Furthermore, the Larger Decoder plot of Fig. 3 shows that increasing generator capacity causes the model to be more prone to overfitting.",5.5. Inference Generalization,[0],[0]
"Thus, there is a tradeoff between ease of inference and decoder overfitting.",5.5. Inference Generalization,[0],[0]
We have seen in Sections 5.2 and 5.3 that expressive approximations as well as increasing encoder capacity can lead to a reduction in the amortization gap.,5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
This leads us to the following question: when should we increase encoder capacity versus increasing the expressiveness of the approximation?,5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"We answer this question in terms of how well each model can generalize its efficient inference (recognition network and variational distribution) to held-out data.
",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"In Fig. 3, we see that the Flow model and the Larger Encoder model achieve similar log p̂(x) on the validation set at the end of training.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"However, we see that the L[q] bound of the Larger Encoder model is significantly lower than the L[q] bound of the Flow model due to the encoder overfitting to the training data.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Although they both model the data nearly equally well, the recognition net of the Larger Encoder model is no longer suitable to perform inference on the held-out data due to overfitting.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Thus a potential rational for utilizing expressive approximations is that they improve generalization to held-out data in comparison to increasing the encoder capacity.
",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"We highlight that, in many scenarios, efficient test time inference is not required and consequently, encoder overfitting is not an issue, since we can use non-efficient encoderindependent methods to estimate log p(x), such as AIS, IWAE with local optimization, or potentially retraining the encoder on the held-out data.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"In contrast, when efficient test time inference is required, encoder generalization is important and expressive approximations are likely advantageous.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Typical warm-up (Bowman et al., 2015; Sønderby et al., 2016) refers to annealing the KL (q(z|x)||p(z)) term during training.",5.6. Annealing the Entropy,[0],[0]
This can also be interpreted as performing maximum likelihood estimation (MLE) early on during training.,5.6. Annealing the Entropy,[0],[0]
"This optimization technique is known to help prevent the latent variable from degrading to the prior (Burda et al., 2016; Sønderby et al., 2016).",5.6. Annealing the Entropy,[0],[0]
"We employ a similar annealing scheme during training by annealing the entropy of the
approximate distribution:
Ez⇠q(z|x) [log p(x, z) log q(z|x)] ,
where is annealed from 0 to 1 over training.",5.6. Annealing the Entropy,[0],[0]
"This can be interpreted as maximum a posteriori (MAP) in the initial phase of training.
",5.6. Annealing the Entropy,[0],[0]
"We find that warm-up techniques, such as annealing the entropy, are important for allowing the true posterior to be more complex.",5.6. Annealing the Entropy,[0],[0]
Table 3 (right) are results from a model trained without the entropy annealing schedule.,5.6. Annealing the Entropy,[0],[0]
"Comparing these results to Table 2, we observe that the difference between LVAE[q⇤FFG] and LVAE[q⇤AF ] is significantly smaller without entropy annealing.",5.6. Annealing the Entropy,[0],[0]
This indicates that the true posterior is more Gaussian when entropy annealing is not used.,5.6. Annealing the Entropy,[0],[0]
"This suggests that, in addition to preventing the latent variable from degrading to the prior, entropy annealing allows the true posterior to better utilize the flexibility of the expressive approximation.",5.6. Annealing the Entropy,[0],[0]
"In this paper, we investigated how encoder capacity, approximation choice, decoder capacity, and model optimization influence inference suboptimality in terms of the approximation and amortization gaps.",6. Conclusion,[0],[0]
We discovered that the amortization gap can be a leading source to inference suboptimality and that the generator can reduce the approximation gap by learning a true posterior that fits to the choice of approximation.,6. Conclusion,[0],[0]
We showed that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.,6. Conclusion,[0],[0]
We confirmed that increasing the capacity of the encoder reduces the amortization error.,6. Conclusion,[0],[0]
"Additionally, we demonstrated that optimization techniques, such as entropy annealing, help the generative model to better utilize the flexibility of expressive variational distributions.",6. Conclusion,[0],[0]
Analyzing these gaps can be useful for guiding improvements in VAEs.,6. Conclusion,[0],[0]
"Future work includes evaluating other types of expressive approximations, more complex likelihood functions, and datasets.",6. Conclusion,[0],[0]
Amortized inference allows latent-variable models trained via variational learning to scale to large datasets.,abstractText,[0],[0]
The quality of approximate inference is determined by two factors: a) the capacity of the variational distribution to match the true posterior and b) the ability of the recognition network to produce good variational parameters for each datapoint.,abstractText,[0],[0]
We examine approximate inference in variational autoencoders in terms of these factors.,abstractText,[0],[0]
"We find that divergence from the true posterior is often due to imperfect recognition networks, rather than the limited complexity of the approximating distribution.",abstractText,[0],[0]
We show that this is due partly to the generator learning to accommodate the choice of approximation.,abstractText,[0],[0]
"Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.",abstractText,[0],[0]
Inference Suboptimality in Variational Autoencoders,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 167–171 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2026",text,[0],[0]
"Continuous word representations, derived from unlabeled text, have proven useful in many NLP tasks.",1 Introduction,[0],[0]
"Such word representations (or embeddings) associate a low-dimensional, real-valued vector with each word, typically induced via neural language models or matrix factorization.
",1 Introduction,[0],[0]
Substantial benefit arises when embeddings can be efficiently trained on large volumes of data.,1 Introduction,[0],[0]
"Hence the recent considerable interest in the continuous bag-of-words (CBOW) and skip-gram with negative sampling (SGNS) models, described in (Mikolov et al., 2013), as implemented in the opensource toolkit word2vec.",1 Introduction,[0],[0]
These models are based on a relatively simple log-linear method and avoid hidden layers typical to neural networks.,1 Introduction,[0],[0]
"Consequently, they can be trained to produce high-quality word embeddings on large corpora like the entirety of English Wikipedia in several hours, compared to days or even weeks in the case of other continuous models.",1 Introduction,[0],[0]
"Recent studies obtained state-of-the-art results by using skip-gram embeddings on a variety of natural language processing tasks, such as named entity extraction (Passos et al., 2014)
and dependency parsing (Bansal et al., 2014).",1 Introduction,[0],[0]
"In recent years, there were several attempts to mathematically interpret word embedding models (Arora et al., 2016; Pennington et al., 2014; Stratos et al., 2015).",1 Introduction,[0],[0]
"Our study pursues this established line of work, attempting to explain the objective function of the SGNS word embedding algorithm.
",1 Introduction,[0],[0]
"In the SGNS model, the energy function takes the form of a dot product between the vectors of an observed word and an observed context.",1 Introduction,[0],[0]
"The objective function is a binary logistic regression classifier that treats a word and its observed context as a positive example, and a word and a randomly sampled context as a negative example.",1 Introduction,[0],[0]
Levy and Goldberg (2014) offered a motivation for this function by showing that it obtains its global maximum value at the word-context pointwise mutual information (PMI) matrix.,1 Introduction,[0],[0]
"In this study, we take their analysis one step further and provide an informationtheoretical interpretation of the SGNS objective function.",1 Introduction,[0],[0]
"In Section 2, we define a new measure of mutual information between random variables based the Jensen-Shennon divergence (Lin, 1991) instead of the KL divergence.",1 Introduction,[0],[0]
"In Section 3, we show that the value of the SGNS objective computed at the PMI matrix is this information measure.",1 Introduction,[0],[0]
We then derive an explicit expression for the information loss caused by the low-dimensional embedding learned by the SGNS algorithm.,1 Introduction,[0],[0]
"Finally, in Section 4, we illustrate this by computing the information loss caused by actual SGNS embeddings learned on a standard text corpus.",1 Introduction,[0],[0]
"In this section, we define a dependency measure between two random variables, which is based on the Jensen-Shannon divergence.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"Later, in Section 3, we show how it relates to the SGNS objective function.
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"167
There are several standard methods of measuring the distance between two discrete probability distributions, defined on a given finite set A.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
The Kullback-Leibler (KL) divergence of a distribution p from a distribution q is defined as follows: KL(p||q) =∑i∈A pi log piqi .,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"The mutual information between two jointly distributed random variables X and Y is defined as the KL divergence of the joint distribution p(x, y) from the product p(x)p(y) of the marginal distributions of X and Y, i.e. I(X;Y ) = KL(p(x, y)||p(x)p(y)).
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"The Jensen-Shannon (JS) divergence (Lin, 1991) between distributions p and q is:
JSα(p, q) =αKL(p||r) + (1−α)KL(q||r) (1)
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
= H(r)− αH(p)− (1−α)H(q) such that 0,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"< α < 1, r = αp+ (1− α)q and H is the entropy function (i.e. H(p) =",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
−∑i pi log pi).,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"Unlike KL divergence, JS divergence is bounded from above and 0 ≤ JSα(p, q) ≤ 1.
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"We next propose a new measure for mutualinformation using the JS-divergence between p(x, y) and p(x)p(y) instead of the KL-divergence.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"We define the Jensen-Shannon Mutual information (JSMI) as follows:
JSMIα(X,Y ) = JSα(p(x, y), p(x)p(y)).",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"(2)
It can be easily verified that X and Y are independent if and only if JSMIα(X,Y ) = 0.
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
We next derive an alternative definition of the JSMI dependency measure.,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"Assume we choose between the two distributions, p(x, y) and the product of marginal distributions p(x)p(y), according to a binary random variableZ, such that p(Z = 1) = α.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"We first sample a binary value for Z and next, we sample a r.v.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"W as follows:
p(W =(x, y)|Z)= { p(x)p(y) if Z=0 p(x, y) if Z=1.
(3) The divergence measure JSMIα(X,Y ) can be alternatively defined in terms of mutual information between W and Z. The mutual-information between W and Z is:
I(W;Z) = H(W )",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"− ∑
i=0,1
p(Z=",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
i)H(W |Z=,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"i)
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"= H(αp(x, y) + (1−α)p(x)p(y))
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"−αH(p(x, y))− (1−α)H(p(x)p(y)).
",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"Eq. (1) thus implies that:
JSMIα(X,Y ) = I(W ;Z).",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"(4)
Applying Bayes rule we obtain:
p(Z=1|W =(x, y)) (5)
= αp(x, y)
αp(x, y) + (1−α)p(x)p(y)
= 1
1 + exp(− log( αp(x,y)(1−α)p(x)p(y)))",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"= σ(pmix,y)
such that σ(u) = 11+exp(−u) is the sigmoid function and
pmix,y = log p(x, y)
p(x)p(y) + log
α
1−α (6)
is a shifted version of the PMI function.",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"Equations (4) and (5) imply that:
JSMIα(X,Y ) = H(Z)−H(Z|W ) (7)
= h(α)+α ∑
x,y
p(x, y) log σ(pmix,y)
+(1−α) ∑
x,y
p(x)p(y) log σ(−pmix,y)
such that h(α) = −α log(α)",2 A Dependency Measure based on Jensen-Shannon,[0],[0]
− (1−α) log(1−α) is the binary entropy function.,2 A Dependency Measure based on Jensen-Shannon,[0],[0]
"The SGNS embedding algorithm (Mikolov et al., 2013) represents each word x and each context y as d-dimensional vectors ~x and ~y, with the purpose that words that are “similar” to each other will have similar vector representations.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"We can represent a given d-dimensional embedding by a matrix m, such that m(x, y) = ~x · ~y.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The rank of the embedding matrix m is (at most) d.
Let p(x, y) be the normalized number of cooccurrences of word x and context-word y in a given corpus and let p(x) and p(y) be the corresponding unigram distributions.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Consider a binary classifier that treats a word and its observed context as a positive example, and a word and a randomly sampled context as a negative example.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The classification is made based on the embedding in such a way that the probability that (x, y) is a positive example is σ(~x · ~y).",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The objective function ideally maximized by the SGNS word embedding
algorithm is the expectation of the log-likelihood function of the embedding:
S(m) = h( 1
k+1 )",3 The Skip-Gram Embedding Algorithm,[0],[0]
"+
1
k+1
∑
x,y
p(x, y) log σ(~x · ~y)
+ k
k+1
∑
x,y
p(x)p(y) log σ(−~x · ~y).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"(8) Note that the term h( 1k+1), which does not appear in the original SGNS objective function (Mikolov et al., 2013), is a constant number that was added here to simplify the following presentation.
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The sparsity of p(x, y) (which is obtained as normalized counts from a given learning corpus) makes it feasible to compute the second term of (8).",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The number of summed-over elements in the third term of (8), however, is quadratic in the size of the vocabulary, making it hard to compute.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Therefore, in practice, we can approximate the expectation by sampling of ‘negative’ examples.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The actual SGNS score, then, is:
S(m)",3 The Skip-Gram Embedding Algorithm,[0],[0]
≈ h( 1 k+1 ),3 The Skip-Gram Embedding Algorithm,[0],[0]
"+ 1 k+1 · 1 n
n∑
t=1
(log σ(~xt · ~yt)
+
k∑
i=1
log σ(−~xt · ~yti)).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
(9) such that t goes over all the word-context pairs in a given corpus.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"The negative examples yti are created for each pair (xt, yt) by drawing k random contexts from the context-word distribution p(y).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"As pointed out in (Levy et al., 2015), k has two distinct functions in the SGNS objective function.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"First, it is used to better estimate the distribution of negative examples.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Second, it is used as a weight on the probability of observing a positive example versus a negative example; a higher k means that negative examples are more probable.
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"We can compute the SGNS score function S(m) for every real-valued matrix m = (mx,y).",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Levy and Goldberg (2014) showed that the function achieves its global maximal value when for each word-pair (x, y) the inner product of the embedding vectors ~x · ~y is equal to pmi(x, y).",3 The Skip-Gram Embedding Algorithm,[0],[0]
"In other words they showed that S(m) ≤ S(pmi) for every matrix m. We next show that the value of the function S(m) at its maximum point, the PMI matrix, has a concrete interpretation, namely it is exactly the Jensen-Shannon Mutual Information (JSMI) between words and their contexts.
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Theorem 1: The value of the SGNS score with k negative samples (8) at the PMI matrix satisfies:
S(pmi) = JSMIα(X,Y )
such that α = 1k+1 .",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Proof: It can be easily verified that by substituting α = 1k+1 in the definition of JSMI (Eq. (7)), we exactly obtain the SGNS score (8) at the PMI matrix.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"2
Levy and Goldberg (2014) showed that SGNS’s objective achieves its maximal value at the PMI matrix.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"However, this result reveals nothing about the more interesting lower dimensional case, where the PMI matrix factorization is forced to compress the joint distribution and thereby learn a meaningful embedding.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"We next derive an explicit description of the approximation criterion that quantifies the gap between S(m) and S(pmi).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Given the word co-occurrences joint distribution p(x, y), we obtained in Eq.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"(5) a conditional distribution on the alphabet of (Z,W ) as follows:
p(Z=1|W =(x, y))",3 The Skip-Gram Embedding Algorithm,[0],[0]
"= σ(pmix,y).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"In a similar way, given any matrixm, we can define a conditional distribution pm on the alphabet of (Z,W ) as follows:
pm(Z=1|W =(x, y))",3 The Skip-Gram Embedding Algorithm,[0],[0]
"= σ(mx,y).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Note that in the special case where m is the PMI matrix, ppmi(z|w) coincides with the original p(z|w) that was defined in Eq.",3 The Skip-Gram Embedding Algorithm,[0],[0]
(5).,3 The Skip-Gram Embedding Algorithm,[0],[0]
Theorem 2:,3 The Skip-Gram Embedding Algorithm,[0],[0]
"The difference between the SGNS score at the PMI matrix and the SGNS score at a given matrix m can be written as:
S(pmi)− S(m) = KL(ppmi(Z|W )||pm(Z|W ))",3 The Skip-Gram Embedding Algorithm,[0],[0]
"(10) Proof:
S(pmi)−S(m) = ∑
x,y
(αp(x, y) log σ(pmix,y) σ(mx,y)
+(1−α)p(x)p(y) log σ(−pmix,y) σ(−mx,y) )
= ∑
x,y
(αp(x, y) log ppmi(Z=1|x, y) pm(Z=1|x, y)
+(1−α)p(x)p(y) log ppmi(Z=0|x, y) pm(Z=0|x, y) )
= ∑
w,z
p(W =w,Z=z) log ppmi(Z=z|W =w) pm(Z=z|W =w)
= KL(ppmi(Z|W )||pm(Z|W )).2",3 The Skip-Gram Embedding Algorithm,[0],[0]
The KL divergence between two distributions is always non-negative and is zero only if the two distributions are the same.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"Therefore, we rederive the results of (Levy and Goldberg, 2014) that S(pmi) = maxm S(m).",3 The Skip-Gram Embedding Algorithm,[0],[0]
Theorem 2 can be viewed as an instance of the well-known connection between maximizing log-likelihood and minimizing KL divergence between the estimated and the true data-generating distribution.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"In this case, the true distribution is the pmi-based classifier ppmi(Z|W ).
",3 The Skip-Gram Embedding Algorithm,[0],[0]
"Combining theorems 1 and 2 we obtain that S(m) ≤ JSMIα(X,Y ) for every low-dimensional embedding matrix.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The difference JSMIα(X,Y )",3 The Skip-Gram Embedding Algorithm,[0],[0]
− S(m) is the information loss caused by the lowdimensional embedding.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"We can view it as a Jensen-Shannon variant of the information bottleneck principle (Tishby et al., 1999; Globerson et al., 2007) that is defined in terms of the KL divergence.",3 The Skip-Gram Embedding Algorithm,[0],[0]
"The optimal d-dimensional embedding, is the best d-dimensional approximation of the JSMI dependency measure in the sense that it minimizes the information loss.",3 The Skip-Gram Embedding Algorithm,[0],[0]
The JSMI is the upper bound that any embedding can obtain.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"To illustrate that, in the next section we compute the JSMI between words and their contexts based on a standard text corpus and show the information gap between the JSMI and the actual SGNS score as a function of the embedding dimension d.
From Theorem 2 we can also derive an explicit information-theoretic interpretation of the score function S(m) (7) as the difference between two KL-divergence terms:
S(m) = S(pmi)− (S(pmi)− S(m))",3 The Skip-Gram Embedding Algorithm,[0],[0]
"=
I(Z;W )",3 The Skip-Gram Embedding Algorithm,[0],[0]
− (S(pmi)− S(m)),3 The Skip-Gram Embedding Algorithm,[0],[0]
"= KL(p(Z|W )||p(Z))− KL(p(Z|W )||pm(Z|W ))
",3 The Skip-Gram Embedding Algorithm,[0],[0]
The word embedding problem can be also viewed as a factorization of the PMI matrix.,3 The Skip-Gram Embedding Algorithm,[0],[0]
"Previous works suggested other criteria for matrix factorization such as least-squares (Eckart and Young, 1936) and KL-divergence between the original matrix and the low-rank matrix approximation (Lee and Seung, 2000).",3 The Skip-Gram Embedding Algorithm,[0],[0]
We have shown that the SGNS algorithm factorizes the PMI matrix based on the JSMI-based criterion stated in Eq. (10).,3 The Skip-Gram Embedding Algorithm,[0],[0]
In this section we use word2vec to train real skipgram with negative sampling (SGNS) embedding models.,4 Experiments,[0],[0]
"By measuring the value of their objective function and comparing it against the optimal one using exact PMI values, we demonstrate how a well-trained model minimizes the difference in Eq.",4 Experiments,[0],[0]
(10).,4 Experiments,[0],[0]
"We note that this is an intrinsic measure that does not necessarily reflect the usefulness of the learned embeddings for other tasks.
",4 Experiments,[0],[0]
"We used the Penn Tree Bank (PTB), a popular small-scale corpus, for our experiments.",4 Experiments,[0],[0]
"A version of this dataset is available from Tomas Mikolov.1 It consists of 929K training words with a 10K word vocabulary, which we used to train our models.",4 Experiments,[0],[0]
"To learn the SGNS word embeddings, we used word2vec’s default parameter values: windowsize = 5, min-count = 5, and number of negative samples k = 5.",4 Experiments,[0],[0]
We varied the dimensionality of the embeddings and the number of training iterations performed.,4 Experiments,[0],[0]
"Once the models were trained, we measured their score (9) on the training corpus.
",4 Experiments,[0],[0]
"Based on the same learning corpus, we computed S(pmi) = JSMIα(X,Y ) for α = 1k+1 = 1/6.",4 Experiments,[0],[0]
"Note that p(x, y) = 0 implies that pmix,y = −∞ and therefore log σ(−pmix,y) = 0.",4 Experiments,[0],[0]
"Hence, as in the second term, to compute the third term of S(m) (8) for the case of m = pmi, we can sum only
1http://www.fit.vutbr.cz/~imikolov/ rnnlm/simple-examples.tgz
over the positive pairs (x, y) that actually appear in the corpus.2",4 Experiments,[0],[0]
"In other words, for the special case m = pmi, it is feasible to compute the exact score (8) and not just its approximation (9) that is based on negative sampling.",4 Experiments,[0],[0]
"Figure 1 illustrates the optimal PMI-based score, compared with the scores obtained by different models with varied embedding dimensionality and number of training iterations.",4 Experiments,[0],[0]
"As can be seen, the embeddings score gets close to the optimal value using higher dimensionality and more training iterations, but doesn’t surpass it.",4 Experiments,[0],[0]
"In this study, we developed a new correlation measure between random variables, denoted JSMI.",5 Conclusion,[0],[0]
This measure is based on the JS divergence and differs from the standard mutual information measure that is based on the KL divergence.,5 Conclusion,[0],[0]
We showed that the optimization of skip-gram embeddings with negative sampling finds the best low-dimensional approximation of the JSMI measure.,5 Conclusion,[0],[0]
"Thus, we provided an information theory framework that hopefully contributes to a better understanding of this embedding algorithm.",5 Conclusion,[0],[0]
"Furthermore, although we focused here on the case of word-context joint distributions, the connection we haven shown between the PMI matrix and the JSMI function is valid for every joint distribution of two random variables.",5 Conclusion,[0],[0]
This work is supported by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI).,Acknowledgments,[0],[0]
"In this paper, we define a measure of dependency between two random variables, based on the Jensen-Shannon (JS) divergence between their joint distribution and the product of their marginal distributions.",abstractText,[0],[0]
"Then, we show that word2vec’s skip-gram with negative sampling embedding algorithm finds the optimal low-dimensional approximation of this JS dependency measure between the words and their contexts.",abstractText,[0],[0]
The gap between the optimal score and the low-dimensional approximation is demonstrated on a standard text corpus.,abstractText,[0],[0]
Information-Theory Interpretation of the Skip-Gram Negative-Sampling Objective Function,title,[0],[0]
"Principal Component Analysis (PCA) is a popular and efficient procedure to approximate the data with a single low dimensional subspace (Lerman et al., 2015).",1. Introduction,[0],[0]
"Nonetheless, in numerous contemporary applications the data points may originate from multiple independent sources, in which case a union of subspaces can better model the data (Vidal, 2011).",1. Introduction,[0],[0]
"The problem of subspace clustering is concerned with learning these low-dimensional subspaces and clustering the data points to their respective subspaces, generally without prior knowledge about the number of subspaces and their dimensions, nor the membership of the data points
1University of Central Florida, Orlando, Florida, USA.",1. Introduction,[0],[0]
"Correspondence to: Mostafa Rahmani <mostafa@knights.ucf.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
to these subspaces.",1. Introduction,[0],[0]
"Subspace clustering naturally arises in many machine learning and data analysis problems, including computer vision (e.g. motion segmentation (Vidal et al., 2008), face clustering (Ho et al., 2003)), image processing (Yang et al., 2008) and system identification (Vidal et al., 2003).",1. Introduction,[0],[0]
"Numerous approaches for subspace clustering have been studied in prior work, including statistical-based approaches (Yang et al., 2006; Rao et al., 2010), spectral clustering (Soltanolkotabi et al., 2012; Von Luxburg, 2007; Dyer et al., 2013; Elhamifar & Vidal, 2013; Heckel & Bölcskei, 2013; Liu et al., 2013; Chen & Lerman, 2009), the algebraic-geometric approach (Vidal et al., 2005) and iterative methods (Bradley & Mangasarian, 2000).",1. Introduction,[0],[0]
"We refer the reader to (Vidal, 2011) for a comprehensive survey on the topic.
",1. Introduction,[0],[0]
This paper aims to advance the state-of-the-art research on subspace clustering on several fronts.,1. Introduction,[0],[0]
"First, the proposed approach – termed iPursuit – rests on a novel geometrical idea whereby one subspace is identified at a time based on its novelty with respect to (w.r.t.)",1. Introduction,[0],[0]
the other subspaces.,1. Introduction,[0],[0]
"Second, the proposed method is a provable and scalable subspace clustering algorithm – the computational complexity of iPursuit only scales linearly in the number of subspaces and quadratically in their dimensions (c.f. Section 2.5).",1. Introduction,[0],[0]
"In contrast to the spectral-clustering-based algorithms such as (Dyer et al., 2013; Elhamifar & Vidal, 2013; Liu et al., 2013), which need to solve an M22 -dimensional optimization problem to build the similarity matrix (where M2 is the number of data points), the proposed method requires solving few M2-dimensional linear optimization problems.",1. Introduction,[0],[0]
This feature makes iPursuit remarkably faster than the state-of-the-art algorithms.,1. Introduction,[0],[0]
"Third, innovation pursuit in the data span enables superior performance when the subspaces have considerable intersections in comparison to the state-of-the-art subspace clustering algorithms.",1. Introduction,[0],[0]
"Given a matrix A, ‖A‖ denotes its spectral norm.",1.1. Notation and definitions,[0],[0]
"For a vector a, ‖a‖ denotes its `2-norm and ‖a‖1 its `1-norm.",1.1. Notation and definitions,[0],[0]
"Given matrices {Ai}ni=1 with equal number of rows, we use the union symbol ∪ to define the matrix
n ∪ i=1",1.1. Notation and definitions,[0],[0]
"Ai :=
[A1 A2 ...",1.1. Notation and definitions,[0],[0]
An] as the concatenation of the matrices {Ai}ni=1.,1.1. Notation and definitions,[0],[0]
"For a matrix D, we overload the set member-
ship operator by using the notation d ∈ D to signify that d is a column of D. A collection of subspaces {Gi}ni=1 is said to be independent if dim ( n ⊕ i=1",1.1. Notation and definitions,[0],[0]
Gi ),1.1. Notation and definitions,[0],[0]
=,1.1. Notation and definitions,[0],[0]
∑n i=1,1.1. Notation and definitions,[0],[0]
"dim(Gi), where ⊕ denotes the direct sum operator and dim(Gi) is the dimension of Gi.",1.1. Notation and definitions,[0],[0]
"Given a vector a,
∣∣a| is the vector of absolute values of the elements of a. For a real number a, sgn(a) denotes the sign of a. The complement of a set L is denoted Lc.",1.1. Notation and definitions,[0],[0]
"For any positive integer n, the index set {1, . . .",1.1. Notation and definitions,[0],[0]
", n} is denoted [n].
",1.1. Notation and definitions,[0],[0]
"Consider two subspaces S1 and S2, such that S2 6⊆ S1 and S1 6⊆ S2.",1.1. Notation and definitions,[0],[0]
This means that each of the subspaces S1 and S2 carries some innovation w.r.t.,1.1. Notation and definitions,[0],[0]
the other.,1.1. Notation and definitions,[0],[0]
"As such, corresponding to each subspace we define an innovation subspace capturing its novelty (innovation) w.r.t.",1.1. Notation and definitions,[0],[0]
"the other subspaces, defined formally as follows.
",1.1. Notation and definitions,[0],[0]
Definition 1.,1.1. Notation and definitions,[0],[0]
"Assume that V1 and V2 are two orthonormal bases for S1 and S2, respectively.",1.1. Notation and definitions,[0],[0]
"We define the innovation subspace of S2 over S1, denoted I (S2 ⊥ S1), as the subspace spanned by ( I−V1VT1 ) V2.",1.1. Notation and definitions,[0],[0]
"In other words, I (S2 ⊥ S1) is the complement of S1 in the subspace S1 ⊕ S2.
",1.1. Notation and definitions,[0],[0]
"Similarly, we can also define I (S1 ⊥ S2) as the innovation subspace of S1 over S2.",1.1. Notation and definitions,[0],[0]
Fig. 1 illustrates a scenario in which the data lies in a union of a two-dimensional and a one-dimensional subspace.,1.1. Notation and definitions,[0],[0]
Note that the innovation subspace of S2 over S1 is orthogonal to S1 and is the complement of S1 in S1 ⊕ S2.,1.1. Notation and definitions,[0],[0]
"In this section, the main geometrical idea underlying iPursuit is first presented.",2. Proposed Approach,[0],[0]
This idea is based on a non-convex `0-norm minimization problem searching for a direction of innovation in the span of the data.,2. Proposed Approach,[0],[0]
"Then, we provide a convex relaxation to a linear optimization problem, whose solution is shown to yield the correct subspaces under mild sufficient conditions.",2. Proposed Approach,[0],[0]
"Due to space limitations, the proofs of all the theoretical results are deferred to an extended version of this paper (Rahmani & Atia, 2015).",2. Proposed Approach,[0],[0]
"It is assumed
that the given data matrix follows the following data model.
",2. Proposed Approach,[0],[0]
Data Model 1.,2. Proposed Approach,[0],[0]
The data matrix D ∈ RM1×M2 can be represented as D =,2. Proposed Approach,[0],[0]
"[D1 ...DN ]T, where T is an arbitrary permutation matrix.",2. Proposed Approach,[0],[0]
"The columns of Di ∈ RM1×ni lie in Si, where Si is an ri-dimensional linear subspace, for 1 ≤ i ≤ N , and, ∑N i=1 ni = M2.",2. Proposed Approach,[0],[0]
Define Vi as an orthonormal basis for Si.,2. Proposed Approach,[0],[0]
"In addition, define D as the space spanned by the data, i.e., D =
N ⊕ i=1",2. Proposed Approach,[0],[0]
Si.,2. Proposed Approach,[0],[0]
"Moreover,
it is assumed that every subspace in the set of subspaces {Si}Ni=1 has an innovation over the other subspaces, to say that, for 1 ≤ i ≤ N , the subspace Si does not completely lie in
N ⊕ k=1 k 6=i Sk .",2. Proposed Approach,[0],[0]
"In addition, the columns of D are
normalized, i.e., each column has an `2-norm equal to one.",2. Proposed Approach,[0],[0]
iPursuit is a multi-step algorithm that identifies one subspace at a time.,2.1. iPursuit: Basic idea,[0],[0]
"In each step, the data is clustered into two subspaces.",2.1. iPursuit: Basic idea,[0],[0]
One subspace is the identified subspace and the other one is the direct sum of the other subspaces.,2.1. iPursuit: Basic idea,[0],[0]
The data points of the identified subspace are removed and the algorithm is applied to the remaining data to find the next subspace.,2.1. iPursuit: Basic idea,[0],[0]
"Accordingly, each step of the algorithm can be interpreted as a subspace clustering problem with two subspaces.",2.1. iPursuit: Basic idea,[0],[0]
"Therefore, for ease of exposition we first investigate the two-subspace scenario then extend the result to multiple (more than two) subspaces.",2.1. iPursuit: Basic idea,[0],[0]
"Thus, in this subsection, it is assumed that the data follows Data model 1 with N = 2.
To gain some intuition, we first consider a simple example before stating our main result.",2.1. iPursuit: Basic idea,[0],[0]
Suppose that S1 and S2 are not orthogonal and assume that n2 < n1.,2.1. iPursuit: Basic idea,[0],[0]
"The non-orthogonality of S1 and S2 is not a requirement, but is merely used herein to simplify the exposition of the basic idea underlying the proposed approach.",2.1. iPursuit: Basic idea,[0],[0]
"Define c∗ as the optimal point of the following optimization problem
min ĉ ‖ĉTD‖0 subject to ĉ ∈ D and ‖ĉ‖ = 1, (1)
where ‖.‖0 is the `0-norm.",2.1. iPursuit: Basic idea,[0],[0]
"The first constraint limits the search space to the span of the data, and the equality constraint ‖ĉ‖ = 1 is used to avoid the trivial ĉ = 0 solution.",2.1. iPursuit: Basic idea,[0],[0]
"Assume that the columns of D1 and D2 are uniformly distributed in S1 and S2, respectively.",2.1. iPursuit: Basic idea,[0],[0]
"Accordingly, with high probability (whp) the data is not aligned along any specific direction in S1 and S2.
",2.1. iPursuit: Basic idea,[0],[0]
The `0-norm minimization problem (1) searches for a nonzero vector inD that is orthogonal to the maximum number of data points.,2.1. iPursuit: Basic idea,[0],[0]
"Since c∗ has to lie in D, we claim that the optimal point of (1) lies in I (S2 ⊥ S1) whp given the assumption that the number of data points in S1 is greater
than the number of data points in S2.",2.1. iPursuit: Basic idea,[0],[0]
"To clarify, consider the following cases:
I.",2.1. iPursuit: Basic idea,[0],[0]
"If c∗ ∈ S1, then it would not be orthogonal to the majority of the data points in S1 given that the columns of D1 are uniformly distributed in S1.",2.1. iPursuit: Basic idea,[0],[0]
"In addition, it cannot be orthogonal to most of the data points in S2 since S1 and S2 are not orthogonal.",2.1. iPursuit: Basic idea,[0],[0]
"Since the optimal vector should be orthogonal to the maximum number of data points, it is highly likely that c∗ 6∈ S1.",2.1. iPursuit: Basic idea,[0],[0]
"Similarly, it is highly unlikely that the optimal point lies in S2. II.",2.1. iPursuit: Basic idea,[0],[0]
"If c∗ ∈ I (S1 ⊥ S2), then according to Definition 1, it is orthogonal to the data points in D2.",2.1. iPursuit: Basic idea,[0],[0]
"However, since it was assumed that n2 < n1, the cost function of (1) can be decreased if c∗ lies in I (S2 ⊥ S1) (which is orthogonal to S1).",2.1. iPursuit: Basic idea,[0],[0]
III.,2.1. iPursuit: Basic idea,[0],[0]
"If c∗ does not lie in any of the subspaces S1, S2, I (S2 ⊥ S1) and I (S2 ⊥ S1), then it is neither orthogonal to S1 nor to S2.",2.1. iPursuit: Basic idea,[0],[0]
"Now, since the data points are distributed uniformly in the subspaces, we see that c∗ would not be orthogonal to the maximum number of data points.
",2.1. iPursuit: Basic idea,[0],[0]
"Hence, it is highly likely that c∗ lies in I (S2 ⊥ S1).",2.1. iPursuit: Basic idea,[0],[0]
It follows that the columns of D corresponding to the nonzero elements of (c∗)TD lie in S2.,2.1. iPursuit: Basic idea,[0],[0]
The following lemma ensures that these columns span S2.,2.1. iPursuit: Basic idea,[0],[0]
Lemma 1.,2.1. iPursuit: Basic idea,[0],[0]
The columns of D corresponding to the nonzero elements of (c∗)TD span S2 if the following conditions are satisfied: (i) c∗ ∈,2.1. iPursuit: Basic idea,[0],[0]
"I (S2 ⊥ S1) , (ii) D2 cannot follow Data model 1 with N > 1, that is, the data points in D2 do not lie in the union of lower dimensional subspaces within S2 each with innovation w.r.t.",2.1. iPursuit: Basic idea,[0],[0]
"the other subspaces.
",2.1. iPursuit: Basic idea,[0],[0]
It is important to note that the conditions of Lemma 1 are by no means restrictive.,2.1. iPursuit: Basic idea,[0],[0]
"Specifically, if the requirement (ii) of Lemma 1 is not satisfied, then the problem can be viewed as a subspace clustering problem with more than two subspaces.",2.1. iPursuit: Basic idea,[0],[0]
"In Section 2.4, we will investigate the clustering problem with more than two subspaces.
",2.1. iPursuit: Basic idea,[0],[0]
Remark 1.,2.1. iPursuit: Basic idea,[0],[0]
"At a high level, the innovation search problem (1) finds the most sparse vector in the row space of D. Interestingly, finding the most sparse vector in a linear subspace has bearing on, and has been effectively used in, other machine learning problems, including dictionary learning and spectral estimation (Qu et al., 2014).",2.1. iPursuit: Basic idea,[0],[0]
The `1-norm is known to provide an efficient convex relaxation of the `0-norm.,2.2. Convex relaxation,[0],[0]
"Thus, we relax the non-convex cost function and rewrite (1) as
min ĉ ‖ĉTD‖1 subject to ĉ ∈ D and ‖ĉ‖ = 1 .",2.2. Convex relaxation,[0],[0]
"(2)
Since the feasible set of (2) is non-convex, we further substitute the equality constraint with a linear constraint to
consider the following convex program
(IP) min ĉ ‖ĉTD‖1 s. t. ĉ ∈ D and ĉTq",2.2. Convex relaxation,[0],[0]
= 1.,2.2. Convex relaxation,[0],[0]
"(3)
(IP) is the core program of iPursuit to find a direction of innovation.",2.2. Convex relaxation,[0],[0]
"The vector q is a unit `2-norm vector that should not be orthogonal toD. In Section 2.6, we present a methodology to obtain a good choice for the vector q from the given data.",2.2. Convex relaxation,[0],[0]
"However, our investigations have shown that iPursuit performs well generally even when q is chosen as a random vector in D.",2.2. Convex relaxation,[0],[0]
"Suppose that D follows Data model 1 with N = 2, i.e., the data lies in a union of two subspaces.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In order to show that the optimal point of (IP) yields correct clustering, it suffices to show that the optimal point lies in I (S2 ⊥ S1) given that condition (ii) of Lemma 1 is satisfied for D2 (or lies in I (S1 ⊥ S2) given that the condition is satisfied for D1).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"The following theorem provides sufficient conditions for the optimal point of (3) to lie in I (S2 ⊥ S1) provided that
inf c∈I(S2⊥S1)
cT q=1
‖cTD‖1 < inf c∈I(S1⊥S2)
cT",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"q=1
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"‖cTD‖1. (4)
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"If the inequality in (4) is reversed, then similar sufficient conditions can be established for the optimal point of (3) to lie in I (S1 ⊥ S2).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Hence, assumption (4) does not lead to any loss of generality.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"The subspaces I (S2 ⊥ S1) and I (S1 ⊥ S2) are orthogonal to S1 and S2, respectively.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Thus, (4) is equivalent to
inf c∈I(S2⊥S1)
cT",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"q=1
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"‖cTD2‖1 < inf c∈I(S1⊥S2)
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
cT,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"q=1
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
‖cTD1‖1.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"(5)
Henceforth, “innovation subspace” refers to I (S2 ⊥ S1) whenever the two-subspace scenario is considered and (5) is satisfied.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Theorem 2 stated next provides sufficient conditions for the optimal point of (IP) in (3) to lie in I (S2 ⊥ S1).,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"These conditions are characterized in terms of the optimal solution to an oracle optimization problem (OP), wherein the feasible set of (IP) is replaced by the innovation subspace.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Define c2 as the optimal point of the following optimization problem
(OP) min ĉ ‖ĉTD2‖1
subject to ĉ ∈",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"I (S2 ⊥ S1) and ĉTq = 1. (6)
Theorem 2 establishes that c2 is the optimal point of (3).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Before we state the theorem, we define the index set L0 := {i ∈",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"[n2] : cT2 di = 0,di ∈ D2}, with cardinality n0 = |L0| and a complement set Lc0, comprising the indices of the columns of D2 orthogonal to c2.
Theorem 2.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Suppose the data matrix D follows Data model 1 with N = 2.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Also, assume that condition (5) and the requirement of Lemma 1 for D2 are satisfied (condition (ii) of Lemma 1).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Let c2 be the optimal point of the oracle (OP) in (6) and define α =
∑ di∈D2",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"i∈Lc0 sgn(cT2 di)di.
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Also, let P2 denote an orthonormal basis for I (S2 ⊥ S1) and assume that q is a unit `2-norm vector in D that is not orthogonal to I (S2 ⊥ S1).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"If
1 2 inf δ∈S1 ‖δ‖=1 ∑ di∈D1 ∣∣δTdi∣∣ >",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"‖VT1 V2‖(‖α‖+ n0) , and ‖qTP2‖ 2‖qTV1‖ ( inf δ∈S1 ‖δ‖=1 ∑ di∈D1
∣∣δTdi∣∣) >",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"‖VT2 P2‖(‖α‖+ n0), (7)
then c2 ∈",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"I (S2 ⊥ S1) is the optimal point of (IP) in (3), and iPursuit clusters the data correctly.
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In what follows, we provide a detailed discussion of the significance of the sufficient conditions (7) of Theorem 2, which reveal some interesting facts about the properties of iPursuit.
1.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Data distribution: The LHS of (7) is known as the permeance statistic, an efficient measure of how well the data points are distributed in a subspace (Lerman et al., 2015).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"As such, the sufficient conditions (7) imply that the distribution and the number of the data points within the subspaces are important performance factors for iPursuit.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"For a set of data points Di in a subspace Si, the permeance statistic is defined as P(Di,Si) = inf
u∈Si ‖u‖=1
∑ di∈Di",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
∣∣uTdi∣∣ .,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"From this definition, we see that the permeance statistic is fairly small if a set of data points are aligned along a given direction (i.e. not well distribued).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In addition, having n0 on the RHS reveals that the distribution of the data points within S2 also matters since c2 cannot be simultaneously orthogonal to a large number of columns of D2 if the data does not align along specific directions.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Hence, according to (7), iPursuit yields correct clustering if the data is well distributed within the subspaces.
2.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"The coherency of q with I (S2 ⊥ S1): For the optimal point of (IP) to lie in I (S2 ⊥ S1), the vector q should not be too coherent with S1.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
This can be seen by observing that if q has a small projection on I (S2 ⊥ S1) – in which case it would be more coherent with S1 – the Euclidean norm of any feasible point of (3) lying in I (S2 ⊥ S1) will have to be large to satisfy the equality constraint in (IP).,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Such points are less likely to be optimal in the sense of attaining the minimum of the objective function in (3).,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
The aforementioned intuition is affirmed by the analysis.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Indeed, the factor ‖qTP2‖/‖qTV1‖ in the sufficient conditions of Theorem 2 and Lemma 3 indicates that the coherency of q
with the innovation subspace is an important performance factor for iPursuit.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"The coherence property could have a more serious effect on the performance of the algorithm for non-independent subspaces, especially when the dimension of their intersection is significant.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"For instance, consider the scenario where the vector q is chosen randomly from D, and define y as the dimension of the intersection of S1 and S2.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
It follows that I (S2 ⊥ S1) has dimension r2,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"− y. Thus, E[‖q
TP2‖] E[‖qTV1‖] = r2−y r1
.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Therefore, a randomly chosen vector q is likely to have a small projection on the innovation subspace when y is large.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"As such, in dealing with subspaces with significant intersection, it may not be favorable to choose the vector q at random.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In Section 2.6 and section 2.7, we develop a simple technique to learn a good choice for q from the given data.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
It makes iPursuit remarkably powerful in dealing with subspaces with intersection as shown in the numerical results section.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Remark 2.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"We conjecture that if the ratios {ni/ri}Ni=1 are sufficiently large, the optimal point of (2) always lies in an innovation subspace; our investigations have shown that the optimal point of (IP) always lies in an innovation subspace provided that q is sufficiently coherent with the innovation subspace regardless how large the intersections between the subspaces are.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"This is particularly compelling if the subspaces are too close, in which case spectralclustering-based methods can seldom construct a correct similarity matrix (which leads to large clustering errors).",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"By contrast, in such cases iPursuit can yield accurate clustering provided that the constraint vector is sufficiently coherent with the innovation subspace.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In Section 2.6, we present a method to identify a coherent constraint vector.
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Now, we demonstrate that the sufficient conditions (7) are not restrictive.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
The following lemma simplifies the conditions when the data points are randomly distributed in the subspaces.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"In this setting, we show that the conditions are naturally satisfied.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Lemma 3.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Assume that the distribution of the columns of D1 in S1 and D2 in S2 is uniformly random and consider the same setup of Theorem 2.,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"If√
2
π n1 r1 − 2 √ n1",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"− t1
√ n1
r1 − 1 > 2‖VT1 V2‖ ( t2 √ n2 − n0 + n0 ) ,
‖qTP2‖ ‖qTV1‖
(√ 2
π n1 r1 − 2 √ n1",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"− t1
√ n1
r1 − 1
)
> 2‖VT2 P2‖ ( t2 √ n2 − n0 + n0 ) ,
(8)
then the optimal point of (3) lies in I (S2 ⊥ S1) with probability at least 1 − exp ( − r22 (t 2 2 − log(t22)− 1) )",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"−
exp ( − t 2 1
2
) , for all t2 > 1 , t1 ≥ 0.
",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"When the data points are not aligned along any specific directions, c2 can only be simultaneously orthogonal to a small number of columns of D2.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Thus, n0 will be much smaller than n2.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
The LHS of (8) has order n1 and the RHS has order √ n2+n0 (which is much smaller than n2).,2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
"Therefore, the sufficient conditions are naturally satisfied when the data is well distributed within the subspaces.",2.3. Segmentation of two subspaces: Performance guarantees,[0],[0]
Suppose that D follows Data Model 1 with N = m where m > 2.,2.4. Clustering multiple subspaces,[0],[0]
"Similar to (5), without loss of generality assume that
inf c∈I ( Sm⊥
m ⊕ k=1 k 6=m Sk ) cT",2.4. Clustering multiple subspaces,[0],[0]
qm=1 ‖cTDm‖1 < inf c∈I ( Sj⊥ m ⊕ k=1 k 6=j Sk ) cT,2.4. Clustering multiple subspaces,[0],[0]
qm=1 ‖cTDj‖1,2.4. Clustering multiple subspaces,[0],[0]
"(9)
for all 1 ≤ j ≤ m − 1 , where qm is a unit `2-norm in ⊕mk=1Sk.",2.4. Clustering multiple subspaces,[0],[0]
"Given (9), we expect the optimal point of (IP) with q = qm to lie in the innovation subspace of Sm over m ⊕ k=1 k 6=m Sk, i.e., I ( Sm ⊥ m ⊕ k=1 k 6=m Sk ) , in which case Sm will be identified.",2.4. Clustering multiple subspaces,[0],[0]
"Accordingly, in this step the clustering problem separates (Dm,Sm) and ( m−1 ∪ i=1",2.4. Clustering multiple subspaces,[0],[0]
"Di , m−1 ⊕ i=1",2.4. Clustering multiple subspaces,[0],[0]
Si).,2.4. Clustering multiple subspaces,[0],[0]
"Theorem 2 can be used to derive sufficient conditions for the optimal point to lie in I ( Sm ⊥
m ⊕ k=1 k 6=m
Sk ) by substituting (D2,S2)
with (Dm,Sm) and (D1,S1) with ( m−1 ∪ i=1",2.4. Clustering multiple subspaces,[0],[0]
"Di , m−1 ⊕ i=1",2.4. Clustering multiple subspaces,[0],[0]
Si).,2.4. Clustering multiple subspaces,[0],[0]
"Consequently, we can also establish sufficient conditions for exact subspace segmentation.",2.4. Clustering multiple subspaces,[0],[0]
"Due to space limitations, we defer the analysis to (Rahmani & Atia, 2015).",2.4. Clustering multiple subspaces,[0],[0]
"Define U as an orthonormal basis for D. Thus, the optimization problem (3) is equivalent to min a
‖aTUTD‖1 subject to aTUTq = 1.",2.5. Complexity analysis,[0],[0]
"Further, define f = UTq.",2.5. Complexity analysis,[0],[0]
"This optimization problem can be efficiently solved using the Alternating Direction Method of Multipliers (ADMM) (Boyd et al., 2011).",2.5. Complexity analysis,[0],[0]
"Due to space constraints, we defer the details of the iterative solver to (Rahmani & Atia, 2015).",2.5. Complexity analysis,[0],[0]
The complexity of the initialization step of the solver is O(r3) plus the complexity of obtaining U. Obtaining an appropriate U has O(r2M2) complexity by applying the clustering algorithm to a random subset of the rows of D (with the rank of sampled rows equal to r).,2.5. Complexity analysis,[0],[0]
"In addition, the complexity of each iteration of the solver is O(rM2).",2.5. Complexity analysis,[0],[0]
"Thus, the overall complexity is less than O((r3 + r2M2)N) since the number of data points remaining keeps decreasing over the iterations.",2.5. Complexity analysis,[0],[0]
"In most cases, r M2, hence the overall complexity is roughly O(r2M2N).
",2.5. Complexity analysis,[0],[0]
Remark 3.,2.5. Complexity analysis,[0],[0]
"The proposed method brings about substantial speedups over existing algorithms due to the following: i) unlike existing multi-step algorithms (such as RANSAC) which have exponential complexity in the number and dimension of subspaces, the complexity of iPursuit is linear in the number of subspaces and quadratic in their dimension.",2.5. Complexity analysis,[0],[0]
"In addition, while iPursuit has linear complexity in M2, spectral-clustering-based algorithms have complexity O(M22N) for their spectral clustering step plus the complexity of obtaining the similarity matrix; ii) more importantly, the solver of the proposed optimization problem has O(rM2) complexity per iteration, while the other operations – whose complexity are O(r2M2) and O(r3) – sit outside of the iterative solver.",2.5. Complexity analysis,[0],[0]
This feature makes the proposed method notably faster than most of the existing algorithms which solve high-dimensional optimization problems.,2.5. Complexity analysis,[0],[0]
"For instance, solving the optimization problem of the SSC algorithm has roughly O(M32 + rM2) complexity per iteration (Elhamifar & Vidal, 2013).",2.5. Complexity analysis,[0],[0]
"For instance, supposeM1 = 100, the data lies in a union of three 10-dimensional subspaces and ni = M2/3.",2.5. Complexity analysis,[0],[0]
Table 1 compares the running time of the algorithms.,2.5. Complexity analysis,[0],[0]
One can observe that iPursuit is remarkably faster.,2.5. Complexity analysis,[0],[0]
"More running time comparisons are available in (Rahmani & Atia, 2015).",2.5. Complexity analysis,[0],[0]
Our investigations have shown that iPursuit performs very well when the subspaces are independent or have small intersections even if q is chosen randomly.,2.6. How to choose the vector q?,[0],[0]
"However, in the more challenging scenarios in which the dimensions of the intersections between the subspaces are significant, randomly choosing the vector q could be unfavorable since the dimension of the innovation subspace decreases as the dimension of the intersection increases.",2.6. How to choose the vector q?,[0],[0]
"This motivates the methodology described next that aims to search for a “good” vector q. Consider the optimization problem
min q̂ ‖q̂TD‖2 subject to q̂ ∈ D and ‖q̂‖ = 1, (10)
which searches for a non-zero vector in D with small projections on the columns of D. It is straightforward to show that the optimal point of (10) is the singular vector corresponding to the least non-zero singular value of D. When the subspaces are close to each other, it is not hard to see
that the least singular vector is highly coherent with the innovation subspace, thus can be a good candidate for the vector q. For subspaces with remarkable intersections, this choice of q brings about substantial improvement in performance compared to using a randomly generated q (cf. Section 3).",2.6. How to choose the vector q?,[0],[0]
"Clearly, when the data is noisy, we utilize the least dominant singular vecor.",2.6. How to choose the vector q?,[0],[0]
"In addition, when the singular values of the noisy data decay rapidly, it may be hard to accurately estimate the rank of D, which may lead to an unfavorable use of a singular vector corresponding to noise as the constraint vector.",2.6. How to choose the vector q?,[0],[0]
"Alternatively, we can choose the data point closest to the least dominant singular vector as our vector q. This technique makes the proposed method robust to the presence of noise (cf. Section 2.7).",2.6. How to choose the vector q?,[0],[0]
"In the presence of additive noise, we model the data as De = D + E , where De is the given noisy data matrix, D is the clean data which follows Data model 1 and E represents the noise component.",2.7. Noisy data,[0],[0]
"The rank of D is equal to r. Thus, the singular values of De can be divided into two subsets: the dominant singular values (the first r singular values) and the small singular values (or the singular values corresponding to the noise component).",2.7. Noisy data,[0],[0]
"Estimating the number of dominant singular values is a fairly well-studied topic (Stoica & Selen, 2004).
",2.7. Noisy data,[0],[0]
"Consider the optimization problem (IP) using De, i.e.,
min ĉ ‖ĉTDe‖1 s.t. ĉ ∈ span(De) and ĉTq = 1.",2.7. Noisy data,[0],[0]
"(11)
Clearly, the optimal point of (11) is very close to the subspace spanned by the singular vectors corresponding to the small singular values.",2.7. Noisy data,[0],[0]
"Thus, if ce denotes the optimal solution of (11), then all the elements of cTe De will be fairly small and the subspaces cannot be distinguished.",2.7. Noisy data,[0],[0]
"However, the span of the dominant singular vectors is approximately equal toD. Accordingly, we propose the following approximation to (IP),
min ĉ ‖ĉTDe‖1 s.t. ĉ ∈ span(Q) and ĉTq = 1 (12)
where Q is an orthonormal basis for the span of the dominant singular vectors.",2.7. Noisy data,[0],[0]
"The first constraint of (12) forces the optimal point to lie in span(Q), which serves as a good approximation to span(D).",2.7. Noisy data,[0],[0]
"For instance, consider D =",2.7. Noisy data,[0],[0]
"[D1 D2], where the columns of D1 ∈ R40×100 lie in a 5-dimensional subspace S1, and the columns of D2 ∈ R40×100 lie in another 5-dimensional subspace S2.",2.7. Noisy data,[0],[0]
"Define ce and cr as the optimal points of (11) and (12), respectively.",2.7. Noisy data,[0],[0]
Fig. 2 shows |cTe De| and |cTr De| with the maximum element scaled to one.,2.7. Noisy data,[0],[0]
"Clearly, cTr De can be used to correctly cluster the data.",2.7. Noisy data,[0],[0]
"In addition, when D is low rank, the subspace constraint in (12) can filter out a remarkable portion of the noise component.
",2.7. Noisy data,[0],[0]
"When the data is noisy and the singular values of D decay rapidly, it may be hard to accurately estimate r.",2.7. Noisy data,[0],[0]
"If the dimension is incorrectly estimated, Q may contain some singular vectors corresponding to the noise component, wherefore the optimal point of (12) could end up lying close to a noise singular vector.",2.7. Noisy data,[0],[0]
"In the sequel, we present two effective techniques to effectively avoid this undesirable scenario.
1.",2.7. Noisy data,[0],[0]
"Using a data point as a constraint vector: A singular vector corresponding to the noise component is nearly orthogonal to the entire data, i.e., has small projection on all the data points.",2.7. Noisy data,[0],[0]
"Thus, if the optimal vector is forced to have strong projection on a data point, it will be unlikely for the optimal direction to be close to a noise singular vector.",2.7. Noisy data,[0],[0]
"Thus, we modify (12) as follows
min ĉ ‖ĉTDe‖1 s.t. ĉ ∈ span(Q) and ĉTdek = 1 , (13)
where dek is the kth column of De.",2.7. Noisy data,[0],[0]
The modified constraint in (13) ensures that the optimal point is not orthogonal to dek.,2.7. Noisy data,[0],[0]
"If dek lies in the subspace Si, the optimal point of (13) will lie in the innovation subspace corresponding to Si whp.",2.7. Noisy data,[0],[0]
"In order to determine a good data point for the constraint vector, we leverage the principle presented in section 2.6.",2.7. Noisy data,[0],[0]
"Specifically, we use the data point that is closest to the least dominant singular vector rather than the least dominant singular vector itself.
2.",2.7. Noisy data,[0],[0]
"Sparse representation of the optimal point: When D is low rank, i.e., r min(M1,M2), any direction in the span of the data – including the optimal direction sought by iPursuit – can be represented as a sparse combination of the data points.",2.7. Noisy data,[0],[0]
"For such settings, we propose the alternative optimization problem
min a,z
‖aTQTDe‖1 + γ‖z‖1
subject to a = QTDe z and aTQTdek = 1 , (14)
where γ is a regularization parameter.",2.7. Noisy data,[0],[0]
"Forcing a sparse representation in (14) for the optimal direction averts a solution that lies in close proximity with the small singular vectors, which are normally obtained through linear combinations of a large number of data points.",2.7. Noisy data,[0],[0]
"This alternative
formulation is particularly useful when the dimension of the data cannot be accurately estimated.",2.7. Noisy data,[0],[0]
"When D is not a low rank matrix, we can set γ equal to zero.",2.7. Noisy data,[0],[0]
The table of Algorithm 1 details the proposed method for noisy data along with the used notation and definitions.,2.7. Noisy data,[0],[0]
"If κ (or ci) and the threshold co in Algorithm 1 are chosen appropriately, the algorithm exhibits strong robustness in the presence of noise.",2.7.1. ERROR PROPAGATION,[0],[0]
"Nonetheless, if the data is too noisy, an error incurred in one step of the algorithm may propagate and unfavorably affect the performance in subsequent steps.",2.7.1. ERROR PROPAGATION,[0],[0]
Two types of error could occur.,2.7.1. ERROR PROPAGATION,[0],[0]
The first type is that some data points are erroneously included in G1 or G2.,2.7.1. ERROR PROPAGATION,[0],[0]
"An example is when Sm is the subspace to be identified in a given step of the algorithm (i.e., the optimal point of (13) lies in the innovation subspace corresponding to Sm), but few data points from the other subspaces are erroneously included in G1.",2.7.1. ERROR PROPAGATION,[0],[0]
The second type of error is that some of the data points remain unidentified.,2.7.1. ERROR PROPAGATION,[0],[0]
"For instance, Sm is to be identified in a given iteration, yet not all the data points belonging to Sm are identified.",2.7.1. ERROR PROPAGATION,[0],[0]
"In an extended version of this work (Rahmani & Atia, 2015), we discuss the two main sources of error and present some techniques to effectively neutralize their impact on subsequent iterations.",2.7.1. ERROR PROPAGATION,[0],[0]
"In addition, a brief discussion about handling the presence of outliers is provided.",2.7.1. ERROR PROPAGATION,[0],[0]
"In (Rahmani & Atia, 2017), we showed that the direction search optimization problem (13) can be utilized to find a neighborhood set for the kth data point.",2.8. Subspace clustering using direction search and spectral clustering,[0],[0]
"We leveraged this feature to propose a new spectral-clusteringbased subspace segmentation algorithm, dubbed Direction search based Subspace Clustering (DSC) (Rahmani & Atia, 2017).",2.8. Subspace clustering using direction search and spectral clustering,[0],[0]
"We showed that DSC often outperforms the existing spectral-clustering-based methods particularly for hard scenarios involving high levels of noise and close subspaces, and notably improves the state-of-the-art result for the challenging problem of face segmentation using subspace clustering.",2.8. Subspace clustering using direction search and spectral clustering,[0],[0]
"In this experiment, we examine the impact of the coherency of q with the innovation subspace.",3.1. The coherency parameter,[0],[0]
"Here, it is assumed that the data follows Data Model 1 with N = 2 and M1 = 50.",3.1. The coherency parameter,[0],[0]
The dimension of the subspaces is equal to 15 and the dimension of their intersection varies between 0 to 14.,3.1. The coherency parameter,[0],[0]
"Each subspace contains 100 data points distributed uniformly at
random within the subspace.",3.1. The coherency parameter,[0],[0]
Let cr = ‖qTP2‖/‖qTV1‖.,3.1. The coherency parameter,[0],[0]
"Thus, cr captures the coherency of q with the innovation subspace.",3.1. The coherency parameter,[0],[0]
Define V̂1 and V̂2 as orthonormal bases for the identified subspaces.,3.1. The coherency parameter,[0],[0]
"A trial is considered successful if
‖(I−V1VT1 )V̂1‖F",3.1. The coherency parameter,[0],[0]
+ ‖(I−V2VT2 ),3.1. The coherency parameter,[0],[0]
V̂2‖F ≤ 10−3 .,3.1. The coherency parameter,[0],[0]
"(15)
The left plot of Fig. 3 shows the phase transition in the plane of cr and y, where y is the dimension of the intersection of the two subspaces.",3.1. The coherency parameter,[0],[0]
"In this figure, white designates exact identification of the subspaces with probability almost equal to one.",3.1. The coherency parameter,[0],[0]
"As shown, the probability of correct clustering increases if cr is increased.",3.1. The coherency parameter,[0],[0]
"Remarkably, the left plot of Fig. 3 shows that when cr is sufficiently large, the algorithm yields exact segmentation even when y = 14.",3.1. The coherency parameter,[0],[0]
"In this simulation, we consider the subspace clustering problem with 15 30-dimensional subspaces {Si}15i=1 and M1 = 500.",3.2. Clustering data in union of multiple subspaces,[0],[0]
Each subspace contains 90 data points and the distribution of the data within the subspaces is uniformly random.,3.2. Clustering data in union of multiple subspaces,[0],[0]
"We compare the performance of the proposed approach to the state-of-the-art sparse subspace clustering (SSC) (Elhamifar & Vidal, 2013) algorithm and low rank representation (LRR) based clustering (Liu et al., 2013).",3.2. Clustering data in union of multiple subspaces,[0],[0]
The number of replicates used in spectral clustering for SSC and LRR is equal to 20.,3.2. Clustering data in union of multiple subspaces,[0],[0]
Define the clustering error as the ratio of misclassified points to the total number of data points.,3.2. Clustering data in union of multiple subspaces,[0],[0]
The right plot of Fig. 3 shows the clustering error versus the dimension of the intersection.,3.2. Clustering data in union of multiple subspaces,[0],[0]
The dimension of intersection varies between 1 and 29.,3.2. Clustering data in union of multiple subspaces,[0],[0]
Each point in the plot is obtained by averaging over 40 independent runs.,3.2. Clustering data in union of multiple subspaces,[0],[0]
iPursuit is shown to yield the best performance.,3.2. Clustering data in union of multiple subspaces,[0],[0]
"In this section, we study the performance of the proposed approach, SSC, LRR, SCC (Chen & Lerman, 2009), TSC (Heckel & Bölcskei, 2013) and SSC-OMP (Dyer et al.,
Table 2.",3.3. Noisy data,[0],[0]
"CE (%) of algorithms on Hopkins155 dataset (Mean - Median).
",3.3. Noisy data,[0],[0]
"N SSC LRR iPursuit SSC-OMP TSC K-flats SCC
N = 2 1.52 - 0 2.13 - 0 3.33 - 0.27 16.92 - 12.77 s 18.44 - 16.92 13.62 - 10.65 2.06 - 0 N = 3 4.40 - 1.56 s 4.03 - 1.43 6.91 - 2.44 27.96 - 30.98 28.58 - 29.67 14.07 - 14.18 6.37 - 0.21
Figure 4.",3.3. Noisy data,[0],[0]
"Performance of the algorithms versus the dimension of intersection for different noise levels.
2013) with different noise levels, and varying dimensions of the intersection between the subspaces, which gives rise to both low rank and high rank data matrices.",3.3. Noisy data,[0],[0]
"It is assumed that D follows Data model 1 with M1 = 100, M2 = 500, N = 6 and {ri}6i=1 = 15.",3.3. Noisy data,[0],[0]
The dimension of the intersection between the subspaces varies from 0 to 14.,3.3. Noisy data,[0],[0]
"Thus, the rank of D ranges from 20 to 90.",3.3. Noisy data,[0],[0]
"The Noisy data is modeled as De = D + E, with the elements of E sampled independently from a zero mean Gaussian distribution.",3.3. Noisy data,[0],[0]
"Fig. 4 shows the performance of the different algorithms versus the dimension of the intersection for τ = ‖E‖F‖D‖F equal to 1/20, 1/10, 1/5 and 1/2.",3.3. Noisy data,[0],[0]
"One can observe that even with τ = 1/5, iPursuit significantly outperforms the other algorithms.",3.3. Noisy data,[0],[0]
"In addition, when the data is very noisy, i.e., τ = 1/2, it yields better performance when the dimension of the intersection is large.",3.3. Noisy data,[0],[0]
"SSC, LRR, and SSC-OMP yield a better performance for lower dimension of intersection.",3.3. Noisy data,[0],[0]
"This is explained by the fact that the rank of the data is high when the dimension of the intersection is low, and the subspace projection operation QTDe may not always filter out the additive noise effectively.",3.3. Noisy data,[0],[0]
"We apply iPursuit to the problem of motion segmentation using the Hopkins155 (Tron & Vidal, 2007) dataset, which contains video sequences of 2 or 3 motions.",3.4. Real data,[0],[0]
"In motion segmentation, each motion corresponds to one subspace.
",3.4. Real data,[0],[0]
"Thus, the problem here is to cluster data lying in two or three subspaces.",3.4. Real data,[0],[0]
"Table 2 shows the clustering error (in percentage) for iPursuit, SSC, LRR, TSC, SSC-OMP and Kflats.",3.4. Real data,[0],[0]
"We use the results reported in (Elhamifar & Vidal, 2013; Heckel & Bölcskei, 2013; Vidal, 2011; Park et al., 2014).",3.4. Real data,[0],[0]
"For SSC-OMP and TSC, the number of parameters for motion segmentation are equal to 8 and 10.",3.4. Real data,[0],[0]
"One can observe that iPursuit yields competitive results comparable to SSC, SCC, and LRR and outperforms TSC, SSC-OMP and K-flats.
",3.4. Real data,[0],[0]
"Algorithm 1 Innovation pursuit (iPursuit) for noisy data Initialization Set κ, n̂ and N̂ as integers greater than 1, and set ci and co as positive real numbers less than 1.
",3.4. Real data,[0],[0]
While The number of identified subspaces is less than N̂ or the number of the columns of De is less than n̂. 1.,3.4. Real data,[0],[0]
Obtaining the basis for the remaining Data: Construct Q as the orthonormal matrix formed by the dominant singular vectors of De. 2.,3.4. Real data,[0],[0]
Choosing the vector q:,3.4. Real data,[0],[0]
Set q = the column of De closest to the last column of Q. 3.,3.4. Real data,[0],[0]
"Solve (14) and define c∗ = Qa∗, where a∗ is the optimal point
of (14) and define h1 = ∣∣DTe c∗∣∣ max(
∣∣DTe c∗∣∣) .",3.4. Real data,[0],[0]
4.,3.4. Real data,[0],[0]
Finding a basis for the identified subspace: Construct G1 as the matrix consisting of the columns of De corresponding to the elements of h1 that are greater than ci.,3.4. Real data,[0],[0]
"Alternatively, construct G1 using the columns of De corresponding to the κ largest elements of h1.",3.4. Real data,[0],[0]
Define F1 as an orthonormal basis for the dominant left singular vectors of G1.,3.4. Real data,[0],[0]
Define the vector h2 whose entries are equal to the `2-norm of the columns of (I − F1FT1 )De.,5. Finding a basis for the rest of the data:,[0],[0]
Scale h2 as h2 := h2/max(h2).,5. Finding a basis for the rest of the data:,[0],[0]
Construct G2 as the columns of De corresponding to the elements of h2 greater than co. Define F2 as an orthonormal basis for the dominant left singular vectors of of G2.,5. Finding a basis for the rest of the data:,[0],[0]
Assign dei to the identified subspace if ‖FT1 dei‖ ≥ ‖FT2 dei‖. 7.,6. Find the data point belonging to the identified subspace:,[0],[0]
"Remove the data points belonging to the identified subspace: Update De by removing the columns corresponding to the identified subspace.
",6. Find the data point belonging to the identified subspace:,[0],[0]
"End While
Acknowledgment: This work was supported by NSF CAREER Award CCF-1552497 and NSF Grant CCF1320547.",6. Find the data point belonging to the identified subspace:,[0],[0]
"This paper presents a new scalable approach, termed Innovation Pursuit (iPursuit), to the problem of subspace clustering.",abstractText,[0],[0]
iPursuit rests on a new geometrical idea whereby each subspace is identified based on its novelty with respect to the other subspaces.,abstractText,[0],[0]
"The subspaces are identified consecutively by solving a series of simple linear optimization problems, each searching for a direction of innovation in the span of the data.",abstractText,[0],[0]
A detailed mathematical analysis is provided establishing sufficient conditions for the proposed approach to correctly cluster the data points.,abstractText,[0],[0]
"Moreover, the proposed direction search approach can be integrated with spectral clustering to yield a new variant of spectral-clustering-based algorithms.",abstractText,[0],[0]
"Remarkably, the proposed approach can provably yield exact clustering even when the subspaces have significant intersections.",abstractText,[0],[0]
The numerical simulations demonstrate that iPursuit can often outperform the state-of-the-art subspace clustering algorithms – more so for subspaces with significant intersections – along with substantial reductions in computational complexity.,abstractText,[0],[0]
Innovation Pursuit: A New Approach to the Subspace Clustering Problem,title,[0],[0]
"In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries.
*Equal contribution. Order decided by a coin flip. 1Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign. 2Department of Mechanical and Aerospace Engineering, University of California, Irvine. 3Department of Electrical Engineering, Princeton University, 4Allen School of Computer Science & Engineering, University of Washington. Correspondence to: Ashok <makkuva2@illinois.edu>, Amir <amirhoseintghv@gmail.com>.
Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 108, 2020. Copyright 2020 by the author(s).",text,[0],[0]
"Finding a mapping that transports mass from one distribution Q to another distribution P is an important task in various machine learning applications, such as deep generative models (Goodfellow et al., 2014; Kingma & Welling, 2013) and domain adaptation (Gopalan et al., 2011; BenDavid et al., 2010).",1. Introduction,[0],[0]
"Among infinitely many transport maps T that can map a random variableX fromQ such that T (X) is distributed as P , several recent advances focus on discovering some inductive bias to find a transport map with desirable properties.",1. Introduction,[0],[0]
"Research in optimal transport has been leading such efforts, in applications such as color transfer (Ferradans et al., 2014), shape matching (Su et al., 2015), data assimilation (Reich, 2013), and Bayesian inference (El Moselhy & Marzouk, 2012).",1. Introduction,[0],[0]
"Searching for an optimal transport encourages a mapping that minimizes the total cost of transporting mass from Q to P , as originally formulated in Monge (1781), and provides the inductive bias needed in many such applications.",1. Introduction,[0],[0]
"However, finding the optimal transport map in general is a challenging task, especially in high dimensions where efficient approaches are critical.
",1. Introduction,[0],[0]
Algorithmic solutions are well-established for discrete variables; the optimal transport can be found as a solution to linear program.,1. Introduction,[0],[0]
"Building upon this mature area, typical approaches for general distributions use quantization, and this becomes intractable for high-dimensional variables we encounter in modern applications (Evans & Gangbo, 1999; Benamou & Brenier, 2000; Papadakis et al., 2014).
",1. Introduction,[0],[0]
"To this end, we propose a novel minimax optimization approach to search for the optimal transport under the quadratic distance (i.e. 2-Wassertstein metric).",1. Introduction,[0],[0]
A major challenge in a minimax formulation of optimal transport is that the constraints in the Kantorovich dual formulation (3) are notoriously challenging.,1. Introduction,[0],[0]
"They require the evaluation of the functions at every point in the domain, which is not tractable.",1. Introduction,[0],[0]
A common straightforward heuristics sample some points and add those sampled constraints as regularizers.,1. Introduction,[0],[0]
"Such regularizations create biases that hinder learning the true optimal transport.
",1. Introduction,[0],[0]
"Our key innovation is to depart from this common practice; we instead eliminate the constraints by restricting our search to the set of all convex functions, building upon the fundamental connection from Theorem 3.1.",1. Introduction,[0],[0]
"This leads to
ar X
iv :1
90 8.
10 96
2v 2
[ cs
.L",1. Introduction,[0],[0]
"G
] 1
7 Ju
n 20
20
a novel minimax formulation in (5).",1. Introduction,[0],[0]
"Leveraging on recent advances in input convex neural networks, we propose a new architecture and a training algorithm for solving this minimax optimization.",1. Introduction,[0],[0]
We establish the consistency of our proposed minimax formulation in Theorem 3.3.,1. Introduction,[0],[0]
"In particular, we show that the solution to this optimization problems yields the exact optimal transport map.",1. Introduction,[0],[0]
"We provide stability analysis for the proposed estimator in Theorem 3.6.
",1. Introduction,[0],[0]
"Further, when used to train deep generative models, our approach can be viewed as a novel framework to train a generator that is modeled as a gradient of a convex function.",1. Introduction,[0],[0]
We provide a principled training rule based on the optimal transport theory.,1. Introduction,[0],[0]
"This ensures that (i) the generator converges to the optimal transport, independent of how we initialize the neural network; and (ii) represent sharp boundaries when the target has multiple disconnected supports.",1. Introduction,[0],[0]
"Gradient of a neural network naturally represents discontinuous functions, which is critical in mapping from a single connected support to disconnected supports.
",1. Introduction,[0],[0]
"To model convex functions, we leverage Input Convex Neural Networks (ICNNs), a class of scalar-valued neural networks f(x; θ) such that the function x 7→ f(x; θ) ∈ R is convex.",1. Introduction,[0],[0]
"These neural networks were introduced by Amos et al. (2016) to provide efficient inference and optimization procedures for structured prediction, data imputation and reinforcement learning tasks.",1. Introduction,[0],[0]
"In this paper, we show that ICNNs can be efficiently trained to learn the optimal transport map between two distributions P and Q. To the best of our knowledge, this is the first such instance where ICNNs are leveraged for the well-known task of learning optimal transport maps in a scalable fashion.",1. Introduction,[0],[0]
"This framework opens up a new realm for understanding problems in optimal transport theory using parametric convex neural networks, both in theory and practice.",1. Introduction,[0],[0]
"Figure 1 provides an example where the optimal transport map has been learned via our proposed Algorithm 1 from the orange distribution to the green distribution.
",1. Introduction,[0],[0]
"Notation. P(X ) denotes the set of probability measures on a Polish space X , and B(X ) denotes the Borel sub-
sets of X .",1. Introduction,[0],[0]
"For P ∈ P(X ) and Q ∈ P(Y), P ⊗ Q denotes the product measure on X × Y .",1. Introduction,[0],[0]
For measurable map T : X,1. Introduction,[0],[0]
"→ Y , T#P denotes the push-forward of P under T , i.e. (T#P )(A) = P (T−1(A)), ∀A ∈ B(Y).",1. Introduction,[0],[0]
"L1(P ) , {f is measurable & ∫ f dP < ∞} denotes the set of integrable functions with respect to P .",1. Introduction,[0],[0]
CVX(P ) denotes the set of all convex functions in L1(P ).,1. Introduction,[0],[0]
Id : x 7→ x denotes the identity function.,1. Introduction,[0],[0]
"〈·, ·〉 and ‖ · ‖ denote the inner-product and `2-Euclidean norm.",1. Introduction,[0],[0]
Let P and Q be two probability distributions on Rd with finite second order moments.,2. Background on optimal transport,[0],[0]
"The Monge’s optimal transportation problem is to transport the probability mass under Q to P with the least amount of cost1, i.e.
minimize T :T#Q=P
1 2 EX∼Q‖X",2. Background on optimal transport,[0],[0]
− T (X)‖2.,2. Background on optimal transport,[0],[0]
"(1)
Any transport map T achieving the minimum in (1) is called optimal transport map.",2. Background on optimal transport,[0],[0]
Optimal transport map may not exist.,2. Background on optimal transport,[0],[0]
"In fact, the feasible set in the above optimization problem may itself be empty, for example when Q is a Dirac distribution and P is any non-Dirac distribution.
",2. Background on optimal transport,[0],[0]
"To resolve the existence issue of the Monge problem (1), Kantorovich introduced a relaxation of the problem,
W 22 (P,Q) , inf π∈Π(P,Q)
1 2 E(X,Y )∼π‖X",2. Background on optimal transport,[0],[0]
"− Y ‖2, (2)
where Π(P,Q) denotes the set of all joint probability distributions (or equivalently, couplings) whose first and second marginals are P and Q, respectively.",2. Background on optimal transport,[0],[0]
"The optimal value in (2) is the 2-Wasserstein distance W2(·, ·) squared.",2. Background on optimal transport,[0],[0]
Any coupling π achieving the infimum is called the optimal coupling.,2. Background on optimal transport,[0],[0]
"Optimization problem (2) is also referred to as the primal formulation for 2-Wasserstein distance.
",2. Background on optimal transport,[0],[0]
"1In general, Monge’s problem is defined in terms of cost function c(x, y).",2. Background on optimal transport,[0],[0]
"This paper is concerned with quadratic cost function c(x, y) = 1
2 ‖x − y‖2 because of its nice geometrical properties
and connection to convex analysis (Villani, 2003, Ch. 2).
",2. Background on optimal transport,[0],[0]
"Kantorovich also provided a dual formulation for (2), known as the Kantorovich duality (Villani, 2003, Theorem 1.3),
W 22 (P,Q) = sup (f,g)∈Φc EP [f(X)]",2. Background on optimal transport,[0],[0]
+,2. Background on optimal transport,[0],[0]
EQ[g(Y ),2. Background on optimal transport,[0],[0]
"], (3)
where Φc denotes the constrained space of functions, defined as Φc , { (f, g) ∈ L1(P )× L1(Q) : f(x) + g(y) ≤ 1 2‖x− y‖ 2 2, ∀(x, y) dP ⊗ dQ a.e. } .
",2. Background on optimal transport,[0],[0]
"The dual problem (3) can be recast as an stochastic optimization problem by approximating the expectations using independent samples from P and Q. However, there is no easy way to ensure the feasibility of the constraint (f, g) ∈",2. Background on optimal transport,[0],[0]
Φc along the gradient updates.,2. Background on optimal transport,[0],[0]
"Common approach is to translate the optimization into a tractable form, while sacrificing the original goal of finding the optimal transport map.",2. Background on optimal transport,[0],[0]
"Concretely, an entropic or a quadratic regularizer is added to the primal problem (2) (Cuturi, 2013; Essid & Solomon, 2018; Peyré et al., 2019; Blondel et al., 2017).",2. Background on optimal transport,[0],[0]
"Then, the dual to the regularized primal problem is an unconstrained version of (3) with additional penalty term.",2. Background on optimal transport,[0],[0]
"The unconstrained problem can be numerically solved using Sinkhorn algorithm in discrete setting (Cuturi, 2013) or stochastic gradient methods with suitable function representation in continuous setting (Genevay et al., 2016; Seguy et al., 2017).",2. Background on optimal transport,[0],[0]
"The optimal transport can then be obtained from f and g, using the first-order optimality conditions of the FenchelRockafellar’s duality theorem (Seguy et al., 2017), or by training a generator through an adversarial computational procedure (Leygonie et al., 2019).
",2. Background on optimal transport,[0],[0]
"In this paper, we take a different approach: solve the dual problem without introducing a regularization.",2. Background on optimal transport,[0],[0]
"This builds upon (Taghvaei & Jalali, 2019), where ICNN for the task of approximating the Wasserstein distance and optimal transport map is originally proposed.",2. Background on optimal transport,[0],[0]
"We bring the idea proposed (Taghvaei & Jalali, 2019) into practice by introducing a novel minimax optimization formulation.",2. Background on optimal transport,[0],[0]
We describe our proposed method in Section 3 and provide a detailed comparison in Remark 3.5.,2. Background on optimal transport,[0],[0]
"Discussion about other related works (Lei et al., 2017; Guo et al., 2019; Xie et al., 2019; Muzellec & Cuturi, 2019; Rabin et al., 2011; Korotin et al., 2019) appears in Appendix D.",2. Background on optimal transport,[0],[0]
"Our goal is to learn the optimal transport map T ∗ from Q to P , from samples drawn from P and Q, respectively.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"We use the fundamental connection between optimal transport and Kantorovich dual in Theorem 3.1, to formulate learning T ∗ as a problem of estimating W 22 (P,Q).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"However, W 2 2 (P,Q) is notoriously hard to estimate.",3. A novel minimax formulation to learn optimal transport,[0],[0]
The standard Kantorovich dual formulation in Eq.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"(3) involves a supremum over a set Φc with infinite constraints, which is challenging to even approximately project onto.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"To this end, we derive an
alternative optimization formulation in Eq.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"(5), inspired by the convexification trick (Villani, 2003, Section 2.1.2).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"This allows us to eliminate the distance constraint of Φc, and instead constrain our search over all convex functions.",3. A novel minimax formulation to learn optimal transport,[0],[0]
This constrained optimization can now be seamlessly integrated with recent advances in designing deep neural architectures with convexity guarantees.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"This leads to a novel minimax optimization to learn the optimal transport.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
"We exploit the fundamental properties of W 22 (P,Q) and the corresponding optimal transport to reparametrize the optimization formulation.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Note that for any (f, g) ∈",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Φc,
f(x) + g(y) ≤ 1 2 ‖x− y‖22 ⇐⇒[
1 2 ‖x‖22 − f(x)
] + [ 1
2 ‖y‖22 − g(y)
]",3. A novel minimax formulation to learn optimal transport,[0],[0]
"≥ 〈x, y〉.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Hence reparametrizing 12‖ · ‖ 2 2 − f(·) and 12‖ · ‖ 2 2 − g(·) by f and g respectively, and substituting them in (3) yields
W 22 (P,Q) = CP,Q − inf (f,g)∈Φ̃c
{ EP [f(X)]",3. A novel minimax formulation to learn optimal transport,[0],[0]
+ EQ[g(Y )],3. A novel minimax formulation to learn optimal transport,[0],[0]
"} ,
where CP,Q = (1/2)E[‖X‖22 + ‖Y ‖22] is a constant independent of (f, g) and Φ̃c , {(f, g) ∈ L1(P )",3. A novel minimax formulation to learn optimal transport,[0],[0]
"× L1(Q) : f(x) + g(y) ≥ 〈x, y〉, ∀(x, y) dP ⊗ dQ a.e.}.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"While the above constrained optimization problem involves a pair of functions (f, g), it can be transformed into the following form involving only a single convex function f , thanks to Villani (2003, Theorem 2.9):
W 22 (P,Q)=CP,Q− inf f∈CVX(P )",3. A novel minimax formulation to learn optimal transport,[0],[0]
EP,3. A novel minimax formulation to learn optimal transport,[0],[0]
"[f(X)]+EQ[f∗(Y )], (4)
where f∗(y) = supx〈x, y〉 − f(x) is the convex conjugate of f(·).
",3. A novel minimax formulation to learn optimal transport,[0],[0]
"The crucial tools behind our formulation are the following celebrated results due to Knott-Smith and Brenier (Villani, 2003), which relate the optimal solutions for the dual form in (4) and the primal form in (2).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Theorem 3.1 ((Villani, 2003, Theorem 2.12)).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Let P,Q be two probability distributions on Rd with finite second order moments.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Then,
1. (Knott-Smith optimality criterion)",3. A novel minimax formulation to learn optimal transport,[0],[0]
"A coupling π ∈ Π(P,Q) is optimal for the primal (2) if and only if there exists a convex function f ∈ CVX(Rd) such that Supp(π) ⊂ Graph(∂f).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Or equivalently, for all dπalmost (x, y), y ∈ ∂f(x).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Moreover, the pair (f, f∗) achieves the minimum in the dual form (4).
2.",3. A novel minimax formulation to learn optimal transport,[0],[0]
(Brenier’s theorem),3. A novel minimax formulation to learn optimal transport,[0],[0]
"If Q admits a density with respect to the Lebesgue measure on Rd, then there is a unique optimal coupling π for the primal problem.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"In particular, the optimal coupling satisfies that
dπ(x, y) = dQ(y)δx=∇f∗(y),
where the convex pair (f, f∗) achieves the minimum in the dual problem (4).",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Equivalently, π = (∇f∗ × Id)#Q.
3.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Under the above assumptions of Brenier’s theorem, ∇f∗ in the unique solution to Monge transportation problem from Q to P , i.e.
EQ‖∇f∗(Y )",3. A novel minimax formulation to learn optimal transport,[0],[0]
− Y ‖2 = inf T :T#Q=P EQ‖T,3. A novel minimax formulation to learn optimal transport,[0],[0]
(Y ),3. A novel minimax formulation to learn optimal transport,[0],[0]
"− Y ‖2.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
Remark 3.2.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"Whenever Q admits a density, we refer to ∇f∗ as the optimal transport map.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Henceforth, throughout the paper we assume that the distribution Q admits a density in Rd.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"Note that in view of Theorem 3.1, any optimal pair (f, f∗) from the dual formulation in (4) provides us an optimal transport map ∇f∗ pushing forward Q onto P .",3. A novel minimax formulation to learn optimal transport,[0],[0]
"However, the objective (4) is not amenable to standard stochastic optimization schemes due to the conjugate function f∗.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"To this end, we propose a novel minimax formulation in the following theorem where we replace the conjugate with a new convex function.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
Theorem 3.3.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"WheneverQ admits a density in Rd, we have
W 22 (P,Q) = sup f∈CVX(P ), f∗∈L1(Q) inf g∈CVX(Q) VP,Q(f, g) +",3. A novel minimax formulation to learn optimal transport,[0],[0]
"CP,Q, (5)
where VP,Q(f, g) is a functional of f, g defined as
VP,Q(f, g) = −EP",3. A novel minimax formulation to learn optimal transport,[0],[0]
"[f(X)]−EQ[〈Y,∇g(Y )〉−f(∇g(Y ))",3. A novel minimax formulation to learn optimal transport,[0],[0]
"].
",3. A novel minimax formulation to learn optimal transport,[0],[0]
"In addition, there exists an optimal pair (f0, g0) achieving the infimum and supremum respectively, where ∇g0 is the optimal transport map from Q to P .
",3. A novel minimax formulation to learn optimal transport,[0],[0]
Proof sketch.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"The proof follows from the inequality 〈y,∇g(y)〉 − f(∇g(y))",3. A novel minimax formulation to learn optimal transport,[0],[0]
"≤ f∗(y) for all functions g, and then taking the expectation over Q, and observing that the equality is achieved with g = f∗.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"The technical details appear in Appendix A.
Remark 3.4.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"For any convex function f , the function g ∈ L1(Q) that achieves the infimum in (5) is convex and equals f∗. Therefore, the constraint g ∈ CVX(Q) can be relaxed to g ∈ L1(Q) without changing the optimal value and optimizing functions.",3. A novel minimax formulation to learn optimal transport,[0],[0]
"We numerically observe that the optimization algorithm performs better under this relaxation.
",3. A novel minimax formulation to learn optimal transport,[0],[0]
Formulation (5) now provides a principled approach to learn the optimal transport mapping∇g(·) as a solution of a minimax optimization.,3. A novel minimax formulation to learn optimal transport,[0],[0]
"Since the optimization involves the search over the space of convex functions, we utilize the recent advances in input convex neural networks (ICNNs) to parametrize them as discussed in the following section.",3. A novel minimax formulation to learn optimal transport,[0],[0]
We propose using parametric models based on deep neural networks to approximate the set of convex functions.,3.1. Minimax optimization over ICNNs,[0],[0]
"This is known as input convex neural networks (Amos et al., 2016), denoted by ICNN(Rd).",3.1. Minimax optimization over ICNNs,[0],[0]
"We propose estimating the following approximate Wasserstein-2 distance, from samples:
W̃ 22 (P,Q)= sup f∈ICNN(Rd) inf g∈ICNN(Rd) VP,Q(f, g)+CP,Q. (6)
ICNNs are a class of scalar-valued neural networks f(x; θ) such that the function x 7→ f(x; θ) ∈ R is convex.
",3.1. Minimax optimization over ICNNs,[0],[0]
The neural network architecture for an ICNN is as follows.,3.1. Minimax optimization over ICNNs,[0],[0]
"Given an input x ∈ Rd, the mapping x 7→ f(x; θ) is given by a L-layer feed-forward NN using the following equations for l = 0, 1, . . .",3.1. Minimax optimization over ICNNs,[0],[0]
", L− 1:
zl+1 =",3.1. Minimax optimization over ICNNs,[0],[0]
"σl(Wlzl +Alx+ bl), f(x; θ) = zL,
where {Wl}, {Al} are weight matrices (with the convention that W0 = 0), and {bl} are the bias terms.",3.1. Minimax optimization over ICNNs,[0],[0]
σl denotes the entry-wise activation function at the layer,3.1. Minimax optimization over ICNNs,[0],[0]
l. This is illustrated in Figure 2.,3.1. Minimax optimization over ICNNs,[0],[0]
"We denote the total set of parameters by θ = ({Wl}, {Al}, {bl}).",3.1. Minimax optimization over ICNNs,[0],[0]
"It follows from Amos et al. (2016, Proposition 1) that f(x; θ) is convex in x provided
(i) all entries of the weights Wl are non-negative;
(ii) activation function σ0 is convex;
(iii) σl is convex and non-decreasing, for l = 1, . . .",3.1. Minimax optimization over ICNNs,[0],[0]
", L− 1.
",3.1. Minimax optimization over ICNNs,[0],[0]
"While ICNNs are a specific parametric class of convex functions, it is important to understand if this class is rich enough representationally.",3.1. Minimax optimization over ICNNs,[0],[0]
"This is answered positively by Chen et al. (2018, Theorem 1).",3.1. Minimax optimization over ICNNs,[0],[0]
"In particular, they show that any convex function over a compact domain can be approximated in sup norm by a ICNN to the desired accuracy.",3.1. Minimax optimization over ICNNs,[0],[0]
"This justifies the choice of ICNNs as a suitable approximating class for the convex functions.
",3.1. Minimax optimization over ICNNs,[0],[0]
"The proposed framework for learning the optimal transport provides a novel training method for deep generative models, where (a) the generator is modeled as a gradient of a convex function and (b) the minimax optimization in (6) (and more concretely, Algorithm 1) provides the training methodology.",3.1. Minimax optimization over ICNNs,[0],[0]
"On the surface, Eq. (6) resembles the minimax optimization of generative adversarial networks based on Wasserstein-1
distance (Arjovsky et al., 2017), called WGAN.",3.1. Minimax optimization over ICNNs,[0],[0]
"However, there are several critical differences making our approach attractive.
",3.1. Minimax optimization over ICNNs,[0],[0]
"First, because WGANs use optimal transportation distance only as a measure of distance, the learned generator map from the latent source to the target is arbitrary and sensitive to the initialization (see Figure 4) (Jacob et al., 2018).",3.1. Minimax optimization over ICNNs,[0],[0]
"On the other hand, our proposed approach aims to find the optimal transport map and learns the same mapping regardless of the initialization (see Figure 1).
",3.1. Minimax optimization over ICNNs,[0],[0]
"Secondly, in a WGAN architecture (Arjovsky et al., 2017; Petzka et al., 2017), the transport map (which is the generator) is represented with neural network that is a continuous mapping.",3.1. Minimax optimization over ICNNs,[0],[0]
"Although, a discontinuous map can be approximated arbitrarily close with continuous neural networks, such a construction requires large weights making training unstable.",3.1. Minimax optimization over ICNNs,[0],[0]
"On the other hand, through our proposed method, by representing the transport map with gradient of a neural network (equipped with ReLU type activation functions), we obtain a naturally discontinuous map.",3.1. Minimax optimization over ICNNs,[0],[0]
"As a consequence we have sharp transition from one part of the support to the other, whereas GANs (including WGANs) suffer from spurious probability masses that are not present in the target.",3.1. Minimax optimization over ICNNs,[0],[0]
This is illustrated in Section 4.3.,3.1. Minimax optimization over ICNNs,[0],[0]
"The same holds for regularization-based methods for learning optimal transport (Genevay et al., 2016; Seguy et al., 2017; Leygonie et al., 2019), where transport map is parametrized by continuous neural nets.
",3.1. Minimax optimization over ICNNs,[0],[0]
Remark 3.5.,3.1. Minimax optimization over ICNNs,[0],[0]
"In a recent work, Taghvaei & Jalali (2019)
proposed to solve the semi-dual optimization problem (4) by representing the function f with an ICNN and learning it using a stochastic optimization algorithm.",3.1. Minimax optimization over ICNNs,[0],[0]
"However, each step of this algorithm requires computing the conjugate f∗ for all samples in the batch via solving a inner convex optimization problem for each sample which makes it slow and challenging to scale to large datasets.",3.1. Minimax optimization over ICNNs,[0],[0]
Further it is memory intensive as each inner optimization step requires a copy of all the samples in the dataset.,3.1. Minimax optimization over ICNNs,[0],[0]
"In contrast, we represent the convex conjugate f∗ using ICNN and present a novel minimax formulation to learn it, in a scalable manner.",3.1. Minimax optimization over ICNNs,[0],[0]
"Theorem 3.3 establishes the consistency of our proposed optimization: if the objective (5) is solved exactly with a pair of functions (f0, g0), then ∇g0 is the exact optimal transport map from Q to P .",3.2. Stability analysis of the learned transport map,[0],[0]
"In this section, we study the error in approximating the optimal transport map∇g0, when the objective (5) is solved up to a small error.",3.2. Stability analysis of the learned transport map,[0],[0]
"To this end, we build upon the recent results from Hütter & Rigollet (2019, Prop. 8) regarding the stability of optimal transport maps.
",3.2. Stability analysis of the learned transport map,[0],[0]
Recall that the optimization objective (5) involves a minimization and a maximization.,3.2. Stability analysis of the learned transport map,[0],[0]
"For any pair (f, g), let 1(f, g) denote the minimization gap and 2(g) denote the
maximization gap, defined according to:
1(f, g) = V(f, g)− inf g̃∈CVX(Q) V(f, g̃), (7)
2(f) = sup f̃∈CVX(P ) inf g̃∈CVX(Q) V(f̃ , g̃)− inf g̃∈CVX(Q) V(f, g̃)
",3.2. Stability analysis of the learned transport map,[0],[0]
"Then, the following theorem bounds the the error between ∇g and the optimal transport map ∇g0 as a function 1 and 2.",3.2. Stability analysis of the learned transport map,[0],[0]
"We defer its proof to Appendix B.
Theorem 3.6.",3.2. Stability analysis of the learned transport map,[0],[0]
Consider the optimization problem (5).,3.2. Stability analysis of the learned transport map,[0],[0]
Assume Q admits a density and let ∇g0(·) denote the optimal transport map from Q to P .,3.2. Stability analysis of the learned transport map,[0],[0]
"Then for any pair (f, g) such that f is α-strongly convex, we have
‖∇g −∇g0‖2L2(Q) ≤ 2
α ( 1(f, g) + 2(f)),
where 1 and 2 are defined in (7), and ‖ · ‖L2(Q) denotes the L2-norm with respect to measure Q.",3.2. Stability analysis of the learned transport map,[0],[0]
"In this section, first we qualitatively illustrate our proposed approach (see Figure 3) on the following two-dimensional synthetic datasets: (a) Checkerboard, (b) Mixture of eight Gaussians.",4. Experiments,[0],[0]
"We compare our method with the following three baselines: (i) Barycentric-OT (Seguy et al., 2017), (ii) W1-LP, which is the state-of-the-art Wasserstein GAN introduced by (Petzka et al., 2017), (iii) W2GAN (Leygonie et al., 2019).",4. Experiments,[0],[0]
"Note that while the goal of W1-LP is not to learn the optimal transport map, the generator obtained at the end of its training can be viewed as a transport map.",4. Experiments,[0],[0]
"For all these baselines, we use the implementations (publicly available) of Leygonie et al. (2019) which has the best set of parameters for each of these methods.",4. Experiments,[0],[0]
"In Section 4.2 and Section 4.3, we highlight the respective robustness and the discontinuity of our transport maps as opposed to other approaches.",4. Experiments,[0],[0]
"Finally, in Section 4.4, we show the effectiveness of our approach on the challenging task of learning the optimal transport map on a variety of synthetic and real world high-dimensional data.",4. Experiments,[0],[0]
"Full experimental details are provided in Appendix C.
Training methodology.",4. Experiments,[0],[0]
We utilize our minimax formulation in (6) to learn the optimal transport map.,4. Experiments,[0],[0]
We parametrize the convex functions f and g using the same ICNN architecture (Figure 2).,4. Experiments,[0],[0]
"Recall that to ensure convexity, we need to restrict all weights W`’s to be non-negative (Assumption (i) in ICNN).",4. Experiments,[0],[0]
"We enforce it strictly for f , as the maximization over g can be unbounded, making optimization unstable, whenever f is non-convex.",4. Experiments,[0],[0]
"However, we relax this constraint for g (as permitted according to Remark 3.4) and instead introduce a regularization term
R(θg) =",4. Experiments,[0],[0]
"λ ∑ Wl∈θg ‖max(−Wl, 0)‖2F , (8)
where λ > 0 is a regularization constant and the maximum is taken entry-wise for all the weight parameters {Wl} ⊂ θg.",4. Experiments,[0],[0]
"We empirically observe that this relaxation makes the optimization converge faster.
",4. Experiments,[0],[0]
"For both the maximization and minimization updates in (6), we use Adam (Kingma & Ba, 2014).",4. Experiments,[0],[0]
"At each iteration, we draw a batch of samples from P and Q denoted by {Xi}Mi=1 and {Yj}Mj=1 respectively.",4. Experiments,[0],[0]
"Then, we use the following objective for optimization which is an empirical counterpart of (6):
max θf :W`≥0,∀`∈[L−1] min θg J(θf , θg) +R(θg), (9)
where θf , θg are the parameters of f and g, respectively, W` ≥ 0 is an entry-wise constraint, and
J(θf , θg) = 1
M M∑ i=1",4. Experiments,[0],[0]
"f(∇g(Yi))− 〈Yi,∇g(Yi)〉 − f(Xi).
",4. Experiments,[0],[0]
This is summarized in Algorithm 1.,4. Experiments,[0],[0]
"In the remainder of the paper, we interchangeably refer to Algorithm 1 as either ‘Our approach’ or ‘Our algorithm’.
",4. Experiments,[0],[0]
Algorithm 1,4. Experiments,[0],[0]
"The numerical procedure to solve the optimization problem (9).
",4. Experiments,[0],[0]
Input: Source dist.,4. Experiments,[0],[0]
"Q, Target dist.",4. Experiments,[0],[0]
"P , Batch size M , Generator iterations K, Total iteratioins T for t = 1, . . .",4. Experiments,[0],[0]
", T do
Sample batch {Xi}Mi=1 ∼ P for k = 1, . . .",4. Experiments,[0],[0]
",K do
Sample batch {Yi}Mi=1 ∼ Q Update θg to minimize (9) using Adam method
end for Update θf to maximize (9) using Adam method Projection: w ← max(w, 0), for all w ∈ {W l} ∈",4. Experiments,[0],[0]
"θf
end for
Remark 4.1.",4. Experiments,[0],[0]
Note that the regularization term R(θg) is data-independent and does not introduce any bias to the optimization problem.,4. Experiments,[0],[0]
"For any convex function f , the minimizer of the problem (9) is still a convex function g as discussed in Remark 3.4.",4. Experiments,[0],[0]
We use this regularization to guide the algorithm towards neural networks that are convex.,4. Experiments,[0],[0]
"As highlighted in Figure 1 and Figure 3d, qualitatively, we observe that our proposed procedure indeed learns the optimal transport map on both the Checkerboard and Mixture of eight Gaussians datasets.",4.1. Learning the optimal transport map,[0],[0]
"In particular, our transport map is able to cut the continuous mass symmetrically and transport it to the nearest target support in both these examples.",4.1. Learning the optimal transport map,[0],[0]
"Also, Figure 3 illustrates the qualitative difference of our approach compared to other approaches, in terms of non-optimality
and existence of trailing dots.",4.1. Learning the optimal transport map,[0],[0]
"The existence of trailing dots is due to representing the transport map with continuous neural networks, discussed in Section 4.3.",4.1. Learning the optimal transport map,[0],[0]
"In this section we numerically illustrate that the generator in W1-LP and W2GAN finds arbitrary transport maps, and it is sensitive to initialization as discussed in Section 3.",4.2. Robustness of learning transport maps,[0],[0]
This is in stark contrast with our proposed approach which finds the optimal transport independent of the initialization.,4.2. Robustness of learning transport maps,[0],[0]
We consider the previous Checkerboard example (Figure 1a) and train W1-LP and W2GAN with different random initializations.,4.2. Robustness of learning transport maps,[0],[0]
"The resulting transport maps for two different random trials are depicted in Figure 4a and Figure 4b for W1-LP, and Figure 4c and Figure 4d for W2-GAN.",4.2. Robustness of learning transport maps,[0],[0]
"In addition to the fact that the learned transport map is very sensitive to initializations, the quality of the samples generated by thus trained models are also sensitive.",4.2. Robustness of learning transport maps,[0],[0]
"This is a major challenge in training GANs (Lin et al., 2018).",4.2. Robustness of learning transport maps,[0],[0]
"The power to represent a discontinuous transport mapping is what fundamentally sets our proposed method apart from the existing approaches, as discussed in Section 3.",4.3. Learning discontinuous transport maps,[0],[0]
"Two prominent approaches for learning transport maps are generative adversarial networks (Arjovsky et al., 2017; Petzka et al., 2017) and regularized optimal transport (Genevay et al., 2016; Seguy et al., 2017).",4.3. Learning discontinuous transport maps,[0],[0]
"In both cases, the transport map is modeled by a standard neural network with finite depth and width, which is a continuous function.",4.3. Learning discontinuous transport maps,[0],[0]
"As a consequence, continuous transport maps suffer from unintended and undesired spurious probability mass that connects disjoint supports of the target probability distribution.
",4.3. Learning discontinuous transport maps,[0],[0]
"First, standard GANs including the original GAN (Goodfellow et al., 2014) and variants of WGAN (Arjovsky et al., 2017; Gulrajani et al., 2017; Wei et al., 2018) all suffer from spurious probability masses.",4.3. Learning discontinuous transport maps,[0],[0]
"Even those designed to tackle such spurious probability masses, like PacGAN (Lin et al., 2018), cannot overcome the barrier of continuous
neural networks.",4.3. Learning discontinuous transport maps,[0],[0]
"This suggests that fundamental change in the architecture, like the one we propose, is necessary.",4.3. Learning discontinuous transport maps,[0],[0]
Figure 3b illustrates the same scenario for the transport map learned through the WGAN framework.,4.3. Learning discontinuous transport maps,[0],[0]
"We can observe the trailing dots of spurious probability masses, resulting from undesired continuity of the learned transport maps.
",4.3. Learning discontinuous transport maps,[0],[0]
"Similarly, regularization methods to approximate optimal transport maps, explained in Section 2, suffer from the same phenomenon.",4.3. Learning discontinuous transport maps,[0],[0]
Representing a transport map with an inherently continuous function class results in spurious probability masses connecting disjoint supports.,4.3. Learning discontinuous transport maps,[0],[0]
"Figure 3a, corresponding to Barycentric-OT, illustrates those trailing dots of spurious masses for the learned transport map from algorithm introduced in Seguy et al. (2017).",4.3. Learning discontinuous transport maps,[0],[0]
"We also observe a similar phenomenon with Leygonie et al. (2019) as illustrated in Figure 3c.
",4.3. Learning discontinuous transport maps,[0],[0]
"On the other hand, we represent the transport map with the gradient of a neural network (equipped with non-smooth ReLU type activation functions).",4.3. Learning discontinuous transport maps,[0],[0]
"The resulting transport map can naturally represent discontinuous transport maps, as illustrated in Figure 1b and Figure 3d.",4.3. Learning discontinuous transport maps,[0],[0]
The vector field of the learned transport map in Figure 1c clearly shows the discontinuity of the learned optimal transport.,4.3. Learning discontinuous transport maps,[0],[0]
We consider the challenging task of learning optimal transport maps on high dimensional distributions.,4.4. High dimensional experiments,[0],[0]
"In particular, we consider both synthetic and real world high dimensional datasets and provide quantitative and qualitative illustration of the performance of our proposed approach.
",4.4. High dimensional experiments,[0],[0]
Gaussian to Gaussian.,4.4. High dimensional experiments,[0],[0]
"Source distribution Q = N (0, Id) and target distribution P = N (µ, Id), for some fixed µ ∈ Rd and d = 784.",4.4. High dimensional experiments,[0],[0]
"The mean vector µ = α(1, . .",4.4. High dimensional experiments,[0],[0]
.,4.4. High dimensional experiments,[0],[0]
", 1)> for some parameter α > 0.",4.4. High dimensional experiments,[0],[0]
"Because both distributions are Gaussian, the optimal transport map is explicitly known: T ∗(x) = x+ µ and hence W 22 (P,Q) = ‖µ‖2/2 = α2d/2.",4.4. High dimensional experiments,[0],[0]
"In Figure 5a, we compare our estimated distance W̃ 22 (P,Q), defined in (6), with the exact value W 22 (P,Q), as the training progresses for various values of α ∈ {1, 5, 10}.",4.4. High dimensional experiments,[0],[0]
"Intu-
itively, learning is more challenging when α is larger.",4.4. High dimensional experiments,[0],[0]
"Further, error in learning the optimal transport map, quantified with the metric ‖µT (Q) − µ‖2, where µT (Q) is the mean of the transported distribution T#Q, is reported in Table 1.
High-dim.",4.4. High dimensional experiments,[0],[0]
Gaussian to low-dim.,4.4. High dimensional experiments,[0],[0]
mixture.,4.4. High dimensional experiments,[0],[0]
"Source distribution Q is standard Gaussian N (0, Id) with d = 784, and the target distribution P is a mixture of four Gaussians that lie in in the two-dimensional subspace of the highdimensional space Rd, i.e. the first two components of the random vector X ∼ P is mixture of four Gaussians, and the rest of the components are zero.",4.4. High dimensional experiments,[0],[0]
The projection of the learned optimal transport map onto the first four components is depicted in Figure 5b.,4.4. High dimensional experiments,[0],[0]
"As illustrated in the left panel of 5b, our transport map correctly maps the source distribution to the mixture of four Gaussians in the first two components.",4.4. High dimensional experiments,[0],[0]
"And it maps the rest of the components to zero, as highlighted by a red blob at zero in the right panel.
",4.4. High dimensional experiments,[0],[0]
"MNIST {0, 1, 2, 3, 4} to MNIST {5, 6, 7, 8, 9}.",4.4. High dimensional experiments,[0],[0]
"We consider the standard MNIST dataset (LeCun et al., 1998) with the goal of learning the optimal transport map from the set of images corresponding to first five digits {0, 1, 2, 3, 4} to the last five digits {5, 6, 7, 8, 9}.",4.4. High dimensional experiments,[0],[0]
"To achieve this, we embed the images into the a space where the Euclidean norm ‖ · ‖ between the embedded images is meaningful.",4.4. High dimensional experiments,[0],[0]
"This is in alignment with the reported results in the literature for learning the L2-optimal transport map (Yang & Karniadakis, 2019, Sec. 4.1).",4.4. High dimensional experiments,[0],[0]
We consider the embeddings into a 16-dimensional latent feature space given by a pre-trained Variational Autoencoder (VAE).,4.4. High dimensional experiments,[0],[0]
"We simulate our algorithm
on this feature space.",4.4. High dimensional experiments,[0],[0]
The results of the learned transport map are depicted in Figure 5.,4.4. High dimensional experiments,[0],[0]
Figure 5c presents samples from the source distribution and Figure 5d illustrates the source samples after transportation under the learned optimal transport map.,4.4. High dimensional experiments,[0],[0]
"We observe that the digits that look alike are coupled via the optimal transport map, e.g. 1→ 9, 2→ 8, and 4→ 9.
Gaussian to MNIST.",4.4. High dimensional experiments,[0],[0]
"The source is 16-dimensional standard Gaussian distribution, and the target is the 16- dimensional latent embeddings of all the MNIST digits.",4.4. High dimensional experiments,[0],[0]
"The MNIST like samples that are generated from the learned optimal transport map are depicted in Figure 6.
",4.4. High dimensional experiments,[0],[0]
These experiments serve as a proof of concept that the algorithm scales to high-dimensional setting and real-world dataset.,4.4. High dimensional experiments,[0],[0]
We believe that further improvements on the performance of the proposed algorithm requires careful tuning of hyper-parameters which takes time to develop (similar to initial WGAN) and is a subject of ongoing work.,4.4. High dimensional experiments,[0],[0]
We presented a novel minimax framework to learn the optimal transport map under W2-metric.,5. Conclusion,[0],[0]
"Our framework is
in contrast to regularization-based approaches, where the constraint of the dual Kantorovich problem is replaced with a penalty term.",5. Conclusion,[0],[0]
"Instead, we represent the dual functions with ICNN, so that the constraint is automatically satisfied.",5. Conclusion,[0],[0]
"Further, the transport map is expressed as gradient of a convex function, which is able to represent discontinuous maps.",5. Conclusion,[0],[0]
We believe that our framework paves way for bridging the optimal transport theory and practice.,5. Conclusion,[0],[0]
"Define Vf (g) , EQ[〈Y,∇g(Y )〉−f(∇g(Y ))",A. Proof of Theorem 3.3,[0],[0]
].,A. Proof of Theorem 3.3,[0],[0]
The main step of the proof is to show that supg∈CVX(Q),A. Proof of Theorem 3.3,[0],[0]
Vf (g) = EQ[f∗(Y )].,A. Proof of Theorem 3.3,[0],[0]
Then the conclusion follows from (4).,A. Proof of Theorem 3.3,[0],[0]
"To prove this, note that for all g ∈ CVX(Q), we have
〈y,∇g(y)〉 − f(∇g(y))",A. Proof of Theorem 3.3,[0],[0]
"≤ 〈y,∇f∗(y)〉 − f(∇f∗(y))",A. Proof of Theorem 3.3,[0],[0]
"= f∗(y),
for all y ∈ Rd such that g and f∗ are differentiable at y.",A. Proof of Theorem 3.3,[0],[0]
We now claim that both g and f∗ are differentiable Q-almost everywhere (a.e).,A. Proof of Theorem 3.3,[0],[0]
"If the claim is true, upon taking the expectation w.r.t Q:
Vf (g) ≤",A. Proof of Theorem 3.3,[0],[0]
"Vf (f∗) = EQ[f∗(Y )], ∀g ∈ CVX(Q) and the inequality is achieved with g = f∗.",A. Proof of Theorem 3.3,[0],[0]
"Now we prove the claim as follows: Since ∫ g dQ <∞, we haveQ(g =∞) = 0.",A. Proof of Theorem 3.3,[0],[0]
ThusQ(Dom(g)),A. Proof of Theorem 3.3,[0],[0]
"= 1, where Dom(g) is the domain of the function g. Moreover, Q(Int(Dom(g))",A. Proof of Theorem 3.3,[0],[0]
"= 1, where Int(·) denotes the interior, because the boundary hasQ-measure zero (Q has a density).",A. Proof of Theorem 3.3,[0],[0]
"Since g is convex, it is differentiable on Int(Dom(g))",A. Proof of Theorem 3.3,[0],[0]
except at points of Lebesgue measure zero which have Q-measure zero too.,A. Proof of Theorem 3.3,[0],[0]
"Therefore, g is Q-a.e differentiable.",A. Proof of Theorem 3.3,[0],[0]
Similar arguments hold for f∗.,A. Proof of Theorem 3.3,[0],[0]
"The proof follows from the bounds
‖∇g −∇f∗‖2L2(Q) ≤ 2
α 1, (10a)
",B. Proof of Theorem 3.6,[0],[0]
"‖∇f∗ −∇g0‖2L2(Q) ≤ 2
α 2, (10b)
and using the triangle inequality.",B. Proof of Theorem 3.6,[0],[0]
The proof for the first bound is as follows.,B. Proof of Theorem 3.6,[0],[0]
"If f is α-strongly convex, then f∗ is 1α smooth.",B. Proof of Theorem 3.6,[0],[0]
"By definition of smoothness,
f∗(z) ≤ f∗(y) + 〈∇f∗(y), z",B. Proof of Theorem 3.6,[0],[0]
− y〉+ 1 2α ‖z,B. Proof of Theorem 3.6,[0],[0]
"− y‖2 , hy(z), ∀y, z ∈ Rd,
where hy(z) is defined to be the quadratic function of z that appears on the right-hand side of the inequality.",B. Proof of Theorem 3.6,[0],[0]
"From f∗(z) ≤ hy(z), it follows that the convex conjugate f(x) ≥ h∗y(x).",B. Proof of Theorem 3.6,[0],[0]
"As a result,
f(x) ≥ h∗y(x) = −f∗(y) +",B. Proof of Theorem 3.6,[0],[0]
"〈y, x〉+ α
2 ‖x−∇f∗(y)‖2, ∀x, y ∈ Rd.",B. Proof of Theorem 3.6,[0],[0]
"(11)
We use this inequality to control the optimality gap 1(f, g):
1(f, g) = V(f, g)− inf g̃ V(f, g̃)
= V(f, g)− V(f, f∗) = EQ[f∗(Y )",B. Proof of Theorem 3.6,[0],[0]
"− 〈Y,∇g(Y )〉+ f(∇g(Y ))]",B. Proof of Theorem 3.6,[0],[0]
"≥ α 2 EQ[‖∇g(Y )−∇f∗(Y )‖2],
where the last step follows from (11), with x = ∇g(y).",B. Proof of Theorem 3.6,[0],[0]
This concludes the proof of the bound (10a).,B. Proof of Theorem 3.6,[0],[0]
It remains to prove (10b).,B. Proof of Theorem 3.6,[0],[0]
"To this end, note that the optimality gap 2(f) is given by
2(f) =",B. Proof of Theorem 3.6,[0],[0]
"V(f0, g0)− inf g̃ V(f, g̃)
= V(f0, f∗0 )− V(f, f∗) =",B. Proof of Theorem 3.6,[0],[0]
−(EP,B. Proof of Theorem 3.6,[0],[0]
[f0(X)],B. Proof of Theorem 3.6,[0],[0]
+ EQ[f∗0 (Y )]),B. Proof of Theorem 3.6,[0],[0]
+ (EP [f(X)] +,B. Proof of Theorem 3.6,[0],[0]
EQ[f∗(Y )]),B. Proof of Theorem 3.6,[0],[0]
= −EQ[f0(∇f∗0 (Y )),B. Proof of Theorem 3.6,[0],[0]
+,B. Proof of Theorem 3.6,[0],[0]
f∗0 (Y )],B. Proof of Theorem 3.6,[0],[0]
+ EQ[f(∇f∗0 (Y )),B. Proof of Theorem 3.6,[0],[0]
+ f∗(Y )],B. Proof of Theorem 3.6,[0],[0]
"= −EQ[〈Y,∇f∗0 (Y )〉] + EQ[f(∇f∗0 (Y ))",B. Proof of Theorem 3.6,[0],[0]
"+ f∗(Y )]
Using the inequality (11) with x = ∇f∗0 (y) yields:
2(f)",B. Proof of Theorem 3.6,[0],[0]
"≥ α
2 EQ[|∇f∗0 (Y )−∇f∗(Y )|2]
concluding (10b) noting that f∗0 = g0.",B. Proof of Theorem 3.6,[0],[0]
C.1.,C. Experimental set-up,[0],[0]
"Two-dimensional experiments
Datasets.",C. Experimental set-up,[0],[0]
"We use the following synthetic datasets: (i) Checkerboard, and (ii) Mixture of eight Gaussians.",C. Experimental set-up,[0],[0]
"For the Checkerboard dataset, the source distribution Q is the law of the random variable Y = X + Z, where X ∼ Unif({(0, 0), (1, 1), (1,−1), (−1, 1), (−1,−1)}) and Z ∼ Unif([−0.5, 0.5]",C. Experimental set-up,[0],[0]
×,C. Experimental set-up,[0],[0]
"[−0.5, 0.5]).",C. Experimental set-up,[0],[0]
"Similarly, P is the distribution of random variable Y = X + Z, where X ∼ Unif({(0, 1), (0,−1), (1, 0), (−1, 0)}) and Z ∼ Unif([−0.5, 0.5] ×",C. Experimental set-up,[0],[0]
"[−0.5, 0.5]).",C. Experimental set-up,[0],[0]
"Note that Unif(B) denotes the uniform distribution over any set B. For the mixture of eight Gaussians dataset, we have Q = N (0, I2) and P is the law of random variable Y , where Y = X + Z with X ∼ Unif({(1, 0), ( 1√
2 , 1√ 2 )}, (0, 1), (−1√ 2 , 1√ 2 ), (−1, 0), (−1√ 2 , −1√ 2 ), (0,−1), ( 1√ 2 , −1√ 2 )}) and Z ∼ N (0, 0.5I2).
",C. Experimental set-up,[0],[0]
Architecture details.,C. Experimental set-up,[0],[0]
"For our Algorithm 1, we parametrize both the convex functions f and g by ICNNs.",C. Experimental set-up,[0],[0]
Both these ICNN networks have equal number of nodes for all the hidden layers followed by a final output layer.,C. Experimental set-up,[0],[0]
"We choose a square of leaky ReLU function, i.e σ0(x) = (max(βx, x))
2 with a small positive constant β as the convex activation function for the first layer σ0.",C. Experimental set-up,[0],[0]
"For the remaining layers, we use the leaky ReLU function, i.e σl(x) = max(βx, x) for l = 1, . . .",C. Experimental set-up,[0],[0]
", L− 1, as the monotonically non-decreasing and convex activation function.",C. Experimental set-up,[0],[0]
Note that the assumptions (ii)-(iii) of the ICNN are satisfied.,C. Experimental set-up,[0],[0]
"In all of our experiments, we set the parameter β = 0.2.",C. Experimental set-up,[0],[0]
"In some of the experiments as explained below, we chose the SELU activation function which also obeys the convexity assumptions.
",C. Experimental set-up,[0],[0]
"For the three baselines, Barycentric-OT, W1-LP, and W2GAN, we use the implementations of Leygonie et al. (2019), made publicly available at https://github.com/jshe/wasserstein-2.",C. Experimental set-up,[0],[0]
"For all these methods, we use the default settings of hyperparameters which were fixed to be the best values from the respective papers.",C. Experimental set-up,[0],[0]
"Further, for a fair comparison we allow the number of parameters in each of these baselines to be larger than ours; in fact, for W2GAN and Barycentric-OT, the default number of neural network parameters is much larger than ours.
",C. Experimental set-up,[0],[0]
Hyperparameters.,C. Experimental set-up,[0],[0]
"For reproducibility, we provide the details of the numerical experiments for each of the figures.",C. Experimental set-up,[0],[0]
"For the Checkerboard dataset in Figure 3 (same as Figure 1), we run Algorithm 1 with the following parameters: For both the ICNNs f and g, we set the hidden size m = 64, number of layers L = 4, regularization constant λ = 1.0, Leaky ReLU activation and for training we use batch size M = 1024, learning rate 10−4, generator iterations K = 10, total number of iterations T = 105, and the Adam optimizer with β1 = 0.5, and β2 = 0.9.",C. Experimental set-up,[0],[0]
"For each of the baselines, the following are the values of the parameters: (a) Barycentric-OT: 3 (1 corresponding to the dual stage and the rest for the map step) neural networks each with m = 128, L = 3,M = 512, T = 2× 105 and l2-entropy penalty, (b) W1-LP: Both the discriminator and the generator neural networks with m = 128, L = 3,K = 5 and M = 512, T = 2× 105, and (c)",C. Experimental set-up,[0],[0]
W2GAN: 3 neural networks (1 corresponding to the generator whereas the remaining are for two functions in the dual formulation (3)),C. Experimental set-up,[0],[0]
"each with m = 128, L = 3,K = 5,M = 512, T = 2 × 105.",C. Experimental set-up,[0],[0]
W2GAN also uses six additional regularization terms which set to default values as provided in the code.,C. Experimental set-up,[0],[0]
"Also, all these baselines use ReLU activation and Adam optimizer with β1 = 0.9 and β2 = 0.990 and the learning rate for generator parameters being 0.0001 and 0.0005 for the rest.",C. Experimental set-up,[0],[0]
"For the mixture of eight Gaussians dataset, we use the same parameters except batch-size M = 256, whereas all the baselines use the same parameters as the above setting.",C. Experimental set-up,[0],[0]
"Also, for the multiple trials in Figure 4 for W1-LP and W2GAN, we use the above parameters but with a different random initialization of the neural network weights and biases.
",C. Experimental set-up,[0],[0]
C.2.,C. Experimental set-up,[0],[0]
"High dimensional experiments
Gaussian to Gaussian.",C. Experimental set-up,[0],[0]
"Source distribution Q = N (0, Id) and target distribution P = N (µ, Id), for some fixed µ ∈ Rd and d = 784.",C. Experimental set-up,[0],[0]
"The mean vector µ = α(1, . .",C. Experimental set-up,[0],[0]
.,C. Experimental set-up,[0],[0]
", 1)> with α ∈ {1, 5, 10}.",C. Experimental set-up,[0],[0]
"For both the ICNNs f and g, we have d = 784,m = 1024, L = 3, Leaky ReLU activation, batch size M = 60, K = 16, λ = 0.1, T = 40, 000, Adam optimizer with β1 = 0.5 and β2 = 0.99, learning rate decay by a factor of 0.5 for every 2, 000 iterations.",C. Experimental set-up,[0],[0]
"Note that in Figure 5a, 1 epoch corresponds to 1000 iterations.
",C. Experimental set-up,[0],[0]
High-dim.,C. Experimental set-up,[0],[0]
Gaussian to low-dim.,C. Experimental set-up,[0],[0]
mixture.,C. Experimental set-up,[0],[0]
"Source distribution Q = N (0, Id) with d = 784.",C. Experimental set-up,[0],[0]
The target distribution is a mixture of four Gaussians P = ∑4 i=1,C. Experimental set-up,[0],[0]
1,C. Experimental set-up,[0],[0]
"4N (µi,Σ), where µi = (±1.4,±1.4, 0, . . .",C. Experimental set-up,[0],[0]
", 0) ∈ R
784 and Σ = diag(0.2, 0.2, 0, . . .",C. Experimental set-up,[0],[0]
", 0).",C. Experimental set-up,[0],[0]
"For both the ICNNs f and g, we have d = 784,m = 1024, L = 3, Leaky ReLU activation, batch size M = 60, K = 25, λ = 0.01, Adam optimizer with β1 = 0.5 and β2 = 0.99, learning rate decay by a factor of 0.5 for every two epochs.",C. Experimental set-up,[0],[0]
"The algorithm is simulated for 30 epochs, where each epoch corresponds to 1000 iterations.
",C. Experimental set-up,[0],[0]
"MNIST {0, 1, 2, 3, 4} to MNIST {5, 6, 7, 8, 9}.",C. Experimental set-up,[0],[0]
"To obtain the latent embeddings of the MNIST dataset, we first train a VAE with both the encoder and decoder having 3 hidden layers with 256 neurons and the size of latent vector being 16 dimensional.",C. Experimental set-up,[0],[0]
"We then use ICNNs f and g to learn the optimal transport between the embeddings of digits {0, 1, 2, 3, 4} to that of {5, 6, 7, 8, 9}.",C. Experimental set-up,[0],[0]
"For both these ICNNs we have d = 16,m = 1024, L = 3, CELU activation, batch size = 128, K = 16, λ = 1, T = 100, 000, Adam optimizer with β1 = 0.9 and β2 = 0.99, learning rate decay by a factor of 0.5 for every 4, 000 iterations.
",C. Experimental set-up,[0],[0]
Gaussian to MNIST.,C. Experimental set-up,[0],[0]
"To obtain the latent embeddings for the MNIST, we use the same pre-trained VAE models as above.",C. Experimental set-up,[0],[0]
"Also we use the same hyperparameter settings as that of the “MNIST {0, 1, 2, 3, 4} to MNIST {5, 6, 7, 8, 9}"" experiment with the only change of batch size being 64.",C. Experimental set-up,[0],[0]
"The idea of solving the semi-dual optimization problem (4) is classically considered in (Chartrand et al., 2009), where the authors derive a formula for the functional derivative of the objective function with respect to f and propose to solve the optimization problem with the gradient descent method.",D. Further discussion of related work,[0],[0]
"Their approach is based on the discretization of the space and knowledge of the explicit form of the probability density functions, that is not applicable to real-world high dimensional problems.
",D. Further discussion of related work,[0],[0]
"More recently, the authors in (Lei et al., 2017; Guo et al., 2019) propose to learn the function f in a semi-discrete setting, where one of the marginals is assumed to be a discrete distribution supported on a set of N points {y1, . . .",D. Further discussion of related work,[0],[0]
", yN} ⊂ Rd, and the other marginal is assumed to have a continuous density with compact convex support Ω ⊂",D. Further discussion of related work,[0],[0]
Rd.,D. Further discussion of related work,[0],[0]
They show that the problem of learning the function f is similar to the variational formulation of the Alexandrov problem: constructing a convex polytope with prescribed face normals and volumes.,D. Further discussion of related work,[0],[0]
"Moreover, they show that, in the semi-distrete setting, the optimal f is of the form f(x) = max1≤i≤1{〈x, yi〉+ bi} and simplify the problem of learning f to the problem learning N real numbers bi ∈ R.",D. Further discussion of related work,[0],[0]
"However, the objective function involves computing polygonal partition of Ω into N convex cells, induced by the function f , which is computationally challenging.",D. Further discussion of related work,[0],[0]
"Moreover, the learned optimal transport map∇f , transports the probability distribution from each convex cell to a single point yi, which results in generalization issues.",D. Further discussion of related work,[0],[0]
"Additionally, the proposed approach is semi-discrete, and as a result, does not scale with the number of samples.
",D. Further discussion of related work,[0],[0]
"Statistical analysis of learning the optimal transport map through the semi-dual optimization problem (4) is studied in (Hütter & Rigollet, 2019; Rigollet & Weed, 2018), where the authors establish a minimax convergence rate with respect to number of samples for certain classes of regular probability distributions.",D. Further discussion of related work,[0],[0]
"They also propose a procedure that achieves the optimal convergence rate, that involves representing the function f with span of wavelet basis functions up to a certain order, and also requiring the function f to be convex.",D. Further discussion of related work,[0],[0]
"However, they do not provide a computational algorithm to implement the procedure.
",D. Further discussion of related work,[0],[0]
There are also other alternative approaches to approximate the optimal transport map that are not based on solving the semi-dual optimization problem (4).,D. Further discussion of related work,[0],[0]
"In (Leygonie et al., 2019), the authors propose to approximate the optimal transport map, through an adversarial computational procedure, by considering the dual optimization problem (3), and replacing the constraint with a quadratic penalty term.",D. Further discussion of related work,[0],[0]
"However, in contrast to the other regularization-based approaches such as (Seguy et al., 2017), they consider a GAN architecture, and propose to take the generator, after the training is finished, as the optimal transport map.",D. Further discussion of related work,[0],[0]
"They also provide a theoretical justification for their proposal, however the theoretical justification is valid in an ideal setting where the generator has infinite capacity, the discriminator is optimal at each update step, and the cost is equal to the exact Wasserstein distance.",D. Further discussion of related work,[0],[0]
"These ideal conditions are far from being true in a practical setting.
",D. Further discussion of related work,[0],[0]
"Another approach, proposed in (Xie et al., 2019), is to learn the optimal coupling from primal formulation (2), instead of solving the dual problem (3).",D. Further discussion of related work,[0],[0]
"The approach involves representing the coupling with two generators that map a Gaussian random variable to Rd, and two discriminators to ensure the coupling satisfies the marginal constraints.",D. Further discussion of related work,[0],[0]
"Although, the proposed approach is attractive when an optimal transport map does not exists, it is computationally expensive because it involves learning four deep neural networks.",D. Further discussion of related work,[0],[0]
"Finally, a procedure is recently proposed to approximate the optimal transport map that is optimal only on a subspace projection instead of the entire space (Muzellec & Cuturi, 2019).",D. Further discussion of related work,[0],[0]
"This approach is inspired by the sliced Wasserstein distance method to approximate the Wasserstein distance (Rabin et al., 2011; Deshpande et al., 2018).",D. Further discussion of related work,[0],[0]
"However, selection of the subspace to project on is a non-trivial task, and optimally selecting the projection is an optimization over the Grassmann manifold which is computationally challenging.
",D. Further discussion of related work,[0],[0]
"In a recent work, Korotin et al. (2019) too model the convex conjugate function f∗ with an ICNN, denoted here by g, and a
penalty term of the form ‖∇f(∇g(y))− y‖2 is added to the semi-dual optimization (4).",D. Further discussion of related work,[0],[0]
The penalty term serves to ensure that∇g is inverse of∇f and hence g = f∗.,D. Further discussion of related work,[0],[0]
"The additional penalty term makes the problem non-convex, even in the infinite capacity case, where the function representation is not restricted.",D. Further discussion of related work,[0],[0]
"In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples.",abstractText,[0],[0]
"Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map.",abstractText,[0],[0]
"This involves learning two convex functions, by solving a novel minimax optimization.",abstractText,[0],[0]
"Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization.",abstractText,[0],[0]
Numerical experiments confirm the accuracy of the learned transport map.,abstractText,[0],[0]
Our approach can be readily used to train a deep generative model.,abstractText,[0],[0]
"When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model.",abstractText,[0],[0]
"Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity.",abstractText,[0],[0]
"As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks.",abstractText,[0],[0]
"Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous.",abstractText,[0],[0]
This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries.,abstractText,[0],[0]
Equal contribution.,abstractText,[0],[0]
Order decided by a coin flip.,abstractText,[0],[0]
"Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign.",abstractText,[0],[0]
"Department of Mechanical and Aerospace Engineering, University of California, Irvine.",abstractText,[0],[0]
"Department of Electrical Engineering, Princeton University, Allen School of Computer Science & Engineering, University of Washington.",abstractText,[0],[0]
"Correspondence to: Ashok <makkuva2@illinois.edu>, Amir <amirhoseintghv@gmail.com>.",abstractText,[0],[0]
"Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 108, 2020.",abstractText,[0],[0]
Copyright 2020 by the author(s).,abstractText,[0],[0]
Optimal transport mapping via input convex neural networks,title,[0],[0]
"As neural networks move into applications where the outcomes of human lives depend on their decisions, it is increasingly crucial that we are able to interpret the decisions they make.",1.1. The importance of interpretable machine learning,[0],[0]
"Indeed, the European Union is considering legislation with a clause that asserts that individuals have ’rights to explanation’, i.e. individuals should be able to understand how algorithms make decisions about them (Council of European Union, 2016).",1.1. The importance of interpretable machine learning,[0],[0]
"Example problem domains re-
*Equal contribution 1This work was performed as an intern at Google Brain 2Work done as a member of the Google Brain Residency program (g.co/brainresidency) 3Google Brain, Mountain View, CA, USA 4Work performed when author was a visiting faculty at Google Brain.",1.1. The importance of interpretable machine learning,[0],[0]
"Correspondence to: Jakob N. Foerster <jakob.foerster@cs.ox.ac.uk>, David Sussillo <sussillo@google.com>.
",1.1. The importance of interpretable machine learning,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1.1. The importance of interpretable machine learning,[0],[0]
"Copyright 2017 by the author(s).
",1.1. The importance of interpretable machine learning,[0],[0]
"quiring interpretable ML include self-driving cars (Bojarski et al., 2016), air traffic control (Katz et al., 2017), power grid control (Siano et al., 2012), hiring and promotion decisions while preventing bias (Scarborough & Somers, 2006), automated sentencing decisions in US courts (Tashea, 2017; Berk et al., 2017), and medical diagnosis (Gulshan et al., 2016).",1.1. The importance of interpretable machine learning,[0],[0]
"For many of these applications, practitioners will not adopt ML models without fully understanding what drives their predictions, including understanding when and how these models fail (Ching et al., 2017; Deo, 2015).",1.1. The importance of interpretable machine learning,[0],[0]
"One approach to interpreting neural networks is to train the network as normal, and then apply analysis techniques after training.",1.2. Post hoc analysis,[0],[0]
"Often this approach yields systems that perform extremely well, but where interpretability is challenging.",1.2. Post hoc analysis,[0],[0]
"For example, Sussillo & Barak (2013) used linearization and nonlinear dynamical systems theory to understand RNNs solving a set of simple but varied tasks.",1.2. Post hoc analysis,[0],[0]
"Karpathy et al. (2015) analyzed an LSTM (Hochreiter & Schmidhuber, 1997) trained on a character-based language modeling task.",1.2. Post hoc analysis,[0],[0]
"They were able to break down LSTM language model errors into classes, such as e.g., “rare word” errors.",1.2. Post hoc analysis,[0],[0]
"Concurrently with our submission, Murdoch & Szlam (2017) decomposed LSTM outputs using telescoping sums of statistics computed from memory cells at different RNN steps.",1.2. Post hoc analysis,[0],[0]
"The decomposition is exact, but not unique and the authors justify it by demonstrating good performance of decision rules formed using the computed cell statistics.
",1.2. Post hoc analysis,[0],[0]
The community is also interested in post hoc interpretation of feed-forward networks.,1.2. Post hoc analysis,[0],[0]
"Examples include the use of linear probes in Alain & Bengio (2016), and a variety of techniques (most driven by back-propagation) to assign credit for activations to specific inputs or input patterns in feed-forward networks (Zeiler et al., 2010; Le et al., 2012; Mordvintsev et al., 2015).",1.2. Post hoc analysis,[0],[0]
A second approach is to build a neural network where interpretability is an explicit design constraint.,1.3. Building interpretability into the architecture,[0],[0]
"In this approach, a typical outcome is a system that can be better understood, but at the cost of reduced performance.",1.3. Building interpretability into the architecture,[0],[0]
"Model classes whose
decisions are naturally interpretable include logistic regression (Freedman, 2009), decision trees (Quinlan, 1987), and support vector machines with simple (e.g. linear) kernels (Andrew, 2013).
",1.3. Building interpretability into the architecture,[0],[0]
"In this work we follow this second approach and build interpretability into our network model, while maintaining good, though not always state-of-the-art, performance for the tasks we study.",1.3. Building interpretability into the architecture,[0],[0]
We focus on the commonly studied task of character based language modeling.,1.3. Building interpretability into the architecture,[0],[0]
"We develop and analyze a model trained on a one-step-ahead prediction task of the Text8 dataset, which is 10 million characters of Wikipedia text (Mahoney, 2011), on the Billion Word Benchmark (Chelba et al., 2013), and finally on a toy multiple parentheses counting task which we fully reverse engineer.",1.3. Building interpretability into the architecture,[0],[0]
"The model we introduce is an Input Switched Affine Network (ISAN), where the input determines the switching behavior by selecting a transition matrix and bias as a function of that input, and there is no nonlinearity.",1.4. Switched affine systems,[0],[0]
"Linear timevarying systems are standard material in undergraduate electrical engineering text books, and are closely related to our technique.
",1.4. Switched affine systems,[0],[0]
"Although the ISAN is deterministic, probabilistic versions of switching linear models with discrete latent variables have a history in the context of probabilistic graphical models.",1.4. Switched affine systems,[0],[0]
"A recent example is the switched linear dynamical system in (Linderman et al., 2016).",1.4. Switched affine systems,[0],[0]
"Focusing on language modeling, (Belanger & Kakade, 2015) defined a probabilistic linear dynamical system (LDS) as a generative language model for creating context-dependent token embeddings and then used steady-state Kalman filtering for inference over token sequences.",1.4. Switched affine systems,[0],[0]
They used singular value decomposition and discovered that the right and left singular vectors were semantically and syntactically related.,1.4. Switched affine systems,[0],[0]
"A critical difference between the ISAN and the LDS is that the ISAN weight matrices are input token dependent (while the biases of both models are input dependent).
",1.4. Switched affine systems,[0],[0]
"Multiplicative neural networks (MRNNs) were proposed precisely for character based language modeling in (Sutskever et al., 2011; Martens & Sutskever, 2011).",1.4. Switched affine systems,[0],[0]
"The MRNN architecture is similar to our own, in that the dynamics matrix switches as a function of the input character.",1.4. Switched affine systems,[0],[0]
"However, the MRNN relied on a tanh nonlinearity, while the ISAN is explicitly linear.",1.4. Switched affine systems,[0],[0]
"It is this property of our model which makes it both amenable to analysis, and computationally efficient.
",1.4. Switched affine systems,[0],[0]
"The Observable Operator Model (OOM) (Jaeger, 2000) is similar to the ISAN in that the OOM updates a latent state using a separate transition matrix for each input symbol
and performs probabilistic sequence modeling.",1.4. Switched affine systems,[0],[0]
"Unlike the ISAN, the OOM requires that a linear projection of the hidden state corresponds to a normalized sequence probability.",1.4. Switched affine systems,[0],[0]
"This imposes strong constraints on both the model parameters and the model dynamics, and restricts the choice of training algorithms.",1.4. Switched affine systems,[0],[0]
"In contrast, the ISAN applies an affine readout to the hidden state to obtain logits, which are then pushed through the softmax function to obtain probabilities.",1.4. Switched affine systems,[0],[0]
Therefore no constraints need to be imposed on the ISAN’s parameters and training is easy using backprop.,1.4. Switched affine systems,[0],[0]
"Lastly, the ISAN is formulated as an affine, rather than linear model.",1.4. Switched affine systems,[0],[0]
"While this doesn’t change the class of processes that can be modeled, it stabilizes training and greatly enhances interpretability, facilitating the analysis in Section 3.3.",1.4. Switched affine systems,[0],[0]
"In what follows, we define the ISAN architecture, demonstrate its performance on the one-step-ahead prediction task, and then analyze the model in a multitude of ways, most of which would be currently difficult or impossible to accomplish with modern nonlinear recurrent architectures.",1.5. Paper structure,[0],[0]
"In what follows Wx and bx respectively denote a transition matrix and a bias vector for a specific input x, the symbol xt is the input at time t, and ht is the hidden state at time t. Our ISAN model is defined as
ht = Wxt ht−1 + bxt .",2.1. Model definition,[0],[0]
"(1)
The network also learns an initial hidden state h0.",2.1. Model definition,[0],[0]
We emphasize the intentional absence of any nonlinear activation function.,2.1. Model definition,[0],[0]
"We trained RNNs on the Text8 Wikipedia dataset and the billion word benchmark (BWB), for one-step-ahead character prediction.",2.2. Character level language modeling with ISAN,[0],[0]
The Text8 dataset consists only of the 27 characters ‘a’-‘z’ and ‘_’ (space).,2.2. Character level language modeling with ISAN,[0],[0]
The BWB dataset consist of Unicode text and was modelled as a sequence of bytes (256 discrete tokens) that formed the UTF8-encoded data.,2.2. Character level language modeling with ISAN,[0],[0]
"Given a character sequence of x1, ...,xt, the RNNs are trained to minimize the cross-entropy between the true next character, and the output prediction.",2.2. Character level language modeling with ISAN,[0],[0]
"We map from the hidden state, ht, into a logit space via an affine map.",2.2. Character level language modeling with ISAN,[0],[0]
"The probabilities are computed as
p (xt+1) = softmax (lt) (2) lt = Wro ht + bro, (3)
where Wro and bro are the readout weights and biases, and lt is the logit vector.",2.2. Character level language modeling with ISAN,[0],[0]
"For the Text8 dataset, we split
the data into 90%, 5%, and 5% for train, validation, and test respectively, in line with (Mikolov et al., 2012).",2.2. Character level language modeling with ISAN,[0],[0]
"The network was trained with the same hyperparameter tuning infrastructure as in (Collins et al., 2016).",2.2. Character level language modeling with ISAN,[0],[0]
"For the BWB dataset, we used data splits and evaluation setup identical to (Józefowicz et al., 2016).",2.2. Character level language modeling with ISAN,[0],[0]
"Due to long experiment running times, we manually tuned the hyperparameters.",2.2. Character level language modeling with ISAN,[0],[0]
The results on Text8 are shown in Table 1.,3.1. ISAN performance on Text8 prediction,[0],[0]
"For the largest parameter count, the ISAN matches almost exactly the performance of all other nonlinear models with the same number of maximum parameters: RNN, IRNN, GRU, LSTM.",3.1. ISAN performance on Text8 prediction,[0],[0]
"However, we note that for small numbers of parameters the ISAN performs considerably worse than other architectures.",3.1. ISAN performance on Text8 prediction,[0],[0]
All analyses use ISAN trained with 1.28e6 maximum parameters (1.58 bpc cross entropy).,3.1. ISAN performance on Text8 prediction,[0],[0]
Samples of generated text from this model are relatively coherent.,3.1. ISAN performance on Text8 prediction,[0],[0]
"We show two examples, after priming with ""annual reve"", at inverse temperature of 1.5, and 2.0, respectively:
• “annual revenue and producer of the telecommunications and former communist action and saving its new state house of replicas and many practical persons” • “annual revenue seven five three million one nine nine eight the rest of the country in the united states and south africa new”.
",3.1. ISAN performance on Text8 prediction,[0],[0]
"As a preliminary, comparative analysis, we performed PCA on the state sequence over a large set of sequences for the vanilla RNN, GRU of varying sizes, and ISAN.",3.1. ISAN performance on Text8 prediction,[0],[0]
This is shown in Figure 1.,3.1. ISAN performance on Text8 prediction,[0],[0]
"The eigenvalue spectra, in log of variance explained, was significantly flatter for the ISAN than the other architectures.
",3.1. ISAN performance on Text8 prediction,[0],[0]
"We compared the ISAN performance to a fully linear RNN
without input switched dynamics.",3.1. ISAN performance on Text8 prediction,[0],[0]
"This achieves a crossentropy of 3.1 bits / char, independent of network size.",3.1. ISAN performance on Text8 prediction,[0],[0]
"This perplexity is only slightly better than that of a Naive Bayes model on the task, at 3.3 bits / char.",3.1. ISAN performance on Text8 prediction,[0],[0]
"The output probability of the fully linear network is a product of contributions from each previous character, as in Naive Bayes.",3.1. ISAN performance on Text8 prediction,[0],[0]
"Those factorial contributions are learned however, giving the non-switched affine network a slight advantage.",3.1. ISAN performance on Text8 prediction,[0],[0]
We also trained a fully linear network with a nonlinear readout.,3.1. ISAN performance on Text8 prediction,[0],[0]
"This achieves 2.15 bits / char, independent of network size.",3.1. ISAN performance on Text8 prediction,[0],[0]
"Both of these comparisons illustrate the importance of the input switched dynamics for achieving good results.
",3.1. ISAN performance on Text8 prediction,[0],[0]
"Lastly we also test to what extent the ISAN can deal with large dictionaries by running it on a byte-pair encoding of the text8 task, where the input dictionary consists of the 272 different possible character combinations.",3.1. ISAN performance on Text8 prediction,[0],[0]
We find that in this setup the LSTM consistently outperforms the ISAN for the same number of parameters.,3.1. ISAN performance on Text8 prediction,[0],[0]
"At 1.3m parameters the LSTM achieves a cross entropy of 3.4 bits / char-pair, while ISAN achieves 3.55.",3.1. ISAN performance on Text8 prediction,[0],[0]
One explanation for this finding is that the matrices in ISAN are 27 times smaller than the matrices of the LSTMs.,3.1. ISAN performance on Text8 prediction,[0],[0]
"For very large numbers of parameters the performance of any architecture saturates in the number of parameters, at which point the ISAN can ‘catch-up’ with more parameter efficient architectures like LSTMs.",3.1. ISAN performance on Text8 prediction,[0],[0]
We trained ISAN and LSTM models on the BWB dataset.,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
All networks were trained using asynchronous gradient descent using the Adagrad learning rule.,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
"Our best LSTM model reached 1.1 bits per character, which matches published results (Hwang & Sung, 2016).",3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
The LSTM model had one layer of 8192 LSTM units whose outputs were projected onto 1024 dimensions (44e6 parameters).,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
"Our best ISAN models reached 1.4 bits per character and used
512 hidden units, a reduced set of most common 70 input tokens and 256 output tokens (18e6 parameters).",3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
Increasing ISAN’s hidden layer size to 768 units (41e6 parameters) yielded a perplexity improvement to 1.36 bits/char.,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
Investigation of generated samples shows that the ISAN learned the distinction between lower- and upper-cased letters and is able to generate text which is coherent over short segments.,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
"To demonstrate sample variability we show continuations of the prompt ""The [Pp]ol"" generated using the ISAN:
• The Pol|ish pilgrims are as angry over the holiday trip • The Pol|ice Department subsequently slipped toward •",3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
The Pol|ice Federation has sought Helix also investors • The Pol|itico is in a tight crowd ever to moderated the •,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
The pol|itical scientist in the Red Shirt Romance cannot • The pol|icy for all Balanchine had formed when it set a •,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
The pol|l conducted when a suspected among Hispanic •,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
The pol|itical frenzy sparked primary care programs,3.2. ISAN performance on Billion Word Benchmark prediction,[0],[0]
"Analysis in this paper is carried out on the best-performing Text8 ISAN model, which has 1, 271, 619 parameters, corresponding to 216 hidden units, and 27 dynamics matrices Wx and biases bx.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
With ISAN we can analyze which factors were important in the past for determining the current character prediction.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Taking advantage of the linearity of the hidden state dynamics for any sequence of inputs, we decompose the current latent state ht into contributions originating from different
time points s in the history of the input:
ht = t∑ s=0
( t∏
s′=s+1
Wxs′ )",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"bxs , (4)
where the empty product when s+1 > t is 1 by convention, and bx0 = h0 is the learned initial hidden state.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Using this decomposition and the fact that matrix multiplication is a linear transformation we can also write the unnormalized logit-vector, lt, as a sum of terms linear in the biases,
lt = bro + t∑ s=0 κts (5)
κts = Wro
( t∏
s′=s+1
Wxs′ )",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"bxs , (6)
where κts is the contribution from time step s to the logits at time step t, and κtt = bxt .",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
For notational convenience we will sometimes replace the subscript s with the corresponding input character xs at step s when referring to κts.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"For example, κt‘q’ refers to the contribution from the character ‘q’ in a string.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Similarly, when discussing the summed contributions from a word or substring we will sometimes write κtword to mean the summed contributions of all the κ t s from
that source word.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"For example, ∑
s∈word κ t s – κ t ‘the’ refers
to the total contribution from the word ‘the’ to the logit.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"While in standard RNNs the nonlinearity causes interdependence of the bias terms across time steps, in the ISAN the bias terms contribute to the state as independent linear
terms that are propagated and transformed through time.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"We emphasize that κts includes the multiplicative contributions from the Wxs′ for s < s
′ ≤ t.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"It is however independent of prior inputs, xs′ for s′ < s.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
This is the main difference between the analysis we can carry out with the ISAN compared to a nonlinear RNN.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
In a general recurrent network the contribution of a specific character sequence will depend on the hidden state at the start of the sequence.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Due to the linearity of the dynamics, this dependency does not exist in the ISAN.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"In Figure 2 we show an example of how this decomposition allows us to understand why a particular prediction is made at a given point in time, and how previous characters influence the decoding.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"For example, the sequence ‘_annual_revenue_’ is processed by the ISAN: Starting with an all-zero hidden state, we use equation (6) to accumulate a sequence of κt‘_′ ,κ t ‘a′ ,κ t ‘n′ ,κ t ‘n′ , ....",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"We then used these values to understand the prediction of the network at some time t, by simple addition across the s index.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
We provide a detailed view of how past characters contribute to the logits predicting the next character in Figure 3.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
There are two competing options for the next letter in the word stem ‘reve’: either ‘revenue’ or ‘reverse’.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"We show that without the contributions from ‘_annual’ the most likely decoding of the character after the second ‘e’ is ‘r’ (to form ‘reverse’), while the contributions from ‘_annual’ tip the balance in favor of ‘n’, decoding to ‘revenue’.
",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Using ISAN, we can investigate information timescales in the network.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"For example, we investigated how quickly the contributions of κts decay as a function of t− s on average.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
Figure 4a shows that this contribution decays on two different exponential timescales.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"We hypothesize that the first time scale corresponds to the decay within a word, while the
next corresponds to the decay of information across words and sentences.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
We also show the relevance of the κts contributions to the decoding of characters at different positions in the word (Figure 4b).,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"For example, we observe that κt‘_’ makes important contributions to the prediction of the next character at time t. We show that using only the κt‘_’, the model can achieve a cross entropy of less than 1 bit / char when the position of the character is more than 3 letters from the beginning of the word.",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
"Finally, we link the norm-decay of κts to the importance of past characters for the decoding quality ( Figure 4c).",3.3. Decomposition of current predictions based on previous time steps,[0],[0]
By artificially limiting the number of past κ available for prediction we show that the prediction quality improves rapidly when extending the history from 0 to 10 characters and then saturates.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
This rapid improvement aligns with the range of faster decay in Figure 4a.,3.3. Decomposition of current predictions based on previous time steps,[0],[0]
The ISAN provides a natural means of moving from character level representation to word level.,3.4. From characters to words,[0],[0]
Using the linearity of the hidden state dynamics we can aggregate all of the κts belonging to a given word and visualize them as a single contribution to the prediction of the letters in the next word.,3.4. From characters to words,[0],[0]
This allows us to understand how each preceding word impacts the decoding for the letters of later words.,3.4. From characters to words,[0],[0]
In Figure 5 we show that the words ‘was’ and ‘higher’ make large contributions to the prediction of the characters in ‘than’ as measured by the norm of the κt‘_was’ and κ t ‘_higher’.,3.4. From characters to words,[0],[0]
"We are free to perform a change of basis on the hidden state, and then to run the affine ISAN dynamics in that new basis.",3.5. Change of basis,[0],[0]
"Note that this change of basis is not possible for other RNN architectures, since the action of the nonlinearity depends on the choice of basis.
",3.5. Change of basis,[0],[0]
"In particular we can construct a ‘readout basis’ that explicitly divides the latent space into a subspace Pro‖ spanned by the rows of the readout matrix Wro, and its orthogonal complement Pro⊥ .",3.5. Change of basis,[0],[0]
"This representation explicitly divides the hidden state dynamics into a 27-dimensional ‘readout’ subspace that is accessed by the readout matrix to make predictions, and a ‘computational’ subspace comprising the remaining 216− 27 dimensions that are orthogonal to the readout matrix.
",3.5. Change of basis,[0],[0]
We apply this change of basis to analyze an intriguing observation about the hidden offsets bx.,3.5. Change of basis,[0],[0]
"As shown in Figure 6, the norm of the bx is strongly correlated to the log-probability of the unigram x in the training data.",3.5. Change of basis,[0],[0]
Reexpressing network parameters using the ‘readout basis’ shows that this correlation is not related to reading out the next-step prediction.,3.5. Change of basis,[0],[0]
"This is because the norm of the projection of bx into Pro⊥ remains strongly correlated with character frequency, while the projection into Pro‖ shows little correlation.",3.5. Change of basis,[0],[0]
"This indicates that the information content or ’surprise’ of a letter is encoded through the norm of the
component of bx in the computational space, rather than in the readout space.
",3.5. Change of basis,[0],[0]
"Similarly, in Figure 7 we illustrate that the structure in the correlations between the biases bx (across all x) is due to their components in Pro‖ , while the correlation in P ro ⊥ is relatively uniform.",3.5. Change of basis,[0],[0]
"We can clearly see two blocks of high correlations between the vowels and consonants respectively, while b‘_’ is uncorrelated to either.
3.6.",3.5. Change of basis,[0],[0]
"Comparison with n-gram model with back-off
We compared the computation performed by n-gram language models and those performed by the ISAN.",3.5. Change of basis,[0],[0]
"An n-gram model with back-off weights expresses the conditional probability p (xt|x1...xt−1) as a sum of smoothed count ratios of n-grams of different lengths, with the contribution of shorter n-grams down-weighted by back-off weights.",3.5. Change of basis,[0],[0]
"On the other hand, the computations performed by the ISAN start with the contribution of bro to the logits, which as shown in Fig-
ure 8a, corresponds to the unigram log-probabilities.",3.5. Change of basis,[0],[0]
"The logits are then additively updated with contributions from longer n-grams, represented by κts.",3.5. Change of basis,[0],[0]
This additive contribution to the logits corresponds to a multiplicative modification of the emission probabilities from histories of different length.,3.5. Change of basis,[0],[0]
"For long time lags, the additive correction to logprobabilities becomes small (Figure 2), which corresponds to multiplication by a uniform distribution.",3.5. Change of basis,[0],[0]
"Despite these differences in how n-gram history is incorporated, we nevertheless observe an agreement between empirical models estimated on the training set and model predictions for unigrams and bigrams.",3.5. Change of basis,[0],[0]
"Figure 8 shows that the bias term bro gives the unigram probabilities of letters, while the addition of the offset terms bx accurately predict the bigram distribution of P (xt+1|xt).",3.5. Change of basis,[0],[0]
"Shown in panel b is an example, P (x|‘_′), and in panel c, a summary plot for all 27 letters.
",3.5. Change of basis,[0],[0]
"We further explore the n-gram comparison by artificially limiting the length of the character history that is available to the ISAN for making predictions, as shown in Figure 4c).",3.5. Change of basis,[0],[0]
To show the possibility of complete interpretability of the ISAN we train a model on a parenthesis counting task.,4. Analyses of a parentheses counting task,[0],[0]
"Bringing together ideas from section 3.5 we re-express the transition dynamics in a new basis that fully reveals performed computations.
",4. Analyses of a parentheses counting task,[0],[0]
"We analyze the task of counting the nesting levels of multiple parentheses types, a simplified version of a task defined in (Collins et al., 2016).",4. Analyses of a parentheses counting task,[0],[0]
"Briefly, a 35-unit ISAN is required to keep track of the nesting level of 2 different types of parentheses independently.",4. Analyses of a parentheses counting task,[0],[0]
"The inputs are the one-hot encoding of the different opening and closing parentheses (e.g. ‘(’, ‘)’, ‘[’, ‘]’) as well as a noise character (‘a’).",4. Analyses of a parentheses counting task,[0],[0]
"The output is the one-hot encoding of the nesting level between (0-5), one set of counts for each parenthesis type (so the complete output vector is a 12 dimensional 2-hot vector).",4. Analyses of a parentheses counting task,[0],[0]
"Furthermore, the target output is the nesting level at the previous time step.",4. Analyses of a parentheses counting task,[0],[0]
This artificial delay requires the model to develop a memory.,4. Analyses of a parentheses counting task,[0],[0]
"One change from (Collins et al., 2016) is that we exchange the cross-entropy error with an L2 error.",4. Analyses of a parentheses counting task,[0],[0]
"This leads to slightly cleaner figures, but does not qualitatively change the results.
",4. Analyses of a parentheses counting task,[0],[0]
"To elucidate the mechanism of ISAN’s operation we first reexpress the affine transitions ht+1 = Wht + b by their linear equivalents h′t+1 = W ′h′t, where W ′ =",4. Analyses of a parentheses counting task,[0],[0]
[W b;0T 1] and h′t =,4. Analyses of a parentheses counting task,[0],[0]
[ht; 1].,4. Analyses of a parentheses counting task,[0],[0]
"Next, we used linear regression to find a change of basis for which all augmented character matrices and the hidden states are sparse.",4. Analyses of a parentheses counting task,[0],[0]
To do this we construct the ‘readout’ (Pro‖ ) and ‘computational’ ( P ro ⊥ ) subspace decomposition as discussed in Section 3.5.,4. Analyses of a parentheses counting task,[0],[0]
"We choose a basis for Pro⊥ which makes the projections of the hidden
states into this computational subspace 2-hot vectors.",4. Analyses of a parentheses counting task,[0],[0]
"With this subspace decomposition, the hidden states and character matrices have the form
W′x = Wrrx Wrcx brxWcrx",4. Analyses of a parentheses counting task,[0],[0]
Wccx bcx 0,4. Analyses of a parentheses counting task,[0],[0]
"T 0T 1  h′t = hrthct 1  (7) and the update equation can be written as
h′t+1",4. Analyses of a parentheses counting task,[0],[0]
= W ′,4. Analyses of a parentheses counting task,[0],[0]
xh ′,4. Analyses of a parentheses counting task,[0],[0]
t = Wrrx hrt +Wrcx hct + brxWcrx,4. Analyses of a parentheses counting task,[0],[0]
hrt +Wccx hct + bcx 1  .,4. Analyses of a parentheses counting task,[0],[0]
"(8) Here hrt and h c t denote the readout and computational portions of ht, and Wrrx ,W cr x ,W rc x ,W cc x denote the readout to readout, readout to computation, computation to readout, and computation to computation blocks of the character matrix for character x, respectively.
",4. Analyses of a parentheses counting task,[0],[0]
In Figure 9d we show the hidden states in the rotated basis as a sequence of column vectors.,4. Analyses of a parentheses counting task,[0],[0]
The 35 dimensional hidden states are all 4-hot.,4. Analyses of a parentheses counting task,[0],[0]
We can treat them as a concatenation of a readout hrt and a computation h c t part.,4. Analyses of a parentheses counting task,[0],[0]
The 12-dimensional readout hrt corresponds to network’s output at time step t and encodes the counts from time step t,4. Analyses of a parentheses counting task,[0],[0]
− 1 as a 2-hot vector (one count per parenthesis type).,4. Analyses of a parentheses counting task,[0],[0]
"The computational space hct is 35 − 12 = 23 dimensional, and encodes the current counts as another 2-hot vector.",4. Analyses of a parentheses counting task,[0],[0]
Note that in this basis the ISAN effectively uses only 24 dimensions and the remaining 11 dimensions have no noticeable effect on the computation.,4. Analyses of a parentheses counting task,[0],[0]
In Figure 9c we show W′[ in the rotated basis.,4. Analyses of a parentheses counting task,[0],[0]
We see from the leftmost 12 columns that Wrr[ and W cr,4. Analyses of a parentheses counting task,[0],[0]
[ are both nearly 0.,4. Analyses of a parentheses counting task,[0],[0]
This means that hrt has no influence on ht+1.,4. Analyses of a parentheses counting task,[0],[0]
"Furthermore, the computation to readout block, Wrc[ , is
identity on the first 12 dimensions, effectively implementing the lagging output hrt = h c t−1.",4. Analyses of a parentheses counting task,[0],[0]
"The current counts are implemented as delay lines and identity sub-matrices in Wcc[ , which respectively has the effect of incrementing the count of ‘[’ by one, saturating at 5, and leaving the count of ’()’ parentheses fixed.",4. Analyses of a parentheses counting task,[0],[0]
"The matrices W],W(,W) behave analogously.",4. Analyses of a parentheses counting task,[0],[0]
"It is clear that this solution is general, in that retraining for increased numbers of parentheses types or an increased counting maximum, would have the analogous solution.",4. Analyses of a parentheses counting task,[0],[0]
In this paper we motivated an input-switched affine recurrent network for the purpose of interpretability.,5. Discussion,[0],[0]
"We showed that a switched affine architecture achieves the same performance as LSTMs on the Text8 dataset for the same number of maximum parameters, and reasonable performance on the BWB.",5. Discussion,[0],[0]
"We performed a series of analyses, demonstrating the ability to understand how inputs at one point in the input sequence affect the outputs later in the output sequence.",5. Discussion,[0],[0]
We showed further in the multiple parentheses counting task that the ISAN dynamics can be completely reverse engineered.,5. Discussion,[0],[0]
"In summary, this work provides evidence that the ISAN is able to express complex dynamical systems, yet its operation can in principle be fully understood, a prospect that remains out of reach for many popular recurrent architectures.",5. Discussion,[0],[0]
Switched affine networks hold the potential to be massively more computationally and memory efficient for text processing than other recurrent architectures.,5.1. Computational benefits,[0],[0]
"First, input-dependent affine transitions reduce the number of parameters used at every step.",5.1. Computational benefits,[0],[0]
"For K possible inputs and N parameters, the computational cost per update step is O ( N K ) , a factor of K speedup over non-switched architectures.",5.1. Computational benefits,[0],[0]
"Similarly, the
number of hidden units is O (√
N K
) , a factor of K 1 2 mem-
ory improvement for storage of the latent state.
",5.1. Computational benefits,[0],[0]
"Furthermore, the ISAN is unique in its ability to precompute affine transformations corresponding to input strings.",5.1. Computational benefits,[0],[0]
This is possible because the composition of affine transformations is also an affine transformation.,5.1. Computational benefits,[0],[0]
"This property is used in Section 3.4 to evaluate the linear contributions of words, rather than characters.",5.1. Computational benefits,[0],[0]
This means that the hidden state update corresponding to an entire input sequence can be computed with identical cost to the update for a single character (plus the dictionary look-up cost for the composed transformation).,5.1. Computational benefits,[0],[0]
"ISAN can therefore achieve very large speedups on input processing, at the cost of increased memory use, by accumulating large look-up tables of the Wx and bx corresponding to common input sequences.",5.1. Computational benefits,[0],[0]
"Of course, practical implementations will have to incorporate
complexities of memory management, batching, etc.",5.1. Computational benefits,[0],[0]
There are some obvious future directions to this work.,5.2. Future work,[0],[0]
"Currently, we define switching behavior using an input set with finite and manageable cardinality.",5.2. Future work,[0],[0]
Studying word-level language models with enormous vocabularies may require some additional logic to scale.,5.2. Future work,[0],[0]
"Another idea is to build a language model that switches on bigrams or trigrams, rather than characters or words, targeting an intermediate number of affine transformations.",5.2. Future work,[0],[0]
Adapting this model to continuous-valued inputs is another important direction.,5.2. Future work,[0],[0]
"One approach is to use a tensor factorization similar to that employed by the MRNN (Sutskever et al., 2014) or defining weights via additional networks, as in HyperNetworks (Ha et al., 2016).",5.2. Future work,[0],[0]
"Finally, we expect that automated methods for changing bases to enable sparse representations in the hidden state and dynamics matrices will be a particularly fruitful direction to pursue.",5.2. Future work,[0],[0]
"We would like to thank Jasmine Collins for her help and advice, and Quoc Le, David Ha and Mohammad Norouzi for helpful discussions.",Acknowledgements,[0],[0]
We would also like to thank Herbert Jaeger for insightful discussions regarding the ObservableOperator-Model.,Acknowledgements,[0],[0]
There exist many problem domains where the interpretability of neural network models is essential for deployment.,abstractText,[0],[0]
"Here we introduce a recurrent architecture composed of input-switched affine transformations – in other words an RNN without any explicit nonlinearities, but with inputdependent recurrent weights.",abstractText,[0],[0]
"This simple form allows the RNN to be analyzed via straightforward linear methods: we can exactly characterize the linear contribution of each input to the model predictions; we can use a change-of-basis to disentangle input, output, and computational hidden unit subspaces; we can fully reverse-engineer the architecture’s solution to a simple task.",abstractText,[0],[0]
"Despite this ease of interpretation, the input switched affine network achieves reasonable performance on a text modeling tasks, and allows greater computational efficiency than networks with standard nonlinearities.",abstractText,[0],[0]
Input Switched Affine Networks: An RNN Architecture Designed for Interpretability,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2271–2277, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
Tree-to-tree machine translation models currently receive limited attention.,1 Introduction,[0],[0]
"However, we believe that using target-side syntax is important to achieve highquality translations between distant language pairs which require long range reorderings.",1 Introduction,[0],[0]
"Especially, using dependency trees on both source and target sides is promising for this purpose (Menezes and Quirk, 2007; Nakazawa and Kurohashi, 2010; Richardson et al., 2014).",1 Introduction,[0],[0]
"Tree-based translation models naturally realize word reorderings using the non-terminals or anchors for the attachment in the translation rules: therefore they do not need a re-
ordering model which string-based models require.",1 Introduction,[0],[0]
"For example, suppose we have a translation rule with the word alignment shown in Figure 1, it is easy to translate a new input sentence which has “図書館 (library)” instead of “公園 (park)” because we can accomplish it by simply substituting “library” for the target word “park” without considering the reordering.",1 Introduction,[0],[0]
"In this case, the source word “公園” and target word “park” work as the non-terminals.
",1 Introduction,[0],[0]
"On the other hand, it is problematic when we need to adjoin a subtree which is not presented in training sentences, which we call floating subtree in this paper.",1 Introduction,[0],[0]
"The floating subtrees are not necessarily adjuncts, but any words or phrases.",1 Introduction,[0],[0]
"For example, suppose the Japanese input sentence in Figure 1 has “ 突然 (suddenly)”, but the training corpus provides only a translation rule without the word.",1 Introduction,[0],[0]
In this case we cannot directly use the rule for the translation because it does not know where to insert the translation of the floating word in the output.,1 Introduction,[0],[0]
"As another example, there is no context information available for the children of the OOV word in the input sentence, so we need some special process to translate them.
",1 Introduction,[0],[0]
"Previous work deals with this problem by using glue rules (Chiang, 2005) or limiting the dependency structures to be well-formed (Shen et al., 2008).",1 Introduction,[0],[0]
Richardson et al. (2016) introduces the concept of flexible non-terminals.,1 Introduction,[0],[0]
It provides multiple possible insertion positions for the floating subtree rather than fixed insertion positions.,1 Introduction,[0],[0]
"A possible insertion position must satisfy the following conditions:
• it must be a child of the aligned word of the parent of the floating subtree
2271
• it must not violate the projectivity of the dependency tree
For example, possible insertion positions for the floating word “突然” are shown in gray arrows in Figure 1.",1 Introduction,[0],[0]
"Since “突然” is a child of “電話する”, and the translation of “電話する” is “called”, insertion positions must be a child of “called”.",1 Introduction,[0],[0]
"Also, insertion positions do not violate the projectivity of the target tree.",1 Introduction,[0],[0]
"Flexible non-terminals are analogous to the auxiliary tree of the tree adjoining grammars (TAG) (Joshi, 1985), which is successfully adopted in machine translation (DeNeefe and Knight, 2009).",1 Introduction,[0],[0]
"The difference is that TAG is defined on the constituency trees rather than the dependency trees.
",1 Introduction,[0],[0]
Flexible non-terminals are powerful to handle floating subtrees and it achieve better translation quality.,1 Introduction,[0],[0]
"However the computational cost of decoding becomes high even though they are compactly represented in the lattice form (Cromieres and Kurohashi, 2014).",1 Introduction,[0],[0]
"In our experiments, using flexible nonterminals causes the decoding to be 3 to 6 times slower than when they are not used.",1 Introduction,[0],[0]
Flexible nonterminals increase the number of translation rules because the insertion positions are selected during the decoding.,1 Introduction,[0],[0]
"However, we think it is possible to restrict possible insertion positions or even select only one insertion position by looking at the tree structures on both sides.
",1 Introduction,[0],[0]
"In this paper, we propose a method to select the appropriate insertion position before decoding.",1 Introduction,[0],[0]
This can not only reduce the decoding time but also improve the translation quality because of reduced search space.,1 Introduction,[0],[0]
"We assume that correct insertion positions can be determined before decoding, using the word to be inserted (I) with the context on the source side and the context of the insertion positions on the target side.",2 Insertion Position Selection,[0],[0]
"On the source side, we use the parent of I (Ps) and the distance of I from Ps (Ds).",2 Insertion Position Selection,[0],[0]
"On the target side, we use the previous (Sp) and next (Sn) sibling of the insertion position, the parent of the insertion position (Pt) and the distance of the insertion position from Pt (Dt).",2 Insertion Position Selection,[0],[0]
"The distances are calculated on the siblings rather than the words in the sentence, and it is a positive or negative value if the insertion
position is to the left or to the right of the parent respectively.
",2 Insertion Position Selection,[0],[0]
"Taking the insertion position between “park” and “yesterday” in Figure 1 as an example, I = “突然”, Ps = “電話した”, Ds = +2, Sp = “park”, Sn = “yesterday”, Pt = “called” and Dt = -3.",2 Insertion Position Selection,[0],[0]
"In cases where Sp or Sn is empty, we use special words “[[LEFTSTART]]”, “[[LEFT-END]]”, “[[RIGHT-START]]” and “[[RIGHT-END]]”.",2 Insertion Position Selection,[0],[0]
"In the case of “yesterday” in Figure 1, Sp = “in” and Sn = “[[RIGHT-END]]”.",2 Insertion Position Selection,[0],[0]
These clues are fed into the neural network model to solve the insertion position selection problem.,2 Insertion Position Selection,[0],[0]
Figure 2 shows the neural network model for the insertion position selection.,2.1 Neural Network Model,[0],[0]
"Given an insertion position candidate with an index k, the words (I , Ps, Skp , S k n, Pt) are first converted into vector representations through the same three embedding layers: surface form embedding (200 dimensions.)",2.1 Neural Network Model,[0],[0]
", partof-speech embedding (10 dimensions) and dependency type (or phrase category) embedding (10 dimensions), and they are concatenated to create the 220-dimension vectors.",2.1 Neural Network Model,[0],[0]
"The word embedding is a randomly initialized transformation from an one-hot vector to a 200 or 10-dimensional vector, and it is learned during the whole network training.
",2.1 Neural Network Model,[0],[0]
"Using these words and the distances, we create source and target context vectors cks and c k t which represent the information of source and target sides, respectively.",2.1 Neural Network Model,[0],[0]
The distances (integer values) are directly inputted to the network.,2.1 Neural Network Model,[0],[0]
"Then the context vec-
tor of the given insertion position cki is created using cks and c k t .",2.1 Neural Network Model,[0],[0]
Finally we get the score of the given insertion position sk from cki .,2.1 Neural Network Model,[0],[0]
"These vectors are calculated as follows:
cks =",2.1 Neural Network Model,[0],[0]
tanh(Wcs,2.1 Neural Network Model,[0],[0]
[I; Ps; Ds]) ckt = tanh(Wct,2.1 Neural Network Model,[0],[0]
[Sp; Sn; Pt; D k t ]) cki = tanh(Wci,2.1 Neural Network Model,[0],[0]
[c k s ; c k t ]),2.1 Neural Network Model,[0],[0]
sk = Wsc k,2.1 Neural Network Model,[0],[0]
"i
where “;” means concatenation of the vectors.",2.1 Neural Network Model,[0],[0]
"The size of cks , c k t and c k",2.1 Neural Network Model,[0],[0]
"i is 100 in our experiments.
",2.1 Neural Network Model,[0],[0]
The same network is applied to all the other insertion positions and get their scores.,2.1 Neural Network Model,[0],[0]
"Finally the scores are normalized by the softmax function, and the loss is calculated by the softmax cross-entropy as the loss function.",2.1 Neural Network Model,[0],[0]
All the links between layers are fully-connected.,2.1 Neural Network Model,[0],[0]
We use dropout (50%) to avoid overfitting.,2.1 Neural Network Model,[0],[0]
The data for training the neural network model can be automatically generated from the word-aligned parallel corpus with dependency parses in both sides by Algorithm 1.,2.2 Training Data Generation,[0],[0]
"The ALIGNMENT function returns the aligned word in the target tree for the given source word1, and the ISPARENTCHILD function returns TRUE if Pt is the parent of Ct.
1In case of the multiple word alignment, we only use the root word of them in both source and target sides.
",2.2 Training Data Generation,[0],[0]
"Algorithm 1 Training Data Generation for NN for all Ps ∈ words in source tree do
The GENERATEDATA function generates one instance of training data to predict the position of Ct from Ps, Cs and Pt with their contexts by removing Ct in the target tree.",2.2 Training Data Generation,[0],[0]
"The position where Ct exists is regarded as the correct insertion position, and others as incorrect insertion positions.",2.2 Training Data Generation,[0],[0]
Note that Cs corresponds to I in Figure 2.,2.2 Training Data Generation,[0],[0]
"Once the neural network model is trained, it can be applied to select the most appropriate insertion positions in the translation rules for the given floating subtree by looking at the score of each insertion position.",2.3 Insertion Position Selection in Translation,[0],[0]
Translation rules only contain part of the original parallel sentence in most of the cases.,2.3 Insertion Position Selection in Translation,[0],[0]
This means that the context used for selecting the insertion position is different from that in the training data for the neural network.,2.3 Insertion Position Selection in Translation,[0],[0]
"For example, if the input sentence does not have “公園で (in the park)” in Figure 1, the number of possible insertion positions is 6 and we do not use “in” as the context.",2.3 Insertion Position Selection in Translation,[0],[0]
"However, this is not so problematic because similar or same context may appear in the different part of the corpus.",2.3 Insertion Position Selection in Translation,[0],[0]
We conducted two kinds of experiments: the insertion position selection and translation.,3 Experiments,[0],[0]
"We used ASPEC (Nakazawa et al., 2016) as the dataset and the numbers of the sentences of the corpus are shown in Table 1.",3 Experiments,[0],[0]
"The Japanese morphological analyzer (Kurohashi et al., 1994) and dependency parser (Kurohashi and Nagao, 1994) are used for Japanese
sentences.",3 Experiments,[0],[0]
"English sentences are first parsed by nlparser (Charniak and Johnson, 2005) and then converted into word dependency trees using Collins’ head percolation table (Collins, 1999).",3 Experiments,[0],[0]
"We used Chinese word segmenter KKN (Shen et al., 2014) and dependency parser SKP (Shen et al., 2012) for Chinese sentences.",3 Experiments,[0],[0]
"The supervised word alignment Nile (Riesa et al., 2011) was used.
",3 Experiments,[0],[0]
"We used a state-of-the-art dependency tree-to-tree decoder (Richardson et al., 2014) with the default settings.",3 Experiments,[0],[0]
"The neural network is constructed and trained using the Chainer (Tokui et al., 2015).",3 Experiments,[0],[0]
"The training, development and test data for the neural network is automatically generated by the procedure explained in Section 2.2.",3.1 Insertion Position Selection,[0],[0]
The size of the generated data from the ASPEC and the average number of insertion positions for each floating subtree are shown in Table 2.,3.1 Insertion Position Selection,[0],[0]
We trained the model for 100 epochs and used the best model on the development data for testing.,3.1 Insertion Position Selection,[0],[0]
"The vocabulary size for the surface form was 50,000.
",3.1 Insertion Position Selection,[0],[0]
"For comparison, we also tried the logistic regression to predict the correct insertion positions.",3.1 Insertion Position Selection,[0],[0]
"Because our training data is huge, we used Multi-core LIBLINEAR2 with L2-regularized logistic regression (primal) solver.",3.1 Insertion Position Selection,[0],[0]
"The format of training instances are: one-hot (binary) vectors for surface form, POS and dependency type, and distances scaled to [0, 1].",3.1 Insertion Position Selection,[0],[0]
"We first find the best value for the C parameter, then train the model.",3.1 Insertion Position Selection,[0],[0]
"The best insertion position is selected using the estimated probabilities for each insertion position.
",3.1 Insertion Position Selection,[0],[0]
"The experimental results are also shown in Table 2https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/multicore-
liblinear/
2.",3.1 Insertion Position Selection,[0],[0]
We evaluated the results by the mean loss of the model and the accuracy on the test data.,3.1 Insertion Position Selection,[0],[0]
The result shows that our model can select the correct insertion position with very high accuracy for every language pair while the classical logistic regression model cannot.,3.1 Insertion Position Selection,[0],[0]
"This supports our claim stated in the beginning of Section 2.
",3.1 Insertion Position Selection,[0],[0]
X → Ja is easier and achieved slightly better accuracy than the reverse direction because Japanese is a head-final language and all children are generally put on the left of their parents.,3.1 Insertion Position Selection,[0],[0]
"There are some cases judged as incorrect but acceptable insertion positions, and hence the true accuracies are higher than the ones reported above.",3.1 Insertion Position Selection,[0],[0]
"We also investigated the top-2 accuracy and found that it is above 99.0% for Ja → X and 99.5% for X → Ja.
Table 3 shows the detailed result of Ja rightarrow En experiment.",3.1 Insertion Position Selection,[0],[0]
The number of insertion-position is at least 2 (left/right of the parent) and it is easy to solve (more than 99% accuracy).,3.1 Insertion Position Selection,[0],[0]
"3 is a situation where the parent has one child, and it is still not so difficult (97-98% accuracy).",3.1 Insertion Position Selection,[0],[0]
About 70% of the test data have only 2 or 3 insertion-positions.,3.1 Insertion Position Selection,[0],[0]
"Difficult cases are the sentences which have many adjuncts as in Figure 1, but we used the scientific paper corpora, where not so many adjuncts appear.",3.1 Insertion Position Selection,[0],[0]
"We conducted translation experiment using the ASPEC in 3 settings:
• No Flexible: not using the flexible nonterminals and using simple glue rules as in the baseline model of (Richardson et al., 2016) 3 • Baseline: using the flexible non-terminals without the insertion position selection • Proposed: using only the most appropriate insertion position for the flexible non-terminals
We also report the translation quality of conventional models for comparison: phrase-based SMT (PBSMT) and hierarchical phrase-based SMT (Hiero).",3.2 Translation,[0],[0]
"We used the default settings of Moses except -distortion-limit=20 for PBSMT.
",3.2 Translation,[0],[0]
"The translation quality is evaluated by the automatic evaluation measures BLEU (Papineni et al.,
352.5% of all the translation rules require glue rule, but it is applied to 22.6% of the rules actually used in the translation.
2002) and RIBES (Isozaki et al., 2010) with the significance testing by bootstrap resampling (Koehn, 2004).",3.2 Translation,[0],[0]
"RIBES is more sensitive to word order than BLEU, so we expect an improvement in RIBES.",3.2 Translation,[0],[0]
We also investigated relative decoding time compared to the No Flexible setting.,3.2 Translation,[0],[0]
"Note that we used the word “decoding” for only exploring the search space, and it does not include constructing the search space (as the table lookup in Phrase-based SMT).",3.2 Translation,[0],[0]
"Our whole translation process is:
1.",3.2 Translation,[0],[0]
translation rule extraction 2.,3.2 Translation,[0],[0]
insertion-position selection 3.,3.2 Translation,[0],[0]
"decoding
At the time of the second step, we have all the translation rules applicable to the input sentence.",3.2 Translation,[0],[0]
The computation time for each step is,3.2 Translation,[0],[0]
3 ≫ 1,3.2 Translation,[0],[0]
≫ 2,3.2 Translation,[0],[0]
"so we only focus on the time for step 3 in the experiments (the computation time for step 2 is negligibly small).
",3.2 Translation,[0],[0]
The results are shown in Table 4.,3.2 Translation,[0],[0]
The Proposed method achieved significantly better automatic evaluation scores than the Baseline for all the language pairs except the BLEU score of En → Ja direction.,3.2 Translation,[0],[0]
"Also, the decoding time is reduced by about 60% relative to that of the Baseline.
",3.2 Translation,[0],[0]
"Our tree-based model is better than the conventional models except C → J, where the accuracy of
Chinese parsing for the input sentences has a bad effect.",3.2 Translation,[0],[0]
In this paper we have proposed a neural network based insertion position selection model to reduce the computational cost of the decoding for dependency tree-to-tree translation with flexible nonterminals.,4 Conclusion,[0],[0]
"The model successfully finds the appropriate insertion position from the candidates and it leads to faster translation speed and better translation quality due to the reduced search space.
",4 Conclusion,[0],[0]
"Currently, we use only words as the context but it seems promising to use subtrees as well.",4 Conclusion,[0],[0]
"For example, using the information of the subtree “in the park” is more informative than using only “in” in Figure 1.",4 Conclusion,[0],[0]
This is especially important for Japanese as the target language because children of verbs are often case markers and they do not provide enough information when selecting the appropriate insertion position.,4 Conclusion,[0],[0]
"It is possible to adopt existing models of creating vector representation of dependency subtrees such as the model using recursive neural networks (Liu et al., 2015) and convolutional neural networks (Mou et al., 2015).",4 Conclusion,[0],[0]
Dependency tree-to-tree translation models are powerful because they can naturally handle long range reorderings which is important for distant language pairs.,abstractText,[0],[0]
The translation process is easy if it can be accomplished only by replacing non-terminals in translation rules with other rules.,abstractText,[0],[0]
However it is sometimes necessary to adjoin translation rules.,abstractText,[0],[0]
Flexible non-terminals have been proposed as a promising solution for this problem.,abstractText,[0],[0]
"A flexible non-terminal provides several insertion position candidates for the rules to be adjoined, but it increases the computational cost of decoding.",abstractText,[0],[0]
In this paper we propose a neural network based insertion position selection model to reduce the computational cost by selecting the appropriate insertion positions.,abstractText,[0],[0]
The experimental results show the proposed model can select the appropriate insertion position with a high accuracy.,abstractText,[0],[0]
It reduces the decoding time and improves the translation quality owing to reduced search space.,abstractText,[0],[0]
Insertion Position Selection Model for Flexible Non-Terminals in Dependency Tree-to-Tree Machine Translation,title,[0],[0]
How can we infer a distribution given a sample from it?,1. Introduction,[0],[0]
"If data is in abundance, the solution may be simple – the empirical distribution will approximate the true distribution.",1. Introduction,[0],[0]
"However, challenges arise when data is scarce in comparison to the size of the domain, and especially when we wish to quantify “rare events.”",1. Introduction,[0],[0]
"This is frequently the case: for example, it has recently been observed that there are several very rare genetic mutations which occur in humans, and we wish to know how many such mutations exist (Keinan & Clark, 2012; Tennessen et al., 2012; Nelson et al., 2012).",1. Introduction,[0],[0]
"Many of these mutations have only been seen once, and we can infer that there are many which have not been seen at all.",1. Introduction,[0],[0]
"Over the last decade, a large body of work has focused on developing theoretically sound and effective tools for such settings (Orlitsky et al., 2016) and references therein, including the problem of estimating the frequency distribution of
*Equal contribution 1ECE, Cornell University, Ithaca, New York, USA 2EECS & CSAIL, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Jayadev Acharya <acharya@cornell.edu>, Gautam Kamath <g@csail.mit.edu>, Ziteng Sun <zs335@cornell.edu>, Huanyu Zhang <hz388@cornell.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"rare genetic variations (Zou et al., 2016).
",1. Introduction,[0],[0]
"However, in many settings where one wishes to perform statistical inference, data may contain sensitive information about individuals.",1. Introduction,[0],[0]
"For example, in medical studies, where the data may contain individuals’ health records and whether they carry some disease which bears a social stigma.",1. Introduction,[0],[0]
"Alternatively, one can consider a map application which suggests routes based on aggregate positions of individuals, which contains delicate information including users’ residence data.",1. Introduction,[0],[0]
"In these settings, it is critical that our methods protect sensitive information contained in the dataset.",1. Introduction,[0],[0]
"This does not preclude our overall goals of statistical analysis, as we are trying to infer properties of the population p, and not the samples which are drawn from said population.
",1. Introduction,[0],[0]
"That said, without careful experimental design, published statistical findings may be prone to leaking sensitive information about the sample.",1. Introduction,[0],[0]
"As a notable example, it was recently shown that one can determine the identity of some individuals who participated in genome-wide association studies (Homer et al., 2008).",1. Introduction,[0],[0]
"This realization has motivated a surge of interest in developing data sharing techniques with an explicit focus on maintaining privacy of the data (Johnson & Shmatikov, 2013; Uhler et al., 2013; Yu et al., 2014; Simmons et al., 2016).
",1. Introduction,[0],[0]
"Privacy-preserving computation has enjoyed significant study in a number of fields, including statistics and almost every branch of computer science, including cryptography, machine learning, algorithms, and database theory – see, e.g., (Dalenius, 1977; Adam & Worthmann, 1989; Agrawal & Aggarwal, 2001; Dinur & Nissim, 2003; Dwork, 2008; Dwork & Roth, 2014) and references therein.",1. Introduction,[0],[0]
"Perhaps the most celebrated notion of privacy, proposed by theoretical computer scientists, is differential privacy (Dwork et al., 2006).",1. Introduction,[0],[0]
"Informally, an algorithm is differentially private if its outputs on neighboring datasets (differing in a single element) are statistically close (for a more precise definition, see Section 2).",1. Introduction,[0],[0]
"Differential privacy has become the standard for theoretically-sound data privacy, leading to its adoption by several large technology companies, including Google and Apple (Erlingsson et al., 2014; Differential Privacy Team, Apple, 2017).
",1. Introduction,[0],[0]
Our focus in this paper is to develop tools for privately performing several distribution property estimation tasks.,1. Introduction,[0],[0]
"In
particular, we study the tradeoff between statistical accuracy, privacy, and error rate in the sample size.",1. Introduction,[0],[0]
"Our model is that we are given sample access to some unknown discrete distribution p, over a domain of size k, which is possibly unknown in some tasks.",1. Introduction,[0],[0]
"We wish to estimate the following properties:
• Support Coverage: If we take m samples from the distribution, what is the expected number of unique elements we expect to see?",1. Introduction,[0],[0]
• Support Size: How many elements of the support have non-zero probability?,1. Introduction,[0],[0]
"• Entropy: What is the Shannon entropy of the distribution?
",1. Introduction,[0],[0]
"For more formal statements of these problems, see Section 2.1.",1. Introduction,[0],[0]
"We require that our output is α-accurate, satisfies (ε, 0)-differential privacy, and is correct with probability 1−β.",1. Introduction,[0],[0]
"The goal is to give an algorithm with minimal sample complexity n, while simultaneously being computationally efficient.
",1. Introduction,[0],[0]
Theoretical Results.,1. Introduction,[0],[0]
Our main results show that privacy can be achieved for all these problems at a very low cost.,1. Introduction,[0],[0]
"For example, if one wishes to privately estimate entropy, this incurs an additional additive cost in the sample complexity which is very close to linear in 1/αε.",1. Introduction,[0],[0]
We draw attention to two features of this bound.,1. Introduction,[0],[0]
"First, this is independent of k. All the problems we consider have complexity Θ(k/ log k), so in the primary regime of study where k 1/αε, this small additive cost is dwarfed by the inherent sample complexity of the non-private problem.",1. Introduction,[0],[0]
"Second, the bound is almost linear in 1/αε.",1. Introduction,[0],[0]
"We note that performing even the most basic statistical task privately, estimating the bias of a coin, incurs this linear dependence.",1. Introduction,[0],[0]
"Surprisingly, we show that much more sophisticated inference tasks can be privatized at almost no cost.",1. Introduction,[0],[0]
"In particular, these properties imply that the additive cost of privacy is o(1) in the most studied regime where the support size is large.",1. Introduction,[0],[0]
"In general, this is not true – for many other problems, including distribution estimation and hypothesis testing, the additional cost of privacy depends significantly on the support size or dimension (Diakonikolas et al., 2015; Cai et al., 2017; Acharya et al., 2017c; Aliakbarpour et al., 2017).",1. Introduction,[0],[0]
"We also provide lower bounds, showing that our upper bounds are almost tight.",1. Introduction,[0],[0]
"A more formal statement of our results appears in Section 3.
",1. Introduction,[0],[0]
Experimental Results.,1. Introduction,[0],[0]
We demonstrate the efficacy of our method with experimental evaluations.,1. Introduction,[0],[0]
"As a baseline, we compare with the non-private algorithms of (Orlitsky et al., 2016) and (Wu & Yang, 2018).",1. Introduction,[0],[0]
"Overall, we find that our algorithms’ performance is nearly identical, showing that, in many cases, privacy comes (essentially) for free.",1. Introduction,[0],[0]
We begin with an evaluation on synthetic data.,1. Introduction,[0],[0]
"Then, inspired by (Valiant & Valiant, 2013; Orlitsky et al., 2016), we ana-
lyze text corpus consisting of words from Hamlet, in order to estimate the number of unique words which occur.",1. Introduction,[0],[0]
"Finally, we investigate name frequencies in the US census data.",1. Introduction,[0],[0]
"This setting has been previously considered by (Orlitsky et al., 2016), but we emphasize that this is an application where private statistical analysis is critical.",1. Introduction,[0],[0]
"This is proven by efforts of the US Census Bureau to incorporate differential privacy into the 2020 US census (Dajani et al., 2017).
",1. Introduction,[0],[0]
Techniques.,1. Introduction,[0],[0]
"Our approach works by choosing statistics for these tasks which possess bounded sensitivity, which is well-known to imply privacy under the Laplace or Gaussian mechanism.",1. Introduction,[0],[0]
We note that bounded sensitivity of statistics is not always something that can be taken for granted.,1. Introduction,[0],[0]
"Indeed, for many fundamental tasks, optimal algorithms for the nonprivate setting may be highly sensitive, thus necessitating crucial modifications to obtain differential privacy (Acharya et al., 2015; Cai et al., 2017).",1. Introduction,[0],[0]
"Thus, careful choice and design of statistics must be a priority when performing inference with privacy considerations.
",1. Introduction,[0],[0]
"To this end, we leverage recent results of (Acharya et al., 2017a), which studies estimators for non-private versions of the problems we consider.",1. Introduction,[0],[0]
"The main technical work in their paper exploits bounded sensitivity to show sharp cutoff-style concentration bounds for certain estimators, which operate using the principle of best-polynomial approximation.",1. Introduction,[0],[0]
"They use these results to show that a single algorithm, the Profile Maximum Likelihood (PML), can estimate all these properties simultaneously.",1. Introduction,[0],[0]
"On the other hand, we consider the sensitivity of these estimators for purposes of privacy – the same property is utilized by both works for very different purposes, a connection which may be of independent interest.
",1. Introduction,[0],[0]
We note that bounded sensitivity of a statistic may be exploited for purposes other than privacy.,1. Introduction,[0],[0]
"For instance, by McDiarmid’s inequality, any such statistic also enjoys very sharp concentration of measure, implying that one can boost the success probability of the test at an additive cost which is logarithmic in the inverse of the failure probability.",1. Introduction,[0],[0]
"One may naturally conjecture that, if a statistical task is based on a primitive which concentrates in this sense, then it may also be privatized at a low cost.",1. Introduction,[0],[0]
"However, this is not true – estimating a discrete distribution in `1 distance is such a task, but the cost of privatization depends significantly on the support size (Diakonikolas et al., 2015).
",1. Introduction,[0],[0]
"One can observe that, algorithmically, our method is quite simple: compute the non-private statistic, and add a relatively small amount of Laplace noise.",1. Introduction,[0],[0]
"The non-private statistics have recently been demonstrated to be practical (Orlitsky et al., 2016; Wu & Yang, 2018), and the additional cost of the Laplace mechanism is minimal.",1. Introduction,[0],[0]
This is in contrast to several differentially private algorithms which invoke significant overhead in the quest for privacy.,1. Introduction,[0],[0]
"Our algorithms
attain almost-optimal rates (which are optimal up to constant factors for most parameter regimes of interest), while simultaneously operating effectively in practice, as demonstrated in our experimental results.
",1. Introduction,[0],[0]
Related Work.,1. Introduction,[0],[0]
"Over the last decade, there have been a flurry of works on the problems we study in this paper by the computer science and information theory communities, including Shannon and Rényi entropy estimation (Paninski, 2003; Valiant & Valiant, 2017; Jiao et al., 2017; Acharya et al., 2017b; Obremski & Skorski, 2017; Wu & Yang, 2018), support coverage and support size estimation (Orlitsky et al., 2016; Wu & Yang, 2018).",1. Introduction,[0],[0]
"A recent paper studies the general problem of estimating functionals of discrete distribution from samples in terms of the smoothness of the functional (Fukuchi & Sakuma, 2017).",1. Introduction,[0],[0]
"These have culminated in a nearly-complete understanding of the sample complexity of these properties, with optimal sample complexities (up to constant factors) for most parameter regimes.
",1. Introduction,[0],[0]
"Recently, there has been significant interest in performing statistical tasks under differential privacy constraints.",1. Introduction,[0],[0]
"Perhaps most relevant to this work are (Cai et al., 2017; Acharya et al., 2017c; Aliakbarpour et al., 2017), which study the sample complexity of differentialy privately performing classical distribution testing problems, including identity and closeness testing.",1. Introduction,[0],[0]
"Other works investigating private hypothesis testing include (Wang et al., 2015a; Gaboardi et al., 2016; Kifer & Rogers, 2017; Kakizaki et al., 2017; Rogers, 2017; Gaboardi & Rogers, 2017), which focus less on characterizing the finite-sample guarantees of such tests, and more on understanding their asymptotic properties and applications to computing p-values.",1. Introduction,[0],[0]
"There has also been study on private distribution learning (Diakonikolas et al., 2015; Duchi et al., 2017; Karwa & Vadhan, 2018; Acharya et al., 2018; Kamath et al., 2018), in which we wish to estimate parameters of the distribution, rather than just a particular property of interest.",1. Introduction,[0],[0]
"A number of other problems have been studied with privacy requirements, including clustering (Wang et al., 2015b; Balcan et al., 2017), principal component analysis (Chaudhuri et al., 2013; Kapralov & Talwar, 2013; Hardt & Price, 2014), ordinary least squares (Sheffet, 2017), and much more.",1. Introduction,[0],[0]
"We will start with some definitions.
",2. Preliminaries,[0],[0]
Let ∆ def=,2. Preliminaries,[0],[0]
{(p(1),2. Preliminaries,[0],[0]
", .",2. Preliminaries,[0],[0]
. .,2. Preliminaries,[0],[0]
", p(k))",2. Preliminaries,[0],[0]
": p(i) ≥ 0, ∑k i=1",2. Preliminaries,[0],[0]
p(i),2. Preliminaries,[0],[0]
"= 1, 1 ≤ k ≤ ∞} be the set of discrete distributions over a countable support.",2. Preliminaries,[0],[0]
Let ∆k be the set of distributions in ∆ with at most k non-zero probability values.,2. Preliminaries,[0],[0]
"A property f(p) is a mapping from ∆→ R. We now describe the classical distribution property estimation problem, and then state the problem under differential privacy.
",2. Preliminaries,[0],[0]
Property Estimation.,2. Preliminaries,[0],[0]
"Given α, β, f , and independent samples Xn1 from an unknown distribution p, design an estimator f̂ : Xn1 → R such that with probability at least 1− β,
∣∣∣f̂(Xn1 )",2. Preliminaries,[0],[0]
− f(p)∣∣∣ < α.,2. Preliminaries,[0],[0]
"The sample complexity of f̂ , Cf̂",2. Preliminaries,[0],[0]
"(f, α, β) def=",2. Preliminaries,[0],[0]
min{n :,2. Preliminaries,[0],[0]
Pr (∣∣∣f̂(Xn1 ),2. Preliminaries,[0],[0]
"− f(p)∣∣∣ > α) < β} is the smallest number of samples to estimate f to accuracy α, and error β.",2. Preliminaries,[0],[0]
"We study the problem for β = 1/3, and by the median trick, we can boost the success probability to 1 − β with an additional multiplicative log(1/β) more samples.",2. Preliminaries,[0],[0]
"Therefore, focusing on β = 1/3, we define Cf̂",2. Preliminaries,[0],[0]
"(f, α)
def= Cf̂",2. Preliminaries,[0],[0]
"(f, α, 1/3).",2. Preliminaries,[0],[0]
"The sample complexity of estimating a property f(p) is the minimum sample complexity over all estimators: C(f, α) = minf̂ Cf̂",2. Preliminaries,[0],[0]
"(f, α).
",2. Preliminaries,[0],[0]
"An estimator f̂ is ε-differentially private (DP) (Dwork et al., 2006)",2. Preliminaries,[0],[0]
"if for any Xn1 and Y n 1 , with dham(Xn1 , Y n1 ) ≤ 1, Pr (f(Xn1 )∈S)",2. Preliminaries,[0],[0]
"Pr (f(Y n1 )∈S) ≤ eε, for all measurable S.
Private Property Estimation.",2. Preliminaries,[0],[0]
"Given α, ε, β, f , and independent samples Xn1 from an unknown distribution p, design an ε-differentially private estimator f̂ : Xn1 → R such that with probability at least 1 − β,
∣∣∣f̂(Xn1 )",2. Preliminaries,[0],[0]
− f(p)∣∣∣ < α.,2. Preliminaries,[0],[0]
"Similar to the non-private setting, the sample complexity of ε-differentially private estimation problem is C(f, α, ε) = minf̂ :f̂ is ε-DP Cf̂",2. Preliminaries,[0],[0]
"(f, α, 1/3), the smallest number of samples n for which there exists such an ε-DP ±α estimator with error probability at most 1/3.
",2. Preliminaries,[0],[0]
"In their original paper (Dwork et al., 2006) provides a scheme for differential privacy, known as the Laplace mechanism.",2. Preliminaries,[0],[0]
This method adds Laplace noise to a non-private scheme in order to make it private.,2. Preliminaries,[0],[0]
"We first define the sensitivity of an estimator, and then state their result in our setting.
",2. Preliminaries,[0],[0]
Definition 1.,2. Preliminaries,[0],[0]
"The sensitivity of an estimator f̂ : [k]n → R is ∆n,f̂ def= maxdham(Xn1 ,Y n1 )",2. Preliminaries,[0],[0]
≤1 ∣∣∣f̂(Xn1 ),2. Preliminaries,[0],[0]
− f̂(Y n1 )∣∣∣ .,2. Preliminaries,[0],[0]
"Let Df̂ (α, ε) = min{n : ∆n,f̂ ≤ αε}.
",2. Preliminaries,[0],[0]
Lemma 1.,2. Preliminaries,[0],[0]
"C(f, α, ε) =",2. Preliminaries,[0],[0]
"O (
min f̂
{ Cf̂ (f, α/2)",2. Preliminaries,[0],[0]
"+Df̂ (α 4 , ε )}) .
",2. Preliminaries,[0],[0]
Proof.,2. Preliminaries,[0],[0]
"(Dwork et al., 2006) showed that for a function with sensitivity ∆n,f̂ , adding Laplace noise X ∼ Lap(∆n,f̂/ε) makes the output ε-differentially private.",2. Preliminaries,[0],[0]
"By the definition of Df̂ ( α 4 , ε), the Laplace noise we add has parameter at most α4 .",2. Preliminaries,[0],[0]
Recall that the probability density function of Lap(b) is 12be,2. Preliminaries,[0],[0]
"− |x|b , hence we have Pr (|X| > α/2)",2. Preliminaries,[0],[0]
< 1e2 .,2. Preliminaries,[0],[0]
"By the union bound, we get an additive error larger than α = α2 + α 2 with probability at most 1/3+ 1 e2 < 0.5.",2. Preliminaries,[0],[0]
"Hence, with the median trick, we can boost the error probability
to 1/3, at the cost of a constant factor in the number of samples.
",2. Preliminaries,[0],[0]
"To prove sample complexity lower bounds for differentially private estimators, we observe that the estimator can be used to test between two distributions with distinct property values, hence is a harder problem.",2. Preliminaries,[0],[0]
"For lower bounds on differentially private testing, (Acharya et al., 2017c) gives the following argument based on coupling:
Lemma 2.",2. Preliminaries,[0],[0]
"Suppose there is a coupling between distributions p and q over Xn, such that E",2. Preliminaries,[0],[0]
"[dham(Xn1 , Y n1 )]",2. Preliminaries,[0],[0]
"≤ D. Then, any ε-differentially private algorithm that distinguishes between p and q with error probability at most 1/3 must satisfy D = Ω ( 1 ε ) .",2. Preliminaries,[0],[0]
Support Size.,2.1. Problems of Interest,[0],[0]
The support size of a distribution p is S(p),2.1. Problems of Interest,[0],[0]
"= |{x : p(x) > 0}|, the number of symbols with nonzero probability values.",2.1. Problems of Interest,[0],[0]
"However, notice that estimating S(p) from samples can be hard due to the presence of symbols with negligible, yet non-zero probabilities.",2.1. Problems of Interest,[0],[0]
"To circumvent this issue, (Raskhodnikova et al., 2009) proposed to study the problem when the smallest probability is bounded.",2.1. Problems of Interest,[0],[0]
Let ∆≥,2.1. Problems of Interest,[0],[0]
"1k
def= {p ∈ ∆ : p(x) ∈ {0} ∪ [1/k, 1]} be the set of all distributions where all non-zero probabilities have value",2.1. Problems of Interest,[0],[0]
at least 1/k. For p ∈ ∆≥,2.1. Problems of Interest,[0],[0]
"1k , our goal is to estimate S(p) up to ±αk with the least number of samples from p.
Support Coverage.",2.1. Problems of Interest,[0],[0]
"For a distribution p, and an integerm, let Sm(p) = ∑ x(1−(1−p(x))m), be the expected number of symbols that appear when we obtain m independent samples from the distribution p.",2.1. Problems of Interest,[0],[0]
"The objective is to find the least number of samples n in order to estimate Sm(p) to an additive ±αm.
",2.1. Problems of Interest,[0],[0]
"Support coverage arises in many ecological and biological studies (Colwell et al., 2012) to quantify the number of new elements (gene mutations, species, words, etc) that can be expected to be seen in the future.",2.1. Problems of Interest,[0],[0]
"Good and Toulmin (Good & Toulmin, 1956) proposed an estimator that for any constant α, requires m/2 samples to estimate Sm(p).
",2.1. Problems of Interest,[0],[0]
Entropy.,2.1. Problems of Interest,[0],[0]
"The Shannon entropy of a distribution p is H(p) = ∑ x p(x) log 1 p(x) , H(p) is a central object in information theory (Cover & Thomas, 2006), and also arises in many fields such as machine learning (Nowozin, 2012), neuroscience (Berry et al., 1997; Nemenman et al., 2004), and others.",2.1. Problems of Interest,[0],[0]
Estimating H(p) is hard with any finite number of samples due to the possibility of infinite support.,2.1. Problems of Interest,[0],[0]
"To circumvent this, a natural approach is to consider distributions in ∆k.",2.1. Problems of Interest,[0],[0]
"The goal is to estimate the entropy of a distribution in ∆k to an additive ±α, where ∆k is all discrete distributions over at most k symbols.",2.1. Problems of Interest,[0],[0]
"Our theoretical results for estimating support coverage, support size, and entropy are given below.",3. Statement of Results,[0],[0]
Algorithms for these problems and proofs of these statements are provided in Section 4.,3. Statement of Results,[0],[0]
"Our experimental results are described and discussed in Section 5.
Theorem 1.",3. Statement of Results,[0],[0]
"The sample complexity of support coverage estimation C(Sm, α, ε) is O ( m log(1/α) logm + m log(1/α) log(2+εm) ) , when m ≥",3. Statement of Results,[0],[0]
"1αε O ( 1 α2 + 1 αε ) , when 1α ≤ m ≤ 1 αε
O ( m2 + mε ) .",3. Statement of Results,[0],[0]
"when m ≤ 1α
Furthermore,
C(Sm, α, ε) =",3. Statement of Results,[0],[0]
"Ω ( m log(1/α)
logm + 1 αε
) .
",3. Statement of Results,[0],[0]
Theorem 2.,3. Statement of Results,[0],[0]
"The sample complexity of support size estimation C(S, α, ε) is O ( k log2(1/α) log k + k log2(1/α) log(2+εk) ) ,",3. Statement of Results,[0],[0]
when k ≥,3. Statement of Results,[0],[0]
1αε O ( k log(1/α) +,3. Statement of Results,[0],[0]
"1αε ) , when 1α ≤ k ≤ 1 αε
O ( k log k + kε ) .",3. Statement of Results,[0],[0]
when k ≤,3. Statement of Results,[0],[0]
"1α
Furthermore,
C(S, α, ε) = { Ω ( k log2(1/α) log k + 1 αε ) , when k ≥ 1α
Ω ( k log k + kε ) .",3. Statement of Results,[0],[0]
when k ≤,3. Statement of Results,[0],[0]
"1α
Theorem 3.",3. Statement of Results,[0],[0]
Let λ > 0 be any small fixed constant.,3. Statement of Results,[0],[0]
"For instance, λ can be chosen to be any constant between 0.01 and 1.",3. Statement of Results,[0],[0]
"We have the following upper bounds on the sample complexity of entropy estimation C(H,α, ε):
O
( k
α + log 2(min{k, n}) α2 + 1 αε
log (
1 αε )) and
O
( k
λ2α log k + log2(min{k, n}) α2",3. Statement of Results,[0],[0]
"+ ( 1 αε )1+λ) .
",3. Statement of Results,[0],[0]
"Furthermore,
C(H,α, ε) = Ω ( k
α log k + log2(min{k, n}) α2 + log k αε
) .
",3. Statement of Results,[0],[0]
We provide some discussion of our results.,3. Statement of Results,[0],[0]
"At a high level, we wish to emphasize the following two points:
1.",3. Statement of Results,[0],[0]
"Our upper bounds show that the cost of privacy in these settings is often negligible compared to the sample complexity of the non-private statistical task, especially when we are dealing with distributions over a large support.",3. Statement of Results,[0],[0]
"Furthermore, our upper bounds are almost tight in all parameters.",3. Statement of Results,[0],[0]
2.,3. Statement of Results,[0],[0]
"The algorithmic complexity introduced by the requirement of privacy is minimal, consisting only of a single step which noises the output of an estimator.",3. Statement of Results,[0],[0]
"In other words, our methods are realizable in practice, and we demonstrate the effectiveness on several synthetic and real-data examples.
",3. Statement of Results,[0],[0]
"Before we continue, we emphasize that, in Theorems 1 and 2, we consider the “sublinear” regime to be of primary interest (when m",3. Statement of Results,[0],[0]
≥ 1αε,3. Statement of Results,[0],[0]
"or k ≥ 1 αε , respectively), both technically, and in terms of parameter regimes which may be of greatest interest in practice.",3. Statement of Results,[0],[0]
"We include results for other regimes mostly for completeness.
",3. Statement of Results,[0],[0]
"First, we examine our results on support coverage and support size estimation in the sublinear regime, when m ≥ 1αε",3. Statement of Results,[0],[0]
"(focusing on support coverage for simplicity, but support size is similar).",3. Statement of Results,[0],[0]
"In this regime, if ε = Ω(mγ/m) for any constant γ > 0, then up to constant factors, our upper bound is within a constant factor of the optimal sample complexity without privacy constratints.",3. Statement of Results,[0],[0]
"In other words, for most meaningful values of ε, privacy comes for free.",3. Statement of Results,[0],[0]
"In the nonsublinear regime for these problems, we provide upper and lower bounds which match in a number of cases.",3. Statement of Results,[0],[0]
"We note that in this regime, the cost of privacy may not be a lower order term – however, this regime only occurs when one requires very high accuracy, or unreasonably large privacy, which we consider to be of somewhat lesser interest.
",3. Statement of Results,[0],[0]
"Next, we turn our attention to entropy estimation.",3. Statement of Results,[0],[0]
We note that the second upper bound in Theorem 3 has a parameter λ that indicates a tradeoff between the sample complexity incurred in the first and third term.,3. Statement of Results,[0],[0]
This parameter determines the degree of a polynomial to be used for entropy estimation.,3. Statement of Results,[0],[0]
"As the degree becomes smaller (corresponding to a large λ), accuracy of the polynomial estimator decreases, however, at the same time, low-degree polynomials have a small sensitivity, allowing us to privatize the outcome.
",3. Statement of Results,[0],[0]
"In terms of our theoretical results, one can think of λ = 0.01.",3. Statement of Results,[0],[0]
"With this parameter setting, it can be observed that our upper bounds are almost tight.",3. Statement of Results,[0],[0]
"For example, one can see that the upper and lower bounds match to either logarithmic factors (when looking at the first upper bound), or a very small polynomial factor in 1/αε (when looking at the second upper bound).",3. Statement of Results,[0],[0]
"For our experimental results, we empirically determined an effective value for the parameter λ on a single synthetic instance.",3. Statement of Results,[0],[0]
"We then show that this choice of parameter generalizes, giving highly-accurate private estimation in other instances, on both synthetic and real-world data.",3. Statement of Results,[0],[0]
"We now prove our results for support coverage estimation, Theorem 1, while support size and entropy estimation appear in the supplementary material.",4. Algorithms and Analysis,[0],[0]
"We first describe and analyze our algorithms, and then go on to describe and analyze a lower bound construction, showing that our upper bounds are almost tight.
",4. Algorithms and Analysis,[0],[0]
"All our algorithms fall into the following simple framework:
1.",4. Algorithms and Analysis,[0],[0]
Compute a non-private estimate of the property; 2.,4. Algorithms and Analysis,[0],[0]
"Privatize this estimate by adding Laplace noise, where
the parameter is determined through analysis of the estimator and potentially computation of the estimator’s sensitivity.",4. Algorithms and Analysis,[0],[0]
We split the analysis into two regimes.,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"First, we focus on the case where m ≤ 1αε , and we prove the upper bound O ( 1 α2 + 1 αε ) .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Note that the problem is identical for any α < 1m , since this corresponds to estimating the support coverage exactly, and the above bound simplifies to O ( m2 + mε ) .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"The algorithm in this case is simple: since n = Ω(m), we group the dataset into n/m batches of size m. Let Yj be the number of unique symbols observed in batch",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
j. Our estimator is Ŝm(Xn1 ) = mn ∑n/m j=1 Yj .,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Observe that E,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"[Yj ] = Sm(p), and that Var[Yj ] ≤ m. The latter can be seen by observing that Yj is the sum of m negatively correlated indicator random variables, each one being the indicator of whether that sample in the batch is the first time the symbol is observed.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"This gives that Ŝm(Xn1 ) is an unbiased estimator of Sm(p), with variance O(m2/n).",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"By Chebyshev’s inequality, since we want an estimate which is accurate up to ±αm, this gives us that CŜm(Sm(p), α/2) =",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
O ( 1 α2 ) .,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Furthermore, we can see that the sensitivity of Ŝm(Xn1 ) is at most 2m/n. By Lemma 1, there is a private algorithm for support coverage estimation as long as ∆ ( Ŝm(Xn1 )
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"m
) ≤ αε.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"With the above bound
on sensitivity, this is true with n = O(1/αε), giving the desired upper bound.
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Now, we turn our attention to the case where m ≥ 1αε , and we prove the upper boundO ( m log(1/α)
logm + m log(1/α) log(2+εm)
) .
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Let ϕi be the number of symbols that appear i times in Xn1 .,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"We will use the following non-private support coverage estimator from (Orlitsky et al., 2016):
Ŝm(Xn1 ) =",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
n∑ i=1,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
ϕi ( 1− (−t)i ·,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Pr (Z ≥ i) ) ,
where Z is a Poisson random variable with mean r (which
is a parameter to be instantiated later), and t = (m− n)/n.
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Our private estimator of support coverage is derived by adding Laplace noise to this non-private estimator with the appropriate noise parameter, and thus the performance of our private estimator, is analyzed by bounding the sensitivity and the bias of this non-private estimator according to Lemma 1.
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"The sensitivity and bias of this estimator is bounded in the following lemmas.
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Lemma 3.,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Suppose m > 2n, then the maximum coefficient of ϕi in Ŝm(p) is at most 1 + er(t−1).
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Proof.,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"By the definition of Z, we know Pr (Z ≥ i) =∑∞",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
k,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"=i e −r rk k! , hence we have: |1 + (−t)
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
i ·,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Pr (Z ≥ i)| ≤ 1 + ti ∑∞,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
k,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
=i e −r rk k! ≤,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
1 + e −r∑∞ k=i (rt)k k! ≤ 1,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"+
e−r ∑∞",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
k=0 (rt)k k! =,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"1 + e r(t−1).
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"The bias of the estimator is bounded in Lemma 4 of (Acharya et al., 2017a):
Lemma 4.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"If m > 2n, then ∣∣∣E [Ŝm(Xn1 )]",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"− Sm(p)∣∣∣ ≤ 2 + 2er(t−1) + min(m,S(p)) ·",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"e−r.
Using these results, letting r = log(1/α), (Orlitsky et al., 2016) showed that there is a constant C, such that with n = C mlogm log(1/α) samples, with probability at least 0.9,∣∣∣ Ŝm(Xn1 )m − Sm(p)m ∣∣∣ ≤ α.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Our upper bound in Theorem 1 is derived by the following analysis of the sensitivity of Ŝm(X n 1 )
m .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"If we change one sample in Xn1 , at most two of the ϕj’s change.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Hence by Lemma 3, the sensitivity of the estimator satisfies ∆",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"( Ŝm(Xn1 )
m ) ≤ 2m · ( 1 + er(t−1) ) .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"By Lemma 1,
there is a private algorithm for support coverage estimation as long as ∆ ( Ŝm(Xn1 )
m
) ≤ αε, which, by the in-
equality above, holds if 2(1 + exp(r(t",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
− 1))),4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
≤ αεm.,4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Let r = log(3/α), note that t − 1 = mn − 2.",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Suppose αεm > 2, then, the condition above reduces to log ( 3 α ) · ( m n − 2 ) ≤ log ( 1 2αεm− 1 ) .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"This is equivalent to n ≥ m log(3/α)log( 12αεm−1)+2 log(3/α) = m log(3/α) log( 32 εm−3/α)+log(3/α) .
",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Suppose αεm > 2, then the condition above reduces to the requirement that n = Ω ( m log(1/α) log(2+εm) ) .",4.1.1. UPPER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
We now prove the lower bound described in Theorem 1.,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Note that the first term in the lower bound is the sample complexity of non-private support coverage estimation, shown
in (Orlitsky et al., 2016).",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Therefore, we turn our attention to prove the last term in the sample complexity.
",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Consider the following two distributions.,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
u1 is uniform over [m(1 + α)].,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
u2 is distributed over m + 1 elements [m] ∪ {4} where u2[i] = 1m(1+α)∀i ∈,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
[m] and u2[4] = α 1+α .,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Moreover, 4 /∈",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
[m(1 + α)].,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Then, Sm(u1) =
m(1 + α) · ( 1− ( 1− 1m(1+α) )m)
, and Sm(u2) = m ·( 1− ( 1− 1m(1+α) )",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
m),4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
+ ( 1− ( 1− α1+α )m) .,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Therefore,
Sm(u2)",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"− Sm(u1) = mα · ( 1− ( 1− 1m(1+α) )m)
",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"−( 1− ( 1− α1+α )m) = Ω(αm).
",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Hence we know there support coverage differs by Ω(αm).,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Moreover, their total variation distance is α1+α .",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"The following lemma is folklore, based on the coupling interpretation of total variation distance, and the fact that total variation distance is subadditive for product measures.",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Lemma 5.,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"For any two distributions p, and q, there is a coupling between n i.i.d.",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"samples from the two distributions with an expected Hamming distance of dTV(p, q) ·",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"n.
Using Lemma 5 and dTV(u1, u2) = α1+α , we have Lemma 6.",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Suppose u1 and u2 are as defined before, there is a coupling between un1 and u n 2 with expected Hamming distance equal to α1+αn.
",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Moreover, given n samples, we must be able to privately distinguish between u1 and u2 given an α accurate estimator of support coverage with privacy considerations.",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
"Thus, according to Lemma 2 and 6, we have α1+αn ≥ 1 ε ⇒ n",4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
=,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
Ω,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
( 1 εα ) .,4.1.2. LOWER BOUND FOR SUPPORT COVERAGE ESTIMATION,[0],[0]
We evaluated our methods for entropy estimation and support coverage on both synthetic and real data.,5. Experiments,[0],[0]
"Overall, we found that privacy is quite cheap: private estimators achieve accuracy which is comparable or near-indistinguishable to non-private estimators in many settings.",5. Experiments,[0],[0]
"Our results on entropy estimation and support coverage appear in Sections 5.1 and 5.2, respectively.",5. Experiments,[0],[0]
Code of our implementation is available at https://github.com/HuanyuZhang/ INSPECTRE.,5. Experiments,[0],[0]
"We compare the performance of our entropy estimator with a number of alternatives, both private and non-private.",5.1. Entropy,[0],[0]
"Nonprivate algorithms considered include the plug-in estimator (plug-in), the Miller-Madow Estimator (MM) (Miller, 1955), the sample optimal polynomial approximation estimator (poly) of (Wu & Yang, 2016).",5.1. Entropy,[0],[0]
"We analyze the privatized versions of plug-in, and poly in the supplementary material.",5.1. Entropy,[0],[0]
"The implementation of the latter is based on
code from the authors of (Wu & Yang, 2016)1.",5.1. Entropy,[0],[0]
"We compare performance on different distributions including uniform, a distribution with two steps, Zipf(1/2), a distribution with Dirichlet-1 prior, and a distribution with Dirichlet-1/2 prior, and over varying support sizes.
",5.1. Entropy,[0],[0]
"While plug-in, and MM are parameter free, poly (and its private counterpart) have to choose the degree L of the polynomial to use, which manifests in the parameter λ in the statement of Theorem 3.",5.1. Entropy,[0],[0]
"(Wu & Yang, 2016) suggests the value of L = 1.6 log k in their experiments.",5.1. Entropy,[0],[0]
"However, since we add further noise, we choose a single L as follows: (i) Run privatized poly for different L values and distributions for k = 2000, ε = 1, (b) Choose the value of L that performs well across different distributions (See Figure 1).",5.1. Entropy,[0],[0]
"We choose L = 1.2 · log k from this, and use it for all other experiments.",5.1. Entropy,[0],[0]
"To evaluate the sensitivity of poly, we computed the estimator’s value at all possible input values, computed the sensitivity, (namely, ∆ = maxdham(Xn1 ,Y n1 )",5.1. Entropy,[0],[0]
≤1 |poly(X n 1 ),5.1. Entropy,[0],[0]
"− poly(Y n1 )|), and
added noise distributed as Lap ( 0, ∆ε ) .
",5.1. Entropy,[0],[0]
"The RMSE of various estimators for k = 1000, and ε = 1 for various distributions are illustrated in Figure 2.",5.1. Entropy,[0],[0]
"The RMSE is averaged over 100 iterations in the plots.
",5.1. Entropy,[0],[0]
"We observe that the performance of our private-poly is near-indistinguishable from the non-private poly, particularly as the number of samples increases.",5.1. Entropy,[0],[0]
"It also performs significantly better than all other alternatives, including the non-private Miller-Madow and the plug-in estimator.",5.1. Entropy,[0],[0]
"The cost of privacy is minimal for several other settings of k and ε, additional experiments appear in the supplementary material.",5.1. Entropy,[0],[0]
We investigate the cost of privacy for the problem of support coverage.,5.2. Support Coverage,[0],[0]
"We provide a comparison between the Smoothed Good-Toulmin estimator (SGT) of (Orlitsky et al., 2016) and our algorithm, which is a privatized version of their statistic (see Section 4.1.1).",5.2. Support Coverage,[0],[0]
"Our implementation is based on code provided by the authors of (Orlitsky et al., 2016).",5.2. Support Coverage,[0],[0]
"As shown in our theoretical results, the sensitivity of SGT is at most 2(1 + er(t− 1)), necessitating the addition of Laplace noise with parameter 2(1 + er(t−1))/ε.",5.2. Support Coverage,[0],[0]
"Note that while the theory suggests we select the parameter r = log(1/α), α is unknown.",5.2. Support Coverage,[0],[0]
"We instead set r = 12t loge n(t+1)2 t−1 , as previously done in (Orlitsky et al., 2016).
",5.2. Support Coverage,[0],[0]
1See https://github.com/Albuso0/entropy for their code for entropy estimation.,5.2. Support Coverage,[0],[0]
"In our synthetic experiments, we consider different distributions over different support sizes k.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We generate n = k/2 samples, and then estimate the support coverage atm = n·t.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"For large t, estimation is harder.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
Some results of our evaluation on synthetic are displayed in Figure 3.,5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We compare the performance of SGT, and privatized versions of SGT with parameters ε = 1, 2, and 10.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"For this instance, we fixed the domain size k = 20000.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We ran the methods described above with n = k/2 samples, and estimated the support coverage at m = nt, for t ranging from 1 to 10.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"The performance of the estimators is measured in terms of RMSE over 1000 iterations.
",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We observe that, in this setting, the cost of privacy is relatively small for reasonable values of ε.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"This is as predicted by our theoretical results, where unless ε is extremely small (less than 1/k) the non-private sample complexity dominates the privacy requirement.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"However, we found that for smaller support sizes (as shown in the supplementary material), the cost of privacy can be significant.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
We provide an intuitive explanation for why no private estimator can perform well on such instances.,5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"To minimize the number of parameters, we instead argue about the related problem of support-size estimation.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
Suppose we are trying to distinguish between distributions which are uniform over supports of size 100 and 200.,5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We note that, if we draw n = 50 samples, the “profile” of the samples (i.e., the histogram of the histogram) will be very similar for the two distributions.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"In particular, if one modifies only a few samples (say, five or six), one could convert one profile into the other.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"In other words, these two profiles are almost-neighboring datasets, but simultaneously correspond to very different support sizes.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"This pits the two goals of privacy and accuracy at odds with each other, thus resulting in a degradation in accuracy.",5.2.1. EVALUATION ON SYNTHETIC DATA,[0],[0]
"We conclude with experiments for support coverage on two real-world datasets, the 2000 US Census data and the text of Shakespeare’s play Hamlet, inspired by investigations in (Orlitsky et al., 2016) and (Valiant & Valiant, 2017).",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Our investigation on US Census data is also inspired by the fact that this is a setting where privacy is of practical importance, evidenced by the proposed adoption of differential privacy in the 2020 US Census (Dajani et al., 2017).
",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
The Census dataset contains a list of last names that appear at least 100 times.,5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Since the dataset is so oversampled, even a small fraction of the data is likely to contain almost all the names.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"As such, we make the task non-trivial by subsampling mtotal = 86080 individuals from the data, obtaining 20412 distinct last names.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"We then sample n of the mtotal individuals without replacement and attempt to
estimate the total number of last names.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
Figure 4 displays the RMSE over 100 iterations of this process.,5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"We observe that even with an exceptionally stringent privacy budget of ε = 0.5, the performance is almost indistinguishable from the non-private SGT estimator.
",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"The Hamlet dataset has mtotal = 31, 999 words, of which 4804 are distinct.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Since the distribution is not as oversampled as the Census data, we do not need to subsample the
data.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Besides this difference, the experimental setup is identical to that of the Census dataset.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Once again, as we can see in Figure 5, we get near-indistinguishable performance between the non-private and private estimators, even for very small values of ε.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"Our experimental results demonstrate that privacy is realizable in practice, with particularly accurate performance on real-world datasets.",5.2.2. EVALUATION ON CENSUS DATA AND HAMLET,[0],[0]
"JA, ZS, and HZ are supported by NSF CCF-1657471 and a Cornell University startup grant.",Acknowledgements,[0],[0]
"GK is supported by ONR N00014-12-1-0999, NSF CCF-1617730, CCF-1650733, and CCF-1741137.",Acknowledgements,[0],[0]
"Work partially done while author was an intern at Microsoft Research, New England.",Acknowledgements,[0],[0]
We develop differentially private methods for estimating various distributional properties.,abstractText,[0],[0]
"Given a sample from a discrete distribution p, some functional f , and accuracy and privacy parameters α and ε, the goal is to estimate f(p) up to accuracy α, while maintaining ε-differential privacy of the sample.",abstractText,[0],[0]
"We prove almost-tight bounds on the sample size required for this problem for several functionals of interest, including support size, support coverage, and entropy.",abstractText,[0],[0]
"We show that the cost of privacy is negligible in a variety of settings, both theoretically and experimentally.",abstractText,[0],[0]
Our methods are based on a sensitivity analysis of several state-of-the-art methods for estimating these properties with sublinear sample complexities.,abstractText,[0],[0]
INSPECTRE: Privately Estimating the Unseen,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 57–67 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Frequently recurring sequences of events in prototypical scenarios, such as visiting a restaurant and driving to work, are a useful source of world knowledge.",1 Introduction,[0],[0]
"Two examples are shown in Figure 1, which are different variations of the “restaurant visiting” scenario, where events are partially ordered and can be flexible.",1 Introduction,[0],[0]
Such knowledge is useful for natural language understanding because texts typically do not include event details when mentioning a scenario.,1 Introduction,[0],[0]
"For example, the reader is expected to infer that the narrator could have been
∗This work has been done when the first author worked at SUTD.
1The term “temporal order” is used throughout this work to indicate the narrative order in texts, following Chambers and Jurafsky (2008).",1 Introduction,[0],[0]
"Strictly speaking, the event order we extract is the narrative order.
",1 Introduction,[0],[0]
driving or cycling given the text “I got flat tire”.,1 Introduction,[0],[0]
Another typical use of event chain knowledge is to help infer what is likely to happen next given a previous event sequence in a scenario.,1 Introduction,[0],[0]
"We investigate the modeling of stereotypical event chains, which is remotely similar to language modeling, but with events being more sparse and flexibly ordered than words.
",1 Introduction,[0],[0]
Our work follows a recent line of NLP research on script learning.,1 Introduction,[0],[0]
"Stereotypical knowledge about partially-ordered events, together with their participant roles such as “customer”, “waiter”, and “table”, is conventionally referred to as scripts (Schank et al., 1977).",1 Introduction,[0],[0]
"NLP algorithms have been investigated for automatically inducing scripts from unstructured texts (Mooney and DeJong, 1985; Chambers and Jurafsky, 2008).",1 Introduction,[0],[0]
"In particular, Chambers and Jurafsky (2008) made a first attempt to learn scripts from test inducing event
57
chains by grouping events based on their narrative coherence, calculated based on Pairwise Mutual Information (PMI).",1 Introduction,[0],[0]
"Jans et al. (2012) showed that the method can be improved by calculating event relations using skip bi-gram probabilities, which explicitly model the temporal order of pairs event.",1 Introduction,[0],[0]
"Jans et al. (2012)’s model is adopted by a line of subsequent methods on inducing event chains from text (Orr et al., 2014; Pichotta and Mooney, 2014; Rudinger et al., 2015).
",1 Introduction,[0],[0]
"While the above methods are statistical, neural network models have recently been used for event sequence modeling.",1 Introduction,[0],[0]
Granroth-Wilding and Clark (2016) used a Siamese Network instead of PMI to calculate the coherence between two events.,1 Introduction,[0],[0]
"Rudinger et al. (2015) extended the idea of Jans et al. (2012) by using a log-bilinear neural language model (Mnih and Hinton, 2007) to calculate event probabilities.",1 Introduction,[0],[0]
"By learning embeddings for reducing sparsity, the above models give much better results compared to the models of Chambers and Jurafsky (2008) and Jans et al. (2012).",1 Introduction,[0],[0]
"Similar in spirit, Modi (2016) predicted the probability of an event belonging to a certain event chain by modeling known events in the chain as a bag of vectors, showing that it outperforms discrete statistical methods.",1 Introduction,[0],[0]
"These neural methods are consistent with the earlier statistical models in leveraging event-pair relations.
",1 Introduction,[0],[0]
"Pichotta and Mooney (2016) experimented with LSTM for script learning, using an existing sequence of events to predict the probability of a next event, which outperformed strong discrete baselines.",1 Introduction,[0],[0]
One advantage of LSTMs is that they can encode unbounded time sequences without losing long-term historical information.,1 Introduction,[0],[0]
"LSTMs capture significantly more order information compared to the methods of Granroth-Wilding and Clark (2016), Rudinger et al. (2015), and Modi (2016), which model the temporal order of only pairs of events.",1 Introduction,[0],[0]
"On the other hand, a strong-order LSTM model can also suffer the disadvantage of over-fitting, given the flexible order of event chains in a script, as demonstrated by the cases of Figure 1.",1 Introduction,[0],[0]
"In this aspect, event-pair models are more adaptive for flexible orders.",1 Introduction,[0],[0]
"However, no direct comparisons have been reported between LSTM and various existing neural network methods that model event-pairs.
",1 Introduction,[0],[0]
"We make such comparisons using the same benchmark, finding that the method of Pichotta
and Mooney (2016) does not necessarily outperform event-pair models, such as Granroth-Wilding and Clark (2016).",1 Introduction,[0],[0]
LSTM temporal ordering and event pair modeling have their respective strength.,1 Introduction,[0],[0]
"To leverage the advantages of both methods, we propose to integrate chain temporal order information into event relation measuring.",1 Introduction,[0],[0]
"In particular, we calculate event pair relations by representing events in a chain using LSTM hidden states, which encode temporal information.",1 Introduction,[0],[0]
"The LSTM over-fitting issue is mitigated by using the temporal-order in a chain as a feature for event pair modeling, rather than the direct model output.",1 Introduction,[0],[0]
"In addition, observing that the importance of existing events can vary for inferring a subsequent event, we use a dynamic memory network model to automatically induce event weights for each event for inferring the next event.",1 Introduction,[0],[0]
"In contrast, previous methods give equal weights to existing events (Chambers and Jurafsky, 2008; Modi, 2016; Granroth-Wilding and Clark, 2016).
Results on a multi-choice narrative cloze benchmark show that our model significantly outperforms both Granroth-Wilding and Clark (2016) and Pichotta and Mooney (2016), improving the state-of-the-art accuracy from 49.57% to 55.12%.",1 Introduction,[0],[0]
"Our contributions can be summarized as follows:
• We make a systematic comparison of LSTM and pair-based event sequence learning methods using the same benchmarks.
",1 Introduction,[0],[0]
"• We propose a novel dynamic memory network model, which combines the advantages of both LSTM temporal order learning and traditional event pair coherence learning.
",1 Introduction,[0],[0]
"• We obtain the best results in the standard multi-choice narrative cloze test.
",1 Introduction,[0],[0]
Our code is released at https://github.,1 Introduction,[0],[0]
com/wangzq870305/event_chain.,1 Introduction,[0],[0]
"Scripts have been a traditional subject in AI research (Schank et al., 1977), where event sequences are manually encoded in knowledge bases, and used for end tasks such as inference.",2 Related Work,[0],[0]
"They are also connected with research in linguistics and psychology, and sometimes referred to as frames (Minsky, 1975; Fillmore, 1982) and schemata (Rumelhart, 1975).",2 Related Work,[0],[0]
"The same concept
is also studied as templates in information extraction (Sundheim, 1991).",2 Related Work,[0],[0]
"Chambers and Jurafsky (2008) pioneered the recent line of work on script induction (Jans et al., 2012; Pichotta and Mooney, 2016; Granroth-Wilding and Clark, 2016), where the focus is on modeling narrative event chains, a crucial subtask for script modeling from raw text.",2 Related Work,[0],[0]
"Below we summarize such investigations.
",2 Related Work,[0],[0]
"With respect to event representation, Chambers and Jurafsky (2008) casted narrative events as triples of the form 〈event, dependency〉, where the event is typically represented by a verb and the dependency represents typed dependency relations between the event and a protagonist, such as “subject” and “object”.",2 Related Work,[0],[0]
"Chambers and Jurafsky (2008) organized narrative chains around a central actor, or protagonist, mining events that share a common protagonist from texts by using a syntactic parser and a coreference resolver.",2 Related Work,[0],[0]
"Balasubramanian et al. (2013) observed that the protagonist representation of event chains can suffer from weaknesses such as lack of coherence, and proposed to represent events as 〈arg1, relation, arg2〉, where arg1 and arg2 represent the subject and object, respectively.",2 Related Work,[0],[0]
"Such representation is inspired by open information extraction (Mausam et al., 2012), and offers richer features for event pair modeling.",2 Related Work,[0],[0]
"Pichotta and Mooney (2014) adpoted a similar idea, using v(es, eo, ep) to represent an event, where v is a verb lemma, es is the subject, eo is the object, and ep is an entity with prepositional relation to v. Their representation is used by subsequent work such as Modi (2016) and Granroth-Wilding and Clark (2016).",2 Related Work,[0],[0]
"We follow Pichotta and Mooney (2016) in our event representation form.
",2 Related Work,[0],[0]
"With respect to modeling, existing methods can be classified into two main categories, namely weak-order models, which calculate relations between pairs of events, and strong-order models, which consider the temporal order of events in a full sequence.",2 Related Work,[0],[0]
Event-pair models have so far been the dominant method in the literature.,2 Related Work,[0],[0]
Earlier work used discrete event representations and estimated event relations by statistical counting.,2 Related Work,[0],[0]
"As mentioned earlier, Chambers and Jurafsky (2008) used PMI to calculate event relations, and Jans et al. (2012) used skip bigram probabilites to the same end, which is order-sensitive.",2 Related Work,[0],[0]
"Most subsequent methods followed Jans et al. (2012) in using skip n-grams (Pichotta and Mooney, 2014; Rudinger et al., 2015).
",2 Related Work,[0],[0]
"Events being multi-argument structures, counting-based methods can suffer from sparsity issues.",2 Related Work,[0],[0]
Recent work employed embeddings to address this disadvantage.,2 Related Work,[0],[0]
Rudinger et al. (2015) learned event embeddings as a by-product of training a log-bilinear language model for events; Granroth-Wilding and Clark (2016) leveraged the skip-gram model of Mikolov et al. (2013) for training the embeddings of event and arguments by ordering them into a pseudo sentence.,2 Related Work,[0],[0]
"Modi (2016) utilized word embeddings of verbs and arguments directly, using a hidden layer to automatically consolidate word embedding into a single structured event embeddings.",2 Related Work,[0],[0]
"We follow Modi (2016) and use a hidden layer to learn event argument compositions given word embeddings, training the composition function as a part of the event chain learning process.
",2 Related Work,[0],[0]
"Mitigating the sparsity issue of event representations, neural methods can capture temporal orders between events beyond skip n-grams.",2 Related Work,[0],[0]
Our model integrates the advantages of strong-order learning and event-pair learning by using LSTM hidden states as feature representation of existing events in the calculation of event pair relationships.,2 Related Work,[0],[0]
"In addition, we use a memory network model to weigh existing events, which gives better results compared to the equal weighting method of existing models.
",2 Related Work,[0],[0]
"With respect to evaluation, Chambers and Jurafsky (2008) proposed the Narrative Cloze Test, which asks for a missing event in a given event chain with a gap.",2 Related Work,[0],[0]
"The task has been adopted by various subsequent work for comparing results with Chambers and Jurafsky (2008) (Jans et al., 2012; Pichotta and Mooney, 2014; Rudinger et al., 2015).",2 Related Work,[0],[0]
"One issue of the narrative cloze test is that there can sometimes be multiple plausible answers, but only one gold-standard answer, which can make it overly expensive to manually evaluate system outputs.",2 Related Work,[0],[0]
"To address this issue, Modi (2016) proposed the Adversarial Narrative Cloze (ANC) task, which is to discriminate between pairs of real and corrupted event chains.",2 Related Work,[0],[0]
"Granroth-Wilding and Clark (2016) proposed the Multi-Choice Narrative Cloze (MCNC) task, which is to choose the most likely next event from a set of candidates given a chain of events.",2 Related Work,[0],[0]
"We choose MCNC for comparing different models.
",2 Related Work,[0],[0]
"Other related work includes learning temporal relations of events (Modi and Titov, 2014; Uz-
Zaman et al., 2013; Abend et al., 2015), evaluated using different metrics.",2 Related Work,[0],[0]
"There has also been work using graph models to induce frames, which emphasize more on learning event structures and less on temporal orders (Chambers, 2013; Cheung et al., 2013).",2 Related Work,[0],[0]
The above methods focus on one of the two subtasks we consider here.,2 Related Work,[0],[0]
Frermann et al. (2014) used a Bayesian model to jointly cluster web collections of explicit event sequence and learn input event-pair temporal orders.,2 Related Work,[0],[0]
"However, their work is under a different input setting (Regneri et al., 2010), not learning event chains from texts.",2 Related Work,[0],[0]
"Mostafazadeh et al. (2016) proposed the story close task (SCT), which is to predict the ending given a unfinished story.",2 Related Work,[0],[0]
"Our narrative chain prediction task can be regarded as a sub task in the story close task, which can contribute as a major approach.",2 Related Work,[0],[0]
"On the other hand, information beyond event chains can be useful for the story close task.",2 Related Work,[0],[0]
"As shown in Figure 2, given a chain of narrative events e1, e2, ..., en−1, our work is to predict the likelihood of a next event candidate en.",3 Problem Definition,[0],[0]
"Formally, an event e is a structure v(a0, a1, a2), where v is a verb describing the event, a0 and a1 are its subject and direct object, respectively, and a2 is a prepositional object.",3 Problem Definition,[0],[0]
"For example, given the sentence “John brought Marry to the restaurant”, an event bring{John,Marry , to the restaurant} can be extracted.
",3 Problem Definition,[0],[0]
"We follow the standard script induction setting (Chambers and Jurafsky, 2008; GranrothWilding and Clark, 2016), extracting events from a text corpus using a syntactic parser and a named entity resolver.",3 Problem Definition,[0],[0]
A neural network is used to model chains of extracted events for script learning.,3 Problem Definition,[0],[0]
"In particular, we model the probability of a sub-
sequent event given a chain of events.",3 Problem Definition,[0],[0]
"For evaluation, we solve the multi-choice narrative cloze task: given a chain of events and a set of candidate next events, the most likely candidate is chosen as the output.",3 Problem Definition,[0],[0]
"The overall structure of our model is shown in Figure 3, which has three main components.",4 Model,[0],[0]
"First, given an event v(a0, a1, a2), a representation layer is used to compose the embeddings of v, a0, a1, and a2 into a single event vector e. Second, a LSTM is used to map a sequence of existing events e1, e2, ..., en−1 into a sequence of hidden vectors h1, h2, ..., hn−1, which encode the temporal order.",4 Model,[0],[0]
"Given a next event candidate ec, the recurrent network takes one further step from hn−1 to derive its hidden vector hc, which encodes ec.",4 Model,[0],[0]
"Third, hc is paired with h1, h2, ..., hn−1 individually, and passed to a dynamic memory network to learn the relatedness score s. s is used to denote the connectedness between the candidate subsequent event and the context event chain.",4 Model,[0],[0]
We learn vector representations of standard events by composing pre-trained word embeddings of its verb and arguments.,4.1 Event Representation,[0],[0]
"The skipgram model (Mikolov et al., 2013) is used to train word vectors.",4.1 Event Representation,[0],[0]
"For arguments that consist of more than one word, we use the averaged word for the representation.",4.1 Event Representation,[0],[0]
OOV words are represented simply using zero vectors.,4.1 Event Representation,[0],[0]
"For events with less than 3 arguments, such as “John fell”, where v = fall, a0 = John, a1 = NULL, and a2 = NULL, the NULL arguments are represented using all-zero vectors.
",4.1 Event Representation,[0],[0]
"Denoting the embeddings of v, a0, a1, and a2 as e(v), e(a0), e(a1), and e(a2), respectively, the embedding of e is calculated using a tanh composition layer
e(e) =",4.1 Event Representation,[0],[0]
"tanh(W ve · e(v) +W 0e · e(a0)+ W 1e · e(a1) +W 2e · e(a2) + be)
(1)
",4.1 Event Representation,[0],[0]
"Here W ve , W 0 e , W 1 e , W 2 e , and b are model parameters, which are randomly initialized and tuned during the training of the main network.",4.1 Event Representation,[0],[0]
"Given the embeddings of the existing chain of events e1, e2, ..., en−1, we use a standard LSTM (Hochreiter and Schmidhuber, 1997) without
coupled input and forget gates or peephole connections to model the temporal order.",4.2 Modeling Temporal Orders,[0],[0]
"We obtain a sequence of hidden state vectors h1, h2, ..., hn−1 by recurrently feeding e(e1), e(e2), ..., e(en−1) as inputs to the LSTM, where hi = LSTM(e(ei), hi−1).",4.2 Modeling Temporal Orders,[0],[0]
"The initial state hs and all stand LSTM parameters are randomly initialized and tuned during training.
",4.2 Modeling Temporal Orders,[0],[0]
"Now for each candidate next event ec, we obtain its vector representation e(ec) in the same way as for e1 to en−1. e(ec) is then appended to the existing event chain to obtain a temporal-ordersensitive feature vector hc, by advancing the recurrent encoding process for one step from hn−1: hc = LSTM(e(ec), hn−1).",4.2 Modeling Temporal Orders,[0],[0]
"With multiple next event candidates e1c , e 2 c , ..., e m c (m ∈ [1,∞]), m feature vectors are obtained, as shown in Figure 4, each being used as a basis for estimating the probability of the corresponding event candidate.",4.2 Modeling Temporal Orders,[0],[0]
"After obtaining the hidden states for events, we model event pair relations using these hidden state vectors.",4.3 Modeling Pairwise Event Relations,[0],[0]
"A straightforward approach to model the relation between two events is using a Siamese network (Granroth-Wilding and Clark, 2016).",4.3 Modeling Pairwise Event Relations,[0],[0]
"The order-sensitive LSTM features for existing events h1, h2, ..., hn−1 and the candidate event hc are
used as event representations.",4.3 Modeling Pairwise Event Relations,[0],[0]
Given a pair of events hi (i ∈,4.3 Modeling Pairwise Event Relations,[0],[0]
[1..n,4.3 Modeling Pairwise Event Relations,[0],[0]
"− 1]) and hc, the relatedness score is calculated by
si = sigmoid(Wsihi +Wschc + bs), (2)
where Wsi, Wsc and bs are model parameters.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Given the relation score si between hc and each existing event hi, the likelihood of ec given e1, e2, ..., en−1 can be calculated as the average of si:
s = ∑n−1
i=1",4.3 Modeling Pairwise Event Relations,[0],[0]
"si n− 1 (3)
",4.3 Modeling Pairwise Event Relations,[0],[0]
Weighting existing events.,4.3 Modeling Pairwise Event Relations,[0],[0]
The drawback of above approach is that it considers the contribution of each event on the chain is same.,4.3 Modeling Pairwise Event Relations,[0],[0]
"However, given a chain of existing events, some are more informative for inferring a subsequent event than others.",4.3 Modeling Pairwise Event Relations,[0],[0]
"For example, given the events “wait in queue”, “getting seated” and “order food”, “order food” is more relevant for inferring “eat food” compared with the other two given events.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Given information over the full event chain, this link can be more evident since the scenario is likely restaurant visiting.
",4.3 Modeling Pairwise Event Relations,[0],[0]
"We use an attentional neural network to calculate the relative importance of each existing event according to the subsequent event candidate, using hi (i ∈",4.3 Modeling Pairwise Event Relations,[0],[0]
"[1..n−1]) and hc for event representations:
ui = tanh(Weihi +Wchc + bu) (4)
αi = exp(ui)∑ j exp(uj)
(5)
where αi ∈",4.3 Modeling Pairwise Event Relations,[0],[0]
"[0, 1] is the weight of hi, and ∑ i α t",4.3 Modeling Pairwise Event Relations,[0],[0]
i = 1.,4.3 Modeling Pairwise Event Relations,[0],[0]
"Wei, Wc, and bu are model parameters.",4.3 Modeling Pairwise Event Relations,[0],[0]
"After obtaining the weight αi of each existing event hi, the relatedness of ec with the existing events can be calculated as:
s = n−1∑ i=1",4.3 Modeling Pairwise Event Relations,[0],[0]
"αi · si (6)
",4.3 Modeling Pairwise Event Relations,[0],[0]
Multi-layer attention using Deep memory network.,4.3 Modeling Pairwise Event Relations,[0],[0]
"Memory network (Weston et al., 2014; Mikolov et al., 2014) has been used for exploring deep semantic information for semantic tasks.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Such as question answering (Sukhbaatar et al., 2015; Kumar et al., 2016) and reading comprehension (Hermann et al., 2015; Weston et al., 2015).",4.3 Modeling Pairwise Event Relations,[0],[0]
"Our task is analogous to such semantic tasks in
the sense that deep semantic information can be necessary for making the most rational inference.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Hence, we are motivated to use a deep memory network model to refine event weight and event relation calculation by recurrently modeling more abstract representations of the scenario.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Different from the previous researches, we use the memory network to model the event chain, refining the attention mechanism used to explore the pair-wise relation between events.
",4.3 Modeling Pairwise Event Relations,[0],[0]
The memory model consists of multiple dynamic computational layers (hops).,4.3 Modeling Pairwise Event Relations,[0],[0]
"For the first layer (hop 1), the weights α for existing events e1, e2, ..., en−1 can be calculated using the same attention mechanism as Eq.4 and Eq.5.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Given the weights α, we build a consolidated representation of context event chain e1, e2, ..., en−1 as a weighted sum of h1, h2, ..., hn−1:
he = n−1∑ i−1 αi · hi (7)
",4.3 Modeling Pairwise Event Relations,[0],[0]
"The event candidate hc and the new representation of the existing chain he can be further integrated to deduce a deeper representation of the full event chain hypothesis to the next layer (hop 2), denoted as v. v contains deeper semantic information compared with hc, which encode the temporal order of the event chain [h1, h2, ..., hn−1, hc] without differentiating the weights of each event.",4.3 Modeling Pairwise Event Relations,[0],[0]
"As a result, in the next hop, better event weights can potentially be deduced by using v instead of hc in the calculation of attention:
uti = tanh(Weihi +Wvv t + bu) (8)
αti = exp(uti)∑ j exp(u t j)
(9)
",4.3 Modeling Pairwise Event Relations,[0],[0]
"In the same way, we stack multiple hops and repeat the steps multiple times, so that more abstract evidences can be extracted according to the chain of existing events.",4.3 Modeling Pairwise Event Relations,[0],[0]
"The above process can be performed recurrently, by taking hc as an initial scenario representation v0, and then repeatedly calculating hte given h1, h2, ..., hn−1 and vt, and using hte and vt to find a deeper scenario representation vt+1.",4.3 Modeling Pairwise Event Relations,[0],[0]
"Following Chung et al. (2014) and Tran et al. (2016), a gated recurrent network is used to this end:
z = σ(Wzhte +",4.3 Modeling Pairwise Event Relations,[0],[0]
Uzv t),4.3 Modeling Pairwise Event Relations,[0],[0]
"r = σ(Wrhte + Urv t)
ĥ = tanh(Whte + U(r vt))",4.3 Modeling Pairwise Event Relations,[0],[0]
vt+1,4.3 Modeling Pairwise Event Relations,[0],[0]
=,4.3 Modeling Pairwise Event Relations,[0],[0]
"(1− z) vt + z ĥ
(10)
",4.3 Modeling Pairwise Event Relations,[0],[0]
"At any step, if the value of |vt+1−vt| is less than the threshold µ, we consider that the progress has reached convergence.",4.3 Modeling Pairwise Event Relations,[0],[0]
Figure 5 shows an overview of the memory network at hop t.,4.3 Modeling Pairwise Event Relations,[0],[0]
"Given a set of event chains, each with a goldstandard subsequent event and a number of nonsubsequent events, our training objective is to minimize the cross-entropy loss between the gold subsequent event and the set of non-subsequent events.",4.4 Training,[0],[0]
"The loss function of event chain prediction is that:
L(Θ) = N∑
i=1
(si − yi)2 + λ2 ||Θ|| 2 (11)
where si is the relation score, yi is the label of the candidate (yi = 1 for positive sample, and yi = 0 for negative sample), Θ is the set of model parameters and λ is a parameter for L2 regularization.",4.4 Training,[0],[0]
"We apply online training, where model parameters are optimized by using AdaGrad (Duchi et al., 2011).",4.4 Training,[0],[0]
"We train word embedding using the Skipgram algorithm (Mikolov et al., 2013)2.",4.4 Training,[0],[0]
"Following Granroth-Wilding and Clark (2016), we extract events from the NYT portion of the Gigaword corpus (Graff et al., 2003).",5.1 Datasets,[0],[0]
"The C&C
2https://code.google.com/p/word2vec/
tools (Curran et al., 2007) are used for POS tagging and dependency parsing, and OpenNLP3 for phrase structure parsing and coreference resolution.",5.1 Datasets,[0],[0]
"The training set consists of 1,500,000 event chains.",5.1 Datasets,[0],[0]
"We follow Granroth-Wilding and Clark (2016) and use 10,000 event chains as the test set, and 1,000 event chains for development.",5.1 Datasets,[0],[0]
"There are 5 choices of output event for event input chain, which are given by Granroth-Wilding and Clark (2016).",5.1 Datasets,[0],[0]
"This dataset is referred to as G&C16.
",5.1 Datasets,[0],[0]
"We also adapt the Chambers and Jurafsky (2008)’s dataset to the multiple choice setting, and use this dataset as the second benchmark.",5.1 Datasets,[0],[0]
"The dataset contains 69 documents, with 346 multiple choice event chain samples.",5.1 Datasets,[0],[0]
We randomly sample 4 negative subsequent events for each event chain to make multiple-choice candidates.,5.1 Datasets,[0],[0]
This dataset is referred to as C&J08.,5.1 Datasets,[0],[0]
"For both datasets, accuracy (Acc.) of the chosen subsequent event is used to measure the performance of our model.",5.1 Datasets,[0],[0]
"There are several important hyper-parameters in our models, and we tune their values using the development dataset.",5.2 Hyper-parameters,[0],[0]
We set the regularization weight λ = 10−8 and the initial learning rate to 0.01.,5.2 Hyper-parameters,[0],[0]
"The size of word vectors is set to 300, and the size of hidden vectors in LSTM to 128.",5.2 Hyper-parameters,[0],[0]
"In order to avoid over-fitting, dropout (Hinton et al., 2012) is used for word embedding with a ratio of 0.2.",5.2 Hyper-parameters,[0],[0]
The neighbor similarity threshold η is set to 0.25.,5.2 Hyper-parameters,[0],[0]
The threshold µ of the memory network sets to 0.1.,5.2 Hyper-parameters,[0],[0]
We conduct a set of development experiments on the G&C16 development set to study the influence of event argument representations and network configurations of the proposed MemNet model.,5.3 Development Experiments,[0],[0]
"Existing literature discussed various structures to denote events, such as v(a0, a1) and v(a0, a1, a2).",5.3.1 Influence of Event Structure,[0],[0]
"We investigate the influence of integrating argument values of the subject a0, object a1 and preposition a2, by doing ablation experiments on the development data.",5.3.1 Influence of Event Structure,[0],[0]
"The results are shown in Table 1, where the system using all arguments gives a 54.36% accuracy.",5.3.1 Influence of Event Structure,[0],[0]
"By removing a2, which exists in 17.6% of the events in our developmental data, the
3https://opennlp.apache.org/
accuracy drops to 54.02%.",5.3.1 Influence of Event Structure,[0],[0]
"In contrast, by removing a0 and a1, which exist in 87.6% and 64.6% of the events in the development data, respectively, the accuracies drop to 53.43% and 53.57%, respectively, which demonstrates the relative importance of a0 (i.e., the subject) and a1 (i.e., the object) for event modelling.",5.3.1 Influence of Event Structure,[0],[0]
"While most previous work (Chambers and Jurafsky, 2008; Balasubramanian et al., 2013; Pichotta and Mooney, 2014) modelled only a0 and a1, recent work (Pichotta and Mooney, 2016; Granroth-Wilding and Clark, 2016) modelled a2 also.
",5.3.1 Influence of Event Structure,[0],[0]
"By removing both a1 and a2, the accuracy drops further to 53.32%.",5.3.1 Influence of Event Structure,[0],[0]
"Interestingly, by removing the verb while keeping only the arguments, the accuracy drops to 42.63%.",5.3.1 Influence of Event Structure,[0],[0]
"While this demonstrates the central value of the verb in denoting a event, it also suggests that the arguments themselves play a useful role in inferring the stereotypical scenario.",5.3.1 Influence of Event Structure,[0],[0]
"We study the influence of various network configurations by performing ablation experiments, as shown in Table 2.",5.3.2 Influence of Network Configurations,[0],[0]
"MemNet is the full model of this paper; -LSTM denotes ablation of the LSTM layer, using e(e1), e(e2), ..., e(en−1) instead of h1, h2, ..., hn−1 to represent events; -Hop denotes ablation of the dynamic network model, using only attention mechanism to calculate the weights of each existing event; -Attention denotes ablation of the attention mechanism, using the same weight on each existing event when inferring ec.",5.3.2 Influence of Network Configurations,[0],[0]
"The model “-Attention, -LSTM” is hence similar to the method of Granroth-Wilding and Clark (2016), although we used a different way of deriving event embeddings.",5.3.2 Influence of Network Configurations,[0],[0]
"The model “LSTM-only” shows a based by using LSTM hidden vector hn−1 to directly predict the next event, which is similar to the method of Pichotta and Mooney (2016).
",5.3.2 Influence of Network Configurations,[0],[0]
Influence of Temporal Order.,5.3.2 Influence of Network Configurations,[0],[0]
"By comparing “MemNet” and “-LSTM”, and comparing “-
Attention” with “-Attention, -LSTM”, one can find that temporal order information over the whole event chain does have significant influence on the results (p − value < 0.01 using t-test).",5.3.2 Influence of Network Configurations,[0],[0]
"On the other hand, using LSTM to directly predict the subsequent event (“LSTM-only”) does not give better accuracies compared to model event pairs (“-Attention, -LSTM”).",5.3.2 Influence of Network Configurations,[0],[0]
"This confirms our intuition that strong-oder modelling and event-pair modelling each have their own strength.
",5.3.2 Influence of Network Configurations,[0],[0]
Influence of Attention.,5.3.2 Influence of Network Configurations,[0],[0]
"Comparison between “-Attention” and “-Hop”, and between “- Attention, -LSTM” and “-Hop, -LSTM” shows that giving different weights to different events does lead to improving results.",5.3.2 Influence of Network Configurations,[0],[0]
Our analysis in Section 4.3 gives more intuitions to this observation.,5.3.2 Influence of Network Configurations,[0],[0]
"Finally, comparison between “-Hop” and “MemNet” and between “-Hop, -LSTM” and “- LSTM” shows that a multi-hop deep memory network can indeed enhance the model with single level attention by offering more effective semantic representation of the scenarios.",5.3.2 Influence of Network Configurations,[0],[0]
"Table 3 shows the final results on the C&C 16 and C&J08 datasets, respectively.",5.4 Final Results,[0],[0]
"We compare the results of our final model with the following baselines:
• PMI is the co-occurrence based model of Chambers and Jurafsky (2008), who calculate event pair relations based on Pointwise Mutual Information (PMI), scoring each candidate event ec by the sum of PMI scores between the given events e0, e1, ..., en−1 and the candidate.
",5.4 Final Results,[0],[0]
"• Bigram is the counting based model of Jans et al. (2012), calculating event pair relations based on skip bigram probabilities, trained using maximum likelihood estimation.
",5.4 Final Results,[0],[0]
• Event-Comp is the neural event relation model proposed by Granroth-Wilding and Clark (2016).,5.4 Final Results,[0],[0]
"They learn event representations by calculating pair-wise event scores using a Siamese network.
",5.4 Final Results,[0],[0]
"• RNN is the method of Pichotta and Mooney (2016), who model event chains by directly using hc in Section 4.2 to predict the output, rather than taking them as features for event pair relation modeling.
",5.4 Final Results,[0],[0]
"• MemNet is the proposed deep memory network model.
",5.4 Final Results,[0],[0]
"Our reimplementation of PMI and Bigrams follows (Granroth-Wilding and Clark, 2016).",5.4 Final Results,[0],[0]
"It can be seen from the table that the statistical counting-based models PMI and Bigram significantly underperform the neural network models Event-Comp, RNN and MemNet, which is largely due to their sparsity and lack of semantic representation power.",5.4 Final Results,[0],[0]
"Under our event representation, Bigram does not outperform PMI significantly either, although considering the order of event pairs.",5.4 Final Results,[0],[0]
"This is likely due to sparsity of events when all arguments are considered.
",5.4 Final Results,[0],[0]
Direct comparison between Event-Comp and RNN shows that the event-pair model gives comparable results to the strong-order LSTM model.,5.4 Final Results,[0],[0]
"Although Granroth-Wilding and Clark (2016) and Pichotta and Mooney (2016) both compared with statistical baselines, they did not make direct comparisons between their methods, which represent two different approaches to the task.",5.4 Final Results,[0],[0]
"Our results show that they each have their unique advantages, which confirm our intuition in the introduction.",5.4 Final Results,[0],[0]
"By considering both pairwise relations and chain temporal orders, our method significantly outperform both Event-Comp and RNN (p − value < 0.01 using t-test), giving the best reported results on both datasets.",5.4 Final Results,[0],[0]
"We proposed a dynamic memory network to integrate chain order information into event relation measuring, calculating event pair relations by representing events in a chain using LSTM hidden states, which encode temporal orders, and using a dynamic memory model to automatically induce event weights for each event.",6 Conclusion,[0],[0]
"Standard evaluation showed that our method significantly outperforms state-of-the-art event pair models and event chain models, giving the best results reported so far.",6 Conclusion,[0],[0]
The corresponding author is Yue Zhang.,Acknowledgments,[0],[0]
We are grateful for the help of Fei Dong for his initial discussion.,Acknowledgments,[0],[0]
"We thank our anonymous reviewers for their constructive comments, which helped to improve the paper.",Acknowledgments,[0],[0]
This work is supported by the Temasek Lab grant IGDST1403012 at Singapore University of Technology and Design.,Acknowledgments,[0],[0]
"There has been a recent line of work automatically learning scripts from unstructured texts, by modeling narrative event chains.",abstractText,[0],[0]
"While the dominant approach group events using event pair relations, LSTMs have been used to encode full chains of narrative events.",abstractText,[0],[0]
"The latter has the advantage of learning long-range temporal orders1, yet the former is more adaptive to partial orders.",abstractText,[0],[0]
"We propose a neural model that leverages the advantages of both methods, by using LSTM hidden states as features for event pair modelling.",abstractText,[0],[0]
A dynamic memory network is utilized to automatically induce weights on existing events for inferring a subsequent event.,abstractText,[0],[0]
"Standard evaluation shows that our method significantly outperforms both methods above, giving the best results reported so far.",abstractText,[0],[0]
Integrating Order Information and Event Relation for Script Event Prediction,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3164–3173 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3164",text,[0],[0]
Sentence simplification aims to reduce the complexity of a sentence while retaining its original meaning.,1 Introduction,[0],[0]
"It can benefit individuals with lowliteracy skills (Watanabe et al., 2009) including children, non-native speakers and individuals with language impairments such as dyslexia (Rello et al., 2013), aphasic (Carroll et al., 1999).
",1 Introduction,[0],[0]
"Most of the previous studies tackled this task in a way similar to machine translation (Xu et al., 2015a; Zhang and Lapata, 2017), in which models are trained on a large number of pairs of sentences, each consisting of a normal sentence and a simplified sentence.",1 Introduction,[0],[0]
Statistical and neural network modeling are two major methods used for this task.,1 Introduction,[0],[0]
"The statistical models have the benefit of easily integrating with human-curated rules and features,
thus they generally perform well even they are trained with a limited number of data.",1 Introduction,[0],[0]
"In contrast, neural network models could learn the simplifying rules automatically without the need for feature engineering, but at the cost of requiring a huge amount of training data.",1 Introduction,[0],[0]
"Even though models based on neural networks have outperformed the statistical methods in multiple Natural Language Processing (NLP) tasks, their performance in sentence simplification is still inferior to that of statistical models (Xu et al., 2015a; Zhang and Lapata, 2017).",1 Introduction,[0],[0]
We speculate that current training datasets may not be large and broad enough to cover common simplification situations.,1 Introduction,[0],[0]
"However, humancreated resources do exist which can provide abundant knowledge for simplification.",1 Introduction,[0],[0]
"This motivates us to investigate if it is possible to train neural network models with these types of resources.
",1 Introduction,[0],[0]
Another limitation to using existing neural network models for sentence simplification is that they are only able to capture frequent transformations; they have difficulty in learning rules that are not frequently observed despite their significance.,1 Introduction,[0],[0]
"This may be due to nature of neural networks (Feng et al., 2017): during training, a neural network tunes its parameters to learn how to simplify different aspects of the sentence, which means that all the simplification rules are actually contained in the shared parameters.",1 Introduction,[0],[0]
"Therefore, if one simplification rule appears more frequently than others, the model will be trained to be more focused on it than the infrequent ones.",1 Introduction,[0],[0]
"Meanwhile, models tend to treat infrequent rules as noise if they are merely trained using sentence pairs.",1 Introduction,[0],[0]
"If we can leverage an additional memory component to maintain simplification rules individually, it would prevent the model from forgetting low-frequency rules as well as help it to distinguish real rules from noise.",1 Introduction,[0],[0]
"Therefore, we propose the Deep Memory Augmented Sentence Simplification (DMASS) model.",1 Introduction,[0],[0]
"For comparison pur-
pose, we also introduce another approach, Deep Critic Sentence Simplification (DCSS) model, to encourage applying the less frequently occurring rules by revising the loss function.",1 Introduction,[0],[0]
"It this way, simplification rules are encouraged to maintained internally in the shared parameters while avoiding the consumption of an unwieldy amount of additional memory.
",1 Introduction,[0],[0]
"In this study, we propose two improvements to the neural network models for sentence simplification.",1 Introduction,[0],[0]
"For the first improvement, we propose to use a multi-layer, multi-head attention architecture (Vaswani et al., 2017).",1 Introduction,[0],[0]
"Compared to RNN/LSTM (Recurrent Neural Network / Long Short-term Memory), the multi-layer, multi-head attention model would be able to selectively choose the correct words in the normal sentence and simplify them more accurately.
",1 Introduction,[0],[0]
"Secondly, we propose two new approaches to integrate neural networks with human-curated simplification rules.",1 Introduction,[0],[0]
Note that previous studies rarely tried to incorporate explicit human language knowledge into the encoder-decoder model.,1 Introduction,[0],[0]
"Our first approach, DMASS, maintains additional memory to recognize the context and output of each simplification rules.",1 Introduction,[0],[0]
"Our second approach, DCSS, follows a more traditional approach to encode the context and output of each simplification rules into the shared parameters.
",1 Introduction,[0],[0]
Our empirical study demonstrates that our model outperforms all the previous sentence simplification models.,1 Introduction,[0],[0]
They achieve both a good coverage of rules to be applied (recall) and a high accuracy gained by applying the correct rules (precision).,1 Introduction,[0],[0]
"Sentence Simplification For statistical modeling, Zhu et al. (2010) proposed a tree-based sentence simplification model drawing inspiration from statistical machine translation.",2 Related Work,[0],[0]
Woodsend and Lapata (2011) employed quasi-synchronous grammar and integer programming to score the simplification rules.,2 Related Work,[0],[0]
"Wubben et al. (2012) proposed a two-stage model PBMT-R, where a standard phrase-based machine translation (PBMT) model was trained on normal-simple aligned sentence pairs, and several best generations from PBMT were re-ranked based how dissimilar they were to a normal sentence.",2 Related Work,[0],[0]
"Hybrid, a model proposed by Narayan and Gardent (2014) was also a
two-stage model combining a deep semantic analysis and machine translation framework.",2 Related Work,[0],[0]
"SBMTSARI (Xu et al., 2016) achieved state-of-the-art performance by employing an external knowledge base to promote simplification.",2 Related Work,[0],[0]
"In terms of neural network models, Zhang and Lapata (2017) argued that the RNN/LSTM model generated sentences but it does not have the capability to simplify them.",2 Related Work,[0],[0]
They proposed DRESS and DRESSLS that employ reinforcement learning to reward simpler outputs.,2 Related Work,[0],[0]
"As they indicated, the performance is still inferior due to the lack of external knowledge.",2 Related Work,[0],[0]
"Our proposed model is designed to address the deficiency of current neural network models which are not able to integrate an external knowledge base.
",2 Related Work,[0],[0]
"Augmented Dynamic Memory Despite positive results obtained so far, a particular problem with the neural network approach is that it has a tendency towards favoring to frequent observations but overlooking special cases that are not frequently observed.",2 Related Work,[0],[0]
"This weakness with regard to infrequent cases has been noticed by a number of researchers who propose an augmented dynamic memory for multiple applications, such as language models (Daniluk et al., 2017; Grave et al., 2016), question answering (Miller et al., 2016), and machine translation (Feng et al., 2017; Tu et al., 2017).",2 Related Work,[0],[0]
"We find that current sentence simplification models suffer from a similar neglect of infrequent simplification rules, which inspires us to explore augmented dynamic memory.",2 Related Work,[0],[0]
"Our basic neural network-based sentence simplification model utilizes a multi-layer and multi-head attention architecture (Vaswani et al., 2017).","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"As shown in Figure 1, our model based on the Transformer architecture works as follows: given a pair consisting a normal sentence I and a simple sentence","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"O, the model learns the mapping from I to O.
The encoder part of the model (see the left part of Figure 1) encodes the normal sentence with a stack ofL identical layers.","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
Each layer has two sublayers: one layer is for multi-head self-attention and the other one is a fully connected feed-forward neural network for transformation.,"3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"The multi-head self-attention layer encodes the output from the
previous layer into hidden state e(s,l) (step s and layer l) as shown in Equation 1, where αenc(s′,l) indicates the attention distribution over the step s′ and layer l. Each hidden state summarizes the hidden states in the previous layer through the multi-head attention function a() (Vaswani et al., 2017) where H refers to the number of heads.
","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
The right part of Figure 1 denotes the decoder for generating the simplified sentence.,"3.1 Multi-Layer, Multi-Head Attention",[0],[0]
The decoder also consists of a stack of L identical layers.,"3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"In addition to the same two sub-layers as those in the encoder part, the decoder also inserts another multi-head attention layer aiming to attend on the encoder outputs.","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"The bottom multi-head self-attention plays the same role as the one in the encoder, where the hidden state d(s,l) is computed in the Equation 2.","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
The upper multi-head attention layer is used to seek relevant information from encoder outputs.,"3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"Through the same mechanism, context vector c(s,l) (step s and layer l) is computed in
the Equation 3.","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"e(s,l) = ∑ s′ αenc(s′,l)e(s′,l−1), α enc (s′,l) =a(e(s,l), e(s′,l−1), H) 1
(1) d(s,l) = ∑ s′ αdec(s′,l)d(s′,l−1), α dec (s′,l) =a(d(s,l), c(s′,l−1), H) 2
(2) c(s,l) = ∑ s′ αdec2(s′,l)e(s′,L), α dec2 (s′,l) =a(d(s,l), e(s′,L), H)
(3)
","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"The model is trained to minimize the negative log-likelihood of the simple sentence, Lseq = −logP (O|I, θ) where θ represents all the parameters in the current model.","3.1 Multi-Layer, Multi-Head Attention",[0],[0]
"A previous study (Xu et al., 2016) has demonstrated the benefits of using an external knowledge base in conjunction with a statistical simplification model.",3.2 Integrating with Simple PPDB,[0],[0]
"However, as far as we know, no efforts have been made to integrate neural network models with the knowledge base, and our study is the first to meet this goal.
",3.2 Integrating with Simple PPDB,[0],[0]
"Simple PPDB (Pavlick and Callison-Burch, 2016) refers to a paraphrase knowledge base for simplification.",3.2 Integrating with Simple PPDB,[0],[0]
"It is a refined version of another knowledge, PPDB (Ganitkevitch et al., 2013), which was originally designed to support paraphrase.",3.2 Integrating with Simple PPDB,[0],[0]
"Simple PPDB contains 4.5 million paraphrase rules, each of which provides the mapping from a normal phrase to a simplified phrase, the syntactic type of the normal phrase, and the simplification weight.",3.2 Integrating with Simple PPDB,[0],[0]
"Table 1 shows four examples, where “recipient” can be simplified to “winner” with a weight 0.75530 if “recipient” is a singular noun (NN).",3.2 Integrating with Simple PPDB,[0],[0]
"The Simple PPDB offers guidance about whether a word needs to be simplified and how it should
1The lowest hidden state e(:,0) is the word embedding.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"2The lowest context vector c(:,0) is the word embedding.
be simplified.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
The Deep Critic Sentence Simplification (DCSS) model is designed to apply rules identified by the Simple PPDB by introducing a new loss function.,3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"Different from the standard loss function that minimizes the distance away from the ground truth, the new loss function aims to maximize the likelihood of applying simplification rules.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"It also reweights the probability of generating each word by its simplification weight in order to relieve the problem of overlooking infrequent simplification rules.
",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"For example, given a normal sentence in the training set, “the recipient of the kate greenaway medal”, the simplified sentence is “the winner of the kate greenaway medal.”, where “recipient” is simplified to “winner”, which is identified by Simple PPDB.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
The major goal of the loss functions is to support the model in generating the simplified word “winner” while deterring the model from generating the word “recipient”.,3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"Specifically, for an applicable simplification rule, our new loss function maximizes the probability of generating the simplified form (word “winner”) and meanwhile minimizes the probability of generating the original form (word “recipient”).",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"As in Equation 4, where wrule indicates the weight of the simplification rule provided by the Simple PPDB, once the model generates “recipient”, the model is criticized to generate word “winner”; when model predicts correctly with “winner”, the model is trained to minimize the probability of “recipient”.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"In this way, the model avoids selecting normal words and instead becomes inclined to choose the simplified words.
",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"Lcritic =  −wrulelogP (winner|I, θ) if model generates recipient wrulelogP (recipient|I, θ)
if model generates winner (4)
",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
The Lcritic merely focuses on the words identified by the Simple PPDB and Lseq focuses on the entire vocabulary.,3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"So, the model is trained in an end-to-end fashion by minimizing Lseq and Lcritic alternately.",3.2.1 Deep Critic Sentence Simplification Model (DCSS),[0],[0]
"DCSS, similar to the majority of neural network models, uses a piece of shared memory, i.e. the parameters, as the media to store the learned rules from the data.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"As a result, it still focuses much
more on rules that are frequently observed and ignores the rules observed infrequently.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"However, infrequent rules are still important, particularly when the training data is limited.
",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"In order to make full use of the rules in the knowledge base, we introduce the Deep Memory Augmented Sentence Simplification (DMASS) model.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
DMASS has an augmented dynamic memory to record multiple key-value pairs for each rule in the Simple PPDB.,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
The key vector stores a context vector that is computed based on the weighted average of encoder hidden states and the current decoder hidden states.,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"The value vector stores the output vector.
",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
Our DMASS model is illustrated in Figure 2.,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"Given the same example normal sentence “ the recipient of kate greenaway medal”, Simple PPDB determines that the word “recipient” should be simplified to “winner”.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"The encoder represents the normal sentence as a list of hidden states, [e(1,L), e(2,L), ...] where L indicates the final layer of encoder hidden states.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"When predicting the next word in the simplified sentence, the decoder of layer j represents the previous words as hidden states [d(1,j), ...",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
].,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"c(1,j) refers to the current context vector following attention layer, which is the weighted average of [e(1,L), e(2,L), ...] based on d(1,j).",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
A feed-forward fully connected neural network (FFN) combines the output of the decoder and the output from memory read module into the final output rwinner.,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"In addition to the word prediction, c(1,j) and rwinner will be sent to memory update module.
",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"In the remainder of this section, we will introduce the two modules of DMASS mentioned above: Memory Read Module and Memory Update Module.
",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
Memory Read Module,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
The memory read module incorporates rules into prediction.,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"As shown in Figure 2, current augmented memory contains three candidate rules for the word “recipient”, which indicates that it can be simplified into “winner”, “receiver” or “host”, respectively.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"The current context vector c(1,j) is treated as a query to search for suitable rules by using Equation 5, where αri denotes the weight for i
th rule, which is computed through the dot product between current context vector c(1,j) and ci.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"Then using Equation 6, αri weights each output vector to generate mem-
ory read output.
",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"αri = ei∑ j ej
ei = exp(c(1,j) · ci) (5)
ro",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
= ∑ αri,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
rr rr ∈,3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"[rwinner, rreceiver, rhost] (6)
Memory Update Module The task of the memory update module is to update the key and value vectors in the augmented memory.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"Once the model predicts the output vector rwinner, both rwinner and the current context vector c1,j are sent to the memory update module.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"If the augmented memory does not contain the key-value pair for the rule, c1,j and rwinner are appended to the memory.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"If the augmented memory contains the key-value pair, the key vector is updated as the mean of current key vector and c1,j .",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"Similarly, the value vector is also updated as the mean of current value vector and rwinner.",3.2.2 Deep Memory Augmented Sentence Simplification Model (DMASS),[0],[0]
"Dataset We utilize the dataset WikiLarge (Zhang and Lapata, 2017) for training.",4 Experiments,[0],[0]
"It is the largest Wikipedia corpus, constructed by merging previously created simplification corpora.",4 Experiments,[0],[0]
"Specifically, the training dataset contains 296,402 normalsimple sentence pairs gathered from (Zhu et al., 2010; Woodsend and Lapata, 2011; Kauchak, 2013).",4 Experiments,[0],[0]
"For validation and testing, we use the dataset Turk created by (Xu et al., 2016).",4 Experiments,[0],[0]
"In this dataset, eight simplified reference sentences for each normal sentence are used as the ground-truth, all of which are generated by Amazon Mechanical Turk workers.",4 Experiments,[0],[0]
"The Turk dataset contains 2,000
data samples for validation and 356 samples for testing.",4 Experiments,[0],[0]
We consider the Turk to be the most reliable data set because (1) it is human-generated and (2) it contains multiple simplification references for each normal sentence due to the existence of multiple equally good simplifications of each sentence.,4 Experiments,[0],[0]
"We also include the second test set Newsela, a corpus introduced by (Xu et al., 2015b) who argue that only using normal-simple sentence pairs from Wikipedia is suboptimal due to the automatic sentence alignment which unavoidably introduces errors, and the uniform writing style which leads to systems that generalize poorly.",4 Experiments,[0],[0]
"The test set contains 1,419 normal-simple sentence pairs3.",4 Experiments,[0],[0]
"To demonstrate that our models are able to perform well on a different style of corpus, we report the results of Newsela test set by using the models trained/tuned on Turk dataset.",4 Experiments,[0],[0]
"Following Zhang and Lapata (2017)’s way, we tag and anonymize name entities with a special token in the format of NE@N, where NE includes {PER,LOC,ORG} and N indicates the N th distinct NE type of entity.",4 Experiments,[0],[0]
"We also replace those tokens occurring three times or less in the training set with a mark “UNK” as mentioned in (Zhang and Lapata, 2017).
",4 Experiments,[0],[0]
Evaluation Metrics,4 Experiments,[0],[0]
"We report the results of the experiment with two metrics that are widely used in the literature: SARI (Xu et al., 2016) and FKGL (Kincaid et al., 1975).",4 Experiments,[0],[0]
FKGL computes the sentence length and word length as a way to measure the simplicity of a sentence.,4 Experiments,[0],[0]
The lower value of FKGL indicates simpler sentence.,4 Experiments,[0],[0]
"FKGL measures the simplicity of a sentence without considering the ground truth simplification references and it correlates little with human judgment (Xu et al., 2016), so we also use another metric, SARI.",4 Experiments,[0],[0]
"SARI, which stands for “System output Against References and against the normal sentence”, computes the arithmetic mean of Ngrams (N includes 1,2,3 and 4) F1-score of three rewrite operations: addition, deletion, and keeping.",4 Experiments,[0],[0]
"Specifically, it rewards addition operations where a word in the generated simplified sentence does not appear in the normal sentence but is mentioned in the reference sentences.",4 Experiments,[0],[0]
It also rewards words kept or deleted in both the simplified sentence and the reference sentences.,4 Experiments,[0],[0]
"In our experiment, we also present the F1-score of three rewrite
3Because the earlier publications don’t provide preprocess details, we use our own script to pre-process the articles into sentence pairs.
operations: addition, deletion, and keeping.",4 Experiments,[0],[0]
Xu et al. (2016) demonstrated that SARI correlates most closely to human judgments in sentence simplification tasks.,4 Experiments,[0],[0]
"Thus, we treated SARI as the most important measurement in our study.
",4 Experiments,[0],[0]
"Because SARI rewards deleting and adding separately, we also include another metric to measure the correctness of lexical transformation, namely word simplification, verified by Simple PPDB.",4 Experiments,[0],[0]
"By comparing the normal sentence and ground truth simplified references, we collect rules that are correct to be used for simplifying each normal sentence.",4 Experiments,[0],[0]
"Then we calculate the precision, recall, and F1 score for using the correct rules.",4 Experiments,[0],[0]
"As a result, the recall expresses the coverage of rules to be applied, and the precision implies the accuracy gained by applying the correct rules.
",4 Experiments,[0],[0]
Training Details,4 Experiments,[0],[0]
"We initialized the encoder and decoder word embedding lookup matrices with 300-dimensional Glove vectors(Pennington et al., 2014).",4 Experiments,[0],[0]
The word embedding dimensionality and the number of hidden units are set to 300.,4 Experiments,[0],[0]
"During the training, we regularize all layers with a dropout rate of 0.2 (Srivastava et al., 2014).",4 Experiments,[0],[0]
"For multilayer and multi-head architecture, 4 encoder and decoder layers (set L as 4) and 5 multi-attention heads (set H as 5) are used.",4 Experiments,[0],[0]
We will discuss the trade-off between different layers and different heads in Sections 4.1.,4 Experiments,[0],[0]
"For DMASS, we use the context vector based on the first layer of the decoder (set j as 1).",4 Experiments,[0],[0]
"For optimization, we use Adagrad (Duchi et al., 2011) with the learning rate set to 0.1.",4 Experiments,[0],[0]
"The gradient is truncated by 4 (Pascanu et al., 2013).",4 Experiments,[0],[0]
"The reason to employ the Transformer architecture in the sentence simplification task is that we believe that its multi-layer, multi-head attention provides a better capability of modeling both the overall context and the important cues for sentence simplification.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"In this section, we examine the applicability of multi-layer, multi-head attention architecture to the sentence simplification task.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
We compare our results against the RNN/LSTMbased sentence simplification models.,"4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"Note that the results of our models presented here have not been integrated with the Simple PPDB.
","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"Table 2 shows the experiment results where LxHy indicates a run with Transformer using x
layers and y heads.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"When compared with results of RNN/LSTM, our Transformer-based model performed better in terms of SARI and FKGL values.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"In addition, with the increased number of layers or heads, the values of SARI and FKGL improve accordingly.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"In the remainder of this section, we analyze the insights of these results in detail.
","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"In our tasks, FKGL measures the sentence length and the word length as two factors for evaluating a simplified sentence.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"Therefore, we include Wlen(Word Length) and Slen(Sentence Length) into our analysis.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"As shown in Table 2, models with higher numbers of layers and/or heads do generally reduce the average word length and the average sentence length, which indicates that the higher number of layers and/or heads in the model leads to simpler outcomes.
","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"It has been found that SARI correlates most closely to human judgment (Xu et al., 2016).","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"To further analyze the effects of SARI, we study the impacts of three rewrite operations in SARI: add, delete, and keep.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"As shown in Table 2, we find that the improvement mostly results from correctly adding simplified words and deleting normal words, but not from keeping words.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"By analyzing the outputs, the increased number of layers or heads results in better capability to simplify the words.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"Specifically, models with the greater number of layers or heads tend to remove the normal words and add simplified words.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"However, they may introduce inaccurate simplified words, thereby driving down the F1 score for keeping words.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"We believe the Simple PPDB, which offers guidance about whether words need to be simplified and how they should be simplified, provides an ideal method to alleviate this issue.","4.1 Impacts of Multi-Layer, Multi-Head Attention Architecture",[0],[0]
"In order to make comprehensive comparisons with the state-of-the-art models, we include multiple baselines from the literature, including PBMTR (Wubben et al., 2012), Hybrid (Narayan and Gardent, 2014), and SBMT-SARI (Xu et al., 2016).",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"We also include several strong baselines based on neural networks such as RNN/LSTM, DRESS, DRESS-LS (Zhang and Lapata, 2017) as shown in Tables 3 and 4 We developed three models for this experiment.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"They are DMASS, DCSS, and DMASS+DCSS, where DMASS+DCSS indicates the combination of DMASS and DCSS.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"The
subscript beam indicates the size of beam search.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Results with FKGL Metric As shown in Tables 3 and 4, Hybrid achieves the lowest (thus the best) FKGL score, and DRESS and DRESS-LS have the second best FKGL scores.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
All the other models including ours do not perform as well as these two.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"But FKGL measures the simplicity of a sentence without considering the ground truth simplification references, so high FKGL may be at the cost of losing information and readability.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"To further analyze the FKGL results, we exam-
ine the average sentence length and word length of the outcomes of the models and they are listed as WLen (Word Length) and",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
SLen (Sentence Length) in Tables 3 and 4.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Hybrid, DRESS, and DRESSLS are good at generating shorter sentences, but they are not as good at choosing shorter words.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"In contrast, SBMT-SARI, DCSS, and DMASS all generate shorter words.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Therefore, we believe that, by optimizing language model as a goal for the reinforcement learning, DRESS and DRESSLS are tuned to simplify sentences by shortening
the sentence lengths.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"In contrast, with the help of an integrated external knowledge base, SBMTSARI and our models have more capability to generate shorter words in order to simplify sentences.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Therefore, these two sets of models complete sentence simplification tasks via different routes, and perhaps there should be an exploration of combining these two routes for even more successful sentence simplification.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
Another interesting finding is that the larger beam search size increases average word length slightly.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
This is because the larger beam search size mitigates the issue of the inaccurate simplification so that fewer words are simplified.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"To measure the correctness of simplification, we analyze the SARI metric and Rule Utilization.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Results with SARI Metric SARI is the most reliable metric for the sentence simplification task (Xu et al., 2016), therefore we would like to present more detailed discussion regarding the SARI results.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"As shown in Tables 3 and 4, DMASS+DCSS achieves the best SARI score, which demonstrates the effectiveness of integrating the knowledge base Simple PPDB for sentence simplification.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"To further examine the impacts of the F1 scores for three operations in calculating the SARI scores, as shown in Tables 3 and 4, DMASS+DCSS, as well as other models with high SARI performance benefit greatly by correctly adding and deleting words.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"We believe these benefits mostly result from the integration with the knowledge base, which provides reliable guidance about which words to modify.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"SBMTSARI, which represents a previous state-of-the-art model that also integrates with knowledge bases, performs best in correctly adding new words but performs inferiorly in deleting/keeping words.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"By analyzing the outputs, SBMT-SARI acts aggressively to simplify as many words as possible.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
But it also results in incorrect simplification.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"DRESS and DRESS-LS are inclined to generate the shorter sentence, which leads to high F1 scores for deleting words, but it lags behind other models in adding/keeping words.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
DMASS leverages an additional memory component to maintain the simplification rules; DCSS uses internal memory to store those rules.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
A large number of simplification rules might confuse the model with limited internal memory.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"This might be the reason why DMASS works better
than DCSS.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"By taking a two-way advantage of both models, DMASS+DCSS takes a two-fisted approach to store the simplification rules in both additional and internal memory.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"As a result, DMASS+DCSS achieves the best performance in SARI.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Results with Rule Utilization In this section, we evaluate the models’ capabilities for word transformation.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"The majority of previous approaches, except for the SBMT-SARI, perform poorly in recall.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"We believe the knowledge base Simple PPDB will reduce uncertainty in the word selection.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"As before, SBMT-SARI acts aggressively to simplify every word in the sentence.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
Such an aggressive action leads to relatively high performance in recall.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"However, it does not achieve a strong performance in precision.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
DMASS performs better in terms of rule utilization as compared to DCSS by leveraging an additional memory.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
DMASS+DCSS takes advantage of both approaches that store the simplification rules in additional and internal memory.,4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"This combined model is guaranteed to apply more accurate rules.
",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"As compared to the loose relationship between SARI and beam search size, we find that that beam search size correlates strongly with the performance in rule utilization.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"Thus, we believe larger beam search size contributes to good coverage of rules to be applied as well as accuracy in applying rules.",4.2 Impacts of Integrating the Simple PPDB,[0],[0]
"In this paper, we propose two innovative approaches for sentence simplification based on neural networks.",5 Conclusion,[0],[0]
"Both approaches are based on multilayer and multi-head attention architecture and integrated with the Simple PPDB, an external sentence simplification knowledge base, in different ways.",5 Conclusion,[0],[0]
"By conducting a set of experiments, we demonstrate that the proposed models perform better than existing methods and achieve new state-of-the-art in sentence simplification.",5 Conclusion,[0],[0]
Our experiments firstly prove that the multi-layer and multi-head attention architecture has an excellent capability to understand the text by accurately selecting specific words in a normal sentence and then choosing right simplified words.,5 Conclusion,[0],[0]
"Secondly, by integrating with the knowledge base, our models outperform multiple state-of-the-art baselines for sentence simplification.",5 Conclusion,[0],[0]
"Compared to previous
models which integrated with the knowledge base, our models, especially, DMASS+DCSS, provide both good coverage of rules to be applied and accuracy in applying the correct rules.",5 Conclusion,[0],[0]
"In future, we would like to investigate deeper into the different effects of additional memory and internal memory.",5 Conclusion,[0],[0]
This research was supported in part by the University of Pittsburgh Center for Research Computing through the resources provided.,6 Acknowledge,[0],[0]
"The research is funded in part by grants the National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR) #90RE5018 and #90DP0064, and by Pittsburgh Health Data Alliance’s “CARE” Project.",6 Acknowledge,[0],[0]
Sentence simplification aims to reduce the complexity of a sentence while retaining its original meaning.,abstractText,[0],[0]
Current models for sentence simplification adopted ideas from machine translation studies and implicitly learned simplification mapping rules from normalsimple sentence pairs.,abstractText,[0],[0]
"In this paper, we explore a novel model based on a multi-layer and multi-head attention architecture and we propose two innovative approaches to integrate the Simple PPDB (A Paraphrase Database for Simplification), an external paraphrase knowledge base for simplification that covers a wide range of real-world simplification rules.",abstractText,[0],[0]
"The experiments show that the integration provides two major benefits: (1) the integrated model outperforms multiple stateof-the-art baseline models for sentence simplification in the literature (2) through analysis of the rule utilization, the model seeks to select more accurate simplification rules.",abstractText,[0],[0]
The code and models used in the paper are available at https://github.com/ Sanqiang/text_simplification.,abstractText,[0],[0]
Integrating Transformer and Paraphrase Rules for Sentence Simplification,title,[0],[0]
Significant research effort has been devoted to developing advanced text analysis technologies.,1. Introduction,[0],[0]
"Probabilistic topic models such as Latent Dirichlet Allocation (LDA), are popular approaches for this task, which discover latent topics from text collections.",1. Introduction,[0],[0]
One preferred property of probabilistic topic models is interpretability: one can explain that a document is composed of topics and a topic is described by words.,1. Introduction,[0],[0]
"Although widely used, most variations of standard vanilla topic models (e.g., LDA) assume topics are independent and there are no structures among them.",1. Introduction,[0],[0]
This limits those models’ ability to explore any hierarchical thematic structures.,1. Introduction,[0],[0]
"Therefore, it is interesting to develop a model that is capable of exploring topic structures and yields not only improved modeling accuracy but also better
1Faculty of Information Technology, Monash University, Australia 2McCombs School of Business, University of Texas at Austin.",1. Introduction,[0],[0]
"Correspondence to: Lan Du <lan.du@monash.edu>, Mingyuan Zhou",1. Introduction,[0],[0]
"<mingyuan.zhou@mccombs.utexas.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
interpretability.
",1. Introduction,[0],[0]
"One popular direction to explore topic structure is using the hierarchical/deep representation of text data, such as the nested hierarchical Dirichlet process (nHDP) (Paisley et al., 2015), Deep Poisson Factor Analysis (DPFA) (Gan et al., 2015), and Gamma Belief Network (GBN) (Zhou et al., 2016; Cong et al., 2017).",1. Introduction,[0],[0]
"In general, these models assume that topics in the higher layers of a hierarchy are more general/abstract than those in the lower layers.",1. Introduction,[0],[0]
"Therefore, by revealing hierarchical correlations between topics, topic hierarchies provide an intuitive way to understand text data.
",1. Introduction,[0],[0]
"In addition to topic hierarchies, we are also interested in analyzing the fine-grained thematic structure within each individual topic.",1. Introduction,[0],[0]
"As we know, in conventional models, topics are discovered locally from the word co-occurrences in a corpus.",1. Introduction,[0],[0]
So we refer those topics as local topics.,1. Introduction,[0],[0]
"Due to the limitation of the context of a target corpus, some local topics may be hard to interpret because of the following two effects: (1) They can mix the words which co-occur locally in the target corpus but are less semantically related in general; (2) Local topics can be dominated by specialized words, which are less interpretable without extra knowledge.",1. Introduction,[0],[0]
"For example, we show four example topics of our experiments in Table 1, where we can see:",1. Introduction,[0],[0]
Topic 1 is composed of the words from both the “scientific publication” and “biology” aspects;,1. Introduction,[0],[0]
Topic 2 is a mixture of “sports” and “music”; Topics 3 and 4 are very specific topics about “singer” and “video game” respectively.,1. Introduction,[0],[0]
"We humans are able to understand those local topics in the above way because we are equipped with the global semantics of the words, making us go beyond the local context of the target corpus.",1. Introduction,[0],[0]
"Therefore, we are motivated to propose a model which is able to automatically analyze the fine-grained thematic structures of local topics, further improving the interpretability of topic modeling.
",1. Introduction,[0],[0]
"Fortunately, word embeddings such as GloVe (Pennington et al., 2014), word2vec (Mikolov et al., 2013), and FastText (Bojanowski et al., 2017) can be used as an accessible source of global semantic information for topic models.",1. Introduction,[0],[0]
"Learned from large corpora, word embeddings encode the semantics of words with their locations in a space, where more related words are closer to each other.",1. Introduction,[0],[0]
"For example in Topic 1, according to the distances of word embeddings, the words “biology, cell, psychology, bioinformatics” should be in one cluster and “journal, science, research, international, scientific” should be in the other.",1. Introduction,[0],[0]
"Therefore, if a topic model can leverage the information in word embeddings, it may discover the fine-grained thematic structures of local topics.",1. Introduction,[0],[0]
"Furthermore, it has been demonstrated that conventional topic models suffer from data sparsity, resulting in a large performance degradation on some shorter internetgenerated documents like tweets, product reviews, and news headlines (Zuo et al., 2016; Zhao et al., 2017c).",1. Introduction,[0],[0]
"In this case, word embeddings can also serve as complementary information to alleviate the sparsity issue in topic models.
",1. Introduction,[0],[0]
"In this paper, we propose a novel deep structured topic model, named the Word Embeddings Deep Topic Model, WEDTM1, which improves the interpretability of topic models by discovering topic hierarchies (i.e., inter topic structure) and fine-grained interpretations of local topics (i.e., intra topic structure).",1. Introduction,[0],[0]
"Specifically, the proposed model adapts a multi-layer Gamma Belief Network which generates deep representations of topics as well as documents.",1. Introduction,[0],[0]
"Moreover, WEDTM is able to split a local topic into a set of sub-topics, each of which captures one finegrained thematic aspect of the local topic, in a way that each sub-topic is informed by word embeddings.",1. Introduction,[0],[0]
WEDTM has the following key properties: (1) Better interpretability with topic hierarchies and sub-topics informed by word embeddings.,1. Introduction,[0],[0]
"(2) The state-of-the-art perplexity, document classification, and topic coherence performance, especially for sparse text data.",1. Introduction,[0],[0]
(3) A straightforward Gibbs sampling algorithm facilitated by fully local conjugacy under data augmentation.,1. Introduction,[0],[0]
Deep/hierarchical topic models: Several approaches have been developed to learn hierarchical representations of documents and topics.,2. Related Work,[0],[0]
"The Pachinko Allocation model (PAM) (Li & McCallum, 2006) assumes the topic structure is modeled by a directed acyclic graph (DAG), which is document specific.",2. Related Work,[0],[0]
"nCRP (Blei et al., 2010) models topic hierarchies by introducing a tree structure prior constructed with multiple CRPs.",2. Related Work,[0],[0]
"Paisley et al. (2015); Kim et al. (2012); Ahmed et al. (2013) further extend nCRP by either softening its constraints or applying it to different problems respec-
1https://github.com/ethanhezhao/WEDTM
tively.",2. Related Work,[0],[0]
"Poisson Factor Analysis (PFA) (Zhou et al., 2012) is a nonnegative matrix factorization model with Poisson link, which is a popular alternative to LDA, for topic modeling.",2. Related Work,[0],[0]
The details of the close relationships between PFA and LDA can be found in Zhou (2018).,2. Related Work,[0],[0]
"There are several deep extensions to PFA for documents, such as DPFA (Gan et al., 2015), DPFM (Henao et al., 2015), and GBN (Zhou et al., 2016).",2. Related Work,[0],[0]
"Among them, GBN factorizes the factor score matrix (topic weights of documents) in PFA with nonnegative gamma-distributed hidden units connected by the weights drawn from the Dirichlet distribution.",2. Related Work,[0],[0]
"From a modeling perspective, GBN is related to PAM, while GBN assumes there is a corpus-level topic hierarchy shared by all the documents.",2. Related Work,[0],[0]
"As reported by Cong et al. (2017), GBN outperforms other hierarchical models including nHDP, DPFA, and DPFM.",2. Related Work,[0],[0]
"Despite having the attractive properties, these deep models barely consider intra topic structures or the sparsity issue associated with internet-generated corpora.
",2. Related Work,[0],[0]
"Word embedding topic models: Recently, there is a growing interest in applying word embeddings to topic models, especially for sparse data.",2. Related Work,[0],[0]
"For example, WF-LDA (Petterson et al., 2010) extends LDA to model word features with the logistic-normal transform, where word embeddings are used as word features in Zhao et al. (2017b).",2. Related Work,[0],[0]
"LF-LDA (Nguyen et al., 2015) integrates word embeddings into LDA by replacing the topic-word Dirichlet multinomial component with a mixture of a Dirichlet multinomial component and a word embedding component.",2. Related Work,[0],[0]
"Due to the non-conjugacy in WF-LDA and LF-LDA, part of the inference has to be done by MAP optimization.",2. Related Work,[0],[0]
"Instead of generating tokens, Gaussian LDA (GLDA)",2. Related Work,[0],[0]
"(Das et al., 2015) directly generates word embeddings with the Gaussian distribution.",2. Related Work,[0],[0]
The model proposed in Xun et al. (2017) further extends GLDA by modeling topic correlations.,2. Related Work,[0],[0]
MetaLDA,2. Related Work,[0],[0]
"(Zhao et al., 2017c; 2018a) is a conjugate topic model that incorporates both document and word meta information.",2. Related Work,[0],[0]
"However, in MetaLDA, word embeddings have to be binarized, which can lose useful information.",2. Related Work,[0],[0]
"WEI-FTM (Zhao et al., 2017b) is a focused topic model where a topic focuses on a subset of words, informed by word embeddings.",2. Related Work,[0],[0]
"To our knowledge, topic hierarchies and sub-topics are not considered in most of the existing word embedding models.",2. Related Work,[0],[0]
"Based on the PFA framework, WEDTM is a hierarchical model with two major components: one for discovering the inter topic hierarchies and the other for discovering intra topic structures (i.e., sub-topics) informed by word embeddings.",3. The Proposed Model,[0],[0]
"The two components are connected by the bottom-layer topics, detailed as follows.",3. The Proposed Model,[0],[0]
"Assume that each document j is presented as a word count vector x(1)j ∈ NV0 , where V is the size of the vocabulary; the pre-trained L
dimensional real-valued embeddings for each word v ∈ {1, · · · , V } are stored in a L-dimensional vector fv ∈ RL.",3. The Proposed Model,[0],[0]
"Now we consider WEDTM with T hidden layers, where the t-th layer is with Kt topics and kt is the index of each topic.",3. The Proposed Model,[0],[0]
"In the bottom layer (t = 1), there are K1 (local) topics, each of which is associated with S sub-topics.",3. The Proposed Model,[0],[0]
"To assist clarity, we split the generative process of the model into three parts, shown as follows:
Generating documents  θ (1) j ∼ Gam [ Φ(2)θ (2) j , p (2) j /(1− p (2) j ) ] , φ (1) k1 ∼ Dir (βk1) ,
x (1) j ∼ Pois
( Φ(1)θ
(1) j
) ,
Inter structure  θ",3. The Proposed Model,[0],[0]
"(T ) j ∼ Gam ( r, 1/c (T+1) j ) , · · · θ (t) j ∼ Gam ( Φ(t+1)θ (t+1) j , 1/c (t+1) j ) (t < T ), φ (t) kt ∼ Dir (η01)",3. The Proposed Model,[0],[0]
"(t > 1),
· · ·
Intra structure  w<s>k1 ∼ N",3. The Proposed Model,[0],[0]
"[0, diag(1/σ <s>)] , α<s>k1 ∼ Gam(α <s> 0 /S, 1/c <s> 0 ), β<s>vk1 ∼ Gam ( α<s>k1 , e f",3. The Proposed Model,[0],[0]
">v w <s> k1 ) ,
βvk1 := ∑S s β <s> vk1 ,
where (t) is the index of the layer that a variable belongs to and <s> is the index of sub-topic s. To complete the model, we impose the following priors on the latent variables:
rkT ∼ Gam(γ0/KT , 1/c0), γ0 ∼ Gam(a0, 1/b0), p(t)j ∼ Beta(a0, b0),
c (t) j ∼ Gam(e0, 1/f0), α <s> 0",3. The Proposed Model,[0],[0]
"∼ Gam(e0, 1/f0),
c<s>0 ∼ Gam(e0, 1/f0), σ<s>l ∼ Gam(a0, 1/b0).
",3. The Proposed Model,[0],[0]
"We first take a look at the bottom layer of the model, i.e., the process of generating the documents, which follows a PFA framework.",3. The Proposed Model,[0],[0]
"In this part, WEDTM models the word counts x(1)j in a document by a Poisson (Pois) distribution and factorizes the Poisson parameters into a product of the factor loadings Φ(1) ∈",3. The Proposed Model,[0],[0]
RV×K1+ and hidden units θ (1) j .,3. The Proposed Model,[0],[0]
"θ (1) j is the first-layer latent representation (unnormalized topic weights) of document j, each element of which is drawn from a gamma (Gam) distribution2.",3. The Proposed Model,[0],[0]
"The k1-th column of Φ(1), φ(1)k1 ∈ R V + is the word distribution of topic k1, drawn from a Dirichlet (Dir) distribution.",3. The Proposed Model,[0],[0]
"We then explain the component for discovering inter topic hierarchies, which is similar to the structure of GBN (Zhou et al., 2016).",3. The Proposed Model,[0],[0]
"Specifically, the shape parameter of θ(1)j is factorized into θ (2) j and Φ(2) ∈ RK1×K2+ , where θ (2) j is the second-layer latent
2The first and second parameters of the gamma distribution are the shape and scale respectively.
representation of document j and φ(2)k2 ∈ R K1 + models the correlations between topic k2 and all the first-layer topics.",3. The Proposed Model,[0],[0]
"Note that strictly speaking, k2 is not a “real” topic as it is not a distribution over words.",3. The Proposed Model,[0],[0]
But it can be interpreted with words by Φ(1)φ(2)k2 .,3. The Proposed Model,[0],[0]
"By repeating this construction, we are able to build a deep structure to discover topic hierarchies.
",3. The Proposed Model,[0],[0]
Now we explain how sub-topics are discovered for the bottom-layer topics with the help of word embeddings.,3. The Proposed Model,[0],[0]
"First of all, WEDTM applies individual asymmetric Dirichlet parameters βk1 ∈ RV+",3. The Proposed Model,[0],[0]
"for each bottom-layer (local) topic φ
(1) k1",3. The Proposed Model,[0],[0]
.,3. The Proposed Model,[0],[0]
We further construct βvk1 = ∑S s β,3. The Proposed Model,[0],[0]
<,3. The Proposed Model,[0],[0]
"s> vk1
, where β<s>vk1 models how strongly word v is associated with sub-topic s in local topic k1.",3. The Proposed Model,[0],[0]
"For each sub-topic s, we introduce an Ldimensional sub-topic embedding: w<s>k1 ∈ R
L. As β<s>vk1 is gamma distributed, its scale parameter is constructed by the dot product of the embeddings of sub-topic s and word v through the exponential function.
",3. The Proposed Model,[0],[0]
"The basic idea of our model is summarized as follows:
1.",3. The Proposed Model,[0],[0]
"In terms of sub-topics, we assume each (local, bottomlayer) topic is associated with several sub-topics, in a way that the sub-topics contribute to the prior of the local topic via a sum model (Zhou, 2016).",3. The Proposed Model,[0],[0]
"Therefore, if a word dominates in one or more sub-topics, it is likely that the word will still dominate in the local topic.",3. The Proposed Model,[0],[0]
"With this construction, a sub-topic is expected to capture one fine-grained thematic aspect of the local topic and each sub-topic can be directly interpreted with words via β<s>k1 ∈ R V + .
2.",3. The Proposed Model,[0],[0]
"To leverage word embeddings to inform the learning of sub-topics, we introduce the sub-topic embedding for each of them, w<s>k1 , which directly interacts with the word embeddings.",3. The Proposed Model,[0],[0]
"Therefore, sub-topic embeddings are learned with both the local context of the target corpus and the global information of word embeddings.",3. The Proposed Model,[0],[0]
"According to our model construction, the probability density function of βvk1 is the convolution of S covariance-dependent gamma distributions (Zhou, 2016).",3. The Proposed Model,[0],[0]
"Therefore, if the sub-topic embeddings of s and word embeddings of v are close, the dot product of them will be large, giving a large expectation of β<s>vk1 .",3. The Proposed Model,[0],[0]
"The large expectation means that v has a large weight in sub-topic s of k. Finally, β<s>vk1 further contributes
to the local topic’s prior βvk1 , informing φ (1) vk1
of the local topic.
3.",3. The Proposed Model,[0],[0]
"It is also noteworthy the special case of WEDTM, where S = 1, meaning that there are no sub-topics and each local topic k1 is associated with one topic embedding vector wk1 .",3. The Proposed Model,[0],[0]
"Consequently, in WEDTM, there are three latent variables capturing the weights between the words and local topic k1:",3. The Proposed Model,[0],[0]
"eF >wk1 (F ∈ RL×V is
the embeddings of all the words), βk1 , and φ (1) k1
, each of which is a vector over words.",3. The Proposed Model,[0],[0]
It is interesting to analyze the connections and differences of them.,3. The Proposed Model,[0],[0]
eF,3. The Proposed Model,[0],[0]
">wk1 is the prior of βk1 , while βk1 is the prior of φ (1) k1 .",3. The Proposed Model,[0],[0]
So eF,3. The Proposed Model,[0],[0]
">wk1 is the closest one to the word embeddings, i.e., the global semantic information, while φ(1)k1 is the closest one to the data, i.e., the local document context of the target corpus.",3. The Proposed Model,[0],[0]
"Therefore, unlike conventional topic models with φ(1)k1 only, the three variables of WEDTM give three different views to the same topic, from global to local, respectively.",3. The Proposed Model,[0],[0]
"We qualitatively show this interesting comparison in Section 5.4.
4.",3. The Proposed Model,[0],[0]
"The last but not least, word embeddings in WEDTM can be viewed to serve as the prior/complementary information to assist the learning of the whole model, which is important especially for sparse data.",3. The Proposed Model,[0],[0]
"Unlike many other word embeddings topic models, the fully local conjugacy of WEDTM facilitates the derivation of an effective Gibbs sampling algorithm.",4. Inference,[0],[0]
"As the sampling for the latent variables in the process of generating documents and modeling inter topic structure are similar to GBN, the details can be found in Zhou et al. (2016).",4. Inference,[0],[0]
"Here we focus on the sampling of the latent variables for modeling intra topic structure.
",4. Inference,[0],[0]
Assume that sampled by Eq.,4. Inference,[0],[0]
"(28) in Appendix B of Zhou et al. (2016), the latent count for the bottom-layer local topics are x(1)vjk1 , which counts how many words v in document j are allocated with local topic k1.
",4. Inference,[0],[0]
Sample β<s>vk1 .,4. Inference,[0],[0]
"We first sample: ( h<1>vk1 , · · · , h <S> vk1 ) ∼ Mult ( hvk1 ,
β<1>vk1 βvk1 , · · · , β<S>vk1 βvk1
) ,
(1)
where hvk1 ∼ CRT ( x (1) v·k1 , βvk1 ) (Zhou & Carin, 2015;
Zhao et al., 2017a), and x(1)v·k1 := ∑ j x (1) vjk1 3.",4. Inference,[0],[0]
"Then:
β<s>vk1 ∼ Gam(α<s>k1 + h",4. Inference,[0],[0]
"<s> vk1 , 1)
",4. Inference,[0],[0]
"e−π <s> vk1 + log 1qk1
, (2)
where qk1 ∼ Beta(β·k1 , x (1) ··k1)",4. Inference,[0],[0]
"(Zhao et al., 2018b) and we define π<s>vk1 := f > v w <s> k1 .
",4. Inference,[0],[0]
"3We hereafter use · of a dimension to denote the sum over that dimension.
",4. Inference,[0],[0]
Sample α<s>k .,4. Inference,[0],[0]
"We first sample g <s> vk1 ∼ CRT ( h<s>vk1 , α <s> k1 ) , then:
α<s>k1 ∼",4. Inference,[0],[0]
Gam(α<s>0 /S,4. Inference,[0],[0]
+,4. Inference,[0],[0]
"g <s> ·k1 , 1)",4. Inference,[0],[0]
"c<s>0 + log ( 1 + eπ
<s> vk1 log 1qk1 ) .",4. Inference,[0],[0]
"(3) It is noteworthy that the hierarchical construction onα<s>k1 is closely related to the gamma-negative binomial process and can be considered as a (truncated) gamma process (Zhou & Carin, 2015; Zhou, 2016) with an intrinsic shrinkage mechanism on S. It means that the model is able to automatically learn the number of effective sub-topics.
",4. Inference,[0],[0]
"Sample w<s>k1 .
",4. Inference,[0],[0]
"w<s>k1 ∼ N (µ <s> k1 ,Σ<s>k1 ),
µ<s>k1 =
Σ<s>k1 [ V∑ v ( h<s>vk1",4. Inference,[0],[0]
− α <s> k1 2,4. Inference,[0],[0]
− ω<s>vk1 log log 1 qk1 ),4. Inference,[0],[0]
"fv ] ,
Σ<s>k1 =
[ diag(1/σ<s>)",4. Inference,[0],[0]
"+
V∑ v ω<s>vk1 fv(fv) >
",4. Inference,[0],[0]
"]−1 ,(4)
where ω<s>vk1 ∼ PG ( h<s>vk1 + α <s> k1 , π<s>vk1 + log log 1 qk1 ) and PG denotes the Pólya gamma distribution (Polson et al., 2013).",4. Inference,[0],[0]
"To sample from PG, we use an accurate and efficient approximate sampler in Zhou (2016).
",4. Inference,[0],[0]
"Omitted derivations, details, and the overall algorithm are in the supplementary materials.",4. Inference,[0],[0]
We evaluate the proposed WEDTM by comparing it with several recent advances including deep topic models and word embedding topic models.,5. Experiments,[0],[0]
The experiments were conducted on four real-world datasets including both regular and sparse texts.,5. Experiments,[0],[0]
"We report perplexity, document classification accuracy, and topic coherence scores.",5. Experiments,[0],[0]
We also qualitatively analyze the topic hierarchies and sub-topics.,5. Experiments,[0],[0]
"In the experiments, we used a regular text dataset (20NG) and three sparse text datasets (WS, TMN, Twitter), the details of which are as follows: 1. 20NG, 20 Newsgroup, consists of 18,774 articles with 20 categories.",5.1. Experimental Settings,[0],[0]
"Following Zhou et al. (2016), we used the 2000 most frequent terms after removing stopwords.",5.1. Experimental Settings,[0],[0]
The average document length is 76.,5.1. Experimental Settings,[0],[0]
2.,5.1. Experimental Settings,[0],[0]
"WS, Web Snippets, contains 12,237 web search snippets with 8 categories, used by Li et al. (2016); Zhao et al. (2017c;b).",5.1. Experimental Settings,[0],[0]
"The vocabulary contains 10,052 tokens and there are 15 words in one snippet on average.",5.1. Experimental Settings,[0],[0]
3.,5.1. Experimental Settings,[0],[0]
"TMN, Tag My
(a) WS
50 100 200 -200
-150
-100
-50
0
50
WEDTM-1 WEDTM-2 WEDTM-3 GBN-1",5.1. Experimental Settings,[0],[0]
"GBN-2 GBN-3
MetaLDA WEI-FTM
GBN-1: 704, 595, 548
(b) TMN
50 100 200 -250
-200
-150
-100
-50
0
50
GBN-1: 1498, 1299, 1190
(c) Twitter
50 100 200 -50
-40
-30
-20
-10
0
10
GBN-1: 461, 349, 305
(d) 20NG
100 200 400 -20
-10
0
10
20
GBN-1: 631, 522, 479
(e) WS
20% 40% 60% 80% -600
-500
-400
-300
-200
-100
0
100
WEDTM-1 WEDTM-2 WEDTM-3",5.1. Experimental Settings,[0],[0]
"GBN-1 GBN-2 GBN-3
MetaLDA WEI-FTM
GBN-1: 1786, 994, 728, 595
(f) TMN
20% 40% 60% 80%",5.1. Experimental Settings,[0],[0]
"-800
-600
-400
-200
0
200
GBN-1: 3140, 1925, 1495, 1299
(g) Twitter
20% 40% 60% 80% -150
-100
-50
0
50
GBN-1: 699, 446, 382, 349
(h) 20NG
20% 40% 60% 80% -25
-20
-15
-10
-5
0
5
GBN-1: 704, 595, 549, 522
Figure 1.",5.1. Experimental Settings,[0],[0]
(a)-(d):,5.1. Experimental Settings,[0],[0]
Relative per-heldout-word perplexity6 (the lower the better) with the varied K1 and fixed proportion (80%) of training words of each document.,5.1. Experimental Settings,[0],[0]
"(e)-(h): Relative per-heldout-word perplexity6 with the varied proportion of training words of each document and fixed K1 (100 on WS, TMN, and Twitter; 200 for 20NG).",5.1. Experimental Settings,[0],[0]
The error bars indicate the standard deviations of 5 random trials.,5.1. Experimental Settings,[0],[0]
"The number attached to WEDTM and GBN indicates the number of layers (i.e., T ) used.
",5.1. Experimental Settings,[0],[0]
"News, consists of 32,597 RSS news snippets from Tag My News with 7 categories, used by Nguyen et al. (2015); Zhao et al. (2017c;b).",5.1. Experimental Settings,[0],[0]
Each snippet contains a title and a short description.,5.1. Experimental Settings,[0],[0]
"There are 13,370 tokens in the vocabulary and the average length of a snippet is 18.",5.1. Experimental Settings,[0],[0]
4.,5.1. Experimental Settings,[0],[0]
"Twitter, was extracted in 2011 and 2012 microblog tracks at Text REtrieval Conference (TREC)4 and preprocessed in Yin & Wang (2014).",5.1. Experimental Settings,[0],[0]
"It has 11,109 tweets in total.",5.1. Experimental Settings,[0],[0]
"The vocabulary size is 6,344 and a tweet contains 21 words on average.
",5.1. Experimental Settings,[0],[0]
We compared WEDTM with: 1.,5.1. Experimental Settings,[0],[0]
"GBN (Zhou et al., 2016), the state-of-the-art deep topic model.",5.1. Experimental Settings,[0],[0]
2. MetaLDA,5.1. Experimental Settings,[0],[0]
"(Zhao et al., 2017c; 2018a), the state-of-the-art topic model with binary meta information about document and/or word.",5.1. Experimental Settings,[0],[0]
Word embeddings need to be binarized before used in the model.,5.1. Experimental Settings,[0],[0]
3.,5.1. Experimental Settings,[0],[0]
"WEI-FTM (Zhao et al., 2017b), the state-of-the-art focused topic model that incorporates real-valued word embeddings.
",5.1. Experimental Settings,[0],[0]
"It is noteworthy that GBN was reported (Cong et al., 2017) to have better performance than other deep (hierarchical) topic models such as nHDP (Paisley et al., 2015), DPFA (Gan et al., 2015), and DPFM (Henao et al., 2015).",5.1. Experimental Settings,[0],[0]
"MetaLDA and WEI-FTM were reported to perform better than other word embedding topic models including WFLDA (Petterson et al., 2010) and GPUDMM (Li et al., 2016) as well as short text topic models like PTM (Zuo et al.,
4http://trec.nist.gov/data/microblog.html
2016).",5.1. Experimental Settings,[0],[0]
"Therefore, we considered the three above competitors to WEDTM.
",5.1. Experimental Settings,[0],[0]
"Originally MetaLDA (when no document meta information is provided) and WEI-FTM follow the LDA framework, where the topic distribution for document j is θj ∼ Dir(α01) and α0 is a hyperparameter (usually set to 0.1).",5.1. Experimental Settings,[0],[0]
"For a fair comparison, we replaced this part with the PFA framework with the gamma-negative binomial process (Zhou & Carin, 2015), which is equivalent to GBN when T = 1 and closely related to the hierarchical Dirichlet Process LDA (HDPLDA)",5.1. Experimental Settings,[0],[0]
"(Teh et al., 2012).
",5.1. Experimental Settings,[0],[0]
"For all the models, we used 50-dimensional GloVe word embeddings pre-trained on Wikipedia5.",5.1. Experimental Settings,[0],[0]
"Except for MetaLDA, where we followed the paper to binarise the word embeddings, the other three models used the original realvalued embeddings.",5.1. Experimental Settings,[0],[0]
"The hyperparameter settings we used for WEDTM and GBN are a0 = b0 = 0.01, e0 = f0 = 1.0, η0 = 0.05.",5.1. Experimental Settings,[0],[0]
"For MetaLDA and WEI-FTM, we collected 1000 MCMC samples after 1000 burnins; for GBN and WEDTM, we collected 1000 for T = 1 and 500 for T > 1 MCMC samples after 1000 for T = 1 and 500 for T > 1 burnins, to estimate the posterior mean.",5.1. Experimental Settings,[0],[0]
"Due to the shrinkage effect of WEDTM on S, discussed in Section 4, we set S = 5 which is large enough for all the topics.
",5.1. Experimental Settings,[0],[0]
5https://nlp.stanford.edu/projects/glove/,5.1. Experimental Settings,[0],[0]
"Perplexity is a measure that is widely used (Wallach et al., 2009) to evaluate the modeling accuracy of topic models.",5.2. Perplexity,[0],[0]
Here we randomly chose a certain proportion of the word tokens in each document as training and used the remaining ones to calculate per-heldout-word perplexity.,5.2. Perplexity,[0],[0]
"Figure 1 shows the relative perplexity6 results of all the models on all the datasets, where we varied the number of bottomlayer topics as well as the proportion of training words.",5.2. Perplexity,[0],[0]
"The proposed WEDTM performs significantly better than the others, especially on sparse data.",5.2. Perplexity,[0],[0]
"There are several interesting remarks of the results: (1) The perplexity advantage of WEDTM over GBN becomes obvious when the corpus becomes sparse (e.g., WS/TMN/Twitter V.S. 20NG and 20% V.S. 80% training words).",5.2. Perplexity,[0],[0]
It shows that using word embeddings as the prior information benefits the model.,5.2. Perplexity,[0],[0]
"(2) In general, increasing the depth of the model leads to better perplexity.",5.2. Perplexity,[0],[0]
"However, when the data are too sparse (e.g. WS with 20% training words), the single-layer WEDTM and GBN perform better than their multi-layer counterparts.",5.2. Perplexity,[0],[0]
"(3) Although MetaLDA and WEI-FTM leverage word embed-
6We subtracted the score of GBN with only one layer (GBN-1) from the score of each model.",5.2. Perplexity,[0],[0]
The lines plot the differences.,5.2. Perplexity,[0],[0]
So GBN-1 is the horizontal line on “0”.,5.2. Perplexity,[0],[0]
"The absolute score of GBN-1 is given below each figure.
",5.2. Perplexity,[0],[0]
"dings as well, the proposed WEDTM outperforms them significantly.",5.2. Perplexity,[0],[0]
Perhaps the way that WEDTM incorporates word embeddings is more effective.,5.2. Perplexity,[0],[0]
"We consider the multi-class classification task for predicting the categories for test documents to evaluate the quality of the latent document representation (unnormalized topic weights) extracted by these models.7 In this experiment, following Zhou et al. (2016), we ran the topic models on the training documents and trained a L2 regularized logistic regression using the LIBLINEAR package (Fan et al., 2008) with the latent representation θ(1)j as features.",5.3. Document Classification,[0],[0]
"After training, we used the trained topic models to extract the latent representations of the test documents and the trained logistic regression to predict the categories.",5.3. Document Classification,[0],[0]
"For all the datasets, we randomly selected 80% documents for training and used the remaining 20% for testing.",5.3. Document Classification,[0],[0]
Figure 2 shows the relative document classification accuracy6 results for all the models.,5.3. Document Classification,[0],[0]
"It can be observed that with word embeddings, WEDTM outperforms GBN significantly, the best on TMN and 20NG, and the second-best on WS.",5.3. Document Classification,[0],[0]
"Again, we see a similar phe-
7The results of Twitter are not reported because each document of it is associated with multiple categories.
",5.3. Document Classification,[0],[0]
nomenon: word embeddings help more on the sparser data and increasing the network depth improves the accuracy.,5.3. Document Classification,[0],[0]
"Topic coherence is another popular evaluation of topic models (Zuo et al., 2016; Zhao et al., 2017b;b).",5.4. Topic Coherence,[0],[0]
It measures the semantic coherence in the most significant words (top words) in a topic.,5.4. Topic Coherence,[0],[0]
"Here we used the Normalized Pointwise Mutual Information (NPMI) (Aletras & Stevenson, 2013; Lau et al., 2014) to calculate topic coherence score of the top 10 words of each topic and report the average score of all the topics.8
To compare with the other models, in this experiment, we set S = 1 for WEDTM.",5.4. Topic Coherence,[0],[0]
"Recall that in WEDTM, from global to local, there are three ways to interpret a topic.",5.4. Topic Coherence,[0],[0]
"Here we evaluate NPMI for two of them: eF
>wk1 and φ(1)k1 .",5.4. Topic Coherence,[0],[0]
"Figure 3 shows the NPMI scores for all the models on WS, TMN, and Twitter.",5.4. Topic Coherence,[0],[0]
"It is not surprising to see that the top words generated by eF
>wk1 in WEDTM always gain the highest NPMI scores, meaning that the topics are more coherent.",5.4. Topic Coherence,[0],[0]
This is because the topic embeddings in WEDTM directly interact with word embeddings.,5.4. Topic Coherence,[0],[0]
"Moreover, if we just compare the topics generated by φ(1)k1 , WEDTM also gives more coherent topics than the other models.",5.4. Topic Coherence,[0],[0]
This demonstrates that the proposed model is able to discover more interpretable topics.,5.4. Topic Coherence,[0],[0]
"As one of the most appealing properties of WEDTM is its interpretability, we conducted the extensive qualitative evaluation of the quality of the topics discovered by WEDTM, including topic embeddings, sub-topics, and topic hierarchies.",5.5. Qualitative Analysis,[0],[0]
"More qualitative analysis including topic hierarchy visualization and synthetic document generation is shown in the supplementary materials.
",5.5. Qualitative Analysis,[0],[0]
Demonstration of topic embeddings: We demonstrate that WEDTM discovers more coherent topics by comparing with those of GBN in Table 2.,5.5. Qualitative Analysis,[0],[0]
Here we set S = 1 as well.,5.5. Qualitative Analysis,[0],[0]
This demonstration further explains the numerical results in Figure 3.,5.5. Qualitative Analysis,[0],[0]
It is also interesting to compare the local interpretation (φ(1)k ) and global interpretation (topic embeddings) of the same topic in WEDTM.,5.5. Qualitative Analysis,[0],[0]
"For example, in the fifth set, the local interpretation (5.b) is about “networks and security,” while the global interpretation (5.c) generalizes it with more general words related to “communications.”",5.5. Qualitative Analysis,[0],[0]
"We can also observe that although the local interpretation of WEDTM is not as close to word embeddings as the global interpretation, as informed by the global interpretation, the
8We used the Palmetto package with a large Wikipedia dump to compute NPMI (http://palmetto.aksw.org).
local interpretation of WEDTM’s topics is still considerably more coherent than those in GBN.
",5.5. Qualitative Analysis,[0],[0]
"Demonstration of sub-topics: In Figure 4, We show the sub-topics discovered by WEDTM for the topics used as examples at the beginning of the paper (Table 1).",5.5. Qualitative Analysis,[0],[0]
It can be observed that the intra topic structures with sub-topics clearly help to explain the local topics.,5.5. Qualitative Analysis,[0],[0]
"For example, WEDTM successfully splits Topic 1 into sub-topics related to “journal” and “biology,” and Topic 2 into “music” and “sports”.",5.5. Qualitative Analysis,[0],[0]
"Moreover, with the help of word embeddings, WEDTM discovers general sub-topics for specific topics.",5.5. Qualitative Analysis,[0],[0]
"For example, Topic 3 and 4 are more interpretable with the sub-topics of “singer” and “game” respectively.",5.5. Qualitative Analysis,[0],[0]
"The experiment also empirically demonstrates the shrinkage mechanism of the model: for most topics, the effective sub-topics are less than the maximum number S = 5.
",5.5. Qualitative Analysis,[0],[0]
Demonstration of topic hierarchies: Figure 5 shows an example that jointly demonstrates the inter and intra structures of WEDTM.,5.5. Qualitative Analysis,[0],[0]
"The tree is a cluster of topics related to “health,” where the topic hierarchies are discovered by ranking {Φ(t)}t, the leaf nodes are the topics in the bottom layer, and each bottom-layer topic is associated with a set of sub-topics.",5.5. Qualitative Analysis,[0],[0]
"In WEDTM, the inter topic structures are revealed in the form of topic hierarchies while the intra topic structures are revealed in the form of sub-topics.",5.5. Qualitative Analysis,[0],[0]
"Combining the two kinds of topic structures in this way gives a better view of the target corpus, which may further benefit other text analysis tasks.",5.5. Qualitative Analysis,[0],[0]
"In this paper, we have proposed WEDTM, a deep topic model that leverages word embeddings to discover inter topic structures with topic hierarchies and intra topic structures with sub-topics.",6. Conclusion,[0],[0]
"Moreover, with the introduction to sub-topic embeddings, each sub-topic can be informed by the global information in word embeddings, so as to discover a fine-grained thematic aspect of a local topic.",6. Conclusion,[0],[0]
"With topic embeddings, WEDTM provides different views to a topic, from global to local, which further improves the interpretability of the model.",6. Conclusion,[0],[0]
"As a fully conjugate model, the inference of WEDTM can be done by a straightforward Gibbs sampling algorithm.",6. Conclusion,[0],[0]
"Extensive experiments have shown that WEDTM achieves the state-of-the-art performance on perplexity, document classification, and topic quality.",6. Conclusion,[0],[0]
"In addition, with topic hierarchies, sub-topics, and topic embeddings, the model can discover more interpretable structured topics, which helps to get better understandings of text data.",6. Conclusion,[0],[0]
"Given the local conjugacy, it is possible to derive more scalable inference algorithms for WEDTM, such as stochastic variational inference and stochastic gradient MCMC, which is a good subject for future work.",6. Conclusion,[0],[0]
One important task of topic modeling for text analysis is interpretability.,abstractText,[0],[0]
By discovering structured topics one is able to yield improved interpretability as well as modeling accuracy.,abstractText,[0],[0]
"In this paper, we propose a novel topic model with a deep structure that explores both inter-topic and intra-topic structures informed by word embeddings.",abstractText,[0],[0]
"Specifically, our model discovers inter topic structures in the form of topic hierarchies and discovers intra topic structures in the form of sub-topics, each of which is informed by word embeddings and captures a fine-grained thematic aspect of a normal topic.",abstractText,[0],[0]
"Extensive experiments demonstrate that our model achieves the state-of-the-art performance in terms of perplexity, document classification, and topic quality.",abstractText,[0],[0]
"Moreover, with topic hierarchies and sub-topics, the topics discovered in our model are more interpretable, providing an illuminating means to understand text data.",abstractText,[0],[0]
Inter and Intra Topic Structure Learning with Word Embeddings,title,[0],[0]
"Programming robots is very difficult, in part because the real world is inherently rich and—to some degree— unpredictable.",1. Introduction,[0],[0]
"In addition, our expectations for physical agents are quite high and often difficult to articulate.",1. Introduction,[0],[0]
"Nevertheless, for robots to have a significant impact on the lives of individuals, even non-programmers need to be able to specify and customize behavior.",1. Introduction,[0],[0]
"Because of these complexities, relying on end-users to provide instructions to robots programmatically seems destined to fail.
",1. Introduction,[0],[0]
Reinforcement learning (RL) from human trainer feedback provides a compelling alternative to programming because agents can learn complex behavior from very simple positive and negative signals.,1. Introduction,[0],[0]
"Furthermore, real-world animal training is an existence proof that people can train complex
*Equal contribution 1Cogitai 2Brown University 3North Carolina State University 4Washington State University.",1. Introduction,[0],[0]
"Correspondence to: James MacGlashan <james@cogitai.com>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
behavior using these simple signals.,1. Introduction,[0],[0]
"Indeed, animals have been successfully trained to guide the blind, locate mines in the ocean, detect cancer or explosives, and even solve complex, multi-stage puzzles.
",1. Introduction,[0],[0]
"Despite success when learning from environmental reward, traditional reinforcement-learning algorithms have yielded limited success when the reward signal is provided by humans.",1. Introduction,[0],[0]
This failure underscores the importance that algorithms for learning from humans are based on appropriate models of human-feedback.,1. Introduction,[0],[0]
"Indeed, much human-centered RL work has investigated and employed different models of human-feedback (Knox & Stone, 2009b; Thomaz & Breazeal, 2006; 2007; 2008; Griffith et al., 2013; Loftin et al., 2015).",1. Introduction,[0],[0]
"Many of these algorithms leverage the observation that people tend to give feedback that is best interpreted as guidance on the policy the agent should be following, rather than as a numeric value to be maximized by the agent.",1. Introduction,[0],[0]
"However, these approaches assume models of feedback that are independent of the policy the agent is currently following.",1. Introduction,[0],[0]
We present empirical results that demonstrate that this assumption is incorrect and further demonstrate cases in which policy-independent learning algorithms suffer from this assumption.,1. Introduction,[0],[0]
"Following this result, we present Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent human feedback.",1. Introduction,[0],[0]
"COACH is based on the insight that the advantage function (a value roughly corresponding to how much better or worse an action is compared to the current policy) provides a better model of human feedback, capturing human-feedback properties like diminishing returns, rewarding improvement, and giving 0-valued feedback a semantic meaning that combats forgetting.",1. Introduction,[0],[0]
We compare COACH to other approaches in a simple domain with simulated feedback.,1. Introduction,[0],[0]
"Then, to validate that COACH scales to complex problems, we train five different behaviors on a TurtleBot robot.",1. Introduction,[0],[0]
"For modeling the underlying decision-making problem of an agent being taught by a human, we adopt the Markov Decision Process (MDP) formalism.",2. Background,[0],[0]
"An MDP is a 5-tuple: 〈S,A, T,R, γ〉, where S is the set of possible states of the
environment; A is the set of actions available to the agent; T (s′|s, a) is the transition function, which defines the probability of the environment transitioning to state s′ when the agent takes action a in environment state s; R(s, a, s′) is the reward function specifying the numeric reward the agent receives for taking action a in state s and transitioning to state s′; and γ ∈",2. Background,[0],[0]
"[0, 1] is a discount factor specifying how much immediate rewards are preferred to more distant rewards.
",2. Background,[0],[0]
"A stochastic policy π for an MDP is a per-state action probability distribution that defines an agent’s behavior; π : S × A → [0, 1], where ∑ a∈A π(s, a) = 1,∀s ∈ S.",2. Background,[0],[0]
"In the MDP setting, the goal is to find the optimal policy π∗, which maximizes the expected future discounted reward when the agent selects actions in each state according to π∗; π∗ = argmaxπ E[ ∑∞ t=0 γ
trt|π], where rt is the reward received at time t. Two important concepts in MDPs are the value function (V π) and action– value function (Qπ).",2. Background,[0],[0]
The value function defines the expected future discounted reward from each state when following some policy and the action–value function defines the expected future discounted reward when an agent takes some action in some state and then follows some policy π thereafter.,2. Background,[0],[0]
"These equations can be recursively defined via the Bellman equation: V π(s) = ∑ a π(s, a)Q
π(s, a) and Qπ(s, a) = ∑ s′ T (s
′|s, a)",2. Background,[0],[0]
"[R(s, a, s′) + γV π(s′)].",2. Background,[0],[0]
"For shorthand, the value functions for the optimal policies are usually denoted V ∗ and Q∗.
In reinforcement learning (RL), an agent interacts with an environment modeled as an MDP, but does not have direct access to the transition function or reward function and instead must learn a policy from environment observations.",2. Background,[0],[0]
A common class of RL algorithms are actorcritic algorithms.,2. Background,[0],[0]
Bhatnagar et al. (2009) provide a general template for these algorithms.,2. Background,[0],[0]
Actor-critic algorithms are named for the two main components of the algorithms: The actor is a parameterized policy that dictates how the agent selects actions; the critic estimates the value function for the actor and provides critiques at each time step that are used to update the policy parameters.,2. Background,[0],[0]
"Typically, the critique is the temporal difference (TD) error: δt = rt + γV (st)− V (st−1), which describes how much better or worse a transition went than expected.",2. Background,[0],[0]
"In this work, a human-centered reinforcement-learning (HCRL) problem is a learning problem in which an agent is situated in an environment described by an MDP but in which rewards are generated by a human trainer instead of from a stationary MDP reward function that the agent is meant to maximize.",3. Human-centered Reinforcement Learning,[0],[0]
The trainer has a target policy π∗ they are trying to teach the agent.,3. Human-centered Reinforcement Learning,[0],[0]
"The trainer communicates this
policy by giving numeric feedback as the agent acts in the environment.",3. Human-centered Reinforcement Learning,[0],[0]
"The goal of the agent is to learn the target policy π∗ from the feedback.
",3. Human-centered Reinforcement Learning,[0],[0]
"To define a learning algorithm for this problem, we first characterize how human trainers typically use numeric feedback to teach target policies.",3. Human-centered Reinforcement Learning,[0],[0]
"If feedback is stationary and intended to be maximized, it can be treated as a reward function and standard RL algorithms used.",3. Human-centered Reinforcement Learning,[0],[0]
"Although this approach has had some success (Pilarski et al., 2011; Isbell et al., 2001), there are complications that limit its applicability.",3. Human-centered Reinforcement Learning,[0],[0]
"In particular, a trainer must take care that the feedback they give contains no unanticipated exploits, constraining the feedback strategies they can use.",3. Human-centered Reinforcement Learning,[0],[0]
"Indeed, prior research has shown that interpreting human feedback like a reward function often induces positive reward cycles that lead to unintended behaviors (Knox, 2012; Ho et al., 2015).
",3. Human-centered Reinforcement Learning,[0],[0]
"The issues with interpreting feedback as reward have led to the insight that human feedback is better interpreted as commentary on the agent’s behavior; for example, positive feedback roughly corresponds to “that was good” and negative feedback roughly corresponds to “that was bad.”",3. Human-centered Reinforcement Learning,[0],[0]
"In the next section, we review existing HCRL approaches that build on this insight.",3. Human-centered Reinforcement Learning,[0],[0]
A number of existing approaches to HCRL and RL that includes human feedback has been explored in the past.,4. Related Work,[0],[0]
"The most similar to ours, and a primary inspiration for this work, is the TAMER framework (Knox, 2012).",4. Related Work,[0],[0]
"In TAMER, trainers provide interactive numeric feedback as the learner takes actions.",4. Related Work,[0],[0]
The learner attempts to estimate a target reward function by interpreting trainer feedback as exemplars of this function.,4. Related Work,[0],[0]
"When the agent makes rapid decisions, TAMER divides the feedback among the recent state–action pairs according to a probability distribution.",4. Related Work,[0],[0]
TAMER makes decisions by myopically choosing the action with the highest reward estimate.,4. Related Work,[0],[0]
"Because the agent myopically maximizes reward, the feedback can also be thought of as exemplars of Q∗. Later work also investigated non-myopically maximizing the learned reward function with a planning algorithm (Knox & Stone, 2013), but this approach requires a model of the environment and special treatment of termination conditions.
",4. Related Work,[0],[0]
"Two other closely related approaches are SABL (Loftin et al., 2015) and Policy Shaping (Griffith et al., 2013).",4. Related Work,[0],[0]
Both of these approaches treat feedback as discrete probabilistic evidence of the trainer’s target parameterized policy.,4. Related Work,[0],[0]
"SABL’s probabilistic model additionally includes (learnable) parameters for describing how often a trainer is expected to give explicit positive or negative feedback.
",4. Related Work,[0],[0]
"There have also been some domains in which treating hu-
man feedback as reward signals to maximize has had some success, such as in shaping the control for a prosthetic arm (Pilarski et al., 2011) and learning how to interact in an online chat room from multiple users’ feedback (Isbell et al., 2001).",4. Related Work,[0],[0]
"Some complications with how people give feedback have been reported, however.
",4. Related Work,[0],[0]
"Some research has also examined combining human feedback with more traditional environmental rewards (Knox & Stone, 2010; Tenorio-Gonzalez et al., 2010; Clouse & Utgoff, 1992; Maclin et al., 2005).",4. Related Work,[0],[0]
A challenge in this context in practice is that rewards do not naturally come from the environment and must be programmatically defined.,4. Related Work,[0],[0]
"However, it is appealing because the agent can learn in the absence of an active trainer.",4. Related Work,[0],[0]
"We believe our approach to HCRL could also straightforwardly incorporate learning from environmental reward as well, but we leave this investigation for future work.
",4. Related Work,[0],[0]
"Finally, a related research area is learning from demonstration (LfD), in which a human provides examples of the desired behavior.",4. Related Work,[0],[0]
There are a number of different approaches to solving this problem surveyed by Argall et al. (2009).,4. Related Work,[0],[0]
"We see these approaches as complementary to HCRL because it is not always possible, or convenient, to provide demonstrations.",4. Related Work,[0],[0]
"LfD approaches that learn a parameterized policy could also operate with COACH, allowing the agent to have their policy seeded by demonstrations, and then fine tuned with interactive feedback.
",4. Related Work,[0],[0]
"Note that the policy-dependent feedback we study here is viewed as essential in behavior analysis reinforcement schedules (Miltenberger, 2011).",4. Related Work,[0],[0]
"Trainers are taught to provide diminishing returns (gradual decreases in positive feedback for good actions as the agent adopts those actions), differential feedback (varied magnitude of feedbacks depending on the degree of improvement or deterioration in behavior), and policy shaping (positive feedback for suboptimal actions that improve behavior and then negative feedback after the improvement has been made), all of which are policy dependent.",4. Related Work,[0],[0]
A common assumption of existing HCRL algorithms is that feedback depends only on the quality of an agent’s action selection.,5. Policy-dependent Feedback,[0],[0]
An alternative hypothesis is that feedback also depends on the agent’s current policy.,5. Policy-dependent Feedback,[0],[0]
"That is, an action selection may be more greatly rewarded or punished depending on how often the agent would typically be inclined to select it.",5. Policy-dependent Feedback,[0],[0]
"For example, more greatly rewarding the agent for improving its performance than maintaining the status quo.",5. Policy-dependent Feedback,[0],[0]
We call the former model of feedback policy-independent and the latter policy-dependent.,5. Policy-dependent Feedback,[0],[0]
"If people are more naturally inclined toward one model of feedback, algorithms
based on the wrong assumption may result in unexpected responses to feedback.",5. Policy-dependent Feedback,[0],[0]
"Consequently, we were interested in investigating which model better fits human feedback.
",5. Policy-dependent Feedback,[0],[0]
"Despite existing HCRL algorithms assuming policyindependent feedback, evidence of policy-dependent feedback can be found in prior works with these algorithms.",5. Policy-dependent Feedback,[0],[0]
"For example, it was often observed that trainers taper their feedback over the course of learning (Ho et al., 2015; Knox et al., 2012; Isbell et al., 2001).",5. Policy-dependent Feedback,[0],[0]
"Although diminishing feedback is a property that is explained by people’s feedback being policy-dependent—as the learner’s performance improves, trainer feedback is decreased—an alternative explanation is simply trainer fatigue.",5. Policy-dependent Feedback,[0],[0]
"To further make the case for human feedback being policy dependent, we provide a stronger result showing that trainers—for the same state– action pair—choose positive or negative feedback depending on their perception of the learner’s behavior.",5. Policy-dependent Feedback,[0],[0]
"We had Amazon Mechanical Turk (AMT) participants teach an agent in a simple sequential task, illustrated in Figure 1.",5.1. Empirical Results,[0],[0]
Participants were instructed to train a virtual dog to walk to the yellow goal location in a grid world as fast as possible but without going through the green cells.,5.1. Empirical Results,[0],[0]
"They were additionally told that, as a result of prior training, their dog was already either “bad,” “alright,” or “good” at the task and were shown examples of each behavior before training.",5.1. Empirical Results,[0],[0]
"In all cases, the dog would start in the location shown in Figure 1.",5.1. Empirical Results,[0],[0]
“Bad” dogs walked straight through the green cells to the yellow cell.,5.1. Empirical Results,[0],[0]
"“Alright” dogs first moved left, then up, and then to the goal, avoiding green but not taking the shortest route.",5.1. Empirical Results,[0],[0]
"“Good” dogs took the shortest path to yellow without going through green.
",5.1. Empirical Results,[0],[0]
"During training, participants saw the dog take an action from one tile to another and then gave feedback after every action using a continuous labeled slider as shown.",5.1. Empirical Results,[0],[0]
"The slider always started in the middle of the scale on each trial, and several points were labeled with different levels
of reward (praise and treats) and punishment (scolding and a mild electric shock).",5.1. Empirical Results,[0],[0]
Participants went through a brief tutorial using this interface.,5.1. Empirical Results,[0],[0]
"Responses were coded as a numeric value from −50 to 50, with “Do Nothing” as the zero-point.
",5.1. Empirical Results,[0],[0]
"During the training phase, participants trained a dog for three episodes that all started in the same position and ended at the goal.",5.1. Empirical Results,[0],[0]
The dog’s behavior was pre-programmed in such a way that the first step of the final episode would reveal if feedback was policy dependent.,5.1. Empirical Results,[0],[0]
"Each user was placed into one of three different conditions: improving, steady, or degrading.",5.1. Empirical Results,[0],[0]
"For all three conditions, the dog’s behavior in the final episode was “alright,” regardless of any prior feedback.",5.1. Empirical Results,[0],[0]
The conditions differed in terms of the behavior users observed in the first two episodes.,5.1. Empirical Results,[0],[0]
"In the first two episodes, users observed bad behavior in the improving condition (improving to alright); alright behavior in the steady condition; and good behavior in the degrading condition.",5.1. Empirical Results,[0],[0]
"If feedback is policy-dependent, we would expect more positive feedback in the final episode for the improving condition, but not for policy-independent feedback since it was the same final behavior for all conditions.
",5.1. Empirical Results,[0],[0]
Figure 2 shows boxplots and individual responses for the first step of the final episode under each of the three conditions.,5.1. Empirical Results,[0],[0]
"These results indicate that the sign of feedback is sensitive to the learner’s policy, as predicted.",5.1. Empirical Results,[0],[0]
"The mean and median feedback under the improving condition is slightly positive (Mean = 9.8, Median = 24, S.D. = 22.2; planned Wilcoxon one-sided signed-rank test: Z = 1.71, p < 0.05), whereas it is negative for the steady condition (Mean = −18.3, Median = −23.5, S.D.",5.1. Empirical Results,[0],[0]
"= 24.6; planned Wilcoxon two-sided signed-rank test: Z = −3.15, p < 0.01) and degrading condition (Mean = −10.8, Median = −18.0, S.D. = 20.7; planned Wilcoxon one-sided signed-rank test: Z = −2.33, p < 0.05).",5.1. Empirical Results,[0],[0]
"There was a main effect across the three conditions (p < 0.01, Kruskal-Wallace Test), and pairwise comparisons indicated that only the improving condition differed from steady and degrading conditions (p < 0.01 for both, Bonferroni-corrected, Mann-Whitney Pairwise test).",5.1. Empirical Results,[0],[0]
"In this section, we introduce Convergent Actor-Critic by Humans (COACH), an actor-critic-based algorithm capable of learning from policy-dependent feedback.",6. Convergent Actor-Critic by Humans,[0],[0]
"COACH is based on the insight that the advantage function is a good model of human feedback and that actor–critic algorithms update a policy using the critic’s TD error, which is an unbiased estimate of the advantage function.",6. Convergent Actor-Critic by Humans,[0],[0]
"Consequently, an agent’s policy can be directly modified by human feedback without a critic component.",6. Convergent Actor-Critic by Humans,[0],[0]
We first define the advantage function and its interpretation as trainer feedback.,6. Convergent Actor-Critic by Humans,[0],[0]
"Then,
we present the general update rule for COACH and its convergence.",6. Convergent Actor-Critic by Humans,[0],[0]
"Finally, we present Real-time COACH, which includes mechanisms for providing variable magnitude feedback and learning in problems with a high-frequency decision cycle.",6. Convergent Actor-Critic by Humans,[0],[0]
"The advantage function (Baird, 1995)",6.1. The Advantage Function and Feedback,[0],[0]
"Aπ is defined as
Aπ(s, a) =",6.1. The Advantage Function and Feedback,[0],[0]
"Qπ(s, a)− V π(s).",6.1. The Advantage Function and Feedback,[0],[0]
"(1)
Roughly speaking, the advantage function describes how much better or worse an action selection is compared to the agent’s performance under policy π.",6.1. The Advantage Function and Feedback,[0],[0]
"The function is closely related to the update used in policy iteration (Puterman, 1994): defining π′(s) = argmaxaA
π(s, a) is guaranteed to produce an improvement over π whenever π is suboptimal.",6.1. The Advantage Function and Feedback,[0],[0]
"It can also be used in policy gradient methods to gradually improve the performance of a policy, as described later.
",6.1. The Advantage Function and Feedback,[0],[0]
It is worth nothing that feedback produced by the advantage function is consistent with that recommended in behavior analysis.,6.1. The Advantage Function and Feedback,[0],[0]
It trivially results in differential feedback since it is defined as the magnitude of improvement of an action over its current policy.,6.1. The Advantage Function and Feedback,[0],[0]
"It induces diminishing returns because, as π improves opportunities to improve on it decrease.",6.1. The Advantage Function and Feedback,[0],[0]
"Indeed, once π is optimal, all advantagefunction-based feedback is zero or negative.",6.1. The Advantage Function and Feedback,[0],[0]
"Finally, advantage function feedback induces policy shaping in that whether feedback is positive or negative for an action depends on whether it is a net improvement over the current behavior.",6.1. The Advantage Function and Feedback,[0],[0]
"Given a performance metric ρ, Sutton et al. (1999) derive a policy gradient algorithm of the form: ∆θ = α∇θρ.",6.2. Convergence and Update Rule,[0],[0]
"Here,
θ represents the parameters that control the agent’s behavior and α is a learning rate.",6.2. Convergence and Update Rule,[0],[0]
"Under the assumption that ρ is the discounted expected reward from a fixed start state distribution, they show that
∇θρ = ∑ s dπ(s) ∑ a ∇θπ(s, a)Qπ(s, a),
where dπ(s) is the component of the (discounted) stationary distribution at s. A benefit of this form of the gradient is that, given that states are visited according to dπ(s) and actions are taken according to π(s, a), the update at time t can be made as:
∆θt = αt∇θπ(st, at) ft+1
π(st, at) , (2)
where E[ft+1] = Qπ(st, at)",6.2. Convergence and Update Rule,[0],[0]
"− v(s) for any actionindependent function v(s).
",6.2. Convergence and Update Rule,[0],[0]
"In the context of the present paper, ft+1 represents the feedback provided by the trainer.",6.2. Convergence and Update Rule,[0],[0]
"It follows trivially that if the trainer chooses the policy-dependent feedback ft = Qπ(st, at), we obtain a convergent learning algorithm that (locally) maximizes discounted expected reward.",6.2. Convergence and Update Rule,[0],[0]
"In addition, feedback of the form ft = Qπ(st, at)",6.2. Convergence and Update Rule,[0],[0]
"− V π(st) = Aπ(st, at) also results in convergence.",6.2. Convergence and Update Rule,[0],[0]
"Note that for the trainer to provide feedback in the form of Qπ or Aπ , they would need to “peer inside” the learner and observe its policy.",6.2. Convergence and Update Rule,[0],[0]
"In practice, the trainer estimates π by observing the agent’s actions.",6.2. Convergence and Update Rule,[0],[0]
There are challenges in implementing Equation 2 for realtime use in practice.,6.3. Real-time COACH,[0],[0]
"Specifically, the interface for providing variable magnitude feedback needs to be addressed, and the question of how to handle sparseness and the timing of feedback needs to be answered.",6.3. Real-time COACH,[0],[0]
"Here, we introduce Realtime COACH, shown in Algorithm 1, to address these issues.
",6.3. Real-time COACH,[0],[0]
"For providing variable magnitude reward, we use reward aggregation (Knox & Stone, 2009b).",6.3. Real-time COACH,[0],[0]
"In reward aggregation, a trainer selects from a discrete set of feedback values and further raises or lowers the numeric value by giving multiple feedbacks in succession that are summed together.
",6.3. Real-time COACH,[0],[0]
"While sparse feedback is not especially problematic (because no feedback results in no change in policy), it may slow down learning unless the trainer is provided with a mechanism to allow feedback to affect a history of actions.",6.3. Real-time COACH,[0],[0]
"We use eligibility traces (Barto et al., 1983) to help apply feedback to the relevant transitions.",6.3. Real-time COACH,[0],[0]
An eligibility trace is a vector that keeps track of the policy gradient and decays exponentially with a parameter λ.,6.3. Real-time COACH,[0],[0]
"Policy parameters are then updated in the direction of the trace, allowing feedback to affect earlier decisions.",6.3. Real-time COACH,[0],[0]
"However, a trainer may not
Algorithm 1 Real-time COACH Require: policy πθ0 , trace set λ, delay d, learning rate α
Initialize traces eλ ← 0 ∀λ ∈ λ observe initial state s0 for t = 0 to∞ do
select and execute action at ∼ πθt(st, ·) observe next state st+1, sum feedback ft+1, and λ for λ′ ∈ λ do eλ′ ← λ′eλ′ + 1πθt (st−d,at−d)∇θtπθt(st−d, at−d) end for θt+1 ← θt + αft+1eλ
end for
always want to influence a long history of actions.",6.3. Real-time COACH,[0],[0]
"Consequently, Real-time COACH maintains multiple eligibility traces with different temporal decay rates and the trainer chooses which eligibility trace to use for each update.",6.3. Real-time COACH,[0],[0]
"This trace choice may be handled implicitly with the feedback value selection or explicitly.
",6.3. Real-time COACH,[0],[0]
"Due to reaction time, human feedback is typically delayed by about 0.2 to 0.8 seconds from the event to which they meant to give feedback (Knox, 2012).",6.3. Real-time COACH,[0],[0]
"To handle this delay, feedback in Real-time COACH is associated with events from d steps ago to cover the gap.",6.3. Real-time COACH,[0],[0]
"Eligibility traces further smooth the feedback to older events.
",6.3. Real-time COACH,[0],[0]
"Finally, we note that just as there are numerous variants of actor-critic update rules, similar variations can be used in the context of COACH.",6.3. Real-time COACH,[0],[0]
"To understand the behavior of COACH under different types of trainer feedback strategies, we carried out a controlled comparison in a simple grid world.",7. Comparison of Update Rules,[0],[0]
The domain is essentially an expanded version of the dog domain used in our human-subject experiment.,7. Comparison of Update Rules,[0],[0]
"It is a 8 × 5 grid in which the agent starts in 0, 0 and must get to 7, 0, which yields +5 reward.",7. Comparison of Update Rules,[0],[0]
"However, from 1, 0 to 6, 0 are cells the agent needs to avoid, which yield −1 reward.",7. Comparison of Update Rules,[0],[0]
Three types of learning algorithms were tested.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Each maintains an internal data structure, which it updates with feedback of the form 〈s, a, f, s′〉, where s is a state, a is an action taken in that state, f is the feedback received from the trainer, and s′ is the resulting next state.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The algorithm also must produce an action for each state encountered.
",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The first algorithm, Q learning (Watkins & Dayan, 1992), represents a standard value-function-based RL algorithm designed for reward maximization under delayed feedback.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"It maintains a data structure Q(s, a), initially 0.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Its update
rule has the form:
∆Q(s, a) = α[f + γmax a′
Q(s′, a′)−Q(s, a)].",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"(3)
Actions are chosen using the rule: argmaxaQ(s, a), where ties are broken randomly.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"We tested a handful of parameters and used the best values: discount factor γ = 0.99 and learning rate α = 0.2.
",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"In TAMER (Knox & Stone, 2009a), a trainer provides interactive numeric feedback that is interpreted as an exemplar of the reward function for the demonstrated state–action pair as the learner takes actions.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"We assumed that each feedback applies to the last action, and thus used a simplified version of the algorithm that did not attempt to spread updates over multiple transitions.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"TAMER maintains a data structure RH(s, a) for the predicted reward in each state, initially 0.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"It is updated by: ∆RH(s, a) = αf .",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
We used α = 0.2.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Actions are chosen via an -greedy rule on RH(s, a) with = 0.2.
",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Lastly, we examined COACH, which is also designed to work well with human-generated feedback.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
We used a softmax policy with a single λ = 0 trace.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The parameters were a matrix of values θ(s, a), initially zero.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The stochastic policy defined by these parameters was
π(s, a) = eβθ(s,a)/ ∑ a eβθ(s,a),
with β = 1.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Parameters were updated via
∆θ = α∇θπ(s, a) f
π(s, a) , (4)
where α is a learning rate.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"We used α = 0.05.
",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"In effect, each of these learning rules makes an assumption about the kind of feedback it expects trainers to use.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
We wanted to see how they would behave with feedback strategies that matched these assumptions and those that did not.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The first feedback strategy we studied is the classical task-based reward function (“task”) where the feedback is sparse: +5 reward when the agent reaches the goal state, −1 for avoidance cells, and 0 for all other transitions.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
Q-learning is known to converge to optimal behavior with this type of feedback.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The second strategy provides policy-independent feedback for each state–action pair (“action”): +5 when the agent reaches termination, +1 reward when the selected action matches an optimal policy, −1 for reaching an avoidance cell, and 0 otherwise.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
This type of feedback serves TAMER well.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"The third strategy (“improvement”) used feedback defined by the advantage function of the learner’s current policy π, Aπ(s, a) =",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
"Qπ(s, a) − V π(s), where the value functions are defined based on the task rewards.",7.1. Learning Algorithms and Feedback Strategies,[0],[0]
This type of feedback is very well suited to COACH.,7.1. Learning Algorithms and Feedback Strategies,[0],[0]
Each combination of algorithm and feedback strategy was run 99 times with the median value of the number of steps needed to reach the goal reported.,7.2. Results,[0],[0]
"Episodes were ended after 1, 000 steps if the goal was not reached.
",7.2. Results,[0],[0]
Figure 3(a) shows the steps needed to reach the goal for the three algorithms trained with task feedback.,7.2. Results,[0],[0]
The figure shows that TAMER can fail to learn in this setting.,7.2. Results,[0],[0]
"COACH also performs poorly with λ = 0, which prevents feedback from influencing earlier decisions.",7.2. Results,[0],[0]
"We did a subsequent experiment (not shown) with λ = 0.9 and found that COACH converged to reasonable behavior, although not as quickly as Q learning.",7.2. Results,[0],[0]
"This result helps justify using traces to combat the challenges of delayed feedback.
",7.2. Results,[0],[0]
Figure 3(b) shows results with action feedback.,7.2. Results,[0],[0]
"This time, Q learning fails to perform well, a consequence of this feedback strategy inducing positive behavior cycles as it tries to avoid ending the trial, the same kind of problem that HCRL algorithms have been designed to avoid.",7.2. Results,[0],[0]
Both TAMER and COACH perform well with this feedback strategy.,7.2. Results,[0],[0]
"TAMER performs slightly better than COACH, as this is precisely the kind of feedback TAMER was designed to handle.
",7.2. Results,[0],[0]
"Figure 3(c) shows the results of the three algorithms with improvement feedback, which is generated via the advantage function defined on the learner’s current policy.",7.2. Results,[0],[0]
These results tells a different story.,7.2. Results,[0],[0]
"Here, COACH performs the best.",7.2. Results,[0],[0]
"Q-learning largely flounders for most of the time, but with enough training sometimes start to converge.",7.2. Results,[0],[0]
"(Although, 14% of the time, Q learning fails to do well even after 100 training episodes).",7.2. Results,[0],[0]
"TAMER, on the other hand, performs very badly at first.",7.2. Results,[0],[0]
"While the median score in the plot shows TAMER suddenly performing more comparably to COACH after about 10 episodes, 29% of our training trials completely failed to improve and timed-out across all 100 episodes.",7.2. Results,[0],[0]
"In this section, we present qualitative results on Real-time COACH applied to a TurtleBot robot.",8. Robotics Case Study,[0],[0]
"The goal of this study was to test that COACH can scale to a complex domain involving multiple challenges, including training an agent that operates on a fast decision cycle (33ms), noisy non-Markov observations from a camera, and agent perception that is hidden from the trainer.",8. Robotics Case Study,[0],[0]
"To demonstrate the flexibility of COACH, we trained it to perform five different behaviors involving a pink ball and cylinder with an orange top using the same parameter selections.",8. Robotics Case Study,[0],[0]
We discuss these behaviors below.,8. Robotics Case Study,[0],[0]
We also contrast the results to training with TAMER.,8. Robotics Case Study,[0],[0]
"We chose TAMER as a comparison because, to our knowledge, it is the only HCRL algorithm with success on a similar platform (Knox et al., 2013).
",8. Robotics Case Study,[0],[0]
The TurtleBot is a mobile base with two degrees of freedom that senses the world from a Kinect camera.,8. Robotics Case Study,[0],[0]
"We discretized the action space to five actions: forward, backward, rotate clockwise, rotate counterclockwise, and do nothing.",8. Robotics Case Study,[0],[0]
The agent selects one of these actions every 33ms.,8. Robotics Case Study,[0],[0]
"To deliver feedback, we used a Nintendo Wii controller to give +1, +4, or−1 numeric feedback, and pause and continue training.",8. Robotics Case Study,[0],[0]
"For perception, we used only the RGB image channels from the Kinect.",8. Robotics Case Study,[0],[0]
"Because our behaviors were based around a relocatable pink ball and a fixed cylinder with an orange top, we hand constructed relevant image features to be used by the learning algorithms.",8. Robotics Case Study,[0],[0]
These features were generated using techniques similar to those used in neural network architectures.,8. Robotics Case Study,[0],[0]
The features were constructed by first transforming the image into two color channels associated with the colors of the ball and cylinder.,8. Robotics Case Study,[0],[0]
Sum pooling to form a lower-dimensional 8 × 8 grid was applied to each color channel.,8. Robotics Case Study,[0],[0]
Each sum-pooling unit was then passed through three different normalized threshold units defined by Ti(x) =,8. Robotics Case Study,[0],[0]
"min( xφi , 1), where φi specifies the saturation point.",8. Robotics Case Study,[0],[0]
"Using multiple saturation parameters differentiates the distance of objects, resulting in three “depth” scales per color channel.",8. Robotics Case Study,[0],[0]
"Finally, we passed these results through a 2× 8 max-pooling layer with stride 1.
",8. Robotics Case Study,[0],[0]
"The five behaviors we trained were push–pull, hide, ball following, alternate, and cylinder navigation.",8. Robotics Case Study,[0],[0]
"In push–pull, the TurtleBot is trained to navigate to the ball when it is far, and back away from it when it is near.",8. Robotics Case Study,[0],[0]
The hide behavior has the TurtleBot back away from the ball when it is near and turn away from it when it is far.,8. Robotics Case Study,[0],[0]
"In ball following, the TurtleBot is trained to navigate to the ball.",8. Robotics Case Study,[0],[0]
"In the alternate task, the TurtleBot is trained to go back and forth between the cylinder and ball.",8. Robotics Case Study,[0],[0]
"Finally, cylinder navigation involves the agent navigating to the cylinder.",8. Robotics Case Study,[0],[0]
"We further classify training methods for each of these behaviors as flat, involving the push–pull, hide, and ball following behaviors; and compositional, involving the alternate and cylinder navigation behaviors.
",8. Robotics Case Study,[0],[0]
"In all cases, our human trainer (one of the co-authors) used differential feedback and diminishing returns to quickly reinforce behaviors and restrict focus to the areas needing tuning.",8. Robotics Case Study,[0],[0]
"However, in alternate and cylinder navigation, they attempted more advanced compositional training methods.",8. Robotics Case Study,[0],[0]
"For alternate, the agent was first trained to navigate to the ball when it sees it, and then turn away when it is near.",8. Robotics Case Study,[0],[0]
"Then, the same was independently done for the cylinder.",8. Robotics Case Study,[0],[0]
"After training, introducing both objects would cause the agent to move back and forth between them.",8. Robotics Case Study,[0],[0]
"For cylinder navigation, they attempted to make use of an animaltraining method called lure training in which an animal is first conditioned to follow a lure object, which is then used to guide it through more complex behaviors.",8. Robotics Case Study,[0],[0]
"In cylinder navigation, they first trained the ball to be a lure, used it to
guide the TurtleBot to the cylinder, and finally gave a +4 reward to reinforce the behaviors it took when following the ball (turning to face the cylinder, moving toward it, and stopping upon reaching it).",8. Robotics Case Study,[0],[0]
"The agent would then navigate to the cylinder without requiring the ball to be present.
",8. Robotics Case Study,[0],[0]
"For COACH parameters, we used a softmax parameterized policy, where each action preference value was a linear function of the image features, plus tanh(θa), where θa is a learnable parameter for action a, providing a preference in the absence of any stimulus.",8. Robotics Case Study,[0],[0]
"We used two eligibility traces with λ = 0.95 for feedback +1 and −1, and λ = 0.9999 for feedback +4.",8. Robotics Case Study,[0],[0]
"The feedback-action delay d was set to 6, which is 0.198 seconds.",8. Robotics Case Study,[0],[0]
"Additionally, we used an actor-critic parameter-update rule variant in which action preference values are directly modified (along its gradient), rather than by the gradient of the policy (Sutton & Barto, 1998).",8. Robotics Case Study,[0],[0]
This variant more rapidly communicates stimulus–response preferences.,8. Robotics Case Study,[0],[0]
"For TAMER, we used typical parameter values for fast decision cycle problems: delay-weighted aggregate TAMER with uniform distribution credit assignment over 0.2 to 0.8 seconds, p = 0, and cmin = 1 (Knox, 2012).",8. Robotics Case Study,[0],[0]
(See prior work for parameter meaning.),8. Robotics Case Study,[0],[0]
TAMER’s reward-function approximation used the same representation as COACH.,8. Robotics Case Study,[0],[0]
COACH was able to successfully learn all five behaviors and a video showing its learning is available online at https://vid.me/3h2s.,8.1. Results and Discussion,[0],[0]
"Each of these behaviors were trained in less than two minutes, including the time spent verifying that a behavior worked.",8.1. Results and Discussion,[0],[0]
Differential feedback and diminishing returns allowed only the behaviors in need of tuning to be quickly reinforced or extinguished without any explicit division between training and testing.,8.1. Results and Discussion,[0],[0]
"Moreover, the agent successfully benefited from the compositional training methods, correctly combining subbehaviors for alternate, and quickly learning cylinder navigation with the lure.
",8.1. Results and Discussion,[0],[0]
TAMER only successfully learned the behaviors using the flat training methodology and failed to learn the compositionally trained behaviors.,8.1. Results and Discussion,[0],[0]
"In all cases, TAMER tended to forget behavior, requiring feedback for previous decisions it learned to be resupplied after it learned a new decision.",8.1. Results and Discussion,[0],[0]
"For the alternate behavior, this forgetting led to failure: after training the behavior for the cylinder, the agent forgot some of the ball-related behavior and ended up drifting off course when it was time to go to the ball.",8.1. Results and Discussion,[0],[0]
"TAMER also failed to learn from lure training because TAMER does not allow reinforcing a long history of behaviors.
",8.1. Results and Discussion,[0],[0]
We believe TAMER’s forgetting is a result of interpreting feedback as reward-function exemplars in which new feedback in similar contexts can change the target.,8.1. Results and Discussion,[0],[0]
"To il-
lustrate this problem, we constructed a well-defined scenario in which TAMER consistently unlearns behavior.",8.1. Results and Discussion,[0],[0]
"In this scenario, the goal was for the TurtleBot to always stay whenever the ball was present, and move forward if just the cylinder was present.",8.1. Results and Discussion,[0],[0]
We first trained TAMER to stay when the ball alone was present using many rapid rewards (yielding a large aggregated signal).,8.1. Results and Discussion,[0],[0]
"Next, we trained it to move forward when the cylinder alone was present.",8.1. Results and Discussion,[0],[0]
"We then introduced both objects, and the TurtleBot correctly stayed.",8.1. Results and Discussion,[0],[0]
"After rewarding it for staying with a single reward (weaker than the previously-used many rapid rewards), the TurtleBot responded by moving forward—the positive feedback actually caused it to unlearn the rewarded behavior.",8.1. Results and Discussion,[0],[0]
This counter-intuitive response is a consequence of the small reward decreasing its reward-function target for the stay action to a point lower than the value for moving forward.,8.1. Results and Discussion,[0],[0]
"Roughly, because TAMER does not treat zero reward as special, a positive reward can be a negative influence if it is less than expected.",8.1. Results and Discussion,[0],[0]
COACH does not exhibit this problem—any positive reward for staying will strengthen the behavior.,8.1. Results and Discussion,[0],[0]
"In this work, we presented empirical results that show that the numeric feedback people give agents in an interactive training paradigm is influenced by the agent’s current policy and argued why such policy-dependent feedback enables useful training strategies.",9. Conclusion,[0],[0]
"We then introduced COACH, an algorithm that, unlike existing humancentered reinforcement-learning algorithms, converges to a local optimum when trained with policy-dependent feedback.",9. Conclusion,[0],[0]
"We showed that COACH learns robustly in the face of multiple feedback strategies and finally showed that COACH can be used in the context of robotics with advanced training methods.
",9. Conclusion,[0],[0]
There are a number of exciting future directions to extend this work.,9. Conclusion,[0],[0]
"In particular, because COACH is built on the actor-critic paradigm, it should be possible to combine it straightforwardly with learning from demonstration and environmental rewards, allowing an agent to be trained in a variety of ways.",9. Conclusion,[0],[0]
"Second, because people give policydependent feedback, investigating how people model the current policy of the agent and how their model differs from the agent’s actual policy may produce even greater gains.",9. Conclusion,[0],[0]
We thank the anonymous reviewers for their useful suggestions and comments.,Acknowledgements,[0],[0]
"This research has taken place in part at the Intelligent Robot Learning (IRL) Lab, Washington State University.",Acknowledgements,[0],[0]
"IRL’s support includes NASA NNX16CD07C, NSF IIS-1149917, NSF IIS-1643614, and USDA 2014-67021-22174.",Acknowledgements,[0],[0]
This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback.,abstractText,[0],[0]
Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner’s current policy.,abstractText,[0],[0]
We present empirical results that show this assumption to be false— whether human trainers give a positive or negative feedback for a decision is influenced by the learner’s current policy.,abstractText,[0],[0]
"Based on this insight, we introduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum.",abstractText,[0],[0]
"Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot.",abstractText,[0],[0]
Interactive Learning from Policy-Dependent Human Feedback,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2148–2159 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
2148",text,[0],[0]
"Broad-coverage knowledge bases (KBs) such as Freebase (Bollacker et al., 2008) and DBPedia (Auer et al., 2007) store a large amount of facts in the form of 〈head entity, relation, tail entity〉 triples (e.g. 〈The Matrix, country of film, Australia〉), which could support a wide range of reasoning and question answering applications.",1 Introduction,[0],[0]
"The Knowledge Base Completion (KBC) task aims
to predict the missing part of an incomplete triple, such as 〈Finding Nemo, country of film, ?〉, by reasoning from known facts stored in the KB.
",1 Introduction,[0],[0]
"As a most common approach (Wang et al., 2017), modeling entities and relations to operate in a low dimension vector space helps KBC, for three conceivable reasons.",1 Introduction,[0],[0]
"First, when dimension is low, entities modeled as vectors are forced to share parameters, so “similar” entities which participate in many relations in common get close to each other (e.g. Australia close to US).",1 Introduction,[0],[0]
This could imply that an entity (e.g. US) “type matches” a relation such as country of film.,1 Introduction,[0],[0]
"Second, relations may share parameters as well, which could transfer facts from one relation to other similar relations, for example from 〈x, award winner, y〉 to 〈x, award nominated, y〉.",1 Introduction,[0],[0]
"Third, spatial positions might be used to implement composition of relations, as relations can be regarded
as mappings from head to tail entities, and the composition of two maps can match a third (e.g. the composition of currency of country and country of film matches the relation currency of film budget), which could be captured by modeling composition in a space.
",1 Introduction,[0],[0]
"However, modeling relations as mappings naturally requires more parameters – a general linear map between d-dimension vectors is represented by a matrix of d2 parameters – which are less likely to be shared, impeding transfers of facts between similar relations.",1 Introduction,[0],[0]
"Thus, it is desired to reduce dimensionality of relations; furthermore, the existence of a composition of two relations (assumed to be modeled by matrices M1,M2) matching a third (M3) also justifies dimension reduction, because it implies a compositional constraint M1 ·M2 ≈M3 that can be satisfied only by a lower dimension sub-manifold in the parameter space1.
",1 Introduction,[0],[0]
"Previous approaches reduce dimensionality of relations by imposing pre-designed hard constraints on the parameter space, such as constraining that relations are translations (Bordes et al., 2013) or diagonal matrices (Yang et al., 2015), or assuming they are linear combinations of a small number of prototypes (Xie et al., 2017).",1 Introduction,[0],[0]
"However, pre-designed hard constraints do not seem to cope well with compositional constraints, because it is difficult to know a priori which two relations compose to which third relation, hence difficult to choose a pre-design; and compositional constraints are not always exact (e.g. the composition of currency of country and headquarter location usually matches business operation currency but not always), so hard constraints are less suited.
",1 Introduction,[0],[0]
"In this paper, we investigate an alternative approach by training relation parameters jointly with an autoencoder (Figure 1).",1 Introduction,[0],[0]
"During training, the autoencoder tries to reconstruct relations from low dimension codings, with the reconstruction objective back-propagating to relation parameters as well.",1 Introduction,[0],[0]
"We show this novel technique promotes parameter sharing between different relations, and drives them toward low dimension manifolds (Sec.6.2).",1 Introduction,[0],[0]
"Besides, we expect the technique to cope better with compositional constraints, because it discovers low dimension manifolds posteriorly from data, and it does not impose any explicit hard constraints.
",1 Introduction,[0],[0]
"1It is noteworthy that similar compositional constraints apply to most modeling schemes of relations, not just matrices.
",1 Introduction,[0],[0]
"Yet, joint training with an autoencoder is not simple; one has to keep a subtle balance between gradients of the reconstruction and KB-learning objectives throughout the training process.",1 Introduction,[0],[0]
We are not aware of any theoretical principles directly addressing this problem; but we found some important settings after extensive pre-experiments (Sec.4).,1 Introduction,[0],[0]
"We evaluate our system using standard KBC datasets, achieving state-of-the-art on several of them (Sec.6.1), with strongly improved Mean Rank.",1 Introduction,[0],[0]
"We discuss detailed settings that lead to the performance (Sec.4.1), and we show that joint training with an autoencoder indeed helps discovering compositional constraints (Sec.6.2) and benefits from compositional training (Sec.6.3).",1 Introduction,[0],[0]
"A knowledge base (KB) is a set T of triples of the form 〈h, r, t〉, where h, t ∈ E are entities and",2 Base Model,[0],[0]
"r ∈ R is a relation (e.g. 〈The Matrix, country of film, Australia〉).",2 Base Model,[0],[0]
"A relation r has its inverse r−1 ∈ R so that for every 〈h, r, t〉 ∈ T , we regard 〈t, r−1, h〉 as also in the KB.",2 Base Model,[0],[0]
"Under this assumption and given T as training data, we consider the Knowledge Base Completion (KBC) task that predicts candidates for a missing tail entity in an incomplete 〈h, r, ?〉 triple.
",2 Base Model,[0],[0]
Most approaches tackle this problem by training a score function measuring the plausibility of triples being facts.,2 Base Model,[0],[0]
"The model we implement in this work represents entities h, t as d-dimension vectors uh,vt respectively, and relation r as a d×d matrix Mr. If uh,vt are one-hot vectors with dimension d = |E| corresponding to each entity, one can take Mr as the adjacency matrix of entities joined by relation r, so the set of tail entities filling into 〈h, r, ?〉 is calculated by u>hMr (with each nonzero entry corresponds to an answer).",2 Base Model,[0],[0]
"Thus, we have u>hMrvt > 0",2 Base Model,[0],[0]
"if and only if 〈h, r, t〉 ∈ T .",2 Base Model,[0],[0]
"This motivates us to use u>hMrvt as a natural parameter to model plausibility of 〈h, r, t〉, even in a low dimension space with d |E|.",2 Base Model,[0],[0]
"Thus, we define the score function as
s(h, r, t) := exp(u>hMrvt) (1)
for the basic model.",2 Base Model,[0],[0]
"This is similar to the bilinear model of Nickel et al. (2011), except that we distinguish uh (the vector for head entities) from vt (the vector for tail entities).",2 Base Model,[0],[0]
"It has also been proposed in Tian et al. (2016), but for modeling dependency trees rather than KBs.
",2 Base Model,[0],[0]
"More generally, we consider composition of relations r1/ . . .",2 Base Model,[0],[0]
/rl,2 Base Model,[0],[0]
"to model paths in a KB (Guu et al., 2015), as defined by r1, . . .",2 Base Model,[0],[0]
", rl participating in a sequence of facts such that the head entity of each fact coincides with the tail of its previous.",2 Base Model,[0],[0]
"For example, a sequence of two facts 〈The Matrix, country of film, Australia〉 and 〈Australia, currency of country, Australian Dollar〉 form a path of composition country of film / currency of country, because the head of the second fact (i.e. Australia) coincides with the tail of the first.",2 Base Model,[0],[0]
"Using the previous d = |E| analogue, one can verify that composition of relations is represented by multiplication of adjacency matrices, so we accordingly define
s(h, r1/ . . .",2 Base Model,[0],[0]
"/rl, t) :",2 Base Model,[0],[0]
"= exp(u > hMr1 · · ·Mrlvt)
to measure the plausibility of a path.",2 Base Model,[0],[0]
It is explored in Guu et al. (2015) to learn a score function not only for single facts but also for paths.,2 Base Model,[0],[0]
This compositional training scheme is shown to bring valuable information about the structure of the KB and may help KBC.,2 Base Model,[0],[0]
"In this work, we conduct experiments both with and without compositional training.
",2 Base Model,[0],[0]
"In order to learn parameters uh,vt,Mr of the score function, we follow Tian et al. (2016) using a Noise Contrastive Estimation (NCE) (Gutmann and Hyvärinen, 2012) objective.",2 Base Model,[0],[0]
"For each path (or triple) 〈h, r1/ . . .",2 Base Model,[0],[0]
", t〉 taken from the KB, we generate negative samples by replacing the tail entity t with some random noise t∗.",2 Base Model,[0],[0]
"Then, we maximize
L1 := ∑ path ln s(h, r1/ . . .",2 Base Model,[0],[0]
", t)",2 Base Model,[0],[0]
k,2 Base Model,[0],[0]
"+ s(h, r1/ . . .",2 Base Model,[0],[0]
", t)
+ ∑ noise ln",2 Base Model,[0],[0]
k k,2 Base Model,[0],[0]
"+ s(h, r1/ . . .",2 Base Model,[0],[0]
", t∗)
as our KB-learning objective.",2 Base Model,[0],[0]
"Here, k is the number of noises generated for each path.",2 Base Model,[0],[0]
"When the score function is regarded as probability, L1 represents the log-likelihood of “〈h, r1/ . . .",2 Base Model,[0],[0]
", t〉 being actual path and 〈h, r1/ . . .",2 Base Model,[0],[0]
", t∗〉 being noise”.",2 Base Model,[0],[0]
Maximizing L1 increases the scores of actual paths and decreases the scores of noises.,2 Base Model,[0],[0]
Autoencoders learn efficient codings of highdimensional data while trying to reconstruct the original data from the coding.,3 Joint Training with an Autoencoder,[0],[0]
"By joint training relation matrices with an autoencoder, we also expect it to help reducing the dimensionality of the original data (i.e. relation matrices).
",3 Joint Training with an Autoencoder,[0],[0]
"Formally, we define a vectorization mr for each relation matrix Mr, and use it as input to the autoencoder.",3 Joint Training with an Autoencoder,[0],[0]
"mr is defined as a reshape of Mr flattened into a d2-dimension vector, and normalized such that ‖mr‖ =",3 Joint Training with an Autoencoder,[0],[0]
√ d.,3 Joint Training with an Autoencoder,[0],[0]
"We define
cr := ReLU(Amr) (2)
as the coding.",3 Joint Training with an Autoencoder,[0],[0]
"Here A is a c × d2 matrix with c d2, and ReLU is the Rectified Linear Unit function (Nair and Hinton, 2010).",3 Joint Training with an Autoencoder,[0],[0]
We reconstruct the input from cr by multiplying a d2×cmatrix B. We want Bcr to be more similar to mr than other relations.,3 Joint Training with an Autoencoder,[0],[0]
"For this purpose, we define a similarity
g(r1, r2)",3 Joint Training with an Autoencoder,[0],[0]
":= exp( 1√ dc m>r1Bcr2), (3)
which measures the length of Bcr2 projected to the direction of mr1 .",3 Joint Training with an Autoencoder,[0],[0]
"In order to learn the parameters A,B, we adopt the Noise Contrastive Estimation scheme as in Sec.2, generate random noises r∗ for each relation r and maximize
L2 := ∑ r∈R ln g(r, r) k + g(r, r) +",3 Joint Training with an Autoencoder,[0],[0]
"∑ r∗∼R ln k k + g(r, r∗)
",3 Joint Training with an Autoencoder,[0],[0]
as our reconstruction objective.,3 Joint Training with an Autoencoder,[0],[0]
"Maximizing L2 increases mr’s similarity with Bcr, and decreases it with Bcr∗ .
",3 Joint Training with an Autoencoder,[0],[0]
"During joint training, both L1 and L2 are simultaneously maximized, and the gradient ∇L2 propagates to relation matrices as well.",3 Joint Training with an Autoencoder,[0],[0]
"Since ∇L2 depends on A and B, and A,B interact with all relations, they promote indirect parameter sharing between different relation matrices.",3 Joint Training with an Autoencoder,[0],[0]
"In Sec.6.2, we further show that joint training drives relations toward a low dimension manifold.",3 Joint Training with an Autoencoder,[0],[0]
Joint training with an autoencoder is not simple.,4 Optimization Tricks,[0],[0]
"Relation matrices receive updates from both∇L1 and ∇L2, but if they update ∇L1 too much, the autoencoder has no effect; conversely, if they update∇L2 too often, all relation matrices crush into one cluster.",4 Optimization Tricks,[0],[0]
"Furthermore, an autoencoder should learn from genuine patterns of relation matrices that emerge from fitting the KB, but not the reverse – in which the autoencoder imposes arbitrary patterns to relation matrices according to random initialization.",4 Optimization Tricks,[0],[0]
"Therefore, it is not surprising that a naive optimization of L1 + L2 does not work.
",4 Optimization Tricks,[0],[0]
"After extensive pre-experiments, we have found some crucial settings for successful training.",4 Optimization Tricks,[0],[0]
"The
most important “magic” is the scaling factor 1√ dc in definition of the similarity function (3), perhaps being combined with other settings as we discuss below.",4 Optimization Tricks,[0],[0]
"We have tried different factors 1, 1√
d , 1√ c
and 1dc instead, with various combinations of d and c; but the autoencoder failed to learn meaningful codings in other settings.",4 Optimization Tricks,[0],[0]
"When the scaling factor is too small (e.g. 1dc ), all relations get almost the same coding; conversely if the factor is too large (e.g. 1), all codings get very close to 0.
",4 Optimization Tricks,[0],[0]
The next important rule is to keep a balance between the updates coming from∇L1 and∇L2.,4 Optimization Tricks,[0],[0]
"We use Stochastic Gradient Descent (SGD) for optimization, and the common practice (Bottou, 2012) is to set the learning rate as
α(τ) := η
1 + ηλτ .",4 Optimization Tricks,[0],[0]
"(4)
Here, η, λ are hyper-parameters and τ is a counter of processed data points.",4 Optimization Tricks,[0],[0]
"In this work, in order to control the updates in detail to keep a balance, we modify (4) to use a a step counter τr for each relation r, counting “number of updates” instead of data points2.",4 Optimization Tricks,[0],[0]
"That is, whenever Mr gets a nonzero update from a gradient calculation, τr increases by 1.",4 Optimization Tricks,[0],[0]
"Furthermore, we use different hyper-parameters for different “types of updates”, namely η1, λ1 for updates coming from∇L1, and η2, λ2 for updates coming from ∇L2.",4 Optimization Tricks,[0],[0]
"Thus, let ∆1 be the partial gradient of ∇L1, and ∆2 the partial gradient of ∇L2, we update Mr by α1(τr)∆1 + α2(τr)∆2 at each step, where
α1(τr) := η1
1 + η1λ1τr , α2(τr) :",4 Optimization Tricks,[0],[0]
"= η2 1 + η2λ2τr .
",4 Optimization Tricks,[0],[0]
"The rule for setting η1, λ1 and η2, λ2 is that, η2 should be much smaller than η1, because η1, η2 control the magnitude of learning rates at the early stage of training, with the autoencoder still largely random and ∆2 not making much sense; on the other hand, one has to choose λ1 and λ2 such that ‖∆1‖/λ1 and ‖∆2‖/λ2 are at the same scale, because the learning rates approach 1/(λ1τr) and 1/(λ2τr) respectively, as the training proceeds.",4 Optimization Tricks,[0],[0]
"In this way, the autoencoder will not impose random patterns to relation matrices according to its initialization at the early stage, and a balance is kept between α1(τr)∆1 and α2(τr)∆2 later.
",4 Optimization Tricks,[0],[0]
But how to estimate ‖∆1‖ and ‖∆2‖?,4 Optimization Tricks,[0],[0]
"It seems that we can approximately calculate their scales
2Similarly, we set separate step counters for all head and tail entities, and the autoencoder as well.
from initialization.",4 Optimization Tricks,[0],[0]
"In this work, we use i.i.d.",4 Optimization Tricks,[0],[0]
"Gaussians of variance 1/d to initialize parameters, so the initial Euclidean norms are ‖uh‖",4 Optimization Tricks,[0],[0]
"≈ 1, ‖vt‖ ≈ 1, ‖Mr‖ ≈ √ d, and ‖BAmr‖ ≈ √ dc",4 Optimization Tricks,[0],[0]
.,4 Optimization Tricks,[0],[0]
"Thus, by calculating ∇L1 and ∇L2 using (1) and (3), we have approximately
‖∆1‖ ≈ ‖uhv>t ‖",4 Optimization Tricks,[0],[0]
"≈ 1, and
‖∆2‖ ≈ ‖ 1√ dc Bcr‖",4 Optimization Tricks,[0],[0]
≈ 1√ dc ‖BAmr‖,4 Optimization Tricks,[0],[0]
"≈ 1.
",4 Optimization Tricks,[0],[0]
"It suggests that, because of the scaling factor 1√ dc in (3), we have ‖∆1‖ and ‖∆2‖ at the same scale, so we can set λ1 = λ2.",4 Optimization Tricks,[0],[0]
This might not be a mere coincidence.,4 Optimization Tricks,[0],[0]
"Besides the tricks for joint training, we also found settings that significantly improve the base model on KBC, as briefly discussed below.",4.1 Training the Base Model,[0],[0]
"In Sec.6.3, we will show performance gains by these settings using the FB15k-237 validation set.
",4.1 Training the Base Model,[0],[0]
Normalization It is better to normalize relation matrices to ‖Mr‖ = √ d,4.1 Training the Base Model,[0],[0]
during training.,4.1 Training the Base Model,[0],[0]
"This might reduce fluctuations in entity vector updates.
",4.1 Training the Base Model,[0],[0]
Regularizer It is better to minimize ‖M>r Mr− 1 d tr(M > r Mr)I‖ during training.,4.1 Training the Base Model,[0],[0]
"This regularizer drives Mr toward an orthogonal matrix (Tian et al., 2016) and might reduce fluctuations in entity vector updates.",4.1 Training the Base Model,[0],[0]
"As a result, all relation matrices trained in this work are very close to orthogonal.
",4.1 Training the Base Model,[0],[0]
"Initialization Instead of pure Gaussian, it is better to initialize matrices as (I + G)/2, where G is random.",4.1 Training the Base Model,[0],[0]
"The identity matrix I helps passing information from head to tail (Tian et al., 2016).
",4.1 Training the Base Model,[0],[0]
"Negative Sampling Instead of a unigram distribution, it is better to use a uniform distribution for generating noises.",4.1 Training the Base Model,[0],[0]
This is somehow counterintuitive compared to training word embeddings.,4.1 Training the Base Model,[0],[0]
"KBs have a wide range of applications (Berant et al., 2013; Hixon et al., 2015; Nickel et al., 2016a) and KBC has inspired a huge amount of research (Bordes et al., 2013; Riedel et al., 2013; Socher et al., 2013; Wang et al., 2014b,a; Xiao et al., 2016; Nguyen et al., 2016; Toutanova et al., 2016; Das et al., 2017; Hayashi and Shimbo, 2017).
",5 Related Works,[0],[0]
"Among the previous works, TransE (Bordes et al., 2013) is the classic method which represents a relation as a translation of the entity vector space, and is partially inspired by Mikolov et al. (2013)’s vector arithmetic method of solving word analogy tasks.",5 Related Works,[0],[0]
"Although competitive in KBC, it is speculated that this method is well-suited for 1- to-1 relations but might be too simple to represent N -to-N relations accurately(Wang et al., 2017).",5 Related Works,[0],[0]
"Thus, extensions such as TransR (Lin et al., 2015b) and STransE (Nguyen et al., 2016) are proposed to map entities into a relation-specific vector space before translation.",5 Related Works,[0],[0]
"The ITransF model (Xie et al., 2017) further enhances this approach by imposing a hard constraint that the relation-specific maps should be linear combinations of a small number of prototypical matrices.",5 Related Works,[0],[0]
"Our work inherits the same motivation with ITransF in terms of promoting parameter-sharing among relations.
",5 Related Works,[0],[0]
"On the other hand, the base model used in this work originates from RESCAL (Nickel et al., 2011), in which relations are naturally represented as analogue to the adjacency matrices (Sec.2).",5 Related Works,[0],[0]
"Further developments include HolE (Nickel et al., 2016b) and ConvE (Dettmers et al., 2018) which improve this approach in terms of parameterefficiency, by introducing low dimension factorizations of the matrices.",5 Related Works,[0],[0]
"We inherit the basic model of RESCAL but draw additional training techniques from Tian et al. (2016), and show that the base model already can achieve near state-of-the-art performance (Sec.6.1,6.3).",5 Related Works,[0],[0]
"This sends a message similar to Kadlec et al. (2017), saying that training tricks might be as important as model designs.
",5 Related Works,[0],[0]
"Nevertheless, we emphasize the novelty of this work in that the previous models mostly achieve dimension reduction by imposing some pre-designed hard constraints (Bordes et al., 2013; Yang et al., 2015; Trouillon et al., 2016; Nickel et al., 2016b; Xie et al., 2017; Dettmers et al., 2018), whereas the constraints themselves are not learned from data; in contrast, our approach by jointly training an autoencoder does not impose any explicit hard constraints, so it leads to more flexible modeling.
",5 Related Works,[0],[0]
"Moreover, we additionally focus on leveraging composition in KBC.",5 Related Works,[0],[0]
"Although this idea has been frequently explored before (Guu et al., 2015; Neelakantan et al., 2015; Lin et al., 2015a), our discussion about the concept of compositional constraints and its connection to dimension reduction has not been addressed similarly in previous research.",5 Related Works,[0],[0]
"In
experiments, we will show (Sec.6.2,6.3) that joint training with an autoencoder indeed helps finding compositional constraints and benefits from compositional training.
",5 Related Works,[0],[0]
"Autoencoders have been used solo for learning distributed representations of syntactic trees (Socher et al., 2011), words and images (Silberer and Lapata, 2014), or semantic roles (Titov and Khoddam, 2015).",5 Related Works,[0],[0]
"It is also used for pretraining other deep neural networks (Erhan et al., 2010).",5 Related Works,[0],[0]
"However, when combined with other models, the learning of autoencoders, or more generally sparse codings (Rubinstein et al., 2010), is usually conveyed in an alternating manner, fixing one part of the model while optimizing the other, such as in Xie et al. (2017).",5 Related Works,[0],[0]
"To our knowledge, joint training with an autoencoder is not widely used previously for reducing dimensionality.
",5 Related Works,[0],[0]
Jointly training an autoencoder is not simple because it takes non-stationary inputs.,5 Related Works,[0],[0]
"In this work, we modified SGD so that it shares traits with some modern optimization algorithms such as Adagrad (Duchi et al., 2011), in that they both set different learning rates for different parameters.",5 Related Works,[0],[0]
"While Adagrad sets them adaptively by keeping track of gradients for all parameters, our modification of SGD is more efficient and allows us to grasp a rough intuition about which parameter gets how much update.",5 Related Works,[0],[0]
We believe our techniques and findings in joint training with an autoencoder could be helpful to reducing dimensionality and improving interpretability in other neural network architectures as well.,5 Related Works,[0],[0]
"We evaluate on standard KBC datasets, including WN18 and FB15k (Bordes et al., 2013), WN18RR (Dettmers et al., 2018) and FB15k-237 (Toutanova and Chen, 2015).",6 Experiments,[0],[0]
"The statistical information of these datasets are shown in Table 1.
",6 Experiments,[0],[0]
"WN18 collects word relations from WordNet (Miller, 1995), and FB15k is taken from Freebase (Bollacker et al., 2008); both have filtered out low frequency entities.",6 Experiments,[0],[0]
"However, it is reported in Toutanova and Chen (2015) that both WN18 and FB15k have information leaks because the inverses of some test triples appear in the training set.",6 Experiments,[0],[0]
FB15k-237 and WN18RR fix this problem by deleting such triples from training and test data.,6 Experiments,[0],[0]
"In this work, we do evaluate on WN18 and FB15k, but our models are mainly tuned on FB15k-237.
",6 Experiments,[0],[0]
"For all datasets, we set the dimension d = 256 and c = 16, the SGD hyper-parameters η1 = 1/64, η2 = 2
−14 and λ1 = λ2 = 2−14.",6 Experiments,[0],[0]
The training batch size is 32 and the triples in each batch share the same head entity.,6 Experiments,[0],[0]
"We compare the base model (BASE) to our joint training with an autoencoder model (JOINT), and the base model with compositional training (BASE+COMP) to our joint model with compositional training (JOINT+COMP).",6 Experiments,[0],[0]
"When compositional training is enabled (BASE+COMP, JOINT+COMP), we use random walk to sample paths of length 1 + X , where X is drawn from a Poisson distribution of mean λ = 1.0.
",6 Experiments,[0],[0]
"For any incomplete triple 〈h, r, ?〉 in KBC test, we calculate a score s(h, r, e) from (1), for every entity e ∈ E such that 〈h, r, e〉 does not appear in any of the training, validation, or test sets (Bordes et al., 2013).",6 Experiments,[0],[0]
"Then, the calculated scores together with s(h, r, t) for the gold triple is converted to ranks, and the rank of the gold entity t is used for evaluation.",6 Experiments,[0],[0]
"Evaluation metrics include Mean Rank (MR), Mean Reciprocal Rank (MRR), and Hits at 10 (H10).",6 Experiments,[0],[0]
"Lower MR, higher MRR, and higher H10 indicate better performance.
",6 Experiments,[0],[0]
We consult MR and MRR on validation sets to determine training epochs; we stop training when both MR and MRR have stopped improving.,6 Experiments,[0],[0]
The results are shown in Table 2.,6.1 KBC Results,[0],[0]
"We found that joint training with an autoencoder mostly improves performance, and the improvement becomes more clear when compositional training is enabled (i.e., JOINT ≥ BASE and JOINT+COMP > BASE+COMP).",6.1 KBC Results,[0],[0]
"This is convincing because generally, joint training contributes with its regularizing effects, and drastic improvements are less expected3.",6.1 KBC Results,[0],[0]
"When compositional training is enabled,
3The source code and trained models are publicly released at https://github.com/tianran/glimvec, where
the system usually achieves better MR, though not always improves in other measures.",6.1 KBC Results,[0],[0]
"The performance gains are more obvious on the WN18RR and FB15k-237 datasets, possibly because WN18 and FB15k contain a lot of easy instances that can be solved by a simple rule (Dettmers et al., 2018).
",6.1 KBC Results,[0],[0]
"Furthermore, the numbers demonstrated by our joint and base models are among the strongest in the literature.",6.1 KBC Results,[0],[0]
"We have conducted re-experiments of several representative algorithms, and also compare with state-of-the-art published results.",6.1 KBC Results,[0],[0]
"For re-experiments, we use Lin et al. (2015b)’s implementation4 of TransE (Bordes et al., 2013) and TransR, which represent relations as vector translations; and Nickel et al. (2016b)’s implementation5 of RESCAL (Nickel et al., 2011) and HolE, where RESCAL is most similar to the BASE model and HolE is a more parameter-efficient variant.",6.1 KBC Results,[0],[0]
"We experimented with the default settings, and found that our models outperform most of them.
",6.1 KBC Results,[0],[0]
"Among the published results, STransE (Nguyen et al., 2016) and ITransF (Xie et al., 2017) are more complicated versions of TransR, achieving the previous highest MR on WN18 but are outperformed by our JOINT+COMP model.",6.1 KBC Results,[0],[0]
ITransF is most similar to our JOINT model in that they both learn sparse codings for relations.,6.1 KBC Results,[0],[0]
"On WN18RR and FB15k237, Dettmers et al. (2018)’s report of ComplEx
we also show the mean performance and deviations of multiple random initializations, to give a more complete picture.
",6.1 KBC Results,[0],[0]
"4https://github.com/thunlp/KB2E 5https://github.com/mnick/
holographic-embeddings
(Trouillon et al., 2016) and ConvE were previously the best results.",6.1 KBC Results,[0],[0]
Our models mostly outperform them.,6.1 KBC Results,[0],[0]
"Other results include Kadlec et al. (2017)’s simple but strong baseline and several recent models (Schlichtkrull et al., 2017; Shi and Weninger, 2017; Shen et al., 2017) which achieve best results on FB15k or WN18 in some measure.",6.1 KBC Results,[0],[0]
Our models have comparable results.,6.1 KBC Results,[0],[0]
What does the autoencoder look like?,6.2 Intuition and Insight,[0],[0]
How does joint training affect relation matrices?,6.2 Intuition and Insight,[0],[0]
"We address these questions by analyses showing that (i) the autoencoder learns sparse and interpretable codings of relations, (ii) the joint training drives relation matrices toward a low dimension manifold, and (iii) it helps discovering compositional constraints.
",6.2 Intuition and Insight,[0],[0]
"Sparse Coding and Interpretability Due to the ReLU function in (2), our autoencoder learns sparse coding, with most relations having large code values at only two or three dimensions.",6.2 Intuition and Insight,[0],[0]
This sparsity makes it easy to find patterns in the model that to some extent explain the semantics of relations.,6.2 Intuition and Insight,[0],[0]
"Figure 2 shows some examples.
",6.2 Intuition and Insight,[0],[0]
"In the first group of Figure 2, we show a small number of relations that are almost always assigned a near one-hot coding, regardless of initialization.",6.2 Intuition and Insight,[0],[0]
"These are high frequency relations joining two large categories (e.g. film and language), which
probably constitute the skeleton of a KB.",6.2 Intuition and Insight,[0],[0]
"In the second group, we found the 12th dimension strongly correlates with currency; and in the third group, we found the 4th dimension strongly correlates with film.",6.2 Intuition and Insight,[0],[0]
"As for the relation currency of film budget, it has large code values at both dimensions.",6.2 Intuition and Insight,[0],[0]
This kind of relation clustering also seems independent of initialization.,6.2 Intuition and Insight,[0],[0]
"Intuitively, it shows that the autoencoder may discover similarities between relations and promote indirect parameter sharing among them.",6.2 Intuition and Insight,[0],[0]
"Yet, as the autoencoder only reconstructs approximations of relation matrices but never constrain them to be exactly equal to the original, relation matrices with very similar codings may still differ considerably.",6.2 Intuition and Insight,[0],[0]
"For example, producer of film and writer of film have codings of cosine similarity 0.973, but their relation matrices only have6 a cosine similarity 0.338.
",6.2 Intuition and Insight,[0],[0]
"Low dimension manifold
In order to visualize the relation matrices learned by our joint and base models, we use UMAP7 (McInnes and Healy, 2018) to embed Mr into a 2D plane8.",6.2 Intuition and Insight,[0],[0]
"We use relation matrices trained on
6Cosine similarity 0.338 is still high for matrices, due to the high dimensionality of their parameter space.
",6.2 Intuition and Insight,[0],[0]
7https://github.com/lmcinnes/umap 8UMAP is a recently proposed manifold learning algorithm based on the fuzzy topological structure.,6.2 Intuition and Insight,[0],[0]
"We also tried
FB15k-237, and compare models trained by the same number of epochs.",6.2 Intuition and Insight,[0],[0]
"The results are shown in Figure 3.
",6.2 Intuition and Insight,[0],[0]
"We can see that Figure 3a and Figure 3c are mostly similar, with high frequency relations scattered randomly around a low frequency cluster, suggesting that they come from various directions of a high dimension space, with frequent relations probably being pulled further by the training updates.",6.2 Intuition and Insight,[0],[0]
"On the other hand, in Figure 3b and Figure 3d we found less frequent relations being clustered with frequent ones, and multiple traces of low dimension structures.",6.2 Intuition and Insight,[0],[0]
It suggests that joint training with an autoencoder indeed drives relations toward a low dimension manifold.,6.2 Intuition and Insight,[0],[0]
"In addition, Figure 3d shows different structures against Figure 3b, which we conjecture could be related to compositional constraints discovered by compositional training.
",6.2 Intuition and Insight,[0],[0]
"Compositional constraints In order to directly evaluate a model’s ability to find compositional constraints, we extracted from FB15k-237 a list of (r1/r2, r3) pairs such that r1/r2 matches r3.",6.2 Intuition and Insight,[0],[0]
"Formally, the list is constructed as below.",6.2 Intuition and Insight,[0],[0]
"For any relation r, we define a content set C(r) as the set of (h, t) pairs such that 〈h, r, t〉 is a fact in the KB.",6.2 Intuition and Insight,[0],[0]
"Similarly, we define C(r1/r2)
t-SNE (van der Maaten and Hinton, 2008) but found UMAP more insightful.
",6.2 Intuition and Insight,[0],[0]
"as the set of (h, t) pairs such that 〈h, r1/r2, t〉 is a path.",6.2 Intuition and Insight,[0],[0]
"We regard (r1/r2, r3) as a compositional constraint if their content sets are similar; that is, if |C(r1/r2) ∩",6.2 Intuition and Insight,[0],[0]
C(r3)| ≥ 50 and the Jaccard similarity between C(r1/r2) and C(r3) is ≥ 0.4.,6.2 Intuition and Insight,[0],[0]
"Then, after filtering out degenerated cases such as r1 = r3 or r2 = r−11 , we obtained a list of 154 compositional constraints, e.g. (currency of country/country of film, currency of film budget).
",6.2 Intuition and Insight,[0],[0]
"For each compositional constraint (r1/r2, r3) in the list, we take the matrices M1, M2 and M3 corresponding to r1, r2 and r3 respectively, and rank M3 according to its cosine similarity with M1M2, among all relation matrices.",6.2 Intuition and Insight,[0],[0]
"Then, we calculate MR and MRR for evaluation.",6.2 Intuition and Insight,[0],[0]
"We compare the JOINT+COMP model to BASE+COMP, as well as a randomized baseline where M2 is selected randomly from the relation matrices in JOINT+COMP instead (RANDOMM2).",6.2 Intuition and Insight,[0],[0]
The results are shown in Table 3.,6.2 Intuition and Insight,[0],[0]
"We have evaluated 5 different random initializations for each model, trained by the same number of epochs, and we report the mean and standard deviation.",6.2 Intuition and Insight,[0],[0]
"We verify that JOINT+COMP performs better than BASE+COMP, indicating that joint training with an autoencoder indeed helps discovering compositional constraints.",6.2 Intuition and Insight,[0],[0]
"Furthermore, the random baseline RANDOMM2 tests a hypothesis that joint training might be just clustering M3 and M1 here, to the extent that M3 and M1 are so close that even a random M2 can give the correct answer; but as it turns out, JOINT+COMP largely outperforms RANDOMM2, excluding this possibility.",6.2 Intuition and Insight,[0],[0]
"Thus, joint training performs better not simply because it clusters relation matrices; it learns compositions indeed.",6.2 Intuition and Insight,[0],[0]
"In the KBC task, where are the losses and what are the gains of different settings?",6.3 Losses and Gains,[0],[0]
"With additional evaluations, we show (i) some crucial settings for the base model, and (ii) joint training with an autoencoder benefits more from compositional training.
",6.3 Losses and Gains,[0],[0]
Crucial settings for the base model It is noteworthy that our base model already achieves strong results.,6.3 Losses and Gains,[0],[0]
This is due to several detailed but crucial settings as we discussed in Sec.4.1; Table 4 shows their gains on the FB15k237 validation data.,6.3 Losses and Gains,[0],[0]
"The most dramatic improvement comes from the regularizer that drives matrices to orthogonal.
",6.3 Losses and Gains,[0],[0]
"Gains with compositional training One can force a model to focus more on (longer) compositions of relations, by sampling longer paths in compositional training.",6.3 Losses and Gains,[0],[0]
"Since joint training with an autoencoder helps discovering compositional constraints, we expect it to be more helpful when the sampled paths are longer.",6.3 Losses and Gains,[0],[0]
"In this work, path lengths are sampled from a Poisson distribution, we thus vary the mean λ of the Poisson to control the strength of compositional training.",6.3 Losses and Gains,[0],[0]
"The results on FB15k-237 are shown in Table 5.
",6.3 Losses and Gains,[0],[0]
"We can see that, as λ gets larger, MR improves much but MRR slightly drops.",6.3 Losses and Gains,[0],[0]
"It suggests that in FB15k-237, composition of relations might mainly help finding more appropriate candidates for a missing entity, rather than pinpointing a correct one.",6.3 Losses and Gains,[0],[0]
"Yet, joint training improves base models even more as the paths get longer, especially in MR.",6.3 Losses and Gains,[0],[0]
It further supports our conjecture that joint training with an autoencoder may strongly interact with compositional training.,6.3 Losses and Gains,[0],[0]
We have investigated a dimension reduction technique which trains a KB embedding model jointly with an autoencoder.,7 Conclusion,[0],[0]
We have developed new training techniques and achieved state-of-the-art results on several KBC tasks with strong improvements in Mean Rank.,7 Conclusion,[0],[0]
"Furthermore, we have shown that the autoencoder learns low dimension sparse codings that can be easily explained; the joint training technique drives high-dimensional data toward low
dimension manifolds; and the reduction of dimensionality may interact strongly with composition, help discovering compositional constraints and benefit from compositional training.",7 Conclusion,[0],[0]
We believe these findings provide insightful understandings of KB embedding models and might be applied to other neural networks beyond the KBC task.,7 Conclusion,[0],[0]
"This work was supported by JST CREST Grant Number JPMJCR1301, Japan.",Acknowledgments,[0],[0]
"We thank Pontus Stenetorp, Makoto Miwa, and the anonymous reviewers for many helpful advices and comments.",Acknowledgments,[0],[0]
"Occasionally, a KBC test set may contain entities that never appear in the training data.",A Out-of-vocabulary Entities in KBC,[0],[0]
"Such out-ofvocabulary (OOV) entities pose a challenge to KBC systems; while some systems address this issue by explicitly learn an OOV entity vector (Dettmers et al., 2018), our approach is described below.",A Out-of-vocabulary Entities in KBC,[0],[0]
"For an incomplete triple 〈h, r, ?〉 in the test, if h is OOV, we replace it with the most frequent entity that has ever appeared as a head of relation r in the training data.",A Out-of-vocabulary Entities in KBC,[0],[0]
"If the gold tail entity is OOV, we use the zero vector for computing the score and the rank of the gold entity.
",A Out-of-vocabulary Entities in KBC,[0],[0]
"Usually, OOV entities are rare and negligible in evaluation; except for the WN18RR test data which contains about 6.7% triples with OOV entities.",A Out-of-vocabulary Entities in KBC,[0],[0]
"Here, we also report adjusted scores on WN18RR in the setting that all triples with OOV entities are removed from the test.",A Out-of-vocabulary Entities in KBC,[0],[0]
The results are shown in Table 6.,A Out-of-vocabulary Entities in KBC,[0],[0]
Embedding models for entities and relations are extremely useful for recovering missing facts in a knowledge base.,abstractText,[0],[0]
"Intuitively, a relation can be modeled by a matrix mapping entity vectors.",abstractText,[0],[0]
"However, relations reside on low dimension sub-manifolds in the parameter space of arbitrary matrices – for one reason, composition of two relations M1,M2 may match a third M3 (e.g. composition of relations currency of country and country of film usually matches currency of film budget), which imposes compositional constraints to be satisfied by the parameters (i.e. M1 ·M2 ≈ M3).",abstractText,[0],[0]
"In this paper we investigate a dimension reduction technique by training relations jointly with an autoencoder, which is expected to better capture compositional constraints.",abstractText,[0],[0]
"We achieve state-of-the-art on Knowledge Base Completion tasks with strongly improved Mean Rank, and show that joint training with an autoencoder leads to interpretable sparse codings of relations, helps discovering compositional constraints and benefits from compositional training.",abstractText,[0],[0]
Our source code is released at github.com/tianran/glimvec.,abstractText,[0],[0]
Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1854–1864 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Previous work has brought up multiple legal assistant systems with various functions, such as finding relevant cases given the query (Chen et al., 2013), providing applicable law articles for a given case (Liu and Liao, 2005) and etc., which have substantially improved the working efficiency.",1 Introduction,[0],[0]
"As legal assistant systems, charge prediction systems aim to determine appropriate charges such as homicide and assault for varied criminal cases by analyzing textual fact descriptions from cases (Luo et al., 2017), but ignore to give out the interpretations for the charge determination.
",1 Introduction,[0],[0]
"Court view is the written explanation from judges to interprete the charge decision for certain criminal case and is also the core part in a legal document, which consists of rationales and a
∗ indicates equal contribution.",1 Introduction,[0],[0]
†,1 Introduction,[0],[0]
"Corresponding author.
",1 Introduction,[0],[0]
"1Data and codes are available at https://github. com/oceanypt/Court-View-Gen.
charge where the charge is supported by the rationales as shown in Fig. 1.",1 Introduction,[0],[0]
"In this work, we propose to study the problem of COURT VIEW",1 Introduction,[0],[0]
"GENeration from fact descriptions in cases, and we formulate it as a text-to-text natural language generation (NLG) problem (Gatt and Krahmer, 2017).",1 Introduction,[0],[0]
The input is the fact description in a case and the output is the corresponding court view.,1 Introduction,[0],[0]
"We only focus on generating rationales because charges can be decided by judges or charge prediction systems by also analyzing the fact descriptions (Luo et al., 2017; Lin et al., 2012).",1 Introduction,[0],[0]
"COURT-VIEW-GEN has beneficial functions, in that: (1) improve the interpretability of charge prediction systems by generating rationales in court views to support the predicted charges.",1 Introduction,[0],[0]
"The justification for charge decision is as important as deciding the charge itself (Hendricks et al., 2016; Lei et al., 2016).",1 Introduction,[0],[0]
"(2) benefit the automatic legal document generation as legal assistant systems, by automatically generating court views from fact descriptions, to release much human labor especially for simple cases but in large amount, where fact descriptions can be obtained from legal professionals or techniques such as information extraction (Cowie and Lehnert, 1996).
",1 Introduction,[0],[0]
COURT-VIEW-GEN is not a trivial task.,1 Introduction,[0],[0]
"Highquality rationales in court views should contain the important fact details such as the degree of injury for charge of intentional injury, as they are important basis for charge determination.",1 Introduction,[0],[0]
"Fact details are like the summary for the fact description similar to the task of DOCument SUMmarization (Yao et al., 2017).",1 Introduction,[0],[0]
"However, rationales are not the simple summary with only fact details, to support charges, they should be charge-discriminative with deduced information which does not appear in fact descriptions.",1 Introduction,[0],[0]
"The fact descriptions for charge of negligent homicide usually only describe someone being killed without direct statement about
1854
FACT DESCRIPTION ... 经审理查明, 2009年7月10日23时许,被告人陈某伙同八至九名男青年在徐闻县新寮镇建寮路口附近路上拦截住搭载着李某的摩托车,然后, 被告人陈某等人持钢管、刀对李某进行殴打。经法医鉴定,李某伤情为轻伤。...",1 Introduction,[0],[0]
# ...,1 Introduction,[0],[0]
"After hearing, our court identified that at 23:00 on July 10, 2009, the defendant Chen together with other eight or nine young men stopped Lee who was riding a motorcycle on street near the road in Xinliao town Xuwen County, after that the defendant Chen and the others beat Lee with steel pipe and knife.",1 Introduction,[0],[0]
"According to forensic identification, Lee suffered minor wound.",1 Introduction,[0],[0]
...,1 Introduction,[0],[0]
"COURT VIEW 本院认为, 被告人陈某无视国家法律,伙同他人,持器械故意伤害他人身体致一人轻伤 rationales, 其 行",1 Introduction,[0],[0]
为 已 构 成故意伤害罪 charge。#,1 Introduction,[0],[0]
Our court hold that the defendant Chen ignored the state law and caused others minor wound with equipment together with others rationales.,1 Introduction,[0],[0]
His acts constituted the crime of intentional assault charge.,1 Introduction,[0],[0]
"...
Table 1: An example of fact description and court view from a legal document for a case.
task.",1 Introduction,[0],[0]
"Firstly, it is hard to maintain the discriminations of generated court views when input fact descriptions are none-discriminative among charges in subtle difference.",1 Introduction,[0],[0]
"For example, the charges of intentional homicide and negligent homicide are similar and the corresponding fact descriptions will be expressed in similar way.",1 Introduction,[0],[0]
"Both of the fact descriptions of the two charges will describe the defendant killing someone but will not directly point out that the defendant is in intention or in neglect, causing it hard to generate chargediscriminative court views.",1 Introduction,[0],[0]
"Secondly, high-quality court views should contain the fact details in the fact descriptions such as the degree of injury for intentional injury charge because fact details are the important basis for charge determination.
",1 Introduction,[0],[0]
Traditional natural language generation (NLG) will need much human-labor to design rules and templates.,1 Introduction,[0],[0]
"To overcome the difficulties of COURT-VIEW-GEN mentioned above and the shortcomings of traditional NLG methods, in this work, we propose a novel label conditioned sequence to sequence model with attention for COURT-VIEW-GEN aiming to directly map fact descriptions to court views.",1 Introduction,[0],[0]
The architecture of our model is shown in Figure 1.,1 Introduction,[0],[0]
Fact descriptions are encoded into context vectors by an encoder then a decoder generates court views with these vectors.,1 Introduction,[0],[0]
"To generate more class-discriminative court views from none-discriminative fact descriptions among charges with subtle difference, we introduce to encode charges as the labels for the corresponding fact descriptions and decode the court views conditioned on the charge labels by additionally encoding the charge information.",1 Introduction,[0],[0]
The intuition lies in that charge labels will provide extra information to classify the non-discriminative fact descriptions and make the decoder learn to select words related to the charges to decode.,1 Introduction,[0],[0]
"To maintain the fact details from fact descriptions like the degree of injury for charge of intentional injury, we further apply the widely used
attention mechanism (?) into Seq2Seq model.",1 Introduction,[0],[0]
"By applying attention technic, every time context vectors will contain most important information from the fact descriptions for decoder.",1 Introduction,[0],[0]
"Experimental results show that our model has strong performance on COURT-VIEW-GEN and exploiting charge labels will significantly improve the class-discriminations of generated court views especially for charges with subtle differences.
",1 Introduction,[0],[0]
Our contributions of this paper can be summarized as follows: •We propose the task of court view generation which is meaningful but has bot been well studied before.,1 Introduction,[0],[0]
• We introduce a novel label conditioned sequence to sequence model with attention for COURT-VIEW-GEN.,1 Introduction,[0],[0]
"• Experimental results demonstrate the effectiveness of our model and exploiting charge labels will significantly improve the classdiscriminations of generated court views.
",1 Introduction,[0],[0]
"2 Related Work
Our work is firstly related to previous studies on legal assistant systems.",1 Introduction,[0],[0]
The task of charge prediction is to determine appropriate charges such as intentional homicide or intentional injury by analyzing the contents of fact descriptions.,1 Introduction,[0],[0]
Previous works regard the task of charge prediction as a text classification problem (????). ?,1 Introduction,[0],[0]
"adopt KNN to classify charges in Taiwan and recently, ?",1 Introduction,[0],[0]
propose an attention based deep learning model to scale the charge classes to a large number.,1 Introduction,[0],[0]
"Besides, researchers also introduce to identify applicable articles for a given case (???), answer legal questions as a consult system (??) and search relevant cases for a given query (??).",1 Introduction,[0],[0]
"As a legal assistant system, COURT-VIEW-GEN can benefit automatic legal document generation by generating the part of court views from fact descriptions obtained from the last phase if we generate legal document step by step.",1 Introduction,[0],[0]
"The fact descriptions can be constructed
Figure 1: An example of fact description and court i from a legal document in a case.
",1 Introduction,[0],[0]
"the motive for killing, DOC-SUM will only summarize the fact of someone being killed, but rationales have to further contain the killing intention, aiming to be discriminative from those rationales for other charges like intentional homicide.",1 Introduction,[0],[0]
"However, it is hard to generate charge-discriminative rationales when input fact descriptions are not distinct among other facts with different charges.",1 Introduction,[0],[0]
"The fact descriptions for charge of intentional homicide are similar to those for charge of negligent homicide and also describe someone being killed but without clear motive, making it hard to generate charge-discriminative court views with accurate killing motives among the two charges.
",1 Introduction,[0],[0]
"Recently, sequence-to-sequence model with encoder-decoder paradigm (Sutskever et al., 2014) has achieved cutting-edge results in many NLG tasks, such as paraphrase (Mallinson et al., 2017), code generation (Ling et al., 2016) and question generation (Du et al., 2017).",1 Introduction,[0],[0]
"Seq2Seq model has also exhibited state-of-the-art performances on task of DOC-SUM (Chopra et al., 2016; Tan et al., 2017).",1 Introduction,[0],[0]
"However, non-distinctions of fact descriptions render Seq2Seq mod hard to generate charge-discriminative rationales.",1 Introduction,[0],[0]
"I this paper, we explore ch rge labels of the corresponding fact descriptions, to benefit generating chargediscriminative rationales, where charge labels can be easily decided by human or charge prediction systems.",1 Introduction,[0],[0]
Charge labels will provide with extra information to classify the non-discriminative fact descriptions.,1 Introduction,[0],[0]
"We propose a label-conditioned Seq2Seq model with attention for our task, in which fact descriptions are encoded into context vectors by an encoder and a decoder generates rationales with these vectors.",1 Introduction,[0],[0]
"We further encode charges as the labels and decode the rationales conditioned on the labels, to entail the decoder to learn to select gold-charge-related words to decode.",1 Introduction,[0],[0]
"Widely used attention mechanism (Luong et al., 2015)",1 Introduction,[0],[0]
"i fused into the Seq2Seq model, learn t align target words to fact de ails in fact
descriptions.",1 Introduction,[0],[0]
"Similar to Luo et al. (2017), we evaluate our model on Chinese criminal cases by constructing dataset from Chinese government website.
",1 Introduction,[0],[0]
Our contributions in this paper can be summarized as follows: •We propose the task of court view generation and release a real-world dataset for this task.,1 Introduction,[0],[0]
• We formulate the task as a text-to-text NLG problem.,1 Introduction,[0],[0]
"We utilize charge labels to benefit charge-discriminative court views generation, and propose a label-conditioned sequence-to-sequence model with attention for this task.",1 Introduction,[0],[0]
• Extensive experiments are conducted on a real-world dataset.,1 Introduction,[0],[0]
The results show the efficiency of our model and exploiting charge labels for charge-discriminations improvement.,1 Introduction,[0],[0]
Our work is firstly related to previous studies on legal assistant systems.,2 Related Work,[0],[0]
"Previous work considers the task of charge prediction as a text classification problem (Luo et al., 2017; Liu et al., 2004; Liu and Hsieh, 2006; Lin et al., 2012).",2 Related Work,[0],[0]
"Recently, Luo et al. (2017) investigate deep learning methods for this task.",2 Related Work,[0],[0]
"Besides, there ar also works on identifying applicable articles for a given case (Liu and Liao, 2005; Liu and Hsieh, 2006; Liu et al., 2015), answering legal questions as a consulting system (Kim et al., 2014; Carvalho et al., 2015) and searching relevant cases for a given query (Raghav et al., 2016; Chen et al., 2013).",2 Related Work,[0],[0]
"As a legal assistant system, COURT-VIEW-GEN can benefit automatic legal document generation by generating court views from fact descriptions obtained from the last phase, through legal professionals or other technics like information extraction (Cowie and Lehnert, 1996) from raw documents in a case, if we generate legal documents step by step.
",2 Related Work,[0],[0]
"Our work is also related to recent studies on model interpretation (Ribeiro et al., 2016; Lipton, 2016; Ling t al., 2017).",2 Related Work,[0],[0]
"Recently, much work has
1855
paid attention to giving textual explanations for classifications.",2 Related Work,[0],[0]
Hendricks et al. (2016) generate visual explanations for image classification.,2 Related Work,[0],[0]
Lei et al. (2016) propose to learn to select most supportive snippets from raw texts for text classification.,2 Related Work,[0],[0]
"COURT-VIEW-GEN can improve the interpretability of charge prediction systems by generating textual court views when predict the charges.
",2 Related Work,[0],[0]
"Our label-conditioned Seq2Seq model steams from widely used encoder-decoder paradigm (Sutskever et al., 2014) which has been widely used in machine translation (Bahdanau et al., 2014; Luong et al., 2015), summarization (Tan et al., 2017; Nallapati et al., 2016; Chopra et al., 2016; Cheng and Lapata, 2016), semantic parsing (Dong and Lapata, 2016) and paraphrase (Mallinson et al., 2017) or other NLG problems such as product review generation (Dong et al., 2017) and code generation (Yin and Neubig, 2017; Ling et al., 2016).",2 Related Work,[0],[0]
Hendricks et al. (2016) propose to encode image labels for visual-language models to generate justification texts for image classification.,2 Related Work,[0],[0]
We also introduce charge labels into Seq2Seq model to improve the charge-discriminations of generated rationales.,2 Related Work,[0],[0]
"Widely used attention mechanism (Luong et al., 2015; Xu et al., 2015) is applied to generate fact details more accurately.",2 Related Work,[0],[0]
"Court View is the judicial explanation to interpret the reasons for the court making such charge for a case, consisting of the rationales and the charge supported by the rationales as shown in Fig. 1.",3 COURT-VIEW-GEN Problem,[0],[0]
"In this work, we only focus on generating the part of rationales in court views.",3 COURT-VIEW-GEN Problem,[0],[0]
"Charge prediction can be achieved by human or charge prediction systems (Luo et al., 2017).",3 COURT-VIEW-GEN Problem,[0],[0]
Final court views can be easily constructed by combining the generated rationales and the pre-decided charges.,3 COURT-VIEW-GEN Problem,[0],[0]
"Fact Description is the identified facts in a case (relevant events that have happened) such as the criminal acts (e.g. degree of injury).
",3 COURT-VIEW-GEN Problem,[0],[0]
The input of our model is the word sequential fact description in a case and the output is a word sequential court view (rationales part).,3 COURT-VIEW-GEN Problem,[0],[0]
"We define the fact description as x = (x1, x2, · · · , x|x|) and the corresponding rationales as y = (y1, y2, · · · , y|y|).",3 COURT-VIEW-GEN Problem,[0],[0]
The charge for the case is denoted as v and will be exploited for COURT-VIEW-GEN.,3 COURT-VIEW-GEN Problem,[0],[0]
"The task of COURT-VIEW-GEN is to find ŷ given x condi-
tioned on the charge label v:
ŷ",3 COURT-VIEW-GEN Problem,[0],[0]
"= argmax y
P (y|x, v) (1)
where P (y|x, v) is the likelihood of the predicted rationales in the court view.",3 COURT-VIEW-GEN Problem,[0],[0]
"Similar to Luong et al. (2015), our Seq2Seq model consists of an encoder and a decoder as shown in Fig. 2.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"Given the pair of fact description and rationales in court view (x, y), the encoder reads the word sequence of x and then the decoder will learn to predict the rationales in court view y.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"The probability of predicted y is given as follows:
P (y) =
|y|∏
i=1
P (yi|y<i, x) (2)
where y<i = y1, y2, · · · , yi−1.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"We use a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) as encoder and use another LSTM as decoder similar to Du et al. (2017).",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
Decoder.,4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"From the decoder side, at time t, the probability to predict yt is computed as follows:
P (yt|y<t, ct) = softmax(W1 tanh(W0[st; ct]))
where W0 and W1 are learnable parameters; st is the hidden state of decoder at time t; ct is the context vector generated from the encoder side containing the information of x at time t; here the bias of model is omitted for simplification.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"The hidden state of st is computed as follows:
st = LSTMd(yt−1, st−1)
where yt−1 is the word embedding vector for prestate target word at time t− 1.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"The initial state for decoder is initialized by the last state of encoder.
",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"Context vector of ct is computed by summing up the hidden states of {hk}|x|k=1 generated by the encoder with attention mechanism and we adopt global attention (Luong et al., 2015) in our work.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
Encoder with Attention.,4.1 Sequence-to-Sequence Model with Attention,[0],[0]
We adopt a one-layer bidirectional LSTM to encoder the fact descriptions.,4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"The hidden state hj at time j is computed as follows:
hj =",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"[ −→ hj ; ←− hj ]
where hj is the concatenation of forward hidden state −→ hj and backward hidden state ←− hj , specifically:
−→ hj = −−−−→ LSTMe(xj , −→ h j−1) ←− hj = ←−−−− LSTMe(xj , ←− h j+1)
",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"The hidden outputs {hk}|x|k=1 will be used to compute the context vectors for decoder.
",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"From the decoder side, by applying attention mechanism at time i, the context vector of ci is generated as follows:
ci =
|x|∑
j=1
αijhj (3)
where αij is the attention weight and is computed as follows:
αij = exp(sTi W2hj)∑|x| k=1 exp(s T i W2hk)
(4)
where si is the hidden output state at time i in the decoder side.",4.1 Sequence-to-Sequence Model with Attention,[0],[0]
"Given the tuple of fact description, rationales in court view and charge label (x, y, v), the probability to predict y is computed as follows:
P (y) =
|y|∏
i=1
P (yi|y<i, x, v) (5)
",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"From this formula, encoding charge labels provides extra constrains comparing to Eq.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"(2), and restricts the target word searching space from the whole space to only gold-charge-related space for rationales generation, so model can generate more charge-distinct rationales.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"Charge labels are trainable parameters denoted by Ev where every
charge will have a trainable vector from Ev, which will be updated in the model training process.
",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"As shown in Fig. 2, in the decoder side, at time t, yt is predicted with the probability as follows:
P (yt|y<t, ct, v) = softmax(W1 tanh(W0[st; ct;E v",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
[v]])),4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"(6)
where Ev[v] is the embedding vector of v obtained from Ev.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"In this formula, we connect charge label v to st and ct aiming to influence the word selection process.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"We hope that our model can learn the latent connections between the charge label v and the words of rationales in court views through this way, to decode out charge-discriminative words.
",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"As shown in Fig. 2, we further embed the charge label v to highlight the computing of hidden state st at time t and st is merged as follows:
st = LSTMd(yt−1, s v t−1)
",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"svt−1 = fv(st−1, v)
fv = tanh(W",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"v[st−1;Ev[v]] + b v) (7)
where Wv and bv are learnable parameters.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"In this way, the information of charge label can be embedded into st.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
From Eq.,4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"(3) and Eq. (4), attention weights ct are computed from st, so encoding the charge label v to hidden states will make the model concentrate more on charge-related information from fact descriptions to help generate more accurate fact details.",4.2 Label-conditioned Sequence-to-Sequence Model with Attention,[0],[0]
"Suppose we are given the training data: {x(i), y(i), v(i)}Ni=1, we aim to maximize the log-likelihood of generated rationales in court views given the fact descriptions and charge labels, so the loss function is computed as follows:
L(θ) =",4.3 Model Training and Inference,[0],[0]
"− N∑
i=1
logP (y(i)|x(i), v(i); θ)
=",4.3 Model Training and Inference,[0],[0]
"− N∑
i=1
|y(i)|∑
j=1
logP (y (i) j |y (i) <",4.3 Model Training and Inference,[0],[0]
"j , x (i), v(i); θ)
We split the training data into multiple batches with size of 64 and adopt adam learning (Kingma and Ba, 2014) to update the parameters in every batch data.",4.3 Model Training and Inference,[0],[0]
"At the inference time, we encode the fact descriptions and charge labels into vectors and use the decoder to generate rationales in
court views based on Eq.",4.3 Model Training and Inference,[0],[0]
(1).,4.3 Model Training and Inference,[0],[0]
We adopt the algorithm of beam search to generate rationales.,4.3 Model Training and Inference,[0],[0]
Beam search size is set to 5.,4.3 Model Training and Inference,[0],[0]
"To make generation process stoppable, an indicator tag “</s>” is added to the end of the rationales sequences, and when “</s>” is generated the inference process will be terminated.",4.3 Model Training and Inference,[0],[0]
The generated word sequential paths will be ranked and the one with largest value is selected as the final rationales in court view.,4.3 Model Training and Inference,[0],[0]
"Following Luo et al. (2017), we construct dataset from the published legal documents in China Judgements Online2.",5.1 Data Preparation,[0],[0]
"We extract the fact descriptions, rationales in court views and charge labels using regular expressions.",5.1 Data Preparation,[0],[0]
The paragraph started with “经审理查明” (“our court identified that”) is regarded as the fact description and the part between “本院认为” (“our court hold that”) and the charge are regarded as the rationales.,5.1 Data Preparation,[0],[0]
Nearly all the samples in dataset match this extraction pattern.,5.1 Data Preparation,[0],[0]
"Length threshold of 256 is set up, and fact description longer than that will be stripped, leaving too long facts for future study.",5.1 Data Preparation,[0],[0]
"We use the tokens of “<name>”, “<num>” and “<date>” to replace the names, numbers and dates appearing in the corpus.",5.1 Data Preparation,[0],[0]
We tokenize the Chinese texts with the open source tool of HanLP3.,5.1 Data Preparation,[0],[0]
"For charge labels, we select the top 50 charge labels ranked by occurrences and leave the left charges as others.",5.1 Data Preparation,[0],[0]
"Details about our dataset are shown in Table 1.
",5.1 Data Preparation,[0],[0]
"For cases with multiple charges and multiple defendants, we can separate the fact descriptions and the court views according to the charges or the defendants.",5.1 Data Preparation,[0],[0]
"In this work, we only focus on the cases with one defendant and one charge, leaving the complex cases for future study, so we can collect large enough data from the published legal
2http://wenshu.court.gov.cn 3https://github.com/hankcs/HanLP
documents without human to annotate the data.",5.1 Data Preparation,[0],[0]
"Word embeddings are randomly initialized and updated in the training process, with the size of 512 tuned from {256, 512, 1024}.",5.2 Experimental Settings,[0],[0]
Charge label vectors are initialized randomly with size of 512.,5.2 Experimental Settings,[0],[0]
Maximal vocabulary size of encoder is set to 100K words and decoder is 50K by stripping words exceeding the bounds.,5.2 Experimental Settings,[0],[0]
Maximal source length is 256 and target is 50.,5.2 Experimental Settings,[0],[0]
"The hidden size of LSTM is 1024 tuned from {256, 512, 1024}.",5.2 Experimental Settings,[0],[0]
We choose perplexity as the update metric.,5.2 Experimental Settings,[0],[0]
Early stopping mechanism is applied to train the model.,5.2 Experimental Settings,[0],[0]
The initial learning rate is set to 0.0003 and the reduce factor is 0.5.,5.2 Experimental Settings,[0],[0]
Model performance will be checked on the validation set after every 1000 batches training and keep the parameters with lowest perplexity.,5.2 Experimental Settings,[0],[0]
Training process will be terminated if model performance is not improved for successive 8 times.,5.2 Experimental Settings,[0],[0]
Evaluation Metrics.,5.3 Comparisons with Baselines,[0],[0]
We adopt both automatic evaluation and human judgement for model evaluation.,5.3 Comparisons with Baselines,[0],[0]
"BLEU-4 score (Papineni et al., 2002) and variant Rouge scores (Lin, 2004) are adopted for automatic evaluation which have been widely used in many NLG tasks.",5.3 Comparisons with Baselines,[0],[0]
"We set up two evaluation dimensions for human judgement: 1) how fluent of the rationales in court view is; 2) how accurate of the rationales is, aiming to evaluate how many fact details have been accurately expressed in the generated rationales.",5.3 Comparisons with Baselines,[0],[0]
We adopt 5 scales for both fluent and accurate evaluation (5 is for the best).,5.3 Comparisons with Baselines,[0],[0]
We ask three annotators who knows well about our task to conduct the human judgement.,5.3 Comparisons with Baselines,[0],[0]
We randomly select 100 generated rationales in court views for every evaluated method.,5.3 Comparisons with Baselines,[0],[0]
The three raters are also asked to judge whether rationales can be adopted for use in comprehensive evaluation (adoptable) and record the number of adoptable rationales for every evaluated method.,5.3 Comparisons with Baselines,[0],[0]
Baselines.,5.3 Comparisons with Baselines,[0],[0]
• Rand is to randomly select rationales in court views from the training set (method of Randall).,5.3 Comparisons with Baselines,[0],[0]
We also randomly choose rationales from pools with same charge labels (Randcharge).,5.3 Comparisons with Baselines,[0],[0]
Adopting Rand method is to indicate the low bound performance of COURT-VIEW-GEN. •,5.3 Comparisons with Baselines,[0],[0]
"BM25 is a retrieval baseline to index the fact description match to the input fact description with highest BM25 score (Robertson and Walker,
1994) from the training set, and use its rationales as the result (BM25f2f).",5.3 Comparisons with Baselines,[0],[0]
Similar fact descriptions may have the similar rationales.,5.3 Comparisons with Baselines,[0],[0]
"Fact descriptions from pools with same charges are also retrieved (BM25f2f+charge), to see how much improvement that adding charge labels can gender.",5.3 Comparisons with Baselines,[0],[0]
• MOSES+,5.3 Comparisons with Baselines,[0],[0]
"(Koehn et al., 2007) is a phrasebased statistical machine translation system mapping fact descriptions to rationales.",5.3 Comparisons with Baselines,[0],[0]
"KenLM (Heafield et al., 2013) is adopted to train a trigram language model on the target corpus of training set which is tuned on the validation set with MERT.",5.3 Comparisons with Baselines,[0],[0]
• NN-S2S is the basic Seq2Seq model without attention from Sutskever et al. (2014) for machine translation.,5.3 Comparisons with Baselines,[0],[0]
We set one LSTM layer for encoding and another one LSTM layer for decoding.,5.3 Comparisons with Baselines,[0],[0]
We adopt perplexity for training metric and select the model with lowest perplexity on validation set.,5.3 Comparisons with Baselines,[0],[0]
• RAS† is an attention based abstract summarization model from Chopra et al. (2016).,5.3 Comparisons with Baselines,[0],[0]
"To deal with the much longer fact descriptions, we exploit the more advanced bidirectional LSTM model for the encoder instead of the simple convolutional model.",5.3 Comparisons with Baselines,[0],[0]
Another LSTM model is set as the decoder coherent to Chopra et al. (2016).,5.3 Comparisons with Baselines,[0],[0]
Experimental Results.,5.3 Comparisons with Baselines,[0],[0]
"In automatic evaluation from Table 2, the evaluation scores are relatively high even for method of Randcharge, which indicates that the expressions of the rationales with same charge labels are similar with many over-
lapped n-grams, such that the rationales for crime of theft usually begin with “以非法占有为目的” (“in intention of illegal possession”).",5.3 Comparisons with Baselines,[0],[0]
Accurately generating fact details like degree of injury or time of theft is more difficult.,5.3 Comparisons with Baselines,[0],[0]
Retrieval method by adding charge labels is the strong baseline even better than basic Seq2Seq model.,5.3 Comparisons with Baselines,[0],[0]
Adding attention mechanism will improve the performance indicated by the method of RAS† which is superior to retrieval methods.,5.3 Comparisons with Baselines,[0],[0]
"By exploiting charge labels, our full model achieves the best performance.",5.3 Comparisons with Baselines,[0],[0]
"The performances of statistical machine translation model are really poor, for it requiring the lengths of parallel corpus to be similar.
",5.3 Comparisons with Baselines,[0],[0]
"In human evaluation, we can see that retrieval methods can not accurately express fact details, for that it is hard to retrieve rationales containing details all matching the fact descriptions.",5.3 Comparisons with Baselines,[0],[0]
"However, our system can learn to generate fact details by analyzing fact descriptions.",5.3 Comparisons with Baselines,[0],[0]
Dropping attention mechanism will have negative effects on model performance.,5.3 Comparisons with Baselines,[0],[0]
RAS† has worse performance in ACC.,5.3 Comparisons with Baselines,[0],[0]
"whose main reason may lie in that RAS† can not generate charge-discriminative rationales with deduced information, which demonstrates that our task is not the simple DOC-SUM task.",5.3 Comparisons with Baselines,[0],[0]
"For the fluent evaluation, generation models are highly close to retrieval methods whose rationales are written by humans, which reflects that the generation models can generate highly natural rationales.",5.3 Comparisons with Baselines,[0],[0]
Impact of Exploiting Charge Labels.,5.4 Further Analysis,[0],[0]
•,5.4 Further Analysis,[0],[0]
Charge2Charge Analysis.,5.4 Further Analysis,[0],[0]
"We first analyze the effects of exploiting charge labels on model performance charge to charge, by dropping to encode charges based on our full model.",5.4 Further Analysis,[0],[0]
"From the results shown in Fig. 3, we can find that the results can be improved much by exploiting charge labels among nearly all charges.",5.4 Further Analysis,[0],[0]
"This result also indicates that the non-distinct fact descriptions are common among nearly all charges and reflects the difficulty of this task, but utilizing charge labels can release the seriousness of the problem.",5.4 Further Analysis,[0],[0]
• Charge-discriminations Analysis.,5.4 Further Analysis,[0],[0]
"We further evaluate the effects of charge labels for charge-discriminations improvement on specific charges with non-distinct fact descriptions: intentional homicide, negligent homicide, duty embezzlement and corruption.",5.4 Further Analysis,[0],[0]
"For every charge, two participants are asked to count the number of ra-
tionales that are relevant to the charge on 20 randomly selected candidates.
",5.4 Further Analysis,[0],[0]
"From Fig. 4, the number of charge discriminative rationales can be much improved among every charge by utilizing charge information, which demonstrates that charge labels can provide with much extra charge-related information to deal with latent information in fact descriptions.",5.4 Further Analysis,[0],[0]
"For crimes of homicide, the motives for killing are latent in the descriptions of killing without direct statement, but our system can learn to align the motives in rationales to the charge labels which are the strong distinct indicator for the two motives.",5.4 Further Analysis,[0],[0]
Ablation Study.,5.4 Further Analysis,[0],[0]
We also ablate our full model to reveal different components of encoding charge labels for performance improvement.,5.4 Further Analysis,[0],[0]
"As shown in Table 3, “ / softmax comp.” is to remove the part in Eq.",5.4 Further Analysis,[0],[0]
"(6) and yields worse performance than our full model, but better than “ / charge comp.”",5.4 Further Analysis,[0],[0]
"that ignores to encode charge labels, which is same to the situation of “ / hidden comp.”",5.4 Further Analysis,[0],[0]
that removes the part in Eq.,5.4 Further Analysis,[0],[0]
(7).,5.4 Further Analysis,[0],[0]
Our full model is still better than the ablated models.,5.4 Further Analysis,[0],[0]
This finding shows that both of the methods of exploiting charge labels can improve model performance and stacking them will achieve better results.,5.4 Further Analysis,[0],[0]
Attention Mechanism Analysis.,5.4 Further Analysis,[0],[0]
Heat map in Fig. 5 is used to illustrate the attention mechanism.,5.4 Further Analysis,[0],[0]
The “slight injury” is aligned between the source and target.,5.4 Further Analysis,[0],[0]
"“responsibility” and “run” are well aligned to “away”, which demonstrate the
efficiency of attention mechanism for generating fact details by forcing context vectors to focus more on fact details.",5.4 Further Analysis,[0],[0]
Performance by Reference Size.,5.4 Further Analysis,[0],[0]
We further investigate the model performance by rationales length in court views.,5.4 Further Analysis,[0],[0]
"As shown in Fig. 6, not surprisingly the model performance drops when the length of reference rationales increases.",5.4 Further Analysis,[0],[0]
"Within the size of 30, BLEU-4 score can maintain around 0.4 and F1 score keeps around 0.5.",5.4 Further Analysis,[0],[0]
"Exceeding the length of 30, model performance decreases dramatically.",5.4 Further Analysis,[0],[0]
Human eval.,5.4 Further Analysis,[0],[0]
vs. Automatic eval.,5.4 Further Analysis,[0],[0]
Are BLEU and Rouge suitable for COURT-VIEW-GEN evaluation?,5.4 Further Analysis,[0],[0]
"Following the work of (Papineni et al., 2002; Liu et al., 2016), for the models evaluated in human judgemnet, we draw the linear regressions of their BLEU-4 and variant Rouge scores, as the function of ACC. and ADOPT.",5.4 Further Analysis,[0],[0]
from human judgement respectively as shown in Fig. 7.,5.4 Further Analysis,[0],[0]
"From
the results, we can find that automatic evaluations track well with the human judgement with high correlation coefficients.",5.4 Further Analysis,[0],[0]
This finding demonstrates that BLEU-4 and variant Rouges are adoptable for COURT-VIEW-GEN evaluation and provides the basis for future studies on this task.,5.4 Further Analysis,[0],[0]
Error Analysis.,5.4 Further Analysis,[0],[0]
"Our model has the drawback of generating latent fact details, which appear in rationales but are not clearly expressed in fact descriptions.",5.4 Further Analysis,[0],[0]
"For example, for the time of theft in charge of larceny, the term of “多次” (“several times”) appears in rationales but may not be expressed in fact descriptions directly, only with descriptions of larceny but without exact term for this detail, so it will be hard for attention mechanism to learn to align “多次” in rationales to latent information in fact descriptions.",5.4 Further Analysis,[0],[0]
"In the generated rationales on test set, we find that only 42.4% samples can accurately extract out the term of “多次”.",5.4 Further Analysis,[0],[0]
"It may need designed rules to deal with such details, like that count the time of theft from the descriptions, and if the time exceeds 1 then the term of “多次” can be generated in rationales.",5.4 Further Analysis,[0],[0]
Fake Charge Label Conditioned Study.,5.5 Analysis through Cases,[0],[0]
What generated rationales in court views will be if they are conditioned on fake charge labels?,5.5 Analysis through Cases,[0],[0]
"We select one fact description with gold charge of intentional injury, then generate rationales conditioned on fake charges of defiance and affray crime, intentional homicide and neglectful homicide.
",5.5 Analysis through Cases,[0],[0]
"From Fig. 8, the rationales conditioned on fake charges will be partly relevant to fake charge labels and also maintain fact details from the input fact description of gold charge.",5.5 Analysis through Cases,[0],[0]
"For the fake charge of intentional homicide, its fact details should be “caused someone dead”, but instead express “causing someone slight injury” which is relevant to charge of intentional injury.",5.5 Analysis through Cases,[0],[0]
"For charge prediction systems, the discriminations between fact details and charges will help to remind people that the prediction results may be unreliable.
",5.5 Analysis through Cases,[0],[0]
Case Study.,5.5 Analysis through Cases,[0],[0]
Examples of generated rationales in court views are shown in Fig. 8.,5.5 Analysis through Cases,[0],[0]
"Generally speaking, our full label-conditioned model has high accuracy on generating fact details better than baseline models.",5.5 Analysis through Cases,[0],[0]
"For charges of traffic accident crime and negligent homicide, all fact details are generated.",5.5 Analysis through Cases,[0],[0]
"The extra information from charge labels helps the model to capture more important fact details, by forcing model to pay more attention to charge-related information in fact descriptions.
",5.5 Analysis through Cases,[0],[0]
"As for the charge-discrimination analysis, from the rationales of negligent homicide, we can infer that its fact description may relate to a traffic accident, which is non-distinct from that for traffic accident crime.",5.5 Analysis through Cases,[0],[0]
"Without encoding charge labels, Ours / c wrongly generates the rationales coherent to traffic accident crime, because traffic accidents are the strong indicator for traffic crimes, but the charge label will provide extra bias towards the homicide crime, so our full model can generate highly discriminative rationales.",5.5 Analysis through Cases,[0],[0]
"Utilizing charge labels, retrieval method can easily retrieve chargerelated rationales, but hard to index rationales with accurate fact details.",5.5 Analysis through Cases,[0],[0]
"For charge of larceny, our full model extracts nearly all fact details but misses the fact of “多次”(“several times”), reflecting the shortcoming of dealing with latent details.",5.5 Analysis through Cases,[0],[0]
"In this paper, we propose a novel task of court view generation and formulate it as a text-to-text NLG problem.",6 Conclusion and Future Work,[0],[0]
We utilize charge labels to benefit the generation of charge-discriminative rationales in court views and propose a label-conditioned Seq2Seq model with attention for this task.,6 Conclusion and Future Work,[0],[0]
"Extensive experiments show the efficiency of our model and exploiting charge labels.
",6 Conclusion and Future Work,[0],[0]
"In the future: 1) More advanced technologies like reinforcement learning (Sutton and Barto, 1998) can be introduced to generate latent fact details such as the time of theft more accurately; 2) In this work, we only generate rationales in court views omitting charge prediction, it is interesting to see whether jointly generating the two parts will benefit both of the tasks; 3)",6 Conclusion and Future Work,[0],[0]
"Studying verification mechanism is meaningful to judge whether generated court views can really be adopted which is important for COURT-VIEW-GEN in practice; 4) More complex cases with multiple charges and multiple defendants will be considered in the future.
",6 Conclusion and Future Work,[0],[0]
MODEL [CHARGE] GENERATED COURT VIEWS CONDITIONED ON FAKE CHARGE LABEL Gold,6 Conclusion and Future Work,[0],[0]
[故意伤害罪] PP 故意伤害他人 身体，致一人轻伤,6 Conclusion and Future Work,[0],[0]
。#,6 Conclusion and Future Work,[0],[0]
"[intentional injury] PP intentionally injured others body , caused one people slight injury .
",6 Conclusion and Future Work,[0],[0]
"Ours
[寻衅滋事罪] PP 随意殴打他人 ，致一人轻伤 ，情节恶劣。#",6 Conclusion and Future Work,[0],[0]
"[defiance and affray crime] PP beat others at will , caused one people slight injury .",6 Conclusion and Future Work,[0],[0]
[故意杀人罪] PP 故意非法剥夺他人生命 ，,6 Conclusion and Future Work,[0],[0]
致一人轻伤,6 Conclusion and Future Work,[0],[0]
。#,6 Conclusion and Future Work,[0],[0]
"[intentional homicide] PP intentionally illegally deprived someone of life , caused one people slight injury .",6 Conclusion and Future Work,[0],[0]
[过失致人死亡罪] PP 过失 致一人轻伤,6 Conclusion and Future Work,[0],[0]
。#,6 Conclusion and Future Work,[0],[0]
"[neglectful homicide] PP neglectfully caused one people slight injury .
",6 Conclusion and Future Work,[0],[0]
MODEL,6 Conclusion and Future Work,[0],[0]
"[CHARGE] GENERATED COURT VIEWS
Gold
[交通肇事罪] PP 违反交通运输管理法规，造成一人死亡",6 Conclusion and Future Work,[0],[0]
，二人受伤 的交通事故，负事故的全部责任,6 Conclusion and Future Work,[0],[0]
。,6 Conclusion and Future Work,[0],[0]
#,6 Conclusion and Future Work,[0],[0]
"[traffic accident crime] PP violated traffic transportation management regulations , caused one people dead , two people injured , take accident’s full responsibility .",6 Conclusion and Future Work,[0],[0]
[过失致人死亡罪] PP 在驾驶机动车过程中，疏忽大意 ，致使他人被碾压致死 。#,6 Conclusion and Future Work,[0],[0]
"[negligent homicide] PP when driving car , being neglectful , caused people dead by rolling .",6 Conclusion and Future Work,[0],[0]
[盗窃罪] PP 以非法占有为目的，伙同他人 多次 秘密窃取公民财物，数额较大 。#,6 Conclusion and Future Work,[0],[0]
"[larceny] PP in intention of illegal possession , ganged up with others and stole goods secretly in relatively large amount for several times .
",6 Conclusion and Future Work,[0],[0]
"Ours
PP 违反交通运输管理法规，发生交通事故，致一人死亡",6 Conclusion and Future Work,[0],[0]
，二人受伤 ，负事故的全部责任 。 #,6 Conclusion and Future Work,[0],[0]
"PP violated traffic transportation management regulations , caused traffic accident , caused one people dead , two people injured , take accident’s full responsibility . """,6 Conclusion and Future Work,[0],[0]
PP 因疏忽大意 致一人死亡 。,6 Conclusion and Future Work,[0],[0]
#,6 Conclusion and Future Work,[0],[0]
"PP neglectfully caused one people dead . """,6 Conclusion and Future Work,[0],[0]
"PP 以非法占有为目的，结伙他人 秘密窃取他人财物，数额较大 。# PP in intention of illegal possession , ganged up with others and stole goods secretly in relatively large amount .",6 Conclusion and Future Work,[0],[0]
"%
Ours / c PP 违反交通运输管理法规，发生重大交通事故，致一人死亡 ，负事故的全部责任 。 #",6 Conclusion and Future Work,[0],[0]
"PP violated traffic transportation management regulations , caused severe traffic accident , caused one people dead , took accident’s full responsibility%",6 Conclusion and Future Work,[0],[0]
PP 违反交通运输管理法规，发生重大交通事故 ，致一人死亡，负事故的全部责任 。#,6 Conclusion and Future Work,[0],[0]
"PP violated traffic transportation management regulations , caused severe traffic accident , caused one people dead , took accident’s full responsibility .",6 Conclusion and Future Work,[0],[0]
%,6 Conclusion and Future Work,[0],[0]
"PP 以非法占有为目的，秘密窃取他人财物，数额较大 。# PP in intention of illegal possession , stole goods secretly in relatively large amount .",6 Conclusion and Future Work,[0],[0]
"%
BM25f2f+c PP 违反道路交通运输管理法规，致一人死亡 且负事故主要责任",6 Conclusion and Future Work,[0],[0]
。#,6 Conclusion and Future Work,[0],[0]
"PP violated road traffic transportation management regulations , caused one people dead , took accident’s main responsibility .",6 Conclusion and Future Work,[0],[0]
%,6 Conclusion and Future Work,[0],[0]
"PP 驾驶车辆过程中疏忽大意 ，过失 致一人死亡 。# PP when driving , neglectfully caused one people dead . """,6 Conclusion and Future Work,[0],[0]
"PP 以非法占有为目的，秘密窃取公民财物。# PP in intention of possession , stole goods secretly .",6 Conclusion and Future Work,[0],[0]
"%
Table 5:",6 Conclusion and Future Work,[0],[0]
"Examples of generated court views and fake charge label conditioned generated court views.
times”) which is important in penalty measurement.",6 Conclusion and Future Work,[0],[0]
"Actually, the time of larceny is not all directly expressed in fact description and only describes the fact of larceny, so it is hard for model to learn to align the time of larceny in court view to latent information in fact description.",6 Conclusion and Future Work,[0],[0]
Fake Charge Label Conditioned Study.,6 Conclusion and Future Work,[0],[0]
What generated court views will be if they are conditioned on fake charge labels?,6 Conclusion and Future Work,[0],[0]
"We select one fact description with gold charge label of intentional injury then generate court views conditioned on fake charge labels of defiance and affray crime, intentional homicide and neglectful homicide.",6 Conclusion and Future Work,[0],[0]
"From Table ??, the court views conditioned on fake charges will be class-discriminative relevant to the fake charge labels and also maintain fact details from the input fact description of gold charge.",6 Conclusion and Future Work,[0],[0]
"For the fake charge of intentional homicide, its corresponding fact will be “caused someone dead”, but instead express “causing someone slight injury” which is relevant to charge of intentional injury.",6 Conclusion and Future Work,[0],[0]
"The discriminations between fact details and charge will help to remind people that the prediction for charge may be unreliable.
6 Conclusion and Future Works
In this paper, we propose a meaningful but notwell studied task of court view generation.",6 Conclusion and Future Work,[0],[0]
We introduce a novel charge label conditioned sequence to sequence model for COURT-VIEW-GEN.,6 Conclusion and Future Work,[0],[0]
Experimental results show the effectiveness of our model.,6 Conclusion and Future Work,[0],[0]
"Generating court views conditioned
on charge labels by encoding charge labels will significantly improve the class-discriminations of generated court views.
",6 Conclusion and Future Work,[0],[0]
In the future: 1) We will apply the copy mechanism (??),6 Conclusion and Future Work,[0],[0]
"to improve the diversities and characteristics of generated court views which are important for generating high-quality court views; 2) More advanced technologies like reinforcement learning (?) will be introduced to generate latent fact details such as the time of theft more accurately; 3) In this work, we only generate rationales in court views omitting charge prediction, it is interesting to see whether jointly generating the two parts will benefit both of the tasks.",6 Conclusion and Future Work,[0],[0]
"Firstly, we would like to thank Yansong Feng, Yu Wu, Xiaojun Wan, Li Dong, Pengcheng Yin and Zichao Yan for their insightful comments and suggestions.",Acknowledgments,[0],[0]
We also very appreciate the comments from anonymous reviewers which will help further improve our work.,Acknowledgments,[0],[0]
This work is supported by National Natural Science Foundation of China (No. 61602490) and National Key R&D Plan (No. 2017YFB1402403).,Acknowledgments,[0],[0]
"The work was done when Hai Ye interned in Beihang University from August, 2017 to January, 2018.",Acknowledgments,[0],[0]
"In this paper, we propose to study the problem of COURT VIEW",abstractText,[0],[0]
GENeration from the fact description in a criminal case.,abstractText,[0],[0]
The task aims to improve the interpretability of charge prediction systems and help automatic legal document generation.,abstractText,[0],[0]
We formulate this task as a text-to-text natural language generation (NLG) problem.,abstractText,[0],[0]
Sequenceto-sequence model has achieved cutting-edge performances in many NLG tasks.,abstractText,[0],[0]
"However, due to the non-distinctions of fact descriptions, it is hard for Seq2Seq model to generate charge-discriminative court views.",abstractText,[0],[0]
"In this work, we explore charge labels to tackle this issue.",abstractText,[0],[0]
"We propose a label-conditioned Seq2Seq model with attention for this problem, to decode court views conditioned on encoded charge labels.",abstractText,[0],[0]
Experimental results show the effectiveness of our method.1,abstractText,[0],[0]
Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4766–4771 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4766",text,[0],[0]
Communication in social media differs from more standard linguistic interactions across a wide range of dimensions.,1 Introduction,[0],[0]
"Immediacy, short text length, the use of pseudowords like #hashtags or @mentions, and even metadata such as user information or geolocalization are essential components of social media messages.",1 Introduction,[0],[0]
"In addition, the use of emojis, small ideograms depicting objects, people and scenes (Cappallo et al., 2015), are becoming increasingly important for fully modeling the underlying semantics of a social media message, be it a product review, a tweet or an Instagram post.",1 Introduction,[0],[0]
"Emojis are the evolution of characterbased emoticons (Pavalanathan and Eisenstein, 2015), and are extensively used, not only as sentiment carriers or boosters, but more importantly, to express ideas about a myriad of topics, e.g., mood ( ), food ( ), sports ( ) or scenery ( ).
",1 Introduction,[0],[0]
"Emoji modeling and prediction is, therefore, an important problem towards the end goal of properly capturing the intended meaning of a so-
cial media message.",1 Introduction,[0],[0]
"In fact, emoji prediction, i.e., given a (usually short) message, predict its most likely associated emoji(s), may help to improve different NLP tasks (Novak et al., 2015), such as information retrieval, generation of emojienriched social media content or suggestion of emojis when writing text messages or sharing pictures online.",1 Introduction,[0],[0]
"It has furthermore proven to be useful for sentiment analysis, emotion recognition and irony detection (Felbo et al., 2017).",1 Introduction,[0],[0]
"The problem of emoji prediction, albeit recent, has already seen important developments.",1 Introduction,[0],[0]
"For example, Barbieri et al. (2017) describe an LSTM model which outperforms a logistic regression baseline based on word vector averaging, and even human judgement in some scenarios.
",1 Introduction,[0],[0]
"The above contributions, in addition to emoji similarity datasets (Barbieri et al., 2016; Wijeratne et al., 2017) or emoji sentiment lexicons (Novak et al., 2015; Wijeratne et al., 2016; Kimura and Katsurai, 2017; Rodrigues et al., 2018), have paved the way for better understanding the semantics of emojis.",1 Introduction,[0],[0]
"However, our understanding of what exactly the neural models for emoji prediction are capturing is currently very limited.",1 Introduction,[0],[0]
"What is a model prioritizing when associating a message with, for example, positive ( ), negative ( ) or patriotic ( ) intents?",1 Introduction,[0],[0]
A natural way of assessing this would be to implement an attention mechanism over the hidden states of LSTM layers.,1 Introduction,[0],[0]
"Attentive architectures in NLP, in fact, have recently received substantial interest, mostly for sequenceto-sequence models (which are useful for machine translation, summarization or language modeling), and a myriad of modifications have been proposed, including additive (Bahdanau et al., 2015), multiplicative (Luong et al., 2015) or self (Lin et al., 2017) attention mechanisms.
",1 Introduction,[0],[0]
"However, standard attention mechanisms only tell us which text fragments are considered impor-
tant for the overall prediction distribution.",1 Introduction,[0],[0]
"While emoji prediction has predominantly been treated as a multi-class classification problem in the literature, it would be more informative to analyze which text fragments are considered important for each individual emoji.",1 Introduction,[0],[0]
"With this motivation in mind, in this paper we put forward a label-wise mechanism that operates over each label during training.",1 Introduction,[0],[0]
"The resulting architecture intuitively behaves like a batch of binary mini-classifiers, which make decisions over one single emoji at a time, but without the computational burden and risk of overfitting associated with learning separate LSTMbased classifiers for each emoji.
",1 Introduction,[0],[0]
Our contribution in this paper is twofold.,1 Introduction,[0],[0]
"First, we use the proposed label-wise mechanism to analyze the behavior of neural emoji classifiers, exploiting the attention weights to uncover and interpret emoji usages.",1 Introduction,[0],[0]
"Second, we experimentally compare the effect of the label-wise mechanism on the performance of an emoji classifier.",1 Introduction,[0],[0]
"We observed a performance improvement over competitive baselines such as FastText (FT) (Joulin et al., 2017) and Deepmoji (Felbo et al., 2017), which is most noticeable in the case of infrequent emojis.",1 Introduction,[0],[0]
This suggests that an attentive mechanism can be leveraged to make neural architectures more sensitive to instances of underrepresented classes.,1 Introduction,[0],[0]
"Our base architecture is the Deepmoji model (Felbo et al., 2017), which is based on two stacked word-based bi-directional LSTM recurrent neural
networks with skip connections between the first and the second LSTM.",2 Methodology,[0],[0]
The model also includes an attention module to increase its sensitivity to individual words during prediction.,2 Methodology,[0],[0]
"In general, attention mechanisms allow the model to focus on specific words of the input (Yang et al., 2016), instead of having to memorize all the important features in a fixed-length vector.",2 Methodology,[0],[0]
"The main architectural difference with respect to the typical attention is illustrated in Figure 1.
",2 Methodology,[0],[0]
"In Felbo et al. (2017), attention is computed as follows:
zi = wahi + ba αi = ezi∑N j=1 e zj
s = N∑ j=1 αjhj
Here",2 Methodology,[0],[0]
"hi ∈ Rd is the hidden representation of the LSTM corresponding to the ith word, with N the total number of words in the sentence.",2 Methodology,[0],[0]
The weight vector wa ∈ Rd and bias term ba ∈ R map this hidden representation to a value that reflects the importance of this state for the considered classification problem.,2 Methodology,[0],[0]
"The values z1, ..., zn are then normalized using a softmax function, yielding the attention weights αi.",2 Methodology,[0],[0]
The sentence representation s is defined as a weighted average of the vectors hi.,2 Methodology,[0],[0]
"The final prediction distribution is then defined as follows:
βl = wf,ls+ bf,l
pl = eβl∑L r=1",2 Methodology,[0],[0]
"e βr
where wf,l ∈ Rd and bf,l define a label-specific linear transformation, with βl reflecting our confidence in the lth label and L is the total number of labels.",2 Methodology,[0],[0]
The confidence scores βl are then normalized to probabilities using another softmax operation.,2 Methodology,[0],[0]
"However, while the above design has contributed to better emoji prediction, in our case we are interested in understanding the contribution of the words of a sentence for each label (i.e., emoji), and not in the whole distribution of the target labels.",2 Methodology,[0],[0]
"To this end, we propose a label-wise attention mechanism.",2 Methodology,[0],[0]
"Specifically, we apply the same type of attention, but repeating it |L| (number of labels) times, where each attention module is reserved for a specific label l:
zi,l = wa,lhi + ba,l αi,l = ezi,l∑N j=1 e zj,l
sl = N∑ j=1 αj,lhj
βl = wf,lsl + bf,l pl = eβl∑L r=1",2 Methodology,[0],[0]
e βr,2 Methodology,[0],[0]
"This section describes the main experiment w.r.t the performance of our proposed attention mechanism, in comparison with existing emoji prediction systems.",3 Evaluation,[0],[0]
"We use the data made available in the context of the SemEval 2018 Shared Task on Emoji Prediction (Barbieri et al., 2018).",3 Evaluation,[0],[0]
"Given a tweet, the task consists of predicting an associated emoji from a predefined set of 20 emoji labels.",3 Evaluation,[0],[0]
We evaluate our model on the English split of the official task dataset.,3 Evaluation,[0],[0]
We also show results from additional experiments in which the label space ranged from 20 to 200 emojis.,3 Evaluation,[0],[0]
"These extended experiments are performed on a corpus of around 100M tweets geolocalized in the United States and posted between October 2015 and May 2018.
",3 Evaluation,[0],[0]
Models.,3 Evaluation,[0],[0]
"In order to put our proposed labelwise attention mechanism in context, we compare its performance with a set of baselines: (1) FastText (Joulin et al., 2017) (FT), which was the official baseline in the SemEval task; (2) 2
stacked Bi-LSTMs (2-BiLSTMs) without attention; and (3) 2 stacked Bi-LSTMs with standard attention (2-BiLSTMsa)",3 Evaluation,[0],[0]
"(Felbo et al., 2017).",3 Evaluation,[0],[0]
"Finally, we denote as 2-BiLSTMsl our proposed label-wise attentive Bi-LSTM architecture.
Results.",3 Evaluation,[0],[0]
Table 1 shows the results of our model and the baselines in the emoji prediction task for the different evaluation splits.,3 Evaluation,[0],[0]
"The evaluation metrics used are: F1, Accuracy@k (A@k, where k ∈ {1, 5}), and Coverage Error (CE1) (Tsoumakas et al., 2009).",3 Evaluation,[0],[0]
We note that the latter metric is not normally used in emoji prediction settings.,3 Evaluation,[0],[0]
"However, with many emojis being “near synonyms” (in the sense of being often used almost interchangeably), it seems natural to evaluate the performance of an emoji prediction system in terms of how far we would need to go through the predicted emojis to recover the true label.",3 Evaluation,[0],[0]
"The results show that our proposed 2-BiLSTMsl method outperforms all baselines for F1 in three out of four settings, and for CE in all of them.",3 Evaluation,[0],[0]
"In the following section we shed light on the reasons behind this performance, and we try to understand how these predictions were made.
1CE is computed as the average number of labels that need to be in the predictions for all true labels to be predicted.",3 Evaluation,[0],[0]
"By inspecting the predictions of our model, we found that the label-wise attention mechanism tends to be less heavily biased towards the most frequent emojis.",4 Analysis,[0],[0]
"This is reflected in the lower coverage error results in all settings, and becomes more noticeable as the number of labels grows.",4 Analysis,[0],[0]
We verified this by computing the average difference between ranked predictions of the two attentive models in the 200-label setting (Figure 2).,4 Analysis,[0],[0]
"We can observe a sudden switch at more or less the median emoji, after which the label-wise attention model becomes increasingly accurate (relative to the standard attention model).",4 Analysis,[0],[0]
"This can be explained by the fact that infrequent emojis tend to be more situational (used in specific contexts and leaving less room for ambiguity or interchangeability), which the label-wise attention mechanism can take advantage of, as it explicitly links emojis with highly informative words.",4 Analysis,[0],[0]
"Let us illustrate this claim with a case in which the label-wise attention model predicts the correct emoji, unlike its single-attention counterpart:
a friendship is built over time , but sisterhood is given automatically.",4 Analysis,[0],[0]
"Gold:
For the above example2, the predictions of the single attention model were all linked to the general meaning of the message, that is love and friendship, leading it to predict associated emojis ( ,
and ), failing to capture the most relevant bit of information.",4 Analysis,[0],[0]
"On the other hand, our proposed model “picks on” the word sisterhood, and with
2The highlights show the αl attention weights of .
label-wise attentive models.",4 Analysis,[0],[0]
"Gold: .
",4 Analysis,[0],[0]
"the added context of the surrounding words, ranks the gold label3 in 4th position, which would be a true positive as per A@5.
",4 Analysis,[0],[0]
Let us explore what we argue are interesting cases of emoji usage (ranging from highly explicit to figurative or situtational intent).,4 Analysis,[0],[0]
"Figure 3 shows how the word (praying) and emojis such as and
are strongly correlated.",4 Analysis,[0],[0]
"In addition, the bond between the word snow and the emoji is also indisputable.",4 Analysis,[0],[0]
"However, a perhaps more surprising example is displayed in Figure 4, which is a negative example.",4 Analysis,[0],[0]
"Here, the emoji was predicted with rank 1, and we see it being strongly associated with the ordinal second, suggesting that the model assumed this was some kind of “ticked enumeration” of completed tasks, which is indeed regular practice in Twitter.",4 Analysis,[0],[0]
"Finally, we found it remarkable that the ambiguous nature of the word boarding is also reflected in two different emojis being predicted with high probability ( and ), each of them showcasing one of the word’s senses.
",4 Analysis,[0],[0]
"As an additional exploratory analysis, we computed statistics on those words with the highest average attention weights associated with one single emoji.",4 Analysis,[0],[0]
"One interesting example is the emoji, which shows two clear usage patterns: one literal (a tree) and one figurative (christmas and holidays).",4 Analysis,[0],[0]
"Finally, as a final (and perhaps thoughtprovoking) finding, the highest attention weights associated to the emoji were given to the words game, boys and football, in that order.",4 Analysis,[0],[0]
"In other words, the model relies more on the word boys than on the actual description of the emoji.",4 Analysis,[0],[0]
"This is in line with a previous study that showed how the current usage of emojis in Twitter is in some cases associated with gender stereotypes (Barbieri and Camacho-Collados, 2018).
",4 Analysis,[0],[0]
3Which is among the 10% most infrequent emojis in the dataset.,4 Analysis,[0],[0]
"In this paper we have presented a neural architecture for emoji prediction based on a label-wise attention mechanism, which, in addition to improving performance, provides a degree of interpretability about how different features are used for predictions, a topic of increasing interest in NLP (Linzen et al., 2016; Palangi et al., 2017).",5 Conclusion,[0],[0]
"As we experimented with sets of emoji labels of different sizes, our proposed label-wise attention architecture proved especially well-suited for emojis which were infrequent in the training data, making the system less biased towards the most frequent.",5 Conclusion,[0],[0]
"We see this as a first step to improve the robustness of recurrent neural networks in datasets with unbalanced distributions, as they were shown not to perform better than well-tuned SVMs on the emoji predicion task (Çöltekin and Rama, 2018).
",5 Conclusion,[0],[0]
"As for future work, we plan to apply our labelwise attention mechanism to understand other interesting linguistic properties of human-generated text in social media, and other multi-class or multilabel classification problems.
",5 Conclusion,[0],[0]
"Finally, code to reproduce our experiments and additional examples of label-wise attention weights from input tweets can be downloaded at https://fvancesco.github.",5 Conclusion,[0],[0]
io/label_wise_attention/.,5 Conclusion,[0],[0]
"F. Barbieri and H. Saggion acknowledge support from the TUNER project (TIN2015-65308-C5-5R, MINECO/FEDER, UE).",Acknowledgments,[0],[0]
"Luis Espinosa-Anke, Jose Camacho-Collados and Steven Schockaert have been supported by ERC Starting Grant 637277.",Acknowledgments,[0],[0]
"Human language has evolved towards newer forms of communication such as social media, where emojis (i.e., ideograms bearing a visual meaning) play a key role.",abstractText,[0],[0]
"While there is an increasing body of work aimed at the computational modeling of emoji semantics, there is currently little understanding about what makes a computational model represent or predict a given emoji in a certain way.",abstractText,[0],[0]
In this paper we propose a label-wise attention mechanism with which we attempt to better understand the nuances underlying emoji prediction.,abstractText,[0],[0]
"In addition to advantages in terms of interpretability, we show that our proposed architecture improves over standard baselines in emoji prediction, and does particularly well when predicting infrequent emojis.",abstractText,[0],[0]
Interpretable Emoji Prediction via Label-Wise Attention LSTMs,title,[0],[0]
"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1244–1254, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics",text,[0],[0]
"In such pro-drop languages as Japanese, Chinese and Italian, pronouns are frequently omitted in text.",1 Introduction,[0],[0]
"For example, the subject of uketa (suffered) is unrealized in the following Japanese example (1):
(1) sono-houkokusho-wa seifui-ga the report-TOP governmenti-SUBJ
jouyaku-o teiketsushi (ϕi-ga) keizaitekini treaty-OBJ make iti-SUBJ economically
higai-o uke-ta koto-o shitekishi-ta damage-OBJ suffer-PAST COMP point out-PAST The report pointed out that the governmenti agreed to a treaty and (iti) suffered economically.
",1 Introduction,[0],[0]
"The omitted argument is called a zero anaphor, which is represented using ϕ.",1 Introduction,[0],[0]
"In example (1), zero
anaphor ϕi refers to its antecedent, seifui (government).",1 Introduction,[0],[0]
Such a reference phenomenon is called zero anaphora.,1 Introduction,[0],[0]
Identifying zero anaphoric relations is an essential task in developing such accurate NLP applications as information extraction and machine translation for pro-drop languages.,1 Introduction,[0],[0]
"For example, in Japanese, 60% of subjects in newspaper articles are unrealized as zero anaphors (Iida et al., 2007).
",1 Introduction,[0],[0]
"This paper proposes a method for intra-sentential subject zero anaphora resolution, in which a zero anaphor and its antecedent appear in the same sentence and the zero anaphor must be a subject of a predicate, for Japanese.",1 Introduction,[0],[0]
We target subject zero anaphors because they represent 85% of the intrasentential zero anaphora in our data set (example (1) is such a case).,1 Introduction,[0],[0]
"Furthermore, this work focuses on intra-sentential zero anaphora because intersentential cases, in which a zero anaphor and its antecedent do not appear in the same sentence, are extremely difficult.",1 Introduction,[0],[0]
"The accuracy of the state-of-theart method for resolving inter-sentential anaphora is low (Sasano and Kurohashi, 2011), and we believe the current technologies are not mature enough to deal with inter-sentential cases.
",1 Introduction,[0],[0]
Our method locally predicts the likelihood of a zero anaphoric relation between every possible combination of potential zero anaphor and potential antecedent without considering the other (potential) zero anaphoric relations in the same sentence.,1 Introduction,[0],[0]
"The final determination of zero anaphoric relations for each zero anaphor in a given sentence is done in a greedy way; only the most likely candidate antecedent for each zero anaphor is selected as its antecedent as far as the likelihood score exceeds a
1244
given threshold.",1 Introduction,[0],[0]
"This approach contrasts with global optimization methods (Yoshikawa et al., 2011; Iida and Poesio, 2011; Ouchi et al., 2015), which have recently become popular.",1 Introduction,[0],[0]
"These methods use the constraints among possible zero anaphoric relations, such as “if a candidate antecedent is identified as the antecedent of a subject zero anaphor of a predicate, the candidate cannot be referred to by the object zero anaphor of the same predicate”, and determine an optimal set of zero anaphoric relations in an entire sentence while satisfying such constraints, using such optimization techniques as sentence-wise global learning (Ouchi et al., 2015) and integer linear programming (Iida and Poesio, 2011).
",1 Introduction,[0],[0]
"Although the global optimization methods have outperformed the previous greedy-style methods, our contention is that greedy-style methods can still, in a certain sense, outperform the state-of-the-art global optimization methods.",1 Introduction,[0],[0]
"Ouchi et al. (2015)’s global optimization method achieved the state-ofthe-art F-score for Japanese intra-sentential subject zero anaphora resolution, but its performance has not yet reached a level of practical use.",1 Introduction,[0],[0]
"In our setting, for example, it actually obtained a precision of only 0.61, and even after attempting to obtain more reliable zero anaphoric relations by several modifications, we could only achieve 0.80 precision at extremely low recall levels (<0.01).",1 Introduction,[0],[0]
"On the other hand, while our proposed greedy-style method obtained a lower F-score than Ouchi et al.’s method, it achieved much higher precision in a wide range of recall levels (e.g., around 0.8 precision at 0.25 in recall and around 0.7 precision at 0.4 in recall).",1 Introduction,[0],[0]
"We believe such high precision is crucial to realworld applications, even though the recall remains low, and thus our method is preferable to Ouchi et al.’s method in that sense.
",1 Introduction,[0],[0]
"In our proposed method, we use a Multi-column Convolutional Neural Network (MCNN) (Cireşan et al., 2012), which is a variant of a Convolutional Neural Network (CNN) (LeCun et al., 1998).",1 Introduction,[0],[0]
"An MCNN has several independent columns, each of which has its own convolutional and pooling layers.",1 Introduction,[0],[0]
The outputs of all the columns are combined in the final layer to provide a final prediction.,1 Introduction,[0],[0]
"In this work, motivated by Centering Theory (Grosz et al., 1995) and other previous works, we exploit as distinct columns the word sequences obtained from the surface word
sequence and the dependency tree of a target sentence in our MCNN.",1 Introduction,[0],[0]
"Although the existing works also exploited such word sequences, they used only particular types of information from them as features based on the researchers’ linguistic insights.",1 Introduction,[0],[0]
"In contrast, we minimized such feature engineering due to using an MCNN.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
"In Section 2, we briefly overview previous work on zero anaphora resolution.",1 Introduction,[0],[0]
"In Section 3, we present the procedure of our zero anaphora resolution method and explain the column sets used in our MCNN architecture.",1 Introduction,[0],[0]
We evaluate how effectively our method recognizes intra-sentential subject zero anaphora in Section 4 and summarize this work and discuss future directions in Section 5.,1 Introduction,[0],[0]
"The typical zero anaphora resolution algorithms proposed so far have exploited the information of a predicate that potentially has a zero anaphor and its candidate antecedent in a supervised manner (Seki et al., 2002; Iida et al., 2003; Isozaki and Hirao, 2003; Iida et al., 2006; Taira et al., 2008; Sasano et al., 2008; Imamura et al., 2009; Hayashibe et al., 2011; Iida and Poesio, 2011; Sasano and Kurohashi, 2011; Yoshikawa et al., 2011).",2 Related work,[0],[0]
"In addition, existing works have exploited the dependency path between a predicate and a candidate antecedent either by encoding such paths to the set of binary features of the words that appear in the path (Iida and Poesio, 2011) or by mining from the paths the sub-trees that effectively discriminate zero anaphoric relations (Iida et al., 2006).",2 Related work,[0],[0]
"However, both methods just focus on the dependency paths between a predicate and a candidate antecedent without exploiting other structural fragments in the dependency tree representing a target sentence, whereas our method uses the text fragments that cover the entire dependency tree.
",2 Related work,[0],[0]
"Another important clue was derived from discourse theories, such as Centering Theory (Grosz et al., 1995).",2 Related work,[0],[0]
"In this theory, (zero) anaphoric phenomenon is explained based on the rules and principles regarding the recency and saliency of candidate antecedents.",2 Related work,[0],[0]
Okumura and Tamura (1996) developed a rule-based method based on the idea of Centering Theory.,2 Related work,[0],[0]
"Iida et al. (2003) and Imamura et
al. (2009) used as features for machine learning the results of rule-based antecedent identification based on a variant of Centering Theory (Nariyama, 2002).",2 Related work,[0],[0]
"However, we observed that actual anaphoric phenomena often do not obey Centering Theory.",2 Related work,[0],[0]
"To robustly resolve zero anaphora, we need to explore additional clues that are represented in a target sentence (or text).
",2 Related work,[0],[0]
"Recent work by Iida et al. (2015) newly introduced a sub-problem of zero anaphora resolution, subject sharing recognition, which is the task that judges whether two predicates have the same subject.",2 Related work,[0],[0]
"In their method, a network of subject sharing predicates is created by their subject sharing recognizer, and then zero anaphora resolution is performed by propagating a subject to the unrealized subject positions through the path in the network.",2 Related work,[0],[0]
"Even though the accuracy of subject sharing recognition exceeds that of zero anaphora resolution, the zero anaphoric relations identified using the results of subject sharing recognition are limited to those that can be reached by subject sharing relations.",2 Related work,[0],[0]
"The recall of this method is not high.
",2 Related work,[0],[0]
"Although most zero anaphora resolution methods independently identify a zero anaphoric relation for each predicate, some previous works optimized the global assignment of zero anaphoric relations in an entire sentence (or an entire text) while satisfying several constraints among zero anaphoric relations.",2 Related work,[0],[0]
"For example, Iida and Poesio (2011) found the best assignment of subject zero anaphoric relations using integer linear programming.",2 Related work,[0],[0]
"As mentioned in the Introduction, Ouchi et al. (2015) estimated the global score of all of the predicate-argument assignments in a sentence, which include the assignments of intrasentential zero anaphoric relations, to find the best assignment using a hill-climbing technique.",2 Related work,[0],[0]
"Their method has an advantage: it can exploit complicated relations (e.g., the combination of two potential zero anaphoric relations) as features to directly decide more than one predicate-argument relation simultaneously.",2 Related work,[0],[0]
"We adopted Ouchi et al. (2015)’s method as a baseline in Section 4 because it achieved the state-of-the-art performance for intra-sentential zero anaphora resolution.
",2 Related work,[0],[0]
"Collobert et al. (2011) proposed CNN architecture that can be applied to various NLP tasks, such as PoS tagging, chunking, named entity recognition
and semantic role labeling.",2 Related work,[0],[0]
"Following this work, CNNs have been utilized in such NLP tasks as document classification (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2015), paraphrase (Hu et al., 2014; Yin and Schütze, 2015) and relation extraction (Liu et al., 2013; Zeng et al., 2014; dos Santos et al., 2015; Nguyen and Grishman, 2015).",2 Related work,[0],[0]
"MCNNs were first introduced for image classification (Cireşan et al., 2012).",2 Related work,[0],[0]
"In NLP tasks, they have been utilized for question-answering (Dong et al., 2015) and relation extraction (Zeng et al., 2015).",2 Related work,[0],[0]
"Our MCNN architecture was inspired by a Siamese architecture (Chopra et al., 2005), which we extend to a multi-column network and replace its similarity measure with a softmax function at its top.",2 Related work,[0],[0]
"Our proposed method consists of the following four steps:
Step 1 Extract every pair of a predicate and a candidate antecedent, ⟨predi, candi⟩, that appears in a target sentence.
",3 Proposed method,[0],[0]
Step 2,3 Proposed method,[0],[0]
"Predict the probability of each pair using our MCNN.
",3 Proposed method,[0],[0]
"Step 3 Rank in descending order all the pairs by their probabilities obtained in Step 2.
",3 Proposed method,[0],[0]
"Step 4 Choose the top pair ⟨predi, candi⟩ in the ranked list and fill the zero anaphor position of predicate predi by candi if the position has not already been filled by another candidate.",3 Proposed method,[0],[0]
"Remove ⟨predi, candi⟩ from the list and repeat this step as long as the score of the chosen pair exceeds a given threshold.
",3 Proposed method,[0],[0]
"In Step 1, we extract set of pairs ⟨predi, candi⟩ in which candidate antecedent candi is paired with predicate predi.",3 Proposed method,[0],[0]
"Note that we extracted predicate predi, instead of a zero anaphor that is an unrealized subject of predi, because the (potential) zero anaphor of predi is omitted in the text and cannot be extracted directly.
",3 Proposed method,[0],[0]
"In Step 2, our MCNN gives a probability that indicates the likelihood of a zero anaphoric relation to judge for each pair whether candi fills the blank subject position of predi through zero anaphora and ranks all of the pairs by the probabilities in Step 3.
",3 Proposed method,[0],[0]
"Finally, in Step 4 we actually fill candi in the blank subject positions of predi in a greedy style in the order of the ranked list in Step 3, i.e., the zero anaphora resolution with a higher probability is done before that with a lower probability.",3 Proposed method,[0],[0]
"If the subject position is already occupied by another candidate antecedent, candidate antecedents are no longer filled at that position.",3 Proposed method,[0],[0]
"In Step 2 of our method, we use a Multi-column Convolutional Neural Network (MCNN).",3.1 Design of columns used in MCNN,[0],[0]
"Note that zero anaphoric phenomena can be divided into two different referential phenomena: anaphoric (i.e., an antecedent precedes its zero anaphor) and cataphoric (i.e., a zero anaphor precedes its antecedent) cases.",3.1 Design of columns used in MCNN,[0],[0]
"To capture this difference, we divided the set of training instances into two subsets by the relative occurrence positions of a predicate and a candidate antecedent and respectively trained two independent MCNNs using each set.
",3.1 Design of columns used in MCNN,[0],[0]
"Our MCNN simultaneously uses four column sets, as illustrated in Figure 1.",3.1 Design of columns used in MCNN,[0],[0]
"In the following explanation for each column set, we assume that candidate antecedent candi precedes predicate predi in the surface order (for the opposite case, i.e., the cataphoric case, the positions of candi and predi are switched).
",3.1 Design of columns used in MCNN,[0],[0]
"BASE The first column set consists of one column, which stores the word vectors of the bunsetsu
phrases1 including either candi or predi.",3.1 Design of columns used in MCNN,[0],[0]
"We call this column set the BASE column set.
",3.1 Design of columns used in MCNN,[0],[0]
SURFSEQ,3.1 Design of columns used in MCNN,[0],[0]
"The second column set consists of three columns, which store the word vectors of (a) the surface word sequence spanning from the beginning of the sentence to candi, (b) the sequence between candi and predi, and (c) the remainder, i.e., from predi to the end of the sentence.",3.1 Design of columns used in MCNN,[0],[0]
Note that candi and predi are not included in any column of this column set.,3.1 Design of columns used in MCNN,[0],[0]
"We call this column set the SURFSEQ column set.
",3.1 Design of columns used in MCNN,[0],[0]
DEPTREE,3.1 Design of columns used in MCNN,[0],[0]
The third set consists of four columns.,3.1 Design of columns used in MCNN,[0],[0]
"We extracted four partial dependency trees from the entire dependency tree of a target sentence: (a) the dependency path between predi and candi, (b) the sub-trees that depend on predi, (c) the sub-trees on which candi depends and (d) the remaining subtrees, which are illustrated in Figure 2.",3.1 Design of columns used in MCNN,[0],[0]
Note that candi and predi are not included in the partial trees.,3.1 Design of columns used in MCNN,[0],[0]
Each column stores the word vectors of the word sequence in which the words in (the set of) the partial trees are ordered by their surface order.,3.1 Design of columns used in MCNN,[0],[0]
"We call this set the DEPTREE column set.
",3.1 Design of columns used in MCNN,[0],[0]
PREDCONTEXT,3.1 Design of columns used in MCNN,[0],[0]
"The fourth set consists of three columns, which store the word vectors of (a) the bunsetsu phrase including predi, (b) the surface word sequence that appears before (a) (from the beginning of the sentence) and (c) the sequence that appears after (a) (until the end of the sentence).",3.1 Design of columns used in MCNN,[0],[0]
"We call this column set the PREDCONTEXT column set.
",3.1 Design of columns used in MCNN,[0],[0]
"Among the four column sets, the SURFSEQ column set was designed to introduce the clues based
1A bunsetsu phrase is a Japanese base phrase that consists of at least one content word optionally followed by function words.
on Centering Theory, in which the antecedent for a given zero anaphor can basically be identified by the recency and saliency properties of a candidate antecedent.",3.1 Design of columns used in MCNN,[0],[0]
"More precisely, in the set of the most salient candidate antecedents, the most recent one is preferred.",3.1 Design of columns used in MCNN,[0],[0]
"For example, suppose example (2) in which the predicate increase has a subject zero anaphor and its antecedent is France:
(2) nihon-wa shoshikataisaku-ni Japan-TOP countermeasures to falling birth rate-IOBJ
shippaishi-taga, furansu-wa sore-ni seikoushi fail-PAST/BUT France-TOP it-IOBJ succeed (ϕi-ga) shusseiritsu-o fuyashiteiru (iti-SUBJ) birth rate-OBJ increase Japan failed to develop countermeasures to its falling birth rate, but Francei succeeded and (ϕi) increased its birth rate.
",3.1 Design of columns used in MCNN,[0],[0]
"In this situation, there are two most salient candidate antecedents, Japan and France, because they are marked with topic marker wa, which basically indicates the highest degree of candidate saliency.",3.1 Design of columns used in MCNN,[0],[0]
"In this case, France is selected as the antecedent because it appears more recently than Japan, and such recency can be estimated by consulting the surface word sequence between France and increase: no other salient candidates are included in the word sequence.",3.1 Design of columns used in MCNN,[0],[0]
"Also, the other two types of word sequences (i.e., the sequence that spans from the beginning of the sentence to candi and that spans from predi to its end) are important for confirming whether a more salient candidate than candi appears in each word sequence.",3.1 Design of columns used in MCNN,[0],[0]
"If such a more salient candidate is found, it should be a stronger candidate of the antecedent.
",3.1 Design of columns used in MCNN,[0],[0]
The DEPTREE column set is introduced for capturing a different aspect of intra-sentential zero anaphora.,3.1 Design of columns used in MCNN,[0],[0]
"In the explanation based on Centering Theory, the most salient candidate (e.g., the candidate marked with wa (topic marker)) is selected as
an antecedent, but example (1) in Section 1 cannot be interpreted based on saliency and recency.",3.1 Design of columns used in MCNN,[0],[0]
"In example (1), the report is the most salient candidate in the sentence because it is marked with topic marker wa, but the less salient candidate government becomes the antecedent of zero anaphor ϕ.",3.1 Design of columns used in MCNN,[0],[0]
Such a problem is often solved by introducing the dependency tree of a sentence.,3.1 Design of columns used in MCNN,[0],[0]
Figure 3 represents the dependency tree of example (1) in which the antecedent of ϕi appears in the embedded clause.,3.1 Design of columns used in MCNN,[0],[0]
"In such a case, an antecedent probably exists among the most salient candidates in the embedded clause.",3.1 Design of columns used in MCNN,[0],[0]
"To introduce such structural clues, we used the partial dependency trees as columns in the DEPTREE column set.
",3.1 Design of columns used in MCNN,[0],[0]
"Anaphoricity determination, which is the task of judging whether a candidate anaphor has an antecedent, was established as a subtask of coreference resolution.",3.1 Design of columns used in MCNN,[0],[0]
"This problem was basically solved by exploring the possible candidate antecedents for a given anaphor candidate in its search space, and the results were used for improving the overall performance of coreference resolution, especially in English (Ng, 2004; Wiseman et al., 2015).",3.1 Design of columns used in MCNN,[0],[0]
"Inspired by such previous works, we designed the PREDCONTEXT set to determine the anaphoricity of zero anaphors, i.e., to judge whether a zero anaphor candidate has its antecedent in a sentence, by consulting the surface word sequences before and after predi.",3.1 Design of columns used in MCNN,[0],[0]
"In our MCNN (Figure 4), we represent each word in text fragment t by d-dimensional embedding vec-
tor xi and t by matrix T =",3.2 MCNN architecture,[0],[0]
"[x1, . . .",3.2 MCNN architecture,[0],[0]
", x|t|].2 T is then wired to a set of M feature maps where each feature map is a vector.",3.2 MCNN architecture,[0],[0]
"Each element O in the feature map is computed by a filter denoted by fj (1 ≤ j ≤ M ) from the N -gram word sequences in t for a fixed integer N , as O = ReLU(Wfj •",3.2 MCNN architecture,[0],[0]
"xi:i+N−1 +bfj ), where • denotes element-wise multiplication followed by the summation of the resulting elements (i.e., a Frobenious inner product of Wfj and xi:i+N−1) and ReLU(x) = max(0, x).",3.2 MCNN architecture,[0],[0]
"In other words, we construct a feature map by convolving a text fragment with a filter, which is parameterized by weight Wfj ∈ Rd×N and bias bfj ∈ R. Note that there can be several sets of feature maps where each set covers N -grams for different N .",3.2 MCNN architecture,[0],[0]
"Note that the weight of the feature maps for each N -gram in each column set is shared.
",3.2 MCNN architecture,[0],[0]
"As a whole, these feature maps are referred to as a convolution layer.",3.2 MCNN architecture,[0],[0]
The next layer is called a pooling layer.,3.2 MCNN architecture,[0],[0]
"Here we use max-pooling (Scherer et al., 2010; Collobert et al., 2011), which simply selects the maximum value among the elements in the same feature map.",3.2 MCNN architecture,[0],[0]
"Our assumption is that the maximum value indicates the existence of a strong clue, i.e., N -gram, for our final judgment.",3.2 MCNN architecture,[0],[0]
"The selected maximum values from all the M feature maps are simply concatenated, and the resulting M -dimensional vector is given to our final layer.
",3.2 MCNN architecture,[0],[0]
The final layer has vectors coming from multiple feature maps in multiple columns.,3.2 MCNN architecture,[0],[0]
They are again simply concatenated and constitute a high dimensional feature vector.,3.2 MCNN architecture,[0],[0]
The final layer applies a linear softmax function to produce the class probabilities of the zero anaphoric labels: true and false.,3.2 MCNN architecture,[0],[0]
"We use a mini-batch stochastic gradient descent (SGD) with the Adadelta update rule (Zeiler, 2012), apply random initialization within (-0.01, 0.01) for Wfj , and initialize the remaining parameters at zero.",3.2 MCNN architecture,[0],[0]
"In our preliminary investigation of the intrasentential zero anaphoric relations in the NAIST Text Corpus (Iida et al., 2007), since we found more annotation errors than we expected, we decided to
2We use zero padding for dealing with text fragments of variable length (Kim, 2014).
revise the annotation results.",4.1 Revising annotation results,[0],[0]
"In this revision, we additionally annotated the subject sharing relations, where two predicates have the same subject regardless whether the subject is realized or omitted, between pairs of predicates in our data set.",4.1 Revising annotation results,[0],[0]
Note that two predicates can have a subject sharing relation even if neither has a realized subject as far as a subject exists that can naturally fill the subject position of the two predicates.,4.1 Revising annotation results,[0],[0]
"We used the annotated results of subject sharing relations to efficiently detect the annotation errors of intra-sentential zero anaphoric relations, as shown below.
",4.1 Revising annotation results,[0],[0]
Twenty-six human annotators directly annotated the subject sharing relations for pairs of predicates in a sentence.,4.1 Revising annotation results,[0],[0]
"For this annotation, we automatically extracted from the NAIST Text Corpus all the pairs of predicates that appear in the same sentence and obtained 227,517 predicate pairs.",4.1 Revising annotation results,[0],[0]
"For making the annotation results more reliable, each subject sharing relation was individually judged by three annotators, and the final label was decided by a majority vote.",4.1 Revising annotation results,[0],[0]
"After that, further revisions of the subject sharing relations and the zero anaphoric relations were performed by focusing on the inconsistent annotations between the newly annotated subject sharing relations and the original predicate-argument relations in the NAIST Text Corpus.",4.1 Revising annotation results,[0],[0]
"More precisely, we scrutinized the suspicious annotations such that a subject, which was determined through the annotated subject sharing relations, is not the same as a subject that was directly annotated in the NAIST Text Corpus.",4.1 Revising annotation results,[0],[0]
"In this revision phase, both the subject sharing and zero anaphora relations for such suspicious instances were independently re-annotated by three annotators, and their final labels of both relations were determined by a majority of the their decisions.3 As a result, 2,120 zero anaphoric instances were newly added to the corpus and 1,184 instances were removed from it for a total of 19,049 instances of intra-sentential subject",4.1 Revising annotation results,[0],[0]
zero anaphoric,4.1 Revising annotation results,[0],[0]
"relations.4
3We are planning to release the annotated results and information on the data separation used in our evaluation from https://alaginrc.nict.go.jp/.
4After this revision, a small number of inconsistent annotated results have both a syntactically dependent subject and a subject zero anaphor because the revision was performed locally.",4.1 Revising annotation results,[0],[0]
There were 30 inconsistent instances in the testing set and 100 in the training and development sets.,4.1 Revising annotation results,[0],[0]
We only removed such instances from the testing set without changing the other,4.1 Revising annotation results,[0],[0]
"The documents in the corpus were divided into five subsets, three of which were used as a training data set, one as a development data set, and one as a testing data set.",4.2 Experimental settings,[0],[0]
The statistics of our data set are summarized in Table 1.,4.2 Experimental settings,[0],[0]
"We evaluated the performance of our intra-sentential subject zero anaphora resolution method and three baseline methods described below using the revised annotated results in our data set.
",4.2 Experimental settings,[0],[0]
"We implemented our MCNN using Theano (Bastien et al., 2012).",4.2 Experimental settings,[0],[0]
"We pre-trained 300- dimensional word embedding vectors for 1,658,487 words5 using Skip-gram with a negative-sampling algorithm (Mikolov et al., 2013)6 on a set of all the sentences extracted from Wikipedia articles7 (35,975,219 sentences).",4.2 Experimental settings,[0],[0]
We removed from the training data all the words that only appeared once before training.,4.2 Experimental settings,[0],[0]
"In training, we treated them as unknown words and assigned them a random vector.",4.2 Experimental settings,[0],[0]
"To avoid overfitting, we applied early-stopping and dropout (Hinton et al., 2012) of 0.5 to the final layer.",4.2 Experimental settings,[0],[0]
We used an SGD with mini-batches of 100 and a learning rate decay of 0.95.,4.2 Experimental settings,[0],[0]
"We ran ten epochs through all of the training data, where each epoch consisted of many mini-batch updates.",4.2 Experimental settings,[0],[0]
"We utilized 3-, 4- and 5-grams with 100 filters each and used the F-score of positive instances as our evaluation metric.",4.2 Experimental settings,[0],[0]
"The total number of the nodes in the final layers of our MCNN was 3,300: 11 columns × 3 N -gram",4.2 Experimental settings,[0],[0]
×,4.2 Experimental settings,[0],[0]
"100 filters.
",4.2 Experimental settings,[0],[0]
"Word segmentation, PoS tagging and dependency parsing of the sentences in the NAIST Text Corpus were performed by a Japanese morphological analyzer, MeCab8 (Kudo et al., 2004), and a depen-
two sets.",4.2 Experimental settings,[0],[0]
5Words occurring less than five times in all the sentences were ignored to train the word embedding vectors.,4.2 Experimental settings,[0],[0]
6We set the skip distance to 5 and the number of negative samples to 10.,4.2 Experimental settings,[0],[0]
"7https://archive.org/details/jawiki-20150118 8http://taku910.github.io/mecab/
dency parser, J.DepP9 (Yoshinaga and Kitsuregawa, 2009).",4.2 Experimental settings,[0],[0]
We compared our method with three baseline methods.,4.3 Baselines,[0],[0]
The first baseline is a single-column convolutional neural network in which the column includes the entire surface word sequence of a sentence.,4.3 Baselines,[0],[0]
"To give the positions of predi and candi to the network, we concatenated to each word vector an additional 2-dimensional vector, where the first element is set to one if the corresponding word is predi, the second element is set to 1 if the corresponding word is candi, and otherwise they are set to 0.",4.3 Baselines,[0],[0]
"This baseline was adopted for estimating the impact of a multicolumn network compared to a single-column one.
",4.3 Baselines,[0],[0]
The remaining two baselines are Ouchi et al. (2015)’s global optimization method and Iida et al. (2015)’s method based on subject sharing recognition.,4.3 Baselines,[0],[0]
"Note that Ouchi’s method outputs predicateargument relations for three grammatical roles (subj, obj, iobj), but for this evaluation we used only the outputs related to intra-sentential subject zero anaphora resolution.",4.3 Baselines,[0],[0]
"As done in Ouchi et al. (2015), we averaged their performances across ten independent runs because the initial random assignment of the predicate-argument relations that was employed in their method changes the performance.",4.3 Baselines,[0],[0]
"Ouchi’s method does not require any development data set, so we used both the development and training data sets for training their joint model.",4.3 Baselines,[0],[0]
"For training the subject sharing recognizer used in Iida’s method, we used the annotated subject sharing relations in the training and development data sets.",4.3 Baselines,[0],[0]
"In these two baselines, we used the same morphological analyzer and dependency analyzer as for our method.",4.3 Baselines,[0],[0]
Table 2 shows the results for each method.,4.4 Results,[0],[0]
"Their performances were evaluated by measuring recall, precision, F-score and average precision (Avg.P).",4.4 Results,[0],[0]
"To assess the effectiveness of each column set introduced in Section 3.1, we evaluated the performance of our method using every possible combination of column sets that includes at least the BASE column set.",4.4 Results,[0],[0]
"We also gave the precision-recall (PR)
9http://www.tkl.iis.u-tokyo.ac.jp/˜ynaga/jdepp/
curves of our method using the four column sets (BASE+SURFSEQ+DEPTREE+PREDCONTEXT), the single column baseline, and Ouchi’s method in Figure 5 to investigate the behavior of each method at a high precision level.10 The PR-curves of our method and the single-column baseline were plotted just by altering the threshold parameters in Step 4 of our method (See Section 3).",4.4 Results,[0],[0]
"In contrast, the PR-curve of Ouchi’s method cannot be easily plotted because it gives a score to each sentence, not to each zero anaphoric relation.",4.4 Results,[0],[0]
"For plotting the PR-curve, we used the normalized global score of a sentence as the score of any zero anaphoric relations in the sentence.11 Note that the recall of their PR-curve reached just 0.539, shown in Table 2, because we could not estimate the scores of the zero anaphoric relations that were not outputted by their method.",4.4 Results,[0],[0]
The PR-curves of the other methods also fail to reach 1.0 in recall.,4.4 Results,[0],[0]
This is because the zero anaphoric relations are exclusive; a zero anaphor does not refer to more than one antecedent.,4.4 Results,[0],[0]
"If a method provides an incorrect zero anaphoric relation, a correct relation for the same zero anaphor will never be provided in its output.",4.4 Results,[0],[0]
"Also, note that the average precision of each method was calculated by averaging the precisions at the available recall
10The PR-curve of Iida et al. (2015)’s method was not plotted because it does not provide the score of each zero anaphoric relation.
",4.4 Results,[0],[0]
11The global score provided by Ouchi’s method becomes greater based on the number of predicate-argument pairs in a sentence.,4.4 Results,[0],[0]
"To control this, we normalized the original global score by the sum of the frequencies of the single or double predicate-argument pairs because the feature functions were applied to such pairs in their method.",4.4 Results,[0],[0]
"This achieved the best performance among the normalization schemes we have tried so far.
levels for each method.",4.4 Results,[0],[0]
The results in Table 2 show that our method using all the column sets achieved the best average precision among the combination of column sets that include at least the BASE column set.,4.4 Results,[0],[0]
This suggests that all of the clues introduced by our four column sets are effective for performance improvement.,4.4 Results,[0],[0]
"Table 2 also demonstrates that our method using all the column sets obtained better average precision than the strongest baseline, Ouchi’s method, in spite of an unfavorable condition for it.12 The results also show that our method with all of the column sets achieved a better F-score than Iida’s method and the single-column baseline.",4.4 Results,[0],[0]
"However, it achieved a lower F-score than Ouchi’s method.",4.4 Results,[0],[0]
This was caused by the choice of different recall levels for computing the F-score.,4.4 Results,[0],[0]
"In contrast, the PR-
12When calculating the average precision of each method, the relatively low values in precision at high recall levels (i.e., from 0.54 to 0.67) were used in our method but not in Ouchi’s method, as seen in Figure 5.
curves for these two methods in Figure 5 show that our method obtained higher precision than Ouchi’s method at all recall levels.",4.4 Results,[0],[0]
"Particularly, it got high precision in a wide range of recall levels (e.g., around 0.8 in precision at 0.25 in recall and around 0.7 in precision at 0.4 in recall), while the precision obtained by Ouchi’s method at 0.25 in recall was just around 0.65.",4.4 Results,[0],[0]
"We believe this difference becomes crucial when using the outputs of each method for developing accurate real-world NLP applications.
",4.4 Results,[0],[0]
"In addition to an evaluation that used all of the test instances, we also investigated how our method performed differently for anaphoric and cataphoric cases.",4.4 Results,[0],[0]
"In this evaluation, we first divided our data set into anaphoric and cataphoric sets by the relative position of the candidate antecedent and evaluated the performance by measuring the recall, precision, Fscore and average precision for each set.",4.4 Results,[0],[0]
"This evaluation was done instance-wise, where we took into account each pair of a predicate and its candidate antecedent as a classification target, while in the previous evaluation the performance was measured for the set of zero anaphors in the test set.",4.4 Results,[0],[0]
"Thus, the figures in Table 2 and Table 3 are not comparable.",4.4 Results,[0],[0]
"Note that we only compared our method with the baseline using a single-column convolutional neural network because the other baselines are not able to output the score of each instance for measuring their average precision.
",4.4 Results,[0],[0]
"The results in Table 3 show that our MCNN-based method achieved better average precision than the
single-column CNN baseline except the method that uses only the BASE column set for the cataphoric case.",4.4 Results,[0],[0]
The results also demonstrate that each column set consistently contributes to improving the average precision for both the anaphoric and cataphoric cases.,4.4 Results,[0],[0]
"However, Table 3 shows that the average precision for the cataphoric set remains low.",4.4 Results,[0],[0]
"As one future direction for further improvement, we need to explore clues for identifying cataphoric relations more accurately.",4.4 Results,[0],[0]
This paper proposed an accurate method for intrasentential subject zero anaphora resolution using a Multi-column Convolutional Neural Network (MCNN).,5 Conclusion,[0],[0]
"As clues, our MCNN exploits both the surface word sequence and the dependency tree of a target sentence.",5 Conclusion,[0],[0]
"Our experimental results show that the proposed method achieved better precision than the strong baselines in a wide range of recall levels.
",5 Conclusion,[0],[0]
"As future work, we plan to use our MCNN architecture for inter-sentential zero anaphora resolution and develop highly accurate NLP applications using our intra-sentential subject zero anaphora resolution method.",5 Conclusion,[0],[0]
We thank Hiroki Ouchi for providing his predicateargument analyzer that was proposed in Ouchi et al. (2015).,Acknowledgement,[0],[0]
This paper proposes a method for intrasentential subject zero anaphora resolution in Japanese.,abstractText,[0],[0]
Our proposed method utilizes a Multi-column Convolutional Neural Network (MCNN) for predicting zero anaphoric relations.,abstractText,[0],[0]
"Motivated by Centering Theory and other previous works, we exploit as clues both the surface word sequence and the dependency tree of a target sentence in our MCNN.",abstractText,[0],[0]
"Even though the F-score of our method was lower than that of the state-of-the-art method, which achieved relatively high recall and low precision, our method achieved much higher precision (>0.8) in a wide range of recall levels.",abstractText,[0],[0]
We believe such high precision is crucial for real-world NLP applications and thus our method is preferable to the state-of-the-art method.,abstractText,[0],[0]
Intra-Sentential Subject Zero Anaphora Resolution using Multi-Column Convolutional Neural Network,title,[0],[0]
"Neural networks have recently been applied to a number of diverse problems with impressive results (van den Oord et al., 2016; Silver et al., 2017; Berthelot et al., 2017).",1. Introduction,[0],[0]
"These breakthroughs largely appear to be driven by ap-
1School of ITEE, University of Queensland, Brisbane, Queensland, Australia 2School of Mathematics and Physics, University of Queensland, Brisbane, Queensland, Australia 3International Computer Science Institute, Berkeley, California, USA.",1. Introduction,[0],[0]
"Correspondence to: Russell Tsuchida <s.tsuchida@uq.edu.au>, Farbod RoostaKhorasani <fred.roosta@uq.edu.au>, Marcus Gallagher <marcusg@uq.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
plication rather than an understanding of the capabilities and training of neural networks.",1. Introduction,[0],[0]
"Recently, significant work has been done to increase understanding of neural networks (Choromanska et al., 2015; Haeffele & Vidal, 2015; Poole et al., 2016; Schoenholz et al., 2017; Zhang et al., 2016; Martin & Mahoney, 2017; Shwartz-Ziv & Tishby, 2017; Balduzzi et al., 2017; Raghu et al., 2017).",1. Introduction,[0],[0]
"However, there is still work to be done to bring theoretical understanding in line with the results seen in practice.
",1. Introduction,[0],[0]
"The connection between neural networks and kernel machines has long been studied (Neal, 1994).",1. Introduction,[0],[0]
"Much past work has been done to investigate the equivalent kernel of certain neural networks, either experimentally (Burgess, 1997), through sampling (Sinha & Duchi, 2016; Livni et al., 2017; Lee et al., 2017), or analytically by assuming some random distribution over the weight parameters in the network (Williams, 1997; Cho & Saul, 2009; Pandey & Dukkipati, 2014a;b; Daniely et al., 2016; Bach, 2017a).",1. Introduction,[0],[0]
"Surprisingly, in the latter approach, rarely have distributions other than the Gaussian distribution been analyzed.",1. Introduction,[0],[0]
"This is perhaps due to early influential work on Bayesian Networks (MacKay, 1992), which laid a strong mathematical foundation for a Bayesian approach to training networks.",1. Introduction,[0],[0]
"Another reason may be that some researchers may hold the intuitive (but not necessarily principled) view that the Central Limit Theorem (CLT) should somehow apply.
",1. Introduction,[0],[0]
"In this work, we investigate the equivalent kernels for networks with Rectified Linear Unit (ReLU), Leaky ReLU (LReLU) or other activation functions, one-hidden layer, and more general weight distributions.",1. Introduction,[0],[0]
Our analysis carries over to deep networks.,1. Introduction,[0],[0]
We investigate the consequences that weight initialization has on the equivalent kernel at the beginning of training.,1. Introduction,[0],[0]
"While initialization schemes that mitigate exploding/vanishing gradient problems (Hochreiter, 1991; Bengio et al., 1994; Hochreiter et al., 2001) for other activation functions and weight distribution combinations have been explored in earlier works (Glorot & Bengio, 2010; He et al., 2015), we discuss an initialization scheme for Muli-Layer Perceptrons (MLPs) with LReLUs and weights coming from distributions with 0 mean and finite absolute third moment.",1. Introduction,[0],[0]
"The derived kernels also allow us to analyze the loss of information as an input is propagated through the network, offering a complementary view to the shattered gradient problem (Balduzzi et al., 2017).",1. Introduction,[0],[0]
Consider a fully connected (FC) feedforward neural network with m inputs and a hidden layer with n neurons.,2. Preliminaries,[0],[0]
Let σ : R → R be the activation function of all the neurons in the hidden layer.,2. Preliminaries,[0],[0]
"Further assume that the biases are 0, as is common when initializing neural network parameters.",2. Preliminaries,[0],[0]
"For any two inputs x,y ∈ Rm propagated through the network, the dot product in the hidden layer is
1 n h(x) · h(y) = 1 n n∑ i=1 σ(wi · x)σ(wi · y), (1)
where h(·) denotes the n dimensional vector in the hidden layer and wi ∈ Rm is the weight vector into the ith neuron.",2. Preliminaries,[0],[0]
"Assuming an infinite number of hidden neurons, the sum in (1) has an interpretation as an inner product in feature space, which corresponds to the kernel of a Hilbert space.",2. Preliminaries,[0],[0]
"We have
k(x,y) = ∫",2. Preliminaries,[0],[0]
"Rm σ(w · x)σ(w · y)f(w)dw, (2)
where f(w) is the probability density function (PDF) for the identically distributed weight vector W = (W1, ...,Wm)
T in the network.",2. Preliminaries,[0],[0]
"The connection of (2) to the kernels in kernel machines is well-known (Neal, 1994; Williams, 1997; Cho & Saul, 2009).
",2. Preliminaries,[0],[0]
"Probabilistic bounds for the error between (1) and (2) have been derived in special cases (Rahimi & Recht, 2008) when the kernel is shift-invariant.",2. Preliminaries,[0],[0]
Two specific random feature mappings are considered: (1) Random Fourier features are taken for the σ in (1).,2. Preliminaries,[0],[0]
Calculating the approximation error in this way requires being able to sample from the PDF defined by the Fourier transform of the target kernel.,2. Preliminaries,[0],[0]
"More explicitly, the weight distribution f is the Fourier transform of the target kernel and the n samples σ(wi ·x) are replaced by some appropriate scale of cos(wi · x).",2. Preliminaries,[0],[0]
(2) A random bit string σ(xi) is associated to each input according to a grid with random pitch δ sampled from f imposed on the input space.,2. Preliminaries,[0],[0]
"This method requires having access to the second derivative of the target kernel to sample from the distribution f .
",2. Preliminaries,[0],[0]
"Other work (Bach, 2017b) has focused on the smallest error between a target function g in the reproducing kernel Hilbert space (RKHS) defined by (2) and an approximate function ĝ expressible by the RKHS with the kernel (1).",2. Preliminaries,[0],[0]
"More explicitly, let g(x) = ∫",2. Preliminaries,[0],[0]
"Rm G(w)σ(w,x)f(w)",2. Preliminaries,[0],[0]
"dw be
the representation of g in the RKHS.",2. Preliminaries,[0],[0]
The quantity ∥∥ĝ,2. Preliminaries,[0],[0]
"−
g ∥∥ = ∥∥∑ni=1 αiσ(wi, ·) − ∫Rm G(w)σ(w, ·)f(w) dw∥∥ (with some suitable norm) is studied for the best set of αi and random wi with an optimized distribution.
",2. Preliminaries,[0],[0]
Yet another measure of kernel approximation error is investigated by Rudi & Rosasco (2017).,2. Preliminaries,[0],[0]
"Let ĝ and g be the
optimal solutions to the ridge regression problem of minimizing a regularized cost function C using the kernel (1) and the kernel (2) respectively.",2. Preliminaries,[0],[0]
The number of datapoints n required to probabilistically bound C(ĝ)−C(g) is found to be O( √ n log n) under a suitable set of assumptions.,2. Preliminaries,[0],[0]
This work notes the connection between kernel machines and one-layer Neural Networks with ReLU activations and Gaussian weights by citing Cho & Saul (2009).,2. Preliminaries,[0],[0]
"We extend this connection by considering other weight distributions and activation functions.
",2. Preliminaries,[0],[0]
"In this work our focus is on deriving expressions for the target kernel, not the approximation error.",2. Preliminaries,[0],[0]
"Additionally, we consider random mappings that have not been considered elsewhere.",2. Preliminaries,[0],[0]
Our work is related to work by Poole et al. (2016) and Schoenholz et al. (2017).,2. Preliminaries,[0],[0]
"However, our results apply to the unbounded (L)ReLU activation function and more general weight distributions, and their work considers random biases as well as weights.",2. Preliminaries,[0],[0]
"The kernel (2) has previously been evaluated for a number of choices of f and σ (Williams, 1997; Roux & Bengio, 2007; Cho & Saul, 2009; Pandey & Dukkipati, 2014a;b).",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
"In particular, the equivalent kernel for a one-hidden layer network with spherical Gaussian weights of variance E[W 2i ] and mean 0 is the Arc-Cosine Kernel (Cho & Saul, 2009)
k(x,y) = E[W 2i ]‖x‖‖y‖
2π
( sin θ0 + (π− θ0) cos θ0 ) , (3)
",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
where θ0 = cos−1 ( x·y ‖x‖‖y‖ ) is the angle between the inputs x and y and ‖·‖ denotes the `2 norm.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
"Noticing that the ArcCosine Kernel k(x,y) depends on x and y only through their norms, with an abuse of notation we will henceforth set k(x,y) ≡ k(θ0).Define the normalized kernel to be the cosine similarity between the signals in the hidden layer.",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
"The normalized Arc-Cosine Kernel is given by
cos θ1 = k(x,y)√ k(x,x)",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
"√ k(y,y) = 1 π
( sin θ0 + (π − θ0) cos θ0 ) ,
where θ1 is the angle between the signals in the first layer.",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
Figure 1 shows a plot of the normalized Arc-Cosine Kernel.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
One might ask how the equivalent kernel changes for a different choice of weight distribution.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
We investigate the equivalent kernel for networks with (L)ReLU activations and general weight distributions in Section 3.1 and 3.2.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
The equivalent kernel can be composed and applied to deep networks.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
The kernel can also be used to choose good weights for initialization.,3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
"These, as well as other implications for practical neural networks, are investigated in Section 5.",3. Equivalent Kernels for Infinite Width Hidden Layers,[0],[0]
In this section we show that (3) holds more generally than for the case where f is Gaussian.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"Specifically, (3) holds when f is any rotationally invariant distribution.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"We do this by casting (2) as the solution to an ODE, and then solving the ODE.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"We then extend this result using the same technique to the case where σ is LReLU.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"A rotationally-invariant PDF one with the property f(w) = f(Rw) = f(‖w‖) for all w and orthogonal matrices R. Recall that the class of rotationally-invariant distributions (Bryc, 1995), as a subclass of elliptically contoured distributions (Johnson, 2013), includes the Gaussian distribution, the multivariate t-distribution, the symmetric multivariate Laplace distribution, and symmetric multivariate stable distributions.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Proposition 1.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Suppose we have a one-hidden layer feedforward network with ReLU σ,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
and,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
random weights W with uncorrelated and identically distributed rows with rotationally-invariant PDF f :,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Rm → R and E[W 2i ],3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"<∞. The equivalent kernel of the network is (3).
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Proof.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"First, we require the following.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Proposition 2.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"With the conditions in Proposition 1 and inputs x,y ∈",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"Rm the equivalent kernel of the network is the solution to the Initial Value Problem (IVP)
k′′(θ0) + k(θ0) = F (θ0), k ′(π) = 0, k(π) = 0, (4)
where θ0 ∈ (0, π) is the angle between the inputs x and y.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"The derivatives are meant in the distributional sense; they are functionals applying to all test functions in C∞c (0, π).",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"F (θ0) is given by the m− 1 dimensional integral
F (θ0) = ∫ Rm−1 f",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"( (s sin θ0,−s cos θ0, w3, ..., wm)T )
Θ(s)s3 ds",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
dw3 dw4...,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"dwm‖x‖‖y‖ sin θ0, (5)
where Θ is the Heaviside step function.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
The proof is given in Appendix A.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
The main idea is to rotate w (following Cho & Saul (2009)),3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"so that
k(x,y) = ∫",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"Rm Θ(w1)Θ(w1 cos θ0 + w2 sin θ0)w1
(w1 cos θ0 + w2 sin θ0)f(w)",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"dw‖x‖‖y‖.
Now differentiating twice with respect to θ0 yields the second order ODE (4).",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"The usefulness of the ODE in its current form is limited, since the forcing term F (θ0) as in (5) is difficult to interpret.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"However, regardless of the underlying distribution on weights w, as long as the PDF f in (5) corresponds to any rotationally-invariant distribution, the integral enjoys a much simpler representation.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Proposition 3.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"With the conditions in Proposition 1, the forcing term F (θ0) in the kernel ODE is given by F (θ0) = K sin θ0, where
K = ∫ Rm−1 Θ(s)s3f ( (s, 0, w3, ..., wm) T )
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"ds dw3, ...",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"dwm‖x‖‖y‖ <∞,
and the solution to the distributional ODE (4) is the solution to the corresponding classical ODE.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"The proof is given in Appendix B.
Note that in the representation F (θ0) = K sin θ0 of the forcing term, the underlying distribution appears only as a constant K. For all rotationally-invariant distributions, the forcing term in (4) results in an equivalent kernel with the same form.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
We can combine Propositions 2 and 3 to find the equivalent kernel assuming rotationally-invariant weight distributions.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"Due to the rotational invariance of f , k(0) =∫",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Rm Θ(w1)w 2 1f(Rw) dw‖x‖‖y‖ = ‖x‖‖y‖E[W 2i ] 2 .,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
The solution to the ODE in Proposition 2 using the forcing term from Proposition 3 is k(θ0) = c1 cos θ0 + c2 sin θ0 − 1 2Kθ0 cos θ0.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"Using the conditions from the IVP and k(0), the values of c1, c2 and K give the required result.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
One can apply the same technique to the case of LReLU activations σ(z) =,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
( a+ (1− a)Θ(z) ),3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"z, where a specifies the gradient of the activation for z < 0.",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Proposition 4.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
Consider the same situation as in Proposition 1 with the exception that the activations are LReLU.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"The integral (2) is then given by
k(x,y) =",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"[ (1− a)2
2π
( sin θ0 + (π − θ0) cos θ0 ) + a cos θ0 ] E[W 2i ]‖x‖‖y‖, (6)
where a ∈",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
"[0, 1) is the LReLU gradient parameter.
",3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
This is just a slightly more involved calculation than the ReLU case; we defer our proof to the supplementary material.,3.1. Kernels for Rotationally-Invariant Weights,[0],[0]
In this section we approximate k for large m and more general weight PDFs.,3.2. Asymptotic Kernels,[0],[0]
"We invoke the CLT as m → ∞, which requires a condition that we discuss briefly before presenting it formally.",3.2. Asymptotic Kernels,[0],[0]
"The dot product w·x can be seen as a linear combination of the weights, with the coefficients corresponding to the coordinates of x. Roughly, such a linear combination will obey the CLT if many coefficients are non-zero.",3.2. Asymptotic Kernels,[0],[0]
"To let m → ∞, we construct a sequence of inputs {x(m)}∞m=2.",3.2. Asymptotic Kernels,[0],[0]
"This may appear unusual in the context of neural networks, since m is fixed and finite in practice.",3.2. Asymptotic Kernels,[0],[0]
"The sequence is used only for asymptotic analysis.
",3.2. Asymptotic Kernels,[0],[0]
"As an example if the dataset were CelebA (Liu et al., 2015) with 116412 inputs, one would have x(116412).",3.2. Asymptotic Kernels,[0],[0]
"To generate an artificial sequence, one could down-sample the image to be of size 116411, 116410, and so on.",3.2. Asymptotic Kernels,[0],[0]
"At each point in the sequence, one could normalize the point so that its `2 norm is ‖x(116412)‖. One could similarly up-sample the image.
",3.2. Asymptotic Kernels,[0],[0]
"Intuitively, if the up-sampled image does not just insert zeros, as m increases the we expect the ratio |x",3.2. Asymptotic Kernels,[0],[0]
"(m) i |
‖x(m)‖ to decrease because the denominator stays fixed and the numerator gets smaller.",3.2. Asymptotic Kernels,[0],[0]
In our proof the application of CLT requires maxmi=1 |x(m)i,3.2. Asymptotic Kernels,[0],[0]
"| ‖x(m)‖ to decrease faster than m
1/4.",3.2. Asymptotic Kernels,[0],[0]
"Hypothesis 5 states this condition precisely.
",3.2. Asymptotic Kernels,[0],[0]
Hypothesis 5.,3.2. Asymptotic Kernels,[0],[0]
"For x(m),y(m) ∈ Rm, define sequences of inputs {x(m)}∞m=2 and {y(m)}∞m=2 with fixed ‖x(m)‖=‖x‖, ‖y(m)‖=‖y‖, and θ0= cos−1 x (m)·y(m) ‖x‖‖y‖ for all m.
Letting x(m)i be the i th coordinate of x(m),
assume that lim m→∞
m(1/4)",3.2. Asymptotic Kernels,[0],[0]
maxmi=1 |x(m)i,3.2. Asymptotic Kernels,[0],[0]
"| ‖x‖ and
lim m→∞
m(1/4)",3.2. Asymptotic Kernels,[0],[0]
maxmi=1 |y(m)i,3.2. Asymptotic Kernels,[0],[0]
"| ‖y‖ are both 0.
",3.2. Asymptotic Kernels,[0],[0]
"Figures 2 and 5 empirically investigate Hypothesis 5 for two datasets, suggesting it makes reasonable assumptions on high dimensional data such as images and audio.",3.2. Asymptotic Kernels,[0],[0]
Theorem 6.,3.2. Asymptotic Kernels,[0],[0]
Consider an infinitely wide FC layer with almost everywhere continuous activation functions σ.,3.2. Asymptotic Kernels,[0],[0]
Suppose the random weights W come from an IID distribution with PDF fm such that E[Wi] = 0 and E|W 3i,3.2. Asymptotic Kernels,[0],[0]
| <∞. Suppose that the conditions in Hypothesis 5 are satisfied.,3.2. Asymptotic Kernels,[0],[0]
"Then
σ(W(m) · x(m))σ(W(m) · y(m)) D−→ σ(Z1)σ(Z2),
where D−→ denotes convergence in distribution and Z = (Z1, Z2) T is a Gaussian random vector with covari-
ance matrix E[W 2i ]",3.2. Asymptotic Kernels,[0],[0]
"[
‖x‖2 ‖x‖‖y‖ cos θ0 ‖x‖‖y‖ cos θ0 ‖y‖2
] and
0 mean.",3.2. Asymptotic Kernels,[0],[0]
"Every Z(m) = (W(m) · x(m),W(m) ·",3.2. Asymptotic Kernels,[0],[0]
"y(m))T has the same mean and covariance matrix as Z.
Convergence in distribution is a weak form of convergence, so we cannot expect in general that all kernels should converge asymptotically.",3.2. Asymptotic Kernels,[0],[0]
"For some special cases however, this is indeed possible to show.",3.2. Asymptotic Kernels,[0],[0]
"We first present the ReLU case.
",3.2. Asymptotic Kernels,[0],[0]
Corollary 7.,3.2. Asymptotic Kernels,[0],[0]
"Let m, W, fm, E[Wi] and E|W 3i | be as defined in Theorem 6.",3.2. Asymptotic Kernels,[0],[0]
"Define the corresponding kernel to be k
(m) f
( x(m),y(m) ) .",3.2. Asymptotic Kernels,[0],[0]
Consider a second infinitely wide FC layer with m inputs.,3.2. Asymptotic Kernels,[0],[0]
Suppose the random weights come from a spherical Gaussian with E[Wi] = 0 and finite variance E[W 2i ] with PDF gm.,3.2. Asymptotic Kernels,[0],[0]
"Define the corresponding kernel to be k(m)g ( x(m),y(m) ) .",3.2. Asymptotic Kernels,[0],[0]
Suppose that the conditions in Hypothesis 5 are satisfied and the activation functions are σ(z) = Θ(z)z.,3.2. Asymptotic Kernels,[0],[0]
"Then for all s ≥ 2,
lim m→∞
k (m) f
( x(m),y(m) ) = k(s)g",3.2. Asymptotic Kernels,[0],[0]
"( x(s),y(s) )",3.2. Asymptotic Kernels,[0],[0]
"= E [ σ(Z1)σ(Z2) ] ,
where Z is as in Theorem 6.",3.2. Asymptotic Kernels,[0],[0]
"Explicitly, k(m)f converges to (3).
",3.2. Asymptotic Kernels,[0],[0]
The proof is given in Appendix D. This implies that the Arc-Cosine Kernel is well approximated by ReLU layers with weights from a wide class of distributions.,3.2. Asymptotic Kernels,[0],[0]
"Similar results hold for other σ including the LReLU and ELU (Clevert et al., 2016), as shown in the supplementary material.",3.2. Asymptotic Kernels,[0],[0]
We empirically verify our results using two families of weight distributions.,4. Empirical Verification of Results,[0],[0]
"First, consider the m-dimensional tdistribution
f(w) = Γ[(ν",4. Empirical Verification of Results,[0],[0]
+m)/2] Γ(ν/2)νm/2πm/2,4. Empirical Verification of Results,[0],[0]
"√ |det(Σ)|[
1 + 1
ν (wTΣ−1w)
]−(ν+m)/2 ,
with degrees of freedom ν and identity shape matrix Σ = I .",4. Empirical Verification of Results,[0],[0]
The multivariate t-distribution approaches the multivariate Gaussian as ν → ∞. Random variables drawn from the multivariate t-distribution are uncorrelated but not independent.,4. Empirical Verification of Results,[0],[0]
"This distribution is rotationally-invariant and satisfies the conditions in Propositions (1) and (4).
",4. Empirical Verification of Results,[0],[0]
"Second, consider the multivariate distribution
f(w) = m∏ i=1
β
2αΓ(1/β) e−|wi/α|
β
, (7)
which is not rotationally-invariant (except when β = 2, which coincides with a Gaussian distribution) but whose random variables are IID and satisfy the conditions in Theorem 6.",4. Empirical Verification of Results,[0],[0]
"As β → ∞ this distribution converges pointwise to the uniform distribution on [−α, α].
",4. Empirical Verification of Results,[0],[0]
"In Figure 3, we empirically verify Propositions 1 and 4.",4. Empirical Verification of Results,[0],[0]
"In the one hidden layer case, the samples follow the blue curve j = 1, regardless of the specific multivariate t weight distribution which varies with ν.",4. Empirical Verification of Results,[0],[0]
"We also observe that the universality of the equivalent kernel appears to hold for the distribution (7) regardless of the value of β, as predicted by theory.",4. Empirical Verification of Results,[0],[0]
We discuss the relevance of the curves j 6= 1 in Section 5.,4. Empirical Verification of Results,[0],[0]
"A recent advancement in understanding the difficulty in training deep neural networks is the identification of the shattered gradients problem (Balduzzi et al., 2017).",5.1. Composed Kernels in Deep Networks,[0],[0]
"Without skip connections, the gradients of deep networks approach white noise as they are backpropagated through the network, making them difficult to train.
",5.1. Composed Kernels in Deep Networks,[0],[0]
A simple observation that complements this view is obtained through repeated composition of the normalized kernel.,5.1. Composed Kernels in Deep Networks,[0],[0]
"As m → ∞, the angle between two inputs in the jth layer of a LReLU network random weights with E[W ] = 0 and E|W 3| < ∞ approaches cos θj =
1 1+a2 ( (1−a)2 π ( sin θj−1+(π−θj−1) cos θj−1 ) +2a",5.1. Composed Kernels in Deep Networks,[0],[0]
"cos θ0 ) .
",5.1. Composed Kernels in Deep Networks,[0],[0]
"A result similar to the following is hinted at by Lee et al. (2017), citing Schoenholz et al. (2017).",5.1. Composed Kernels in Deep Networks,[0],[0]
"Their analysis, which considers biases in addition to weights (Poole et al., 2016), yields insights on the trainability of random neural networks that our analysis cannot.",5.1. Composed Kernels in Deep Networks,[0],[0]
"However, their argument does not appear to provide a complete formal proof for the case when the activation functions are unbounded, e.g., ReLU.",5.1. Composed Kernels in Deep Networks,[0],[0]
"The degeneracy of the composed kernel with more general activation functions is also proved by Daniely (2016), with the assumption that the weights are Gaussian distributed.",5.1. Composed Kernels in Deep Networks,[0],[0]
Corollary 8.,5.1. Composed Kernels in Deep Networks,[0],[0]
"The normalized kernel corresponding to LReLU activations converges to a fixed point at θ∗ = 0.
",5.1. Composed Kernels in Deep Networks,[0],[0]
Proof.,5.1. Composed Kernels in Deep Networks,[0],[0]
"Let z = cos θj−1 and define
T (z)= 1
1 + a2 ( (1− a)2 π (√ 1− z2+(π−cos−1 z)z ) +2az ) .
",5.1. Composed Kernels in Deep Networks,[0],[0]
The magnitude of the derivative of T is ∣∣∣1−(,5.1. Composed Kernels in Deep Networks,[0],[0]
"1−a1+a)2 cos−1 zπ ∣∣∣
which is bounded above by 1 on [−1, 1].",5.1. Composed Kernels in Deep Networks,[0],[0]
"Therefore, T is a contraction mapping.",5.1. Composed Kernels in Deep Networks,[0],[0]
"By Banach’s fixed point theorem there exists a unique fixed point z∗ = cos θ∗. Set θ∗ = 0 to verify that θ∗ = 0 is a solution, and θ∗ is unique.
",5.1. Composed Kernels in Deep Networks,[0],[0]
"Corollary 8 implies that for this deep network, the angle between any two signals at a deep layer approaches 0.",5.1. Composed Kernels in Deep Networks,[0],[0]
"No matter what the input is, the kernel “sees” the same thing after accounting for the scaling induced by the norm of the input.",5.1. Composed Kernels in Deep Networks,[0],[0]
"Hence, it becomes increasingly difficult to train deeper networks, as much of the information is lost and the outputs will depend merely on the norm of the inputs; the signals decorrelate as they propagate through the layers.
",5.1. Composed Kernels in Deep Networks,[0],[0]
At first this may seem counter-intuitive.,5.1. Composed Kernels in Deep Networks,[0],[0]
"An appeal to intuition can be made by considering the corresponding linear network with deterministic and equal weight matrices in each layer, which amounts to the celebrated power iteration method.",5.1. Composed Kernels in Deep Networks,[0],[0]
"In this case, the repeated application of a matrix transformation A to a vector v converges to the dominant eigenvector (i.e. the eigenvector corresponding to the largest eigenvalue) of A.
Figure 3 shows that the theoretical normalized kernel for networks of increasing depth closely follows empirical samples from randomly initialized neural networks.
",5.1. Composed Kernels in Deep Networks,[0],[0]
"In addition to convergence of direction, by also requiring that ‖x‖ = ‖y‖ it can be shown that after accounting for scaling, the magnitude of the signals converge as the signals propagate through the network.",5.1. Composed Kernels in Deep Networks,[0],[0]
"This is analogous to having the dominant eigenvalue equal to 1 in the power iteration method comparison.
",5.1. Composed Kernels in Deep Networks,[0],[0]
Corollary 9.,5.1. Composed Kernels in Deep Networks,[0],[0]
"The quantity E [( σ(j)(x) −
σ(j)(y) )2]
/E[σ(j)(x)2] in a j-layer random (L)ReLU network of infinite width with random uncorrelated and identically distributed rotationally-invariant weights with ‖x‖=‖y‖ approaches 0 as j →∞.
Proof.",5.1. Composed Kernels in Deep Networks,[0],[0]
Denote the output of one neuron in the jth layer of a network σ(W (1) ·σ(...σ(W (j)x)) by σ(j)(x) and let kj be the kernel for the j-layer network.,5.1. Composed Kernels in Deep Networks,[0],[0]
"Then
E",5.1. Composed Kernels in Deep Networks,[0],[0]
"[( σ(j)(x)− σ(j)(y) )2] /E[σ(j)(x)2]
= ( kj(x,x)− 2kj(x,y) + kj(y,y) )",5.1. Composed Kernels in Deep Networks,[0],[0]
"/kj(x,x),
= 2− 2 cos θj
which approaches 0 as j →∞.
Contrary to the shattered gradients analysis, which applies to gradient based optimizers, our analysis relates to any optimizers that initialize weights from some distribution satisfying conditions in Proposition 4 or Corollary 7.",5.1. Composed Kernels in Deep Networks,[0],[0]
"Since information is lost during signal propagation, the network’s output shares little information with the input.",5.1. Composed Kernels in Deep Networks,[0],[0]
"An
optimizer that tries to relate inputs, outputs and weights through a suitable cost function will be “blind” to relationships between inputs and outputs.
",5.1. Composed Kernels in Deep Networks,[0],[0]
"Our results can be used to argue against the utility of controversial Extreme Learning Machines (ELM) (Huang et al., 2004), which randomly initialize hidden layers from symmetric distributions and only learn the weights in the final layer.",5.1. Composed Kernels in Deep Networks,[0],[0]
A single layer ELM can be replaced by kernel ridge regression using the equivalent kernel.,5.1. Composed Kernels in Deep Networks,[0],[0]
"Furthermore, a Multi-Layer ELM (Tang et al., 2016) with (L)ReLU activations utilizes a pathological kernel as shown in Figure 3.",5.1. Composed Kernels in Deep Networks,[0],[0]
"It should be noted that ELM bears resemblance to early works (Schmidt et al., 1992; Pao et al., 1994).",5.1. Composed Kernels in Deep Networks,[0],[0]
Suppose we wish to approximately preserve the `2 norm from the input to hidden layer.,5.2. Initialization,[0],[0]
"By comparing (1) and (2), we approximately have ‖h(x)‖ ≈ √ k(x,x)n.",5.2. Initialization,[0],[0]
"Letting
θ0 = 0 in (6), we have ‖h(x)‖ = ‖x‖ √ nE[W 2i ](1+a2) 2 .",5.2. Initialization,[0],[0]
"Setting ‖h(x)‖ = ‖x‖,
√ E[W 2i ] = √√√√ 2( 1 + a2 ) n .",5.2. Initialization,[0],[0]
"(8)
This applies whenever the conditions in Proposition 4 or Corollary 12 are satisfied.",5.2. Initialization,[0],[0]
"This agrees with the well-known case when the elements of W are IID (He et al., 2015) and a = 0.",5.2. Initialization,[0],[0]
"For small values of a, (8) is well approximated by the known result (He et al., 2015).",5.2. Initialization,[0],[0]
"For larger values of a, this approximation breaks down, as shown in Figure 4.
",5.2. Initialization,[0],[0]
"An alternative approach to weight initialization is the datadriven approach (Mishkin & Matas, 2016), which can be applied to more complicated network structures such as
convolutional and max-pooling layers commonly used in practice.",5.2. Initialization,[0],[0]
"As parameter distributions change during training, batch normalization inserts layers with learnable scaling and centering parameters at the cost of increased computation and complexity (Ioffe & Szegedy, 2015).",5.2. Initialization,[0],[0]
We have considered universal properties of MLPs with weights coming from a large class of distributions.,6. Conclusion,[0],[0]
We have theoretically and empirically shown that the equivalent kernel for networks with an infinite number of hidden ReLU neurons and all rotationally-invariant weight distributions is the Arc-Cosine Kernel.,6. Conclusion,[0],[0]
The CLT can be applied to approximate the kernel for high dimensional input data.,6. Conclusion,[0],[0]
"When the activations are LReLUs, the equivalent kernel has a similar form.",6. Conclusion,[0],[0]
"The kernel converges to a fixed point, showing that information is lost as signals propagate through the network.
",6. Conclusion,[0],[0]
"One avenue for future work is to study the equivalent kernel for different activation functions, noting that some activations such as the ELU may not be expressible in a closed form (we do show in the supplementary material however, that the ELU does have an asymptotically universal kernel).
",6. Conclusion,[0],[0]
"Since wide networks with centered weight distributions have approximately the same equivalent kernel, powerful trained deep and wide MLPs with (L)ReLU activations should have asymmetric, non-zero mean, non-IID parameter distributions.",6. Conclusion,[0],[0]
Future work may consider analyzing the equivalent kernels of trained networks and more complicated architectures.,6. Conclusion,[0],[0]
"We should not expect that k(x,y) may be expressed neatly as k(θ0) in these cases.",6. Conclusion,[0],[0]
This work is a crucial first step in identifying invariant properties in neural networks and sets a foundation from which we hope to expand in future.,6. Conclusion,[0],[0]
Proof.,A. Proof of Proposition 2,[0],[0]
"The kernel with weight PDF f(ω) and ReLU σ is
k(x,y) = ∫",A. Proof of Proposition 2,[0],[0]
Rm Θ(ω · x)Θ(ω · y)(ω · x)(ω · y)f(ω) dω.,A. Proof of Proposition 2,[0],[0]
"Let θ0 be the angle between x and y. Define u = (‖x‖, 0, ..., 0)T and v = (‖y‖ cos θ0, ‖y‖ sin θ0, 0, ..., 0)T with u,",A. Proof of Proposition 2,[0],[0]
v ∈ Rm.,A. Proof of Proposition 2,[0],[0]
"Following Cho & Saul (2009), there exists some m×m rotation matrix R such that x = Ru and y = Rv.",A. Proof of Proposition 2,[0],[0]
"We have
k(x,y) = ∫",A. Proof of Proposition 2,[0],[0]
"Rm Θ(ω ·Ru)Θ(ω ·Rv)(ω ·Ru)(ω ·Rv)
f(ω) dω.
",A. Proof of Proposition 2,[0],[0]
"Let ω = Rw and note that the dot product is invariant under rotations and the determinant of the Jacobian of the
transformation is 1 since R is orthogonal.",A. Proof of Proposition 2,[0],[0]
"We have
k(x,y) = ∫",A. Proof of Proposition 2,[0],[0]
"Rm Θ(w · u)Θ(w · v)(w · u)(w · v)
f(Rw) dw,
= ∫",A. Proof of Proposition 2,[0],[0]
"Rm Θ(‖x‖w1)Θ(‖y‖(w1 cos θ0 + w2 sin θ0))
w1(w1 cos θ0 + w2 sin θ0)f(w) dw‖x‖‖y‖. (9)
One may view the integrand as a functional acting on test functions of θ0.",A. Proof of Proposition 2,[0],[0]
"Denote the set of infinitely differentiable test functions on (0, π) by C∞c (0, π).",A. Proof of Proposition 2,[0],[0]
"The linear functional acting over C∞c (0, π) is a Generalized Function and we may take distributional derivatives under the integral by Theorem 7.40 of Jones (1982).",A. Proof of Proposition 2,[0],[0]
"Differentiating twice,
k′′ + k
= ∫",A. Proof of Proposition 2,[0],[0]
"Rm Θ(w1)w1(−w1 sin θ0 + w2 cos θ0)2
δ ( w1 cos θ0 + w2 sin θ0 ) f(w) dw‖x‖‖y‖,
= ∫ Rm−1 f",A. Proof of Proposition 2,[0],[0]
"( (s sin θ0,−s cos θ0, w3, ..., wm)T )
Θ(s)s3 ds",A. Proof of Proposition 2,[0],[0]
dw3 dw4...,A. Proof of Proposition 2,[0],[0]
dwm‖x‖‖y‖ sin θ0.,A. Proof of Proposition 2,[0],[0]
The initial condition k(π) = 0 is obtained by putting θ0 = π in (9) and noting that the resulting integrand contains a factor of Θ(w1)Θ(−w1)w1 which is 0 everywhere.,A. Proof of Proposition 2,[0],[0]
"Similarly, the integrand of k′(π) contains a factor of Θ(w2)Θ(−w2)w2.",A. Proof of Proposition 2,[0],[0]
"The ODE is meant in a distributional sense, that∫ π 0 ψ(θ0) ( k′′(θ0) +",A. Proof of Proposition 2,[0],[0]
k(θ0)− F (θ0) ),A. Proof of Proposition 2,[0],[0]
"dθ0 = 0 ∀ψ ∈ Cc∞(0, π), where k is a distribution with a distributional second derivative k′′.",A. Proof of Proposition 2,[0],[0]
Proof.,B. Proof of Proposition 3,[0],[0]
Denote the marginal PDF of the first two coordinates of W by f12.,B. Proof of Proposition 3,[0],[0]
"Due to the rotational invariance of f , f(Ox) = f(‖x‖) = f(x) for any orthogonal matrix O. So
F (θ0) = ∫ Rm−1 f ( (s sin θ0,−s cos θ0, w3, ..., wm)T ) sin θ0Θ(s)s 3 ds dw3, ...",B. Proof of Proposition 3,[0],[0]
"dwm‖x‖‖y‖,
= sin θ0 ∫ R Θ(s)s3f12",B. Proof of Proposition 3,[0],[0]
"( (s, 0, )T ) ds‖x‖‖y‖,
= K sin θ0, K ∈ (0,∞].",B. Proof of Proposition 3,[0],[0]
"It remains to check that K <∞. F is integrable since∫
R2 ∫ π 0 Θ(w1)w1(−w1 sin θ0 + w2 cos θ0)2
δ(w1 cos θ0 + w2 sin θ0)f12(w1, w2)dθ0dw1dw2
= ∫ R2 Θ(w1)w1 ∣∣(w21 + w22)1/2∣∣f12(w1, w2)dw1dw2,
≤",B. Proof of Proposition 3,[0],[0]
√ E,B. Proof of Proposition 3,[0],[0]
[ Θ2(W1)W 21 ]√ E,B. Proof of Proposition 3,[0],[0]
"[ W 21 +W 2 2 ] <∞.
Therefore, F is finite almost everywhere.",B. Proof of Proposition 3,[0],[0]
This is only true if K < ∞. k′′ = F,B. Proof of Proposition 3,[0],[0]
"− k must be a function, so the distributional and classical derivatives coincide.",B. Proof of Proposition 3,[0],[0]
Proof.,C. Proof of Theorem 6,[0],[0]
"There exist some orthonormal R1,R2∈Rm such that y(m)=‖y(m)‖(R1 cos θ0 + R2 sin θ0) and x(m) = ‖x(m)‖R1.",C. Proof of Theorem 6,[0],[0]
We would like to examine the asymptotic distribution of σ ( ‖y(m)‖W(m)·,C. Proof of Theorem 6,[0],[0]
"( R1 cos θ0+R2 sin θ0
))",C. Proof of Theorem 6,[0],[0]
σ,C. Proof of Theorem 6,[0],[0]
"( ‖x(m)‖W(m)·R1 ) .
",C. Proof of Theorem 6,[0],[0]
"Let U (m)1 =W ·R1 cos θ0 + W ·R2 sin θ0 and U
(m) 2 = −W·R1 sin θ0+W·R2 cos θ0.",C. Proof of Theorem 6,[0],[0]
"Note that
E[U (m)21 ]=E[U (m)2 2 ]=E[W 2i ] and E[U (m) 1 ]=E[U (m) 2 ]=0.",C. Proof of Theorem 6,[0],[0]
Also note that U (m)1 and U (m) 2 are uncorrelated since E[U (m)1 U (m) 2 ] = E [ (W·R1)(W·R2)(cos2 θ0+sin2,C. Proof of Theorem 6,[0],[0]
"θ0)−
cos θ0 sin θ0 ( (W ·R1)2 − (W ·R2)2 )]",C. Proof of Theorem 6,[0],[0]
"= 0.
LetMk = E ∣∣W ki ∣∣, U(m) = (U1, U2)T , I be the 2×2 iden-
tity matrix and Q ∼ N ( 0,M2I ) .",C. Proof of Theorem 6,[0],[0]
"Then for any convex set S ∈ R2 and some C ∈ R, by the Berry-Esseen Theorem,∣∣P[U ∈ S]− P[Q ∈ S]∣∣2 ≤ Cγ2 where γ2 is given by( m∑ j=1 E ∥∥∥M −122",C. Proof of Theorem 6,[0],[0]
"Wi I ( R1j cos θ0 +R2j sin θ0−R1j sin θ0 +R2j cos θ0
)∥∥∥3)2, = ( M −3 2
2 M3 m∑ j=1 E ∥∥∥( R1j cos θ0 +R2j sin θ0−R1j sin θ0 +R2j cos θ0 )∥∥∥3)2, = ( M −3 2
2 M3 m∑ j=1 ∣∣∣R21j",C. Proof of Theorem 6,[0],[0]
"+R22j∣∣∣(3/2))2, ≤M−32 M23m
m∑ j=1 ∣∣∣R21j +R22j∣∣∣3, = M−32 M 2 3m
m∑ j=1 ∣∣∣R61j + 3R41jR22j + 3R21jR42j",C. Proof of Theorem 6,[0],[0]
"+R62j∣∣∣, ≤M−32 M23m ( 4
m max k=1 R41k",C. Proof of Theorem 6,[0],[0]
"+ 4 m max k=1 R42k
) .
",C. Proof of Theorem 6,[0],[0]
The last line is due to the fact that m∑ j=1 ∣∣∣R61j + 3R41jR22j∣∣∣ ≤,C. Proof of Theorem 6,[0],[0]
"mmax k=1 R41k ( m∑ j=1 R21j + 3R 2 2j ) .
",C. Proof of Theorem 6,[0],[0]
Now R1k =,C. Proof of Theorem 6,[0],[0]
"xk‖x‖ and R2k = 1
sin θ0
( yk ‖y‖",C. Proof of Theorem 6,[0],[0]
"− xk ‖x‖ cos θ0 ) ,
so if θ0 6= 0, π by Hypothesis 5 U(m) converges in distribution to the bivariate spherical Gaussian with variance E[W 2i ].",C. Proof of Theorem 6,[0],[0]
Then the random vector Z(m) =,C. Proof of Theorem 6,[0],[0]
"(Z (m) 1 , Z (m) 2 ) T =
( ‖x‖W ·R1, ‖y‖(W ·R1 cos θ0 + W ·R2 sin θ0) )",C. Proof of Theorem 6,[0],[0]
"T =(
‖x‖(U1 cos θ0−U2 sin θ0), ‖y‖U1 )T
converges in distribution to the bivariate Gaussian random variable with covariance matrix E[W 2i ]",C. Proof of Theorem 6,[0],[0]
"[
‖x‖2 ‖x‖‖y‖ cos θ0 ‖x‖‖y‖ cos θ0 ‖y‖2
] .
Since σ is continuous almost everywhere, by the Continuous Mapping Theorem,
σ(W(m) · x(m))σ(W(m) · y(m))",C. Proof of Theorem 6,[0],[0]
D−→ σ(Z1)σ(Z2).,C. Proof of Theorem 6,[0],[0]
"If θ0 = 0 or θ0 = π, we may treat R2 as 0 and the above still holds.",C. Proof of Theorem 6,[0],[0]
Proof.,D. Proof of Corollary 7,[0],[0]
"We have limm→∞ k (m) f
( x(m),y(m) )",D. Proof of Corollary 7,[0],[0]
"=
limm→∞ E [ σ(Z (m) 1 )σ(Z (m) 2 ) ] and would like to bring the limit inside the expected value.",D. Proof of Corollary 7,[0],[0]
"By Theorem 6 and Theorem 25.12 of Billingsley (1995), it suffices to show that σ(Z(m)1 )σ(Z (m) 2 ) is uniformly integrable.",D. Proof of Corollary 7,[0],[0]
Define h to be the joint PDF of Z(m).,D. Proof of Corollary 7,[0],[0]
"We have
lim α→∞ ∫ |σ(z1)σ(z2)|>α |σ(z1)σ(z2)|h(z1, z2) dz1dz2
",D. Proof of Corollary 7,[0],[0]
= lim,D. Proof of Corollary 7,[0],[0]
"α→∞ ∫ |Θ(z1)Θ(z2)z1z2|>α |Θ(z1)Θ(z2)z1z2|h(z1, z2)
dz1dz2,
but the integrand is 0 whenever z1 ≤ 0 or z2 ≤ 0.",D. Proof of Corollary 7,[0],[0]
So∫ |σ(z1)σ(z2)|>α,D. Proof of Corollary 7,[0],[0]
"|σ(z1)σ(z2)|h(z1, z2) dz1dz2
= ∫ R2 z1z2Θ(z1z2 − α)Θ(z1)Θ(z2)h(z1, z2) dz1dz2.
",D. Proof of Corollary 7,[0],[0]
We may raise the Heaviside functions to any power without changing the value of the integral.,D. Proof of Corollary 7,[0],[0]
"Squaring the Heaviside functions and applying Hölder’s inequality, we have(∫
R2 z1z2Θ
2(z1z2 − α)Θ2(z1)Θ2(z2)h(z1, z2)dz1dz2 )2
≤ E[z21Θ(z1z2 − α)Θ(z1)Θ(z2)]",D. Proof of Corollary 7,[0],[0]
E[z22Θ(z1z2,D. Proof of Corollary 7,[0],[0]
"− α)Θ(z1)Θ(z2)].
",D. Proof of Corollary 7,[0],[0]
"Examining the first of these factors,∫ ∞ 0 ∫ ∞ α/z1 z21h(z1, z2) dz2dz1,
= ∫ ∞ 0 z21 ∫ ∞ α/z1 h(z1, z2) dz2dz1.
",D. Proof of Corollary 7,[0],[0]
Now let gα(z1) =,D. Proof of Corollary 7,[0],[0]
"∫∞ α/z1
h(z1, z2) dz2.",D. Proof of Corollary 7,[0],[0]
gα(z1)z21 is monotonically pointwise non-increasing to 0 in α for all z1 > 0 and ∫ z21g0(z1)dz1 ≤ E[Z21 ],D. Proof of Corollary 7,[0],[0]
<∞ .,D. Proof of Corollary 7,[0],[0]
By the Monotone Convergence Theorem limα→∞ E[z21Θ(z1z2 − α)Θ(z1)],D. Proof of Corollary 7,[0],[0]
= 0.,D. Proof of Corollary 7,[0],[0]
"The second factor has the same limit, so the limit of the right hand side of Hölder’s inequality is 0.",D. Proof of Corollary 7,[0],[0]
We thank the anonymous reviewers for directing us toward relevant work and providing helpful recommendations regarding the presentation of the paper.,Acknowledgements,[0],[0]
Farbod Roosta-Khorasani gratefully acknowledges the support from the Australian Research Council through a Discovery Early Career Researcher Award (DE180100923).,Acknowledgements,[0],[0]
Russell Tsuchida’s attendance at the conference was made possible by an ICML travel award.,Acknowledgements,[0],[0]
An interesting approach to analyzing neural networks that has received renewed attention is to examine the equivalent kernel of the neural network.,abstractText,[0],[0]
"This is based on the fact that a fully connected feedforward network with one hidden layer, a certain weight distribution, an activation function, and an infinite number of neurons can be viewed as a mapping into a Hilbert space.",abstractText,[0],[0]
"We derive the equivalent kernels of MLPs with ReLU or Leaky ReLU activations for all rotationally-invariant weight distributions, generalizing a previous result that required Gaussian weight distributions.",abstractText,[0],[0]
"Additionally, the Central Limit Theorem is used to show that for certain activation functions, kernels corresponding to layers with weight distributions having 0 mean and finite absolute third moment are asymptotically universal, and are well approximated by the kernel corresponding to layers with spherical Gaussian weights.",abstractText,[0],[0]
"In deep networks, as depth increases the equivalent kernel approaches a pathological fixed point, which can be used to argue why training randomly initialized networks can be difficult.",abstractText,[0],[0]
Our results also have implications for weight initialization.,abstractText,[0],[0]
Invariance of Weight Distributions in Rectified MLPs,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3110–3119 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
3110",text,[0],[0]
Modeling articles or sentences computationally is a fundamental topic in natural language processing.,1 Introduction,[0],[0]
"It could be as simple as a keyword/phrase matching problem, but it could also be a nontrivial problem if compositions, hierarchies, and structures of texts are considered.",1 Introduction,[0],[0]
"For example, a news article which mentions a single phrase “US election” may be categorized into the political news with high probability.",1 Introduction,[0],[0]
"But it could be very difficult for a computer to predict which presidential candidate is favored by its author, or whether the
∗ Corresponding author (min.yang@siat.ac.cn) 1Codes are publicly available at: https:
//github.com/andyweizhao/capsule_text_ classification.
author’s view in the article is more liberal or more conservative.
",1 Introduction,[0],[0]
"Earlier efforts in modeling texts have achieved limited success on text categorization using a simple bag-of-words classifier (Joachims, 1998; McCallum et al., 1998), implying understanding the meaning of the individual word or n-gram is a necessary step towards more sophisticated models.",1 Introduction,[0],[0]
"It is therefore not a surprise that distributed representations of words, a.k.a. word embeddings, have received great attention from NLP community addressing the question “what” to be modeled at the basic level (Mikolov et al., 2013; Pennington et al., 2014).",1 Introduction,[0],[0]
"In order to model higher level concepts and facts in texts, an NLP researcher has to think cautiously the so-called “what” question: what is actually modeled beyond word meanings.",1 Introduction,[0],[0]
"A common approach to the question is to treat the texts as sequences and focus on their spatial patterns, whose representatives include convolutional neural networks (CNNs) (Kim, 2014; Zhang et al., 2015; Conneau et al., 2017) and long shortterm memory networks (LSTMs) (Tai et al., 2015; Mousa and Schuller, 2017).",1 Introduction,[0],[0]
"Another common approach is to completely ignore the order of words but focus on their compositions as a collection, whose representatives include probabilistic topic modeling (Blei et al., 2003; Mcauliffe and Blei, 2008) and Earth Mover’s Distance based modeling (Kusner et al., 2015; Ye et al., 2017).
",1 Introduction,[0],[0]
"Those two approaches, albeit quite different from the computational perspective, actually follow a common measure to be diagnosed regarding their answers to the “what” question.",1 Introduction,[0],[0]
"In neural network approaches, spatial patterns aggregated at lower levels contribute to representing higher level concepts.",1 Introduction,[0],[0]
"Here, they form a recursive process to articulate what to be modeled.",1 Introduction,[0],[0]
"For example, CNN builds convolutional feature detectors to extract local patterns from a window of vector sequences
and uses max-pooling to select the most prominent ones.",1 Introduction,[0],[0]
It then hierarchically builds such pattern extraction pipelines at multiple levels.,1 Introduction,[0],[0]
"Being a spatially sensitive model, CNN pays a price for the inefficiency of replicating feature detectors on a grid.",1 Introduction,[0],[0]
"As argued in (Sabour et al., 2017), one has to choose between replicating detectors whose size grows exponentially with the number of dimensions, or increasing the volume of the labeled training set in a similar exponential way.",1 Introduction,[0],[0]
"On the other hand, methods that are spatially insensitive are perfectly efficient at the inference time regardless of any order of words or local patterns.",1 Introduction,[0],[0]
"However, they are unavoidably more restricted to encode rich structures presented in a sequence.",1 Introduction,[0],[0]
"Improving the efficiency to encode spatial patterns while keeping the flexibility of their representation capability is thus a central issue.
",1 Introduction,[0],[0]
A recent method called capsule network introduced by Sabour et al. (2017) possesses this attractive potential to address the aforementioned issue.,1 Introduction,[0],[0]
They introduce an iterative routing process to decide the credit attribution between nodes from lower and higher layers.,1 Introduction,[0],[0]
A metaphor (also as an argument) they made is that human visual system intelligently assigns parts to wholes at the inference time without hard-coding patterns to be perspective relevant.,1 Introduction,[0],[0]
"As an outcome, their model could encode the intrinsic spatial relationship between a part and a whole constituting viewpoint invariant knowledge that automatically generalizes to novel viewpoints.",1 Introduction,[0],[0]
"In our work, we follow a similar spirit to use this technique in modeling texts.",1 Introduction,[0],[0]
Three strategies are proposed to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain “background” information such as stop words and the words that are unrelated to specific categories.,1 Introduction,[0],[0]
We conduct a series of experiments with capsule networks on top of the pre-trained word vectors for six text classification benchmarks.,1 Introduction,[0],[0]
"More importantly, we show that capsule networks achieves significant improvement when transferring singlelabel to multi-label text classifications over the compared baseline methods.",1 Introduction,[0],[0]
"Our capsule network, depicted in Figure 1, is a variant of the capsule networks proposed in Sabour et al. (2017).",2 Our Methodology,[0],[0]
"It consists of four layers: ngram convolutional layer, primary capsule layer,
convolutional capsule layer, and fully connected capsule layer.",2 Our Methodology,[0],[0]
"In addition, we explore two capsule frameworks to integrate these four components in different ways.",2 Our Methodology,[0],[0]
"In the rest of this section, we elaborate the key components in detail.",2 Our Methodology,[0],[0]
"This layer is a standard convolutional layer which extracts n-gram features at different positions of a sentence through various convolutional filters.
",2.1 N -gram Convolutional Layer,[0],[0]
Suppose x ∈ RL×V denotes the input sentence representation where L is the length of the sentence and V is the embedding size of words.,2.1 N -gram Convolutional Layer,[0],[0]
Let xi ∈ RV be the V -dimensional word vector corresponding to the i-th word in the sentence.,2.1 N -gram Convolutional Layer,[0],[0]
"Let W a ∈ RK1×V be the filter for the convolution operation, where K1 is the N -gram size while sliding over a sentence for the purpose of detecting features at different positions.",2.1 N -gram Convolutional Layer,[0],[0]
"A filter W a convolves with the word-window xi:i+K1−1 at each possible position (with stride of 1) to produce a column feature map ma ∈ RL−K1+1, each element mai ∈ R of the feature map is produced by
mai = f(xi:i+K1−1 ◦W a + b0) (1)
where ◦ is element-wise multiplication, b0 is a bias term, and f is a nonlinear activate function (i.e., ReLU).",2.1 N -gram Convolutional Layer,[0],[0]
We have described the process by which one feature is extracted from one filter.,2.1 N -gram Convolutional Layer,[0],[0]
"Hence, for a = 1, . . .",2.1 N -gram Convolutional Layer,[0],[0]
", B, totally B filters with the same N -gram size, one can generate B feature maps which can be rearranged as
M =",2.1 N -gram Convolutional Layer,[0],[0]
"[m1,m2, ...,mB] ∈",2.1 N -gram Convolutional Layer,[0],[0]
R(L−K1+1)×B (2),2.1 N -gram Convolutional Layer,[0],[0]
"This is the first capsule layer in which the capsules replace the scalar-output feature detectors of CNNs with vector-output capsules to preserve the instantiated parameters such as the local order of words and semantic representations of words.
",2.2 Primary Capsule Layer,[0],[0]
"Suppose pi ∈ Rd denotes the instantiated parameters of a capsule, where d is the dimension of the capsule.",2.2 Primary Capsule Layer,[0],[0]
Let W b ∈ RB×d be the filter shared in different sliding windows.,2.2 Primary Capsule Layer,[0],[0]
"For each matrix multiplication, we have a window sliding over each N - gram vector denoted as Mi ∈ RB , then the corresponding N -gram phrases in the form of capsule are produced with pi = (W b)TMi.
",2.2 Primary Capsule Layer,[0],[0]
"The filter W b multiplies each N -gram vector in {Mi}L−K1+1i=1 with stride of 1 to produce a
column-list of capsules p ∈",2.2 Primary Capsule Layer,[0],[0]
"R(L−K1+1)×d, each capsule pi ∈ Rd in the column-list is computed as
pi = g(W bMi + b1) (3)
where g is nonlinear squash function through the entire vector, b1 is the capsule bias term.",2.2 Primary Capsule Layer,[0],[0]
"For all C filters, the generated capsule feature maps can be rearranged as
P =",2.2 Primary Capsule Layer,[0],[0]
"[p1,p2, ...,pC] ∈ R(L−K1+1)×C×d, (4)
where totally (L − K1 + 1)",2.2 Primary Capsule Layer,[0],[0]
× C d-dimensional vectors are collected as capsules in P.,2.2 Primary Capsule Layer,[0],[0]
"As argued in (Sabour et al., 2017), capsule network tries to address the representational limitation and exponential inefficiencies of convolutions with transformation matrices.",2.2.1 Child-Parent Relationships,[0],[0]
"It allows the networks to automatically learn child-parent (or partwhole) relationships constituting viewpoint invariant knowledge that automatically generalizes to novel viewpoints.
",2.2.1 Child-Parent Relationships,[0],[0]
"In this paper, we explore two different types of transformation matrices to generate prediction vector (vote) ûj|i ∈ Rd from its child capsule i to the parent capsule j. The first one shares weights W t1 ∈ RN×d×d across child capsules in the layer below, where N is the number of parent capsules in the layer above.",2.2.1 Child-Parent Relationships,[0],[0]
"Formally, each corresponding vote can be computed by:
ûj|i = W t1 j ui + b̂j|i ∈ R d (5)
where ui is a child-capsule in the layer below and b̂j|i is the capsule bias term.
",2.2.1 Child-Parent Relationships,[0],[0]
"In the second design, we replace the shared weight matrix W t1j with non-shared weight matrix W t2i,j , where the weight matrices W
t2 ∈ RH×N×d×d and H is the number of child capsules in the layer below.",2.2.1 Child-Parent Relationships,[0],[0]
"The basic idea of dynamic routing is to construct a non-linear map in an iterative manner ensuring that the output of each capsule gets sent to an appropriate parent in the subsequent layer:{
ûj|i ∈ Rd } i=1,...,H,j=1...,N 7→ { vj ∈ Rd }N j=1 .
",2.3 Dynamic Routing,[0],[0]
"For each potential parent, the capsule network can increase or decrease the connection strength by dynamic routing, which is more effective than the primitive routing strategies such as max-pooling in CNN that essentially detects whether a feature is present in any position of the text, but loses spatial information about the feature.",2.3 Dynamic Routing,[0],[0]
"We explore three strategies to boost the accuracy of routing process by alleviating the disturbance of some noisy capsules:
Orphan Category Inspired by Sabour et al. (2017), an additional “orphan” category is added to the network, which can capture the “background” information of the text such as stop words and the words that are unrelated to specific categories, helping the capsule network model the child-parent relationship more efficiently.",2.3 Dynamic Routing,[0],[0]
"Adding “orphan” category in the text is more effective than in image since there is no single consistent “background” object in images, while the stop words are
consistent in texts such as predicate “s”, “am” and pronouns “his”, “she”.
",2.3 Dynamic Routing,[0],[0]
Leaky-Softmax We explore Leaky-Softmax Sabour et al. (2017) in the place of standard softmax while updating connection strength between the children capsules and their parents.,2.3 Dynamic Routing,[0],[0]
"Despite the orphan category in the last capsule layer, we also need a light-weight method between two consecutive layers to route the noise child capsules to extra dimension without any additional parameters and computation consuming.
",2.3 Dynamic Routing,[0],[0]
"Coefficients Amendment We also attempt to use the probability of existence of child capsules in the layer below to iteratively amend the connection strength as Eq.6.
",2.3 Dynamic Routing,[0],[0]
"Algorithm 1: Dynamic Routing Algorithm 1 procedure ROUTING(ûj|i, âj|i, r, l) 2 Initialize the logits of coupling coefficients
bj|i = 0
3 for r iterations do 4 for all capsule i in layer l and capsule j in
layer l + 1: cj|i = âj|i · leaky-softmax(bj|i)
5 for all capsule j in layer l + 1: vj = g",2.3 Dynamic Routing,[0],[0]
"( ∑ i cj|iûj|i), aj = |vj",2.3 Dynamic Routing,[0],[0]
"| 6 for all capsule i in layer l and capsule j in layer l + 1: bj|i = bj|i + ûj|i · vj
7 return vj ,aj
Given each prediction vector ûj|i and its probability of existence âj|i, where âj|i = âi, each iterative coupling coefficient of connection strength cj|i is updated by
cj|i = âj|i · leaky-softmax(bj|i) (6)
where bj|i is the logits of coupling coefficients.",2.3 Dynamic Routing,[0],[0]
"Each parent capsule vj in the layer above is a weighted sum over all prediction vectors ûj|i:
vj = g",2.3 Dynamic Routing,[0],[0]
"( ∑ i cj|iûj|i), aj = |vj | (7)
where aj is the probabilities of parent capsules, g is nonlinear squash function Sabour et al. (2017) through the entire vector.",2.3 Dynamic Routing,[0],[0]
"Once all of the parent capsules are produced, each coupling coefficient bj|i is updated by:
bj|i = bj|i + ûj|i · vj (8)
For simplicity of notation, the parent capsules and their probabilities in the layer above are denoted as
v, a = Routing(û) (9)
where û denotes all of the child capsules in the layer below, v denotes all of the parent-capsules and their probabilities",2.3 Dynamic Routing,[0],[0]
"a.
Our dynamic routing algorithm is summarized in Algorithm 1.",2.3 Dynamic Routing,[0],[0]
"In this layer, each capsule is connected only to a local region K2 × C spatially in the layer below.",2.4 Convolutional Capsule Layer,[0],[0]
"Those capsules in the region multiply transformation matrices to learn child-parent relationships followed by routing by agreement to produce parent capsules in the layer above.
",2.4 Convolutional Capsule Layer,[0],[0]
Suppose W c1 ∈,2.4 Convolutional Capsule Layer,[0],[0]
RD×d×d,2.4 Convolutional Capsule Layer,[0],[0]
and,2.4 Convolutional Capsule Layer,[0],[0]
"W c2 ∈ RK2×C×D×d×d denote shared and non-shared weights, respectively, where K2 · C is the number of child capsules in a local region in the layer below, D is the number of parent capsules which the child capsules are sent to.",2.4 Convolutional Capsule Layer,[0],[0]
"When the transformation matrices are shared across the child capsules, each potential parent-capsule ûj|i is produced by
ûj|i = W c1 j ui + b̂j|i (10)
where b̂j|i is the capsule bias term, ui is a child capsule in a local region K2 × C and W c1j is the jth matrix in tensor W c1 .",2.4 Convolutional Capsule Layer,[0],[0]
"Then, we use routingby-agreement to produce parent capsules feature maps totally (L−K1−K2+2)×D d-dimensional capsules in this layer.",2.4 Convolutional Capsule Layer,[0],[0]
"When using the non-shared weights across the child capsules, we replace the transformation matrix W c1j in Eq.",2.4 Convolutional Capsule Layer,[0],[0]
(10) with W c2 j .,2.4 Convolutional Capsule Layer,[0],[0]
The capsules in the layer below are flattened into a list of capsules and fed into fully connected capsule layer in which capsules are multiplied by transformation matrix W d1 ∈ RE×d×d or W d2 ∈ RH×E×d×d followed by routing-by-agreement to produce final capsule vj ∈ Rd and its probability aj ∈ R for each category.,2.5 Fully Connected Capsule Layer,[0],[0]
"Here, H is the number of child capsules in the layer below, E is the number of categories plus an extra orphan category.",2.5 Fully Connected Capsule Layer,[0],[0]
"We explore two capsule architectures (denoted as Capsule-A and Capsule-B) to integrate these four
components in different ways, as depicted in Figure 2.
",2.6 The Architectures of Capsule Network,[0],[0]
"Capsule-A starts with an embedding layer which transforms each word in the corpus to a 300-dimensional (V = 300) word vector, followed by a 3-gram (K1 = 3) convolutional layer with 32 filters (B = 32) and a stride of 1 with ReLU non-linearity.",2.6 The Architectures of Capsule Network,[0],[0]
"All the other layers are capsule layers starting with a B × d primary capsule layer with 32 filters (C = 32), followed by a 3 × C × d ×",2.6 The Architectures of Capsule Network,[0],[0]
d,2.6 The Architectures of Capsule Network,[0],[0]
"(K2 = 3) convolutional capsule layer with 16 filters (D = 16) and a fully connected capsule layer in sequence.
",2.6 The Architectures of Capsule Network,[0],[0]
Each capsule has 16-dimensional (d = 16) instantiated parameters and their length (norm) can describe the probability of the existence of capsules.,2.6 The Architectures of Capsule Network,[0],[0]
"The capsule layers are connected by the transformation matrices, and each connection is also multiplied by a routing coefficient that is dynamically computed by routing by agreement mechanism.
",2.6 The Architectures of Capsule Network,[0],[0]
"The basic structure of Capsule-B is similar to Capsule-A except that we adopt three parallel networks with filter windows (N ) of 3, 4, 5 in the N -gram convolutional layer (see Figure 2).",2.6 The Architectures of Capsule Network,[0],[0]
The final output of the fully connected capsule layer is fed into the average pooling to produce the final results.,2.6 The Architectures of Capsule Network,[0],[0]
"In this way, Capsule-B can learn more meaningful and comprehensive text representation.",2.6 The Architectures of Capsule Network,[0],[0]
"In order to evaluate the effectiveness of our model, we conduct a series of experiments on six bench-
marks including: movie reviews (MR) (Pang and Lee, 2005), Stanford Sentiment Treebankan extension of MR (SST-2) (Socher et al., 2013), Subjectivity dataset (Subj) (Pang and Lee, 2004), TREC question dataset (TREC) (Li and Roth, 2002), customer review (CR) (Hu and Liu, 2004), and AG’s news corpus (Conneau et al., 2017).",3.1 Experimental Datasets,[0],[0]
"These benchmarks cover several text classification tasks such as sentiment classification, question categorization, news categorization.",3.1 Experimental Datasets,[0],[0]
The detailed statistics are presented in Table 1.,3.1 Experimental Datasets,[0],[0]
"In the experiments, we use 300-dimensional word2vec (Mikolov et al., 2013) vectors to initialize embedding vectors.",3.2 Implementation Details,[0],[0]
We conduct mini-batch with size 50 for AG’s news and size 25 for other datasets.,3.2 Implementation Details,[0],[0]
We use Adam optimization algorithm with 1e-3 learning rate to train the model.,3.2 Implementation Details,[0],[0]
We use 3 iteration of routing for all datasets since it optimizes the loss faster and converges to a lower loss at the end.,3.2 Implementation Details,[0],[0]
"In the experiments, we evaluate and compare our model with several widely used baseline methods including: LSTM/Bi-LSTM (Cho et al., 2014), tree-structured LSTM (Tree-LSTM)",3.3 Baseline methods,[0],[0]
"(Tai et al., 2015), LSTM regularized by linguistic knowledge (LR-LSTM)",3.3 Baseline methods,[0],[0]
"(Qian et al., 2016), CNNrand/CNN-static/CNN-non-static (Kim, 2014), very deep convolutional network (VD-CNN) (Conneau et al., 2017), and character-level convolutional network (CL-CNN) (Zhang et al., 2015).",3.3 Baseline methods,[0],[0]
"In our experiments, the evaluation metric is classification accuracy.",4.1 Quantitative Evaluation,[0],[0]
We summarize the experimental results in Table 2.,4.1 Quantitative Evaluation,[0],[0]
"From the results, we observe that the capsule networks achieve best results on 4 out of 6 benchmarks, which verifies the effectiveness of the capsule networks.",4.1 Quantitative Evaluation,[0],[0]
"In particular, our model substantially and consistently outperforms
the simple deep neural networks such as LSTM, Bi-LSTM and CNN-rand by a noticeable margin on all the experimental datasets.",4.1 Quantitative Evaluation,[0],[0]
"Capsule network also achieves competitive results against the more sophisticated deep learning models such as LR-LSTM, Tree-LSTM, VC-CNN and CL-CNN.",4.1 Quantitative Evaluation,[0],[0]
Note that Capsule-B consistently performs better than Capsule-A since Capsule-B allows to learn more meaningful and comprehensive text representation.,4.1 Quantitative Evaluation,[0],[0]
"For example, a combination of N-gram convolutional layer with filter windows of {3,4,5} can capture the 3/4/5-gram features of the text which play a crucial role in text modeling.",4.1 Quantitative Evaluation,[0],[0]
"To analyze the effect of varying different components of our capsule architecture for text classification, we also report the ablation test of the capsuleB model in terms of using different setups of the capsule network.",4.2 Ablation Study,[0],[0]
The experimental results are summarized in Table 5.,4.2 Ablation Study,[0],[0]
"Generally, all three proposed dynamic routing strategies contribute to the effectiveness of Capsule-B by alleviating the disturbance of some noise capsules which may contain “background” information such as stop words and the words that are unrelated to specific categories.",4.2 Ablation Study,[0],[0]
Capsule network demonstrates promising performance in single-label text classification which assigns a label from a predefined set to a text (see Table 2).,5 Single-Label to Multi-Label Text Classification,[0],[0]
"Multi-label text classification is, however, a
more challenging practical problem.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"From singlelabel to multi-label (with n category labels) text classification, the label space is expanded from n to 2n, thus more training is required to cover the whole label space.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"For single-label texts, it is practically easy to collect and annotate the samples.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"However, the burden of collection and annotation for a large scale multi-label text dataset is generally extremely high.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"How deep neural networks (e.g., CNN and LSTM) best cope with multi-label text classification still remains a problem since obtaining large scale of multi-label dataset is a timeconsuming and expensive process.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"In this section, we investigate the capability of capsule network on multi-label text classification by using only the single-label samples as training data.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"With feature property as part of the information extracted by capsules, we may generalize the model better to multi-label text classification without an over extensive amount of labeled data.
",5 Single-Label to Multi-Label Text Classification,[0],[0]
"The evaluation is carried on the Reuters-21578 dataset (Lewis, 1992).",5 Single-Label to Multi-Label Text Classification,[0],[0]
"This dataset consists of 10,788 documents from the Reuters financial newswire service, where each document contains either multiple labels or a single label.",5 Single-Label to Multi-Label Text Classification,[0],[0]
We reprocess the corpus to evaluate the capability of capsule networks of transferring from single-label to multi-label text classification.,5 Single-Label to Multi-Label Text Classification,[0],[0]
"For dev and training, we only use the single-label documents in the Reuters dev and training sets.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"For testing, ReutersMulti-label only uses the multi-label documents in testing dataset, while Reuters-Full includes all documents in test set.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"The characteristics of these two datasets are described in Table 3.
",5 Single-Label to Multi-Label Text Classification,[0],[0]
"Following (Sorower, 2010), we adopt Micro Averaged Precision (Precision), Micro Averaged Recall (Recall) and Micro Averaged F1 scores (F1) as the evaluation metrics for multi-label text classification.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"Any of these scores are firstly computed on individual class labels and then averaged over all classes, called label-based measures.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"In addition, we also measure the Exact Match Ratio (ER) which considers partially correct prediction as incorrect and only counts fully correct samples.
",5 Single-Label to Multi-Label Text Classification,[0],[0]
The experimental results are summarized in Table 4.,5 Single-Label to Multi-Label Text Classification,[0],[0]
"From the results, we can observe that the capsule networks have substantial and significant improvement in terms of all four evaluation metrics over the compared baseline methods on the test sets in both Reuters-Multi-label and ReutersFull datasets.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"In particular, larger improvement
is achieved on Reuters-Multi-label dataset which only contains the multi-label documents in the test set.",5 Single-Label to Multi-Label Text Classification,[0],[0]
This is within our expectation since the capsule network is capable of preserving the instantiated parameters of the categories trained by singlelabel documents.,5 Single-Label to Multi-Label Text Classification,[0],[0]
The capsule network has much stronger transferring capability than the conventional deep neural networks.,5 Single-Label to Multi-Label Text Classification,[0],[0]
"In addition, the good results on Reuters-Full also indicate that the capsule network has robust superiority over competitors on single-label documents.",5 Single-Label to Multi-Label Text Classification,[0],[0]
"To visualize the connection strength between capsule layers clearly, we remove the convolutional capsule layer and make the primary capsule layer followed by the fully connected capsule layer directly, where the primary capsules denote N-gram phrases in the form of capsules.",5.1 Connection Strength Visualization,[0],[0]
"The connection strength shows the importance of each primary capsule for text categories, acting like a parallel attention mechanism.",5.1 Connection Strength Visualization,[0],[0]
"This should allow the capsule networks to recognize multiple categories in
the text even though the model is trained on singlelabel documents.
",5.1 Connection Strength Visualization,[0],[0]
"Due to space reasons, we choose a multilabel document from Reuters-Multi-label test set whose category labels (i.e., Interest Rates and Money/Foreign Exchange) are correctly predicted (fully correct) by our model with high confidence (p > 0.8) to report in Table 6.",5.1 Connection Strength Visualization,[0],[0]
The categoryspecific phrases such as “interest rates” and “foreign exchange” are highlighted with red color.,5.1 Connection Strength Visualization,[0],[0]
We use the tag cloud to visualize the 3-gram phrases for Interest Rates and Money/Foreign Exchange categories.,5.1 Connection Strength Visualization,[0],[0]
"The stronger the connection strength, the bigger the font size.",5.1 Connection Strength Visualization,[0],[0]
"From the results, we observe that capsule networks can correctly recognize and cluster the important phrases with respect to the text categories.",5.1 Connection Strength Visualization,[0],[0]
"The histograms are used to show the intensity of connection strengths between primary capsules and the fully connected capsules, as shown in Table 6 (bottom line).",5.1 Connection Strength Visualization,[0],[0]
"Due to space reasons, five histograms are demonstrated.",5.1 Connection Strength Visualization,[0],[0]
"The routing procedure correctly routes the votes into the Interest Rates and Money/Foreign Exchange categories.
",5.1 Connection Strength Visualization,[0],[0]
"To experimentally verify the convergence of the routing algorithm, we also plot learning curve to show the training loss over time with different iterations of routing.",5.1 Connection Strength Visualization,[0],[0]
"From Figure 3, we observe that the Capsule-B with 3 or 5 iterations of routing optimizes the loss faster and converges to a lower loss at the end than the capsule network with 1 iteration.",5.1 Connection Strength Visualization,[0],[0]
"Early methods for text classification adopted the typical features such as bag-of-words, n-grams, and their TF-IDF features (Zhang et al., 2008) as
input of machine learning algorithms such as support vector machine (SVM) (Joachims, 1998), logistic regression (Genkin et al., 2007), naive Bayes (NB) (McCallum et al., 1998) for classification.",6 Related Work,[0],[0]
"However, these models usually heavily relied on laborious feature engineering or massive extra linguistic resources.
",6 Related Work,[0],[0]
Recent advances in deep neural networks and representation learning have substantially improved the performance of text classification tasks.,6 Related Work,[0],[0]
"The dominant approaches are recurrent neural networks, in particular LSTMs and CNNs.",6 Related Work,[0],[0]
"(Kim, 2014) reported on a series of experiments with CNNs trained on top of pre-trained word vectors for sentence-level classification tasks.",6 Related Work,[0],[0]
"The CNN
models improved upon the state of the art on 4 out of 7 tasks.",6 Related Work,[0],[0]
"(Zhang et al., 2015) offered an empirical exploration on the use of character-level convolutional networks (Convnets) for text classification and the experiments showed that Convnets outperformed the traditional models.",6 Related Work,[0],[0]
"(Joulin et al., 2016) proposed a simple and efficient text classification method fastText, which could be trained on a billion words within ten minutes.",6 Related Work,[0],[0]
"(Conneau et al., 2017) proposed a very deep convolutional networks (with 29 convolutional layers) for text classification.",6 Related Work,[0],[0]
"(Tai et al., 2015) generalized the LSTM to the tree-structured network topologies (Tree-LSTM) that achieved best results on two text classification tasks.
",6 Related Work,[0],[0]
"Recently, a novel type of neural network is proposed using the concept of capsules to improve the representational limitations of CNN and RNN.",6 Related Work,[0],[0]
Hinton et al. (2011) firstly introduced the concept of “capsules” to address the representational limitations of CNNs and RNNs.,6 Related Work,[0],[0]
Capsules with transformation matrices allowed networks to automatically learn part-whole relationships.,6 Related Work,[0],[0]
"Consequently, Sabour et al. (2017) proposed capsule networks that replaced the scalar-output feature detectors of CNNs with vector-output capsules and max-pooling with routing-by-agreement.",6 Related Work,[0],[0]
The capsule network has shown its potential by achieving a state-of-the-art result on MNIST data.,6 Related Work,[0],[0]
"Unlike max-pooling in CNN, however, Capsule net-
work do not throw away information about the precise position of the entity within the region.",6 Related Work,[0],[0]
"For lowlevel capsules, location information is placecoded by which capsule is active.",6 Related Work,[0],[0]
"(Xi et al., 2017) further tested out the application of capsule networks on CIFAR data with higher dimensionality.",6 Related Work,[0],[0]
"(Hinton et al., 2018) proposed a new iterative routing procedure between capsule layers based on the EM algorithm, which achieves significantly better accuracy on the smallNORB data set.",6 Related Work,[0],[0]
"(Zhang et al., 2018) generalized existing routing methods within the framework of weighted kernel density estimation.",6 Related Work,[0],[0]
"To date, no work investigates the performance of capsule networks in NLP tasks.",6 Related Work,[0],[0]
This study herein takes the lead in this topic.,6 Related Work,[0],[0]
"In this paper, we investigated capsule networks with dynamic routing for text classification.",7 Conclusion,[0],[0]
Three strategies were proposed to boost the performance of the dynamic routing process to alleviate the disturbance of noisy capsules.,7 Conclusion,[0],[0]
Extensive experiments on six text classification benchmarks show the effectiveness of capsule networks in text classification.,7 Conclusion,[0],[0]
"More importantly, capsule networks also show significant improvement when transferring single-label to multi-label text classifications over the co baseline methods.",7 Conclusion,[0],[0]
"In this study, we explore capsule networks with dynamic routing for text classification.",abstractText,[0],[0]
We propose three strategies to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain “background” information or have not been successfully trained.,abstractText,[0],[0]
A series of experiments are conducted with capsule networks on six text classification benchmarks.,abstractText,[0],[0]
"Capsule networks achieve competitive results over the compared baseline methods on 4 out of 6 datasets, which shows the effectiveness of capsule networks for text classification.",abstractText,[0],[0]
We additionally show that capsule networks exhibit significant improvement when transfer single-label to multi-label text classification over the competitors.,abstractText,[0],[0]
"To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for text modeling1.",abstractText,[0],[0]
Investigating Capsule Networks with Dynamic Routing for Text Classification,title,[0],[0]
"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1403–1414, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics",text,[0],[0]
"Computational models of meaning that rely on corpus-extracted context vectors, such as LSA (Landauer and Dumais, 1997), HAL (Lund and Burgess, 1996), Topic Models (Griffiths et al., 2007) and more recent neural-network approaches (Collobert and Weston, 2008; Mikolov et al., 2013b) have successfully tackled a number of lexical semantics tasks, where context vector similarity highly correlates with various indices of semantic relatedness (Turney and Pantel, 2010).",1 Introduction,[0],[0]
"Given that these models are learned from naturally occurring data using simple associative techniques, various authors have advanced the claim
that they might be also capturing some crucial aspects of how humans acquire and use language (Landauer and Dumais, 1997; Lenci, 2008).
",1 Introduction,[0],[0]
"However, the models induce the meaning of words entirely from their co-occurrence with other words, without links to the external world.",1 Introduction,[0],[0]
This constitutes a serious blow to claims of cognitive plausibility in at least two respects.,1 Introduction,[0],[0]
"One is the grounding problem (Harnad, 1990; Searle, 1984).",1 Introduction,[0],[0]
"Irrespective of their relatively high performance on various semantic tasks, it is debatable whether models that have no access to visual and perceptual information can capture the holistic, grounded knowledge that humans have about concepts.",1 Introduction,[0],[0]
"However, a possibly even more serious pitfall of vector models is lack of reference: natural language is, fundamentally, a means to communicate, and thus our words must be able to refer to objects, properties and events in the outside world (Abbott, 2010).",1 Introduction,[0],[0]
"Current vector models are purely language-internal, solipsistic models of meaning.",1 Introduction,[0],[0]
"Consider the very simple scenario in which visual information is being provided to an agent about the current state of the world, and the agent’s task is to determine the truth of a statement similar to There is a dog in the room.",1 Introduction,[0],[0]
"Although the agent is equipped with a powerful context vector model, this will not suffice to successfully complete the task.",1 Introduction,[0],[0]
"The model might suggest that the concepts of dog and cat are semantically related, but it has no means to determine the visual appearance of dogs, and consequently no way to verify the truth of such a simple statement.
",1 Introduction,[0],[0]
"Mapping words to the objects they denote is such a core function of language that humans are highly optimized for it, as shown by the so-called fast mapping phenomenon, whereby children can learn to associate a word to an object or property by a single exposure to it (Bloom, 2000; Carey, 1978; Carey and Bartlett, 1978; Heibeck and Markman, 1987).",1 Introduction,[0],[0]
"But lack of reference is not
1403
only a theoretical weakness: Without the ability to refer to the outside world, context vectors are arguably useless for practical goals such as learning to execute natural language instructions (Branavan et al., 2009; Chen and Mooney, 2011), that could greatly benefit from the rich network of lexical meaning such vectors encode, in order to scale up to real-life challenges.
",1 Introduction,[0],[0]
"Very recently, a number of papers have exploited advances in automated feature extraction form images and videos to enrich context vectors with visual information (Bruni et al., 2014; Feng and Lapata, 2010; Leong and Mihalcea, 2011; Regneri et al., 2013; Silberer et al., 2013).",1 Introduction,[0],[0]
This line of research tackles the grounding problem: Word representations are no longer limited to their linguistic contexts but also encode visual information present in images associated with the corresponding objects.,1 Introduction,[0],[0]
"In this paper, we rely on the same image analysis techniques but instead focus on the reference problem: We do not aim at enriching word representations with visual information, although this might be a side effect of our approach, but we address the issue of automatically mapping objects, as depicted in images, to the context vectors representing the corresponding words.",1 Introduction,[0],[0]
"This is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hidden layer that can be interpreted as a cross-modal semantic space.
",1 Introduction,[0],[0]
"We first test the effectiveness of our crossmodal semantic space on the so-called zero-shot learning task (Palatucci et al., 2009), which has recently been explored in the machine learning community (Frome et al., 2013; Socher et al., 2013).",1 Introduction,[0],[0]
"In this setting, we assume that our system possesses linguistic and visual information for a set of concepts in the form of text-based representations of words and image-based vectors of the corresponding objects, used for vision-to-language-mapping training.",1 Introduction,[0],[0]
"The system is then provided with visual information for a previously unseen object, and the task is to associate it with a word by cross-modal mapping.",1 Introduction,[0],[0]
"Our approach is competitive with respect to the recently proposed alternatives, while being overall simpler.
",1 Introduction,[0],[0]
The aforementioned task is very demanding and interesting from an engineering point of view.,1 Introduction,[0],[0]
"However, from a cognitive angle, it relies on strong, unrealistic assumptions: The learner is
asked to establish a link between a new object and a word for which they possess a full-fledged textbased vector extracted from a billion-word corpus.",1 Introduction,[0],[0]
"On the contrary, the first time a learner is exposed to a new object, the linguistic information available is likely also very limited.",1 Introduction,[0],[0]
"Thus, in order to consider vision-to-language mapping under more plausible conditions, similar to the ones that children or robots in a new environment are faced with, we next simulate a scenario akin to fast mapping.",1 Introduction,[0],[0]
"We show that the induced cross-modal semantic space is powerful enough that sensible guesses about the correct word denoting an object can be made, even when the linguistic context vector representing the word has been created from as little as 1 sentence containing it.
",1 Introduction,[0],[0]
The contributions of this work are three-fold.,1 Introduction,[0],[0]
"First, we conduct experiments with simple imageand text-based vector representations and compare alternative methods to perform cross-modal mapping.",1 Introduction,[0],[0]
"Then, we complement recent work (Frome et al., 2013) and show that zero-shot learning scales to a large and noisy dataset.",1 Introduction,[0],[0]
"Finally, we provide preliminary evidence that cross-modal projections can be used effectively to simulate a fast mapping scenario, thus strengthening the claims of this approach as a full-fledged, fully inductive theory of meaning acquisition.",1 Introduction,[0],[0]
The problem of establishing word reference has been extensively explored in computational simulations of cross-situational learning (see Fazly et al. (2010) for a recent proposal and extended review of previous work).,2 Related Work,[0],[0]
"This line of research has traditionally assumed artificial models of the external world, typically a set of linguistic or logical labels for objects, actions and possibly other aspects of a scene (Siskind, 1996).",2 Related Work,[0],[0]
"Recently, Yu and Siskind (2013) presented a system that induces word-object mappings from features extracted from short videos paired with sentences.",2 Related Work,[0],[0]
Our work complements theirs in two ways.,2 Related Work,[0],[0]
"First, unlike Yu and Siskind (2013) who considered a limited lexicon of 15 items with only 4 nouns, we conduct experiments in a large search space containing a highly ambiguous set of potential target words for every object (see Section 4.1).",2 Related Work,[0],[0]
"Most importantly, by projecting visual representations of objects into a shared semantic space, we do not limit ourselves to establishing a link between ob-
jects and words.",2 Related Work,[0],[0]
"We induce a rich semantic representation of the multimodal concept, that can lead, among other things, to the discovery of important properties of an object even when we lack its linguistic label.",2 Related Work,[0],[0]
"Nevertheless, Yu and Siskind’s system could in principle be used to initialize the vision-language mapping that we rely upon.
",2 Related Work,[0],[0]
Closer to the spirit of our work are two very recent studies coming from the machine learning community.,2 Related Work,[0],[0]
Socher et al. (2013) and Frome et al. (2013) focus on zero-shot learning in the visionlanguage domain by exploiting a shared visuallinguistic semantic space.,2 Related Work,[0],[0]
Socher et al. (2013) learn to project unsupervised vector-based image representations onto a word-based semantic space using a neural network architecture.,2 Related Work,[0],[0]
"Unlike us, Socher and colleagues train an outlier detector to decide whether a test image should receive a known-word label by means of a standard supervised object classifier, or be assigned an unseen label by vision-to-language mapping.",2 Related Work,[0],[0]
"In our zeroshot experiments, we assume no access to an outlier detector, and thus, the search for the correct label is performed in the full concept space.",2 Related Work,[0],[0]
"Furthermore, Socher and colleagues present a much more constrained evaluation setup, where only 10 concepts are considered, compared to our experiments with hundreds or thousands of concepts.
",2 Related Work,[0],[0]
Frome et al. (2013) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguistic semantic space.,2 Related Work,[0],[0]
"Unlike Socher et al. (2013) and the current study that adopt simple unsupervised techniques for constructing image representations, Frome et al. (2013) rely on a supervised state-ofthe-art method: They feed low-level features to a deep neural network trained on a supervised object recognition task (Krizhevsky et al., 2012).",2 Related Work,[0],[0]
"Furthermore, their text-based vectors encode very rich information, such as ~king − ~man + ~woman = ~queen (Mikolov et al., 2013c).",2 Related Work,[0],[0]
A natural question we aim to answer is whether the success of cross-modal mapping is due to the high-quality embeddings or to the general algorithmic design.,2 Related Work,[0],[0]
"If the latter is the case, then these results could be extended to traditional distributional vectors bearing other desirable properties, such as high interpretability of dimensions.",2 Related Work,[0],[0]
"“We found a cute, hairy wampimuk sleeping behind the tree.”",3 Zero-shot learning and fast mapping,[0],[0]
"Even though the previous statement is certainly the first time one hears about wampimuks, the linguistic context already creates some visual expectations: Wampimuks probably resemble small animals (Figure 1a).",3 Zero-shot learning and fast mapping,[0],[0]
This is the scenario of zero-shot learning.,3 Zero-shot learning and fast mapping,[0],[0]
"Moreover, if this is also the first linguistic encounter of that concept, then we refer to the task as fast mapping.
",3 Zero-shot learning and fast mapping,[0],[0]
"Concretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distributional semantic space (see Section 4.3).",3 Zero-shot learning and fast mapping,[0],[0]
Objects corresponding to concepts are represented in visual terms by vectors in an image-based semantic space (Section 4.2).,3 Zero-shot learning and fast mapping,[0],[0]
"For a subset of concepts (e.g., a set of animals, a set of vehicles), we possess information related to both their linguistic and visual representations.",3 Zero-shot learning and fast mapping,[0],[0]
"During training, this cross-modal vocabulary is used to induce a projection function (Section 4.4), which – intuitively – represents a mapping between visual and linguistic dimensions.",3 Zero-shot learning and fast mapping,[0],[0]
"Thus, this function, given a visual vector, returns its corresponding linguistic representation.",3 Zero-shot learning and fast mapping,[0],[0]
"At test time, the system is presented with a previously unseen object (e.g., wampimuk).",3 Zero-shot learning and fast mapping,[0],[0]
"This object is projected onto the linguistic space and associated with the word label of the nearest neighbor in that space (degus in Figure 1b).
",3 Zero-shot learning and fast mapping,[0],[0]
The fast mapping setting can be seen as a special case of the zero-shot task.,3 Zero-shot learning and fast mapping,[0],[0]
"Whereas for the latter our system assumes that all concepts have rich linguistic representations (i.e., representations estimated from a large corpus), in the case of the former, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations.",3 Zero-shot learning and fast mapping,[0],[0]
"This is operationalized by constructing the text-based vector for these
concepts from a context of just a few occurrences.",3 Zero-shot learning and fast mapping,[0],[0]
"In this way, we simulate the first encounter of a learner with a concept that is new in both visual and linguistic terms.",3 Zero-shot learning and fast mapping,[0],[0]
CIFAR-100,4.1 Visual Datasets,[0],[0]
"The CIFAR-100 dataset (Krizhevsky, 2009) consists of 60,000 32x32 colour images (note the extremely small size) representing 100 distinct concepts, with 600 images per concept.",4.1 Visual Datasets,[0],[0]
The dataset covers a wide range of concrete domains and is organized into 20 broader categories.,4.1 Visual Datasets,[0],[0]
"Table 1 lists the concepts used in our experiments organized by category.
",4.1 Visual Datasets,[0],[0]
"ESP Our second dataset consists of 100K images from the ESP-Game data set, labeled through a “game with a purpose” (Von Ahn, 2006).1 The ESP image tags form a vocabulary of 20,515 unique words.",4.1 Visual Datasets,[0],[0]
"Unlike other datasets used for zeroshot learning, it covers adjectives and verbs in addition to nouns.",4.1 Visual Datasets,[0],[0]
"On average, an image has 14 tags and a word appears as a tag for 70 images.",4.1 Visual Datasets,[0],[0]
"Unlike the CIFAR-100 images, which were chosen specifically for image object recognition tasks (i.e., each image is clearly depicting a single object in the foreground), ESP contains a random selection of images from the Web.",4.1 Visual Datasets,[0],[0]
"Consequently, objects do not appear in most images in their prototypical display, but rather as elements of complex scenes (see Figure 2).",4.1 Visual Datasets,[0],[0]
"Thus, ESP constitutes a more realistic, and at the same time more challenging, simulation of how things are encountered in real life, testing the potentials of cross-modal mapping in dealing with the complex scenes that one would encounter in event recognition and caption generation tasks.
",4.1 Visual Datasets,[0],[0]
1http://www.cs.cmu.edu/˜biglou/ resources/,4.1 Visual Datasets,[0],[0]
"Image-based vectors are extracted using the unsupervised bag-of-visual-words (BoVW) representational architecture (Sivic and Zisserman, 2003; Csurka et al., 2004), that has been widely and successfully applied to computer vision tasks such as object recognition and image retrieval (Yang et al., 2007).",4.2 Visual Semantic Spaces,[0],[0]
"First, low-level visual features (Szeliski, 2010) are extracted from a large collection of images and clustered into a set of “visual words”.",4.2 Visual Semantic Spaces,[0],[0]
"The low-level features of a specific image are then mapped to the corresponding visual words, and the image is represented by a count vector recording the number of occurrences of each visual word in it.",4.2 Visual Semantic Spaces,[0],[0]
"We do not attempt any parameter tuning of the pipeline.
",4.2 Visual Semantic Spaces,[0],[0]
"As low-level features, we use Scale Invariant Feature Transform (SIFT) features (Lowe, 2004).",4.2 Visual Semantic Spaces,[0],[0]
"SIFT features are tailored to capture object parts and to be invariant to several image transformations such as rotation, illumination and scale change.",4.2 Visual Semantic Spaces,[0],[0]
"These features are clustered into vocabularies of 5,000 (ESP) and 4,096 (CIFAR-100) visual words.2",4.2 Visual Semantic Spaces,[0],[0]
"To preserve spatial information in the BoVW representation, we use the spatial pyramid technique (Lazebnik et al., 2006), which consists in dividing the image into several regions, computing BoVW vectors for each region and concatenating them.",4.2 Visual Semantic Spaces,[0],[0]
"In particular, we divide ESP images into 16 regions and the smaller CIFAR-100 images into 4.",4.2 Visual Semantic Spaces,[0],[0]
"The vectors resulting from region concatenation have dimensionality 5000 × 16 = 80, 000",4.2 Visual Semantic Spaces,[0],[0]
"(ESP) and 4, 096",4.2 Visual Semantic Spaces,[0],[0]
"× 4 = 16, 384 (CIFAR-100), respectively.",4.2 Visual Semantic Spaces,[0],[0]
"We apply Local Mutual Information (LMI, (Evert, 2005)) as weighting scheme and reduce the full co-occurrence space to 300 dimensions using the Singular Value Decomposition.
",4.2 Visual Semantic Spaces,[0],[0]
"For CIFAR-100, we extract distinct visual vectors for single images.",4.2 Visual Semantic Spaces,[0],[0]
"For ESP, given the size and amount of noise in this dataset, we build vectors for visual concepts, by normalizing and summing the BoVW vectors of all the images that have the relevant concept as a tag.",4.2 Visual Semantic Spaces,[0],[0]
"Note that relevant literature (Pereira et al., 2010) has emphasized the importance of learners self-generating multiple views when faced with new objects.",4.2 Visual Semantic Spaces,[0],[0]
"Thus, our multiple-image assumption should not be considered as problematic in the current setup.
",4.2 Visual Semantic Spaces,[0],[0]
"2For selecting the size of the vocabulary size, we relied on standard settings found in the relevant literature (Bruni et al., 2014; Chatfield et al., 2011).
",4.2 Visual Semantic Spaces,[0],[0]
"We implement the entire visual pipeline with VSEM, an open library for visual semantics (Bruni et al., 2013).3",4.2 Visual Semantic Spaces,[0],[0]
"For constructing the text-based vectors, we follow a standard pipeline in distributional semantics (Turney and Pantel, 2010) without tuning its parameters and collect co-occurrence statistics from the concatenation of ukWaC4 and the Wikipedia, amounting to 2.7 billion tokens in total.",4.3 Linguistic Semantic Spaces,[0],[0]
"Semantic vectors are constructed for a set of 30K target words (lemmas), namely the top 20K most frequent nouns, 5K most frequent adjectives and 5K most frequent verbs, and the same 30K lemmas are also employed as contextual elements.",4.3 Linguistic Semantic Spaces,[0],[0]
We collect co-occurrences in a symmetric context window of 20 elements around a target word.,4.3 Linguistic Semantic Spaces,[0],[0]
"Finally, similarly to the visual semantic space, raw counts are transformed by applying LMI and then reduced to 300 dimensions with SVD.5",4.3 Linguistic Semantic Spaces,[0],[0]
The process of learning to map objects to the their word label is implemented by training a projection function fprojv→w from the visual onto the linguistic semantic space.,4.4 Cross-modal Mapping,[0],[0]
"For the learning, we use a set of Ns seen concepts for which we have both image-based visual representations Vs ∈ RNs×dv
3http://clic.cimec.unitn.it/vsem/ 4http://wacky.sslmit.unibo.it 5We also experimented with the image- and text-based vectors of Socher et al. (2013), but achieved better performance with the reported setup.
and text-based linguistic representations Ws ∈ RNs×dw .",4.4 Cross-modal Mapping,[0],[0]
The projection function is subject to an objective that aims at minimizing some cost function between the induced text-based representations Ŵs ∈,4.4 Cross-modal Mapping,[0],[0]
RNs×dw and the gold ones Ws.,4.4 Cross-modal Mapping,[0],[0]
The induced fprojv→w is then applied to the imagebased representations Vu ∈ RNu×dv of Nu unseen objects to transform them into text-based representations Ŵu ∈ RNu×dw .,4.4 Cross-modal Mapping,[0],[0]
"We implement 4 alternative learning algorithms for inducing the cross-modal projection function fprojv→w .
",4.4 Cross-modal Mapping,[0],[0]
Linear Regression (lin),4.4 Cross-modal Mapping,[0],[0]
Our first model is a very simple linear mapping between the two modalities estimated by solving a least-squares problem.,4.4 Cross-modal Mapping,[0],[0]
"This method is similar to the one introduced by Mikolov et al. (2013a) for estimating a translation matrix, only solved analytically.",4.4 Cross-modal Mapping,[0],[0]
"In our setup, we can see the two different modalities as if they were different languages.",4.4 Cross-modal Mapping,[0],[0]
"By using least-squares regression, the projection function fprojv→w can be derived as
fprojv→w =",4.4 Cross-modal Mapping,[0],[0]
(V T s Vs) −1 VTs,4.4 Cross-modal Mapping,[0],[0]
"Ws (1)
Canonical Correlation Analysis (CCA) CCA (Hardoon et al., 2004; Hotelling, 1936) and variations thereof have been successfully used in the past for annotation of regions (Socher and Fei-Fei, 2010) and complete images (Hardoon et al., 2006; Hodosh et al., 2013).",4.4 Cross-modal Mapping,[0],[0]
"Given two paired observation matrices, in our case Vs and Ws, CCA aims at capturing the linear relationship that exists between these variables.",4.4 Cross-modal Mapping,[0],[0]
"This is achieved by finding a pair of matrices, in our
case CV ∈ Rdv×d and CW ∈ Rdw×d, such that the correlation between the projections of the two multidimensional variables into a common, lower-rank space is maximized.",4.4 Cross-modal Mapping,[0],[0]
"The resulting multimodal space has been shown to provide a good approximation to human concept similarity judgments (Silberer and Lapata, 2012).",4.4 Cross-modal Mapping,[0],[0]
"In our setup, after applying CCA on the two spaces Vs and Ws, we obtain the two projection mappings onto the common space and thus our projection function can be derived as:
fprojv→w = CV CW −1",4.4 Cross-modal Mapping,[0],[0]
"(2)
Singular Value Decomposition (SVD) SVD is the most widely used dimensionality reduction technique in distributional semantics (Turney and Pantel, 2010), and it has recently been exploited to combine visual and linguistic dimensions in the multimodal distributional semantic model of Bruni et al. (2014).",4.4 Cross-modal Mapping,[0],[0]
"SVD smoothing is also a way to infer values of unseen dimensions in partially incomplete matrices, a technique that has been applied to the task of inferring word tags of unannotated images (Hare et al., 2008).",4.4 Cross-modal Mapping,[0],[0]
"Assuming that the concept-representing rows of Vs and Ws are ordered in the same way, we apply the (k-truncated) SVD to the concatenated matrix",4.4 Cross-modal Mapping,[0],[0]
"[VsWs], such that [V̂sŴs] = UkΣkZTk is a k-rank approximation of the original matrix.6 The projection function is then:
fprojv→w = ZkZ T k",4.4 Cross-modal Mapping,[0],[0]
"(3)
where the input is appropriately padded with 0s",4.4 Cross-modal Mapping,[0],[0]
"([Vu0Nu×W ]) and we discard the visual block of the output matrix [V̂uŴu].
",4.4 Cross-modal Mapping,[0],[0]
Neural Network (NNet),4.4 Cross-modal Mapping,[0],[0]
The last model that we introduce is a neural network with one hidden layer.,4.4 Cross-modal Mapping,[0],[0]
"The projection function in this model can be described as:
fprojv→w = Θv→w",4.4 Cross-modal Mapping,[0],[0]
"(4)
where Θv→w consists of the model weights θ(1) ∈ Rdv×h and θ(2) ∈ Rh×dw that map the input image-based vectors Vs first to the hidden layer and then to the output layer in order to obtain text-based vectors, i.e., Ŵs = σ(2)(σ(1)(Vsθ(1))θ(2)), where σ(1) and σ(2) are
6We denote the right singular vectors matrix by Z instead of the customary V to avoid confusion with the visual matrix.
",4.4 Cross-modal Mapping,[0],[0]
the non-linear activation functions.,4.4 Cross-modal Mapping,[0],[0]
"We experimented with sigmoid, hyperbolic tangent and linear; hyperbolic tangent yielded the highest performance.",4.4 Cross-modal Mapping,[0],[0]
"The weights are estimated by minimizing the objective function
J(Θv→w)",4.4 Cross-modal Mapping,[0],[0]
"= 1 2 (1− sim(Ws,Ŵs)) (5)
where sim is some similarity function.",4.4 Cross-modal Mapping,[0],[0]
"In our experiments we used cosine as similarity function, so that sim(A,B) = AB‖A‖‖B‖ , thus penalizing parameter settings leading to a low cosine between the target linguistic representations",4.4 Cross-modal Mapping,[0],[0]
Ws and those produced by the projection function Ŵs.,4.4 Cross-modal Mapping,[0],[0]
"The cosine has been widely used in the distributional semantic literature, and it has been shown to outperform Euclidean distance (Bullinaria and Levy, 2007).7 Parameters were estimated with standard backpropagation and L-BFGS.",4.4 Cross-modal Mapping,[0],[0]
Our experiments focus on the tasks of zero-shot learning (Sections 5.1 and 5.2) and fast mapping (Section 5.3).,5 Results,[0],[0]
"In both tasks, the projected vector of the unseen concept is labeled with the word associated to its cosine-based nearest neighbor vector in the corresponding semantic space.
",5 Results,[0],[0]
For the zero-shot task we report the accuracy of retrieving the correct label among the top k neighbors from a semantic space populated with the union of seen and unseen concepts.,5 Results,[0],[0]
"For fast mapping, we report the mean rank of the correct concept among fast mapping candidates.",5 Results,[0],[0]
"For this experiment, we use the intersection of our linguistic space with the concepts present in CIFAR-100, containing a total of 90 concepts.",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"For each concept category, we treat all concepts but one as seen concepts (Table 1).",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"The 71 seen concepts correspond to 42,600 distinct visual vectors and are used to induce the projection function.",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"Table 2 reports results obtained by averaging the performance on the 11,400 distinct vectors of the 19 unseen concepts.
",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
Our 4 models introduced in Section 4.4 are compared to a theoretically derived baseline Chance simulating selecting a label at random.,5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"For the neural network NN, we use prior knowledge
7We also experimented with the same objective function as Socher et al. (2013), however, our objective function yielded consistently better results in all experimental settings.
about the number of concept categories to set the number of hidden units to 20 in order to avoid tuning of this parameter.",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"For the SVD model, we set the number of dimensions to 300, a common choice in distributional semantics, coherent with the settings we used for the visual and linguistic spaces.
",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"First and foremost, all 4 models outperform Chance by a large margin.",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"Surprisingly, the very simple lin method outperforms both CCA and SVD.",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"However, NN, an architecture that can capture more complex, non-linear relations in features across modalities, emerges as the best performing model, confirming on a larger scale the recent findings of Socher et al. (2013).",5.1 Zero-shot Learning in CIFAR-100,[0],[0]
"In order to gain qualitative insights into the performance of the projection process of NN, we attempt to investigate the role and interpretability of the hidden layer.",5.1.1 Concept Categorization,[0],[0]
We achieve this by looking at which visual concepts result in the highest hidden unit activation.8,5.1.1 Concept Categorization,[0],[0]
"This is inspired by analogous qualitative analysis conducted in Topic Models (Griffiths et al., 2007), where “topics” are interpreted in terms of the words with the highest probability under each of them.
",5.1.1 Concept Categorization,[0],[0]
Table 3 presents both seen and unseen concepts corresponding to visual vectors that trigger the highest activation for a subset of hidden units.,5.1.1 Concept Categorization,[0],[0]
"The table further reports, for each hidden unit, the “correct” unseen concept for the category of the top seen concepts, together with its rank in terms of activation of the unit.",5.1.1 Concept Categorization,[0],[0]
"The analysis demonstrates that, although prior knowledge about categories was not explicitly used to train the network, the latter induced an organization of concepts into superordinate categories in which the
8For this post-hoc analysis, we include a sparsity parameter in the objective function of Equation 5 in order to get more interpretable results; hidden units are therefore maximally activated by a only few concepts.
",5.1.1 Concept Categorization,[0],[0]
hidden layer acts as a cross-modal concept categorization/organization system.,5.1.1 Concept Categorization,[0],[0]
"When the induced projection function maps an object onto the linguistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object.",5.1.1 Concept Categorization,[0],[0]
This suggests a bias towards seen concepts.,5.1.1 Concept Categorization,[0],[0]
"Furthermore, in many cases of miscategorization, the concepts are still semantically coherent with the induced category, confirming that the projection function is indeed capturing a latent, cross-modal semantic space.",5.1.1 Concept Categorization,[0],[0]
"A squirrel, although not a “large omnivore”, is still an animal, while butterflies are not flowers but often feed on their nectar.",5.1.1 Concept Categorization,[0],[0]
"For this experiment, we focus on NN, the best performing model in the previous experiment.",5.2 Zero-shot Learning in ESP,[0],[0]
"We use a set of approximately 9,500 concepts, the intersection of the ESP-based visual semantic space with the linguistic space.",5.2 Zero-shot Learning in ESP,[0],[0]
"For tuning the number of hidden units of NN, we use the MEN-concrete dataset of Bruni et al. (2014).",5.2 Zero-shot Learning in ESP,[0],[0]
"Finally, we randomly pick 70% of the concepts to induce the projection function fprojv→w and report results on the remaining 30%.",5.2 Zero-shot Learning in ESP,[0],[0]
"Note that the search space for the correct label in this experiment is approximately 95 times larger than the one used for the experiment presented in Section 5.1.
",5.2 Zero-shot Learning in ESP,[0],[0]
"Although our experimental setup differs from the one of Frome et al. (2013), thus preventing a direct comparison, the results reported in Table 5 are on a comparable scale to theirs.",5.2 Zero-shot Learning in ESP,[0],[0]
We note that previous work on zero-shot learning has used standard object recognition benchmarks.,5.2 Zero-shot Learning in ESP,[0],[0]
"To the best of our knowledge, this is the first time this task has been performed on a dataset as noisy as ESP.",5.2 Zero-shot Learning in ESP,[0],[0]
"Overall, the results suggest that cross-modal mapping could be applied in tasks where images exhibit a more complex structure, e.g., caption generation and event recognition.",5.2 Zero-shot Learning in ESP,[0],[0]
"In this section, we aim at simulating a fast mapping scenario in which the learner has been just exposed to a new concept, and thus has limited linguistic evidence for that concept.",5.3 Fast Mapping in ESP,[0],[0]
"We operationalize this by considering the 34 concrete concepts introduced by Frassinelli and Keller (2012), and deriving their text-based representations from just a few sentences randomly picked from the corpus.",5.3 Fast Mapping in ESP,[0],[0]
"Concretely, we implement 5 models: context 1, context 5, context 10, context 20 and context full, where the name of the model denotes the number of sentences used to construct the text-based representations.",5.3 Fast Mapping in ESP,[0],[0]
The derived vectors were reduced with the same SVD projection induced from the complete corpus.,5.3 Fast Mapping in ESP,[0],[0]
"Cross-modal mapping is done via NN.
",5.3 Fast Mapping in ESP,[0],[0]
The zero-shot framework leads us to frame fast mapping as the task of projecting visual representations of new objects onto language space for retrieving their word labels (v→ w).,5.3 Fast Mapping in ESP,[0],[0]
This mapping from visual to textual representations is arguably a more plausible task than vice versa.,5.3 Fast Mapping in ESP,[0],[0]
"If we think about how linguistic reference is acquired, a scenario in which a learner first encounters a new object and then seeks its reference in the language of the surrounding environment (e.g., adults having a conversation, the text of a book with an illustration of an unknown object) is very natural.",5.3 Fast Mapping in ESP,[0],[0]
"Furthermore, since not all new concepts in the linguistic
environment refer to new objects (they might denote abstract concepts or out-of-scene objects), it seems more reasonable for the learner to be more alerted to linguistic cues about a recently-spotted new object than vice versa.",5.3 Fast Mapping in ESP,[0],[0]
"Moreover, once the learner observes a new object, she can easily construct a full visual representation for it (and the acquisition literature has shown that humans are wired for good object segmentation and recognition (Spelke, 1994)) – the more challenging task is to scan the ongoing and very ambiguous linguistic communication for contexts that might be relevant and informative about the new object.",5.3 Fast Mapping in ESP,[0],[0]
"However, fast mapping is often described in the psychological literature as the opposite task: The learner is exposed to a new word in context and has to search for the right object referring to it.",5.3 Fast Mapping in ESP,[0],[0]
We implement this second setup (w→ v) by training the projection function fprojw→v which maps linguistic vectors to visual ones.,5.3 Fast Mapping in ESP,[0],[0]
"The adaptation of NN is straightforward; the new objective function is derived as
J(Θw→v)",5.3 Fast Mapping in ESP,[0],[0]
"= 1 2 (1− sim(Vs, V̂s)) (6)
",5.3 Fast Mapping in ESP,[0],[0]
"where V̂s = σ(2)(σ(1)(Wsθ(1))θ(2)), θ(1) ∈ Rdw×h and θ(2) ∈ Rh×dv .
",5.3 Fast Mapping in ESP,[0],[0]
Table 7 presents the results.,5.3 Fast Mapping in ESP,[0],[0]
"Not surprisingly, performance increases with the number of sentences that are used to construct the textual representations.",5.3 Fast Mapping in ESP,[0],[0]
"Furthermore, all models perform better than Chance, including those that are based on just 1 or 5 sentences.",5.3 Fast Mapping in ESP,[0],[0]
"This suggests that the system can make reasonable inferences about object-word connections even when linguistic evidence is very scarce.
",5.3 Fast Mapping in ESP,[0],[0]
"Regarding the sources of error, a qualitative analysis of predicted word labels and objects as
presented in Table 6 suggests that both textual and visual representations, although capturing relevant “topical” or “domain” information, are not enough to single out the properties of the target concept.",5.3 Fast Mapping in ESP,[0],[0]
"As an example, the textual vector of dishwasher contains kitchen-related dimensions such as 〈fridge, oven, gas, hob, ..., sink〉.",5.3 Fast Mapping in ESP,[0],[0]
"After projecting onto the visual space, its nearest visual neighbours are the visual ones of the same-domain concepts corkscrew and kettle.",5.3 Fast Mapping in ESP,[0],[0]
"The latter is shown in Figure 3a, with a gas hob well in evidence.",5.3 Fast Mapping in ESP,[0],[0]
"As a further example, the visual vector for cooker is extracted from pictures such as the one in Figure 3b.",5.3 Fast Mapping in ESP,[0],[0]
"Not surprisingly, when projecting it onto the linguistic space, the nearest neighbours are other kitchenrelated terms, i.e., potato and dishwasher.",5.3 Fast Mapping in ESP,[0],[0]
"At the outset of this work, we considered the problem of linking purely language-based distri-
butional semantic spaces with objects in the visual world by means of cross-modal mapping.",6 Conclusion,[0],[0]
We compared recent models for this task both on a benchmark object recognition dataset and on a more realistic and noisier dataset covering a wide range of concepts.,6 Conclusion,[0],[0]
"The neural network architecture emerged as the best performing approach, and our qualitative analysis revealed that it induced a categorical organization of concepts.",6 Conclusion,[0],[0]
"Most importantly, our results suggest the viability of crossmodal mapping for grounded word-meaning acquisition in a simulation of fast mapping.
",6 Conclusion,[0],[0]
"Given the success of NN, we plan to experiment in the future with more sophisticated neural network architectures inspired by recent work in machine translation (Gao et al., 2013) and multimodal deep learning (Srivastava and Salakhutdinov, 2012).",6 Conclusion,[0],[0]
"Furthermore, we intend to adopt visual attributes (Farhadi et al., 2009; Silberer et al., 2013) as visual representations, since they should allow a better understanding of how crossmodal mapping works, thanks to their linguistic interpretability.",6 Conclusion,[0],[0]
"The error analysis in Section 5.3 suggests that automated localization techniques (van de Sande et al., 2011), distinguishing an object from its surroundings, might drastically improve mapping accuracy.",6 Conclusion,[0],[0]
"Similarly, in the textual domain, models that extract collocates of a word that are more likely to denote conceptual properties (Kelly et al., 2012) might lead to more informative and discriminative linguistic vectors.",6 Conclusion,[0],[0]
"Finally, the lack of large child-directed speech corpora constrained the experimental design of fast mapping simulations; we plan to run more realistic experiments with true nonce words and using source corpora (e.g., the Simple Wikipedia, child stories, portions of CHILDES) that contain sentences more akin to those a child might effectively hear or read in her word-learning years.",6 Conclusion,[0],[0]
We thank Adam Liška for helpful discussions and the 3 anonymous reviewers for useful comments.,Acknowledgments,[0],[0]
This work was supported by ERC 2011 Starting Independent Research Grant n. 283554 (COMPOSES).,Acknowledgments,[0],[0]
"Following up on recent work on establishing a mapping between vector-based semantic embeddings of words and the visual representations of the corresponding objects from natural images, we first present a simple approach to cross-modal vector-based semantics for the task of zero-shot learning, in which an image of a previously unseen object is mapped to a linguistic representation denoting its word.",abstractText,[0],[0]
"We then introduce fast mapping, a challenging and more cognitively plausible variant of the zero-shot task, in which the learner is exposed to new objects and the corresponding words in very limited linguistic contexts.",abstractText,[0],[0]
"By combining prior linguistic and visual knowledge acquired about words and their objects, as well as exploiting the limited new evidence available, the learner must learn to associate new objects with words.",abstractText,[0],[0]
Our results on this task pave the way to realistic simulations of how children or robots could use existing knowledge to bootstrap grounded semantic knowledge about new concepts.,abstractText,[0],[0]
Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world,title,[0],[0]
"use of multimodal data, such as sensor streams and self-report, to construct interpretable timeto-event predictions of, for example, lapse to alcohol or illicit drug use. Interpretability of the prediction model is important for acceptance and adoption by domain scientists, enabling model outputs and parameters to inform theory and guide intervention design. Temporal latent state models are therefore attractive, and so we adopt the continuous time hidden Markov model (CT-HMM) due to its ability to describe irregular arrival times of event data. Standard CTHMMs, however, are not specialized for predicting the time to a future event, the key variable for mHealth interventions. Also, standard emission models lack a sufficiently rich structure to describe multimodal data and incorporate domain knowledge. We present iSurvive, an extension of classical survival analysis to a CT-HMM. We present a parameter learning method for GLM emissions and survival model fitting, and present promising results on both synthetic data and an mHealth drug use dataset.",text,[0],[0]
"In the emerging field of mobile health (mHealth) an important problem is the use of collected multimodal data – e.g., sensor streams along with self-report – to make time-varying predictions of events like lapse (Chih et al., 2014).",1. Introduction,[0],[0]
"Using latent state models for prediction is an attractive choice for three reasons: (1) States can be made interpretable by representing behavioral constructs such as stress and craving; (2) Emission models can handle noisy
*
Equal contribution
1
University of Michigan
2
Georgia Institute
of Technology
3
Lighthouse Institute
4
University of Wisconsin-
Madison.",1. Introduction,[0],[0]
"Correspondence to: Alexander Moreno <alexander.f.moreno@gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
measurements; and (3) Parameters can capture domain knowledge.,1. Introduction,[0],[0]
"Moreover, an interpretable model can represent a theoretical relationship, such as the hypothesized link between increased stress and risk of smoking lapse, in a form which supports learning from data, simulation and visualization, and hypothesis testing.",1. Introduction,[0],[0]
"Such models can be a tool for data-driven design and testing of theoretical models by domain scientists (Nahum-Shani et al., 2015).",1. Introduction,[0],[0]
"Further, in the case of small sample sizes, the incorporation of domain knowledge may be critical for good performance.",1. Introduction,[0],[0]
"In such cases, superior performance relative to an alternative ”black box” model can provide additional evidence for the correctness of a behavioral theory.
",1. Introduction,[0],[0]
"Discrete time hidden Markov models (DT-HMMs) are a standard tool for regularly-sampled sensor data, but many important datatypes, such as EMAs or detected periods of high stress, take the form of event data with irregular arrival times.",1. Introduction,[0],[0]
"Fortunately, recent work (Wang et al., 2014; Rao & Teh, 2013) makes it feasible to use continuous time HMMs (CT-HMMs) to model irregularly-sampled data.",1. Introduction,[0],[0]
"This paper builds on our prior work on efficient parameter learning algorithms for CT-HMMs (Liu et al., 2015).
",1. Introduction,[0],[0]
"In order to utilize CT-HMMs for mobile health interventions, however, two limitations with existing models must be addressed: (1) A mechanism is needed for predicting the time to future events; and (2) Emission models must go beyond the standard Gaussian and multinomial observations to embrace general multimodal data models.",1. Introduction,[0],[0]
The first limitation can be addressed via classical methods for time-toevent prediction from survival analysis.,1. Introduction,[0],[0]
"Prior work in joint survival and longitudinal analysis has focused on sharedrandom effects models (Rizopoulos, 2012) or latent class models (Proust-Lima et al., 2014) with Gaussian emissions.",1. Introduction,[0],[0]
Survival analysis has not been previously used in an interpretable hidden state setting with multimodal data.,1. Introduction,[0],[0]
"We develop a method for using the states of a CT-HMM as interpretable, time-varying covariates in a survival model.",1. Introduction,[0],[0]
"In prior work, Lian et al. (2014) developed an interpretable latent event process model; interpretability, however, was achieved post hoc rather than being a built-in feature of the model as is the case here.",1. Introduction,[0],[0]
"We describe additional differences between this prior work and our current approach in the supplementary material.
",1. Introduction,[0],[0]
"We address the second limitation, the treatment of multimodal observations, by using a factorized GLM emission model.",1. Introduction,[0],[0]
"Rather than simply ”stacking” multimodal observations into a single vector, GLMs allow the specification of a different link function for each type of observation data, such as ordinal, count, and continuous data.",1. Introduction,[0],[0]
"Due to this choice, the M-step of EM does not have a closed form solution, and the temporal dependencies are different from standard GLM training.",1. Introduction,[0],[0]
"We derive an iterative M-step update approach to solve this problem, and provide convergence guarantees to match.",1. Introduction,[0],[0]
We believe we are the first to use interpretable latent variables from a CT-HMM as covariates in a survival model with use of GLM emissions to handle multimodal data types in a CTHMM.,1. Introduction,[0],[0]
"Our method allows us to make precise intuitive statements like “under high risk and low engagement, the probability of lapse is 74.4%.”",1. Introduction,[0],[0]
Our publicly-released software (http://cbi.gatech.edu/Survival-HMM) will enable the mHealth and data science communities to benefit from these new modeling capabilities.,1. Introduction,[0],[0]
We show promising results both in simulation and on a real-world mHealth recovery support services dataset from individuals with substance use disorders.,1. Introduction,[0],[0]
"Our latent variable-based survival model, which we term iSurvive, has three components: (1) continuous-time hidden Markov process, (2) GLM emission models, and (3) event process.",2. Model Description,[0],[0]
We assume there are N participants.,2. Model Description,[0],[0]
"For each participant, t is the time in hours since the start of the study.",2. Model Description,[0],[0]
The study-window length ⇠ is pre-specified and fixed for all participants.,2. Model Description,[0],[0]
"A continuous-time hidden Markov model (Liu et al., 2015) is a continuous-time latent Markov process where state transitions and observations can occur at arbitrary times.",2.1. Continuous-Time HMM,[0],[0]
There are two sources of hidden information: the states and their transition times.,2.1. Continuous-Time HMM,[0],[0]
"The estimation problem involves three sets of parameters: (1) an emission model p(o|s), relating observations o to the latent state s; (2) a transition rate matrix Q that captures the exponentially distributed transition rates between states; and (3) an initial state distribution.
",2.1. Continuous-Time HMM,[0],[0]
Let S be a vector Markov process of length p with vector representation S(t) =,2.1. Continuous-Time HMM,[0],[0]
"[S1(t), . . .",2.1. Continuous-Time HMM,[0],[0]
", Sp(t)] in which each S i (t) takes discrete values in {0, 1, . . .",2.1. Continuous-Time HMM,[0],[0]
", ` i
}.",2.1. Continuous-Time HMM,[0],[0]
"Note that this can always be reduced to an equivalent representation with a single discrete state
˜S(t) with cardinality p̃ =Q p
i=1(`i + 1).",2.1. Continuous-Time HMM,[0],[0]
"We will alternate between these representations as needed.
",2.1. Continuous-Time HMM,[0],[0]
"A p̃⇥ p̃-dimensional transition rate matrix Q governs transitions for the latent Markov process
˜S. The negative diagonal element Q
ii
is the rate at which the process leaves
state i 2",2.1. Continuous-Time HMM,[0],[0]
"[p̃], assumed exponentially distributed with parameter q
i = Q ii .",2.1. Continuous-Time HMM,[0],[0]
"The equation P j 6=i Qij = Qii must
hold.",2.1. Continuous-Time HMM,[0],[0]
"If the latent process is currently in state i then at a transition time from state i, the probability of transitioning to state j is Q
ij /q",2.1. Continuous-Time HMM,[0],[0]
i .,2.1. Continuous-Time HMM,[0],[0]
"Suppose we observe the latent state
transition times (t01 = 0, t 0 2, . . .",2.1. Continuous-Time HMM,[0],[0]
", t 0 V 1, t 0 V
= ⇠) and corresponding states (s̃(t00), . . .",2.1. Continuous-Time HMM,[0],[0]
", s̃(t 0 V )).",2.1. Continuous-Time HMM,[0],[0]
"From these we deduce the sufficient statistics: (1) the number of transitions between states {n ij }p̃ i,j=1 and (2) the total length of time spent in each state {⌧ i }p̃ i=1.",2.1. Continuous-Time HMM,[0],[0]
"The probability of this progression for the latent process is
V 1Y
v=1
q s̃(t
v ) exp( qs̃(t v ) · (tv+1 tv))",2.1. Continuous-Time HMM,[0],[0]
"·Qs̃(t v ),s̃(t v+1)/qs̃(tv).
",2.1. Continuous-Time HMM,[0],[0]
"The CT-HMM also includes an observation process O = {O(t)} t2[0,⇠], which is only observed at observation times.",2.1. Continuous-Time HMM,[0],[0]
"Let t = (t1, . . .",2.1. Continuous-Time HMM,[0],[0]
", tV ) denote the observation schedule; note this is a random subset of [0, ⇠].",2.1. Continuous-Time HMM,[0],[0]
"At each observation time t
i we observe the vector O(t i ).",2.1. Continuous-Time HMM,[0],[0]
We assume O(t) ?,2.1. Continuous-Time HMM,[0],[0]
"(O,S) | S(t).",2.1. Continuous-Time HMM,[0],[0]
"Let O[t] denote the vector of observation values at the observation schedule (O(t1), . . .",2.1. Continuous-Time HMM,[0],[0]
", O(tV )).",2.1. Continuous-Time HMM,[0],[0]
Consider a participant who has already had k observation times t(k).,2.1. Continuous-Time HMM,[0],[0]
"In this paper, we make the following conditional independence assumption:
t k+1 ?",2.1. Continuous-Time HMM,[0],[0]
"(O,S) | (t(k), O[t(k)]) (1)
In other words, the conditional distribution of the random interval t k+1 tk only depends on the observed history.",2.1. Continuous-Time HMM,[0],[0]
"Under both above conditional independence assumptions, the joint probability of the latent process S and observation sequence O[t] = (O(t1), . . .",2.1. Continuous-Time HMM,[0],[0]
", O(tV )) is equal to
p̃Y
i=1
2 4 Y
j 6=i
Q n ij
ij
3 5 e qi⌧i VY
v=1
p(O(tv) | s̃(tv))p(tv | Hv) (2)
where H v
is the observed history (t(v 1), O[tv 1]).
",2.1. Continuous-Time HMM,[0],[0]
Each observation O(t k ) is a multimodal vector.,2.1. Continuous-Time HMM,[0],[0]
"In an mHealth application, for example, we may observe several self-reported ordinal ratings (e.g. EMA) along with the number of times the mobile app has been used recently.",2.1. Continuous-Time HMM,[0],[0]
"Thus, we have both ordinal and count data.",2.1. Continuous-Time HMM,[0],[0]
Our observation model summarizes each component of the observation vector in terms of the p latent sources.,2.1. Continuous-Time HMM,[0],[0]
"We assume conditional independence of the M observation components given the latent process, leading to the emission factorization:
p(O(t) | S(t))",2.1. Continuous-Time HMM,[0],[0]
=,2.1. Continuous-Time HMM,[0],[0]
"MY
m=1
p(Om(t)",2.1. Continuous-Time HMM,[0],[0]
"| S(t)).
",2.1. Continuous-Time HMM,[0],[0]
"This factorization simplifies the specification of the GLM
for each observation component.",2.1. Continuous-Time HMM,[0],[0]
A generalized linear model (GLM) is a flexible generalization of ordinary linear regression where the error distributions need not be Gaussian.,2.2. Emissions and Generalized Linear Models,[0],[0]
"A GLM has three components (McCullagh & Nelder, 1989; Agresti, 2015): (1) a response variable y following a dispersion exponential family with distribution p(y | ⌘, d(⌧)) with natural parameter ⌘ and dispersion term d(⌧).",2.2. Emissions and Generalized Linear Models,[0],[0]
"(2) a linear predictor 0s, where is a vector of weights and s our input vector; and (3) a link function g or activation function g 1.
",2.2. Emissions and Generalized Linear Models,[0],[0]
"Suppose the p latent sources are binary (i.e., l i = 1 for each i).",2.2. Emissions and Generalized Linear Models,[0],[0]
"For the j-th observation process, O j = {O j (t)} t2[0,⇠], the conditional mean given the latent process at time t equals E[O
j (t) | S(t)]",2.2. Emissions and Generalized Linear Models,[0],[0]
= g 1 ( 0 + 0S(t)).,2.2. Emissions and Generalized Linear Models,[0],[0]
"That is, the conditional expectation is equal to the activation function applied to a linear combination of the current values of the p latent sources plus a constant.",2.2. Emissions and Generalized Linear Models,[0],[0]
Note this is an assumption of parsimony as the number of parameters in the fully nonparametric model would be 2 p .,2.2. Emissions and Generalized Linear Models,[0],[0]
"Much of behavioral science theory concerns latent states such as stress, craving, engagement and risk.",2.3. Interpretability via Link Restriction,[0],[0]
"We aim for our model outputs to be interpretable by the clinician, an important feature necessary for both acceptance and adoption by domain scientists.",2.3. Interpretability via Link Restriction,[0],[0]
"We achieve this through the following assumption: some of the variables collected are noisy measures of only one latent state and not the others.
",2.3. Interpretability via Link Restriction,[0],[0]
"For example, suppose S has latent binary sources S1(t) and S2(t) representing stress and craving, respectively.",2.3. Interpretability via Link Restriction,[0],[0]
"Further let O1(t) be a binary observation dependent only on stress, and O2(t) be a second observation dependent on both stress and craving (see Appendix B for the associated graphical model).",2.3. Interpretability via Link Restriction,[0],[0]
"Then taking the logit link function, the form of the conditional mean is
logit (E[O1(t)",2.3. Interpretability via Link Restriction,[0],[0]
| S]) = baseline + stress · S1(t).,2.3. Interpretability via Link Restriction,[0],[0]
"(3)
Therefore O1(t) is conditionally independent of S2(t) given S1(t).",2.3. Interpretability via Link Restriction,[0],[0]
"That is, given information about the user’s stress, the observation value does not depend on craving.",2.3. Interpretability via Link Restriction,[0],[0]
We call such conditional independence assumptions link restrictions.,2.3. Interpretability via Link Restriction,[0],[0]
"iSurvive achieves interpretability via link restriction: for each latent source {S
i (t)} t2[0,⇠] there ex-
ists at least one observation process {O j (t)} t2[0,⇠] such that O j (t) is a noisy measure of only S i
(t).",2.3. Interpretability via Link Restriction,[0],[0]
"In an EMA context, this can be achieved with questions such as ”Are you currently experiencing stress?” which target a single latent state construct.",2.3. Interpretability via Link Restriction,[0],[0]
"These direct observations enforce interpretability and allow us to incorporate additional more
complex observation processes that can provide improved accuracy over self-report.",2.3. Interpretability via Link Restriction,[0],[0]
Using a survival model then allows us to make intuitive statements such as ”The probability of lapse within the next 30 minutes when the participant is stressed but not craving is 70%.”,2.3. Interpretability via Link Restriction,[0],[0]
"We now build a model relating the interpretable, latent process S to the event process Y = {Y (t)} t2[0,⇠] of interest; this is a binary process where Y (t)",2.4. Event Process,[0],[0]
= 1 implies an event occurs at time t.,2.4. Event Process,[0],[0]
"In our case study, for example, the event of interest is alcohol or drug use at a particular moment t. Survival analysis provides the appropriate tools for modeling the intensity function – the instantaneous rate of occurrence of the event – given the latent process.",2.4. Event Process,[0],[0]
"Let N(t, t + s] be the number of events in the window (t, t + s].",2.4. Event Process,[0],[0]
"Then the intensity function at time t is defined:
h(t) =",2.4. Event Process,[0],[0]
"lim t!0
1 t P(N(t, t+ t] > 0",2.4. Event Process,[0],[0]
"| S) (4)
",2.4. Event Process,[0],[0]
"For this paper we consider the proportional hazards model which expresses the hazard as
h(t | S) = h0(t) exp
pX
i=1
",2.4. Event Process,[0],[0]
"i S i (t)
!",2.4. Event Process,[0],[0]
"(5)
where h0(t) is the baseline hazard function.",2.4. Event Process,[0],[0]
"In this paper we consider a constant baseline hazard; moreover, we presuppose the intensity only depends on the latent process at the current time t. The proposed model is an interpretable Cox process (Cox & Isham, 1980; Taylor et al., 2013) – a generalization of a Poisson process in which the intensity function is itself a stochastic process.",2.4. Event Process,[0],[0]
"Cox processes have found success in event prediction problems with respect to complex health data (Ranganath et al., 2015).",2.4. Event Process,[0],[0]
Here the latent process is interpretable and therefore helps in answering both the prediction problem and the sequential decision making problem of interest.,2.4. Event Process,[0],[0]
The Cox process assumes “lapses” are conditionally independent given the latent process.,2.4. Event Process,[0],[0]
"Such a model is appropriate when lapse is only a function of the latent behavioral constructs.
",2.4. Event Process,[0],[0]
"In mHealth applications, the event process can be measured either via sensors (Sarker et al., 2016; Hossain et al., 2014) (i.e., continuous monitoring) or self-report (i.e., intermittent monitoring).",2.4. Event Process,[0],[0]
"Alternatively, scientists may schedule observation times at which the participant is asked if they have used drugs within a prior window of time.",2.4. Event Process,[0],[0]
"In the case study for this work, participants were asked if they used either alcohol or drugs within the past 30 minutes.",2.4. Event Process,[0],[0]
"This can be modeled as
P(N(t , t] > 0) = 1 exp ✓ Z t
t h(s)ds
◆ (6)
",2.4. Event Process,[0],[0]
"Here we assume the window length (i.e., 30 minutes) is short enough so that (1) the latent process is likely to be constant within the window; then given the latent process, the chance of no use (exponentiated term in eq. 6) can be well-approximated by exp ( · ( 0 + 0S(t))), where 0 + 0S(t) is the hazard.",2.4. Event Process,[0],[0]
We focus on the latter case with a similar discretized approximation for the remainder of the paper.,2.4. Event Process,[0],[0]
"For more on survival analysis see (Aalen et al., 2008; Cook & Lawless, 2007).",2.4. Event Process,[0],[0]
Here we present an expectation-maximization algorithm for parameter estimation of iSurvive.,3. Parameter Estimation for iSurvive,[0],[0]
"Our development uses the context of our case study, and so we assume that the event process and observation processes are measured via self-report (EMA) following the same observation schedule (i.e., Y (t) ⇢ O(t)).",3. Parameter Estimation for iSurvive,[0],[0]
"It is straightforward to apply our approach to other use cases.
",3. Parameter Estimation for iSurvive,[0],[0]
"One property of self-report data is that participants may not respond at a scheduled observation time, and instead may decline to provide data.",3. Parameter Estimation for iSurvive,[0],[0]
"Let M = {M(t)} t2[0,⇠] be a binary process representing missing data.",3. Parameter Estimation for iSurvive,[0],[0]
Suppose an observation is scheduled at time t v ; we write M(t v ),3. Parameter Estimation for iSurvive,[0],[0]
"= 1 if the participant declines to provide information (i.e., the observation O(t v ) is missing).",3. Parameter Estimation for iSurvive,[0],[0]
Consider a participant who already has k observations at times t(k).,3. Parameter Estimation for iSurvive,[0],[0]
"Then define t(k)0 to be the set of observation times at which we do observe the observation (i.e., {t
i 2 t(k) s.t. M(t",3. Parameter Estimation for iSurvive,[0],[0]
i ),3. Parameter Estimation for iSurvive,[0],[0]
= 0}).,3. Parameter Estimation for iSurvive,[0],[0]
"We make the following conditional independence assumptions regarding the missing data indicator process:
M(tk+1) ?",3. Parameter Estimation for iSurvive,[0],[0]
S | O[t(k)0,3. Parameter Estimation for iSurvive,[0],[0]
"],M [t (k) ], t(k).",3. Parameter Estimation for iSurvive,[0],[0]
"(7)
That is, the missing data indicator at tk+1 is independent of the latent process, given the observed history (i.e., observation and missing data processes at prior observation times of tk).",3. Parameter Estimation for iSurvive,[0],[0]
"This assumption plus variational independence (i.e., no parameter sharing across components of the joint density) imply that likelihood estimation can ignore the missing data process.",3. Parameter Estimation for iSurvive,[0],[0]
Note that observed missing data indicators can still be used in the survival and emission models.,3. Parameter Estimation for iSurvive,[0],[0]
"For example, missing data may be an indicator of future risk; assumption (7) only states that missing data may only depend on the latent process through the observed history.
",3. Parameter Estimation for iSurvive,[0],[0]
"A plausible alternative to assumption (7) is conditional independence given the observed history and the latent process at the observation time,
M(tk+1) ?",3. Parameter Estimation for iSurvive,[0],[0]
"S | S(tk+1), O[t(k)0 ],M [t (k) ], t(k).",3. Parameter Estimation for iSurvive,[0],[0]
"(8)
Under this assumption, likelihood estimation cannot ignore the missing data process; however, the emission model becomes hierarchical and so can be readily handled within the iSurvive framework.
",3. Parameter Estimation for iSurvive,[0],[0]
"As the preceding discussion illustrates, the iSurvive framework is sufficiently flexible to describe a wide range of experiment designs and modeling assumptions.",3. Parameter Estimation for iSurvive,[0],[0]
"In the case study in Section 6, behavioral scientists identified through participant interviews that the primary cause for missed appointment was exogenous shocks to their schedule.",3. Parameter Estimation for iSurvive,[0],[0]
"For ease of presentation, we present the EM algorithm based on equation (2) under the conditional independence assumptions for observations and missing data given by equations (1) and (7) respectively.",3.1. EM Method,[0],[0]
"Excluding the initial state distribution, the expected complete log-likelihood is given by
L(Q, ) = PX
i=1
2 4 X
j 6=i
log(qij)E h nij | O[t], ˆQ(l), ˆ (l)
",3.1. EM Method,[0],[0]
"i 3
5
qiE h ⌧i | O[t], ˆQ(l), ˆ (l) i
+
VX
v=1
E h log p(O(tv) | S(tv))",3.1. EM Method,[0],[0]
"| O[t], ˆQ(l), ˆ (l) i
where ( ˆQ(l), ˆ (l)) are the parameter estimates from the l-th iteration.",3.1. EM Method,[0],[0]
"Under variational independence of the emission models and the latent Markov process, the maximization step can be done separately for the latent variable parameters and emission models.
",3.1. EM Method,[0],[0]
We begin by describing the EM-steps for the transition matrix.,3.1. EM Method,[0],[0]
"The M-step for the transition matrix yields the following (l + 1) iteration estimate:
ˆQ(l+1)ij",3.1. EM Method,[0],[0]
"= E h nij | O[t], ˆQ(l), ˆ (l) i
E h ⌧i | O[t], ˆQ(l), ˆ (l) i (9)
for i 6= j and ˆQ ii = P j 6=i ˆQ ij .
",3.1. EM Method,[0],[0]
"The main challenge here is in the E-step, which (Liu et al., 2015) solved by breaking up the expectations into terms per observation, and terms conditioned on the possible state transitions between observations.",3.1. EM Method,[0],[0]
"Let ⇣(v, s, s0) denote the transition probability p(S(t
v )",3.1. EM Method,[0],[0]
"= s, S(t v+1) =
s0 | O[t], ˆQ(l), ˆ (l)).",3.1. EM Method,[0],[0]
"Then E ⇥ nij | O[t], ˆQ(l), ˆ (l) ⇤
=
V 1X
v=1
SX
s,s0=1
⇣(v, s, s0)⇥",3.1. EM Method,[0],[0]
"E h nij | S(tv) = s, S(tv+1) = s0, ˆQ(l)",3.1. EM Method,[0],[0]
"i
E ⇥",3.1. EM Method,[0],[0]
"⌧i | O[t], ˆQ(l), ˆ (l) ⇤
=
V 1X
v=1
SX
s,s0=1
⇣(v, s, s0)⇥",3.1. EM Method,[0],[0]
"E h ⌧i | S(tv) = s, S(tv+1) = s0, ˆQ(l)",3.1. EM Method,[0],[0]
"i .
",3.1. EM Method,[0],[0]
"Liu et al. (2015) adapt methods from the continuous-time
Markov chain (CTMC) literature to compute the end-state
conditioned expectations, and develop an equivalent inhomogeneous discrete-time hidden Markov model to calculate the pairwise beliefs ⇣(v, s, s0).
",3.1. EM Method,[0],[0]
"The density for the kth observation process p(O
k (t) | S(t) = s; ) can be rewritten in the following exponential dispersion family form:
p(O k
(t) =",3.1. EM Method,[0],[0]
o,3.1. EM Method,[0],[0]
"| S(t) = s) = h(o, ⌧) exp ✓ ⌘ s T (o) A(⌘ s )
",3.1. EM Method,[0],[0]
"d(⌧)
◆ .
",3.1. EM Method,[0],[0]
"Define v,s = p(S(t v )",3.1. EM Method,[0],[0]
"= s | O, ˆQ(l), ˆ (l)).",3.1. EM Method,[0],[0]
"Then the corresponding component of the expected complete loglikelihood (ECLL) is given by
VX
v=1
SX
s=1
v,s
 log h(O(t
v
), ⌧) + ⌘ s T (O(t v ))",3.1. EM Method,[0],[0]
"A(⌘ s )
d(⌧)
.
",3.1. EM Method,[0],[0]
"Maximizing the ECLL, which is done after maximization of the transition terms, does not have a closed form solution, and Fisher scoring or Newton’s method must be used.",3.1. EM Method,[0],[0]
"However, Fisher scoring for GLMs assumes an unweighted log-likelihood, which is not the case for this objective because of the v,s terms.",3.1. EM Method,[0],[0]
Appendix C extends the Fisher scoring method to the weighted setting above.,3.1. EM Method,[0],[0]
"A similar learning procedure was derived in (Escola et al., 2011), but focused on incorporating covariates into an HMM rather than using GLM emissions.
",3.1. EM Method,[0],[0]
"Algorithm 1 Forward-backward + Weighted Fisher scoring estimation procedure
Input: N participants, observation processes {O(i)}N
i=1, observation times {t(i)}Ni=1 Output: rate matrix ˆQ, emission parameters ˆ Smart initialization: ( ˆQ(0), ˆ (0))",3.1. EM Method,[0],[0]
"Set l = 0 repeat
Use forward-backward algorithm to compute ⇣(v, s, s0) and (v, s) for v = 0, . . .",3.1. EM Method,[0],[0]
", V and s, s0 = 1, . . .",3.1. EM Method,[0],[0]
", S. Compute E h ⌧ i | O[t], ˆQ(l), ˆ",3.1. EM Method,[0],[0]
"(l) i , and E h n",3.1. EM Method,[0],[0]
ij,3.1. EM Method,[0],[0]
"| O[t], ˆQ(l), ˆ (l) i .
",3.1. EM Method,[0],[0]
Compute ˆQ(l+1) via equation (9).,3.1. EM Method,[0],[0]
"Compute ˆ (l+1) via weighted Fisher scoring with
weights { (v, s)}.",3.1. EM Method,[0],[0]
until log-likelihood converges,3.1. EM Method,[0],[0]
Algorithm 1 presents the EM-algorithm for iSurvive using a combination of the forward-backward and weighted Fisher scoring procedures.,3.2. Parameter Initialization and Convergence,[0],[0]
"The algorithm requires initial estimates ( ˆQ(0), ˆ (0)), and these initial values will effect
its convergence properties.",3.2. Parameter Initialization and Convergence,[0],[0]
"We want to ensure that EM converges to intuitively reasonable estimates so that we can interpret the resulting model parameters in the context of relevant behavioral theory.
",3.2. Parameter Initialization and Convergence,[0],[0]
"Prior theoretical work has provided some convergence guarantees for standard EM algorithms (Balakrishnan et al., 2014; Wang et al., 2015).",3.2. Parameter Initialization and Convergence,[0],[0]
"To guarantee convergence, in each case strong concavity and first-order stability conditions are required along with reasonable parameter initialization.",3.2. Parameter Initialization and Convergence,[0],[0]
Here we provide a similar guarantee for EM parameter estimation for the case of CT-HMMs with factorized GLM emissions and conditional independence on the observation schedule.,3.2. Parameter Initialization and Convergence,[0],[0]
"Our development is based on the assumption of strong concavity, which seems likely to hold based on prior work (Kakade et al., 2010) on almost strong concavity of exponential families.",3.2. Parameter Initialization and Convergence,[0],[0]
Our supporting simulation results in Section 5 provide additional evidence.,3.2. Parameter Initialization and Convergence,[0],[0]
"A proof of strong concavity remains for future work.
",3.2. Parameter Initialization and Convergence,[0],[0]
"For iSurvive, the Q-function of the EM-algorithm is decomposable into three components for the latent process, the observation model, and the event process.",3.2. Parameter Initialization and Convergence,[0],[0]
"Decomposability allows us to discuss the assumption of strong concavity separately for each component; in particular, it allows us to isolate the issue of strong concavity for generalized linear models and investigate this independently of the other model components.",3.2. Parameter Initialization and Convergence,[0],[0]
"Further, since the Q-function is decomposable, so is the M -step.
",3.2. Parameter Initialization and Convergence,[0],[0]
"Under the assumption that the participant trajectories are independent and identically distributed, the law of large numbers ensures that as the sample size N increases, the sample-based Q-function approaches its expectation:
˜Q(✓ | ✓0) = E ⇥",3.2. Parameter Initialization and Convergence,[0],[0]
QN (✓ | ✓0),3.2. Parameter Initialization and Convergence,[0],[0]
"⇤
= E ⇥",3.2. Parameter Initialization and Convergence,[0],[0]
"ES | O[t],Y,",3.2. Parameter Initialization and Convergence,[0],[0]
✓0,3.2. Parameter Initialization and Convergence,[0],[0]
"[log(p(S, O[t],Y; ✓))]",3.2. Parameter Initialization and Convergence,[0],[0]
"⇤
The population M -function can then be defined as ˜M(✓0) =",3.2. Parameter Initialization and Convergence,[0],[0]
"argmax
✓2⌦ ˜Q(✓ | ✓0).",3.2. Parameter Initialization and Convergence,[0],[0]
"When applying EM, ✓0 corresponds to ✓(t 1), the parameters of the previous iteration.",3.2. Parameter Initialization and Convergence,[0],[0]
The population M -function is also decomposable; We now present Lemma 1 which provides convergence guarantees and motivates our approach to parameter initialization.,3.2. Parameter Initialization and Convergence,[0],[0]
Lemma 1.,3.2. Parameter Initialization and Convergence,[0],[0]
"If each component of the population M - function satisfies strong concavity and first-order stability conditions for parameters ✓ 2 ⌦, then for sample size N sufficiently large the EM-algorithm satisfies
kˆ✓(t) ✓?",3.2. Parameter Initialization and Convergence,[0],[0]
k  tk✓?,3.2. Parameter Initialization and Convergence,[0],[0]
"ˆ✓(0)k+ 1 1  ( (N, )) (10) where ✓⇤ is the MLE, ˆ✓(t) is the tth EM-iteration estimates,  = L/ , L is a measure of first-order stability, a measure of strong concavity, and (N, ) is the sum of high-probability lower bounds on the distance between M
N
(✓) and ˜M(✓) for each component.
",3.2. Parameter Initialization and Convergence,[0],[0]
See Appendix D for additional technical details.,3.2. Parameter Initialization and Convergence,[0],[0]
Lemma 1 motivates a practical problem: how do we choose the initial parameter estimates?,3.2. Parameter Initialization and Convergence,[0],[0]
iSurvive leverages GLMs for connecting the latent process to each component of the observable process.,3.2. Parameter Initialization and Convergence,[0],[0]
Kakade et al. (2010) shows (almost) strong concavity of exponential families.,3.2. Parameter Initialization and Convergence,[0],[0]
"In particular, their Theorem 3.4 quantifies the fact that “exponential families behave in a strongly concave manner only in a (sufficiently small) neighborhood of ✓?.",3.2. Parameter Initialization and Convergence,[0],[0]
"These findings combined with equation (10) highlight the importance of appropriately choosing
ˆ✓(0).",3.2. Parameter Initialization and Convergence,[0],[0]
A good initialization will ensure convergence to high quality parameter estimates.,3.2. Parameter Initialization and Convergence,[0],[0]
We propose a smart initialization strategy which leverages domain expertise.,3.2. Parameter Initialization and Convergence,[0],[0]
"First, we treat rate matrix and emission initializations separately.",3.2. Parameter Initialization and Convergence,[0],[0]
"For the rate matrix, we obtain an initial estimate of the hidden state sequences by assuming that the direct observations of the states resulting from link restriction (see Section 2.3) are noise-free.",3.2. Parameter Initialization and Convergence,[0],[0]
"This allows us to estimate an initial Q corresponding to a CTMC over the observed states using the method of (Metzner et al., 2007).",3.2. Parameter Initialization and Convergence,[0],[0]
"For the emission parameters, we hand-design an initial emission model by drawing from behavioral theory to connect the latent states to the observations.",3.2. Parameter Initialization and Convergence,[0],[0]
"For example, we can ascertain the likelihood that a participant is experiencing stress if they answer positively to a question about being stressed.",3.2. Parameter Initialization and Convergence,[0],[0]
We can then choose GLM weight parameters accordingly.,3.2. Parameter Initialization and Convergence,[0],[0]
"Note that this initialization method provides an indirect test of of our behavioral theories: if they are correct, they should lead to good predictive accuracy.",3.2. Parameter Initialization and Convergence,[0],[0]
iSurvive is designed to be an interpretable event prediction model.,4. Prediction and Validation,[0],[0]
"Here we show how to take parameter estimates (
ˆQ, ˆ ) and answer the question “Given observed data O[t], what is the probability that a lapse will not occur at any of a future set of observation times (t01, . . .",4. Prediction and Validation,[0],[0]
", t 0 k )?”.",4. Prediction and Validation,[0],[0]
Note we allow for multiple events to occur and thus are interested in whether any event occurs in the window or not.,4. Prediction and Validation,[0],[0]
This is the primary question of interest when analyzing the recovery support services data in Section 6.,4. Prediction and Validation,[0],[0]
"In this case, prior data includes self-reported alcohol or drug use at observation times (i.e., Y [t] ⇢ O[t]).",4. Prediction and Validation,[0],[0]
"As we are interested in predicting self-reported lapse, we do not require the full generality of equation (6), as we only need to compute the chance of no use within a small prior window (i.e., a discretized approximation).",4. Prediction and Validation,[0],[0]
At time t01 we can use the forward algorithm to compute the posterior distribution of the latent process at time t1 conditional on the observed data.,4. Prediction and Validation,[0],[0]
We can then compute the probability of not observing a lapse at time t01.,4. Prediction and Validation,[0],[0]
"To do this, we use a logistic emission model for p(Y (t
i ) = 0",4. Prediction and Validation,[0],[0]
| S(t i ) = s).,4. Prediction and Validation,[0],[0]
"This is equivalent to the discretized approximation described in Section 2.4 for the
event process.",4. Prediction and Validation,[0],[0]
We iterate on this procedure to compute a sequence of conditional probabilities of not lapsing (conditional on observed history and the fact that the participant has yet to lapse at any future scheduled observation time); multiplying them together yields the prediction of interest.,4. Prediction and Validation,[0],[0]
"Algorithm 2 presents pseudo-code.
",4. Prediction and Validation,[0],[0]
"We use the brier score (Blanche et al., 2015; van Houwelingen & Putter, 2011) and log-loss to define prediction accuracy.",4. Prediction and Validation,[0],[0]
"Use of the log-likelihood is inappropriate as it measures overall fit, which is not the main quantity of interest.",4. Prediction and Validation,[0],[0]
We choose a time t and window-length .,4. Prediction and Validation,[0],[0]
"We then produce the probability of no lapses at any of the scheduled observations times within the interval (t, t + ).",4. Prediction and Validation,[0],[0]
"Let ⇡ n
(t, ) denote this prediction for the nth participant.",4. Prediction and Validation,[0],[0]
"We compute an indicator of whether no events occur at these scheduled observation times within the window for the chosen participant I n
(t, ).",4. Prediction and Validation,[0],[0]
"The brier score is the average squared difference in these quantities (⇡
n (t, ) I n
(t, ))2.
",4. Prediction and Validation,[0],[0]
"The complete brier score and log-loss are then
BS( ) / NX
n=1
m nX
j=1
(⇡n(tj , ) In(tj , ))2
LL( ) / NX
n=1
m nX
j=1
 In(tj , ) log(1 ⇡n(tj , ))
+ (1 In(tj , ))",4. Prediction and Validation,[0],[0]
"log(⇡n(tj , ))
",4. Prediction and Validation,[0],[0]
"respectively where {t j }mn j=1 are a set of chosen, participant specific times.",4. Prediction and Validation,[0],[0]
"The Brier score and log-loss are two ways to verify the accuracy of a probability forecast, the former ranges from 0 (completely accurate) to 1 (wholly inaccurate) while the latter from 0 to1.
",4. Prediction and Validation,[0],[0]
"For each experiment that follows, we perform a crossvalidation based assessment of prediction accuracy.",4. Prediction and Validation,[0],[0]
We randomly partition the N participants into groups of size K. Suppose N/K = M,4. Prediction and Validation,[0],[0]
"and we label each partition uniquely m = 1, . . .",4. Prediction and Validation,[0],[0]
",M , then the Brier score and log-loss for the mth run is denoted BS
m ( ) and LL m ( ) respec-
tively.",4. Prediction and Validation,[0],[0]
The cross-validated complete brier score and logloss is then given by P m BS m ( ) and P m LL m ( ) respectively.,4. Prediction and Validation,[0],[0]
We perform this calculation for various choices of to observe performance over a range of windowlengths.,4. Prediction and Validation,[0],[0]
"Our experiments are focused on the setting of self-reported alcohol or illicit drug use at scheduled observation times, which is the basis for our case study in Section 6.
",5. Synthetic Experiments,[0],[0]
"We start with a synthetic experiment aimed at illustrating
Algorithm 2",5. Synthetic Experiments,[0],[0]
"Event prediction algorithm Input: Rate matrix Q, emission parameters , prior observations O[t]; current time t0 and future observation times (t1, . . .",5. Synthetic Experiments,[0],[0]
", tk).
",5. Synthetic Experiments,[0],[0]
"Output: Q k
i=1",5. Synthetic Experiments,[0],[0]
"(ti) for i = 1, . . .",5. Synthetic Experiments,[0],[0]
", k. Compute ↵
t (s) p(S(t)",5. Synthetic Experiments,[0],[0]
"= s | O[t];Q, ) for k0 2 {1, . . .",5. Synthetic Experiments,[0],[0]
", k} do
Compute P (i)",5. Synthetic Experiments,[0],[0]
"exp(Q(t i t i 1)) for s 2 {1, . . .",5. Synthetic Experiments,[0],[0]
", S} do Set ↵
t
i
(s) hP
s
0",5. Synthetic Experiments,[0],[0]
t,5. Synthetic Experiments,[0],[0]
i 1(s 0 ),5. Synthetic Experiments,[0],[0]
"P (i)
s 0 s
i
Set t
i
(s) ↵ t
i
(s)p(Y (t i ) = 0",5. Synthetic Experiments,[0],[0]
"| S(t i ) = s) end for Set (t
i
) P
s2S ti(s)",5. Synthetic Experiments,[0],[0]
"Normalize
t
i
(s) t
i
(s)/ P
s
t
i (s) end for
the importance of good initialization.",5. Synthetic Experiments,[0],[0]
"Due to our desire for interpretability, we are concerned with how close the parameter estimates are to the true parameter values.",5. Synthetic Experiments,[0],[0]
We now briefly describe the synthetic experiment; see Appendix F for details.,5. Synthetic Experiments,[0],[0]
The latent process has three binary sources.,5. Synthetic Experiments,[0],[0]
"We generate a random transition matrix, Q. We generate
three ordinal ratings, each taking binary values.",5. Synthetic Experiments,[0],[0]
"Each ratings question is associated with only one latent source (i.e., one binary question per latent source).",5. Synthetic Experiments,[0],[0]
We also generate count data to represent the number of times a user has used the app in the past 30 minutes.,5. Synthetic Experiments,[0],[0]
All emissions models are generalized linear models; for the ordinal ratings we assume a logit link while for the count data we assume a logarithmic link.,5. Synthetic Experiments,[0],[0]
"For each, we are interested in observing the effect of smart initialization.
",5. Synthetic Experiments,[0],[0]
Figure 1 shows convergence (50 iterations) of the emission coefficients to the generating parameters a) with and b) without smart initialization.,5. Synthetic Experiments,[0],[0]
"With smart initialization, convergence is very good, and without it, convergence is very poor; in fact, the estimated logistic parameters do not even converge toward the generating parameters.",5. Synthetic Experiments,[0],[0]
Here we analyze a set of recovery support studies on individuals with substance use disorders (SUDs).,6. Recovery Support Services – a Case Study,[0],[0]
"In particular, we analyze two pilot studies – a 5-week study of adults (N = 23) and a 6-week study of adolescents (N = 29) – where participants have recently been discharged from outpatient, intensive outpatient, or residential treatment.",6. Recovery Support Services – a Case Study,[0],[0]
"Each study was done using a modified version of the Addiction Comprehensive Health Enhancement Support System (ACHESS) (Gustafson et al., 2014).",6. Recovery Support Services – a Case Study,[0],[0]
Participants of each pilot study have met criteria for substance use disorder in the year prior to the original treatment intake and have used alcohol or other drugs in the 90 days prior to the original treatment; prompts occur at six random times by the mobile phone per day.,6. Recovery Support Services – a Case Study,[0],[0]
"At each prompt, self-report data is collected concerning the prior 30 minutes exposure to internal and external protective and risk factors.",6. Recovery Support Services – a Case Study,[0],[0]
Ratings were given to how each factor aids in their recovery or makes them want to use drugs/alcohol.,6. Recovery Support Services – a Case Study,[0],[0]
"Self-report also included questions regarding physical pain, illness or withdrawal from drugs/alcohol, level of craving for drugs/alcohol, exposure to drugs/alcohol, and resistance to drugs/alcohol.",6. Recovery Support Services – a Case Study,[0],[0]
"Participants were given smartphones enabled with 24/7 access to a range of drug abuse and HIV ecological momentary interventions (Dennis et al., 2015; Scott et al., 2017).",6. Recovery Support Services – a Case Study,[0],[0]
Participants were asked to self-report use of drugs/alcohol in the prior 30 minutes.,6. Recovery Support Services – a Case Study,[0],[0]
Sensor data was collected including information on when EMIs (Ecological momentary interventions; interventions delivered in real time) were accessed and the amount of time engaged with the EMI.,6. Recovery Support Services – a Case Study,[0],[0]
"Such a rich dataset of complex longitudinal data (e.g., simultaneously measuring EMI usage, drug use, self-reported ratings) is becoming increasingly common as the field of mobile health grows.",6. Recovery Support Services – a Case Study,[0],[0]
"We are interested in using the collected complex longitudinal data in event prediction – in particular the probability of any substance use within a future
window of time.
",6. Recovery Support Services – a Case Study,[0],[0]
Prompts occur at random times so the observation schedule automatically satisfies the sequential conditional independence assumption.,6. Recovery Support Services – a Case Study,[0],[0]
"Prompts cannot occur from midnight to 6AM every morning; since participants are likely asleep at these times, we compute time since recruitment after removing these “sleeping windows”.",6. Recovery Support Services – a Case Study,[0],[0]
Consider a prompt at time t; we consider the reduced observation O(t) =,6. Recovery Support Services – a Case Study,[0],[0]
"(O1(t), O2(t), O3(t), Y (t)).",6. Recovery Support Services – a Case Study,[0],[0]
"This is a 4-dimensional vector where O1(t) is a 3-level ordinal response to a question on how one’s current feelings helps with/supports recovery, O2(t) is a 3-level ordinal variable related to EMI usage, O3(t) is a binary variable indicating whether the participant kept all default answers in the self-report, and Y (t) is the binary event process indicating use of drugs/alcohol.",6. Recovery Support Services – a Case Study,[0],[0]
"We assume the latent process S = {(S1(t), S2(t))}",6. Recovery Support Services – a Case Study,[0],[0]
"t2[0,⇠] is comprised of two binary sources; S1(t) represents level of engagement; S2(t) represents level of risk.",6. Recovery Support Services – a Case Study,[0],[0]
"In this paper engagement is defined in terms of active engagement in selfreport and is therefore connected to the indicator O3(t).
",6. Recovery Support Services – a Case Study,[0],[0]
We now specify the models for each observation component conditional on S(t).,6. Recovery Support Services – a Case Study,[0],[0]
"For the event variable Y (t), we assume a logit model where the mean is a linear, additive model in terms of S1(t) and S2(t).",6. Recovery Support Services – a Case Study,[0],[0]
"For the engagement variable O3(t), we assume a logit model where the mean is a linear, additive model in terms of only S1(t).",6. Recovery Support Services – a Case Study,[0],[0]
"For the EMI usage variable O2(t), we assume a proportional odds model where the linear predictor is additive in terms of S1(t) and S2(t).",6. Recovery Support Services – a Case Study,[0],[0]
The risk variable O1(t) is a mixture depending on engagement.,6. Recovery Support Services – a Case Study,[0],[0]
"Given the participant is not currently engaged, the responses are not related to latent risk; given the participant is currently engaged, we assume a proportional odds model where the linear predictor is additive only in terms of S2(t).",6. Recovery Support Services – a Case Study,[0],[0]
"Appendix E provides further details on the observations, latent states, and models.
",6. Recovery Support Services – a Case Study,[0],[0]
We fit several alternative discriminative models aiming to predict future events given a fixed window length .,6. Recovery Support Services – a Case Study,[0],[0]
We fit both logistic regressions and kernel SVMs where the response is an indicator of use in a future window with a particular choice of features from the history.,6. Recovery Support Services – a Case Study,[0],[0]
The first feature set is simply the current observation values; the second adds an additional covariate indicating whether an event occurred at the current observation time; the third adds an additional covariate indicating whether an event occurred in the prior twenty-four hours; the fourth adds an additional covariate indicating whether an event occurred in the prior week.,6. Recovery Support Services – a Case Study,[0],[0]
"Finally, we add as a covariate the number of scheduled observation times in the future window.",6. Recovery Support Services – a Case Study,[0],[0]
"For each discriminative model and iSurvive, we compute the cross-validated complete brier score and complete logloss.",6. Recovery Support Services – a Case Study,[0],[0]
"Figure 2 shows that iSurvive outperforms the discriminative models in terms of the cross-validated Brier score
for each  5 days.",6. Recovery Support Services – a Case Study,[0],[0]
"Figure 8 in Appendix E shows iSurvive also outperforms the alternative discriminative models in terms of the cross-validated log-loss.
",6. Recovery Support Services – a Case Study,[0],[0]
"Our analysis via iSurvive yields the interpretable finding that 30-minute probability of lapse is highest for individuals in the latent states of High risk and Low engagement (74.4%), decreases for High risk and High engagement (21.5%), decreases more for Low risk and Low Engagement (1.1%), and is negligible for Low risk and High engagement (0.1%).",6. Recovery Support Services – a Case Study,[0],[0]
The finding is intuitive for our behavioral scientist collaborators and can be used to help decide what types of interventions to provide and when to provide them.,6. Recovery Support Services – a Case Study,[0],[0]
"In this paper we introduce iSurvive, an interpretable, eventtime prediction model for mHealth.",7. Conclusion and Future Work,[0],[0]
"By using a continuoustime hidden Markov model and a factorized GLM emission model with link restriction, we can summarize our observations in terms of interpretable latent variables.",7. Conclusion and Future Work,[0],[0]
We then use these in a survival model to predict event times.,7. Conclusion and Future Work,[0],[0]
"iSurvive is designed with an interest toward treatment policies; by having interpretable latent states, we hope to leverage iSurvive in optimizing the delivery of mobile health interventions as future work.",7. Conclusion and Future Work,[0],[0]
We thank the reviewers for their useful comments and the members of the Statistical Reinforcement Learning Lab at the University of Michigan for valuable discussions.,Acknowledgements,[0],[0]
"We acknowledge support from the National Institutes of Health under BD2K grant U54EB020404 and grants R01EY13178-15, R01AA023187, P50 DA039838, and R01HL125440.",Acknowledgements,[0],[0]
"This work was also supported by NIDA R01 DA035879 and additional grants from NIAAA, NIDA and NIMH.",Acknowledgements,[0],[0]
"An important mobile health (mHealth) task is the use of multimodal data, such as sensor streams and self-report, to construct interpretable timeto-event predictions of, for example, lapse to alcohol or illicit drug use.",abstractText,[0],[0]
"Interpretability of the prediction model is important for acceptance and adoption by domain scientists, enabling model outputs and parameters to inform theory and guide intervention design.",abstractText,[0],[0]
"Temporal latent state models are therefore attractive, and so we adopt the continuous time hidden Markov model (CT-HMM) due to its ability to describe irregular arrival times of event data.",abstractText,[0],[0]
"Standard CTHMMs, however, are not specialized for predicting the time to a future event, the key variable for mHealth interventions.",abstractText,[0],[0]
"Also, standard emission models lack a sufficiently rich structure to describe multimodal data and incorporate domain knowledge.",abstractText,[0],[0]
"We present iSurvive, an extension of classical survival analysis to a CT-HMM.",abstractText,[0],[0]
"We present a parameter learning method for GLM emissions and survival model fitting, and present promising results on both synthetic data and an mHealth drug use dataset.",abstractText,[0],[0]
"iSurvive: An Interpretable, Event-time Prediction Model for mHealth",title,[0],[0]
"Variational inference (Jordan et al., 1998) has been essential in learning deep directed latent variable models on high-dimensional data, enabling extraction of complex, nonlinear relationships, such as object identities (Higgins et al., 2016) and dynamics (Xue et al., 2016; Karl et al., 2017) directly from observations.",1. Introduction,[0],[0]
"Variational inference reformulates inference as optimization (Neal & Hinton, 1998; Hoffman et al., 2013).",1. Introduction,[0],[0]
"However, the current trend has moved toward employing inference models (Dayan et al., 1995; Gregor et al., 2014; Kingma & Welling, 2014; Rezende et al., 2014), mappings from data to approximate posterior estimates that
1California Institute of Technology (Caltech), Pasadena, CA, USA 2Disney Research, Los Angeles, CA, USA.",1. Introduction,[0],[0]
"Correspondence to: Joseph Marino <jmarino@caltech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
are amortized across examples.",1. Introduction,[0],[0]
"Intuitively, the inference model encodes observations into latent representations, and the generative model decodes these representations into reconstructions.",1. Introduction,[0],[0]
"Yet, this approach has notable limitations.",1. Introduction,[0],[0]
"For instance, in models with empirical priors, such as hierarchical latent variable models, “bottom-up” data-encoding inference models cannot account for “top-down” priors (Section 4.1).",1. Introduction,[0],[0]
"This has prompted the use of top-down inference techniques (Sønderby et al., 2016), which currently lack a rigorous theoretical justification.",1. Introduction,[0],[0]
"More generally, the inability of inference models to reach fully optimized approximate posterior estimates results in decreased modeling performance, referred to as an amortization gap (Krishnan et al., 2018; Cremer et al., 2017).
",1. Introduction,[0],[0]
"To combat this problem, our work offers a departure from previous approaches by re-examining inference from an optimization perspective.",1. Introduction,[0],[0]
We utilize approximate posterior gradients to perform inference optimization.,1. Introduction,[0],[0]
"Yet, we improve computational efficiency over conventional optimizers by encoding these gradients with an inference model that learns how to iteratively update approximate posterior estimates.",1. Introduction,[0],[0]
"The resulting iterative inference models resemble learning to learn (Andrychowicz et al., 2016) applied to variational inference optimization.",1. Introduction,[0],[0]
"However, we refine and extend this method along several novel directions.",1. Introduction,[0],[0]
"Namely, (1) we show that learned optimization models can be applied to inference optimization of latent variables; (2) we show that non-recurrent optimization models work well in practice, breaking assumptions about the necessity of nonlocal curvature for outperforming conventional optimizers (Andrychowicz et al., 2016; Putzky & Welling, 2017); and (3) we provide a new form of optimization model that encodes errors rather than gradients to approximate higher order derivatives, empirically resulting in faster convergence.
",1. Introduction,[0],[0]
"Our main contributions are summarized as follows:
1.",1. Introduction,[0],[0]
"we introduce a family of iterative inference models, which generalize standard inference models,
2.",1. Introduction,[0],[0]
"we provide the first theoretical justification for topdown inference techniques,
3.",1. Introduction,[0],[0]
"we empirically evaluate iterative inference models, demonstrating that they outperform standard inference models on several data sets of images and text.",1. Introduction,[0],[0]
"Latent variable models are generative probabilistic models that use local (per data example) latent variables, z, to model observations, x, using global (across data examples) parameters, θ.",2.1. Latent Variable Models & Variational Inference,[0],[0]
"A model is defined by the joint distribution pθ(x, z) = pθ(x|z)pθ(z), composed of the conditional likelihood and the prior.",2.1. Latent Variable Models & Variational Inference,[0],[0]
"Learning the model parameters and inferring the posterior, p(z|x), are intractable for all but the simplest models, as they require evaluating the marginal likelihood, pθ(x) = ∫",2.1. Latent Variable Models & Variational Inference,[0],[0]
"pθ(x, z)dz, which involves integrating the model over z.",2.1. Latent Variable Models & Variational Inference,[0],[0]
"For this reason, we often turn to approximate inference methods.
",2.1. Latent Variable Models & Variational Inference,[0],[0]
"Variational inference reformulates this intractable integration as an optimization problem by introducing an approximate posterior1, q(z|x), typically chosen from some tractable family of distributions, and minimizing the KLdivergence from the posterior, DKL(q(z|x)||p(z|x)).",2.1. Latent Variable Models & Variational Inference,[0],[0]
"This quantity cannot be minimized directly, as it contains the posterior.",2.1. Latent Variable Models & Variational Inference,[0],[0]
"Instead, KL-divergence can be decomposed into
DKL(q(z|x)||p(z|x))",2.1. Latent Variable Models & Variational Inference,[0],[0]
"= log pθ(x)− L, (1)
where L is the evidence lower bound (ELBO), which is defined as:
L ≡ Ez∼q(z|x)",2.1. Latent Variable Models & Variational Inference,[0],[0]
"[log pθ(x, z)− log q(z|x)] (2) = Ez∼q(z|x) [log pθ(x|z)]−DKL(q(z|x)||pθ(z)).",2.1. Latent Variable Models & Variational Inference,[0],[0]
"(3)
The first term in eq. 3 expresses how well the output reconstructs the data example.",2.1. Latent Variable Models & Variational Inference,[0],[0]
The second term quantifies the dissimilarity between the approximate posterior and the prior.,2.1. Latent Variable Models & Variational Inference,[0],[0]
"Because log pθ(x) is not a function of q(z|x), we can minimize DKL(q(z|x)||p(z|x)) in eq. 1 by maximizing L w.r.t. q(z|x), thereby performing approximate inference.",2.1. Latent Variable Models & Variational Inference,[0],[0]
"Likewise, becauseDKL(q(z|x)||p(z|x)) is non-negative, L is a lower bound on log pθ(x).",2.1. Latent Variable Models & Variational Inference,[0],[0]
"Therefore, once we have inferred an optimal q(z|x), learning corresponds to maximizing L w.r.t.",2.1. Latent Variable Models & Variational Inference,[0],[0]
θ.,2.1. Latent Variable Models & Variational Inference,[0],[0]
"The optimization procedures for variational inference and learning are respectively the expectation and maximization steps of the variational EM algorithm (Dempster et al., 1977; Neal & Hinton, 1998), which alternate until convergence.",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"This is typically performed in the batched setting of stochastic variational inference (Hoffman et al., 2013).",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"When q(z|x) takes a parametric form, the expectation step for data
1We use q(z|x) to denote that the approximate posterior is conditioned on a data example (i.e. local), however this does not necessarily imply a direct functional mapping.
example x(i) involves finding a set of distribution parameters, λ(i), that are optimal w.r.t.",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
L.,2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"With a factorized Gaussian density over continuous latent variables, i.e. λ(i) = {µ(i)q ,σ2(i)q } and q(z(i)|x(i))",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"= N (z(i);µ(i)q ,diagσ2(i)q ), conventional optimization techniques repeatedly estimate the stochastic gradients ∇λL to optimize L w.r.t. λ(i), e.g.:
λ(i) ← λ(i) + α∇λL(x(i),λ(i); θ), (4)
where α is the step size.",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"This procedure, which is repeated for each example, is computationally expensive and requires setting step-size hyper-parameters.",2.2. Variational Expectation Maximization (EM) via Gradient Ascent,[0],[0]
"Due to the aforementioned issues, gradient updates of approximate posterior parameters are rarely performed in practice.",2.3. Amortized Inference Models,[0],[0]
"Rather, inference models are often used to map observations to approximate posterior estimates.",2.3. Amortized Inference Models,[0],[0]
"Optimization of each data example’s approximate posterior parameters, λ(i), is replaced with the optimization of a shared, i.e. amortized (Gershman & Goodman, 2014), set of parameters, φ, contained within an inference model, f , of the form:
λ(i) ← f(x(i);φ).",2.3. Amortized Inference Models,[0],[0]
"(5)
While inference models have a long history, e.g. (Dayan et al., 1995), the most notable recent example is the variational auto-encoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014), which employs the reparameterization trick to propagate stochastic gradients from the generative model to the inference model, both of which are parameterized by neural networks.",2.3. Amortized Inference Models,[0],[0]
We refer to inference models of this form as standard inference models.,2.3. Amortized Inference Models,[0],[0]
"As discussed in Section 3, the aim of this paper is to move beyond the direct encoder paradigm of standard inference models to develop improved techniques for performing inference.",2.3. Amortized Inference Models,[0],[0]
"In Section 3.3, we introduce our contribution, iterative inference models.",3. Iterative Amortized Inference,[0],[0]
"However, we first motivate our approach in Section 3.1 by discussing the limitations of standard inference models.",3. Iterative Amortized Inference,[0],[0]
We then draw inspiration from other techniques for learning to optimize (Section 3.2).,3. Iterative Amortized Inference,[0],[0]
"As described in Section 2.1, variational inference reformulates inference as the maximization of L w.r.t. q(z|x), constituting the expectation step of the variational EM algorithm.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"In general, this is a difficult non-convex optimization problem, typically requiring a lengthy iterative estimation procedure.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"Yet, standard inference models attempt to perform this optimization through a direct, discriminative mapping from data observations to approximate posterior
parameters.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"Of course, generative models can adapt to accommodate sub-optimal approximate posteriors.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"Nevertheless, the possible limitations of a direct inference mapping applied to this difficult optimization procedure may result in a decrease in overall modeling performance.
",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"We demonstrate this concept in Figure 1 by visualizing the optimization surface of L defined by a 2-D latent Gaussian model and a particular binarized MNIST (LeCun et al., 1998) data example.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"To visualize the approximate posterior, we use a point estimate, q(z|x) = δ(µq), where µq = (µ1, µ2) is the estimate and δ is the Dirac delta function.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
See Appendix C.1 for details.,3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"Shown on the plot are the optimal (maximum a posteriori or MAP) estimate, the estimate from a standard inference model, and an optimization trajectory of gradient ascent.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"The inference model is unable to achieve the optimum, but manages to output a reasonable estimate in one pass.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"Gradient ascent requires many iterations and is sensitive to step-size, but through the iterative estimation procedure, ultimately arrives at a better final estimate.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"The inability of inference models to reach optimal approximate posterior estimates, as typically compared with gradient-based methods, creates an amortization gap (Krishnan et al., 2018; Cremer et al., 2017), which impairs modeling performance.",3.1. Standard Inference Models & Amortization Gaps,[0],[0]
Additional latent dimensions and more complex data could further exacerbate this problem.,3.1. Standard Inference Models & Amortization Gaps,[0],[0]
"While offering significant benefits in computational efficiency, standard inference models can suffer from sizable amortization gaps (Krishnan et al., 2018).",3.2. Learning to Iteratively Optimize,[0],[0]
"Parameterizing inference models as direct, static mappings from x to q(z|x)
may be overly restrictive, widening this gap.",3.2. Learning to Iteratively Optimize,[0],[0]
"To improve upon this direct encoding paradigm, we pose the following question: can we retain the computational efficiency of inference models while incorporating more powerful iterative estimation capabilities?",3.2. Learning to Iteratively Optimize,[0],[0]
"Our proposed solution is a new class of inference models, capable of learning how to update approximate posterior estimates by encoding gradients or errors.",3.2. Learning to Iteratively Optimize,[0],[0]
"Due to the iterative nature of these models, we refer to them as iterative inference models.",3.2. Learning to Iteratively Optimize,[0],[0]
"Through an analysis with latent Gaussian models, we show that iterative inference models generalize standard inference models (Section 4.3) and offer theoretical justification for top-down inference in hierarchical models (Section 4.1).
",3.2. Learning to Iteratively Optimize,[0],[0]
"Our approach relates to learning to learn (Andrychowicz et al., 2016), where an optimizer model learns to optimize the parameters of an optimizee model.",3.2. Learning to Iteratively Optimize,[0],[0]
The optimizer receives the optimizee’s parameter gradients and outputs updates to these parameters to improve the optimizee’s loss.,3.2. Learning to Iteratively Optimize,[0],[0]
The optimizer itself can be learned due to the differentiable computation graph.,3.2. Learning to Iteratively Optimize,[0],[0]
"Such models can adaptively adjust step sizes, potentially outperforming conventional optimizers.",3.2. Learning to Iteratively Optimize,[0],[0]
"For inference optimization, previous works have combined standard inference models with gradient updates (Hjelm et al., 2016; Krishnan et al., 2018; Kim et al., 2018), however, these works do not learn to iteratively optimize.",3.2. Learning to Iteratively Optimize,[0],[0]
"(Putzky & Welling, 2017) use recurrent inference models for MAP estimation of denoised images in linear models.",3.2. Learning to Iteratively Optimize,[0],[0]
"We propose a unified method for learning to perform variational inference optimization, generally applicable to probabilistic latent variable models.",3.2. Learning to Iteratively Optimize,[0],[0]
"Our work extends techniques for learning to optimize along several novel directions, discussed in Section 4.",3.2. Learning to Iteratively Optimize,[0],[0]
We denote an iterative inference model as f with parameters φ.,3.3. Iterative Inference Models,[0],[0]
"With L(i)t ≡ L(x(i),λ",3.3. Iterative Inference Models,[0],[0]
"(i) t ; θ) as the ELBO for data example x(i) at inference iteration t, the model uses the approximate posterior gradients, denoted∇λL(i)t , to output updated estimates of λ(i):
λ (i) t+1",3.3. Iterative Inference Models,[0],[0]
"← ft(∇λL (i) t ,λ (i) t ;φ), (6)
where λ(i)t is the estimate of λ (i) at inference iteration t. Eq. 6 is in a general form and contains, as special cases, the linear update in eq. 4, as well as the residual, nonlinear update used in (Andrychowicz et al., 2016).",3.3. Iterative Inference Models,[0],[0]
"Figure 2 displays a computation graph of the inference procedure, and Algorithm 1 in Appendix B describes the procedure in detail.",3.3. Iterative Inference Models,[0],[0]
"As with standard inference models, the parameters of an iterative inference model can be updated using estimates of∇φL, obtained through the reparameterization trick (Kingma & Welling, 2014; Rezende et al., 2014) or through score function methods (Gregor et al., 2014; Ranganath et al., 2014).",3.3. Iterative Inference Models,[0],[0]
Model parameter updating is performed using stochastic gradient techniques with∇θL and ∇φL.,3.3. Iterative Inference Models,[0],[0]
"We now describe an instantiation of iterative inference models for (single-level) latent Gaussian models, which have a Gaussian prior density over latent variables: p(z) = N (z;µp,diagσ2p).",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"Although the prior is typically a standard Normal density, we use this prior form for generality.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
Latent Gaussian models are often used in VAEs and are a common choice for continuous-valued latent variables.,4. Iterative Inference in Latent Gaussian Models,[0],[0]
"While the approximate posterior can be any probability density, it is typically also chosen as Gaussian: q(z|x) = N (z;µq,diagσ2q ).",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"With this choice, λ(i) corresponds to {µ(i)q ,σ2(i)q } for example x(i).",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"Dropping the superscript (i) to simplify notation, we can express eq. 6 for this model as:
µq,t+1 = f µq t (∇µqLt,µq,t;φ), (7)
σ2q,t+1 = f σ2q t (∇σ2qLt,σ 2 q,t;φ), (8)
where fµqt and f σ2q t are the iterative inference models for updating µq and σ2q respectively.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"In practice, these models can be combined, with shared inputs and model parameters but separate outputs to update each term.
",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"In Appendix A, we derive the stochastic gradients ∇µqL and ∇σ2qL for the cases where pθ(x|z) takes a Gaussian and Bernoulli form, though any output distribution can be used.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"Generally, these gradients are comprised of (1) errors, expressing the mismatch in distributions, and (2) Jacobian matrices, which invert the generative mappings.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"For instance, assuming a Gaussian output density, p(x|z) = N (x;µx,diagσ2x), the gradient for µq is
∇µqL = Jᵀεx − εz, (9)
where the Jacobian (J), bottom-up errors (εx), and topdown errors (εz) are defined as
J ≡ Ez∼q(z|x) [ ∂µx ∂µq ] , (10)
",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"εx ≡ Ez∼q(z|x)[(x− µx)/σ2x], (11) εz ≡ Ez∼q(z|x)[(z− µp)/σ2p].",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"(12)
Here, we have assumed µx is a function of z and σ2x is a global parameter.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
The gradient ∇σ2qL is comprised of similar terms as well as an additional term penalizing approximate posterior entropy.,4. Iterative Inference in Latent Gaussian Models,[0],[0]
"Inspecting and understanding the composition of the gradients reveals the forces pushing the approximate posterior toward agreement with the data, through εx, and agreement with the prior, through εz.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"In other words, inference is as much a top-down process as it is a bottom-up process, and the optimal combination of these terms is given by the approximate posterior gradients.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"As discussed in Section 4.1, standard inference models have traditionally been purely bottom-up, only encoding the data.",4. Iterative Inference in Latent Gaussian Models,[0],[0]
"To increase the model capacity of latent variable models, it is common to add higher-level latent variables, thereby providing flexible empirical priors on lower-level variables.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"Traditionally, corresponding standard inference models were parmeterized as purely bottom-up (e.g. Fig. 1 of (Rezende et al., 2014)).",4.1. Reinterpreting Top-Down Inference,[0],[0]
"It was later found to be beneficial to incorporate top-down information from higher-level variables in the inference model, the given intuition being that “a purely bottom-up inference process . . .",4.1. Reinterpreting Top-Down Inference,[0],[0]
"does not correspond well with real perception” (Sønderby et al., 2016), however, a rigorous justification of this technique was lacking.
",4.1. Reinterpreting Top-Down Inference,[0],[0]
"Iterative inference models, or rather, the gradients that they encode, provide a theoretical explanation for this previously empirical heuristic.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"As seen in eq. 9, the approximate posterior parameters are optimized to agree with the prior, while also fitting the conditional likelihood to the data.",4.1. Reinterpreting Top-Down Inference,[0],[0]
Analogous terms appear in the gradients for hierarchical models.,4.1. Reinterpreting Top-Down Inference,[0],[0]
"For instance, in a chain-structured hierarchical model, the gradient of µ`q , the approximate posterior mean at layer `, is
∇µ`qL = J `ᵀε`−1z",4.1. Reinterpreting Top-Down Inference,[0],[0]
"− ε`z, (13)
where J` is the Jacobian of the generative mapping at layer ` and ε`z is defined similarly to eq. 12.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"ε ` z depends on the top-down prior at layer `, which, unlike the single-level case, varies across data examples.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"Thus, a purely bottom-up inference procedure may struggle, as it must model both the bottom-up data dependence as well as the top-down prior.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"Top-down inference (Sønderby et al., 2016) explicitly uses the prior to perform inference.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"Iterative inference models instead rely on approximate posterior gradients, which naturally account for both bottom-up and top-down influences.",4.1. Reinterpreting Top-Down Inference,[0],[0]
"In the formulation of iterative inference models given in eq. 6, inference optimization is restricted to first-order approximate posterior derivatives.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"Thus, it may require many inference iterations to reach reasonable approximate posterior estimates.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"Rather than calculate costly higher-order derivatives, we can take a different approach.
",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"Approximate posterior derivatives (e.g. eq. 9 and higherorder derivatives) are essentially defined by the errors at the current estimate, as the other factors, such as the Jacobian matrices, are internal to the model.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"Thus, the errors provide more general information about the curvature beyond the gradient.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"As iterative inference models already learn to perform approximate posterior updates, it is natural to ask whether the errors provide a sufficient signal for faster inference optimization.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"In other words, we may be able to offload approximate posterior derivative calculation onto the inference model, yielding a model that requires fewer in-
ference iterations while maintaining or possibly improving computational efficiency.
",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
Comparing with eqs.,4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"7 and 8, the form of this new iterative inference model is
µq,t+1 = f µq t (εx,t, εz,t,µq,t;φ), (14)
σ2q,t+1 = f σ2q",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"t (εx,t, εz,t,σ 2 q,t;φ), (15)
where, again, these models can be shared, with separate outputs per parameter.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"In Section 5.2, we empirically find that models of this form converge to better solutions than gradient-encoding models when given fewer inference iterations.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"It is also worth noting that this error encoding scheme is similar to DRAW (Gregor et al., 2015).",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"However, in addition to architectural differences in the generative model, DRAW and later extensions do not include top-down errors (Gregor et al., 2016), nor error precision-weighting.",4.2. Approximating Approximate Posterior Derivatives,[0],[0]
"Under certain assumptions on single-level latent Gaussian models, iterative inference models of the form in Section 4.2 generalize standard inference models.",4.3. Generalizing Standard Inference Models,[0],[0]
"First, note that εx (eq. 11) is a stochastic affine transformation of x:
εx = Ax+ b, (16)
where A ≡ Eq(z|x)",4.3. Generalizing Standard Inference Models,[0],[0]
"[ (diagσ2x) −1] , (17) b ≡ −Eq(z|x)",4.3. Generalizing Standard Inference Models,[0],[0]
[ µx σ2x ] .,4.3. Generalizing Standard Inference Models,[0],[0]
"(18)
Reasonably assuming that the initial approximate posterior and prior are both constant, then in expectation, A, b, and εz are constant across all data examples at the first inference iteration.",4.3. Generalizing Standard Inference Models,[0],[0]
"Using proper weight initialization and input normalization, it is equivalent to input x or an affine transformation of x into a fully-connected neural network.",4.3. Generalizing Standard Inference Models,[0],[0]
"Therefore, standard inference models are equivalent to the special case of a one-step iterative inference model.",4.3. Generalizing Standard Inference Models,[0],[0]
"Thus, we can interpret standard inference models as learning a map of local curvature around a fixed approximate posterior estimate.",4.3. Generalizing Standard Inference Models,[0],[0]
"Iterative inference models, on the other hand, learn to traverse the optimization landscape more generally.",4.3. Generalizing Standard Inference Models,[0],[0]
"Using latent Gaussian models, we performed an empirical evaluation of iterative inference models on both image and text data.",5. Experiments,[0],[0]
"For images, we used MNIST (LeCun et al., 1998), Omniglot (Lake et al., 2013), Street View House Numbers (SVHN) (Netzer et al., 2011), and CIFAR-10 (Krizhevsky & Hinton, 2009).",5. Experiments,[0],[0]
"MNIST and Omniglot were dynamically binarized and modeled with Bernoulli output
distributions, and SVHN and CIFAR-10 were modeled with Gaussian output densities, using the procedure from (Gregor et al., 2016).",5. Experiments,[0],[0]
"For text, we used RCV1 (Lewis et al., 2004), with word count data modeled with a multinomial output.
",5. Experiments,[0],[0]
Details on implementing iterative inference models are found in Appendix B. The primary difficulty of training iterative inference models comes from shifting gradient and error distributions during the course of inference and learning.,5. Experiments,[0],[0]
"In some cases, we found it necessary to normalize these inputs using layer normalization (Ba et al., 2016).",5. Experiments,[0],[0]
"We also found it beneficial, though never necessary, to additionally encode the data itself, particularly when given few inference iterations (see Figure 7a).",5. Experiments,[0],[0]
"For comparison, all experiments use feedforward networks, though we observed similar results with recurrent inference models.",5. Experiments,[0],[0]
"Reported values of L were estimated using 1 sample, and reported values of log p(x) and perplexity (Tables 1 & 2) were estimated using 5,000 importance weighted samples.",5. Experiments,[0],[0]
"Additional experiment details, including model architectures, can be found in Appendix C. Accompanying code can be found on GitHub at joelouismarino/iterative inference.
",5. Experiments,[0],[0]
Section 5.1 demonstrates the optimization capabilities of iterative inference models.,5. Experiments,[0],[0]
Section 5.2 explores two methods by which to further improve the modeling performance of these models.,5. Experiments,[0],[0]
Section 5.3 provides a quantitative comparison between standard and iterative inference models.,5. Experiments,[0],[0]
"We begin with a series of experiments that demonstrate the inference optimization capabilities of iterative inference
models.",5.1. Approximate Inference Optimization,[0],[0]
These experiments confirm that iterative inference models indeed learn to perform inference optimization through an adaptive iterative estimation procedure.,5.1. Approximate Inference Optimization,[0],[0]
These results highlight the qualitative differences between this inference optimization procedure and that of standard inference models.,5.1. Approximate Inference Optimization,[0],[0]
"That is, iterative inference models are able to effectively utilize multiple inference iterations rather than collapsing to static, one-step encoders.
",5.1. Approximate Inference Optimization,[0],[0]
"Direct Visualization As in Section 3.1, we directly visualize iterative inference optimization in a 2-D latent Gaussian model trained on MNIST with a point estimate approximate posterior.",5.1. Approximate Inference Optimization,[0],[0]
"Model architectures are identical to those used in Section 3.1, with additional details found in Appendix C.1.",5.1. Approximate Inference Optimization,[0],[0]
Shown in Figure 3 is a 16-step inference optimization trajectory taken by the iterative inference model for a particular example.,5.1. Approximate Inference Optimization,[0],[0]
"The model adaptively adjusts inference update step sizes to navigate the optimization surface, quickly arriving and remaining at a near-optimal estimate.
",5.1. Approximate Inference Optimization,[0],[0]
L During Inference We can quantify and compare optimization performance through the ELBO.,5.1. Approximate Inference Optimization,[0],[0]
"In Figure 4, we plot the average ELBO on the MNIST validation set during inference, comparing iterative inference models with conventional optimizers.",5.1. Approximate Inference Optimization,[0],[0]
Details are in Appendix C.2.,5.1. Approximate Inference Optimization,[0],[0]
"On average, the iterative inference model converges significantly faster to better estimates than the optimizers.",5.1. Approximate Inference Optimization,[0],[0]
"The model actually has less derivative information than the optimizers; it only has access to the local gradient, whereas the optimizers use momentum and similar terms.",5.1. Approximate Inference Optimization,[0],[0]
"The model’s final estimates are also stable, despite only being trained using 16 inference iterations.
",5.1. Approximate Inference Optimization,[0],[0]
Reconstructions Approximate inference optimization can also be visualized through image reconstructions.,5.1. Approximate Inference Optimization,[0],[0]
"As the reconstruction term is typically the dominant term in L, the output reconstructions should improve in terms of visual quality during inference optimization, resembling x.",5.1. Approximate Inference Optimization,[0],[0]
We demonstrate this phenomenon with iterative inference models for several data sets in Figure 5.,5.1. Approximate Inference Optimization,[0],[0]
"Additional reconstructions are shown in Appendix C.3.
Gradient Magnitudes During inference optimization, iterative inference models should ideally obtain approximate posterior estimates near local maxima.",5.1. Approximate Inference Optimization,[0],[0]
The approximate posterior gradient magnitudes should thus decrease during inference.,5.1. Approximate Inference Optimization,[0],[0]
"Using a model trained on RCV1, we recorded average gradient magnitudes for the approximate posterior mean during inference.",5.1. Approximate Inference Optimization,[0],[0]
"In Figure 6, we plot these values throughout training, finding that they do, indeed, decrease.",5.1. Approximate Inference Optimization,[0],[0]
See Appendix C.4 for more details.,5.1. Approximate Inference Optimization,[0],[0]
We highlight two sources that allow iterative inference models to further improve modeling performance: additional inference iterations and samples.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
Additional inference iterations allow the model to further refine approximate posterior estimates.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"Using MNIST, we trained models by encoding approximate posterior gradients (∇λL) or errors (εx, εz), with or without the data (x), for 2, 5, 10, and 16 inference iterations.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"While we kept the model architectures identical, the encoded terms affect the number of input parameters to each model.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"For instance, the small size of z relative to x gives the gradient encoding model fewer input parameters than a standard inference model.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
The other models have more input parameters.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"Results are shown in Figure
7a, where we observe improved performance with increasing inference iterations.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
All iterative inference models outperformed standard inference models.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"Note that encoding errors to approximate higher-order derivatives helps when training with fewer inference iterations.
",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"Additional approximate posterior samples provide more precise gradient and error estimates, potentially allowing an iterative inference model to output improved updates.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"To verify this, we trained standard and iterative inference models on MNIST using 1, 5, 10, and 20 approximate posterior samples.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
Iterative inference models were trained by encoding the data (x) and approximate posterior gradients (∇λL) for 5 iterations.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
Results are shown in Figure 7b.,5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"Iterative inference models improve by more than 1 nat with additional samples, further widening the improvement over similar standard inference models.",5.2. Additional Inference Iterations & Latent Samples,[0],[0]
"We now provide a quantitative performance comparison between standard and iterative inference models on MNIST, CIFAR-10, and RCV1.",5.3. Comparison with Standard Inference Models,[0],[0]
"Inference model architectures are identical across each comparison, with the exception of input parameters.",5.3. Comparison with Standard Inference Models,[0],[0]
Details are found in Appendix C.7.,5.3. Comparison with Standard Inference Models,[0],[0]
Table 1 contains estimated marginal log-likelihood performance on MNIST and CIFAR-10.,5.3. Comparison with Standard Inference Models,[0],[0]
Table 2 contains estimated perplexity on RCV12.,5.3. Comparison with Standard Inference Models,[0],[0]
"In each case, iterative inference models outperform standard inference models.",5.3. Comparison with Standard Inference Models,[0],[0]
"This holds for both
2Perplexity re-weights log-likelihood by document length.
single-level and hierarchical models.",5.3. Comparison with Standard Inference Models,[0],[0]
"We observe larger improvements on the high-dimensional RCV1 data set, consistent with (Krishnan et al., 2018).",5.3. Comparison with Standard Inference Models,[0],[0]
"Because the generative model architectures are kept fixed, performance improvements demonstrate improvements in inference optimization.",5.3. Comparison with Standard Inference Models,[0],[0]
"We have proposed iterative inference models, which learn to refine inference estimates by encoding approximate posterior gradients or errors.",6. Conclusion,[0],[0]
"These models generalize and extend standard inference models, and by naturally accounting for priors during inference, these models provide insight and justification for top-down inference.",6. Conclusion,[0],[0]
"Through empirical evaluations, we have demonstrated that iterative inference models learn to perform variational inference optimization, with advantages over current inference techniques shown on several benchmark data sets.",6. Conclusion,[0],[0]
"However, this comes with the limitation of requiring additional computation over similar standard inference models.",6. Conclusion,[0],[0]
"While we discussed the relevance of iterative inference models to hierarchical latent variable models, sequential latent variable models also contain empirical priors.",6. Conclusion,[0],[0]
"In future work, we hope to apply iterative inference models to the online filtering setting, where fewer inference iterations, and thus less additional computation, may be required at each time step.",6. Conclusion,[0],[0]
"We would like to thank the reviewers as well as Peter Carr, Oisin Mac Aodha, Grant Van Horn, and Matteo Ruggero Ronchi for their insightful feedback.",Acknowledgements,[0],[0]
This research was supported in part by JPL PDF 1584398 and NSF 1564330.,Acknowledgements,[0],[0]
"Inference models are a key component in scaling variational inference to deep latent variable models, most notably as encoder networks in variational auto-encoders (VAEs).",abstractText,[0],[0]
"By replacing conventional optimization-based inference with a learned model, inference is amortized over data examples and therefore more computationally efficient.",abstractText,[0],[0]
"However, standard inference models are restricted to direct mappings from data to approximate posterior estimates.",abstractText,[0],[0]
The failure of these models to reach fully optimized approximate posterior estimates results in an amortization gap.,abstractText,[0],[0]
"We aim toward closing this gap by proposing iterative inference models, which learn to perform inference optimization through repeatedly encoding gradients.",abstractText,[0],[0]
"Our approach generalizes standard inference models in VAEs and provides insight into several empirical findings, including top-down inference techniques.",abstractText,[0],[0]
We demonstrate the inference optimization capabilities of iterative inference models and show that they outperform standard inference models on several benchmark data sets of images and text.,abstractText,[0],[0]
Iterative Amortized Inference,title,[0],[0]
"Machine teaching (Zhu, 2015; 2013; Zhu et al., 2018) is the problem of constructing a minimal dataset for a target concept such that a student model (i.e., leaner) can learn the target concept based on this minimal dataset.",1. Introduction,[0],[0]
"Recently, machine teaching has been shown very useful in applications ranging from human computer interaction (Suh et al., 2016), crowd sourcing (Singla et al., 2014; 2013) to cyber security (Alfeld et al., 2016; 2017).",1. Introduction,[0],[0]
"Besides various applications, machine teaching also has nice connections with curriculum learning (Bengio et al., 2009; Hinton et al., 2015).",1. Introduction,[0],[0]
"In traditional machine learning, a teacher usually constructs a batch set of training samples, and provides them to a student in one shot without further interactions.",1. Introduction,[0],[0]
Then the student keeps learning from this batch dataset and tries to learn the target concept.,1. Introduction,[0],[0]
"Previous machine teaching paradigm (Zhu, 2013; 2015; Liu et al., 2016) usually focuses on constructing the smallest such dataset, and characterizing the size of such dataset, called the teaching dimension of the student model.
",1. Introduction,[0],[0]
*Equal contribution 1Georgia Tech 2University of Minnesota 3Ant Financial.,1. Introduction,[0],[0]
"Correspondence to: W. L. <wyliu@gatech.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"For machine teaching to work effectively in practical scenarios, (Liu et al., 2017a) propose an iterative teaching framework which takes into consideration that the learner usually uses iterative algorithms (e.g. gradient descent) to update the models.",1. Introduction,[0],[0]
"Different from the traditional machine teaching framework where the teacher only interacts with the student in one-shot, the iterative machine teaching allows the teacher to interact with the student in every single iteration.",1. Introduction,[0],[0]
"It hence shifts the teaching focus from models to algorithms: the objective of teaching is no longer constructing a minimal dataset in one shot but searching for samples so that the student learns the target concept in a minimal number of iterations (i.e., fastest convergence for the student algorithm).",1. Introduction,[0],[0]
Such a minimal number of iterations is called the iterative teaching dimension for the student algorithm.,1. Introduction,[0],[0]
"(Liu et al., 2017a) mostly consider the simplest iterative case where the teacher can fully observe the student.",1. Introduction,[0],[0]
"This case is interesting in theory but too restrictive in practice.
",1. Introduction,[0],[0]
Human teaching is arguably the most realistic teaching scenario in which the learner is completely a black-box to the teacher.,1. Introduction,[0],[0]
"Analogously, the ultimate problem for machine teaching is how to teach a black-box learner.",1. Introduction,[0],[0]
We call such problem black-box machine teaching.,1. Introduction,[0],[0]
"Inspired by the fact that the teacher and the student typically represent the same concept but in different ways, we present a step towards the black-box machine teaching – cross-space machine teaching, where the teacher i) does not share the same feature representation with the student, and ii) can not observe the
student model.",1. Introduction,[0],[0]
"This setting is interesting in the sense that it can both relax the assumptions for iterative machine teaching and improve our understanding on human learning.
",1. Introduction,[0],[0]
"Inspired by a real-life fact, that a teacher will regularly examine the student to learn how well the student has mastered the concept, we propose an active teacher model to address the cross-space teaching problem.",1. Introduction,[0],[0]
"The active teacher is allowed to actively query the student with a few (limited) samples every certain number of iterations, and the student can only return the corresponding prediction results to the teacher.",1. Introduction,[0],[0]
"For example, if the student uses a linear regression model, it will return to the teacher its prediction 〈wt, x̃〉 where wt is the student parameter at the t-th iteration and x̃ is the representation of the query example in student’s feature space.",1. Introduction,[0],[0]
"Under suitable conditions, we show that the active teacher can always achieve faster rate of improvement than a random teacher that feeds samples randomly.",1. Introduction,[0],[0]
"In other words, the student model guided by the active teacher can provably achieve faster convergence than the stochastic gradient descent (SGD).",1. Introduction,[0],[0]
"Additionally, we discuss the extension of the active teacher to deal with the learner with forgetting behavior, and the learner guided by multiple teachers.
",1. Introduction,[0],[0]
"To validate our theoretical findings, we conduct extensive experiments on both synthetic data and real image data.",1. Introduction,[0],[0]
The results show the effectiveness of the active teacher.,1. Introduction,[0],[0]
Machine teaching defines a task where we need to find an optimal training set given a learner and a target concept.,2. Related Work,[0],[0]
"(Zhu, 2015) describes a general teaching framework which has nice connections to curriculum learning (Bengio et al., 2009) and knowledge distillation (Hinton et al., 2015).",2. Related Work,[0],[0]
"(Zhu, 2013) considers Bayesian learners in exponential family and formulates the machine teaching as an optimization problem over teaching examples that balance the future loss of the learner and the effort of the teacher.",2. Related Work,[0],[0]
"(Liu et al., 2016) give the teaching dimension of linear learners.",2. Related Work,[0],[0]
"Machine teaching has been found useful in cyber security (Mei & Zhu, 2015), human computer interaction (Meek et al., 2016), and human education (Khan et al., 2011).",2. Related Work,[0],[0]
"(Johns et al., 2015) extend machine teaching to human-in-the-loop settings.",2. Related Work,[0],[0]
"(Doliwa et al., 2014; Gao et al., 2015; Zilles et al., 2008; Samei et al., 2014; Chen et al., 2018) study the machine teaching problem from a theoretical perspective.
",2. Related Work,[0],[0]
"Previous machine teaching works usually ignore the fact that a student model is typically optimized by an iterative algorithm (e.g., SGD), and in practice we focus more on how fast a student can learn from the teacher.",2. Related Work,[0],[0]
"(Liu et al., 2017a) propose the iterative teaching paradigm and an omniscient teaching model where the teacher knows almost everything about the learner and provides training examples based on the learner’s status.",2. Related Work,[0],[0]
Our cross-space teaching serves as a stepping stone towards the black-box iterative teaching.,2. Related Work,[0],[0]
The cross-space iterative teaching paradigm is different from the standard iterative machine teaching in terms of two major aspects: i),3. Cross-Space Iterative Machine Teaching,[0],[0]
the teacher does not share the feature representation with the student; ii) the teacher cannot observe the student’s current model parameter in each iteration.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"Specifically, we consider the following teaching settings:
Teacher.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"The teacher model observes a sample A (e.g. image, text, etc.) and represents it as a feature vector xA∈ Rd and a label y∈R. The teacher knows the model (e.g., loss function) and the optimization algorithm (including the learning rate1) of the learner, and the teacher preserves an optimal parameter v∗ of this model in its own feature space.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"We denote the prediction of the teacher as ŷv∗=〈v∗, x〉2.",3. Cross-Space Iterative Machine Teaching,[0],[0]
Learner.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"The learner observes the same sample A and represents it as a vectorized feature x̃A∈Rs and a label ỹ∈R. The learner uses a linear model 〈w, x̃〉 where w is its model parameter and updates it with SGD (if guided by a passive teacher).",3. Cross-Space Iterative Machine Teaching,[0],[0]
"We denote the prediction of the student model as ŷtw=〈wt, x̃〉 in t-th iteration.",3. Cross-Space Iterative Machine Teaching,[0],[0]
Representation.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"Although the teacher and learner do not share the feature representation, we still assume their representations have an intrinsic relationship.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"For simplicity, we assume there exists a unknown one-to-one mapping G from the teacher’s feature space to the student’s feature space such that x̃=G(x).",3. Cross-Space Iterative Machine Teaching,[0],[0]
"However, the conclusions in this paper are also applicable to injective mappings.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"Unless specified, we assume that y = ỹ by default.
",3. Cross-Space Iterative Machine Teaching,[0],[0]
Interaction.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"In each iteration, the teacher will provide a training example to the learner and the learner will update its model using this example.",3. Cross-Space Iterative Machine Teaching,[0],[0]
The teacher cannot directly observe the model parameter w of the student.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"In this paper, the active teacher is allowed to query the learner with a few examples every certain number of iterations.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"The learner can only return to the teacher its prediction 〈wt, x̃〉 in the regression scenario, its predicted label sign(〈wt, x̃〉) or confidence score S(〈wt, x̃〉) in the classification scenario, where wt is the student’s model parameter at t-th iteration and S(·) is some nonlinear function.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"Note that the teacher and student preserve the same loss function `(·, ·).",3. Cross-Space Iterative Machine Teaching,[0],[0]
"Similar to (Liu et al., 2017a), we consider three ways for the teacher to provide examples to the learner:
Synthesis-based teaching.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"In this scenario, the space of provided examples is
X = {x ∈ Rd, ‖x‖ ≤ R} Y = R (Regression) or {−1, 1} (Classification).
",3. Cross-Space Iterative Machine Teaching,[0],[0]
Combination-based teaching.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"In this scenario, the space 1For simplicity, the teacher is assumed to know the learning rate of the learner, but this prior is not necessary, as discussed later.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"2For simplicity, we omit the bias term throughout the paper.",3. Cross-Space Iterative Machine Teaching,[0],[0]
"It is straightforward to add them back.
of provided examples is (αi ∈ R) X = {",3. Cross-Space Iterative Machine Teaching,[0],[0]
x|,3. Cross-Space Iterative Machine Teaching,[0],[0]
"‖x‖ ≤ R, x = Σki=1αixi, xi ∈ D } ,D = {x1, . . .",3. Cross-Space Iterative Machine Teaching,[0],[0]
", xk}
Y = R (Regression) or {−1, 1} (Classification)
Rescalable pool-based teaching.",3. Cross-Space Iterative Machine Teaching,[0],[0]
This scenario further restrict the knowledge pool for samples.,3. Cross-Space Iterative Machine Teaching,[0],[0]
The teacher can pick examples from X ×Y: X = {x|,3. Cross-Space Iterative Machine Teaching,[0],[0]
"‖x‖ ≤ R, x = γxi, xi ∈ D, γ ∈ R},D",3. Cross-Space Iterative Machine Teaching,[0],[0]
=,3. Cross-Space Iterative Machine Teaching,[0],[0]
"{x1, . . .}",3. Cross-Space Iterative Machine Teaching,[0],[0]
"Y = R (Regression) or {−1, 1} (Classification)
",3. Cross-Space Iterative Machine Teaching,[0],[0]
We also note that the pool-based teaching (without rescalability) is the most restricted teaching scenario and it is very close to the practical settings.,3. Cross-Space Iterative Machine Teaching,[0],[0]
"To address the cross-space iterative machine teaching, we propose the active teaching algorithm, which actively queries its student for its prediction output.",4. The Active Teaching Algorithm,[0],[0]
We first describe the general version of the active teaching algorithm.,4. The Active Teaching Algorithm,[0],[0]
"Then without loss of generality, we will discuss three specific examples: least square regression (LSR) learner for regression, logistic regression (LR) and support vector machine (SVM) learner for classification (Friedman et al., 2001).",4. The Active Teaching Algorithm,[0],[0]
"Inspired by human teaching, we expand the teacher’s capabilities by enabling the teacher to actively query the student.",4.1. General Algorithm,[0],[0]
The student will return its predictions to the teacher.,4.1. General Algorithm,[0],[0]
"Based on the student’s feedback, The teacher will estimate the student’s status and determine which example to provide next time.",4.1. General Algorithm,[0],[0]
"The student’s feedback enables the active teacher to teach without directly observing the student’s model.
",4.1. General Algorithm,[0],[0]
"The active teacher can choose to query the learner with a few samples in each iteration, and the learner will usually report the prediction F (〈w, x̃〉) where F (·) denotes some function of the inner product prediction.",4.1. General Algorithm,[0],[0]
"For example, we usually have F (z) = z for regression and F (z)=sign(z) or F (z)= 11+exp(−z) for classification.",4.1. General Algorithm,[0],[0]
"Based on our assumption that there is an unknown mapping from teacher’s feature to student’s feature, there also exists a mapping from the model parameters of the teacher to those of the student.",4.1. General Algorithm,[0],[0]
"These active queries enables the teacher to estimate the student’s corresponding model parameter “in the teacher’s space” and maintain a virtual learner, the teacher’s estimation of the real learner, in its own space.",4.1. General Algorithm,[0],[0]
"The teacher will
decide which example to provide based on its current virtual learner model.",4.1. General Algorithm,[0],[0]
"The ideal virtual learner v will have the same prediction output as the real learner, i.e. 〈v, x〉=〈w, x̃〉 where x̃=G(x).",4.1. General Algorithm,[0],[0]
"Equivalently, v=G>(w) always holds for the ideal virtual learner, where G> is the conjugate mapping of G. Note that for the purpose of analysis, we assume that G is a generic linear operator, though our analysis can easily extends to general cases.",4.1. General Algorithm,[0],[0]
"In fact, one of the most important challenges in active teaching is to recover a virtual student that approximates the real leaner as accurately as possible.",4.1. General Algorithm,[0],[0]
The estimation error of the teacher may affect the quality of training examples that the teacher provides for the real learner.,4.1. General Algorithm,[0],[0]
"Intuitively, if we can recover the virtual learner with an appropriate accuracy, then we can still achieve faster teaching speed than that of passive learning.",4.1. General Algorithm,[0],[0]
"Fig. 2 shows the pipeline of the cross-space teaching.
",4.1. General Algorithm,[0],[0]
"With full access to the obtained virtual learner in the teacher’s space, the teacher can perform omniscient teaching as in (Liu et al., 2017a).",4.1. General Algorithm,[0],[0]
"Specifically, the active teacher will optimize the following objective:
argmin x∈X ,y∈Y
η 2 t ∥∥∥∥∥∂`( 〈 vt, x 〉 , y)",4.1. General Algorithm,[0],[0]
"∂vt ∥∥∥∥∥ 2
2
− 2ηt 〈 v t − v∗, ∂`( 〈 vt, x 〉 , y)
∂vt
〉 (1)
where ` is a loss function and vt is the teacher’s estimation of G>(wt) after the teacher performs an active query in t-th iteration (i.e., the current model parameter of the virtual learner).",4.1. General Algorithm,[0],[0]
ηt is the learning rate of the virtual learner.,4.1. General Algorithm,[0],[0]
The learning rate of the student model is not necessarily needed.,4.1. General Algorithm,[0],[0]
"The general teaching algorithm is given in Algorithm 1.
",4.1. General Algorithm,[0],[0]
"Particularly, different types of feedback (i.e., the form of F (·)) from learners contain different amount of information, resulting in different levels of difficulties in recovering the parameters of the learner’s model.",4.1. General Algorithm,[0],[0]
We will discuss two general ways to recover the virtual learner for two types of frequently used feedbacks in practice.,4.1. General Algorithm,[0],[0]
Exact recovery of the virtual learner.,4.1. General Algorithm,[0],[0]
"We know that the learner returns a prediction in the form of F (〈w, x̃〉).",4.1. General Algorithm,[0],[0]
"In general, if F (·) is an one-to-one mapping, we can exactly recover the ideal virtual learner (i.e. G>(w)) in the teacher’s space using the system of linear equations.",4.1. General Algorithm,[0],[0]
"In other words, the recovery of virtual learner could be exact as long as there is no information loss from 〈w, x̃〉 to F (〈w, x̃〉).",4.1. General Algorithm,[0],[0]
"Specifically, we have 〈v, qj〉=〈w, q̃j〉 where qj is the j-th query for the learner.",4.1. General Algorithm,[0],[0]
"Because 〈w, q̃j〉 is given by the real learner, we only need to construct d queries (d is the dimension of the teacher space) and require {q1, q2, · · · , qd} to be linearly independent to estimate v.",4.1. General Algorithm,[0],[0]
"Without no numerical error, we can exactly recover v.",4.1. General Algorithm,[0],[0]
"Since the recovery is exact, we have G>(w)=v.",4.1. General Algorithm,[0],[0]
Note that there are cases that we can achieve exact recovery without F (·) being an one-to-one mapping.,4.1. General Algorithm,[0],[0]
"For example, F (z) = max(0, z) (hinge function) is not an one-to-one mapping but we can still achieve exact recovery.",4.1. General Algorithm,[0],[0]
Approximate recovery of the virtual learner.,4.1. General Algorithm,[0],[0]
"If F (·) is not an one-to-one mapping (e.g., sign(·) which provides
Algorithm 1 The active teacher 1: Randomly initialize the student parameter w0; 2: Set t = 1, exam = True (i.e., whether we make the student
takes exams) and maximal iteration number T ; 3: while vt has not converged or t < T",4.1. General Algorithm,[0],[0]
do 4: if G>G 6=,4.1. General Algorithm,[0],[0]
"I and exam = True then 5: Obtain an estimation Ĝ>(wt) of the student model in
the teacher’s space using the virtual learner construction Algorithm 2;
6: vt = Ĝ>(wt); 7: else if G>G = I and exam = True then 8: Perform the one-time “background” exam using Algorithm 2 and set exam to False; 9: end if 10: Solve the optimization for the virtual learner (e.g. poolbased teaching):
(xt, yt) = argmin x∈X ,y∈Y η2t ∥∥∥∥∥∂` (〈 vt−1, x 〉 , y ) ∂vt−1 ∥∥∥∥∥ 2
− 2ηt 〈 vt−1 − v∗, ∂` (〈 vt−1, x 〉 , y )
∂vt−1 〉 11: if exam = False then 12: Use the selected example (xt, yt) to perform the update
of the virtual learner in the teacher’s space: vt = vt−1 − ηt ∂` (〈 vt−1, xt 〉 , yt )
∂vt−1 .
13: end if 14: Use the selected example (x̃t, ỹt) where x̃=G(x), ỹ=y to
perform the update of the real learner in the student’s space: wt = wt−1 − ηt ∂` (〈 wt−1, x̃t 〉 , ỹt )
∂wt−1 .
15: t← t+ 1; 16: end while
1-bit feedback), then generally we may not be able to exactly recover the student’s parameters.",4.1. General Algorithm,[0],[0]
"Therefore, we have to develop a more intelligent technique (i.e. less sample complexity) to estimate G>(w).",4.1. General Algorithm,[0],[0]
"In this paper, we use active learning (Settles, 2010) to help the teacher better estimate G>(w) for the virtual learner.",4.1. General Algorithm,[0],[0]
One of the difficulties is that the active learning algorithm obtains the parameters of a model based on the predicted labels on which the norm of the weights has no effect.,4.1. General Algorithm,[0],[0]
It becomes ambiguous which set of weights the teacher should choose.,4.1. General Algorithm,[0],[0]
"Therefore, the active teacher also needs to have access to the norm of the student’s weights for recovering the virtual learner.",4.1. General Algorithm,[0],[0]
"In the following sections, we will develop and analyze our estimation algorithm for the virtual learner based on the existing active learning algorithms with guarantees on sample complexity (Balcan et al., 2009; Ailon, 2012; Hanneke, 2007; Schein & Ungar, 2007; Settles, 2010).",4.1. General Algorithm,[0],[0]
"For the LSR learner, we use the following model:
min w∈Rs,b∈R
1
n n∑ i=1 1 2 (〈w, x̃i〉 − ỹi)2.",4.2. Least Square Regression Learner,[0],[0]
"(2)
Algorithm 2",4.2. Least Square Regression Learner,[0],[0]
"The virtual learner construction 1: if The feedback function F (z) is an one-to-one mapping or a
hinge function then 2:",4.2. Least Square Regression Learner,[0],[0]
"Perform one-time exam by actively query multiple examples; 3: Solve a system of linear equations to obtain the exact recovery of the ideal virtual learner; 4: else 5: Apply acitve learning algorithms to perform an approximate
recovery of the ideal virtual learner (in this case, the teacher will need to know the norm of the student model);
6: end if
Because F (〈w, x̃〉)=〈w, x̃〉, the LSR learner belongs to the case where the active teacher can exactly recover the ideal virtual learner.",4.2. Least Square Regression Learner,[0],[0]
"When G>G = I , the teacher only need to perform active exam once.",4.2. Least Square Regression Learner,[0],[0]
"It can be viewed as a “background exam” for the teacher to figure out how well the student has mastered the knowledge at the beginning, and the teacher can track the dynamics of students exactly later.",4.2. Least Square Regression Learner,[0],[0]
"Otherwise, for a general one-to-one mapping G, the teacher needs to query the student in each iteration.",4.2. Least Square Regression Learner,[0],[0]
"Still, the teacher can reuse the same set of queries in all iterations.",4.2. Least Square Regression Learner,[0],[0]
"For the LR learner, we use the following model (without loss of generality, we consider the binary classification):
min w∈Rs,b∈R
1
n n∑ i=1 log",4.3. Logistic Regression Learner,[0],[0]
"( 1 + exp{−ỹi(〈w, x̃i〉)} ) (3)
We discuss two cases separately: (1) the learner returns the probability of each class (i.e. F (z) = S(z) where S(·) denotes a sigmoid function); (2) the learner only returns the predicted label (i.e. F (z) = sign(z)).
",4.3. Logistic Regression Learner,[0],[0]
"In the first case where F (·) is a sigmoid function, we can exactly recover the ideal virtual learner.",4.3. Logistic Regression Learner,[0],[0]
This case is essentially similar to the LSR learner where we need only one “background exam” if G>G=I,4.3. Logistic Regression Learner,[0],[0]
and we can reuse the queries in each iteration for a general one-to-one mapping G (G>G 6=I).,4.3. Logistic Regression Learner,[0],[0]
"In the second case where F (·) is a sign function, we can only approximate the ideal virtual learner with some error.",4.3. Logistic Regression Learner,[0],[0]
"In this case, we use active learning to do the recovery.",4.3. Logistic Regression Learner,[0],[0]
"For the SVM learner, we use the following model for the binary classification:
min w∈Rs,b∈R
1
n n∑ i=1",4.4. Support Vector Machine Learner,[0],[0]
max(1− yi(wT,4.4. Support Vector Machine Learner,[0],[0]
"x̃i + b), 0) (4)
Similarly, we have two cases: (1) the learner returns the hinge value of each class (i.e. F (z)=max(0, z); (2) the learner only returns the label (i.e. F (z) = sign(z)).
",4.4. Support Vector Machine Learner,[0],[0]
"In the first case where F (·) is a hinge function, we can still recover the ideal virtual learner.",4.4. Support Vector Machine Learner,[0],[0]
"Although the hinge function is not a bijective mapping (only half of it is one-to-one),
we prove that it can still achieve exact recovery with slightly more query samples.",4.4. Support Vector Machine Learner,[0],[0]
"For G>G = I , we need only one “background exam” as in the case of the LR learner.",4.4. Support Vector Machine Learner,[0],[0]
"Otherwise, we still need to query the student in each iteration.",4.4. Support Vector Machine Learner,[0],[0]
"In the second case where F (·) is a sign function, we can only approximate the ideal virtual learner with some error.",4.4. Support Vector Machine Learner,[0],[0]
"We define an important notion of being “exponentially teachable” to characterize the teacher’s performance.
",5. Theoretical Results,[0],[0]
Definition 1,5. Theoretical Results,[0],[0]
"Given > 0, the loss function ` and feature mapping G, (`,G) is exponentially teachable (ET) if the number of total samples (teaching samples and query samples) is t = O(poly(log 1 )) for a learner to achieve - approximation, i.e.,
∥∥G>(wt)− v∗∥∥ ≤ .",5. Theoretical Results,[0],[0]
"Note that the potential dependence of t on the problem dimension is omitted here, which will be discussed in detail in the following.",5. Theoretical Results,[0],[0]
We summarize our theoretical results in Table 1.,5. Theoretical Results,[0],[0]
"Given a learner that is exponentially teachable by the omniscient teacher, we find that the learner is not exponentially teachable by the active teacher only when F (·) is not an one-to-one mapping and the teacher uses rescalable pool-based teaching.",5. Theoretical Results,[0],[0]
We denote σmax = maxx>x=1 G>(x)G(x) and σmin = minx>x=1 G>(x)G(x),5.1. Synthesis-Based Active Teaching,[0],[0]
> 0,5.1. Synthesis-Based Active Teaching,[0],[0]
(G is invertible).,5.1. Synthesis-Based Active Teaching,[0],[0]
We first discuss the teaching algorithm when the teacher is able to exactly recover the student’s parameters.,5.1. Synthesis-Based Active Teaching,[0],[0]
"A generic theory for synthesis-based ET is provided as follows.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Theorem 2 Suppose that the teacher can recover G>(wt) exactly using m samples at each iteration.,5.1. Synthesis-Based Active Teaching,[0],[0]
"If for any v∈Rd, there exists γ 6=0 and ŷ",5.1. Synthesis-Based Active Teaching,[0],[0]
"such that x̂=γ (v−v∗) and
0 < γ∇〈vt,x̂〉` (〈 vt, x̂ 〉 , ŷ )",5.1. Synthesis-Based Active Teaching,[0],[0]
"<
",5.1. Synthesis-Based Active Teaching,[0],[0]
"2σmin ησ2max ,
then (`,G) is ET with O ( (m+ 1) log 1 ) samples.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"Existence of the exponentially teachable (`,G) via exact recovery.",5.1. Synthesis-Based Active Teaching,[0],[0]
"Different from (Liu et al., 2017a) where the condition for synthesis-based exponentially teaching is only related to the loss function",5.1. Synthesis-Based Active Teaching,[0],[0]
"`, the condition for the cross-space teaching setting is related to both loss function ` and feature mapping",5.1. Synthesis-Based Active Teaching,[0],[0]
G.,5.1. Synthesis-Based Active Teaching,[0],[0]
"The spectral property of G is involved due to the differences of feature spaces, leading to the mismatch of parameters of the teacher and student.",5.1. Synthesis-Based Active Teaching,[0],[0]
"It is easy to see that ∃ G such that the commonly used loss functions, e.g., absolute loss, square loss, hinge loss, and logistic loss, are ET with exact recovery, i.e., G>(wt) = vt.",5.1. Synthesis-Based Active Teaching,[0],[0]
"This can be shown
by construction.",5.1. Synthesis-Based Active Teaching,[0],[0]
"For example, if the σminσ2max = 1 2 , the ET condition will be the same for both omniscient teacher (Liu et al., 2017a) and active teacher.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"Next we present generic results of the sample complexity m required to recover G>, which is a constant to (i.e., (`,G) is ET), shown as follows.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Lemma 3,5.1. Synthesis-Based Active Teaching,[0],[0]
"If F (·) is bijective, then we can exactly recover G>(w)∈Rd with d samples.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Lemma 4,5.1. Synthesis-Based Active Teaching,[0],[0]
"If F (·) = max (0, ·), then we can exactly recover G>(w) ∈ Rd with 2d samples.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"Lemma 3 and 4 cover F (·)=I(·), F (·)=S(·), or F (·)= max (0, ·), where I denotes the identity mapping and S denotes some sigmoid function, e.g., logistic function, hyperbolic tangent, error function, etc.",5.1. Synthesis-Based Active Teaching,[0],[0]
"If the student’s answers to the queries via these student feedbacks F (·) in the exam phase, then we can exactly recover v=G>(w)∈Rd with arbitrary d independent data, omitting the numerical error.",5.1. Synthesis-Based Active Teaching,[0],[0]
"Also note that the query samples in Lemma 3 and 4 can be reused in each iteration, thus the query sample complexity is m = O(d), which is formalized as follows.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Corollary 5 Suppose that the student answers questions in query phase via F (·) =,5.1. Synthesis-Based Active Teaching,[0],[0]
"I(·), F (·) = S(·), or F (·) = max (0, ·), then (`,G) is ET with O ( log 1 ) teaching samples and O(d) query samples via exact recovery.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Here we emphasize that the number of query samples (i.e. active queries) does not depend on specific tasks.,5.1. Synthesis-Based Active Teaching,[0],[0]
"For both regression and classification, as long as the student feedbacks F (·) are bijective functions, then Corollary 5 holds.",5.1. Synthesis-Based Active Teaching,[0],[0]
"The loss function only affects the synthesis or selection of the teaching samples.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"In both regression and classification, if F (·) = sign(·) which only provides 1-bit feedback, F−1 no longer exists and the exact recovery of G>(w) may not be obtained.",5.1. Synthesis-Based Active Teaching,[0],[0]
"In such case, the teacher may only approximate the student’s parameter using active learning.",5.1. Synthesis-Based Active Teaching,[0],[0]
"We first present the generic result for ET via approximate recovery as follows.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"Theorem 6 Suppose that the loss function ` is L-Lipschitz smooth in a compact domain Ωv⊂Rd containing v∗ and sample candidates (x, y) are from bounded set X × Y , where X = { x∈Rd, ‖x‖≤R } .",5.1. Synthesis-Based Active Teaching,[0],[0]
"Further suppose at t-th iteration, the teacher estimates the student est :=∥∥G>(wt)−vt∥∥=O ( ) with probability at least 1− δ using m ( est, δ) samples.",5.1. Synthesis-Based Active Teaching,[0],[0]
If for any v ∈,5.1. Synthesis-Based Active Teaching,[0],[0]
"Ωv , there exists γ 6=0 and ŷ",5.1. Synthesis-Based Active Teaching,[0],[0]
"such that for x̂=γ (v−v∗), we have
0 <",5.1. Synthesis-Based Active Teaching,[0],[0]
"γ∇〈vt,x̂〉` (〈 vt, x̂ 〉 , ŷ )",5.1. Synthesis-Based Active Teaching,[0],[0]
"<
2 (1− λ)σmin ησ2max , with 0 <",5.1. Synthesis-Based Active Teaching,[0],[0]
"λ < min (κ (G>G) √
2 , 1 ) ,
then the student can achieve -approximation of v∗ with O ( log 1 ( 1 +m ( λ , δ
log 1
)))",5.1. Synthesis-Based Active Teaching,[0],[0]
"samples with probability
at least 1− δ.",5.1. Synthesis-Based Active Teaching,[0],[0]
"If m ( est, δ) = O(log 1 ), then (`,G) is ET.
Existence of exponentially teachable (`,G) via approximate recovery.",5.1. Synthesis-Based Active Teaching,[0],[0]
"m ( est, δ) is the number of samples needed for approximately recovering G>(wt) in each iteration.",5.1. Synthesis-Based Active Teaching,[0],[0]
"Different from the exact recovery setting wherem only depends on the feature dimension, m ( est, δ) here also depends on how accurately the teacher wants to recover G>(wt) in each iteration ( est denotes the estimation error of G>(wt)).",5.1. Synthesis-Based Active Teaching,[0],[0]
"The condition for exponentially teachable with approximate recovery is related to both (`,G) and the approximation level of the student parameters, i.e., the effect of λ.",5.1. Synthesis-Based Active Teaching,[0],[0]
"For example, if the σminσ2max = 1 and λ = 1 2 , the exponentially teachable condition will be the same for both the omniscient teaching (Liu et al., 2017a) and active teaching with exact recovery.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"For F (·)=sign(·), if the student provides sign (〈w,G(x)〉) for the query x, it is unlikely to recover G>(w) unless we know ∥∥G>(w)∥∥.",5.1. Synthesis-Based Active Teaching,[0],[0]
This leads to the following assumption.,5.1. Synthesis-Based Active Teaching,[0],[0]
Assumption 1,5.1. Synthesis-Based Active Teaching,[0],[0]
"The feedback is 1-bit, i.e. F (·)=sign(·), and the norm of G>(w) is known to teacher.",5.1. Synthesis-Based Active Teaching,[0],[0]
Assumption 1 is necessary because sign(·) is scale invariant.,5.1. Synthesis-Based Active Teaching,[0],[0]
We cannot distinguish between G>(w) and k · G>(w) for any k ∈ R+ only with their signs.,5.1. Synthesis-Based Active Teaching,[0],[0]
"The following theorem provides the query sample complexity in this scenario.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Theorem 7 Suppose that Assumption 1 holds.,5.1. Synthesis-Based Active Teaching,[0],[0]
"Then with probability at least 1−δ, then we can recover G>(w) ∈ Rd with Õ (( d2 + d log 1δ ) log 1 ) query samples.",5.1. Synthesis-Based Active Teaching,[0],[0]
"Combining Theorem 6 with Theorem 7, we have the results for the 1-bit feedback case.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Corollary 8 Suppose Assumption 1 holds.,5.1. Synthesis-Based Active Teaching,[0],[0]
"Then then (`,G) is ET with O ( log 1 ) teaching samples and
Õ (
log 1 log 1 λ
( d2 + d log
log 1 δ
))",5.1. Synthesis-Based Active Teaching,[0],[0]
"query samples.
",5.1. Synthesis-Based Active Teaching,[0],[0]
Trade-off between teaching samples and query samples.,5.1. Synthesis-Based Active Teaching,[0],[0]
There is a delicate trade-off between query sample complexity (in the exam phase) and teaching sample complexity.,5.1. Synthesis-Based Active Teaching,[0],[0]
"Specifically, with est =O ( 1 t2 ) and m ( O ( 1 t2
)) query samples, we can already achieve the conclusion that∥∥G>(wt+1)−v∗∥∥2 converges in rate O ( 1t ), which makes the number of teaching samples to be O ( 1 2 ) .",5.1. Synthesis-Based Active Teaching,[0],[0]
We emphasize that this rate is the same with the convergence of SGD minimizing strongly convex functions.,5.1. Synthesis-Based Active Teaching,[0],[0]
Note that the teaching algorithm can achieve at least this rate for general convex loss.,5.1. Synthesis-Based Active Teaching,[0],[0]
"Compared to the number of teaching samples in Corollary 8, although the query samples is less, this setting requires much more effort in teaching.",5.1. Synthesis-Based Active Teaching,[0],[0]
"Such phenomenon is reasonable in practice in the sense that if the examination is not accurate, the teacher provides the student less effective samples and hence has to teach for more iterations when the teacher cannot accurately evaluate student’s performance.
",5.1. Synthesis-Based Active Teaching,[0],[0]
"We remark that if G is a unitary operator, i.e., G>G = I , we can show that the teacher need only one exam.",5.1. Synthesis-Based Active Teaching,[0],[0]
"The key insight is that after the first “background exam”, the teacher can replace the following exams by updating the virtual
learner via the same dynamic of the real learner.",5.1. Synthesis-Based Active Teaching,[0],[0]
This is formalized as follows.,5.1. Synthesis-Based Active Teaching,[0],[0]
Lemma 9 Suppose that G is a unitary operator.,5.1. Synthesis-Based Active Teaching,[0],[0]
"If∥∥G>(w0)− v0∥∥ ≤ , then ∥∥G>(wt+1)− vt+1∥∥ ≤ .",5.1. Synthesis-Based Active Teaching,[0],[0]
"Therefore, with a unitary feature mapping, we only need one exam in the whole teaching procedure.",5.1. Synthesis-Based Active Teaching,[0],[0]
"It follows that the query sample complexity in theorem 6 will be reduced to Õ (
log 1λ
( d2 + d log
log 1 δ
)) via approximate recovery.",5.1. Synthesis-Based Active Teaching,[0],[0]
We discuss how the results for synthesis-based active teaching can be extended to the combination-based active teaching.,5.2. Combination-Based Active Teaching,[0],[0]
"In this scenario, we assume both training and query samples are constructed by linear combination of k samples in D={xi}ki=1.",5.2. Combination-Based Active Teaching,[0],[0]
"We have the following corollaries for both exact recovery and approximate recovery in the sense of
〈v1, v2〉D := √ v>1 D (D>D)
+D>v2, and ‖v‖D := 〈v, v〉D .
",5.2. Combination-Based Active Teaching,[0],[0]
"Note that with the introduced metric, for v ∈ Rd, we only consider its component in span (D) and the components in the null space will be ignored.",5.2. Combination-Based Active Teaching,[0],[0]
"Therefore, ∀ v1, v2 ∈ span(D) such that ‖v1‖D = ‖v2‖D, we have v>1 x=v>2 x= 〈v1, x〉D for all x ∈ Rd.",5.2. Combination-Based Active Teaching,[0],[0]
Then we have the result via exact recovery as follows.,5.2. Combination-Based Active Teaching,[0],[0]
"Corollary 10 Suppose the learner gives feedbacks in query phase by F (·)=I(·) or F (·)=S(·), and G>(w0), v∗∈ span (D).",5.2. Combination-Based Active Teaching,[0],[0]
"Then (`,G) is ET with O ( log 1 ) teaching samples and rank(D) query samples for exact recovery.",5.2. Combination-Based Active Teaching,[0],[0]
"The result via approximate recovery holds analogously to synthesis-based active teaching, given as follows.",5.2. Combination-Based Active Teaching,[0],[0]
"Corollary 11 Suppose Assumption 1 holds, the student answers questions in query phase via F (·)=",5.2. Combination-Based Active Teaching,[0],[0]
"I(·) or F (·)=S(·) and G>(w0), v∗∈span (D).",5.2. Combination-Based Active Teaching,[0],[0]
"Then (`,G) is ET with O ( log 1 ) teaching samples and
Õ (
log 1 log 1 λ
( d2 + d log
log 1 δ
))",5.2. Combination-Based Active Teaching,[0],[0]
"query samples via ap-
proximate recovery.",5.2. Combination-Based Active Teaching,[0],[0]
"In this scenario, the teacher can only pick examples from a fixed sample candidate pool, D={xi}ki=1, for teaching and active query.",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
We still evaluate with the metric ‖·‖D defined in (5.2).,5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"We first define pool volume to characterize the richness of the pool (Liu et al., 2017a).",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
Definition 12 (Pool Volume),5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"Given the training example pool X ∈ Rd, the volume of X is defined as
V(X )",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
":= min w∈span(D) max x∈X 〈w, x〉D ‖w‖2D .
",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
Then the result via exact recovery is given as follows.,5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"Theorem 13 Suppose that the student answers questions in the exam phase via F (·)=I(·) or F (·)=S(·)
and G>(w0), v∗∈span (D).",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"If ∀ G>(w) ∈ span(D), there exist (x, y) ∈ D × Y and γ such that for x̂= γ‖G>(w)−v∗‖D
‖x‖D",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"x, ŷ=y, we have 0 ≤ γ∇〈vt,x̂〉` (〈 vt, x̂ 〉 , ŷ )",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"≤ 2V (X )σmin
ησ2max , then (`,G) is ET with O ( log 1 ) teaching samples and rank(D) query samples.",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
"For the approximate recovery case, the active learning is no longer able to achieve the desired accuracy for estimating the student’s parameter in the restricted pool scenario.",5.3. Rescaled Pool-Based Active Teaching,[0],[0]
Thus the active teacher may not achieve exponential teaching.,5.3. Rescaled Pool-Based Active Teaching,[0],[0]
The active teacher need not know the learning rate.,6. Discussions and Extensions,[0],[0]
"To estimate the learning rate, the active teacher should first estimate the student’s initial parameters w1 ∈ Rd, and then feed the student with one random sample (xr, yr).",6. Discussions and Extensions,[0],[0]
"Once the updated student’s parameter w2 is estimated by the teacher, the learning rate η can be computed by η=",6. Discussions and Extensions,[0],[0]
"1d ∑( (w1−w2)./∇w`(wT1 x, y) ) where ./ denotes the element-wise division and the sum is over all the dimensions in w1.",6. Discussions and Extensions,[0],[0]
"The number of samples for estimating η will be 2m+1, wherem denotes the samples used in estimating student’s parameter.",6. Discussions and Extensions,[0],[0]
"Even if the learning rate is unknown, the teacher only needs 2m+1 more samples to estimate it.",6. Discussions and Extensions,[0],[0]
"Most importantly, it will not affect the exponential teachability.
",6. Discussions and Extensions,[0],[0]
Teaching with forgetting.,6. Discussions and Extensions,[0],[0]
"We consider the scenario where the learner may forget some knowledge that the teacher has taught, which is very common in human teaching.",6. Discussions and Extensions,[0],[0]
We model the forgetting behavior of the learner by adding a deviation to the learned parameter.,6. Discussions and Extensions,[0],[0]
"Specifically in one iteration, the learner updates its model with wt+1 =wt+ ∇w`(〈wt, x〉, y), but due to the forgetting, its truly learned parameter ŵt+1 is wt+1 + t where t is a random deviation vector.",6. Discussions and Extensions,[0],[0]
"Based on Theorem 6, we can show that such forgetting learner is not ET with a teacher that only knows the learner’s initial parameter and can not observe the learner along iteration.",6. Discussions and Extensions,[0],[0]
"However, the active teacher can make the forgetting learner ET via the active query strategy.",6. Discussions and Extensions,[0],[0]
"More details and experiments are provided in Appendix D.
Teaching by multiple teachers.",6. Discussions and Extensions,[0],[0]
"Suppose multiple teachers sequentially teach a learner, a teacher can not guide the learner without knowing its current parameter.",6. Discussions and Extensions,[0],[0]
It is natural for the teacher to actively estimate the learner.,6. Discussions and Extensions,[0],[0]
Our active teaching can be easily extended to multiple teacher scenario.,6. Discussions and Extensions,[0],[0]
General settings.,7. Experiments,[0],[0]
Detailed settings are given in Appendix B. We mainly evaluate the practical pool-based teaching (without rescaling) in the experiments.,7. Experiments,[0],[0]
"Still, in the exam stage, our active teacher is able to synthesize novel query examples as needed.",7. Experiments,[0],[0]
"The active teacher works in a different feature space from the learner’s space, while the omniscient
teacher (Liu et al., 2017a) can fully observe the learner and works in the same feature space as the learner.",7. Experiments,[0],[0]
The omniscient teacher serves as a baseline (possibly an upper bound) in our experiments.,7. Experiments,[0],[0]
"For active learning, we use the algorithm in (Balcan et al., 2009; Schein & Ungar, 2007).
Evaluation.",7. Experiments,[0],[0]
"For synthetic data, we use two metrics to evaluate the convergence performance: the objective value and∥∥G>(wt)−v∗∥∥
2 w.r.t.",7. Experiments,[0],[0]
the training set.,7. Experiments,[0],[0]
"For real images, we
further use accuracy on the testing set for evaluation.",7. Experiments,[0],[0]
We put the experiments of forgetting learner in Appendix D.,7. Experiments,[0],[0]
We use Gaussian distributed data to evaluate our active teacher model on linear regression and binary linear classification tasks.,7.1. Teaching with Synthetic Data,[0],[0]
"We study the LRS learner with F (〈w, x̃〉)=",7.1. Teaching with Synthetic Data,[0],[0]
"〈w, x̃〉, LR learner with F (〈w, x̃〉) being the sigmoid function, LR learner with F (〈w, x̃〉)=sign(〈w, x̃〉).",7.1. Teaching with Synthetic Data,[0],[0]
"For the first two cases, the active teacher can perform an one-time exam (“background exam”) to exactly recover the ideal virtual learner.",7.1. Teaching with Synthetic Data,[0],[0]
"After recovering the ideal virtual learner, the active teaching could achieve the performance of the omniscient teaching.",7.1. Teaching with Synthetic Data,[0],[0]
The experimental results in Fig. 3(a) and Fig. 3(b) meet our expectations.,7.1. Teaching with Synthetic Data,[0],[0]
"In the initial iterations (on the order of feature dimensions), we can see that the learner does not update itself.",7.1. Teaching with Synthetic Data,[0],[0]
"In this stage, the active teacher provides query samples to the learner and recover a virtual learner based on the feedbacks of these query samples.",7.1. Teaching with Synthetic Data,[0],[0]
"After the exact recovery of the virtual learner, one can observe that the active teacher achieves faster convergence compared with the random teacher (SGD).",7.1. Teaching with Synthetic Data,[0],[0]
"In fact, the active teacher and the omniscient teacher should achieve the same convergence speed if omitting numerical errors.
",7.1. Teaching with Synthetic Data,[0],[0]
"For the LR learner with F (〈w, x̃〉)=sign(〈w, x̃〉), the teacher could only approximate the learner with the active learning algorithm.",7.1. Teaching with Synthetic Data,[0],[0]
"Besides, the active teacher needs to know the norm of the student model.",7.1. Teaching with Synthetic Data,[0],[0]
"We use the algorithm in (Schein & Ungar, 2007) and recover the virtual learner in each iteration such that ‖Ĝ>(w)−G>(w)‖2 becomes small enough.",7.1. Teaching with Synthetic Data,[0],[0]
"From the results in Fig. 3(c), we can see that due to the approximation error between the recovered virtual learner and the ideal virtual learner, the active teacher can not achieve the same performance as the omniscient teacher.",7.1. Teaching with Synthetic Data,[0],[0]
"However, the convergence of the active teacher is very close to the omniscient teacher, and is still much faster than SGD.",7.1. Teaching with Synthetic Data,[0],[0]
"Note that, we remove the iterations used for exams to better compare the convergence of different approaches.",7.1. Teaching with Synthetic Data,[0],[0]
"We apply the active teacher to teach the LR learner on the MNIST dataset (LeCun et al., 1998) to further evaluate the performance.",7.2. Teaching with Real Image Data,[0],[0]
"In this experiment, we perform binary classification on the digits 7 and 9.",7.2. Teaching with Real Image Data,[0],[0]
"We use two random projections to obtain two sets of 24-dim features for each image: one is for the teacher’s feature space and the other is for the
Towards Black-box Iterative Machine Teaching
0 100 200 300 400 500 600
0
10
20
30
40
50
60
70
0 100 200 300 400 500 600
0
1
2
3
4
5
6
7
8
SGD Omniscient Teacher Active Learner
0 200 400 600 800
0
1
2
3
4
5
SGD Omniscient Teacher Active Teacher
0",7.2. Teaching with Real Image Data,[0],[0]
"200 400 600 800
0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Background Exam
Background Test
Background Test Background Test
0 200 400 600 800 1000 1200
0
1
2
3
4
5
SGD Omniscient Teacher Active Teacher
0 200 400 600 800 1000 1200
0
0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Iteration Number
SGD Omniscient Teacher Active Teacher
Iteration NumberIteration Number
Iteration Number Iteration NumberIteration Number
D if
fe re
n c e b
e tw
e e n
w t",7.2. Teaching with Real Image Data,[0],[0]
"a n
d w
*
D if
fe re
n c e b
e tw
e e n
w t",7.2. Teaching with Real Image Data,[0],[0]
"a n
d w
*
D if
fe re
n c e b
e tw
e e n
w t",7.2. Teaching with Real Image Data,[0],[0]
"a n
d w
*
O",7.2. Teaching with Real Image Data,[0],[0]
"b
je",7.2. Teaching with Real Image Data,[0],[0]
"c ti
v e V
a lu
e
O b
je",7.2. Teaching with Real Image Data,[0],[0]
"c ti
v e V
a lu
e
O b
je",7.2. Teaching with Real Image Data,[0],[0]
"c ti
v e V
a lu
e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmoid) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regression (F(z) is sign)
0",7.2. Teaching with Real Image Data,[0],[0]
"100 200 300 400 500 600 0
10
20
30
40 50 60 70
0 100 2 0 300 400 5 0 600 0
1
2
3
4
5
6
7
8
SGD Omniscient Teacher Active Teacher
0 200 400 600 800 0
1
2
3 4 5
SGD Omniscient Teacher Active Teacher
0 200 400 600 8 0 0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Background Test
Background Test
Background Exam Background Test
0 200 400 600 800 1000 1200 0
1
2
3 4 5 SGD Omniscient Teacher Active Teacher
0 200 400 600 800 1000 1200 0
0.5
1
1.5
2 2.5 SGD Omniscient Teacher Active Teacher
Iteration Number
SGD Omniscient Teacher Active Learner
Iteration NumberIteration Number
Itera ion Number Iteration NumberIteration Number
D iff
er en
ce b
et w
ee n vt a nd v *
D iff
er en
ce b
et w
ee n",7.2. Teaching with Real Image Data,[0],[0]
"vt a nd v *
D iff
er en
ce b
et w
ee n",7.2. Teaching with Real Image Data,[0],[0]
"vt a nd v *
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmoid) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regression (F(z) is sign)
LSR LSR
0 100 200 300 400 500 600 0
10
20
30
40
50
60
70
0 100 200 300 400 500 600 0
1
2
3
4
5
6
7
8
SGD Omniscient Teacher Active Learner
0 200 400 600 800 0
1
2
3
4
5
SGD Omniscient Teacher Active Teacher
0",7.2. Teaching with Real Image Data,[0],[0]
"200 400 600 800 0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Background Test
Background Exam
Background Test Background Test
0 200 400 600 800 1000 1200 0
1
2
3
4 5 SGD Omniscient Teacher Active Teacher
0 200 400 600 800 1000 1200 0
0.5
1
1.5
2 2.5 SGD Omniscient Teacher Active Teacher
Iteration Number
SGD Omniscient Teacher Active Learner
Iteration NumberIteration Number
Iteration Number Iteration NumberIteration Number
D iff
er en
ce b
et w
ee n
w t a
nd w
*
D iff
er en
ce b
et w
ee n
w t a
nd w
*
D iff
er en
ce b
et w
ee n
w t a
nd w
*
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmoid) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regression (F(z) is sign)
0",7.2. Teaching with Real Image Data,[0],[0]
"100 200 300 400 500 600 0
10
20
30
40
50
60
70
0 100 200 300 400 500 600 0
1
2
3
4
5
6
7
8
SGD Omniscient Teacher Active Learner
0 200 400 600 800 0
1
2
3
4
5
SGD Omnisc ent Teacher Active Teacher
0 2 0 400 600 80 0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Background Test
Background Test
Background Test Background Exam
0 200 400 600 800 1000 1200 0
1
2
3
4 5 SGD Omniscient eac r Active Teacher
0 200 400 600 800 1000 1200 0
0.5
1
1.5
2 2.5 SGD Omniscient eac",7.2. Teaching with Real Image Data,[0],[0]
"er Active Teacher
Iteration Number
SGD Omniscient Teacher Active Learner
Iteration NumberIteration Number
Iteration Number Iteration NumberIteration Number
D iff
er en
ce b
et w
ee n
vt a
nd v
*
D iff
er en
ce b
et w
ee n
vt a
nd v
*
D iff
er en
ce b
et w
ee n
vt a
nd v
*
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmoid) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regression (F(z) is sign)
",7.2. Teaching with Real Image Data,[0],[0]
"LR (F (z) is sigmoid) LR (F (z) is sigmoid)
0",7.2. Teaching with Real Image Data,[0],[0]
"100 200 300 400 500 600 0
10
20
30
40
50
60
70
0 100 200 300 400 500 600 0
1
2
3
4
5
6
7
8
SGD Omniscient Teacher Active Learner
0 200 400 600 800 0
1
2
3
4
5
SGD Omniscient Teacher Active Teacher
0 200 400 600 800 0.5
1
1.5
2
2.5
SGD Omniscient Teacher Active Teacher
Background Test
Background Test
Background Test Background Test
0 200 400 600 800 1000 1200 0
1
2
3
4
5
O niscient",7.2. Teaching with Real Image Data,[0],[0]
"Teacher Active Teacher
0 200 400 600 800 1000 1200 0
0.5
1
1.5
2
2.5
SGD
Omniscient Teacher
Active Teacher
Iteration Number
SGD Omniscient Teacher Active Learner
Iteration NumberIteration Number
Iteration Number Iteration NumberIteration Number
D iff
er en
ce b
et w
ee n
w t",7.2. Teaching with Real Image Data,[0],[0]
"a
nd w
*
D iff
er en
ce b
et w
ee n
w t a
nd w
*
D iff
er en
ce b
et w
ee n
w t a
nd w
*
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
O
bj
ec tiv
e Va
lu e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmoid) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regression (F(z) is sign)
0",7.2. Teaching with Real Image Data,[0],[0]
"100 200 300 400 500 600 0
10
20
30
40
50
60
70
0 100 2 0 300 400 5 0 600 0
1
2
3
4
5
6
7
8
SGD Omnisc ent Teacher Active Learner
0 200 400 600 800 0
1
2
3
4
5
SGD Omniscient Teacher Active Teacher
0 2 0 400 600 80 0.5
1
1.5
2
2.5
SGD Omnisc ent Teacher Active Teacher
Background Test
Background Test
Background Test Background Test
0 200 400 600 800 1000 1200 0
1
2
3
4 5 SGD Omniscient Teacher Active Teacher
0 200 400 600 800 1000 1200 0
0.5
1
1.5
2 2.5 SGD Omniscient Teacher Active Teacher
Iteration Number
SGD Omniscient Teacher Active Learner
Iteration NumberIteration Number
Iteration Number Iteration NumberItera ion Number
D iff
er en
ce b
et w
ee n
vt a
nd v
*
D iff
er en
ce b
et w
ee n
vt a
nd v
*
D iff
er en
ce b
et w
ee n
vt a
nd v
*
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
O bj
ec tiv
e Va
lu e
(d) Least Square Regression (e) Logistic Regression (F(z) is sigmo d) (f) Logistic Regression (F(z) is sign)
(a) Least Square Regression (b) Logistic Regression (F(z) is sigmoid) (c) Logistic Regre sion (F(z) is sign)
",7.2. Teaching with Real Image Data,[0],[0]
LR (F (z) is sign),7.2. Teaching with Real Image Data,[0],[0]
"LR (F (z) is sign)
",7.2. Teaching with Real Image Data,[0],[0]
"Figure 3: The convergence performance of random teacher (SGD), omniscient teacher and ctive teacher.",7.2. Teaching with Real Image Data,[0],[0]
"As we need to perform the active query in each iteration for logistic regression (F (z) is sign), we remove the iteration for fair comparison.",7.2. Teaching with Real Image Data,[0],[0]
"We only show the teaching complexity for fair comparison.
student’s feature space.",7.2. Teaching with Real Image Data,[0],[0]
"The omniscient teacher uses the student’s space as its own space (i.e., shared feature space), while the active teacher uses different feature space with the student.",7.2. Teaching with Real Image Data,[0],[0]
"For the LR learner with sign function (i.e. 1-bit feedbacks), one can observe that the active teacher has comparable performance to the omniscient teacher, even doing better at the beginning.",7.2. Teaching with Real Image Data,[0],[0]
"Because we evaluate the teaching performance on real image data, the omniscient teacher will not necessarily be an upper bound of all the teacher.",7.2. Teaching with Real Image Data,[0],[0]
"Still, as the algorithms iterate, the active teacher becomes worse than the omniscient teacher due to its approximation error.
",7.2. Teaching with Real Image Data,[0],[0]
"In the right side of Fig.4, we visualize the images selected by the active teacher, omniscient teacher and random teacher.",7.2. Teaching with Real Image Data,[0],[0]
"The active teacher preserves the pattern of images selected by the omniscient teacher: starting from easy examples first and gradually shifting to difficult ones, while the images selected by the random teacher have no patterns.",7.2. Teaching with Real Image Data,[0],[0]
"As a step towards the ultimate black-box machine teaching, cross-space teaching greatly relaxes the assumptions of previous teaching scenarios and bridges the gap between the iterative machine teaching and the practical world.",8. Conclusions and Open Problems,[0],[0]
"The ac-
Iteration Number Iteration NumberIteration Number
O bj
ec tiv
e Va
lu e
D iff
er en
ce b
et w
ee n
vt a
nd v
*
A cc
ur ac
y
(a) Logistic Regression (F(z) is sign) (b) Logistic Regression (F(z) is sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
SGD Omniscient Teacher Active Teacher
500 1000 1500 2000 0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
SGD Omniscient Teacher Active Teacher
500 10 1500 2000 0
0.05
0.1
0.15
0.2
0.25
0.3
SGD Omniscient Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher (e) Omniscient Teacher (f) Random Teacher (SGD)
",8. Conclusions and Open Problems,[0],[0]
"Iteration Number Iteration NumberIteration Number
O bj
ec tiv
e Va lu e
D iff
er en
ce b
et w ee n",8. Conclusions and Open Problems,[0],[0]
"vt a nd v *
A cc
ur ac y
(a) Logistic Regression (F(z) is sign)",8. Conclusions and Open Problems,[0],[0]
"(b) Logistic Regression (F(z) is sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65 0.7 0.75 0.8 0.85
SGD Omniscient Teacher Active Teacher
0 500 1000 1500 2000 0.35
0.4
0.45
0.5
0.55 0.6 0.65 0.7 0.75
SGD Omniscient Teacher Active Teacher
0 500 1000 1500 2000 0
0.05
0.1
0.15 0.2 0.25 0.3
SGD Omniscient Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher (e) Omniscient Teacher (f) Random Teacher (SGD)LR (F (z) is sign)",8. Conclusions and Open Problems,[0],[0]
"Active Teacher
Iteration Number Iteration NumberIteration Number
O bj
ec tiv
e Va
lu e
D iff
er en
ce b
et w
ee n
vt a
nd v
*
A cc
ur ac
y
(a) Logistic Regression (F(z) is sign) (b) Logistic Regression (F(z) is sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
SGD Omniscient Teacher Active Teacher
0 500 10 1500 2000 0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
SGD Omniscient Teacher Active Teacher
0 500 1000 1500 2000 0
0.05
0.1
0.15
0.2
0.25
0.3
SGD Omniscient Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher (e) Omniscient Teacher (f) Random Teacher (SGD)
",8. Conclusions and Open Problems,[0],[0]
"It r ti r Iteration NumberIteration Number
O bj
ec tiv
e Va
lu e
D iff
er en
ce b
et w
ee n
vt a
nd v
*
A cc
ur ac
y
(a) Logistic Regre sion (F(z) is sign) (b) Logistic Regression (F(z) i sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
SGD Omniscient Teacher Active Teacher
5 0 10 1500 2000 0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
",8. Conclusions and Open Problems,[0],[0]
"0.7
SGD Omniscient Teacher Active Teach r
0 500 1 00 1500 200 0
0.05
0.1
0.15
0.2
0.25
0.3
SGD Omnisci nt Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher e Omniscient T acher (f) Random Teacher (SGD)LR (F (z) is sign)",8. Conclusions and Open Problems,[0],[0]
"Omniscient Teacher
Iteration Number Iteration NumberIteration Number
O bj
ec tiv
e Va
lu e
D iff
er en
ce b
et w
ee n
vt a
nd v
*
A cc
ur ac
y
(a) Logistic Regression (F(z) is sign) (b) Logistic Regression (F(z) is sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
SGD Omniscient Teacher Active Teacher
0 500 1000 1500 2000 0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
SGD Omniscient Teacher Active Teacher
0 500 1000 1500 2000 0
0.05
0.1
0.15
0.2
0.25
0.3
SGD Omniscient Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher (e) Omni cient T acher (f) Random Teacher (SGD)
Iteration u ber Iteration NumberIteration u ber
O bj
ec tiv
e Va
lu e
D iff
er en
ce b
et w
ee n
vt a
nd v
*
A cc
ur ac
y
(a) Logistic Regres ion (F(z) is sign) (b) Logistic Regression (F(z) is sign) (c) Logistic Regression (F(z) is sign)
0 1000 2000 3000 4000 0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
SGD Omniscient Teacher Active Teacher
0 5 100 1500 2000 .35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
SGD Omniscient Teacher Active Teacher
0 500 1 0 1500 2000 0
0.05
0.1
0.15
0.2
0.25
0.3
SGD Omniscient Teacher Active Teacher
Iteration 1-40 Iteration 601-640 Iteration 1201-1240Iteration 1-40 Iteration 601-640 Iteration 1201-1240 Iteration 1-40 Iteration 601-640 Iteration 1201-1240
(d) Active Teacher (e) Omnisc ent Teacher (f) Random Teacher (SGD)LR (F (z) is sign)",8. Conclusions and Open Problems,[0],[0]
"Random Teacher (SGD)
Figure 4: The convergence performance of random teacher (SGD), omniscient teacher and active teacher in MNIST 7/9 classification.",8. Conclusions and Open Problems,[0],[0]
"Similar to the previous, we only show the teaching complexity for fair comparison.",8. Conclusions and Open Problems,[0],[0]
"More experiments on the logistic regression with F (z)=S(z) is in Appendix C.
tive teaching strategy is inspired by realistic human teaching.",8. Conclusions and Open Problems,[0],[0]
"For machine teaching to be applicable in practice, we need to gradually remove all the unrealistic assumptions to obtain more realistic teaching scenario.",8. Conclusions and Open Problems,[0],[0]
The benefits of more realistic machine teaching are in two folds.,8. Conclusions and Open Problems,[0],[0]
"First, it enables us make better use of the existing off-the-shelf pretrained models to teach a new model on some new tasks.",8. Conclusions and Open Problems,[0],[0]
"It is also related to transfer learning (Pan & Yang, 2010).",8. Conclusions and Open Problems,[0],[0]
"Second, it can improve our understanding on human education and provide more effective teaching strategies for humans.
",8. Conclusions and Open Problems,[0],[0]
Rescalable pool-based active teaching with 1-bit feedback.,8. Conclusions and Open Problems,[0],[0]
The proposed algorithm may not work the in poolbased teaching setting when the student return 1-bit feedback.,8. Conclusions and Open Problems,[0],[0]
"We leave the possibility of achieving exponential teachability in this setting as an open problem.
",8. Conclusions and Open Problems,[0],[0]
Relaxation for the conditions on G. Current constraints on the operator G are still too strong to match more practical scenarios.,8. Conclusions and Open Problems,[0],[0]
How to relax the conditions on G is important.,8. Conclusions and Open Problems,[0],[0]
A better alternative to approximate recovery?,8. Conclusions and Open Problems,[0],[0]
Is there some other tool other than active learning for our teacher to recover the virtual learner?,8. Conclusions and Open Problems,[0],[0]
"For example, 1-bit compressive sensing (Boufounos & Baraniuk, 2008) may help.",8. Conclusions and Open Problems,[0],[0]
"The project was supported in part by NSF IIS-1218749, NSF Award BCS-1524565, NIH BIGDATA 1R01GM108341, NSF CAREER IIS-1350983, NSF IIS-1639792 EAGER, NSF CNS-1704701, ONR N00014-15-1-2340, Intel ISTC, NVIDIA, and Amazon AWS.",Acknowledgements,[0],[0]
"In this paper, we make an important step towards the black-box machine teaching by considering the cross-space machine teaching, where the teacher and the learner use different feature representations and the teacher can not fully observe the learner’s model.",abstractText,[0],[0]
"In such scenario, we study how the teacher is still able to teach the learner to achieve faster convergence rate than the traditional passive learning.",abstractText,[0],[0]
"We propose an active teacher model that can actively query the learner (i.e., make the learner take exams) for estimating the learner’s status and provably guide the learner to achieve faster convergence.",abstractText,[0],[0]
The sample complexities for both teaching and query are provided.,abstractText,[0],[0]
"In the experiments, we compare the proposed active teacher with the omniscient teacher and verify the effectiveness of the active teacher model.",abstractText,[0],[0]
Towards Black-box Iterative Machine Teaching,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1527–1536 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"The ability to automatically learn concepts1 from examples is a core cognitive ability, with applications across diverse domains.",1 Introduction,[0],[0]
"Examples of such concepts include the concept of a ‘negative review’ in product reviews, the concept of ‘check’ over the domain of game states in chess, the concept of ‘fraud’ in credit history analysis, etc.",1 Introduction,[0],[0]
"Concept learning is generally approached using classification
1where a concept is any Boolean function on some domain of instances.
methods that can automatically leverage regularities in large amounts of labeled training data.",1 Introduction,[0],[0]
"However, there are two shortcomings of this paradigm.",1 Introduction,[0],[0]
"First, labeling large amounts of data is unnatural compared to how a person might teach another person (e.g., a human secretary) in a similar situation.",1 Introduction,[0],[0]
"For example, for identifying emails about postdoc positions, a university professor might say ‘These inquiries usually seek a postdoc opportunity and include a CV’, rather than label scores of examples of such emails.",1 Introduction,[0],[0]
"Second, acquiring large quantities of labeled data may be infeasible because of a long tail of concepts that are highly domain or user specific.",1 Introduction,[0],[0]
"For our example of a busy professor, it might be relevant to teach concepts such as ‘postdoc seeking emails’, ‘course related questions from students’, etc. to an email assistant in order to better manage her/his inbox.",1 Introduction,[0],[0]
"However, these concepts might be irrelevant to a general user.
",1 Introduction,[0],[0]
"On the other hand, humans can efficiently learn about new concepts and phenomena through language.",1 Introduction,[0],[0]
"In fact, verbal and written language form the basis for much of human learning and pedagogy, as reflected in text-books, lectures and student-teacher dialogues.",1 Introduction,[0],[0]
"Natural language explanations can be a potent mode of supervision, and can alleviate issues of data sparsity by directly encoding relevant knowledge about concepts.",1 Introduction,[0],[0]
"Figure 1 shows
1527
examples of concepts explained using natural language.",1 Introduction,[0],[0]
"In general, natural language can subsume several modes of supervision: instance labeling (e.g., ‘This email is spam’), feature labeling (e.g., ‘The word ‘Viagra’ indicates spam’), model expectations (‘Spam emails rarely come from edu extensions’), etc.",1 Introduction,[0],[0]
"However, here we focus on the ability of natural language to express rich and compositional features for characterizing concepts.
",1 Introduction,[0],[0]
"In this paper, we address the task of learning concepts from natural language statements and a small number of labeled examples of the concept.",1 Introduction,[0],[0]
Figure 2 summarizes the outline of our approach.,1 Introduction,[0],[0]
"We map statements to logical interpretations, which can be evaluated in context of new instances.",1 Introduction,[0],[0]
"In doing this, each statement s effectively acts as a binary feature function {z = fs(x) ∈ {0, 1}} that fires when the interpretation of a statement s is true for an instance x.",1 Introduction,[0],[0]
"The crux of our approach is that correct interpretations of natural language explanations are more likely to be useful in discriminating concepts, and this observation can be used to guide both semantic interpretation and concept learning2.
",1 Introduction,[0],[0]
"In Section 3, we describe our probabilistic latent variable formulation that learns a semantic parser and a concept classifier from labeled examples of the concept.",1 Introduction,[0],[0]
"The latent variables correspond to evaluations of natural language statements for different instances, and training proceeds via a generalized EM procedure that iteratively (1) estimates evaluations of explanations (marginalizing over all
2e.g., a parser may associate multiple incorrect interpretations with the statement in Figure 2 (like stringMatch(attachment stringVal (‘usually’))), which are unlikely to help in discriminating instances of the concept.
interpretations), and (2) updates the classification and semantic parsing models.",1 Introduction,[0],[0]
"The inputs to the method consist of a small number of labeled examples and non-examples of a concept, natural language statements explaining the concept, and a domain specific lexicon.",1 Introduction,[0],[0]
"The method does not require labeling sentences with logical forms.
",1 Introduction,[0],[0]
"For our empirical evaluation, we focus on personal emails, a practical example of a domain where target concepts are often highly individualized and labeled data is scarce.",1 Introduction,[0],[0]
"The contributions of this work are: • We introduce the problem of concept learning
from natural language.",1 Introduction,[0],[0]
"We also collect a corpus of emails about common email concepts, along with statements from human users explaining these concepts.",1 Introduction,[0],[0]
• We provide a method for concept learning and language understanding that can be trained from a small number of labeled concept instances.,1 Introduction,[0],[0]
"Thus, we extend supervised semantic parsing by learning from a weaker form of supervision than has previously been explored.",1 Introduction,[0],[0]
"• We demonstrate that for small labeled data, using natural language statements can achieve substantial gains in classification accuracy.",1 Introduction,[0],[0]
"Concept learning from labeled examples has been a dominant focus of research in supervised learning (Caruana et al., 2008).",2 Related work,[0],[0]
"Notable approaches such as Generalized Expectation (Mann and McCallum, 2010) and Posterior Regularization (Ganchev et al., 2010) have explored integration of manually provided ‘side-information’ (feature and label constraints) to guide machine learning models.",2 Related work,[0],[0]
"Earlier work on Explanation-based learning (Mitchell et al., 1986; DeJong and Mooney, 1986) leverages structured knowledge to ‘explain’ why an example belongs to a concept.",2 Related work,[0],[0]
"Recent work by Lake et al. (2015) explores visual concept learning from few examples, and presents encouraging results for one-shot learning by learning representations over Bayesian programs.",2 Related work,[0],[0]
"However, none of these address the issue of learning from natural language.
",2 Related work,[0],[0]
Semantic interpretation of language has been explored in diverse domains.,2 Related work,[0],[0]
"While semantic parsers have traditionally relied on labeled datasets of statements paired with labeled logical forms (Zettlemoyer and Collins, 2005), recent approaches have focused on training semantic parsers from
denotations of logical forms, rather than logical forms themselves (Krishnamurthy and Mitchell, 2012; Berant et al., 2013).",2 Related work,[0],[0]
"Our work extends this paradigm by attempting to learn from still weaker signal, where denotations (evaluations) of logical forms too are not directly observed.",2 Related work,[0],[0]
"Similar to our work, previous approaches have used different kinds of external-world signals to guide semantic interpretation (Liang et al., 2009; Branavan et al., 2009).",2 Related work,[0],[0]
"Natural instructions have been studied in game playing frameworks (Branavan et al., 2012; Eisenstein et al., 2009).",2 Related work,[0],[0]
"Our work is also closely related to work by Goldwasser and Roth (2014); Clarke et al. (2010), who also train semantic parsers in weakly supervised contexts, where language interpretation is integrated in real-world tasks.",2 Related work,[0],[0]
"The general idea of learning through human interactions has previously been explored in settings such as behavioral programming (Harel et al., 2012), natural language programming (Biermann, 1983), learning by instruction (Azaria et al., 2016), etc.",2 Related work,[0],[0]
"To the best of our knowledge, this work is the first to use semantic interpretation to guide concept learning.",2 Related work,[0],[0]
"We consider concept learning problems in which the goal is to approximate an unknown classification function f : X → Y where Y = {0, 1}.",3 Method,[0],[0]
"The input to our learning algorithm consists of a set of labeled training examples T := {(x1, y1), . . .",3 Method,[0],[0]
", (xm, ym)}, along with a set of natural language statements S := {s1 . . .",3 Method,[0],[0]
sn} about the concept.,3 Method,[0],[0]
Our aim is to leverage statements in S to learn a better classifier for the concept.,3 Method,[0],[0]
"Our training data does not contain any other form of supervision (such as logical forms).
",3 Method,[0],[0]
"We assume that each statement sj defines some Boolean property over the instances X; that is,
statement sj should be interpreted as defining a predicate lj : X",3 Method,[0],[0]
"→ {0, 1}.",3 Method,[0],[0]
"We augment the representation of each instance, xi, with a feature vector zi, that encodes the information contained in S. The individual elements of this feature vector, zij ∈ {0, 1}, denote whether the statement sj applies to instance xi (see Figure 3).",3 Method,[0],[0]
"In the general case, the evaluation values zi’s are not directly observed.",3 Method,[0],[0]
These are obtained by parsing each statement sj into a logical expression lj :,3 Method,[0],[0]
"X → {0, 1} which can be evaluated for an instance xi to obtain zij = JljKxi .",3 Method,[0],[0]
"Details of this evaluation are given in Section 3.4.
",3 Method,[0],[0]
"In this paper, we jointly learn a classifier and a semantic parser while treating z’s as latent variables.",3 Method,[0],[0]
"For training, we maximize the conditional log likelihood of the observed data.",3 Method,[0],[0]
Let us consider the log likelihood for a single data instance (ignoring the subscript i) for now.,3 Method,[0],[0]
"Since the evaluations z of natural statements for any context are latent, we marginalize over these.",3 Method,[0],[0]
"Using Jensen’s inequality, any distribution q over the latent variables provides a lower-bound on the data log-likelihood:
log p(y | x,S) = log ∑ z p(y, z | x,S)
",3 Method,[0],[0]
"≥ ∑ z q(z) log p(y, z | x,S) q(z)
= ∑ z q(z) ( log pθc(y",3 Method,[0],[0]
"| z, x)︸ ︷︷ ︸
classification
+ log pθp(z | x,S)︸ ︷︷ ︸ parsing )",3 Method,[0],[0]
+,3 Method,[0],[0]
"Hq
(1)
Here,Hq is the entropy term for the distribution q.",3 Method,[0],[0]
"In Equation 1, we observe that the data likelihood decouples into the log probability of observing the concept labels pθc(yi | z, x) conditioned on the statement evaluations and the log probability of the latent statement evaluations pθp(z | x,S).",3.1 Coupling parsing and classification:,[0],[0]
"In particular, the first term can be naturally parametrized by a discriminative classifier such as a loglinear model (with associated parameters θc).",3.1 Coupling parsing and classification:,[0],[0]
"We provide more details in Section 3.3.
",3.1 Coupling parsing and classification:,[0],[0]
"On the other hand, the probability of the latent statement evaluation values z can be parametrized using a probabilistic semantic parsing model (with associated parameters θp).",3.1 Coupling parsing and classification:,[0],[0]
"The second term decouples over evaluations of individual statements (log pθp(z | x,S) = ∑ j log pθp(zj | x, sj)).",3.1 Coupling parsing and classification:,[0],[0]
"In
turn, since we never observe the correct interpretation l for any statement, but only model its evaluation zj , we marginalize over all interpretations whose evaluations in a context x matches zj (similar to Liang et al. (2011)).
log pθp(zj | x, sj) = log ∑
l:JlKx=zj pθp(l | sj) (2) Following recent work in semantic parsing (Liang and Potts, 2015; Krishnamurthy and Mitchell, 2012), we use a log-linear model over logical forms:
pθp(l | s) ∝",3.1 Coupling parsing and classification:,[0],[0]
"exp(θpTφ(s, l))",3.1 Coupling parsing and classification:,[0],[0]
"(3) where φ(s, l) ∈ Rd is a feature vector over statements s and logical interpretations l.",3.1 Coupling parsing and classification:,[0],[0]
"In Equation 1, q(z) denotes a distribution over evaluation values of statements; whereas θc and θp denote the model parameters for the classifier and semantic parser.",3.2 Learning:,[0],[0]
"The learning algorithm consists of an iterative generalized EM procedure, which can be interpreted as a block-coordinate ascent in the estimates of statement evaluations q(z) and the model parameters θc and θp.
",3.2 Learning:,[0],[0]
"E-step: In the E-step, we update our estimates of evaluation variables (z).",3.2 Learning:,[0],[0]
We make a mean-field approximation by assuming that the joint distribution over evaluations decouples as q(z) = ∏ qj(zj).,3.2 Learning:,[0],[0]
"Then maximizing the lower bound in Equation 1 in terms of qj leads to the following update:
qj(zj) ∝",3.2 Learning:,[0],[0]
"exp (
E j′ 6=j
[log pθc(z|x)]+log pθp(zj |x, sj) )
(4) The first term in the update prefers values of an evaluation variable that are more discriminative on average (when values of other statements are marginalized out).",3.2 Learning:,[0],[0]
The second term favours values of the evaluation variable that conforms with the most likely interpretations of the corresponding statement (sj) by the semantic parser.,3.2 Learning:,[0],[0]
"Thus, in the E-step, we upweight evaluations of statements that are both discriminative, as well as supported by interpretations from the semantic parser.
",3.2 Learning:,[0],[0]
"M-step: In the M-step, we update the model parameters to maximize the lower bound in Equation 1.",3.2 Learning:,[0],[0]
"This corresponds to independently optimizing the log likelihoods for the classification model and
the semantic parser, based on current estimates of qj(zj)’s of the statement evaluations.",3.2 Learning:,[0],[0]
"The entropy term Hq is constant from the perspective of model parameters, and is not relevant for the optimization.",3.2 Learning:,[0],[0]
"In particular, the semantic parser is updated to agree with evaluations of natural language statements that are discriminative.",3.2 Learning:,[0],[0]
"At the same time, the classification model is updated to fit evaluations that are supported by interpretations from the semantic parser.
",3.2 Learning:,[0],[0]
"We now describe the M-step updates for the loglinear semantic parser with parameters, θp.",3.2 Learning:,[0],[0]
"The updates for the classifier parameters, θc, depend on the form of the classification model, and are described in Section 3.3.",3.2 Learning:,[0],[0]
"For clarity, we focus on updates corresponding to a particular statement sj from the training dataset.",3.2 Learning:,[0],[0]
"From Equations 1, 2 and 3, the objective for the semantic parser is given by:
`j(θp) =",3.2 Learning:,[0],[0]
"∑ i ∑ z∈{0,1} q(zij) log
∑ l:JlKxi=z exp(θp
Tφ(sj ,",3.2 Learning:,[0],[0]
l))∑,3.2 Learning:,[0],[0]
"l exp(θp Tφ(sj , l))
",3.2 Learning:,[0],[0]
"(5)
Semantic parsers are usually optimized using gradient updates.",3.2 Learning:,[0],[0]
"Here, the gradient is:
∇`j(θp) = ∑ i,z,l q(zij)pθp(l | s) pθp(zij 6= z|xi, s) pθp(zij = z|xi, s) φ(sj",3.2 Learning:,[0],[0]
", l)
(6)",3.2 Learning:,[0],[0]
The model and learning procedure described in Sections 3.1 and 3.2 is agnostic to the choice of the classification model (with parameters θc).,3.3 Classification models,[0],[0]
"For this work, we experimented with a logistic classifier (LR) and a Naive Bayes model (NB).",3.3 Classification models,[0],[0]
We briefly describe these here: Logistic Regression (LR): The form of the logistic function log p(y|z) =,3.3 Classification models,[0],[0]
"− log(1 + exp(-θTc z y)) means that the likelihood does not decouple for individual components in z. Hence, in the E-step, the expectation in Equation 4 cannot be computed analytically.",3.3 Classification models,[0],[0]
"Instead, we estimate this by drawing Bernoulli samples for individual zj’s using previous estimates of qj(zj).",3.3 Classification models,[0],[0]
"In the M-step, we update classification parameters θc using stochastic gradient updates, while again sampling individual zj’s.",3.3 Classification models,[0],[0]
"Naive Bayes (NB): The likelihood for this model is p(y, z) = ∏",3.3 Classification models,[0],[0]
j θ zj cy(1− θcy)1−zj .,3.3 Classification models,[0],[0]
"In this case, the individual components of z decouple in the log likelihood, leading to simple updates in both the E and M steps.",3.3 Classification models,[0],[0]
"While this is not a conditional likelihood
(as expected in Section 3.1), in our experiments we found that the NB objective to be empirically effective with our approach.",3.3 Classification models,[0],[0]
"Semantic parsing refers to mapping a sentence s like ‘The subject contains the word postdoc’ to a logical form l like getPhraseMention(subject, stringVal(‘postdoc’)).",3.4 Semantic Parsing details,[0],[0]
"Logical forms can be evaluated in a context x (here, an email) to yield some meaningful output JlKx (whether the statement is true for an email).",3.4 Semantic Parsing details,[0],[0]
The predicates (such as stringVal) and constants (such as subject) come from a pre-specified logical language.,3.4 Semantic Parsing details,[0],[0]
"Since our focus in this work is concepts about emails, we specify a logical language that is expressive enough to be useful for concept learning in this domain.",3.4 Semantic Parsing details,[0],[0]
"Table 1 lists the predicates in our logical language along with descriptions of their evaluation, and some illustrative examples showing how they can represent the meaning of natural statements3.",3.4 Semantic Parsing details,[0],[0]
Note that this logical language can express compositional meanings.,3.4 Semantic Parsing details,[0],[0]
"e.g., ‘These inquiries will usually seek a postdoc opportunity
3We include a special predicate (unknown) to label statements whose meanings go beyond our logical language (last row in Table 1), essentially ignoring them.",3.4 Semantic Parsing details,[0],[0]
Such statements compose about 25% of our data.,3.4 Semantic Parsing details,[0],[0]
An agent should ideally be able to ask a user about unfamiliar concepts such as ‘weird email addresses’ that occur in explanations.,3.4 Semantic Parsing details,[0],[0]
"See Section 6.
and include a CV’ can be expressed as and (getPhrasesLike(email, stringVal(‘seek
postdoc opportunity’)), (stringMatch attachment (stringVal‘CV’))).",3.4 Semantic Parsing details,[0],[0]
The evaluations of some predicates uses NLP tools that go beyond exact keyword matching.,3.4 Semantic Parsing details,[0],[0]
"In Section 5, we show that it is language understanding (semantic parsing), rather than these resources, which enables learning from natural explanations.
",3.4 Semantic Parsing details,[0],[0]
"Semantic parsers involve grammars containing mappings from words to symbols in the logical language, as well as coarse syntactic rules.",3.4 Semantic Parsing details,[0],[0]
The grammar specifies the possible set of logical interpretations that can be associated with a natural language sentence.,3.4 Semantic Parsing details,[0],[0]
"For this work, we use CCG based semantic parsing, a popular semantic parsing approach (Zettlemoyer and Collins, 2005; Artzi et al., 2015) that couples syntax with semantics.",3.4 Semantic Parsing details,[0],[0]
"For the CCG grammar, we manually compile a domain lexicon containing a list of trigger words mapped to their syntactic categories and associated logical predicates.",3.4 Semantic Parsing details,[0],[0]
"e.g. {‘subject’, NP, subject}.",3.4 Semantic Parsing details,[0],[0]
"We then use the PAL lexicon induction algorithm (Krishnamurthy, 2016) to expand the lexicon by adding automatically generated entries.",3.4 Semantic Parsing details,[0],[0]
"For training the parser, we follow the feature set from (Zettlemoyer and Collins, 2007), consisting of indicator features for lexicon entries and rule applications that fire for a given parse of a logical form.",3.4 Semantic Parsing details,[0],[0]
"We also include
string based features denoting the number of words in a string span, and whether a string spans occur at the beginning or end of the utterance.",3.4 Semantic Parsing details,[0],[0]
"For retrieving the best parses for a statement, we use beam search with a beam size of 500.
While we have chosen a particular instantiation of a semantic parsing formalism, our learning approach is independent of the semantic parsing framework in principle, and only assumes a loglinear parametrization over logical interpretations of sentences.",3.4 Semantic Parsing details,[0],[0]
"Thus, while we present results for a particular parsing framework and lexicon, the method may conceptually extend to other parsing formalisms such as DCS (Liang et al., 2011).",3.4 Semantic Parsing details,[0],[0]
"We created a dataset of 1,030 emails paired with 235 natural language statements made by human users in the process of teaching a set of seven concepts.",4 Data,[0],[0]
The dataset was collected using the Amazon Mechanical Turk crowdsourcing platform.,4 Data,[0],[0]
"We deployed two tasks: (i) a Generation task requiring workers to create original emails, and (ii) a Teaching task requiring workers to write statements that characterize a concept.",4 Data,[0],[0]
"Below, we describe the data and the two tasks in more detail.
",4 Data,[0],[0]
"We create an email corpus, rather than use an existing corpus such as Enron, since we wanted diverse examples representative of everyday concepts that most people would be able to understand as well as teach to a computer.",4 Data,[0],[0]
"Much of the Enron corpus is highly specific and contextualized, making it difficult to teach for an outsider.
",4 Data,[0],[0]
"The Generation task consisted of a web-page resembling a traditional email composition form (with fields: recipient, subject, body, attachment), requiring workers to compose emails in a grounded setting.",4 Data,[0],[0]
"For this task, we recruited 146 workers residing in the United States.",4 Data,[0],[0]
"The workers were presented with each of the seven concepts in a sequence, where each concept was represented by a short prompt encouraging workers to imagine a scenario (e.g., a boss writing a request to an employee) and write a hypothetical email.",4 Data,[0],[0]
See Table 2 for details of email concepts and corresponding prompts.,4 Data,[0],[0]
"Workers were instructed to be realistic (e.g., to include an attachment if an email is likely to have an attachment in reality), but also creative (to encourage diversity) in composing their emails.
",4 Data,[0],[0]
"The Teaching task was then deployed to collect natural language statements that people would
make to teach a particular concept to a machine.",4 Data,[0],[0]
Workers were presented with five randomly selected concepts using the same prompts (Table 2) used in the Generation task.,4 Data,[0],[0]
"For each concept, a small sample of emails were shown in a style resembling a traditional email inbox (Figure 4) to illustrate the concept.",4 Data,[0],[0]
"Half of the emails were from the prompted concept (these emails were highlighted and “starred”), and half were sampled randomly from the other concepts.",4 Data,[0],[0]
Workers were encouraged to peruse through the emails while creating up to five statements explaining the concept.,4 Data,[0],[0]
"A followup quiz assessed an understanding of the task, and contributions from workers with low scores were filtered.",4 Data,[0],[0]
The final data contains between 30 and 35 statements describing each category.,4 Data,[0],[0]
"In this section, we evaluate the performance of our approach from the perspectives of concept learn-
ing as well as semantic parsing.",5 Evaluation,[0],[0]
"We first compare our methods against traditional supervised learning methods on the task of learning email-based concepts described in the previous section.
",5 Evaluation,[0],[0]
"Our baselines include the following models: Text-only models: • BoW: A logistic regression (LR) classifier over
bag-of-words representation of emails • BoW tf-idf: LR classifier over bag-of-words rep-
resentation, with tf-idf weighting •",5 Evaluation,[0],[0]
"Para2Vec: LR classifier over a distributed repre-
sentation of documents, using deep neural network approach by Le and Mikolov (2014).",5 Evaluation,[0],[0]
"• Bigram: LR model also incorporating bigram features, known to be competitive on several text classification tasks (Wang and Manning, 2012).",5 Evaluation,[0],[0]
"• ESA: LR model over ESA (Explicit Semantic Analysis) representations of emails (Gabrilovich and Markovitch, 2007), which describe a text in terms of its Wikipedia topics.
",5 Evaluation,[0],[0]
"Models incorporating Statements: • RTE: This uses a Textual Entailment model
(based on features from Sachan et al. (2015)) that computes a score for aligning of each statement to the text of each email.",5 Evaluation,[0],[0]
"A logistic regression is
trained over this representation of the data.",5 Evaluation,[0],[0]
"• Keyword filtering: Filters based on keywords are
common in email systems.",5 Evaluation,[0],[0]
We add this as a baseline by manually filtering statements referring to occurrences of specific keywords.,5 Evaluation,[0],[0]
Such statements compose nearly 30% of the data.,5 Evaluation,[0],[0]
"We train a logistic regression over this representation.
",5 Evaluation,[0],[0]
Table 4 shows classification performance of our approaches for Learning from Natural Language (LNL) against baselines described above for n = 10 labeled examples.,5 Evaluation,[0],[0]
The reported numbers are average F1 scores over 10 data draws.,5 Evaluation,[0],[0]
We observe that Bigram and bag-of-word methods are the most competitive among the baselines.,5 Evaluation,[0],[0]
"On the other hand, Para2Vec doesn’t perform well, probably due to the relatively small scale of the available training data, while ESA fails due to the lack of topical associations in concepts.",5 Evaluation,[0],[0]
"However, most significantly, we observe that both LNL-NB (Naive Bayes) and LNL-LR (Logistic Regression) dramatically outperform all baselines for most concepts (except EMPLOYEE), and show a 30% relative improvement in average F1 over other methods (p < 0.05, Paired Permutation test).",5 Evaluation,[0],[0]
"Interestingly, we note that LNLNB and LNL-LR show similar performance for most
concepts.",5 Evaluation,[0],[0]
"For evaluating semantic parsing of natural language statements, we manually annotated the statements in our dataset using the logical language described in Section 3.4.",5 Evaluation,[0],[0]
"In Table 4, LNL-Gold denotes the classification performance with using these annotated gold parses.",5 Evaluation,[0],[0]
This corresponds to the hypothetical case where the classifier knows the correct semantic interpretation of each natural language sentence from an oracle.,5 Evaluation,[0],[0]
"While this provides a further 10% relative improvement over our proposed models, the results suggest that our weakly supervised method is quite effective in interpreting natural language statements for concept learning, without explicit supervision.",5 Evaluation,[0],[0]
"We also observe that LNL models perform significantly better than Keyword filtering (p < 0.05), indicating that the model leverages the expressiveness of our logical language.
",5 Evaluation,[0],[0]
"Finally, the last three rows show performance when the LNL methods also utilize BoW representations of the data.",5 Evaluation,[0],[0]
"The further gains over the base LNL models suggest that original feature representations and natural language explanations contain complementary information for many concepts.
",5 Evaluation,[0],[0]
A significant motivation for this work is the promise of natural language explanations in facilitating concept learning with a relatively small number of examples.,5 Evaluation,[0],[0]
Figure 5 shows the dependence of concept learning performance of LNL(-LR) on the number of labeled training examples (size of training set).,5 Evaluation,[0],[0]
"We observe that while our approach consistently outperforms the bag-of-words model (BoW), LNL also requires fewer examples to reach near optimal performance, before it plateaus.",5 Evaluation,[0],[0]
"In particular, the generalization performance for LNL is more robust than BoW for n < 10.",5 Evaluation,[0],[0]
"The performance trajectory for LNL(-NB) is similar, and omitted in the figure for clarity.
",5 Evaluation,[0],[0]
"Parsing performance: We next evaluate the parsing performance of our approach, which learns a semantic parser from only concept labels of examples.",5 Evaluation,[0],[0]
Table 5 evaluates parsing performance against the gold annotation logical forms for statements.,5 Evaluation,[0],[0]
"For this task, we check for exact match of logical forms.",5 Evaluation,[0],[0]
"In the table, full supervision refers to traditional training of a semantic parser using complete annotations of statements with their logical forms (Zettlemoyer and Collins, 2007).",5 Evaluation,[0],[0]
"The results report average accuracy over 10-fold CV, and demonstrate that while not comparable to supervised parsing, our weakly supervised approach is relatively effective in learning semantic parsers.
",5 Evaluation,[0],[0]
"Further, exact match to gold annotated logical forms is a restrictive measure.",5 Evaluation,[0],[0]
"Qualitative analysis revealed that even when the predicted and gold annotation logical forms don’t match, predicted logical forms are often strongly correlated in terms of evaluation to gold annotations.",5 Evaluation,[0],[0]
"e.g., getPhraseMention( email, stringVal(‘postdoc’))",5 Evaluation,[0],[0]
"vs getPhraseMention( body, stringVal(‘postdoc’)).",5 Evaluation,[0],[0]
"In about 5% of cases, predicted and gold interpretations are different on the surface, but are semantically equivalent (e.g., stringEquals( sender, recipient) vs stringEquals( recipient, sender)).
",5 Evaluation,[0],[0]
"Concept learning vs language interpretation: To delineate the relationship between parsing performance and concept learning more clearly, we plot concept classification performance for different levels of semantic parsing proficiency in Figure 6.",5 Evaluation,[0],[0]
"For this, we choose the gold annotation logical form for a statement with a probability corresponding to the semantic parsing accuracy, or randomly select a candidate logical form with a uniform probability otherwise for all the statements in our data.",5 Evaluation,[0],[0]
"The figure shows a (expectedly) strong association between parsing performance and concept learning, although gains from parsing taper after a certain level of proficiency.",5 Evaluation,[0],[0]
"This is partially explained by the fact that natural statements in our
data often contain overlapping information, and that the set of statements in our data set may not be sufficient to achieve perfect classification accuracy.",5 Evaluation,[0],[0]
We show that natural language explanations can be utilized by supervised learning methods to significantly improve generalization.,6 Conclusion and Future Work,[0],[0]
"This suggests a broader class of possible machine learning interfaces that use language to not only expedite learning, but make machine learning accessible to everyday users.",6 Conclusion and Future Work,[0],[0]
"Thus, we hope that the current work will inspire further explorations in learning from natural language explanations.",6 Conclusion and Future Work,[0],[0]
"In terms of scalability, learning from language would require specification of a logical language and a lexicon of trigger words for each new domain.",6 Conclusion and Future Work,[0],[0]
"However, this effort is onetime, and can find re-use across the long tail of concepts in a domain.
",6 Conclusion and Future Work,[0],[0]
"A consequence of the expressiveness of language is that in describing a concept, humans often invoke other concepts that may not correspond to existing predicates in the logical language.",6 Conclusion and Future Work,[0],[0]
"A natural solution could detect that a feature described in the statement is novel4, and request the user to teach the unknown concept.",6 Conclusion and Future Work,[0],[0]
"The same principle can be applied recursively, resulting in a mixed-initiative dialog, much like between a student and a teacher.",6 Conclusion and Future Work,[0],[0]
Future work can also incorporate other modes of supervision from language.,6 Conclusion and Future Work,[0],[0]
"For example, this work ignores modifiers such as ‘always’ and ‘usually’, which often carry valuable information that could be incorporated via model expectation constraints.",6 Conclusion and Future Work,[0],[0]
This research was supported by the Yahoo! InMind project.,Acknowledgments,[0],[0]
"The authors thank Sujay Jauhar and
4currently the parser returns (unknown) for such statements
anonymous reviewers for helpful comments and suggestions.",Acknowledgments,[0],[0]
Natural language constitutes a predominant medium for much of human learning and pedagogy.,abstractText,[0],[0]
"We consider the problem of concept learning from natural language explanations, and a small number of labeled examples of the concept.",abstractText,[0],[0]
"For example, in learning the concept of a phishing email, one might say ‘this is a phishing email because it asks for your bank account number’.",abstractText,[0],[0]
"Solving this problem involves both learning to interpret open-ended natural language statements, as well as learning the concept itself.",abstractText,[0],[0]
We present a joint model for (1) language interpretation (semantic parsing) and (2) concept learning (classification) that does not require labeling statements with logical forms.,abstractText,[0],[0]
"Instead, the model prefers discriminative interpretations of statements in context of observable features of the data as a weak signal for parsing.",abstractText,[0],[0]
"On a dataset of email-related concepts, this approach yields across-theboard improvements in classification performance, with a 30% relative improvement in F1 score over competitive classification methods in the low data regime.",abstractText,[0],[0]
Joint Concept Learning and Semantic Parsing from Natural Language Explanations,title,[0],[0]
"“To make it tractable for the distance metric learning algorithms we perform dimensionality reduction by PCA to a 100 dimensional subspace” (Koestinger et al., 2012).",1. Introduction,[0],[0]
"“Like most of the metric learning methods we first center the dataset and reduce the dimensionality to a n-dimensional space by PCA” (Bohné et al., 2014).",1. Introduction,[0],[0]
"“ITML and LDML are intractable when using 600 PCA dimensions” (Guillaumin et al., 2009).
",1. Introduction,[0],[0]
"These quotations, extracted from the metric learning literature, give rise to a simple question: Is PCA, or, more generally, dimensionality reduction, a must to make metric learning work on high-dimensional data, such as that in computer vision problems?
",1. Introduction,[0],[0]
"To quantify this, in the top portion of Table 1, we provide the area under the ROC curve of state-of-the-art metric learning techniques applied to the ASLAN dataset (KliperGross et al., 2012) using various PCA dimensions (denoted
1Data61, CSIRO, Canberra, Australia 2Australian National University, Canberra, Australia 3CVLab, EPFL, Switzerland.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Mehrtash Harandi <mehrtash.harandi@anu.edu.au>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
by p).",1. Introduction,[0],[0]
"These results suggest that state-of-the-art methods either scale poorly with the dimensionality of the input and thus require PCA to remain tractable (e.g., LDML), or require PCA to achieve an accuracy comparable to the other baselines (e.g., KISSME).
",1. Introduction,[0],[0]
"In essence, this observation indicates that dimensionality reduction is beneficial to (i) reduce the computational burden of the algorithms; and (ii) extract the relevant information from the original noisy data.",1. Introduction,[0],[0]
"However, it also raises an additional question: Is PCA, or any other specific dimensionality reduction technique, really the best method for the problem at hand?",1. Introduction,[0],[0]
"In other words, Shouldn’t we rather learn the low-dimensional representation and the metric jointly?
",1. Introduction,[0],[0]
"Motivated by these questions, in this paper, we introduce a unified formulation for dimensionality reduction and metric learning.",1. Introduction,[0],[0]
"As suggested by our results on the ASLAN dataset in the bottom row of Table 1, our method outperforms the state-of-the-art metric learning techniques.",1. Introduction,[0],[0]
"Furthermore, despite the fact that we directly use highdimensional features as input, our method has comparable runtimes to that of the fastest algorithms working on PCAbased low-dimensional representations.
",1. Introduction,[0],[0]
"In the context of Mahalanobis metric learning, several methods have proposed to allow the metric M to have low rank, thus inherently performing dimensionality reduction.",1. Introduction,[0],[0]
"Most methods, however, achieve this implicitly, by letting M be positive semi-definite (Weinberger & Saul, 2009; Davis et al., 2007), which, as opposed to explicit dimensionality reduction, does not reduce the computational cost of these algorithms.",1. Introduction,[0],[0]
"As a consequence, they still need to rely on PCA as a pre-processing step in practice.",1. Introduction,[0],[0]
"While (Lu et al., 2014) explicitly decomposes M = LLT , it enforces orthogonality constraints on L to disambiguate the solutions, thus effectively only performing dimensionality reduction, and not metric learning.",1. Introduction,[0],[0]
"By contrast, our approach lets us learn a complete Mahalanobis metric jointly with a low-dimensional projection.
",1. Introduction,[0],[0]
At the heart of our joint dimensionality reduction and metric learning formulation lie notions of Riemannian geometry and quotient spaces.,1. Introduction,[0],[0]
"More specifically, we model the projection to a low-dimensional space as a point on a Stiefel manifold, and the metric in this space as a Symmetric Pos-
itive Definite (SPD) matrix.",1. Introduction,[0],[0]
We then show that our search space reduces to a quotient of the product space of the Stiefel and SPD manifolds with the orthogonal group.,1. Introduction,[0],[0]
"By building upon recent advances in optimization on Riemannian matrix manifolds (Absil et al., 2009), we therefore develop a mathematical framework that effectively and efficiently lets us find a solution in this space.",1. Introduction,[0],[0]
"Furthermore, we show that our formulation can be kernelized.",1. Introduction,[0],[0]
"This not only lets us handle non-linearity in the data, but also makes our approach applicable to non-vectorial input data, such as linear subspaces (Harandi et al., 2014), which have proven beneficial for many recognition tasks.
",1. Introduction,[0],[0]
"We demonstrate the benefits of our joint dimensionality reduction and metric learning approach over existing metric learning schemes on several tasks, including action similarity matching, face verification and person re-identification.",1. Introduction,[0],[0]
"In this work, as most metric learning algorithms, we are interested in learning a Mahalanobis distance defined below.
",2. Mathematical Background,[0],[0]
Definition 1 (The Mahalanobis distance).,2. Mathematical Background,[0],[0]
"The Mahalanobis distance between x and x̃ in Rn is defined as
d2M (x, x̃) =",2. Mathematical Background,[0],[0]
‖x− x̃‖2M = (x− x̃)TM(x− x̃) .,2. Mathematical Background,[0],[0]
"(1)
To have a valid metric, the Mahalanobis matrix M must be positive definite.
",2. Mathematical Background,[0],[0]
"As will be shown in Section 3, our approach to learning a Mahalanobis metric can be formulated as a non-convex optimization problem on a Riemannian manifold.",2. Mathematical Background,[0],[0]
"This type of problems can be expressed with the general form
minimize f(z)
s.t. z ∈M , (2)
where M is a Riemannian manifold, i.e., informally, a smooth surface that locally resembles a Euclidean space.
",2. Mathematical Background,[0],[0]
"While Riemannian manifolds can often be explicitly encoded in terms of constraints on z, the recent advances in Riemannian optimization techniques (Absil et al., 2009)
have shown the benefits of truly exploiting the geometry of the manifold over standard constrained optimization.",2. Mathematical Background,[0],[0]
"As a consequence, these techniques have become increasingly popular in diverse application domains (Mishra et al., 2014; Harandi et al., 2017; Cunningham & Ghahramani, 2015).",2. Mathematical Background,[0],[0]
"A detailed discussion of Riemannian optimization goes beyond the scope of this paper, and we refer the interested reader to (Absil et al., 2009).
",2. Mathematical Background,[0],[0]
"As will be discussed in details in Section 3, we formulate metric learning in the quotient space of the product space of two Riemannian manifolds with the orthogonal group.",2. Mathematical Background,[0],[0]
"The two Riemannian manifolds at the heart of this formulation are the Stiefel manifold and the manifold of Symmetric Positive Definite (SPD) matrices defined below.
",2. Mathematical Background,[0],[0]
Definition 2 (The Stiefel Manifold).,2. Mathematical Background,[0],[0]
"The set of (n × p)dimensional matrices, p ≤ n, with orthonormal columns endowed with the Frobenius inner product1 forms a compact Riemannian manifold called the Stiefel manifold St(p, n)",2. Mathematical Background,[0],[0]
"(Boothby, 2003).
St(p, n) , {W ∈ Rn×p : W TW = Ip} .",2. Mathematical Background,[0],[0]
"(3)
Definition 3 (The SPD Manifold).",2. Mathematical Background,[0],[0]
"The set of (p × p) dimensional real, SPD matrices endowed with the Affine Invariant Riemannian Metric (AIRM)",2. Mathematical Background,[0],[0]
"(Pennec et al., 2006) forms the SPD manifold Sp++.
Sp++ , {M ∈ Rp×p :",2. Mathematical Background,[0],[0]
"vTMv > 0, ∀v ∈",2. Mathematical Background,[0],[0]
Rp − {0p}} .,2. Mathematical Background,[0],[0]
"(4)
The dimensionality of St(p, n) and Sp++ are np− 12p(p+1) and p(p+ 1)/2, respectively.",2. Mathematical Background,[0],[0]
"Our goal, as that of many other metric learning algorithms, is to learn a Mahalanobis distance between the input measurements.",3. Our Approach,[0],[0]
"Ideally, this distance should reflect the class
1Note that the literature is divided between this choice and another form of Riemannian metric.",3. Our Approach,[0],[0]
"See (Edelman et al., 1998) for details.
labels of the samples.",3. Our Approach,[0],[0]
"Furthermore, motivated by our analysis of existing methods, which all benefit from a PCA preprocessing step, we also seek to reduce the dimensionality of the data.",3. Our Approach,[0],[0]
"However, in contrast to existing methods, we propose to learn the lower-dimensional representation and the Mahalanobis distance in that space jointly.
",3. Our Approach,[0],[0]
"More specifically, we want to learn a projection W : Rn → Rp and a Mahalanobis matrix M ∈ Sp++, such that the induced distance in Rp is more discriminative.",3. Our Approach,[0],[0]
"To this end, let X = {(xi, x̃i, yi)}mi=1 be a set of triplets, where xi, x̃i ∈",3. Our Approach,[0],[0]
"Rn are the feature vectors of two training samples, and the label yi ∈ {0, 1} determines whether xi and x̃i are similar (yi = 1) or not (yi = 0).",3. Our Approach,[0],[0]
"The Mahalanobis distance between xi and x̃i in the low-dimensional space can thus be written as
d2M ,W (xi, x̃i) =",3. Our Approach,[0],[0]
(W Txi −W T x̃i)TM(W,3. Our Approach,[0],[0]
Txi,3. Our Approach,[0],[0]
"−W T x̃i)
= (x− x̃i)TWMW T (xi − x̃i) .",3. Our Approach,[0],[0]
"(5)
To learn a latent space whose Mahalanobis distance reflects class similarity, we make use of the logistic loss.",3. Our Approach,[0],[0]
"More precisely, for each pair of samples (xi, x̃i) sharing the same label, i.e., yi = 1, we define the loss
`(xi, x̃i|yi = 1) = log(1 + pi) , (6)
with pi = exp ( β(x−",3. Our Approach,[0],[0]
"x̃)TWMW T (x− x̃) ) , β > 0.",3. Our Approach,[0],[0]
"(7)
Conversely, for a pair of samples (xj , x̃j) whose labels differ, i.e., yj = 0, we define the loss
`(xj , x̃j |yj = 0) = log(1 + p−1j ) .",3. Our Approach,[0],[0]
"(8)
Intuitively, the loss of Eq. 6 is minimized when d2M ,W (xi, x̃i)",3. Our Approach,[0],[0]
"→ 0, whereas the loss of Eq. 8 is minimized when d2M ,W (xj , x̃j)→∞.
The losses for all training triplets can be grouped into a cost function of the form
L(W ,M |X) , ∑
i|yi=1
log(1 + pi)
+ ∑
i|yi=0
log(1 + p−1i ) +",3. Our Approach,[0],[0]
"λr(M ,M0), (9)
which further encodes a regularizer on M .",3. Our Approach,[0],[0]
"This regularizer, r : Sp++ × S p ++ → R+, allows us to exploit prior knowledge on the Mahalanobis matrix, encoded by a reference matrix M0.",3. Our Approach,[0],[0]
"Following common practice (Davis et al., 2007; Hoffman et al., 2014), we make use of the asymmetric Burg divergence, which yields
r(M ,M0) =",3. Our Approach,[0],[0]
Tr(MM −1 0 ),3. Our Approach,[0],[0]
− log det(MM −1 0 ),3. Our Approach,[0],[0]
"− p .
(10)
In our experiments, since typically no strong prior is available, we simply use M0 = Ip, i.e., the identity matrix.",3. Our Approach,[0],[0]
Joint dimensionality reduction and metric learning can then be achieved by minimizing the cost function of Eq. 9 w.r.t.,3. Our Approach,[0],[0]
W and M .,3. Our Approach,[0],[0]
"To avoid degeneracies, and following common practice in dimensionality reduction, we constrain W to be a matrix with orthonormal columns.",3. Our Approach,[0],[0]
"That is,
W TW = Ip.",3. Our Approach,[0],[0]
"(11)
With this constraint, W is in fact a point on the Stiefel manifold St(p, n).",3. Our Approach,[0],[0]
"Since both M and W lie on Riemannian manifolds, albeit different ones, we propose to make use of Riemannian optimization to solve our problem, as described below.",3. Our Approach,[0],[0]
"To determine W and M , we need to solve the optimization problem
min W ,M
L(W ,M |X)
s.t.",3.1. Manifold-based Optimization,[0],[0]
"W TW = Ip, M 0 .",3.1. Manifold-based Optimization,[0],[0]
"(12)
Jointly minimizing with respect to W and M can be achieved by making use of the product space of the Stiefel and SPD manifolds,Mp = St(p, n)×Sp++.",3.1. Manifold-based Optimization,[0],[0]
"Both St(p, n) and Sp++ are smooth homogeneous spaces and their product preserves smoothness and differentiability (Absil et al., 2009).",3.1. Manifold-based Optimization,[0],[0]
"Thus, Mp can be given a Riemannian structure.",3.1. Manifold-based Optimization,[0],[0]
"However, in our case, a closer look at L(W ,M |X) reveals that
L(W ,M |X) = L(WR,RTMR|X) ,∀R ∈ Op , (13)
where Op is the orthogonal group.",3.1. Manifold-based Optimization,[0],[0]
"This implies that π :Mp×Op →Mp : ( (W ,M ) ,R ) → ( WR,RTMR ) (14) is a right group action onMp.",3.1. Manifold-based Optimization,[0],[0]
"The theorem below establishes an important property about the action ofOp onMp, which will prove crucial to our develop our approach.",3.1. Manifold-based Optimization,[0],[0]
Theorem 1.,3.1. Manifold-based Optimization,[0],[0]
"The setM , ( St(p, n)",3.1. Manifold-based Optimization,[0],[0]
"× Sp++ ) \O(p) with the equivalence relation
[ ( W ,M ) ]",3.1. Manifold-based Optimization,[0],[0]
"∼ {( WR,RTMR ) ; ∀R ∈ O(p) } (15)
and Riemannian metric
g(W ,M)((ξW , ξM ) , (ςW , ςM ))",3.1. Manifold-based Optimization,[0],[0]
"= 2 Tr(ξ T W ςW ) (16)
+ Tr(M−1ξMM −1ςM )
forms a Riemannian quotient manifold.
",3.1. Manifold-based Optimization,[0],[0]
Proof.,3.1. Manifold-based Optimization,[0],[0]
"See the supplementary material.
",3.1. Manifold-based Optimization,[0],[0]
"The search space of our problem therefore truly is this Riemannian manifoldM. To be able to perform Riemannian optimization onM, below, we derive the required entities.
",3.1. Manifold-based Optimization,[0],[0]
"The Geometry ofM
The general theory of quotient manifolds (Lee, 2003; Absil et al., 2009) tells us that the equivalence relation splits the tangent space ofMp at Ω =",3.1. Manifold-based Optimization,[0],[0]
"(W ,M) into two complementary parts: the horizontal spaceHΩMp and the vertical space VΩMp.",3.1. Manifold-based Optimization,[0],[0]
"These two spaces are such that
gp(hΩ,vΩ) = 0, ∀hΩ ∈ HΩMp and ∀vΩ ∈ VΩMp , (17) where gp is the Riemannian metric of the product manifold Mp.",3.1. Manifold-based Optimization,[0],[0]
"The vertical space VΩMp has the property that projecting any of its vectors to Mp via the exponential map yields a point in the equivalence class of Ω. Therefore, the tangent space of M can be identified with the horizontal space, i.e., T[Ω]M , HΩMp.
",3.1. Manifold-based Optimization,[0],[0]
A tangent vector,3.1. Manifold-based Optimization,[0],[0]
ξ↑Ω ∈,3.1. Manifold-based Optimization,[0],[0]
T[Ω]M can be obtained from a tangent vector ξΩ ∈ TΩMp by projection.,3.1. Manifold-based Optimization,[0],[0]
"It can be shown that the horizontal space at Mp 3 (W ,M) =",3.1. Manifold-based Optimization,[0],[0]
"(U [Ip, 0p,n−p]
T ,M) with U ∈",3.1. Manifold-based Optimization,[0],[0]
"On is the set (details in the supplementary material){(
U
[ V M−1 −M−1V
B
] ,V )} ,
with V ∈ Sym(p), B ∈ R(n−p)×p.",3.1. Manifold-based Optimization,[0],[0]
"Furthermore, we have the following theorem to obtain the tangent vectors inM.",3.1. Manifold-based Optimization,[0],[0]
Theorem 2 (Projecting on the Horizontal Space).,3.1. Manifold-based Optimization,[0],[0]
"For (ξW , ξM ) ∈ T(W ,M)Mp, the horizontal vector (i.e., the associated tangent vector in T[(W ,M)]M) is identified as(
ξW −WΘ, ξM −MΘ + ΘM ) , (18)
with Θ the solution of the following Sylvester equation:
ΘM2 + M2Θ = M",3.1. Manifold-based Optimization,[0],[0]
( ξTWW −W T ξW,3.1. Manifold-based Optimization,[0],[0]
"+
M−1ξM − ξMM−1 ) M .",3.1. Manifold-based Optimization,[0],[0]
"(19)
Proof.",3.1. Manifold-based Optimization,[0],[0]
"See the supplementary material.
",3.1. Manifold-based Optimization,[0],[0]
"To perform Newton-type optimization onM, we also need the form of the retraction R[(W ,M)]",3.1. Manifold-based Optimization,[0],[0]
": T[(W ,M)]M→M, which follows from the retraction onMp.",3.1. Manifold-based Optimization,[0],[0]
"In particular, we suggest the following retraction:
R[(W ,M)](ξW , ξM ) , ( uf(W + ξW ), M1/2 expm(M−1/2ξMM −1/2)M1/2 ) .",3.1. Manifold-based Optimization,[0],[0]
"(20)
Here uf(A) = A(ATA)−1/2, which yields an orthogonal matrix and expm(·) denotes the matrix exponential.",3.1. Manifold-based Optimization,[0],[0]
"Altogether, this provides us with the tools required to perform Riemannian optimization to solve our problem.",3.1. Manifold-based Optimization,[0],[0]
"The only missing mathematical entity is the Euclidean gradient of
our loss function w.r.t.",3.1. Manifold-based Optimization,[0],[0]
"W and M , which we provide in the supplementary material.
",3.1. Manifold-based Optimization,[0],[0]
"In our experiments, we employed Conjugate Gradient descent on M to solve (12).",3.1. Manifold-based Optimization,[0],[0]
"In particular, we implemented the operations required for our manifold within the manopt Riemannian optimization toolbox (Boumal et al., 2014).",3.1. Manifold-based Optimization,[0],[0]
"The code is available at https://sites.google. com/site/mehrtashharandi/.
In Fig. 1, we illustrate the typical convergence behavior of our algorithm using the ASLAN dataset (Kliper-Gross et al., 2012).",3.1. Manifold-based Optimization,[0],[0]
"In our experiments, we have observed that the algorithm converges quite fast (typically in less than 25 iterations), thus making it scalable to learning large metrics.",3.1. Manifold-based Optimization,[0],[0]
"The complexity of each iteration of our algorithm to solve (12) depends on the computational cost of the following major steps:
• Objective function evaluation.",3.2. Computational Complexity,[0],[0]
"Computing L(W ,M |X) takes O(mnp+mp2 + p3 + np2).
",3.2. Computational Complexity,[0],[0]
• Euclidean gradient evaluation: Computing ∇W takes O(mn2 +,3.2. Computational Complexity,[0],[0]
"pn2 + np2), and computing ∇M takes O(mn2 +",3.2. Computational Complexity,[0],[0]
pn2,3.2. Computational Complexity,[0],[0]
+ np2,3.2. Computational Complexity,[0],[0]
+ p3).,3.2. Computational Complexity,[0],[0]
Note that some computations are common to both ∇W and ∇M .,3.2. Computational Complexity,[0],[0]
"Hence the total flops for this step is less than the addition of the Stiefel and SPD parts.
",3.2. Computational Complexity,[0],[0]
"• Projecting (∇W ,∇M ) to the tangent space of Mp takes O(2p2(n+ p)).
",3.2. Computational Complexity,[0],[0]
"• Projecting a tangent vector in Mp costs O(2np2) to form the Sylvester equation and O(p3) to solve it using the Bartels - Stewart algorithm (Bartels & Stewart, 1972).
",3.2. Computational Complexity,[0],[0]
"• Retraction: For the Stiefel part, the retraction τSt takes O(4np2 + 11p3).",3.2. Computational Complexity,[0],[0]
"For the SPD part, τSPD takes O(3p3).
",3.2. Computational Complexity,[0],[0]
"These steps are either linear or quadratic in n. Therefore, and as evidenced by our experiments, our approach can effectively and efficiently handle high-dimensional input features without any PCA pre-processing.
",3.2. Computational Complexity,[0],[0]
Remark 1.,3.2. Computational Complexity,[0],[0]
"The number of unknowns determined by our algorithm corresponds to the dimensionality of Mp, that is, np− 12p(p+ 1) + 1 2p(p+ 1)− 1 2p(p− 1) = 1 2p(2n− p + 1).",3.2. Computational Complexity,[0],[0]
"By contrast, the metric learning techniques that utilize PCA as a pre-processing step only determine 12p(p+ 1) unknowns, which is typically much smaller.",3.2. Computational Complexity,[0],[0]
"As such, our method can potentially better leverage large amounts of training triplets.",3.2. Computational Complexity,[0],[0]
"In our Big Data era, we believe this to be an important strength of our approach.",3.2. Computational Complexity,[0],[0]
An SPD matrix M ∈ Sp++ can be decomposed as UDU T with U ∈ Op and D a diagonal matrix with positive elements.,3.3. Discussion,[0],[0]
"As such, the term WMW T appearing in our loss L(W ,M |X) can be written as
WMW T = WUDUTW T = V DV T ,
with St(p, n) 3 V = WU .",3.3. Discussion,[0],[0]
"Thus, our optimization problem can be expressed by a loss L(V ,D|X) with a search space defined as St(p, n) × Rp+.",3.3. Discussion,[0],[0]
"Theoretically, this representation has the same expressive power as our formulation if we ignore the invariance of V DV T to permutations.",3.3. Discussion,[0],[0]
"However, in the context of fixed-rank matrix factorization (see (Mishra et al., 2014), Section 3.2), it has been shown that, for a parametrization of the form WMV T , where W ,V ∈ St(p, n), modeling M as an SPD matrix is typically more effective than as a diagonal matrix with positive elements.",3.3. Discussion,[0],[0]
"The argument there is that it “gives more flexibility to optimization algorithms” (Mishra et al., 2014).
",3.3. Discussion,[0],[0]
One can also factorize WMW T as LLT with L ∈ Rn×p.,3.3. Discussion,[0],[0]
"This factorization, though being widely used, is not invariant to the action of Op, meaning that replacing L → LR,R ∈ Op will not change the loss.",3.3. Discussion,[0],[0]
"Such an invariance hinders gradient descent algorithms, as shown for example in (Journée et al., 2010; Mishra et al., 2014).",3.3. Discussion,[0],[0]
"In Section 6, we empirically show that this is indeed the case for the problem of interest here, i.e., metric learning.
",3.3. Discussion,[0],[0]
"In (Journée et al., 2010), the invariance induced by the action of Op in a factorization of the form LLT is taken into account.",3.3. Discussion,[0],[0]
"In particular, the authors make use of a quotient geometry to overcome the undesirable effects of the invariance in gradient descent optimization.",3.3. Discussion,[0],[0]
"There is a subtle, yet important difference between our formulation and that of (Journée et al., 2010):",3.3. Discussion,[0],[0]
"Our approach can benefit from a factorization with redundancy, which is effective in practice.",3.3. Discussion,[0],[0]
"Furthermore, note that the geometry developed in our paper can also handle the case where a Mahalanobis metric is searched for (i.e., without recasting the problem as a fac-
torization problem), which is the case in techniques such as (Globerson & Roweis, 2005; Koestinger et al., 2012; Zadeh et al., 2016).
",3.3. Discussion,[0],[0]
"Before concluding this part, we contrast the aforementioned factorization for the experiment reported in Table 1.",3.3. Discussion,[0],[0]
"To this end, we replace the term WMW T in our loss with
1.",3.3. Discussion,[0],[0]
"LLT , L ∈ Rn×p, and optimize using Euclidean geometry.",3.3. Discussion,[0],[0]
"We call this solution Euc-LLT .
2.",3.3. Discussion,[0],[0]
"LLT , L ∈ Rn×p, and optimize using the geometry developed in (Journée et al., 2010).",3.3. Discussion,[0],[0]
"We call this solution Rim-LLT .
3.",3.3. Discussion,[0],[0]
"V DV T , V ∈ St(p, n) and D a diagonal and positive matrix.",3.3. Discussion,[0],[0]
"We optimize using the geometry of the product manifold St(p, n)",3.3. Discussion,[0],[0]
× Rp+.,3.3. Discussion,[0],[0]
"We call this solution RimV DV T .
",3.3. Discussion,[0],[0]
"Following the experiment shown in Table 1, we evaluate the AUC for various dimensionalities using the aforementioned geometries.",3.3. Discussion,[0],[0]
The results are provided in Table 2.,3.3. Discussion,[0],[0]
"First, we note that the general practice, i.e., using Euclidean geometry, is significantly outperformed by its Riemannian counterparts.",3.3. Discussion,[0],[0]
"The quotient geometry developed in (Journée et al., 2010) performs on par with our approach for low dimensionalities (e.g., p = 25).",3.3. Discussion,[0],[0]
"However, for larger dimensionalities, our technique yields more accurate solutions, suggesting that the redundancy in the formulation plays an important role.",3.3. Discussion,[0],[0]
The importance of the redundancy can also be noticed by comparing Rim-V DV T against our solution.,3.3. Discussion,[0],[0]
"In terms of computation time, the diagonal form, i.e., Rim-V DV T yields only slightly faster runtimes.",3.3. Discussion,[0],[0]
"In the particular case of ASLAN, the training time for p = 1000 was reduced to 150s.",3.3. Discussion,[0],[0]
"We now show how our approach can handle nonlinearity in the data, as well as generalize to non-vectorial input data, such as linear subspaces, which have proven effective for video recognition (Turaga et al., 2011; Harandi et al., 2014; Jayasumana et al., 2015).",4. Kernelizing the Solution,[0],[0]
"Following common practice when converting a linear algorithm to a nonlinear one (e.g., from PCA to kernel PCA), we make use of a mapping of the input data to a Reproducing Kernel Hilbert Space (RKHS).",4. Kernelizing the Solution,[0],[0]
"As shown below, the resulting algorithm then only depends on kernel values (i.e., it does not explicitly depend on the mapping to RKHS).",4. Kernelizing the Solution,[0],[0]
"Since much progress has recently been made in developing positive def-
inite kernels for non-vectorial data (Harandi et al., 2014; Jayasumana et al., 2015; Vishwanathan et al., 2010), this makes our approach applicable to a much broader variety of input types.
",4. Kernelizing the Solution,[0],[0]
"Specifically, let φ : X → H be a mapping from the input spaceX to an RKHSHwith corresponding kernel function",4. Kernelizing the Solution,[0],[0]
"k(xi,xj) = 〈φ(xi), φ(xj)〉.",4. Kernelizing the Solution,[0],[0]
"Following the same formalism as before, we can define a cost function of the form
LH(W ,M |X) , ∑
i,yi=1
log(1 + p̃i) (21)
+ ∑
i,yi=0
log(1 + p̃−1i ) +",4. Kernelizing the Solution,[0],[0]
"λr(M ,M0),
with p̃i = exp ( βd2H(xi, x̃i) ) and d2H(x, x̃) =",4. Kernelizing the Solution,[0],[0]
( φ(xi),4. Kernelizing the Solution,[0],[0]
"−
φ(xj) )",4. Kernelizing the Solution,[0],[0]
"T WMW T ( φ(xi)− φ(xj) ) , with M ∈ Sp++ and W ∈ St(p,dim(H)).",4. Kernelizing the Solution,[0],[0]
"Note that for universal kernel functions, such as the Gaussian kernel, dim(H) → ∞. We therefore need a formulation where only the kernel function appears, and not φ explicitly.",4. Kernelizing the Solution,[0],[0]
"To this end, we exploit the representer theorem (Schölkopf et al., 2001), which states that the mapping W lies in the span of the training data, and can thus be expressed as W = Φ(D)A. Here, Φ(D) = (φ(d1), · · · , φ(dl))",4. Kernelizing the Solution,[0],[0]
∈ Rdim(H)×l is a matrix that stacks the representation of the l training samples in the feature space.,4. Kernelizing the Solution,[0],[0]
"In this formalism, the orthogonality constraint on W can be written as
W TW = AT Φ(D)T",4. Kernelizing the Solution,[0],[0]
"Φ(D)A = ATK(D,D)A = Ip ,
where K(D,D) ∈",4. Kernelizing the Solution,[0],[0]
"Sl++ is the kernel matrix with elements [K(D,D)]i,j = k(di,dj).",4. Kernelizing the Solution,[0],[0]
"Let us define St(p, l) 3 B = K(D,D)1/2A, such that the orthogonality constraint becomes BTB = Ip.",4. Kernelizing the Solution,[0],[0]
"This lets us write
d2H(x, x̃) =",4. Kernelizing the Solution,[0],[0]
( φ(x)− φ(x̃) ),4. Kernelizing the Solution,[0],[0]
T WMW T ( φ(x)− φ(x̃) ),4. Kernelizing the Solution,[0],[0]
"= ( k(x,D)− k(x̃,D) )",4. Kernelizing the Solution,[0],[0]
"T K(D,D)− 1 2BMBT
×K(D,D)− 12 ( k(x,D)− k(x̃,D) ) , (22)
where Rl 3 k(x,D) =",4. Kernelizing the Solution,[0],[0]
"( k(x,d1), · · · , k(x,dl) )T .",4. Kernelizing the Solution,[0],[0]
"Thus, the cost defined in Eq. 21 can be rewritten as a function of B, i.e., LH(B,M |X), which, by taking d2H(x, x̃) from Eq. 22, only depends on kernel values.",4. Kernelizing the Solution,[0],[0]
"Since this cost function has essentially the same form as the one derived in Section 3, and the variables M and B lie on the same types of manifold as those of Section 3, we can use the same optimization strategy as before.",4. Kernelizing the Solution,[0],[0]
"Metric learning is a well-studied problem whose origins can be traced back to the early eighties (e.g., (Short & Fukunaga, 1981)).",5. Related Work,[0],[0]
"Here, we focus on the prime representatives that will be used as baselines in our experiments.
",5. Related Work,[0],[0]
"For a more thorough study, we refer the reader to the recent book by (Bellet et al., 2015).
",5. Related Work,[0],[0]
"The idea of Neighborhood Component Analysis (NCA) (Goldberger et al., 2004) is to optimize the error of a stochastic nearest neighbor classifier in the space induced by the Mahalanobis metric.",5. Related Work,[0],[0]
"The InformationTheoretic Metric Learning (ITML) algorithm, proposed by (Davis et al., 2007), learns a Mahalanobis metric by exploiting a notion of margin between pairs of samples.",5. Related Work,[0],[0]
"More precisely, the algorithm searches for a Mahalanobis matrix satisfying two types of constraints: (i) an upper bound u on the distance between pairs of samples from the same class, i.e., in our formalism, d2M (xi, x̃i) ≤ u, ∀i | yi = 1; (ii) a lower bound l on the distance between pairs of dissimilar samples, i.e., d2M (xi, x̃i)",5. Related Work,[0],[0]
"≥ l, ∀i | yi = 0.
",5. Related Work,[0],[0]
"The Large Margin Nearest Neighbors (LMNN) of (Weinberger & Saul, 2009) introduces the notion of local margins for metric learning.",5. Related Work,[0],[0]
"In LMNN, learning the Mahalanobis metric is expressed as a convex optimization problem that encourages the k nearest neighbors of any training instance xi to belong to the same class as xi, while keeping away instances of other classes.
",5. Related Work,[0],[0]
Logistic Discriminant based Metric Learning (LDML),5. Related Work,[0],[0]
"(Guillaumin et al., 2009) relies on a Mahalanobis distance-based sigmoid function to encode the likelihood that two samples belong to the same class.",5. Related Work,[0],[0]
"The metric is then learned by maximizing the likelihood of the sample pairs (xi, x̃i) that truly belong to the same class, i.e., yi = 1, while minimizing that of the sample pairs that do not, i.e., yi = 0.
",5. Related Work,[0],[0]
"While effective, all the above-mentioned techniques rely on PCA as a pre-processing step to remain tractable.",5. Related Work,[0],[0]
"By contrast, the efficient “Keep It Simple and Straightforward Metric” (KISSME) algorithm of (Koestinger et al., 2012) focuses on addressing large-scale problems.",5. Related Work,[0],[0]
KISSME assumes that the similar and dissimilar pairs are generated from two independent Gaussian distributions.,5. Related Work,[0],[0]
"Computing the Mahalanobis metric then translates to maximizing a log-likelihood, which can be achieved in closedform.",5. Related Work,[0],[0]
"As illustrated in Table 1, however, this algorithm requires PCA pre-processing to achieve accuracies comparable to the ones produced by the other algorithms.",5. Related Work,[0],[0]
"In the spirit of KISSME, Geometric Mean Metric Learning (GMML) (Zadeh et al., 2016) relies on the geodesic connecting two covariance matrices to identify the Mahalanobis metric.
",5. Related Work,[0],[0]
"While effective and quite efficient, the above-mentioned techniques usually rely on PCA as a pre-processing step to reduce the dimensionality of the data.",5. Related Work,[0],[0]
"As evidenced by our experiments, this pre-processing step is sub-optimal.
",5. Related Work,[0],[0]
Figure 2:,5. Related Work,[0],[0]
Examples from the ASLAN dataset.,5. Related Work,[0],[0]
"We now evaluate our algorithms (DRML and kDRML) and compare them with the representative baseline metric learning methods discussed above, i.e.,",6. Experimental Evaluation,[0],[0]
"NCA (Goldberger et al., 2004) LMNN (Weinberger & Saul, 2009), ITML (Davis et al., 2007), LDML (Guillaumin et al., 2009), KISSME (Koestinger et al., 2012) and GMML (Zadeh et al., 2016), as well as with datasetspecific baselines mentioned below.",6. Experimental Evaluation,[0],[0]
Our experiments consist of two parts.,6. Experimental Evaluation,[0],[0]
"First, we make use of benchmark datasets where the data can be represented in vector (Euclidean) form, and thus both DRML and kDRML are applicable.",6. Experimental Evaluation,[0],[0]
"Second, we consider manifold-valued data where only kDRML applies.
",6. Experimental Evaluation,[0],[0]
"In all our experiments, we followed the so-called restricted protocol.",6. Experimental Evaluation,[0],[0]
"That is, the only information accessible to the algorithms is the similarity/dissimilarity labels of pairs of samples; the class labels of the samples are unknown.",6. Experimental Evaluation,[0],[0]
"For all the methods, we report the results obtained with the best subspace dimension.",6. Experimental Evaluation,[0],[0]
Note that this means that not all methods use the same subspace dimension.,6. Experimental Evaluation,[0],[0]
"However, it makes the comparison more fair, since it truly shows the full potential of the algorithms.",6. Experimental Evaluation,[0],[0]
"ACTION SIMILARITY MATCHING.
",6.1. Experiments with Euclidean Data,[0],[0]
"As a first experiment, we considered the task of action similarity recognition using the ASLAN dataset (Kliper-Gross et al., 2012).",6.1. Experiments with Euclidean Data,[0],[0]
"The ASLAN dataset contains 3,697 human action clips collected from YouTube, spanning over 432 unique action categories (see Fig. 2).",6.1. Experiments with Euclidean Data,[0],[0]
"The sample distribution across the categories is highly uneven, with 116 classes possessing only one video clip.",6.1. Experiments with Euclidean Data,[0],[0]
"The benchmark protocol focuses on action similarity (same/not-same), rather than action classification, and testing is performed on previously-unseen actions.
",6.1. Experiments with Euclidean Data,[0],[0]
"The dataset comes with 10 predefined splits of the data, where each split consists of 5,400 training and 600 testing pairs of action videos.",6.1. Experiments with Euclidean Data,[0],[0]
"The ASLAN dataset also provides three different types of descriptors: Histogram of Oriented
Gradients (HoG), Histogram of Optical Flow (HoF), and a composition of both (referred to as HnF).",6.1. Experiments with Euclidean Data,[0],[0]
"The videos are represented by spatiotemporal bags of features (Laptev et al., 2008) with a codebook of size 5,000.",6.1. Experiments with Euclidean Data,[0],[0]
"For kDRML, we used an RBF Gaussian kernel whose bandwidth was set using Jaakkola’s heuristic (Jaakkola et al., 1999).
",6.1. Experiments with Euclidean Data,[0],[0]
"In Table 3, we report the classification accuracy and the Area Under the ROC Curve (AUC) of our algorithms and of the baselines.",6.1. Experiments with Euclidean Data,[0],[0]
"Here, we also include the results of the benchmark (Kliper-Gross et al., 2012), which provides us with a direct comparison of previously published results.",6.1. Experiments with Euclidean Data,[0],[0]
Note that DRML and kDRML outperform all the other algorithms.,6.1. Experiments with Euclidean Data,[0],[0]
"In general, kDRML performs better than DRML.
",6.1. Experiments with Euclidean Data,[0],[0]
"To further evidence the benefits of jointly learning the low-dimensional projection and the metric, we performed the following experiment, using the HoG features.",6.1. Experiments with Euclidean Data,[0],[0]
"We fixed the matrix W to the subspace obtained by PCA, and learned the metric using our loss function.",6.1. Experiments with Euclidean Data,[0],[0]
"This resulted in a drop in accuracy of roughly 1%, i.e., a CRR of 57.4%.",6.1. Experiments with Euclidean Data,[0],[0]
This confirms our intuition that we can achieve better than PCA by jointly learning the subspace and the metric.,6.1. Experiments with Euclidean Data,[0],[0]
Remark 2.,6.1. Experiments with Euclidean Data,[0],[0]
"In (Kliper-Gross et al., 2012), it was shown that other metrics (e.g., the cosine similarity) could outperform the Euclidean distance (used here as a baseline).",6.1. Experiments with Euclidean Data,[0],[0]
"In principle, our framework can also be used to learn cosine similarities by generalizing the inner product 〈a, b〉 as aTWMW T b.",6.1. Experiments with Euclidean Data,[0],[0]
"Doing so, however, goes beyond the scope of this paper.
",6.1. Experiments with Euclidean Data,[0],[0]
"PERSON RE-IDENTIFICATION.
",6.1. Experiments with Euclidean Data,[0],[0]
"For the task of person re-identification, we used the iLIDS dataset (Zheng et al., 2009).",6.1. Experiments with Euclidean Data,[0],[0]
The dataset consists of 476 images of 119 pedestrians and was captured in an airport.,6.1. Experiments with Euclidean Data,[0],[0]
The number of images for each person varies from 2 to 8.,6.1. Experiments with Euclidean Data,[0],[0]
"The dataset contains severe occlusions caused by people and baggage.
",6.1. Experiments with Euclidean Data,[0],[0]
"In our experiments, we adopted the single-shot protocol.",6.1. Experiments with Euclidean Data,[0],[0]
"That is, the dataset was randomly divided into two subsets, training and test, with 59 and 60 exclusive individuals, respectively.",6.1. Experiments with Euclidean Data,[0],[0]
The random splitting was repeated 10 times.,6.1. Experiments with Euclidean Data,[0],[0]
"In each partition, one image from each individual
in the test set was randomly selected as the reference image and the rest of the images were used as query images.",6.1. Experiments with Euclidean Data,[0],[0]
This process was repeated 20 times.,6.1. Experiments with Euclidean Data,[0],[0]
"We used the features provided by the authors of (Xiong et al., 2014).",6.1. Experiments with Euclidean Data,[0],[0]
"These features describe each image using 16-bin histograms from the RGB, YUV and HSV color channels, as well as texture histograms based on Local Binary Patterns (Ojala et al., 2002) extracted from 6 non-overlapping horizontal bands.",6.1. Experiments with Euclidean Data,[0],[0]
"For the kernel-based solutions, i.e., kDRML and kLFDA, we used the Chi-square kernel.
",6.1. Experiments with Euclidean Data,[0],[0]
We report performance in terms of the Cumulative Match Characteristic (CMC) curves for different rank values r indicating that we search for a correct match among the r nearest neighbors.,6.1. Experiments with Euclidean Data,[0],[0]
"Table 4 compares our results with those of the baseline metric learning algorithms, as well as with kernel Local Fisher Discriminant Analysis (kLFDA)",6.1. Experiments with Euclidean Data,[0],[0]
"(Xiong et al., 2014), which represents the stateof-the-art on this dataset.",6.1. Experiments with Euclidean Data,[0],[0]
Our kDRML method achieves the highest scores for all ranks.,6.1. Experiments with Euclidean Data,[0],[0]
"Note that kLFDA requires the subject identities during training, while the other methods, including ours, don’t.",6.1. Experiments with Euclidean Data,[0],[0]
"Despite this, kDRML outperforms the state-of-the-art results of kLFDA-Chi2.",6.1. Experiments with Euclidean Data,[0],[0]
"To illustrate the fact that our algorithm generalizes to nonvectorial input data, we utilized the Youtube Faces (YTF) dataset (Wolf et al., 2011) and represented each video as a point on a Grassmann manifold.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"The YTF dataset contains 3,425 videos of 1,595 subjects collected from the YouTube website.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"These videos depict large variations in pose, illumination and expression.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"To evaluate the performance of the algorithms, we followed the protocol suggested in (Wolf et al., 2011).",6.2. Experiments with Manifold-Valued Data,[0],[0]
"Specifically, we used the 5,000 video pairs officially provided with the dataset, which are equally divided into 10 folds.",6.2. Experiments with Manifold-Valued Data,[0],[0]
Each fold contains 250 ‘same’ and 250 ‘not-same’ pairs.,6.2. Experiments with Manifold-Valued Data,[0],[0]
"We used the provided LBP features
and modeled each video by a subspace of dimensionality 10 as described in (Wolf et al., 2011).",6.2. Experiments with Manifold-Valued Data,[0],[0]
"As a result, each video was modeled as a point on the Grassmann manifold G(10, 1770), where 1,770 is the dimensionality of the LBP features.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"We used the projection kernel defined as
kproj(Si,Sj) = ‖STi Sj‖2F .
",6.2. Experiments with Manifold-Valued Data,[0],[0]
"While kDRML directly uses a kernel function, some baselines (e.g., KISSME), do not.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"To still be able to report results for these baselines, we utilized kernel PCA, instead of PCA, to create their inputs.
",6.2. Experiments with Manifold-Valued Data,[0],[0]
"Table 5 summarizes the performance of the metric learning techniques and the baseline (Wolf et al., 2011) using the same input, i.e., subspaces of dimensionality 10.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"Here again, kDRML comfortably outperforms the other methods for all the error metrics.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"For example, the gap in accuracy between kDRML and its closest competitor, i.e., KISSME, is more than 4%.",6.2. Experiments with Manifold-Valued Data,[0],[0]
Remark 3.,6.2. Experiments with Manifold-Valued Data,[0],[0]
"Note that, as shown in (Feragen et al., 2015), an RBF kernel of the form",6.2. Experiments with Manifold-Valued Data,[0],[0]
"exp(−σd2g(·, ·))",6.2. Experiments with Manifold-Valued Data,[0],[0]
with dg being the geodesic distance on the Grassmann manifold is not a positive definite kernel.,6.2. Experiments with Manifold-Valued Data,[0],[0]
"The projection kernel, however, has been shown to be positive definite (Hamm & Lee, 2008), which, ultimately, is all we require to make our algorithm applicable to manifold-valued data.",6.2. Experiments with Manifold-Valued Data,[0],[0]
"Furthermore, this kernel has proven effective in a variety of applications (Hamm & Lee, 2008; Harandi et al., 2017).",6.2. Experiments with Manifold-Valued Data,[0],[0]
"In this paper, we have argued against treating dimensionality reduction as a pre-processing step to metric learning.",7. Conclusions and Future Work,[0],[0]
We have therefore introduced a framework that learns a low-dimensional representation and a Mahalanobis metric in this space in a unified manner.,7. Conclusions and Future Work,[0],[0]
We have shown that the resulting framework could be cast an optimization problem on the quotient space of the product space of two Riemannian manifolds with the orthogonal group.,7. Conclusions and Future Work,[0],[0]
Our experiments have evidenced the benefits of our unified approach over state-of-the-art metric learning algorithms that rely on PCA as a pre-processing step.,7. Conclusions and Future Work,[0],[0]
"In the future, we plan to study the use of other cost functions within our unified framework, especially formulations based on the concept of large margin.",7. Conclusions and Future Work,[0],[0]
"To be tractable and robust to data noise, existing metric learning algorithms commonly rely on PCA as a pre-processing step.",abstractText,[0],[0]
"How can we know, however, that PCA, or any other specific dimensionality reduction technique, is the method of choice for the problem at hand?",abstractText,[0],[0]
The answer is simple: We cannot!,abstractText,[0],[0]
"To address this issue, in this paper, we develop a Riemannian framework to jointly learn a mapping performing dimensionality reduction and a metric in the induced space.",abstractText,[0],[0]
"Our experiments evidence that, while we directly work on high-dimensional features, our approach yields competitive runtimes with and higher accuracy than state-of-the-art metric learning algorithms.",abstractText,[0],[0]
Joint Dimensionality Reduction and Metric Learning: A Geometric Take,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2074–2080, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.",text,[0],[0]
Events convey semantic information such as who did what to whom where and when.,1 Introduction,[0],[0]
"They also corefer to each other, playing a role of discourse connection points to form a coherent story.",1 Introduction,[0],[0]
"These aspects of events have been already utilized in a wide variety of natural language processing (NLP) applications, such as automated population of knowledge bases (Ji and Grishman, 2011), topic detection and tracking (Allan, 2002), question answering (Bikel and Castelli, 2008), text summarization (Li et al., 2006), and contradiction detection (de Marneffe et al., 2008).",1 Introduction,[0],[0]
"This fact illustrates the importance of event extraction and event coreference resolution.
",1 Introduction,[0],[0]
"Those semantic and discourse aspects of events are not independent from each other, and in fact often work in interactive manners.",1 Introduction,[0],[0]
We give two examples of the interactions: (1) British bank Barclays had agreed to buy(E1),1 Introduction,[0],[0]
"Spanish
rival Banco Zaragozano for 1.14 billion euros.",1 Introduction,[0],[0]
"The combination(E2) of the banking operations of Barclays Spain and Zaragozano will bring together two complementary businesses.
",1 Introduction,[0],[0]
"(2) The Palestinian Authority condemned the attack(E3), saying it(E4) would divert international sympathy away from the far higher Palestinian civilian death toll.
E1 corefers to E2, and E3 does to E4.",1 Introduction,[0],[0]
"E2 is more abstract than E1, and has less evidence of being an event.",1 Introduction,[0],[0]
"E4 is a pronoun, and thus may seem to refer to an entity rather than an event.",1 Introduction,[0],[0]
"Thus, E2 and E4 are relatively difficult to be recognized as events by themselves.",1 Introduction,[0],[0]
"However, event coreference E1-E2, which is supported primarily by E2’s participants Barclays and Zaragozano shared with E1, helps determine that E2 is an event.",1 Introduction,[0],[0]
The same logic applies to E3 and E4.,1 Introduction,[0],[0]
"On the other hand, previous works typically rely on a pipelined model that extracts events (e.g., E1 and E3) at the first stage, and then resolves event coreference at the second stage.",1 Introduction,[0],[0]
"Although this modularity is preferable from development perspectives, the pipelined model limits the interactions.",1 Introduction,[0],[0]
"That is, the first stage alone is unlikely to detect E2 and E4 as events due to the difficulties described above.",1 Introduction,[0],[0]
"These missing events make it impossible for the second stage to resolve event coreference E1-E2 and E3-E4.
",1 Introduction,[0],[0]
"In this work, we address the problem using the ProcessBank corpus (Berant et al., 2014).",1 Introduction,[0],[0]
"Following the terminology defined in the corpus, we introduce several terms:
•",1 Introduction,[0],[0]
"Event: an abstract representation of a change of state, independent from particular texts.",1 Introduction,[0],[0]
"• Event trigger: main word(s) in text, typically a verb or a noun that most clearly expresses an event.",1 Introduction,[0],[0]
"• Event arguments: participants or attributes in text, typically nouns, that are involved in an event.",1 Introduction,[0],[0]
•,1 Introduction,[0],[0]
"Event mention: a clause in text that describes an event, and includes both a trigger and arguments.",1 Introduction,[0],[0]
"• Event coreference: a linguistic phenomenon that two event mentions refer to the same event.
",1 Introduction,[0],[0]
We aim to explore the interactions between event mentions and event coreference.,1 Introduction,[0],[0]
"As a first step toward the goal, we focus on the task of identifying event triggers and resolving event coreference, and
2074
propose a document-level joint learning model using structured perceptron (Collins, 2002) that simultaneously predicts them.",1 Introduction,[0],[0]
"Our assumption is that the joint model is able to capture the interactions between event triggers and event coreference adequately, and such comprehensive decision improves the system performance.",1 Introduction,[0],[0]
"For instance, the joint model is likely to extract E2 as well as E1 successfully via their event coreference by simultaneously looking at coreference features.
",1 Introduction,[0],[0]
Our contributions are as follows: 1.,1 Introduction,[0],[0]
"This is the first work that simultaneously pre-
dicts event triggers and event coreference using a single joint model.",1 Introduction,[0],[0]
At the core of the model is a document-level structured perceptron algorithm that learns event triggers and event coreference jointly.,1 Introduction,[0],[0]
2.,1 Introduction,[0],[0]
The incremental token-based prediction in joint decoding poses a challenge of synchronizing the assignments of event triggers and coreference.,1 Introduction,[0],[0]
"To avoid this problem, we propose an incremental decoding algorithm that combines the segment-based decoding and best-first clustering algorithm.",1 Introduction,[0],[0]
3.,1 Introduction,[0],[0]
"Our experiments indicate that the joint model achieves a substantial performance gain in event coreference resolution with a corpus in the biology domain, as compared to a pipelined model.",1 Introduction,[0],[0]
No previous work deals with event extraction and event coreference resolution simultaneously.,2 Related Work,[0],[0]
"We thus describe how these two tasks have been addressed separately, and how joint structured learning has been studied in other NLP tasks.
",2 Related Work,[0],[0]
Event extraction has been studied mainly in the newswire domain and the biomedical domain as the task of detecting event triggers and determining their event types and arguments.,2 Related Work,[0],[0]
"In the former domain, most work took a pipelined approach where local classifiers identify triggers first, and then detect arguments (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011).",2 Related Work,[0],[0]
Li et al. (2013) presented a structured perceptron model to detect triggers and arguments jointly.,2 Related Work,[0],[0]
"Similarly, joint dependencies in events were also addressed in the latter domain (Poon and Vanderwende, 2010; McClosky et al., 2011; Riedel and McCallum, 2011; Venugopal et al., 2014).",2 Related Work,[0],[0]
"However, none of them incorporated event coreference
into their model.",2 Related Work,[0],[0]
Event coreference resolution is more challenging and less explored.,2 Related Work,[0],[0]
"To set up event triggers as a starting point of the task, some works use human annotation in a corpus (Bejan and Harabagiu, 2014; Liu et al., 2014), and others use the output of a separate event extraction system (Lee et al., 2012).",2 Related Work,[0],[0]
Berant et al. (2014) presented a model that jointly predicts event arguments and event coreference (as well as other relations between event triggers).,2 Related Work,[0],[0]
"However, none of them tries to predict event triggers and event coreference jointly.
",2 Related Work,[0],[0]
"Joint structured learning has been applied to several NLP tasks, such as word segmentation and part-of-speech (POS) tagging (Zhang and Clark, 2008a), POS tagging and dependency parsing (Bohnet and Nivre, 2012), dependency parsing and semantic role labeling (Johansson and Nugues, 2008), the extraction of event triggers and arguments (Li et al., 2013), and the extraction of entity mentions and relations (Li and Ji, 2014).",2 Related Work,[0],[0]
Their underlying ideas are similar to ours.,2 Related Work,[0],[0]
"That is, one can train a structured learning model to globally capture the interactions between two relevant tasks via a certain kind of structure, while making predictions specifically for these respective tasks.",2 Related Work,[0],[0]
"However, no prior work has studied the interactions between event trigger identification and event coreference resolution.",2 Related Work,[0],[0]
We formalize the extraction of event triggers and event coreference as a problem of structured prediction.,3 Approach,[0],[0]
"The output structure is a document-level event graph where each node represents an event trigger, and each edge represents an event coreference link between two event triggers.",3 Approach,[0],[0]
"The ProcessBank corpus consists of 200 paragraphs from the textbook Biology (Campbell and Reece, 2005).",3.1 Corpus,[0],[0]
Table 1 shows statistics of our data splits.,3.1 Corpus,[0],[0]
"The original corpus provides 150 paragraphs as training data, and we split them into 120 and 30 for our training and development, respectively.",3.1 Corpus,[0],[0]
We chose ProcessBank instead of a larger corpus such as the Automatic Content Extraction (ACE) 2005 corpus for the following two reasons.,3.1 Corpus,[0],[0]
"First, the human annotation of event coreference links in ProcessBank enables us to apply the bestfirst clustering directly; on the other hand, this is
not readily feasible in ACE 2005 since it annotates event coreference as clusters, and gold standard event coreference links required for the bestfirst clustering are not available.",3.1 Corpus,[0],[0]
"Second, event coreference resolution using ProcessBank is novel since almost no previous work on the task used that corpus.",3.1 Corpus,[0],[0]
"The only exception could be (Berant et al., 2014), where they extracted several types of relations between event triggers, including event coreference.",3.1 Corpus,[0],[0]
"However, they did not report any performance scores of their system specifically on event coreference, and thus their work is not comparable to ours.
",3.1 Corpus,[0],[0]
"Unlike previous work (Berant et al., 2014; Li et al., 2013), we explicitly allow an event trigger to have multiple tokens, such as verb phrase ‘look into’ and compound proper noun ‘World War II’.",3.1 Corpus,[0],[0]
This is a more realistic setting for event trigger identification since in general there are a considerable number of multi-token event triggers1.,3.1 Corpus,[0],[0]
Let x denote an input document with n tokens where xi is the i-th token in the document.,3.2 Event Graph Learning,[0],[0]
"For event graph learning, we use structured perceptron (Collins, 2002), and average weights to reduce overfitting as suggested in (Collins, 2002).",3.2 Event Graph Learning,[0],[0]
The algorithm involves decoding to generate the best event graph for each input document.,3.2 Event Graph Learning,[0],[0]
We elaborate on our decoding algorithm in Section 3.3.,3.2 Event Graph Learning,[0],[0]
"Since an event graph has an exponentially large search space, we use beam search to approximate exact inference.",3.2 Event Graph Learning,[0],[0]
We extract a range of features by using Stanford CoreNLP,3.2 Event Graph Learning,[0],[0]
"(Manning et al., 2014), MATE (Björkelund et al., 2009), OpenNLP2, Nomlex (Macleod et al., 1998), and Levin verb classes (Levin, 1993).",3.2 Event Graph Learning,[0],[0]
"For brevity, we provide details of the structured perceptron algorithm and features in the supplementary material.
",3.2 Event Graph Learning,[0],[0]
We use the standard-update strategy in our structured perceptron model.,3.2 Event Graph Learning,[0],[0]
"As variants of structured perceptron, one could employ the early up-
1For example, around 13.4% of the 1403 event triggers in ProcessBank have multiple tokens.
",3.2 Event Graph Learning,[0],[0]
"2http://opennlp.apache.org/
date (Collins and Roark, 2004) and max-violation update (Huang et al., 2012) to our model.",3.2 Event Graph Learning,[0],[0]
"Our initial experiments indicated that early updates happen too early to gain sufficient feedback on weights from entire documents in training examples, ending up with a poorer performance than the standard update.",3.2 Event Graph Learning,[0],[0]
"This contrasts with the fact that the early-update strategy was successfully applied to other NLP tasks such as constituent parsing (Collins and Roark, 2004) and dependency parsing (Zhang and Clark, 2008b).",3.2 Event Graph Learning,[0],[0]
The main reason why the early update fell short of the standard update in our setting is that joint event trigger identification and event coreference resolution is a much more difficult task since they require more complex knowledge and argument structures.,3.2 Event Graph Learning,[0],[0]
"Due to the difficultly of the task, it is also very difficult to develop such an effective feature set that beam search can explore the search space of an entire document thoroughly with early updates.",3.2 Event Graph Learning,[0],[0]
"This observation follows (Björkelund and Kuhn, 2014) on entity coreference resolution.",3.2 Event Graph Learning,[0],[0]
"In contrast, the maxviolation update showed almost the same performance as the standard update on the development data.",3.2 Event Graph Learning,[0],[0]
"From these results, we chose the standardupdate strategy for simplicity.",3.2 Event Graph Learning,[0],[0]
"Given that an event trigger has one or more tokens, event trigger identification could be solved as a token-level sequential labeling problem with BIO or BILOU scheme in the same way as named entity recognition (Ratinov and Roth, 2009).",3.3 Joint Decoding,[0],[0]
"If one uses this approach, a beam state may represent a partial assignment of an event trigger.",3.3 Joint Decoding,[0],[0]
"However, event coreference can be explored only from complete assignments of an event trigger.",3.3 Joint Decoding,[0],[0]
"Thus, one would need to synchronize the search process of event coreference by comparing event coreferences from the complete assignment at a certain position with those from complete assignments at following positions.",3.3 Joint Decoding,[0],[0]
This makes it complicated to implement the formalization of token-level sequential labeling for joint decoding in our task.,3.3 Joint Decoding,[0],[0]
"One possible way to avoid this problem is to extract event trigger candidates with a preference on high recall first, and then search event coreference from those candidates, regarding them as complete assignments of an event trigger.",3.3 Joint Decoding,[0],[0]
"This recalloriented pre-filtering is often used in entity coreference resolution (Lee et al., 2013; Björkelund
Algorithm 1 Joint decoding for event triggers and coreference with beam search.",3.3 Joint Decoding,[0],[0]
"Input: input document x = (x1, x2, . . .",3.3 Joint Decoding,[0],[0]
", xn) Input: beam width k, max length of event trigger lmax Output: best event graph ŷ for x 1: initialize empty beam history B[1..n] 2: for i← 1..n do 3: for l← 1..lmax do 4: for y ∈",3.3 Joint Decoding,[0],[0]
"B[i− l] do 5: e← CREATEEVENTTRIGGER(l, i).",3.3 Joint Decoding,[0],[0]
"6: APPENDEVENTTRIGGER(y, e) 7: B[i]← k-BEST(B[i] ∪ y) 8: for j ← 1..i− 1 do 9: c← CREATEEVENTCOREF(j, e).",3.3 Joint Decoding,[0],[0]
"10: ADDEVENTCOREF(y, c) 11",3.3 Joint Decoding,[0],[0]
:,3.3 Joint Decoding,[0],[0]
"B[i]← k-BEST(B[i] ∪ y) 12: return B[n][0]
and Farkas, 2012).",3.3 Joint Decoding,[0],[0]
"In our initial experiments, we observed that our rule-based filter gained around 97% recall, but extracted around 12,400 false positives against 823 true positives in the training data.",3.3 Joint Decoding,[0],[0]
"This made it difficult for our structured perceptron to learn event triggers, which underperformed on event coreference resolution.
",3.3 Joint Decoding,[0],[0]
"We, therefore, employ segment-based decoding with multiple-beam search (Zhang and Clark, 2008a; Li and Ji, 2014) for event trigger identification, and combine it with the best-first clustering (Ng and Cardie, 2002) for event coreference resolution in document-level joint decoding.",3.3 Joint Decoding,[0],[0]
"The key idea of segment-based decoding with multiple-beam search is to keep previous beam states available, and use them to form segments from previous positions to the current position.",3.3 Joint Decoding,[0],[0]
Let lmax denote the upper bound on the number of tokens in one event trigger.,3.3 Joint Decoding,[0],[0]
"The k-best partial structures (event subgraphs) in beam B at the j-th token is computed as follows:
B[j] = k-BEST y∈{y[1:j−l]∈B[j−l], y[j−l+1,j]=s}
Φ(x, y) ·w
where 1 ≤",3.3 Joint Decoding,[0],[0]
"l ≤ lmax, y[1:j] is an event subgraph ending at the j-th token, and y[j−l+1,j] = s means that partial structure y[j−l+1,j] is a segment, i.e., an event trigger candidate with a subsequence of tokens x[j−l+1,j].",3.3 Joint Decoding,[0],[0]
"This approximates Viterbi decoding with beam search.
",3.3 Joint Decoding,[0],[0]
The best-first clustering incrementally makes coreference decisions by selecting the most likely antecedent for each trigger.,3.3 Joint Decoding,[0],[0]
Our joint decoding algorithm makes use of the incremental process to combine the segment-based decoding and bestfirst clustering.,3.3 Joint Decoding,[0],[0]
Algorithm 1 shows the summary of the joint decoding algorithm.,3.3 Joint Decoding,[0],[0]
"Line 3 - 7 implements the segment-based decoding, and line 8 - 11
implements the best-first clustering.",3.3 Joint Decoding,[0],[0]
"Once a new event trigger is appended to an event subgraph at line 6, the decoder uses it as a referring mention regardless of whether the event subgraph is in the beam, and seeks the best antecedent for it.",3.3 Joint Decoding,[0],[0]
"This enables the joint model to make a more global decision on event trigger identification and event coreference decision, as described in Section 1.",3.3 Joint Decoding,[0],[0]
"When training our model, we observed that 20- iteration training almost reached convergence, and thus we set the number of iterations to 20.",4 Experimental Settings,[0],[0]
We set lmax to 6 because we observed that the longest event trigger in the entire ProcessBank corpus has six tokens.,4 Experimental Settings,[0],[0]
"When tuning beam width k on the development set, large beam width did not give us a significant performance difference.",4 Experimental Settings,[0],[0]
We attribute this result to the small size of the development data.,4 Experimental Settings,[0],[0]
"In particular, the development data has only 28 event coreferences, which makes it difficult to reveal the effect of beam width.",4 Experimental Settings,[0],[0]
We thus set k to 1 in our experiments.,4 Experimental Settings,[0],[0]
Our baseline is a pipelined model that divides the event trigger decoding and event coreference decoding in Algorithm 1 into two separate stages.,4.1 Baseline Systems,[0],[0]
It uses the same structured perceptron with the same hyperparameters and feature templates.,4.1 Baseline Systems,[0],[0]
We choose this baseline because it clearly reveals the effectiveness of the joint model by focusing only on the architectural difference.,4.1 Baseline Systems,[0],[0]
One could develop other baseline systems.,4.1 Baseline Systems,[0],[0]
One of them is a deterministic sieve-based approach by Lee et al. (2013).,4.1 Baseline Systems,[0],[0]
A natural extension to the approach for performing event trigger identification as well as event coreference resolution would be to develop additional sieves to classify singletons into real event triggers or spurious ones.,4.1 Baseline Systems,[0],[0]
We leave it for future work.,4.1 Baseline Systems,[0],[0]
"We evaluate our system using a reference implementation of coreference scoring algorithms (Pradhan et al., 2014; Luo et al., 2014).",4.2 Evaluation,[0],[0]
"As for event trigger identification, this scorer computes precision (P), recall (R), and the F1 score.",4.2 Evaluation,[0],[0]
"With respect to event coreference resolution, the scorer computes MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), two CEAF metrics CEAFm and CEAFe (Luo, 2005), and
BLANC (Recasens and Hovy, 2011) extended by Luo et al. (2014).",4.2 Evaluation,[0],[0]
"We also report the CoNLL average (Denis and Baldridge, 2009), which is the average of MUC F1, B3 F1, and CEAFe F1.",4.2 Evaluation,[0],[0]
We first show the result of event coreference resolution on the test data in Table 2.,5 Results and Discussions,[0],[0]
The joint model outperforms the baseline by 6.9 BLANC F1 and 1.8 CoNLL F1 points.,5 Results and Discussions,[0],[0]
"We observed that this overall performance gain comes largely from a precision gain, more specifically, substantially reduced false positives.",5 Results and Discussions,[0],[0]
We explain the superiority of the joint model as follows.,5 Results and Discussions,[0],[0]
"In the baseline, the second stage uses the output of the first stage.",5 Results and Discussions,[0],[0]
"Since event triggers are fixed at this point, the baseline explores coreference links only between these event triggers.",5 Results and Discussions,[0],[0]
"In contrast, the joint model seeks event triggers and event coreference simultaneously, and thus it explores a larger number of false positives in the search process, thereby learning to penalize false positives more adequately than the baseline.
",5 Results and Discussions,[0],[0]
Table 3 shows the results of event trigger identification on the test data.,5 Results and Discussions,[0],[0]
"We observed that the joint model also reduced false positives, similarly in event coreference resolution.",5 Results and Discussions,[0],[0]
"However, its improvement on precision is small, ending up with almost the same F1 point as the baseline.",5 Results and Discussions,[0],[0]
"We speculate that this is due to the small size of the corpus, and the joint model was unable to show its advantages in event trigger identification.
",5 Results and Discussions,[0],[0]
"Below are two error cases in event coreference resolution, where our model fails to resolve E5E6 and E7-E8.",5 Results and Discussions,[0],[0]
"The model was unable to adequately extract features for both event triggers and event coreference, particularly because their surface strings are not present in training data, they are lexically and syntactically different, and they
do not share key semantic roles (e.g., agents and patients) in a clear argument structure.
",5 Results and Discussions,[0],[0]
"(3) When the cell is stimulated, gated channels open that facilitate Na+ diffusion(E5).",5 Results and Discussions,[0],[0]
"Sodium ions then ”fall”(E6) down their electrochemical gradient, . . .
",5 Results and Discussions,[0],[0]
(4) The next seven steps decompose(E7),5 Results and Discussions,[0],[0]
the citrate back to oxaloacetate.,5 Results and Discussions,[0],[0]
It is this regeneration(E8) of oxaloacetate that makes this process a cycle.,5 Results and Discussions,[0],[0]
We present a joint structured prediction model for event trigger identification and event coreference resolution.,6 Conclusion and Future Work,[0],[0]
"To our knowledge, this is the first work that solves these two tasks simultaneously.",6 Conclusion and Future Work,[0],[0]
"Our experiment shows that the proposed method effectively penalizes false positives in joint search, thereby outperforming a pipelined model substantially in event coreference resolution.
",6 Conclusion and Future Work,[0],[0]
There are a number of avenues for future work.,6 Conclusion and Future Work,[0],[0]
One can further ensure the advantage of the joint model using a larger corpus.,6 Conclusion and Future Work,[0],[0]
"Our preliminary experiment on the ACE 2005 corpus shows that due to its larger document size and event types, one will need to reduce training time by a distributed learning algorithm such as mini-batches (Zhao and Huang, 2013).",6 Conclusion and Future Work,[0],[0]
Another future work is to incorporate other components of events into the model.,6 Conclusion and Future Work,[0],[0]
"These include event types, event arguments, and other relations such as subevents.",6 Conclusion and Future Work,[0],[0]
"One could leverage them as other learning targets or constraints, and investigate further benefits of joint modeling.",6 Conclusion and Future Work,[0],[0]
"This research was supported in part by DARPA grant FA8750-12-2-0342 funded under the Deep Exploration and Filtering of Text (DEFT) Program, and by U.S. Army Research Office (ARO) grant W911NF-14-1-0436 under the Reading, Extraction, and Assembly of Pathways for Evidentiary Reading (REAPER) Program.",Acknowledgments,[0],[0]
"Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of DARPA, ARO, or the U.S. government.",Acknowledgments,[0],[0]
Jun Araki is partly supported by a Funai Overseas Scholarship.,Acknowledgments,[0],[0]
Events and their coreference offer useful semantic and discourse resources.,abstractText,[0],[0]
We show that the semantic and discourse aspects of events interact with each other.,abstractText,[0],[0]
"However, traditional approaches addressed event extraction and event coreference resolution either separately or sequentially, which limits their interactions.",abstractText,[0],[0]
This paper proposes a document-level structured learning model that simultaneously identifies event triggers and resolves event coreference.,abstractText,[0],[0]
We demonstrate that the joint model outperforms a pipelined model by 6.9 BLANC F1 and 1.8 CoNLL F1 points in event coreference resolution using a corpus in the biology domain.,abstractText,[0],[0]
Joint Event Trigger Identification and Event Coreference Resolution with Structured Perceptron,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1227–1236 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1113",text,[0],[0]
"Joint extraction of entities and relations is to detect entity mentions and recognize their semantic relations simultaneously from unstructured text, as Figure 1 shows.",1 Introduction,[0],[0]
"Different from open information extraction (Open IE) (Banko et al., 2007) whose relation words are extracted from the given sentence, in this task, relation words are extracted from a predefined relation set which may not appear in the given sentence.",1 Introduction,[0],[0]
"It is an important issue in knowledge extraction and automatic construction of knowledge base.
",1 Introduction,[0],[0]
"Traditional methods handle this task in a pipelined manner, i.e., extracting the entities (Nadeau and Sekine, 2007) first and then recognizing their relations (Rink, 2010).",1 Introduction,[0],[0]
"This separated framework makes the task easy to deal with, and each component can be more flexible.",1 Introduction,[0],[0]
"But it neglects the relevance between these two sub-tasks
and each subtask is an independent model.",1 Introduction,[0],[0]
"The results of entity recognition may affect the performance of relation classification and lead to erroneous delivery (Li and Ji, 2014).
",1 Introduction,[0],[0]
"Different from the pipelined methods, joint learning framework is to extract entities together with relations using a single model.",1 Introduction,[0],[0]
"It can effectively integrate the information of entities and relations, and it has been shown to achieve better results in this task.",1 Introduction,[0],[0]
"However, most existing joint methods are feature-based structured systems (Li and Ji, 2014; Miwa and Sasaki, 2014; Yu and Lam, 2010; Ren et al., 2017).",1 Introduction,[0],[0]
"They need complicated feature engineering and heavily rely on the other NLP toolkits, which might also lead to error propagation.",1 Introduction,[0],[0]
"In order to reduce the manual work in feature extraction, recently, (Miwa and Bansal, 2016) presents a neural networkbased method for the end-to-end entities and relations extraction.",1 Introduction,[0],[0]
"Although the joint models can represent both entities and relations with shared parameters in a single model, they also extract the entities and relations separately and produce redundant information.",1 Introduction,[0],[0]
"For instance, the sentence in Figure 1 contains three entities: “United States”, “Trump” and “Apple Inc”.",1 Introduction,[0],[0]
But only “United States” and “Trump” hold a fix relation “CountryPresident”.,1 Introduction,[0],[0]
"Entity “Apple Inc” has no obvious relationship with the other entities in this sen-
1227
tence.",1 Introduction,[0],[0]
"Hence, the extracted result from this sentence is {United Statese1, Country-Presidentr, Trumpe2}, which called triplet here.
",1 Introduction,[0],[0]
"In this paper, we focus on the extraction of triplets that are composed of two entities and one relation between these two entities.",1 Introduction,[0],[0]
"Therefore, we can model the triplets directly, rather than extracting the entities and relations separately.",1 Introduction,[0],[0]
"Based on the motivations, we propose a tagging scheme accompanied with the end-to-end model to settle this problem.",1 Introduction,[0],[0]
We design a kind of novel tags which contain the information of entities and the relationships they hold.,1 Introduction,[0],[0]
"Based on this tagging scheme, the joint extraction of entities and relations can be transformed into a tagging problem.",1 Introduction,[0],[0]
"In this way, we can also easily use neural networks to model the task without complicated feature engineering.
",1 Introduction,[0],[0]
"Recently, end-to-end models based on LSTM (Hochreiter and Schmidhuber, 1997) have been successfully applied to various tagging tasks: Named Entity Recognition (Lample et al., 2016), CCG Supertagging (Vaswani et al., 2016), Chunking (Zhai et al., 2017)",1 Introduction,[0],[0]
"et al. LSTM is capable of learning long-term dependencies, which is beneficial to sequence modeling tasks.",1 Introduction,[0],[0]
"Therefore, based on our tagging scheme, we investigate different kinds of LSTM-based end-to-end models to jointly extract the entities and relations.",1 Introduction,[0],[0]
"We also modify the decoding method by adding a biased loss to make it more suitable for our special tags.
",1 Introduction,[0],[0]
The method we proposed is a supervised learning algorithm.,1 Introduction,[0],[0]
"In reality, however, the process of manually labeling a training set with a large number of entity and relation is too expensive and error-prone.",1 Introduction,[0],[0]
"Therefore, we conduct experiments on a public dataset1 which is produced by distant supervision method (Ren et al., 2017) to validate our approach.",1 Introduction,[0],[0]
The experimental results show that our tagging scheme is effective in this task.,1 Introduction,[0],[0]
"In addition, our end-to-end model can achieve the best results on the public dataset.
",1 Introduction,[0],[0]
"The major contributions of this paper are: (1) A novel tagging scheme is proposed to jointly extract entities and relations, which can easily transform the extraction problem into a tagging task.",1 Introduction,[0],[0]
"(2) Based on our tagging scheme, we study different kinds of end-to-end models to settle the problem.",1 Introduction,[0],[0]
The tagging-based methods are better than most of the existing pipelined and joint learning methods.,1 Introduction,[0],[0]
"(3) Furthermore, we also develop an end-to-
1https://github.com/shanzhenren/CoType
end model with biased loss function to suit for the novel tags.",1 Introduction,[0],[0]
It can enhance the association between related entities.,1 Introduction,[0],[0]
"Entities and relations extraction is an important step to construct a knowledge base, which can be benefit for many NLP tasks.",2 Related Works,[0],[0]
Two main frameworks have been widely used to solve the problem of extracting entity and their relationships.,2 Related Works,[0],[0]
"One is the pipelined method and the other is the joint learning method.
",2 Related Works,[0],[0]
"The pipelined method treats this task as two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007) and relation classification (RC) (Rink, 2010).",2 Related Works,[0],[0]
"Classical NER models are linear statistical models, such as Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Passos et al., 2014; Luo et al., 2015).",2 Related Works,[0],[0]
"Recently, several neural network architectures (Chiu and Nichols, 2015; Huang et al., 2015; Lample et al., 2016) have been successfully applied to NER, which is regarded as a sequential token tagging task.",2 Related Works,[0],[0]
"Existing methods for relation classification can also be divided into handcrafted feature based methods (Rink, 2010; Kambhatla, 2004) and neural network based methods (Xu, 2015a; Zheng et al., 2016; Zeng, 2014; Xu, 2015b; dos Santos, 2015).
",2 Related Works,[0],[0]
While joint models extract entities and relations using a single model.,2 Related Works,[0],[0]
"Most of the joint methods are feature-based structured systems (Ren et al., 2017; Yang and Cardie, 2013; Singh et al., 2013; Miwa and Sasaki, 2014; Li and Ji, 2014).",2 Related Works,[0],[0]
"Recently, (Miwa and Bansal, 2016) uses a LSTM-based model to extract entities and relations, which can reduce the manual work.
",2 Related Works,[0],[0]
"Different from the above methods, the method proposed in this paper is based on a special tagging manner, so that we can easily use end-toend model to extract results without NER and RC. end-to-end method is to map the input sentence into meaningful vectors and then back to produce a sequence.",2 Related Works,[0],[0]
"It is widely used in machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014) and sequence tagging tasks (Lample et al., 2016; Vaswani et al., 2016).",2 Related Works,[0],[0]
"Most methods apply bidirectional LSTM to encode the input sentences, but the decoding methods are always different.",2 Related Works,[0],[0]
"For examples, (Lample et al., 2016) use a CRF layers to decode the tag sequence, while
(Vaswani et al., 2016; Katiyar and Cardie, 2016) apply LSTM layer to produce the tag sequence.",2 Related Works,[0],[0]
We propose a novel tagging scheme and an end-toend model with biased objective function to jointly extract entities and their relations.,3 Method,[0],[0]
"In this section, we firstly introduce how to change the extraction problem to a tagging problem based on our tagging method.",3 Method,[0],[0]
Then we detail the model we used to extract results.,3 Method,[0],[0]
Figure 2 is an example of how the results are tagged.,3.1 The Tagging Scheme,[0],[0]
Each word is assigned a label that contributes to extract the results.,3.1 The Tagging Scheme,[0],[0]
"Tag “O” represents the “Other” tag, which means that the corresponding word is independent of the extracted results.",3.1 The Tagging Scheme,[0],[0]
"In addition to “O”, the other tags consist of three parts: the word position in the entity, the relation type, and the relation role.",3.1 The Tagging Scheme,[0],[0]
"We use the “BIES” (Begin, Inside, End,Single) signs to represent the position information of a word in the entity.",3.1 The Tagging Scheme,[0],[0]
The relation type information is obtained from a predefined set of relations and the relation role information is represented by the numbers “1” and “2”.,3.1 The Tagging Scheme,[0],[0]
"An extracted result is represented by a triplet: (Entity1, RelationType,Entity2).",3.1 The Tagging Scheme,[0],[0]
"“1” means that the word belongs to the first entity in the triplet, while “2” belongs to second entity that behind the relation type.",3.1 The Tagging Scheme,[0],[0]
"Thus, the total number of tags is Nt = 2 ∗ 4 ∗ |R|+ 1, where |R| is the size of the predefined relation set.
",3.1 The Tagging Scheme,[0],[0]
Figure 2 is an example illustrating our tagging method.,3.1 The Tagging Scheme,[0],[0]
"The input sentence contains two triplets: {United States, Country-President, Trump} and {Apple Inc, Company-Founder, Steven Paul Jobs}, where “Country-President” and “Company-Founder” are the predefined relation types.",3.1 The Tagging Scheme,[0],[0]
"The words “United”,“States”,“ Trump”,“Apple”,“Inc” ,“Steven”, “Paul” and
“Jobs” are all related to the final extracted results.",3.1 The Tagging Scheme,[0],[0]
Thus they are tagged based on our special tags.,3.1 The Tagging Scheme,[0],[0]
"For example, the word of “United” is the first word of entity “United States” and is related to the relation “Country-President”, so its tag is “B-CP-1”.",3.1 The Tagging Scheme,[0],[0]
"The other entity “ Trump”, which is corresponding to “United States”, is labeled as “S-CP-2”.",3.1 The Tagging Scheme,[0],[0]
"Besides, the other words irrelevant to the final result are labeled as “O”.",3.1 The Tagging Scheme,[0],[0]
"From the tag sequence in Figure 2, we know that “ Trump” and “United States” share the same relation type “Country-President”, “Apple Inc” and “Steven Paul Jobs” share the same relation type “Company-Founder”.",3.2 From Tag Sequence To Extracted Results,[0],[0]
We combine entities with the same relation type into a triplet to get the final result.,3.2 From Tag Sequence To Extracted Results,[0],[0]
"Accordingly, “ Trump” and “United States” can be combined into a triplet whose relation type is “Country-President”.",3.2 From Tag Sequence To Extracted Results,[0],[0]
"Because, the relation role of “ Trump” is “2” and “United States” is “1”, the final result is {United States, CountryPresident, Trump}.",3.2 From Tag Sequence To Extracted Results,[0],[0]
"The same applies to {Apple Inc, Company-Founder, Steven Paul Jobs}.
",3.2 From Tag Sequence To Extracted Results,[0],[0]
"Besides, if a sentence contains two or more triplets with the same relation type, we combine every two entities into a triplet based on the nearest principle.",3.2 From Tag Sequence To Extracted Results,[0],[0]
"For example, if the relation type “Country-President” in Figure 2 is “CompanyFounder”, then there will be four entities in the given sentence with the same relation type.",3.2 From Tag Sequence To Extracted Results,[0],[0]
"“United States” is closest to entity “ Trump” and the “Apple Inc” is closest to “Jobs”, so the results will be {United States, Company-Founder, Trump} and {Apple Inc, Company-Founder, Steven Paul Jobs}.
",3.2 From Tag Sequence To Extracted Results,[0],[0]
"In this paper, we only consider the situation where an entity belongs to a triplet, and we leave identification of overlapping relations for future work.
",3.2 From Tag Sequence To Extracted Results,[0],[0]
"The United States president
O B-CP-1 E-CP-1 O S-CP-2
W1
Bi-LSTM
h1
LSTMd
T1
W2
Bi-LSTM
h2
LSTMd
T2
W3
Bi-LSTM
h3
LSTMd
T3
W4
Bi-LSTM
h4
LSTMd
T4
W5
Bi-LSTM
h5
LSTMd
T5
Trump
tanhσ σ σ
X
+X
tanh
X
Wt
ht-1 ht
ct-1",3.2 From Tag Sequence To Extracted Results,[0],[0]
"ct
tanhσ σ σ
X
+X
tanh
X
Wt
ht-1 ht
ct-1",3.2 From Tag Sequence To Extracted Results,[0],[0]
"ct
Tt Tt-1
tanh
(a) Bi-LSTM Block
(b) LSTMd",3.2 From Tag Sequence To Extracted Results,[0],[0]
"Block Input Sentence
Embeding Layer
Encoding Layer
Decoding Layer
Softmax
Output",3.2 From Tag Sequence To Extracted Results,[0],[0]
"In recent years, end-to-end model based on neural network is been widely used in sequence tagging task.",3.3 The End-to-end Model,[0],[0]
"In this paper, we investigate an end-to-end model to produce the tags sequence as Figure 3 shows.",3.3 The End-to-end Model,[0],[0]
It contains a bi-directional Long Short Term Memory (Bi-LSTM) layer to encode the input sentence and a LSTM-based decoding layer with biased loss.,3.3 The End-to-end Model,[0],[0]
"The biased loss can enhance the relevance of entity tags.
",3.3 The End-to-end Model,[0],[0]
The Bi-LSTM Encoding Layer.,3.3 The End-to-end Model,[0],[0]
"In sequence tagging problems, the Bi-LSTM encoding layer has been shown the effectiveness to capture the semantic information of each word.",3.3 The End-to-end Model,[0],[0]
"It contains forward lstm lay r, backw rd lstm layer and the concatenate layer.",3.3 The End-to-end Model,[0],[0]
The word embedding layer converts the word with 1-hot representation to an embedding vector.,3.3 The End-to-end Model,[0],[0]
"Hence, a sequence of words can be represented as W = {w1, ...wt, wt+1...",3.3 The End-to-end Model,[0],[0]
"wn}, where wt ∈ Rd is the d-dimensional word vector corresponding to the t-th word in the sentence and n is the length of the given sentence.",3.3 The End-to-end Model,[0],[0]
"After word embedding layer, there are two parallel LSTM layers: forward LSTM layer and backward LSTM layer.",3.3 The End-to-end Model,[0],[0]
"The LSTM architecture consists of a set of recurrently connected subnets, known as memory blocks.",3.3 The End-to-end Model,[0],[0]
Each time-step is a LSTM memory block.,3.3 The End-to-end Model,[0],[0]
"The LSTM memory block in Bi-LSTM encoding layer is used to compute current hidden vector ht based on the previous hidden vector ht−1, the previous cell vector ct−1 and the current input word embedding wt.",3.3 The End-to-end Model,[0],[0]
"Its structure diagram is shown in Figure 3 (b), and detail operations are defined as
follows:
it = δ(Wwiwt +Whiht−1 +Wcict−1 + bi), (1)
ft = δ(Wwfwt+Whfht−1+Wcfct−1+bf ), (2)
",3.3 The End-to-end Model,[0],[0]
"zt = tanh(Wwcwt +Whcht−1 + bc), (3)
ct = ftct−1 + itzt, (4)
",3.3 The End-to-end Model,[0],[0]
"ot = δ(Wwowt +W oht−1 +Wcoct + bo), (5)
ht = ottanh(ct), (6)
where i, f and o are the input gate, forget gate and output gate respectively, b is the bias term, c is the cell memory, and W(.) are the parameters.",3.3 The End-to-end Model,[0],[0]
"For each word wt, the forward LSTM layer will encode wt by considering he contextual information from wordw1 towt, which is marked as −→ ht .",3.3 The End-to-end Model,[0],[0]
"In the similar way, the backward LSTM layer will encode wt based on the contextual information from wn to wt, which is marked as ←− ht .",3.3 The End-to-end Model,[0],[0]
"Finally, we concatenate ←−",3.3 The End-to-end Model,[0],[0]
"ht and −→ ht to represent word t’s encoding information, denoted as ht =",3.3 The End-to-end Model,[0],[0]
"[ −→ ht , ←− ht ].",3.3 The End-to-end Model,[0],[0]
The LSTM Decoding Layer.,3.3 The End-to-end Model,[0],[0]
We also adopt a LSTM structure to produce the tag sequence.,3.3 The End-to-end Model,[0],[0]
"When detecting the tag of word wt, the inputs of decoding layer are: ht obtained from Bi-LSTM encoding layer, former predicted tag embedding Tt−1, former cell value c(2)t−1, and the former hidden vector in decoding layer h(2)t−1.",3.3 The End-to-end Model,[0],[0]
"The structure diagram of the memory block in LSTMd is shown in Figure 3 (c), and detail operations are defined as follows:
i (2) t = δ(W (2) wi ht +W (2) hi h (2) t−1 +WtiTt−1 + b (2) i ),
(7)
f (2) t = δ(W (2)",3.3 The End-to-end Model,[0],[0]
wf ht +W (2) hf h (2) t−1 +WtfTt−1 + b,3.3 The End-to-end Model,[0],[0]
"(2) f ),
(8)
z (2) t = tanh(W (2) wc ht+W (2) hc h (2) t−1+WtcTt−1+b (2) c ), (9)
c (2) t = f (2) t c (2) t−1",3.3 The End-to-end Model,[0],[0]
"+ i (2) t z (2) t , (10)
o (2) t = δ(W (2)",3.3 The End-to-end Model,[0],[0]
wo ht +W (2) ho h (2) t−1 +W (2) co ct + b,3.3 The End-to-end Model,[0],[0]
"(2) o ), (11)
h (2) t =",3.3 The End-to-end Model,[0],[0]
o,3.3 The End-to-end Model,[0],[0]
"(2) t tanh(c (2) t ), (12)
",3.3 The End-to-end Model,[0],[0]
Tt = Wtsh (2) t + bts.,3.3 The End-to-end Model,[0],[0]
"(13)
The final softmax layer computes normalized entity tag probabilities based on the tag predicted vector Tt:
yt = WyTt + by, (14)
pit = exp(yit)
",3.3 The End-to-end Model,[0],[0]
"Nt∑ j=1 exp(yjt )
, (15)
where Wy is the softmax matrix, Nt is the total number of tags.",3.3 The End-to-end Model,[0],[0]
"Because T is similar to tag embedding and LSTM is capable of learning longterm dependencies, the decoding manner can model tag interactions.",3.3 The End-to-end Model,[0],[0]
The Bias Objective Function.,3.3 The End-to-end Model,[0],[0]
"We train our model to maximize the log-likelihood of the data and the optimization method we used is RMSprop proposed by Hinton in (Tieleman and Hinton, 2012).",3.3 The End-to-end Model,[0],[0]
"The objective function can be defined as:
L =max
|D|∑
j=1
Lj∑
t=1
(log(p (j) t = y (j) t |xj ,Θ) ·",3.3 The End-to-end Model,[0],[0]
"I(O)
",3.3 The End-to-end Model,[0],[0]
"+α · log(p(j)t = y (j) t |xj ,Θ) · (1− I(O))),
where |D| is the size of training set, Lj is the length of sentence xj , y (j) t is the label of word t in sentence xj and p (j) t is the normalized probabilities of tags which defined in Formula 15.",3.3 The End-to-end Model,[0],[0]
"Besides, I(O) is a switching function to distinguish the loss of tag ’O’ and relational tags that can indicate the results.",3.3 The End-to-end Model,[0],[0]
"It is defined as follows:
I(O)",3.3 The End-to-end Model,[0],[0]
"=
{ 1, if tag = ′O′
0, if tag 6= ′O′.
α is the bias weight.",3.3 The End-to-end Model,[0],[0]
"The larger α is, the greater influence of relational tags on the model.",3.3 The End-to-end Model,[0],[0]
"Dataset To evaluate the performance of our methods, we use the public dataset NYT 2 which is produced by distant supervision method (Ren et al., 2017).",4.1 Experimental setting,[0],[0]
A large amount of training data can be obtained by means of distant supervision methods without manually labeling.,4.1 Experimental setting,[0],[0]
While the test set is manually labeled to ensure its quality.,4.1 Experimental setting,[0],[0]
"In total, the training data contains 353k triplets, and the test set contains 3, 880 triplets.",4.1 Experimental setting,[0],[0]
"Besides, the size of relation set is 24.",4.1 Experimental setting,[0],[0]
"Evaluation We adopt standard Precision (Prec), Recall (Rec) and F1 score to evaluate the results.",4.1 Experimental setting,[0],[0]
"Different from classical methods, our method can extract triplets without knowing the information of entity types.",4.1 Experimental setting,[0],[0]
"In other words, we did not use the label of entity types to train the model, therefore we do not need to consider the entity types in the evaluation.",4.1 Experimental setting,[0],[0]
A triplet is regarded as correct when its relation type and the head offsets of two corresponding entities are both correct.,4.1 Experimental setting,[0],[0]
"Besides, the ground-truth relation mentions are given and “None” label is excluded as (Ren et al., 2017; Li and Ji, 2014; Miwa and Bansal, 2016) did.",4.1 Experimental setting,[0],[0]
"We create a validation set by randomly sampling 10% data from test set and use the remaining data as evaluation based on (Ren et al., 2017)’s suggestion.",4.1 Experimental setting,[0],[0]
We run 10 times for each experiment then report the average results and their standard deviation as Table 1 shows.,4.1 Experimental setting,[0],[0]
Hyperparameters Our model consists of a BiLSTM encoding layer and a LSTM decoding layer with bias objective function.,4.1 Experimental setting,[0],[0]
"The word embeddings used in the encoding part are initialed by running word2vec3 (Mikolov et al., 2013) on NYT training corpus.",4.1 Experimental setting,[0],[0]
The dimension of the word embeddings is d = 300.,4.1 Experimental setting,[0],[0]
We regularize our network using dropout on embedding layer and the dropout ratio is 0.5.,4.1 Experimental setting,[0],[0]
The number of lstm units in encoding layer is 300 and the number in decoding layer is 600.,4.1 Experimental setting,[0],[0]
"The bias parameter α corresponding to the results in Table 1 is 10.
2The dataset can be downloaded at: https://github.com/shanzhenren/CoType.",4.1 Experimental setting,[0],[0]
There are three data sets in the public resource and we only use the NYT dataset.,4.1 Experimental setting,[0],[0]
Because more than 50% of the data in BioInfer has overlapping relations which is beyond the scope of this paper.,4.1 Experimental setting,[0],[0]
"As for dataset Wiki-KBP, the number of relation type in the test set is more than that of the train set, which is also not suitable for a supervised training method.",4.1 Experimental setting,[0],[0]
"Details of the data can be found in Ren’s(Ren et al., 2017) paper.
",4.1 Experimental setting,[0],[0]
"3https://code.google.com/archive/p/word2vec/
Baselines We compare our method with several classical triplet extraction methods, which can be divided into the following categories: the pipelined methods, the jointly extracting methods and the end-to-end methods based our tagging scheme.
",4.1 Experimental setting,[0],[0]
"For the pipelined methods, we follow (Ren et al., 2017)’s settings:",4.1 Experimental setting,[0],[0]
"The NER results are obtained by CoType (Ren et al., 2017) then several classical relation classification methods are applied to detect the relations.",4.1 Experimental setting,[0],[0]
"These methods are: (1) DS-logistic (Mintz et al., 2009) is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE (Tang et al., 2015) is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM (Gormley et al., 2015) is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction.
",4.1 Experimental setting,[0],[0]
"The jointly extracting methods used in this paper are listed as follows: (4) DS-Joint (Li and Ji, 2014) is a supervised method, which jointly extracts entities and relations using structured perceptron on human-annotated dataset; (5) MultiR",4.1 Experimental setting,[0],[0]
"(Hoffmann et al., 2011) is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType (Ren et al., 2017) is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into meaningful representations.
",4.1 Experimental setting,[0],[0]
"In addition, we also compare our method with two classical end-to-end tagging models: LSTMCRF (Lample et al., 2016) and LSTM-LSTM
(Vaswani et al., 2016).",4.1 Experimental setting,[0],[0]
LSTM-CRF is proposed for entity recognition by using a bidirectional LSTM to encode input sentence and a conditional random fields to predict the entity tag sequence.,4.1 Experimental setting,[0],[0]
"Different from LSTM-CRF, LSTM-LSTM uses a LSTM layer to decode the tag sequence instead of CRF.",4.1 Experimental setting,[0],[0]
They are used for the first time to jointly extract entities and relations based on our tagging scheme.,4.1 Experimental setting,[0],[0]
We report the results of different methods as shown in Table 1.,4.2 Experimental Results,[0],[0]
"It can be seen that our method, LSTM-LSTM-Bias, outperforms all other methods in F1 score and achieves a 3% improvement in F1 over the best method CoType (Ren et al., 2017).",4.2 Experimental Results,[0],[0]
It shows the effectiveness of our proposed method.,4.2 Experimental Results,[0],[0]
"Furthermore, from Table 1, we also can see that the jointly extracting methods are better than pipelined methods, and the tagging methods are better than most of the jointly extracting methods.",4.2 Experimental Results,[0],[0]
"It also validates the validity of our tagging scheme for the task of jointly extracting entities and relations.
",4.2 Experimental Results,[0],[0]
"When compared with the traditional methods, the precisions of the end-to-end models are significantly improved.",4.2 Experimental Results,[0],[0]
But only LSTM-LSTM-Bias can be better to balance the precision and recall.,4.2 Experimental Results,[0],[0]
The reason may be that these end-to-end models all use a Bi-LSTM encoding input sentence and different neural networks to decode the results.,4.2 Experimental Results,[0],[0]
The methods based on neural networks can well fit the data.,4.2 Experimental Results,[0],[0]
"Therefore, they can learn the common features of the training set well and may lead to the lower expansibility.",4.2 Experimental Results,[0],[0]
"We also find that the LSTM-LSTM
model is better than LSTM-CRF model based on our tagging scheme.",4.2 Experimental Results,[0],[0]
"Because, LSTM is capable of learning long-term dependencies and CRF (Lafferty et al., 2001) is good at capturing the joint probability of the entire sequence of labels.",4.2 Experimental Results,[0],[0]
The related tags may have a long distance from each other.,4.2 Experimental Results,[0],[0]
"Hence, LSTM decoding manner is a little better than CRF.",4.2 Experimental Results,[0],[0]
LSTM-LSTM-Bias adds a bias weight to enhance the effect of entity tags and weaken the effect of invalid tag.,4.2 Experimental Results,[0],[0]
"Therefore, in this tagging scheme, our method can be better than the common LSTM-decoding methods.",4.2 Experimental Results,[0],[0]
"In this paper, we focus on extracting triplets composed of two entities and a relation.",5.1 Error Analysis,[0],[0]
Table 1 has shown the predict results of the task.,5.1 Error Analysis,[0],[0]
It treats an triplet is correct only when the relation type and the head offsets of two corresponding entities are both correct.,5.1 Error Analysis,[0],[0]
"In order to find out the factors that affect the results of end-to-end models, we analyze the performance on predicting each element in the triplet as Table 2 shows.",5.1 Error Analysis,[0],[0]
"E1 and E2 represent the performance on predicting each entity, respectively.",5.1 Error Analysis,[0],[0]
"If the head offset of the first entity is correct, then the instance of E1 is correct, the same to E2.",5.1 Error Analysis,[0],[0]
"Regardless of relation type, if the head offsets of two corresponding entities are both correct, the instance of (E1, E2) is correct.
",5.1 Error Analysis,[0],[0]
"As shown in Table 2, (E1, E2) has higher precision when compared with E1 and E2.",5.1 Error Analysis,[0],[0]
But its recall result is lower than E1 and E2.,5.1 Error Analysis,[0],[0]
It means that some of the predicted entities do not form a pair.,5.1 Error Analysis,[0],[0]
"They only obtain E1 and do not find its corresponding E2, or obtain E2 and do not find its corresponding E1.",5.1 Error Analysis,[0],[0]
"Thus it leads to the prediction of more single E and less (E1, E2) pairs.",5.1 Error Analysis,[0],[0]
"Therefore, entity pair (E1, E2) has higher precision and lower recall than single E. Besides, the predicted results of (E1, E2) in Table 2 have about 3% improvement when compared predicted results in Table 1, which means that 3% of the test data is
predicted to be wrong because the relation type is predicted to be wrong.",5.1 Error Analysis,[0],[0]
"Different from LSTM-CRF and LSTM-LSTM, our approach is biased towards relational labels to enhance links between entities.",5.2 Analysis of Biased Loss,[0],[0]
"In order to further analyze the effect of the bias objective function, we visualize the ratio of predicted single entities for each end-to-end method as Figure 4.",5.2 Analysis of Biased Loss,[0],[0]
The single entities refer to those who cannot find their corresponding entities.,5.2 Analysis of Biased Loss,[0],[0]
"Figure 4 shows whether it is E1 or E2, our method can get a relatively low ratio on the single entities.",5.2 Analysis of Biased Loss,[0],[0]
"It means that our method can effectively associate two entities when compared LSTM-CRF and LSTM-LSTM which pay little attention to the relational tags.
",5.2 Analysis of Biased Loss,[0],[0]
"Besides, we also change the Bias Parameter α from 1 to 20, and the predicted results are shown in Figure 5.",5.2 Analysis of Biased Loss,[0],[0]
"If α is too large, it will affect the accuracy of prediction and if α is too small, the recall will decline.",5.2 Analysis of Biased Loss,[0],[0]
"When α = 10, LSTM-LSTMBias can balance the precision and recall, and can achieve the best F1 scores.",5.2 Analysis of Biased Loss,[0],[0]
"In this section, we observe the prediction results of end-to-end methods, and then select several representative examples to illustrate the advantages and disadvantages of the methods as Table 3 shows.",5.3 Case Study,[0],[0]
"Each example contains three row, the first row is the gold standard, the second and the third rows are the extracted results of model LSTM-LSTM and LSTM-LSTM-Bias respectively.",5.3 Case Study,[0],[0]
"S1 represents the situation that the distance between the two interrelated entities is far away
from each other, which is more difficult to detect their relationships.",5.3 Case Study,[0],[0]
"When compared with LSTMLSTM, LSTM-LSTM-Bias uses a bias objective function which enhance the relevance between entities.",5.3 Case Study,[0],[0]
"Therefore, in this example, LSTM-LSTMBias can extract two related entities, while LSTMLSTM can only extract one entity of “Florida” and can not detect entity “Panama City Beach”.
",5.3 Case Study,[0],[0]
S2 is a negative example that shows these methods may mistakenly predict one of the entity.,5.3 Case Study,[0],[0]
There are no indicative words between entities Nuremberg and Germany.,5.3 Case Study,[0],[0]
"Besides, the patten “a * of *” between Germany and MiddleAges may be easy to mislead the models that there exists a relation of “Contains” between them.",5.3 Case Study,[0],[0]
"The problem can be solved by adding some samples of this kind of expression patterns to the training data.
",5.3 Case Study,[0],[0]
"S3 is a case that models can predict the entities’ head offset right, but the relational role is wrong.",5.3 Case Study,[0],[0]
"LSTM-LSTM treats both “Stephen A. Schwarzman” and “Blackstone Group” as entity E1, and can not find its corresponding E2.",5.3 Case Study,[0],[0]
"Although, LSTM-LSMT–Bias can find the entities pair (E1, E2), it reverses the roles of “Stephen A. Schwarzman” and “Blackstone Group”.",5.3 Case Study,[0],[0]
"It shows that LSTM-LSTM-Bias is able to better on pre-
dicting entities pair, but it remains to be improved in distinguishing the relationship between the two entities.",5.3 Case Study,[0],[0]
"In this paper, we propose a novel tagging scheme and investigate the end-to-end models to jointly extract entities and relations.",6 Conclusion,[0],[0]
The experimental results show the effectiveness of our proposed method.,6 Conclusion,[0],[0]
But it still has shortcoming on the identification of the overlapping relations.,6 Conclusion,[0],[0]
"In the future work, we will replace the softmax function in the output layer with multiple classifier, so that a word can has multiple tags.",6 Conclusion,[0],[0]
"In this way, a word can appear in multiple triplet results, which can solve the problem of overlapping relations.",6 Conclusion,[0],[0]
"Although, our model can enhance the effect of entity tags, the association between two corresponding entities still requires refinement in next works.",6 Conclusion,[0],[0]
We thank Xiang Ren for dataset details and helpful discussions.,Acknowledgments,[0],[0]
"This work is also supported by the National High Technology Research and Development Program of China (863 Program) (Grant No. 2015AA015402), the National Natural Science Foundation of China (No. 61602479) and the NSFC project 61501463.",Acknowledgments,[0],[0]
Joint extraction of entities and relations is an important task in information extraction.,abstractText,[0],[0]
"To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem.",abstractText,[0],[0]
"Then, based on our tagging scheme, we study different end-toend models to extract entities and their relations directly, without identifying entities and relations separately.",abstractText,[0],[0]
We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods.,abstractText,[0],[0]
"What’s more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.",abstractText,[0],[0]
Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 646–651 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
646
 
We present a neural network-based joint approach for emotion classification and emotion cause detection, which attempts to capture mutual benefits across the two sub-tasks of emotion analysis. Considering that emotion classification and emotion cause detection need different kinds of features (affective and event-based separately), we propose a joint encoder which uses a unified framework to extract features for both sub-tasks and a joint model trainer which simultaneously learns two models for the two sub-tasks separately. Our experiments on Chinese microblogs show that the joint approach is very promising.",text,[0],[0]
The analysis of emotions in texts is an important task in NLP.,1 Introduction,[0],[0]
Traditional studies treat this task as a pipeline of two separated sub-tasks: emotion classification and emotion cause detection.,1 Introduction,[0],[0]
The former identifies the category of an emotion and the latter detects the cause of an emotion.,1 Introduction,[0],[0]
"This separated framework makes each sub-task more flexible to deal with, but it neglects the relevance between the two sub-tasks.",1 Introduction,[0],[0]
"In this paper, we explore joint approaches which can capture mutual benefits across the relevant two sub-tasks.",1 Introduction,[0],[0]
"To the best of our knowledge, this work is the first attempt to incorporate both emotion classification and emotion cause detection into a unified framework.
",1 Introduction,[0],[0]
"Although emotion classification relies on affective features and emotion cause detection needs event-based features, we propose a joint encoder which uses a unified framework to ex-
tract features for both emotion classification instances and emotion cause detection instances.",1 Introduction,[0],[0]
"Then, we propose a joint model trainer which simultaneously learns two models for the two sub-tasks separately.",1 Introduction,[0],[0]
The experiments on Chinese microblogs show that our joint approach can effectively learn models for both sub-tasks.,1 Introduction,[0],[0]
"In this paper, we use the human-labeled emotion corpus provided by Cheng et al. (2017) as our experimental data (namely Cheng emotion corpus).",2.1 Corpus,[0],[0]
"To better explain our work, we adopt twitter’s terminology used in Cheng et al. (2017).",2.1 Corpus,[0],[0]
Cheng emotion corpus can be considered as a collection of subtweets.,2.1 Corpus,[0],[0]
"For each emotion in a subtweet, all emotion keywords expressing the emotion are selected, and then the class and the cause of the emotion are annotated.",2.1 Corpus,[0],[0]
"The emotion categorization used in Huang et al. (2016) is adopted, which includes four basic emotions (i.e., joy, angry, sad and fearful) and three complex emotions (i.e., positive, neutral and negative).",2.1 Corpus,[0],[0]
"E.g. in the following example, the class of the emotion keyword (“ ”) is sad, and the cause of the emotion is “only I was at home again”.
",2.1 Corpus,[0],[0]
"647
 ",2.1 Corpus,[0],[0]
"In this paper, both the emotion classification subtask (namely EClass) and the emotion cause detection sub-task (namely ECause) are clauselevel.",2.2 Problem Formulation,[0],[0]
"Given an instance which is a clause in a subtweet, EClass assigns one of seven labels (i.e. six emotion classes and label ‘non-emotion’ which indicates the absence of an emotion) to the instance.",2.2 Problem Formulation,[0],[0]
"Notice, because of the extremely low percentage of emotion ‘fearful’ (~0.6% in §3.1 Table 1), we ignore this emotion class in EClass.",2.2 Problem Formulation,[0],[0]
"Given an instance which is a pair of <an emotion keyword, a clause in the subtweet>, ECause assigns a binary label to the instance to indicates the presence of a causal relation.",2.2 Problem Formulation,[0],[0]
"Moreover, the clause-level EClass can effectively avoid the problem of multiple emotions (Li et al., 2015) because clauses are a kind of fine-grained texts.
",2.2 Problem Formulation,[0],[0]
"Furthermore, the input text of an EClass instance contains three sequences of words: the previous clause (i.e. PrevCL), the current clause (i.e. CurCL), and the following clause (i.e. FolCL).",2.2 Problem Formulation,[0],[0]
The previous clause and the following clause provide contextual information for the current clause.,2.2 Problem Formulation,[0],[0]
"The input text of an ECause instance also has three sequences of words: the emotion keyword (i.e. EmoKW), the current clause (i.e. CauseCL) and the context between EmoKW and CauseCL.",2.2 Problem Formulation,[0],[0]
"The emotion keyword serves as an anchor, the current clause gives the description of an event which may cause the emotion, and the context provides complemental information for
the event.",2.2 Problem Formulation,[0],[0]
"Moreover, each word is represented with a vector from our word embedding model which is trained with word2vec1 and the tweet corpus of Cheng et al. (2017).",2.2 Problem Formulation,[0],[0]
"As shown in Fig. 2, there are two parts in our joint approach which is based on neural networks: a joint encoder (the lower part) which extracts feature representations for both EClass instances and ECause instances, and a linear decoder (the upper part) which assigns labels to instances according to their representations.",2.3 The Joint Approach,[0],[0]
"Neural Networks In the joint encoder, there are two neural networks (the attention network and the LSTM network), and each neural network is composed of several layers: bidirectional LSTM (i.e. BiLSTM) and attention.",2.3 The Joint Approach,[0],[0]
"The BiLSTM layer focuses on the extraction of sequence features, and the attention layer focuses on the learning of word importance (weights).",2.3 The Joint Approach,[0],[0]
"Because of the feature sparse problem in our small-scaled experimental data, the attention network often cannot effectively extract features to represent an event (see §3.2).",2.3 The Joint Approach,[0],[0]
"Thus, in our joint encoder, we use the attention network to extract affective features (e.g. “ ” in Fig. 1) and the LSTM network to extract event-based features (e.g. “I found that only I was at home again” in Fig. 1).",2.3 The Joint Approach,[0],[0]
"
                                                             1 https://code.google.com/p/word2vec/
648
 
The attention network: we implement the attention network used in Felbo et al. (2017), which includes two layers: a BiLSTM layer which extracts a sequence feature for each input word, and an attention layer which represents the input sequence using weighted words.",2.3 The Joint Approach,[0],[0]
"The LSTM network: the network uses a BiLSTM layer to capture a sequence feature for each input word, and then uses the average of those features as the representation of the input sequence.
",2.3 The Joint Approach,[0],[0]
"In the linear decoder, there are two classification networks (CNet EClass and CNet ECause) for EClass and ECause separately.",2.3 The Joint Approach,[0],[0]
"Each classification network uses a linear layer to build a probabilistic classification model.
",2.3 The Joint Approach,[0],[0]
"The Joint Encoder As shown in Fig. 2, there are two sub-encoders in our joint encoder: Encoder EClass (the left part) which provides a representation for an EClass instance, and Encoder ECause (the right part) which extracts a representation for an ECause instance.",2.3 The Joint Approach,[0],[0]
"Given an instance, one sub-encoder extracts a main representation (through the black lines in Fig.2) and the other sub-encoder provides an auxiliary representation (through the blue or red lines in Fig.2).",2.3 The Joint Approach,[0],[0]
"Then, the concatenation of the two representations serves as the final representation for the instance (i.e. hEClass or hECause in Fig.2).",2.3 The Joint Approach,[0],[0]
"In order to deal with the case that a main representation may be overwhelmed by its corresponding auxiliary representation, linear layers are used to reduce the dimensions of auxiliary representations.",2.3 The Joint Approach,[0],[0]
"Moreover, there are three sequences of words either in the input text of an EClass instance or in the input text of an ECause instance.",2.3 The Joint Approach,[0],[0]
"In order to effectively use these input sequences, a multi-channel structure is chosen, which encodes the input sequences one by one.",2.3 The Joint Approach,[0],[0]
"Encoder EClass: given the three sequences of words in an EClass instance (PrevCL, CurCL and FolCL), the attention network is applied to CurCL to extract an affective representation, and the LSTM network is applied to PrevCL and FolCL separately to extract two event-based representations.",2.3 The Joint Approach,[0],[0]
"Then, the concatenation of the three representations is used as the main representation (i.e. hmain_EClass).",2.3 The Joint Approach,[0],[0]
"Furthermore, in order to extract more contextual information, the LSTM network of Encoder ECause is applied to PrevCL and FolCL (through the blue lines in Fig. 2) to extract the auxiliary representation (i.e. haux_EClass), which
provides another event-based view for our emotion classification.",2.3 The Joint Approach,[0],[0]
"Encoder ECause: in order to separately deal with the three sequences of words (EmoKW, CauseCL and Context) in an ECause instance, the LSTM network is applied to each input sequence and then the concatenation of the three representations is used as the main representation (i.e. hmain_ECause).",2.3 The Joint Approach,[0],[0]
"Furthermore, for each input sequence (CauseCL or Context), the BiLSTM layer in the attention network is used to extract more eventbased features (through the red lines in Fig. 2), and those features serve as an auxiliary representation (i.e. haux_ECause) which provides another event-based view for our emotion cause detection.",2.3 The Joint Approach,[0],[0]
"The Joint Model Trainer During training, two models (JMEClass and JMECause) are learned simultaneously for the two sub-tasks (EClass and ECause) separately.",2.3 The Joint Approach,[0],[0]
"Model JMEClass contains Encoder EClass and CNet EClass, and Model JMECause contains Encoder ECause and CNet ECause.",2.3 The Joint Approach,[0],[0]
"Although each model uses auxiliary representations from the other model, but the learning of the model focuses on its own parameters.",2.3 The Joint Approach,[0],[0]
"In other words, gradient calculation is disabled along the dashed lines in Fig. 2.
",2.3 The Joint Approach,[0],[0]
"In each episode, the batch of input data is composed of two sets of instances: EClass subbatch containing only EClass instances and ECause sub-batch containing only ECause instances.",2.3 The Joint Approach,[0],[0]
"Given the batch of data, the parameters of each model are updated according its corresponding loss function.",2.3 The Joint Approach,[0],[0]
"E.g., Model JMEClass uses only the EClass sub-batch, and its loss function is the mean squared errors of the instances in the sub-batch.",2.3 The Joint Approach,[0],[0]
"In our joint model trainer, the two models are optimized using their own loss functions as pipeline model training does, but they use up-to-date auxiliary representations from each other to help optimization.",2.3 The Joint Approach,[0],[0]
"In Cheng emotion corpus, there are ~3,000 subtweets, ~11,000 instances for EClass, and ~13,000 instances for ECause.",3.1 Experimental Setup,[0],[0]
"Moreover, Table 1 lists the class distribution in Cheng emotion corpus for EClass.",3.1 Experimental Setup,[0],[0]
"All experiments in this paper are
649
 
trained and tested by 5-fold cross-validation on Cheng emotion corpus, and all the results reported are the average ones of 5-fold cross-validation performances.",3.1 Experimental Setup,[0],[0]
"We use the precision, recall and Fscore as our evaluation metrics.",3.1 Experimental Setup,[0],[0]
"However, because of the high percentage of label ‘nonemotion’ in EClass (see Table 1) and label ‘0’ in ECause, similar to previous work (Li et al. 2015; Felbo et al., 2017; Cheng et al., 2017; Gui et al., 2017), we report only the evaluation metrics of the six emotion classes for EClass and the evaluation metrics of label ‘1’ for ECause.
",3.1 Experimental Setup,[0],[0]
"During our joint training process, the dimension of the word embeddings is 20; the output dimension of the BiLSTM layer used in both the LSTM network and the attention network is 128; the output dimension of the linear network is 8; the batch size is 32.
",3.1 Experimental Setup,[0],[0]
The two models (JMEClass and JMECause) which are learned by our joint approach are compared with several pipeline models which are learned in a pipeline manner (i.e. either for EClass or for ECause) using one of the following state-of-the-art encoders.  ,3.1 Experimental Setup,[0],[0]
ATT: the attention network in Fig.2 .  ,3.1 Experimental Setup,[0],[0]
LSTM: the LSTM network in Fig.2.  ,3.1 Experimental Setup,[0],[0]
"ATT+LSTM: an hybrid encoder for emotion
classification, which applies ATT to CurCL and LSTM to PrevCL and FolCL.
 ",3.1 Experimental Setup,[0],[0]
"ConvMSMemnet: the encoder proposed by Gui et al. (2017) for emotion cause detection, which applies a convolutional multiple-slot deep memory network to CauseCL.",3.1 Experimental Setup,[0],[0]
"Table 2 shows the performances of different emotion classification models, where “Sequence” lists the sequences of input words used by each model and each metric is the average performances of six emotion classes.",3.2 Method Analysis,[0],[0]
"Moreover, Table 3 lists the detailed performances of each emotion class in Model JMEClass.
",3.2 Method Analysis,[0],[0]
"In Table 2, Model ATT + CurCL out-performs LSTM + CurCL by 2.8% in F-scores, where ATT is a state-of-the-art encoder for emotion classification (Felbo et al., 2017).",3.2 Method Analysis,[0],[0]
The significant performance improvement means that ATT can effectively extract affective features in CurCL.,3.2 Method Analysis,[0],[0]
"In fact, the emotion classification on Chinese microblogs can rely much on emotion keywords occurring in CurCL.",3.2 Method Analysis,[0],[0]
E.g. ~50% emotional instances in our experimental data contains emoticons (e.g. “ ” in Fig. 1) in CurCL and those emoticons themselves are strong emotion indicators.,3.2 Method Analysis,[0],[0]
"Secondly, when different kinds of contextual information are incorporated to Model ATT + CurCL, different performance improvements obtain (0.2% for ATT + all and 0.7% for ATT+LSTM in F-scores).",3.2 Method Analysis,[0],[0]
"This indicates that for the emotion classification, the event-based features extracted by LSTM are more helpful than the affective features extracted by ATT, because contexts often provide the cause event of an emotion.",3.2 Method Analysis,[0],[0]
"E.g. in Fig. 1, the previous clause of “ ” contains its cause “only I was at home again”.",3.2 Method Analysis,[0],[0]
"Finally, taking the advantage of the event-based features extracted by JMECause, JMEClass out-performs the best pipeline model (ATT+LSTM) by 0.7% in F-scores.",3.2 Method Analysis,[0],[0]
"This shows that it is important for the emotion classification to have an encoder which can effectively extract event-based features from contexts.
",3.2 Method Analysis,[0],[0]
"In Table 3, the performance of a basic emotion (i.e., joy, angry or sad) is often better than the one of a complex emotion (i.e., positive, neutral or negative).",3.2 Method Analysis,[0],[0]
"However, in Table 1, the data size of a
650
 
basic emotion is often smaller than the one of a complex emotion.",3.2 Method Analysis,[0],[0]
This indicates that difference in performance is likely linked to differences in the emotional contents of labels rather than differences in data sizes.,3.2 Method Analysis,[0],[0]
"E.g. the complex emotion ‘negative’ (i.e. a collection of complex emotions with negativity, such as ‘hate’, ‘anxious’, and so on) is more diverse than the basic emotion ‘sad’, and this diversity in emotional contents brings more challenges to the detection of this complex emotion.",3.2 Method Analysis,[0],[0]
"Furthermore, even if both ‘sad’ and ‘angry’ are basic emotions and have similar data sizes in our experimental data, it seems much easier to detect ‘sad’ instances than to detect ‘angry’ instances.",3.2 Method Analysis,[0],[0]
This is maybe because ‘angry’ is caused by more various events and it is more difficult to capture and utilize those cause events.,3.2 Method Analysis,[0],[0]
"Thus, it is necessary for the emotion classification to have an encoder which can extract the eventbased information of emotion cause from texts.",3.2 Method Analysis,[0],[0]
"Encoder Sequence Prec Rec F1 ConvMSMemnet CauseCL 34.3 77.5 47.5
ATT all 55.4 60.9 58.0 LSTM all 55.6 61.3 58.3 JMECause all 53.1 66.7 59.1
Table 4: The performances of emotion cause detection models.",3.2 Method Analysis,[0],[0]
"(all: EmoKW, CauseCL plus Context)
Table 4 shows the performances of different emotion cause detection models, where “Sequence” lists the sequences of input words used by each model.",3.2 Method Analysis,[0],[0]
"In Table 4, JMECause outperforms the best pipeline model (LSTM) by 0.8% in F-scores.",3.2 Method Analysis,[0],[0]
"The LSTM encoder is a stateof-the-art approach used for emotion cause detection (Cheng et al., 2017).",3.2 Method Analysis,[0],[0]
"Furthermore, the performance improvement of JMECause is from the significant increasing in recalls (5.4%).",3.2 Method Analysis,[0],[0]
This indicates that more emotion causes are correctly detected when the event-based features extracted by Model JMEClass are incorporated.,3.2 Method Analysis,[0],[0]
"Moreover, among all models, the two models (ATT and LSTM) achieve relatively high precision and relatively low recall, and ConvMS-Memnet obtains the lowest precision and highest recall.",3.2 Method Analysis,[0],[0]
"This means that both ATT and LSTM suffer from the feature coverage problem because some useful features cannot be extracted through their encoders, and ConvMS-Memn suffers from the feature
quality problem maybe because its encoder cannot handle the informal writing style used in Chinese microblogs.",3.2 Method Analysis,[0],[0]
"In recent years, intensive studies have explored supervised machine learning approaches using various types of features for different-level emotion classification, such as document level (Alm et al. 2005; Li et al. 2014; Huang et al. 2016), sentence level or short text level (Tokushisa et al. 2008; Bhowmick et al. 2009; Xu et al. 2012; Wen and Wan, 2014; Li et al. 2015; Felbo et al., 2017), and so on.",4 Related Work,[0],[0]
"Moreover, since both emotion and sentiment belong to affective feeling, some studies have explored the join learning of sentiment classification and emotion classification (Gao et al., 2013; Wang et al., 2015).
",4 Related Work,[0],[0]
"In the other hand, most of previous emotion cause detection studies is clause-based, which examine whether a clause around a given emotion keyword is a cause or not.",4 Related Work,[0],[0]
"Moreover, these studies (Chen et al., 2010; Xu et al., 2017; Ghazi et al., 2015; Gui et al., 2017; Cheng et al., 2017) focus on how to extract two kinds of features for supervised model learning: explicit expression patterns (e.g. “to cause”, “for”), and implicit features which can reflect the causal relation.",4 Related Work,[0],[0]
"In this paper, we focus on a joint learning approach to emotion classification and emotion cause detection on Chinese microblogs, and the experiments show such a joint approach is very promising.",5 Conclusion,[0],[0]
This research work was partially supported by four the National Science Foundation of China (No. 61503386).,Acknowledgments,[0],[0]
"We present a neural network-based joint approach for emotion classification and emotion cause detection, which attempts to capture mutual benefits across the two sub-tasks of emotion analysis.",abstractText,[0],[0]
"Considering that emotion classification and emotion cause detection need different kinds of features (affective and event-based separately), we propose a joint encoder which uses a unified framework to extract features for both sub-tasks and a joint model trainer which simultaneously learns two models for the two sub-tasks separately.",abstractText,[0],[0]
Our experiments on Chinese microblogs show that the joint approach is very promising.,abstractText,[0],[0]
Joint Learning for Emotion Classification and Emotion Cause Detection,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 90–101 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1009",text,[0],[0]
Within-document event coreference resolution is the task of determining which event mentions in a text refer to the same real-world event.,1 Introduction,[0],[0]
"Compared to entity coreference resolution, event coreference resolution is not only much less studied, but it is arguably more challenging.",1 Introduction,[0],[0]
"The challenge stems in part from the fact that an event coreference resolver typically lies towards the end of the standard information extraction pipeline, assuming as input the noisy outputs of its upstream components.",1 Introduction,[0],[0]
"One such component is the trigger detection system, which is responsible for identifying event triggers and determining their event subtypes.
",1 Introduction,[0],[0]
"As is commonly known, trigger detection is another challenging task that is far from being
solved.",1 Introduction,[0],[0]
"In fact, in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, trigger detection (a.k.a. event nugget detection in KBP) is deliberately made more challenging by focusing only on detecting the 18 subtypes of triggers on which the KBP 2015 participating systems’ performances were the poorest (Mitamura et al., 2016).",1 Introduction,[0],[0]
"The best-performing KBP 2016 system on English trigger detection achieved only an F-score of 47 (Lu and Ng, 2016).1
Given the difficulty of trigger detection, it is conceivable that many errors will propagate from the trigger detection component to the event coreference component in any pipeline architecture where trigger detection precedes event coreference resolution.",1 Introduction,[0],[0]
These trigger detection errors could severely harm event coreference performance.,1 Introduction,[0],[0]
"For instance, two event mentions could be wrongly posited as coreferent if the underlying triggers were wrongly predicted to have the same subtype.",1 Introduction,[0],[0]
"Nevertheless, the top-performing systems in the KBP 2016 event coreference task all adopted the aforementioned pipeline architecture (Liu et al., 2016; Lu and Ng, 2016; Nguyen et al., 2016).",1 Introduction,[0],[0]
"Their performances are not particularly impressive, however: the best English event coreference F-score (averaged over four scoring metrics) is only around 30%.
",1 Introduction,[0],[0]
"To address this error propagation problem, we describe a joint model of trigger detection, event coreference, and event anaphoricity in this paper.",1 Introduction,[0],[0]
Our choice of these three tasks is motivated in part by their inter-dependencies.,1 Introduction,[0],[0]
"As mentioned above, it is well-known that trigger detection performance has a huge impact on event coreference performance.",1 Introduction,[0],[0]
"Though largely underinvestigated, event coreference could also improve
1This is the best English nugget type result in KBP 2016.",1 Introduction,[0],[0]
"In this paper, we will not be concerned with realis classification, as it does not play any role in event coreference.
90
trigger detection.",1 Introduction,[0],[0]
"For instance, if two event mentions are posited as coreferent, then the underlying triggers must have the same event subtype.",1 Introduction,[0],[0]
"While the use of anaphoricity information for entity coreference has been extensively studied (see Ng (2010)), to our knowledge there has thus far been no attempt to explicitly model event anaphoricity for event coreference.2",1 Introduction,[0],[0]
"Although the mention-ranking model we employ for event coreference also allows an event mention to be posited as non-anaphoric (by resolving it to a null candidate antecedent), our decision to train a separate anaphoricity model and integrate it into our joint model is motivated in part by the recent successes of Wiseman et al. (2015), who showed that there are benefits in jointly training a noun phrase anaphoricity model and a mention-ranking model for entity coreference resolution.",1 Introduction,[0],[0]
"Finally, event anaphoricity and trigger detection can also mutually benefit each other.",1 Introduction,[0],[0]
"For instance, any verb posited as a non-trigger cannot be anaphoric, and any verb posited as anaphoric must be a trigger.",1 Introduction,[0],[0]
"Note that in our joint model, anaphoricity serves as an auxiliary task: its intended use is to improve trigger detection and event coreference, potentially mediating the interaction between trigger detection and event coreference.
",1 Introduction,[0],[0]
"Being a structured conditional random field, our model encompasses two types of factors.",1 Introduction,[0],[0]
Unary factors encode the features specific for each task.,1 Introduction,[0],[0]
"Binary and ternary factors capture the interaction between each pair of tasks in a soft manner, enabling the learner to learn which combinations of values of the output variables are more probable.",1 Introduction,[0],[0]
"For instance, the learner should learn that it is not a good idea to classify a verb both as anaphoric and as a non-trigger.",1 Introduction,[0],[0]
"Our model is similar in spirit to Durrett and Klein’s (2014) joint model for entity analysis, which performs joint learning for entity coreference, entity linking and semantic typing via the use of interaction features.
",1 Introduction,[0],[0]
Our contributions are two-fold.,1 Introduction,[0],[0]
"First, we present a joint model of event coreference, trigger detection, and anaphoricity that is novel in terms of the choice of tasks and the features used to capture cross-task interactions.",1 Introduction,[0],[0]
"Second, our model achieves the best results to date on the KBP 2016 English and Chinese event coreference tasks.
",1 Introduction,[0],[0]
"2Following the entity coreference literature, we overload the term anaphoricity, saying that an event mention is anaphoric if it is coreferent with a preceding mention in the associated text.",1 Introduction,[0],[0]
"We employ the following definitions in our discussion of trigger detection and event coreference:
•",2.1 Definitions,[0],[0]
"An event mention is an explicit occurrence of an event consisting of a textual trigger, arguments or participants (if any), and the event type/subtype.",2.1 Definitions,[0],[0]
•,2.1 Definitions,[0],[0]
"An event trigger is a string of text that most clearly expresses the occurrence of an event, usually a word or a multi-word phrase • An event argument is an argument filler that plays a certain role in an event.",2.1 Definitions,[0],[0]
•,2.1 Definitions,[0],[0]
An event coreference chain (a.k.a. an event hopper) is a group of event mentions that refer to the same real-world event.,2.1 Definitions,[0],[0]
"They must have the same event (sub)type.
",2.1 Definitions,[0],[0]
"To understand these definitions, consider the example in Table 1, which contains two coreferent event mentions, ev1 and ev2.",2.1 Definitions,[0],[0]
left is the trigger for ev1 and departed is the trigger for ev2.,2.1 Definitions,[0],[0]
Both triggers have subtype Movement.,2.1 Definitions,[0],[0]
TransportPerson.,2.1 Definitions,[0],[0]
"ev1 has three arguments, Georges Cipriani, prison, and Wednesday with roles Person, Origin, and Time respectively.",2.1 Definitions,[0],[0]
"ev2 also has three arguments, He, Ensisheim, and police vehicle with roles Person, Origin, and Instrument respectively.",2.1 Definitions,[0],[0]
The version of the event coreference task we focus on in this paper is the Event Nugget Detection and Coreference task in the TAC KBP 2016 Event Track.,2.2 Task,[0],[0]
"While we discuss the role played by event arguments in event coreference in the previous subsection, KBP 2016 addresses event argument detection as a separate shared task.",2.2 Task,[0],[0]
"In other words, the KBP 2016 Event Nugget Detection and Coreference task focuses solely on trigger detection and event coreference.
",2.2 Task,[0],[0]
"It is worth mentioning that the KBP Event Nugget Detection and Coreference task, which started in 2015, aims to address a major weakness of the ACE 2005 event coreference task.",2.2 Task,[0],[0]
"Specifically, ACE 2005 adopts a strict notion of event identity, with which two event mentions were annotated as coreferent if and only if “they had the same agent(s), patient(s), time, and location” (Song et al., 2015), and their event attributes (polarity, modality, genericity, and tense) were not incompatible.",2.2 Task,[0],[0]
"In contrast, KBP adopts a more relaxed definition of event coreference, allowing two
Georges Cipriani[Person], {left}ev1 the prison[Origin] in Ensisheim in northern France on parole on Wednesday[Time].
event mentions to be coreferent as long as they intuitively refer to the same real-world event.",2.2 Task,[0],[0]
"Under this definition, two event mentions can be coreferent even if their time and location arguments are not coreferent.",2.2 Task,[0],[0]
"In our example in Table 1, ev1 and ev2 are coreferent in KBP because they both refer to the same event of Cipriani leaving the prison.",2.2 Task,[0],[0]
"However, they are not coreferent in ACE because their Origin arguments are not coreferent (one Origin argument involves a prison in Ensisheim while the other involves the city Ensisheim).",2.2 Task,[0],[0]
"Given our focus on the KBP 2016 Event Nugget Detection and Coreference task, we employ the English and Chinese corpora used in this task for evaluation, referring to these corpora as the KBP 2016 English and Chinese corpora for brevity.",2.3 Corpora,[0],[0]
There are no official training sets: the task organizers simply made available a number of event coreference-annotated corpora for training.,2.3 Corpora,[0],[0]
"For English, we use LDC2015E29, E68, E73, and E94 for training.",2.3 Corpora,[0],[0]
"These corpora are composed of two types of documents, newswire documents and discussion forum documents.",2.3 Corpora,[0],[0]
Together they contain 648 documents with 18739 event mentions distributed over 9955 event coreference chains.,2.3 Corpora,[0],[0]
"For Chinese, we use LDC2015E78, E105, and E112 for training.",2.3 Corpora,[0],[0]
These corpora are composed of discussion forum documents only.,2.3 Corpora,[0],[0]
"Together they contain 383 documents with 4870 event mentions distributed over 3614 event coreference chains.
",2.3 Corpora,[0],[0]
The test set for English consists of 169 newswire and discussion forum documents with 4155 event mentions distributed over 3191 event coreference chains.,2.3 Corpora,[0],[0]
The test set for Chinese consists of 167 newswire and discussion forum documents with 2518 event mentions distributed over 1912 event coreference chains.,2.3 Corpora,[0],[0]
"Note that these test sets contain only annotations for event triggers and event coreference (i.e., there are no event argument annotations).",2.3 Corpora,[0],[0]
"While some of the training sets additionally contain event argument annotations, we do not make use of event argument annotations in model training to ensure a fairer comparison to the teams participating in the KBP 2016 Event Nugget Detection and Coreference task.",2.3 Corpora,[0],[0]
"Our model, which is a structured conditional random field, operates at the document level.",3.1 Overview,[0],[0]
"Specifically, given a test document, we first extract from it (1) all single-word nouns and verbs and (2) all words and phrases that have appeared at least once as a trigger in the training data.",3.1 Overview,[0],[0]
We treat each of these extracted words and phrases as a candidate event mention.3 The goal of the model is to make joint predictions for the candidate event mentions in a document.,3.1 Overview,[0],[0]
"Three predictions will be made for each candidate event mention that correspond to the three tasks in the model: its trigger subtype, its anaphoricity, and its antecedent.
",3.1 Overview,[0],[0]
"Given this formulation, we define three types of output variables:
• Event subtype variables t = (t1, . . .",3.1 Overview,[0],[0]
", tn).",3.1 Overview,[0],[0]
"Each ti takes a value in the set of 18 event subtypes defined in KBP 2016 or NONE, which indicates that the event mention is not a trigger.
",3.1 Overview,[0],[0]
"• Anaphoricity variables a = (a1, . . .",3.1 Overview,[0],[0]
", an).",3.1 Overview,[0],[0]
"Each ai is either ANAPHORIC or NOT ANAPHORIC.
",3.1 Overview,[0],[0]
"• Coreference variables c = (c1, . . .",3.1 Overview,[0],[0]
", cn), where ci ∈ {1, . . .",3.1 Overview,[0],[0]
", i − 1, NEW}.",3.1 Overview,[0],[0]
"In other words, the value of each ci is the id of its antecedent, which can be one of the preceding event mentions or NEW (if the event mention underlying ci starts a new cluster).
",3.1 Overview,[0],[0]
"Each candidate event mention is associated with exactly one coreference variable, one event subtype variable, and one anaphoricity variable.",3.1 Overview,[0],[0]
"Our model induces the following log-linear probability distribution over these variables:
p(t,a, c|x; Θ) ∝ exp( ∑
i
θifi(t,a, c,x))
3According to the KBP annotation guidelines, each word may trigger multiple event mentions (e.g., murder can trigger two event mentions with subtypes Life.",3.1 Overview,[0],[0]
Die and Conflict.,3.1 Overview,[0],[0]
Attack).,3.1 Overview,[0],[0]
"Hence, our treating each extracted word as a candidate event mention effectively prevents a word from triggering multiple event mentions.",3.1 Overview,[0],[0]
"Rather than complicate model design by relaxing this simplifying assumption, we present an alternative, though partial, solution to this problem wherein we allow each event mention to be associated with multiple event subtypes.",3.1 Overview,[0],[0]
"See the Appendix for details.
where θi ∈ Θ is the weight associated with feature function fi and x is the input document.",3.1 Overview,[0],[0]
"Given that our model is a structured conditional random field, the features can be divided into two types: (1) task-specific features, and (2) crosstask features, which capture the interactions between a pair of tasks.",3.2 Features,[0],[0]
We express these two types of features in factor graph notation.,3.2 Features,[0],[0]
"The taskspecific features are encoded in unary factors, each of which is connected to the corresponding variable (Figure 1).",3.2 Features,[0],[0]
"The cross-task features are encoded in binary or ternary factors, each of which couples the output variables from two tasks (Figure 2).",3.2 Features,[0],[0]
"Next, we describe these two types of features.",3.2 Features,[0],[0]
Each feature is used to train models for both English and Chinese unless otherwise stated.,3.2 Features,[0],[0]
"We begin by describing the task-specific features, which are encoded in unary factors, as well as each of the three independent models.",3.2.1 Task-Specific Features,[0],[0]
"When applied in isolation, our trigger detection model returns a distribution over possible subtypes given a candidate trigger.",3.2.1.1 Trigger Detection,[0],[0]
"Each candidate trigger t is represented using t’s word, t’s lemma, word bigrams formed with a window size of three from t, as well as feature conjunctions created by pairing t’s lemma with each of the following features:
the head word of the entity syntactically closest to t, the head word of the entity textually closest to t, the entity type of the entity that is syntactically closest to t, and the entity type of the entity that is textually closest to t.4",3.2.1.1 Trigger Detection,[0],[0]
"In addition, for event mentions with verb triggers, we use the head words and the entity types of their subjects and objects as features, where the subjects and objects are extracted from the dependency parse trees obtained using Stanford CoreNLP (Manning et al., 2014).",3.2.1.1 Trigger Detection,[0],[0]
"For event mentions with noun triggers, we create the same features that we did for verb triggers, except that we replace the subjects and verbs with heuristically extracted agents and patients.",3.2.1.1 Trigger Detection,[0],[0]
"Finally, for the Chinese trigger detector, we additionally create two features from each character in t, one encoding the character itself and the other encoding the entry number of the corresponding character in a Chinese synonym dictionary.5",3.2.1.1 Trigger Detection,[0],[0]
We employ a mention-ranking model for event coreference that selects the most probable antecedent for a mention to be resolved (or NEW if the mention is non-anaphoric) from its set of candidate antecedents.,3.2.1.2 Event Coreference,[0],[0]
"When applied in isolation, the model is trained to maximize the condi-
4We train a CRF-based entity extraction model for jointly identifying the entity mentions and their types.",3.2.1.2 Event Coreference,[0],[0]
"Details can be found in Lu et al. (2016).
",3.2.1.2 Event Coreference,[0],[0]
"5The dictionary is available from http://ir.hit.edu.cn/. An entry number in this dictionary conceptually resembles a synset id in WordNet (Fellbaum, 1998).
",3.2.1.2 Event Coreference,[0],[0]
"tional likelihood of collectively resolving the mentions to their correct antecedents in the training texts (Durrett and Klein, 2013).",3.2.1.2 Event Coreference,[0],[0]
"Below we describe the features used to represent the candidate antecedents for the mention to be resolved, mj .",3.2.1.2 Event Coreference,[0],[0]
Features representing the NULL candidate antecedent:,3.2.1.2 Event Coreference,[0],[0]
"Besides mj’s word and mj’s lemma, we employ feature conjunctions given their usefulness in entity coreference (Fernandes et al., 2014).",3.2.1.2 Event Coreference,[0],[0]
"Specifically, we create a conjunction between mj’s lemma and the number of sentences preceding mj , as well as a conjunction between mj’s lemma and the number of mentions preceding mj in the document.",3.2.1.2 Event Coreference,[0],[0]
"Features representing a non-NULL candidate antecedent, mi: mi’s word, mi’s lemma, whether mi and mj have the same lemma, and feature conjunctions including: (1) mi’s word paired with mj’s word, (2) mi’s lemma paired with mj’s lemma, (3) the sentence distance between mi and mj paired with mi’s lemma and mj’s lemma, (4) the mention distance between mi and mj paired with mi’s lemma and mj’s lemma, (5) a quadruple consisting of mi and mj’s subjects and their lemmas, and (6) a quadruple consisting of mi and mj’s objects and their lemmas.",3.2.1.2 Event Coreference,[0],[0]
"When used in isolation, the anaphoricity model returns the probability that the given event mention is anaphoric.",3.2.1.3 Anaphoricity Determination,[0],[0]
"To train the model, we represent each event mention mj using the following features: (1) the head word of each candidate antecedent paired with mj’s word, (2) whether at least one candidate antecedent has the same lemma as that of mj , and (3) the probability that mj is anaphoric in the training data (if mj never appears in the training data, this probability is set to 0.5).",3.2.1.3 Anaphoricity Determination,[0],[0]
Cross-task interaction features are associated with the binary and ternary factors.,3.2.2 Cross-Task Interaction Features,[0],[0]
"We fire features that conjoin each candidate event mention’s event subtype, the lemma of its trigger and its anaphoricity.",3.2.2.1 Trigger Detection and Anaphoricity,[0],[0]
"We define our joint coreference and trigger detection factors such that the features defined on subtype variables ti and tj are fired only if current mention mj is coreferent with preceding mention
mi.",3.2.2.2 Trigger Detection and Coreference,[0],[0]
"These features are: (1) the pair of mi and mj’s subtypes, (2) the pair of mj’s subtype and mi’s word, and (3) the pair of mi’s subtype and mj’s word.",3.2.2.2 Trigger Detection and Coreference,[0],[0]
We fire a feature that conjoins event mention mj’s anaphoricity and whether or not a non-NULL antecedent is selected for mj .,3.2.2.3 Coreference and Anaphoricity,[0],[0]
"We learn the model parameters Θ from a set of d training documents, where document i contains content xi, gold triggers t∗i and gold event coreference partition C∗i .",3.3 Training,[0],[0]
"Before learning, there are a couple of issues we need to address.
",3.3 Training,[0],[0]
"First, we need to derive gold anaphoricity labels a∗i from C ∗",3.3 Training,[0],[0]
i .,3.3 Training,[0],[0]
"This is straightforward: the first mention of each coreference chain is NOT ANAPHORIC, whereas the rest are ANAPHORIC.
",3.3 Training,[0],[0]
"Second, we employ gold event mentions for model training, but training models only on gold mentions is not sufficient: for instance, a trigger detector trained solely on gold mentions will not be able to classify a candidate event mention as NONE during testing.",3.3 Training,[0],[0]
"To address this issue, we additionally train the models on candidate event mentions corresponding to non-triggers.",3.3 Training,[0],[0]
We create these candidate event mentions as follows.,3.3 Training,[0],[0]
"For each word w that appears as a true trigger at least once in the training data, we create a candidate event mention from each occurrence of w in the training data that is not annotated as a true trigger.
",3.3 Training,[0],[0]
"Third, since our model produces event coreference output in the form of an antecedent vector (with one antecedent per event mention), it needs to be trained on antecedent vectors.",3.3 Training,[0],[0]
"However, since the coreference annotation for each document i is provided in the form of a clustering C∗i , we follow previous work on entity coreference resolution (Durrett and Klein, 2013): we sum over all antecedent structures A(C∗i ) that are consistent with C∗i (i.e., the first mention of a cluster has antecedent NEW, whereas each of the subsequent mentions can select any of the preceding mentions in the same cluster as its antecedent).
",3.3 Training,[0],[0]
"Next, we learn the model parameters to maximize the following conditional likelihood of the training data with L1 regularization:
L(Θ) =
d∑
i=1
log ∑
c∗∈A(C∗i )",3.3 Training,[0],[0]
"p′(t∗i ,a ∗",3.3 Training,[0],[0]
"i , c ∗|xi; Θ)+λ‖Θ‖1
In this objective, p′ is obtained by augmenting the distribution p (defined in Section 3.1) with task-specific parameterized loss functions:
p′(t,a, c|xi; Θ) ∝",3.3 Training,[0],[0]
"p(t,a, c|xi; Θ) exp[αtlt(t, t∗) +",3.3 Training,[0],[0]
"αala(a,a ∗)",3.3 Training,[0],[0]
"+ αclc(c, C∗)]
where lt, la and lc are task-specific loss functions, and αt, αa and αc are the associated weight parameters that specify the relative importance of the three tasks in the objective function.
",3.3 Training,[0],[0]
"Softmax-margin, the technique of integrating task-specific loss functions into the objective function, was introduced by Gimpel and Smith (2010) and subsequently used by Durrett and Klein (2013, 2014).",3.3 Training,[0],[0]
"By encoding task-specific knowledge, these loss functions can help train a model that places less probability mass on less desirable output configurations.
",3.3 Training,[0],[0]
"Our loss function for event coreference, lc, is motivated by the one Durrett and Klein (2013) developed for entity coreference.",3.3 Training,[0],[0]
"It is a weighted sum of the counts of three error types:
lc(c, C ∗) = αc,FAFA(c, C∗)+αc,FNFN(c, C∗)
+ αc,WLWL(c, C ∗)
where FA(c, C∗) is the number of non-anaphoric mentions misclassified as anaphoric, FN(c, C∗) is the number of anaphoric mentions misclassified as non-anaphoric, and WL(c, C∗) is the number of incorrectly resolved anaphoric mentions.
",3.3 Training,[0],[0]
"Our loss function for trigger detection, lt, is parameterized in a similar way, having three parameters associated with three error types:",3.3 Training,[0],[0]
"αt,FT is associated with the number of non-triggers misclassified as triggers, αt,FN is associated with the number of triggers misclassified as non-triggers, and αt,WL is associated with the number of triggers labeled with the wrong subtype.
",3.3 Training,[0],[0]
"Finally, our loss function for anaphoricity determination, la, is also similarly parameterized, having two parameters: αa,FA and αa,FN are associated with the number of false anaphors and the number of false non-anaphors, respectively.
",3.3 Training,[0],[0]
"Following Durrett and Klein (2014), we use AdaGrad (Duchi et al., 2011) to optimize our objective with λ = 0.001 in our experiments.",3.3 Training,[0],[0]
"Inference, which is performed during training and decoding, involves computing the marginals for a
variable or a set of variables to which a factor connects.",3.4 Inference,[0],[0]
"For efficiency, we perform approximate inference using belief propagation rather than exact inference.",3.4 Inference,[0],[0]
"Given that convergence can typically be reached within five iterations of belief propagation, we employ five iterations in all experiments.
",3.4 Inference,[0],[0]
"Performing inference using belief propagation on the full factor graph defined in Section 3.1 can still be computationally expensive, however.",3.4 Inference,[0],[0]
One reason is that the number of ternary factors grows quadratically with the number of event mentions in a document.,3.4 Inference,[0],[0]
"To improve scalability, we restrict the domains of the coreference variables.",3.4 Inference,[0],[0]
"Rather than allow the domain of coreference variable cj to be of size j, we allow a preceding mention mi to be a candidate antecedent of mention mj if (1) the sentence distance between the two mentions is less than an empirically determined threshold and (2) either they are coreferent at least once in the training data or their head words have the same lemma.",3.4 Inference,[0],[0]
Doing so effectively enables us to prune the unlikely candidate antecedents for each event mention.,3.4 Inference,[0],[0]
"As Durrett and Klein (2014) point out, such pruning has the additional benefit of reducing “the memory footprint and time needed to build a factor graph”, as we do not need to create any factor between mi and mj and its associated features if mi is pruned.",3.4 Inference,[0],[0]
"To further reduce the memory footprint, we additionally restrict the domains of the event subtype variables.",3.4 Inference,[0],[0]
"Given a candidate event mention created from word w, we allow the domain of its subtype variable to include only NONE as well as those subtypes that w is labeled with at least once in the training data.
",3.4 Inference,[0],[0]
"For decoding, we employ minimum Bayes risk, which computes the marginals of each variable w.r.t.",3.4 Inference,[0],[0]
the joint model and derives the most probable assignment to each variable.,3.4 Inference,[0],[0]
We perform training and evaluation on the KBP 2016 English and Chinese corpora.,4.1 Experimental Setup,[0],[0]
"For English, we train models on 509 of the training documents, tune parameters on 139 training documents, and report results on the official KBP 2016 English test set.6 For Chinese, we train models on 302 of the training documents, tune parameters on 81 training documents, and report results on the official
6The parameters to be tuned are the α’s multiplying the loss functions and those inside the loss functions.
",4.1 Experimental Setup,[0],[0]
KBP 2016 Chinese test set.,4.1 Experimental Setup,[0],[0]
Results of event coreference and trigger detection are obtained using version 1.7.2 of the official scorer provided by the KBP 2016 organizers.,4.1 Experimental Setup,[0],[0]
"To evaluate event coreference performance, the scorer employs four scoring measures, namely MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAFe (Luo, 2005) and BLANC (Recasens and Hovy, 2011), as well as the unweighted average of their F-scores (AVG-F).",4.1 Experimental Setup,[0],[0]
"The scorer reports event mention detection performance in terms of F-score, considering a mention correctly detected if it has an exact match with a gold mention in terms of boundary, event type, and event subtype.",4.1 Experimental Setup,[0],[0]
"In addition, we report anaphoricity determination performance in terms of the F-score computed over anaphoric mentions, counting an extracted anaphoric mention as a true positive if it has an exact match with a gold anaphoric mention in terms of boundary.",4.1 Experimental Setup,[0],[0]
"Results are shown in Table 2 where performance on all three tasks (event coreference, trigger detection, and anaphoricity determination) is expressed in terms of F-score.",4.2 Results and Discussion,[0],[0]
The top half of the table shows the results on the English evaluation set.,4.2 Results and Discussion,[0],[0]
"Specifically, row 1 shows the performance of the best event coreference system participating in KBP 2016 (Lu and Ng, 2016).",4.2 Results and Discussion,[0],[0]
This system adopts a pipeline architecture.,4.2 Results and Discussion,[0],[0]
It first uses an ensemble of one-nearest-neighbor classifiers for trigger detection.,4.2 Results and Discussion,[0],[0]
"Using the extracted triggers, it then applies a pipeline of three sieves, each of which is a one-
nearest-neighbor classifier, for event coreference.",4.2 Results and Discussion,[0],[0]
"As we can see, this system achieves an AVG-F of 30.08 for event coreference and an F-score of 46.99 for trigger detection.
",4.2 Results and Discussion,[0],[0]
"Row 2 shows the performance of the independent models, each of which is trained independently of the other models.",4.2 Results and Discussion,[0],[0]
"Specifically, each independent model is trained using only the unary factors associated with it.",4.2 Results and Discussion,[0],[0]
"As we can see, the independent models outperform the top KBP 2016 system by 1.2 points in AVG-F for event coreference and 1.83 points for trigger detection.
",4.2 Results and Discussion,[0],[0]
Results of our joint model are shown in row 3.,4.2 Results and Discussion,[0],[0]
The absolute performance differences between the joint model and the independent models are shown in row 4.,4.2 Results and Discussion,[0],[0]
"As we can see, the joint model outperforms the independent models for all three tasks: by 1.80 points for event coreference, 0.48 points for trigger detection and 4.59 points for anaphoricity determination.",4.2 Results and Discussion,[0],[0]
"Most encouragingly, the joint model outperforms the top KBP 2016 system for both event coreference and trigger detection.",4.2 Results and Discussion,[0],[0]
"For event coreference, it outperforms the top KBP system w.r.t.",4.2 Results and Discussion,[0],[0]
"all scoring metrics, yielding an improvement of 3 points in AVG-F. For trigger detection, it outperforms the top KBP system by 2.31 points.
",4.2 Results and Discussion,[0],[0]
The bottom half of Table 2 shows the results on the Chinese evaluation set.,4.2 Results and Discussion,[0],[0]
The top KBP 2016 event coreference system on Chinese is also the Lu and Ng (2016) system.,4.2 Results and Discussion,[0],[0]
"While the top KBP system outperforms the independent models for both tasks (by 0.59 points in AVG-F for event coreference and 0.19 points for trigger detection), our joint model outperforms the independent models
for all three tasks: by 1.95 points for event coreference, 4.02 points for anaphoricity determination, and 0.71 points for trigger detection.",4.2 Results and Discussion,[0],[0]
"Like its English counterpart, our Chinese joint model outperforms the top KBP system for both event coreference and trigger detection.",4.2 Results and Discussion,[0],[0]
"For event coreference, it outperforms the top KBP system w.r.t.",4.2 Results and Discussion,[0],[0]
"all but the CEAFe metric, yielding an absolute improvement of 1.36 points in AVG-F. For trigger detection, it outperforms the top KBP system by 0.52 points.
",4.2 Results and Discussion,[0],[0]
"For both datasets, the joint model’s superior performance to the independent coreference model stems primarily from considerable improvements in MUC F-score.",4.2 Results and Discussion,[0],[0]
"As MUC is a link-based measure, these results provide suggestive evidence that joint modeling has enabled more event coreference links to be discovered.",4.2 Results and Discussion,[0],[0]
"To evaluate the importance of each of the three types of joint factors in the joint model, we perform ablation experiments.7 Table 3 shows the results on the English and Chinese datasets when we add each type of joint factors to the independent model and remove each type of joint factors from the full joint model.",4.3 Model Ablations,[0],[0]
"The results of each task are expressed in terms of changes to the corresponding independent model’s F-score.
",4.3 Model Ablations,[0],[0]
7Chen and Ng (2013) also performed ablation on their ACE-style Chinese event coreference resolver.,4.3 Model Ablations,[0],[0]
"However, given the differences in the tasks involved (e.g., they did not model event anaphoricity, but included tasks such as event argument extraction and role classification, entity coreference, and event mention attribute value computation) and the ablation setup (e.g., they ablated individual tasks/components in their pipeline-based system in an incremental fashion, whereas we ablate interaction factors rather than tasks), a direct comparison of their observations and ours is difficult.
",4.3 Model Ablations,[0],[0]
Coref-Trigger interactions.,4.3 Model Ablations,[0],[0]
"Among the three types of factors, this one contributes the most to coreference performance, regardless of whether it is applied in isolation or in combination with the other two types of factors to the independent coreference model.",4.3 Model Ablations,[0],[0]
"In addition, it is the most effective type of factor for improving trigger detection.",4.3 Model Ablations,[0],[0]
"When applied in combination, it also improves anaphoricity determination, although less effectively than the other two types of factors.
",4.3 Model Ablations,[0],[0]
Coref-Anaphoricity interactions.,4.3 Model Ablations,[0],[0]
"When applied in isolation to the independent models, this type of factor improves coreference resolution but has a mixed impact on anaphoricity determination.",4.3 Model Ablations,[0],[0]
"When applied in combination with other types of factors, it improves both tasks, particularly anaphoricity determination.",4.3 Model Ablations,[0],[0]
"Its impact on trigger detection, however, is generally negative.
",4.3 Model Ablations,[0],[0]
Trigger-Anaphoricity interactions.,4.3 Model Ablations,[0],[0]
"When applied in isolation to the independent models, this type of factor improves both trigger detection and anaphoricity determination.",4.3 Model Ablations,[0],[0]
"When applied in combination with other types of factors, it still improves anaphoricity determination (particularly on Chinese), but has a mixed effect on trigger detection.",4.3 Model Ablations,[0],[0]
"Among the three types of factors, it has the least impact on coreference resolution.",4.3 Model Ablations,[0],[0]
"Next, we conduct an analysis of the major sources of error made by our joint coreference model.",4.4 Error Analysis,[0],[0]
Erroneous and mistyped triggers.,4.4.1 Two Major Types of Precision Error,[0],[0]
Our trigger model tends to assign the same subtype to event mentions triggered by the same word.,4.4.1 Two Major Types of Precision Error,[0],[0]
"As a result, it often assigns the wrong subtype to triggers that
possess different subtypes in different contexts.",4.4.1 Two Major Types of Precision Error,[0],[0]
"For the same reason, words that are only sometimes used as triggers are often wrongly posited as triggers when they are not.",4.4.1 Two Major Types of Precision Error,[0],[0]
"These two types of triggers have in turn led to the establishment of incorrect coreference links.8
Failure to extract arguments.",4.4.1 Two Major Types of Precision Error,[0],[0]
"In the absence of an annotated corpus for training an argument classifier, we exploit dependency relations for argument extraction.",4.4.1 Two Major Types of Precision Error,[0],[0]
"Doing so proves inadequate, particularly for noun triggers, owing to the absence of dependency relations that can be used to reliably extract their arguments.",4.4.1 Two Major Types of Precision Error,[0],[0]
"Moreover, using dependency relations does not allow the extraction of arguments that do not appear in the same sentence as their trigger.",4.4.1 Two Major Types of Precision Error,[0],[0]
"Since the presence of incompatible arguments is an important indicator of noncoreference, our model’s failure to extract arguments has resulted in incorrect coreference links.",4.4.1 Two Major Types of Precision Error,[0],[0]
Missing triggers.,4.4.2 Three Major Types of Recall Error,[0],[0]
Our trigger model fails to identify trigger words that are unseen or rarelyoccurring in the training data.,4.4.2 Three Major Types of Recall Error,[0],[0]
"As a result, many coreference links cannot be established.",4.4.2 Three Major Types of Recall Error,[0],[0]
Lack of entity coreference information.,4.4.2 Three Major Types of Recall Error,[0],[0]
Entity coreference information is useful for event coreference because the corresponding arguments of two event mentions are typically coreferent.,4.4.2 Three Major Types of Recall Error,[0],[0]
"Since our model does not exploit entity coreference information, it treats two lexically different event arguments as non-coreferent/unrelated.",4.4.2 Three Major Types of Recall Error,[0],[0]
This in turn weakens its ability to determine whether two event mentions are coreferent.,4.4.2 Three Major Types of Recall Error,[0],[0]
"This issue is particularly serious in discussion forum documents, where it is not uncommon to see pronouns serve as subjects and objects of event mentions.",4.4.2 Three Major Types of Recall Error,[0],[0]
"The situation is further aggravated in Chinese documents, where zero pronouns are prevalent.",4.4.2 Three Major Types of Recall Error,[0],[0]
Lack of contextual understanding.,4.4.2 Three Major Types of Recall Error,[0],[0]
Our model only extracts features from the sentence in which an event mention appears.,4.4.2 Three Major Types of Recall Error,[0],[0]
"However, additional contextual information present in neighboring sentences may be needed for correct coreference resolution.",4.4.2 Three Major Types of Recall Error,[0],[0]
"This is particularly true in discussion forum documents, where the same event may be described differently by different people.",4.4.2 Three Major Types of Recall Error,[0],[0]
"For exam-
8In our joint model, mentions that are posited as coreferent are encouraged to have the same subtype.",4.4.2 Three Major Types of Recall Error,[0],[0]
"While it can potentially fix the errors involving coreferent mentions that have different subtypes, it cannot fix the errors in which the two mentions involved have the same erroneous subtype.
",4.4.2 Three Major Types of Recall Error,[0],[0]
"ple, when describing the fact that Tim Cook will attend Apple’s Istanbul store opening, one person said “Cook is expected to return to Turkey for the store opening”, and another person described this event as “Tim travels abroad YET AGAIN to be feted by the not-so-high-and-mighty”.",4.4.2 Three Major Types of Recall Error,[0],[0]
It is by no means easy to determine that return and travel trigger two coreferent mentions in these sentences.,4.4.2 Three Major Types of Recall Error,[0],[0]
"Existing event coreference resolvers have been evaluated on different corpora, such as MUC (e.g., Humphreys et al. (1997)), ACE (e.g., Ahn (2006), Chen and Ji (2009), McConky et al. (2012), Sangeetha and Arock (2012), Chen and Ng (2015, 2016), Krause et al. (2016)), OntoNotes (e.g., Chen et al. (2011)), the Intelligence Community corpus (e.g., Cybulska and Vossen (2012), Araki et al. (2014), Liu et al. (2014)), the ECB corpus (e.g., Lee et al. (2012), Bejan and Harabagiu (2014)) and its extension ECB+ (e.g., Yang et al. (2015)), and ProcessBank (e.g., Araki and Mitamura (2015)).",5 Related Work,[0],[0]
"The newest event coreference corpora are the ones used in the KBP 2015 and 2016 Event Nugget Detection and Coreference shared tasks, in which the best performers in 2015 and 2016 are RPI’s system (Hong et al., 2015) and UTD’s system (Lu and Ng, 2016), respectively.",5 Related Work,[0],[0]
The KBP 2015 corpus has recently been used to evaluate Peng et al.’s (2016) minimally supervised approach and Lu et al.’s (2016) joint inference approach to event coreference.,5 Related Work,[0],[0]
"With the rarest exceptions (e.g., Lu et al. (2016)), existing resolvers have adopted a pipeline architecture in which trigger detection is performed prior to coreference resolution.",5 Related Work,[0],[0]
"We proposed a joint model of event coreference resolution, trigger detection, and event anaphoricity determination.",6 Conclusion,[0],[0]
The model is novel in its choice of tasks and the cross-task interaction features.,6 Conclusion,[0],[0]
"When evaluated on the KBP 2016 English and Chinese corpora, our model not only outperforms the independent models but also achieves the best results to date on these corpora.",6 Conclusion,[0],[0]
We thank the three anonymous reviewers for their detailed comments.,Acknowledgments,[0],[0]
This work was supported in part by NSF Grants IIS-1219142 and IIS-1528037.,Acknowledgments,[0],[0]
"In KBP, a word can trigger multiple event mentions.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"However, since we create exactly one candidate event mention from each extracted word in each test document, our model effectively prevents a word from triggering multiple event mentions.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
This poses a problem: each word cannot be associated with more than one event subtype.,Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"This appendix describes how we (partially) address this issue that involves allowing each event mention to be associated with multiple event subtypes.
",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"To address this problem, we preprocess the gold trigger annotations in the training data as follows.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"First, for each word triggering multiple event mentions (with different event subtypes), we merge their event mentions into one event mention having the combined subtype.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"In principle, we can add each of these combined subtypes into our event subtype inventory and allow our model to make predictions using them.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"However, to avoid over-complicating the prediction task (by having a large subtype inventory), we only add the three most frequently occurring combined subtypes in the training data to the inventory.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"Merged mentions whose combined subtype is not among the most frequent three will be unmerged in order to recover the original mentions so that the model can still be trained on them.
",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"To train our joint model, however, the trigger annotations and the event coreference annotations in the training data must be consistent.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"Since we modified the trigger annotations (by merging event mentions and allowing combined subtypes), we make two modifications to the event coreference annotations to ensure consistency between the two sets of annotations.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"First, let C1 and C2 be two event coreference chains in a training document such that the set of words triggering the event mentions in C1 (with subtype t1) is the same as that triggering the event mentions in C2 (with subtype t2).",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"If each of the event mentions in C1 was merged with the corresponding event mention in C2 during the aforementioned preprocessing of the trigger annotations (because combining t1 and t2 results in one of the three most frequent combined subtypes), then we delete one of the two coreference chains, and assign the combined subtype to the remaining chain.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"Finally, we remove any remaining event mentions that were merged during the preprocessing of trigger annotations from their respective coreference chains and create a singleton cluster for each of the merged mentions.",Appendix: Handling Words that Trigger Multiple Event Mentions,[0],[0]
"While joint models have been developed for many NLP tasks, the vast majority of event coreference resolvers, including the top-performing resolvers competing in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipelinebased, where the propagation of errors from the trigger detection component to the event coreference component is a major performance limiting factor.",abstractText,[0],[0]
"To address this problem, we propose a model for jointly learning event coreference, trigger detection, and event anaphoricity.",abstractText,[0],[0]
Our joint model is novel in its choice of tasks and its features for capturing cross-task interactions.,abstractText,[0],[0]
"To our knowledge, this is the first attempt to train a mention-ranking model and employ event anaphoricity for event coreference.",abstractText,[0],[0]
Our model achieves the best results to date on the KBP 2016 English and Chinese datasets.,abstractText,[0],[0]
Joint Learning for Event Coreference Resolution,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4737–4742 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
4737",text,[0],[0]
"Targeted sentiment analysis (TSA) aims to extract targets in a text and simultaneously predict their sentiment classes (Hu and Liu, 2004; Jin et al., 2009; Li et al., 2010; Yang and Cardie, 2013).",1 Introduction,[0],[0]
"For example, given a sentence “ESPN poll says Michael Jordan is the greatest basketball athlete”, the targets are ESPN and Michael Jordan and their sentiment classes are Neutral and Positive respectively.
",1 Introduction,[0],[0]
Targeted sentiment analysis can be seen as two tasks: target extraction and sentiment classification.,1 Introduction,[0],[0]
"Some researchers have tackled two tasks separately, e.g., target extraction (Liu et al., 2013; Wang et al., 2016a; Yin et al., 2016) and sentiment classification (Tang et al., 2016; Wang et al., 2016b; Ruder et al., 2016).",1 Introduction,[0],[0]
"Recently, some researches have attempted to conduct the two tasks jointly and generally see them as sequence labeling problems, where the B/I/O labels indicate target boundaries and the Positive/Neutral/Negative labels denote sentiment classes (Klinger and Cimiano, 2013; Yang and Cardie, 2013).",1 Introduction,[0],[0]
"Mitchell et al.
(2013) explore labeling targets and their sentiment classes simultaneously by using the Conditional Random Fields (CRF) approach with traditional manual discrete features, and present three models: pipeline, joint and collapsed, according to different labeling processes of the two tasks.",1 Introduction,[0],[0]
They find that the pipeline method outperforms the joint model on tweet dataset.,1 Introduction,[0],[0]
"Further, Zhang et al. (2015) introduce word embedding representations into the CRF framework and find that it is beneficial to integrate word embeddings into handcraft features in TSA regardless of pipeline, joint or collapsed methods.
",1 Introduction,[0],[0]
"With the success of deep learning techniques, neural networks have demonstrated their capability of sequence labeling (Collobert et al., 2011; Pei et al., 2014; Chen et al., 2015).",1 Introduction,[0],[0]
"However, Zhang et al. (2015) only use word embeddings to enrich features without taking full advantages of neural networks’ potential in automatically capturing important sequence labeling features like long distance dependencies and character-level features.
",1 Introduction,[0],[0]
"To make better use of neural networks to explore appropriate character-level features and high-level semantic features for the two tasks, we design a hierarchical multi-layer bidirectional gated recurrent units networks (HMBiGRU) which uses a multi-layer Bi-GRU to automatically learn character features (e.g. capitalization, noun suffix, etc) on letter sequence and model long distance dependencies between words on the concatenation of word embedding and its character features.",1 Introduction,[0],[0]
"The learned character features can also address out-of-vocabulary word problems.
",1 Introduction,[0],[0]
"In above example, the target label and sentiment label for Michael Jordon are “B-Person, IPerson” and “B-Positive, I-Positive”, we can see that the boundary information (B, I) of target label and sentiment label is consistent.",1 Introduction,[0],[0]
"From the
view of human, we should first predict the target label and give corresponding sentiment label afterwards.",1 Introduction,[0],[0]
"Therefore, we introduce target label information into predicting sentiment label.",1 Introduction,[0],[0]
"In this way, our model can know about the target boundary information when predicting the sentiment label.",1 Introduction,[0],[0]
"Meanwhile, we also introduce transition matrix (Collobert et al., 2011) to model the dependencies between labels.
",1 Introduction,[0],[0]
"We conduct experiments on two datasets, and the performances show that our models outperform other baselines.",1 Introduction,[0],[0]
This verifies the effectiveness of neural networks in TSA.,1 Introduction,[0],[0]
"In the experiments, we find that the target label information is important for predicting sentiment label.",1 Introduction,[0],[0]
We also analyze the performance of multi-layer Bi-GRU and hierarchical architecture in learning character features and dependencies between words.,1 Introduction,[0],[0]
"We will detailedly introduce our model in this section, and our model is shown in Figure 1.",2 Model,[0],[0]
"Supposing that a sentence is composed of n words [w1, w2, ..., wn].",2 Model,[0],[0]
"For each word wi consists of li characters [c1, c2, ..., cli ] and li is the length of wi.",2 Model,[0],[0]
"We embed all words and characters into low-dimensional real-value vectors which can be learned by language model (Bengio et al., 2003; Mikolov et al., 2013).",2 Model,[0],[0]
We represent sentence as a matrix of word embeddings W =,2 Model,[0],[0]
"[E1, E2, ..., En] ∈ Rn×dw .",2 Model,[0],[0]
"Similarly, word wi is denoted as a matrix of character embeddings Ci ∈ Rli×dc , and dw and dc are the size of word embedding and character embedding respectively.
",2 Model,[0],[0]
"First, we design a hierarchical two-layer architecture where each layer includes a multi-layer bidirectional Gated Recurrent Units (MBi-GRU).",2 Model,[0],[0]
GRU is good at modeling a sequence with the benefits of avoiding the gradient vanishing and exploding problems.,2 Model,[0],[0]
"For a MBi-GRU, supposing that it has M layers of Bi-GRU, the hidden state on layerm ∈ {1, 2, ...,m} at time t ∈ {1, 2, ..., n} is recursively computed by:
hmt = BiGRU(h m−1 t , h m t−1).",2 Model,[0],[0]
"(1)
where the superscript of h denotes the corresponding layer of a MBi-GRU, and h0 means the original inputs.",2 Model,[0],[0]
"BiGRU is bidirectional GRU which is
defined as:
BiGRU(xt, ht−1)",2 Model,[0],[0]
"= −→ ht ⊕ ←− ht ; (2)
−→ ht = GRU(xt, −−→ ht−1); (3) ←− ht = GRU(xt, ←−− ht−1).",2 Model,[0],[0]
"(4)
where xt is inputs which can be word embeddings or the hidden states of other BiGRU.",2 Model,[0],[0]
"⊕ indicates the operation of concatenating two vectors.
",2 Model,[0],[0]
"With the matrix of character embeddings Ci as inputs, we utilize a MBi-GRU to learn characterlevel abstract features for word wi based on its character embeddings.",2 Model,[0],[0]
"Through MBi-GRU, we can obtain the hidden states [hM1 , h M 2 , ..., h M li ] on which a max-pooling operation is applied to output the character-level features ri ∈ R2dc for word wi.",2 Model,[0],[0]
The character features of all words in a sentence form a new matrix C ∈ Rn×2dc .,2 Model,[0],[0]
"Next, We concatenate C with the matrix of word embeddings W and denote the concatenation as F ∈ Rn×(dw+2dc).",2 Model,[0],[0]
"With F as input, We utilize another MBi-GRU to learn the hidden states H =",2 Model,[0],[0]
"[h′M1 , h ′M 2 , ..., h ′M n ]",2 Model,[0],[0]
as the final representations of the sentence.,2 Model,[0],[0]
"Therefore, the hierarchical two-layer MBi-GRU architecture can learn highlevel abstract features with consideration of both character-level and word-level information.
",2 Model,[0],[0]
"After learning the final representations for sentence, we first project the features: tfi = h′ M i of each word into target label space by:
yit = f(tfi ·W tp + btp) (5)
where W tp and b t p are weight matrix and bias.
",2 Model,[0],[0]
"As we know, the boundary of a target should be the same as that of its sentiment in sequence label.",2 Model,[0],[0]
"As the example in Section 1, the target label and sentiment label of Michael Jordan are “BPerson, I-Person” and “B-Positive, I-Positive” respectively.",2 Model,[0],[0]
"To learn this kind of consistency, we introduce the target label information into predicting sentiment label by:
yis = f(sfi ·W sp + bsp) (6)
where sfi = h′ M i ⊕ yit, W ts and bts are weight matrix and bias respectively.",2 Model,[0],[0]
"This makes our model know the target label information when predicting their sentiment.
",2 Model,[0],[0]
"For sequence labeling, there usually exist dependencies between labels.",2 Model,[0],[0]
"Take the target labeling task for example, label I will never follow label
B-Positive I-Positive
O. To consider the influence of label dependencies, we introduce the transition matrix Ai,j proposed by Collobert et al. (2011) which measures the probability of jumping from label i to label j.
Given the sentence x =",2 Model,[0],[0]
"[w1, w2, ..., wn] and the scores yt =",2 Model,[0],[0]
"[y1t , y 2 t , ..., y n t ] and ys =",2 Model,[0],[0]
"[y1s , y 2 s , ..., y n s ] computed by Eq. 5 and Eq. 6, we get the target labeling scores by summing up transition scores and the scores yit:
s(yt, x, θt) = ∑n
i=1",2 Model,[0],[0]
"(Ati−1,i + y i t)",2 Model,[0],[0]
"; (7)
whereAt is label transition matrix for target labeling.",2 Model,[0],[0]
"θt = θ ∪ {Ati,j}, and θ denotes parameters of HMBi-GRUs.
",2 Model,[0],[0]
"Next, we normalize the target label scores over all possible labeling paths of target (i.e., Yt) by a softmax function:
pt(yt|x) = es(yt,x,θt)∑
ŷt∈Yt e s(ŷt,x,θt)
; (8)
We can also use Eq. 7 and Eq. 8 to get the normalized sentiment label scores ps(ys|x).",2 Model,[0],[0]
"To train our model, we define the loss function by:
loss = − log(pt(yt|x))− log(ps(ys|x)).",2 Model,[0],[0]
"(9)
Finally, we obtain targets label sequence y∗t and their sentiment label sequence y∗s which have maximal score y∗t = argmaxŷ∈Yt(s(x, ŷ, θt))",2 Model,[0],[0]
"y ∗ s = argmaxŷ∈Ys(s(x, ŷ, θs)).",2 Model,[0],[0]
y ∗ t and y ∗ s can be computed by Viterbi algorithm.,2 Model,[0],[0]
"To validate the effectiveness of our model, we conduct experiments on two datasets, consisting of
English tweets and Spanish tweets, which are constructed by Mitchell et al. (2013)1.",3.1 Setup,[0],[0]
"Table 2 depicts the statistics of data, which contains sentence number, target number and the number of positive target, negative target and neutral target.",3.1 Setup,[0],[0]
"To evaluate the system performance, we adopt Precision, Recall and F-measure.",3.1 Setup,[0],[0]
"In our experiments, we evaluate the performance of detecting targets (DT) and targeted sentiment analysis (TSA) which a target is taken as correct only when the boundary and the sentiment are both correctly recognized.",3.1 Setup,[0],[0]
"We also adopt Precision, Recall and F-measure used in Zhang et al. (2015) to evaluate our model.",3.1 Setup,[0],[0]
"The reason why we don’t compare with Mitchell et al. (2013) is that they only evaluate the beginning of targets along with the sentiment expressed towards it.
",3.1 Setup,[0],[0]
"In our experiments, we use embeddings from Pennington et al. (2014)2 and Cieliebak et al. (2017)3 for English words and Spanish words respectively.",3.1 Setup,[0],[0]
"The character embeddings are initialized by Xavier (Glorot and Bengio, 2010) and their dimension is 50.",3.1 Setup,[0],[0]
"In our model, all unknown words, weight matrices and biases are initialized by Xavier Glorot and Bengio (2010).",3.1 Setup,[0],[0]
The dimensions of the character-level and word-level hidden states in MBi-GRU are set to 300 and 600 respectively.,3.1 Setup,[0],[0]
The layer number of multi-layer bidirectional GRU is set to 2.,3.1 Setup,[0],[0]
"To avoid overfitting, we adopt dropout on embeddings, sfi and tfi, and the dropout rate is set to 0.5.",3.1 Setup,[0],[0]
The word embeddings and character embeddings will be tuned during training.,3.1 Setup,[0],[0]
"Finally, we utilize Adam (Kingma and Ba, 2014) to optimize all parameters of our model.",3.1 Setup,[0],[0]
"To investigate the performance of our joint model, we compare it with several baselines as follows: • Discrete uses traditional discrete features as 1http://www.m-mitchell.com/code/index.",3.2 Baselines,[0],[0]
html,3.2 Baselines,[0],[0]
"2https://nlp.stanford.edu/projects/ glove/ 3https://spinningbytes.com/resources/ embeddings/
inputs and multi-label CRF which contains two separate output clique potentials and two separate edge clique potentials for target extraction and sentiment classification respectively.",3.2 Baselines,[0],[0]
"There also exist links between target labels and sentiment labels for each word (Zhang et al., 2015).
",3.2 Baselines,[0],[0]
"• Neural uses word embeddings transformed with non-linear function as inputs, and others are the same as Discrete model (Zhang et al., 2015).
",3.2 Baselines,[0],[0]
"• Integrated integrates both discrete features and word embeddings into the same CRF framework and other settings are the same as Discrete (Zhang et al., 2015).
",3.2 Baselines,[0],[0]
"• Bi-GRU only uses word embeddings as inputs, and Bi-GRU is employed to learn representations for sentence.
•MBi-GRU also uses word embeddings as inputs, but MBi-GRU is utilized to model sentence.
",3.2 Baselines,[0],[0]
• HBi-GRU first uses Bi-GRU to learn character level features for each word.,3.2 Baselines,[0],[0]
"Then, character level features and word embeddings are concatenated as inputs for another Bi-GRU to learn final representations for sentence.
",3.2 Baselines,[0],[0]
"• No-Target uses HMBi-GRU to learn representations for sentence, but h′Mi (depicted in Section 2) are used to predict target label and sentiment label separately.",3.2 Baselines,[0],[0]
No-Target doesn’t let target label information to affect sentiment label.,3.2 Baselines,[0],[0]
"This is the biggest difference between No-Target and ours.
",3.2 Baselines,[0],[0]
"It is noticed that all of Bi-GRU, MBi-GRU and HBi-GRU use transition matrix to model the dependencies between labels and introduce target label information into predicting sentiment label.",3.2 Baselines,[0],[0]
Table 2 displays the performance comparison of our models with the baselines.,3.3 Analysis,[0],[0]
"We can see that Discrete gets the worst results on English dataset, and Neural gets the worst results on Spanish dataset.",3.3 Analysis,[0],[0]
"The Integrate greatly improves the performances on both datasets because discrete features and word embeddings can complement each other.
",3.3 Analysis,[0],[0]
Bi-GRU greatly improves the performance compared with Discrete and Neural but gets worse performance than Integrate.,3.3 Analysis,[0],[0]
This verifies the effectiveness of neural networks in TAS.,3.3 Analysis,[0],[0]
"However, simple neural networks are not enough to acquire better results.",3.3 Analysis,[0],[0]
"MBi-GRU learns high-level features via multi-layer bidirectional GRU and achieves comparable results compared with Integrate.
",3.3 Analysis,[0],[0]
"Nevertheless, Bi-GRU and MBi-GRU do not make full use of character-level features.",3.3 Analysis,[0],[0]
HBiGRU incorporates character-level features by BiGRU on letter sequence of word.,3.3 Analysis,[0],[0]
We can see that HBi-GRU improves about 1.85% and 1.16% in TSA on both datasets compared with Integrate.,3.3 Analysis,[0],[0]
"The performance of HBi-GRU demonstrates the importance of character-level features in TSA, and the hierarchical architecture is good at leaning multi-level (character-level, word-level) features.
",3.3 Analysis,[0],[0]
"Our model improves 3.20%, 2.59% in TSA and 2.39%, 0.27% in DT on both datasets compared with the existing best system: Integrate.",3.3 Analysis,[0],[0]
"Compared with No-Target, our model introduces target label information into predicting sentiment label and improves about 0.66%, 1.44% in TSA and 0.59%, 0.91% in DT on both datasets.",3.3 Analysis,[0],[0]
The improvements demonstrate that target label information plays important roles in predicting sentiment label.,3.3 Analysis,[0],[0]
"It is noticed that the results of our model in
DT are also improved compared with No-Target.",3.3 Analysis,[0],[0]
"The reason may be that the gradients from sentiment loss have positive effects on detecting targets.
",3.3 Analysis,[0],[0]
"In a word, our model achieves state-of-the-art in DT and TSA on both datasets.",3.3 Analysis,[0],[0]
"Character-level features play great roles in DT and TSA, and HMBiGRU is good at learning multi-level features.",3.3 Analysis,[0],[0]
It is useful to learn boundary consistence by introducing target label information into predicting sentiment label.,3.3 Analysis,[0],[0]
"Here, we use a tweet from English Dataset as a case study, and the tweet is “Congratulations to our Champ Roger Federer ...”.",3.4 Case Study,[0],[0]
We apply NoTarget and our model on the tweet.,3.4 Case Study,[0],[0]
No-Target and our model get the same target labels:,3.4 Case Study,[0],[0]
"[O,O,O,O,BPerson,I-Person,...], and we can see that both models correctly extract the target: Roger Federer, and this results show the effectiveness of both models in detecting targets.",3.4 Case Study,[0],[0]
Our model successfully obtains the correct sentiment labels:,3.4 Case Study,[0],[0]
"[O,O,O,O,B-Positive,I-Positive,...].",3.4 Case Study,[0],[0]
"However, NoTarget predicts a wrong sentiment label sequence: [O,O,O,B-Positive,I-Positive,O,...].",3.4 Case Study,[0],[0]
We can see that No-Target wrongly regard Champ as the beginning position and ignore Federer.,3.4 Case Study,[0],[0]
"The reasons are that the first letter of Champ is capitalized, which may mislead No-Target and there is no correlation between target and sentiment label.",3.4 Case Study,[0],[0]
"In our model, we incorporate target label information into predicting sentiment label.",3.4 Case Study,[0],[0]
"Therefore, our model tends to force target and sentiment label to have same boundary information.
",3.4 Case Study,[0],[0]
This case study shows that the target label information plays important roles in predicting sentiment label because they share the same boundary information.,3.4 Case Study,[0],[0]
Early works on target sentiment analysis were based on subjects and features.,4 Related Work,[0],[0]
"For example, Yi et al. (2003) extracted all references to the given subject and determined the sentiment of each reference.",4 Related Work,[0],[0]
"Hu and Liu (2004) first proposed several techniques to mine the product features that customers have expressed their opinions and determined their sentiment, and Popescu and Etzioni (2007) utilized unsupervised methods to identify opinions with respect to features and determine the
polarity of opinions.",4 Related Work,[0],[0]
"Jin et al. (2009) proposed a novel lexicalized HMMs model to mine customer reviews of a product and extract highly specific product related entities which reviewers expressed their opinion, and they also identified the sentiment of opinion entities.",4 Related Work,[0],[0]
"The works of (Yang and Cardie, 2013) and (Li et al., 2010) are similar to (Jin et al., 2009).",4 Related Work,[0],[0]
"However, these works only take pre-defined features into account and can not find new features.",4 Related Work,[0],[0]
"To automatically extract targets and predict their sentiment, Mitchell et al. (2013) first proposed a conditional random fields (CRF) framework to jointly detect entities and identify their sentiment.",4 Related Work,[0],[0]
"Based on the work of (Mitchell et al., 2013), Zhang et al. (2015) explored the effect of word embeddings and automatic feature combinations by extending a CRF baseline using neural networks.
",4 Related Work,[0],[0]
We propose a neural networks based joint model which extracts targets and their sentiments simultaneously.,4 Related Work,[0],[0]
Our model takes full advantages of neural networks’ potential in capturing sequence labeling features such as long distance dependencies and character-level features.,4 Related Work,[0],[0]
"Furthermore, Our model allows the target label to have positive effects on their sentiment label because target label shares boundary information with sentiment label.",4 Related Work,[0],[0]
"In this paper, we propose a HMBi-GRU based joint model for targeted sentiment analysis.",5 Conclusion,[0],[0]
Our model will simultaneously extract targets and predict their sentiment.,5 Conclusion,[0],[0]
"Furthermore, our model introduces target information into predicting corresponding sentiment label.",5 Conclusion,[0],[0]
"Experiments show that the well-designed neural networks can greatly improve the result for targeted sentiment analysis, and target label information plays great roles in predicting sentiment label.",5 Conclusion,[0],[0]
We thank anonymous reviewers for their insightful suggestions.,Acknowledgments,[0],[0]
Our work is supported by National Natural Science Foundation of China under Grant No.61433015 and the National Key Research and Development Program of China under Grant No.2017YFB1002101.,Acknowledgments,[0],[0]
The corresponding author of this paper is Houfeng Wang.,Acknowledgments,[0],[0]
Targeted sentiment analysis (TSA) aims at extracting targets and classifying their sentiment classes.,abstractText,[0],[0]
Previous works only exploit word embeddings as features and do not explore more potentials of neural networks when jointly learning the two tasks.,abstractText,[0],[0]
"In this paper, we carefully design the hierarchical multi-layer bidirectional gated recurrent units (HMBi-GRU) model to learn abstract features for both tasks, and we propose a HMBi-GRU based joint model which allows the target label of word to have influence on its sentiment label.",abstractText,[0],[0]
Experimental results on two datasets show that our joint learning model can outperform other baselines and demonstrate the effectiveness of HMBi-GRU in learning abstract features.,abstractText,[0],[0]
Joint Learning for Targeted Sentiment Analysis,title,[0],[0]
"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 857–867, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
We present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets.",text,[0],[0]
One of the essential goals in natural language processing (NLP) is the development of effective systems that can capture the underlying semantics conveyed by human languages.,1 Introduction,[0],[0]
"An important step towards such a goal is the development of practical systems that can efficiently extract useful shallow semantic information such as entities and at the same time identify their semantic classes (e.g., person, organization, etc).
",1 Introduction,[0],[0]
"Such a task is often known as named entity recognition and classification (NERC), one of the standard tasks in information extraction (IE).",1 Introduction,[0],[0]
"While such a task focuses on the extraction and classification of entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing.",1 Introduction,[0],[0]
"Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004).",1 Introduction,[0],[0]
"The task of mention detection and tracking has received substantial attention, largely due
to its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013).
",1 Introduction,[0],[0]
"While most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models.",1 Introduction,[0],[0]
"In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence.",1 Introduction,[0],[0]
"Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges.",1 Introduction,[0],[0]
"First, a mention can consist of multiple words, so its length can be arbitrarily long.",1 Introduction,[0],[0]
"Second, the mentions can overlap with one another.",1 Introduction,[0],[0]
"Popular models used for POS tagging, such as linear-chain conditional random fields (Lafferty et al., 2001) or semi-Markov conditional random fields (Sarawagi and Cohen, 2004) have difficulties coping with these issues.",1 Introduction,[0],[0]
"While approaches on addressing these issues exist, current algorithms typically suffer from high time complexity (Finkel and Manning, 2009) and are therefore difficult to scale to large datasets.",1 Introduction,[0],[0]
"On the other hand, the problem of designing efficient and scalable models for mention extraction and classification from natural language texts becomes increasingly important in this era where a large volume of textual data is becoming available on the Web every day – users need systems which are able to scale to extremely large datasets to support efficient semantic analysis for timely decisonmaking.
",1 Introduction,[0],[0]
"In this paper, we tackle the above-mentioned issue by introducing a novel model for joint mention extraction and classification.",1 Introduction,[0],[0]
"We make the following major contributions in this work:
• We propose a model that is able to effectively
857
handle overlapping mentions with unbounded lengths.",1 Introduction,[0],[0]
"• The learning and inference algorithms of our
proposed model have a time complexity that is linear in the number of words in the input sentence and also linear in the number of possible semantic classes/types, making our model scalable to extremely large datasets.",1 Introduction,[0],[0]
"• Our model can additionally capture mentions’
head information in a joint manner under the same time complexity.
",1 Introduction,[0],[0]
Our system and code are available for download from http://statnlp.org/research/ie/.,1 Introduction,[0],[0]
Existing work has been largely focused on the task of named entity recognition and classification (NERC).,2 Related Work,[0],[0]
"The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic.
",2 Related Work,[0],[0]
Most prior work took a supervised learning approach.,2 Related Work,[0],[0]
Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach.,2 Related Work,[0],[0]
Florian et al. (2003) presented a system for named entity recognition by combining different classifiers.,2 Related Work,[0],[0]
McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts.,2 Related Work,[0],[0]
Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed.,2 Related Work,[0],[0]
"Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005).",2 Related Work,[0],[0]
"Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013).
",2 Related Work,[0],[0]
"As pointed out by Finkel and Manning (2009), named entities are often nested.",2 Related Work,[0],[0]
This fact was often ignored by the community largely due to technical reasons.,2 Related Work,[0],[0]
"They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets.",2 Related Work,[0],[0]
Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts.,2 Related Work,[0],[0]
"Hoffmann et al. (2011) looked into a separate
issue, which is to identify overlapping relations amongst entities.
",2 Related Work,[0],[0]
Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing.,2 Related Work,[0],[0]
Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts.,2 Related Work,[0],[0]
Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used.,2 Related Work,[0],[0]
Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction.,2 Related Work,[0],[0]
Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner.,2 Related Work,[0],[0]
"Typically, a mention that appears in a natural language sentence consists of a contiguous sequence of natural language words.",3.1 Mentions and Their Combinations,[0],[0]
Consider a sentence that consists of n words where each word is indexed with its position in the sentence.,3.1 Mentions and Their Combinations,[0],[0]
"A mention m can be uniquely represented with a tuple 〈bm, em, τ〉, where bm and em are the indices of the first and last word of the mention, respectively, and τ is its semantic class (type).
",3.1 Mentions and Their Combinations,[0],[0]
"We can see that for a given sentence consisting of n words, there are altogether tn(n + 1)/2 possible different mention candidates, where t is the total number of possible mention types.",3.1 Mentions and Their Combinations,[0],[0]
"Now, for each such candidate in the given sentence, it can be either a mention, or not a mention.",3.1 Mentions and Their Combinations,[0],[0]
This leads to a total number of 2tn(n+1)/2 possible mention combinations.,3.1 Mentions and Their Combinations,[0],[0]
"This number is prohibitively large even for small values of n and t, which prevents us from exhaustively enumerating all of them during learning and inference.
",3.1 Mentions and Their Combinations,[0],[0]
One approach to performing inference over such a large space is to introduce compact representations that are able to encode exponentially many mentions that would enable tractable inference algorithms to be employed.,3.1 Mentions and Their Combinations,[0],[0]
We discuss in the next section our novel mention hypergraph representation proposed for such a purpose.,3.1 Mentions and Their Combinations,[0],[0]
"Central to our approach is the introduction of the novel mention hypergraphs that allow us to
compactly represent exponentially many possible combinations of potentially overlapping, lengthunbounded mentions of different types.
",3.2 Mention Hypergraphs,[0],[0]
"A hypergraph is a generalization of a conventional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes.",3.2 Mention Hypergraphs,[0],[0]
"In this work, we consider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes.",3.2 Mention Hypergraphs,[0],[0]
"Hypergraphs have also been used in other fields, such as syntactic parsing (Klein and Manning, 2001), semantic parsing (Lu, 2015) and machine translation (Cmejrek et al., 2013).
",3.2 Mention Hypergraphs,[0],[0]
"Our mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes.",3.2 Mention Hypergraphs,[0],[0]
A partial mention hypergraph is depicted in Figure 1.,3.2 Mention Hypergraphs,[0],[0]
"We describe the definition of each type of nodes next.
",3.2 Mention Hypergraphs,[0],[0]
• A nodes.,3.2 Mention Hypergraphs,[0],[0]
These nodes are used to sequentially arrange mentions with different left boundaries.,3.2 Mention Hypergraphs,[0],[0]
"Specifically, each A node at position k (the k-th word), or Ak, is used to compactly represent all such mentions in the sentence whose left boundaries are exactly at or strictly after k. • E nodes.",3.2 Mention Hypergraphs,[0],[0]
"The node Ek is used to compactly represent all possible mentions (possibly of length zero) whose left boundaries are exactly at the current position k.
• T nodes.",3.2 Mention Hypergraphs,[0],[0]
"The node Tkj is used to compactly represent all mentions (possibly of length zero) whose left boundaries are exactly at position k, and have the mention type j. • I nodes.",3.2 Mention Hypergraphs,[0],[0]
"The node Ikj is used to compactly
represent all incomplete mentions which contain the current word at position k as part of the mention, and have the mention type j. • X nodes.",3.2 Mention Hypergraphs,[0],[0]
"These are the “terminal” nodes indi-
cating the completion of a path.",3.2 Mention Hypergraphs,[0],[0]
"No additional node will be attached to such nodes as a child.
",3.2 Mention Hypergraphs,[0],[0]
There are also various hyperedges that connect different nodes in the mention hypergraph.,3.2 Mention Hypergraphs,[0],[0]
"We use 〈α← β1, . . .",3.2 Mention Hypergraphs,[0],[0]
", βn〉 to denote a hyperedge which connects a parent node α and child nodes β1, . . .",3.2 Mention Hypergraphs,[0],[0]
", βn.",3.2 Mention Hypergraphs,[0],[0]
Each hyperedge essentially provides one possible way of re-expressing the semantics conveyed by the parent node using the child nodes.,3.2 Mention Hypergraphs,[0],[0]
"For example, as shown in Figure 1, the hyperedge connecting the parent node Ak and the child nodes Ek,Ak+1 explains the fact that any mention covered by Ak either has a left boundary that is “exactly at k” (Ek), or “exactly at or strictly after k + 1” (Ak+1).
",3.2 Mention Hypergraphs,[0],[0]
"Similarly, for each I node, there exist 3 hyperedges that connect it to other child nodes.",3.2 Mention Hypergraphs,[0],[0]
"The top hyperedge (in green) encodes the fact that the current word appears in the middle of a mention; the bottom hyperedge (in yellow) encodes the fact that the current word appears in a mention as the last word; the middle hyperedge (in brown) encodes the fact that both cases can occur at the same time (i.e., the current word belongs to multiple overlapping mentions of the same type).",3.2 Mention Hypergraphs,[0],[0]
"We have the following theorem: Theorem 3.1 Any combination of mentions in a sentence can be represented with exactly one subhypergraph of the complete mention hypergraph.
",3.2 Mention Hypergraphs,[0],[0]
"Proof For each mention, there exists a unique path in the mention hypergraph to represent it.",3.2 Mention Hypergraphs,[0],[0]
"For any combination of mentions, there exist unique paths in the mention hypergraph to represent such a combination.",3.2 Mention Hypergraphs,[0],[0]
"These paths altogether form a unique sub-hypergraph of the original hypergraph.
",3.2 Mention Hypergraphs,[0],[0]
"For example, consider the following sentence: “he also talked with the egyptian president .”",3.2 Mention Hypergraphs,[0],[0]
This sentence contains three mentions.,3.2 Mention Hypergraphs,[0],[0]
"The first is “he” with type PER, the second is “the egyptian president’’ with type PER, and the third mention is “egyptian” with type GPE.",3.2 Mention Hypergraphs,[0],[0]
"Figure 2 gives the subhypergraph structure showing how these mentions
are jointly represented.",3.2 Mention Hypergraphs,[0],[0]
"The mention hypergraph defined over the input sentence contains exponentially many such sub-hypergraph structures.
",3.2 Mention Hypergraphs,[0],[0]
We note that the converse of Theorem 3.1 is not true.,3.2 Mention Hypergraphs,[0],[0]
"In certain cases, it is possible for two different overlapping mention combinations to share the same mention hypergraph.
",3.2 Mention Hypergraphs,[0],[0]
"For example, consider a toy example sentence A B C D shown in Figure 3, both B C and A B C D are mentions of the same type PER (i.e. one is strictly contained by the other.",3.2 Mention Hypergraphs,[0],[0]
We call such combinations type-I combinations).,3.2 Mention Hypergraphs,[0],[0]
The above sub-hypergraph shows how to encode such a combination.,3.2 Mention Hypergraphs,[0],[0]
"However, if both A B C and B C D are mentions of the same type PER (i.e., two mentions overlap but no one is contained by the other.",3.2 Mention Hypergraphs,[0],[0]
"We call such com-
binations type-II combinations), such a combination shares the same representation as the above sub-hypergraph.",3.2 Mention Hypergraphs,[0],[0]
"Note that such an ambiguity happens only when two overlapping mentions have the same type, and one mention is strictly contained by the other and their boundaries are all different.",3.2 Mention Hypergraphs,[0],[0]
"In practice, however, we found that in the two datasets that we used for evaluations, if two mentions overlap with one another, they almost always form a type-I combination, and type-II combinations are very rare.",3.2 Mention Hypergraphs,[0],[0]
"Empirically, as we will see later in our experiments, our model is effective in handling overlapping mentions.",3.2 Mention Hypergraphs,[0],[0]
"Following the conditional random fields (Lafferty et al., 2001), we adopted a log-linear approach for such a joint mention extraction and typing task.",3.3 Log-Linear Modeling,[0],[0]
"Specifically, for a given input sentence x, the probability of predicting a possible output y (a mention sub-hypergraph that represents a particular combination of mentions) is given as follows:
p(y|x) = exp(w T f(x,y))∑
y′ exp(wT",3.3 Log-Linear Modeling,[0],[0]
"f(x,y′))",3.3 Log-Linear Modeling,[0],[0]
"(1)
where f(x,y) is the feature vector defined over the input-output pair (x,y), and the weight vector w gives the parameters of the model.
",3.3 Log-Linear Modeling,[0],[0]
"Our objective is to minimize the regularized negative joint log-likelihood of the dataset:
L(w) =",3.3 Log-Linear Modeling,[0],[0]
"∑
i log ∑ y′ exp(wT f(xi,y′))
",3.3 Log-Linear Modeling,[0],[0]
"− ∑
i
wT f(xi,yi) + λwTw (2)
where (xi,yi) refers to the i-th training instance, and the last term is a L2 regularization term with λ being a positive scalar (fixed to 0.01 in this work).
",3.3 Log-Linear Modeling,[0],[0]
"The gradient of the above objective function is:
∂L(w)",3.3 Log-Linear Modeling,[0],[0]
"∂wk
= ∑
i
",3.3 Log-Linear Modeling,[0],[0]
"Ep(y′|xi)[fk(xi,y ′)]
",3.3 Log-Linear Modeling,[0],[0]
"− ∑
i
fk(xi,yi) + 2λwk (3)
where wk is the weight of the k-th feature fk.",3.3 Log-Linear Modeling,[0],[0]
"We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure.",3.3 Log-Linear Modeling,[0],[0]
"Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found.
",3.3 Log-Linear Modeling,[0],[0]
The objective function defined in Equation 2 can be optimized with standard gradient-based methods.,3.3 Log-Linear Modeling,[0],[0]
"We used L-BFGS (Liu and Nocedal, 1989) as our optimization method.",3.3 Log-Linear Modeling,[0],[0]
"In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in Equation 3.",3.4 Algorithms,[0],[0]
Computation of the second and third terms in this equation is straightforward.,3.4 Algorithms,[0],[0]
The first term in Equation 3 involves the computation of an expectation of feature values over all possible mention combinations for a given input sentence.,3.4 Algorithms,[0],[0]
"Following classic dynamic programming algorithms used in graphical models, we develop analogous efficient dynamic programming algorithms that work on hypergraphs and generalize the conventional forward-backward/inside-outside algorithm to efficiently compute such values.
",3.4 Algorithms,[0],[0]
"Time Complexity At each time step k, we need to compute scores for m I nodes, m T nodes, 1 E node, and 1 A node.",3.4 Algorithms,[0],[0]
"Hence, the overall time complexity for our algorithm is in O(mn) (assuming computation of the feature scores at each node involves a constant time), where m is the total number of possible mention types, and n is the total number of words in the given sentence.",3.4 Algorithms,[0],[0]
"1
1Note that the time complexity for the linear chain CRF is in O(m2n) due to their first-order assumption.",3.4 Algorithms,[0],[0]
"The features that we use are inspired by the work of (Carreras et al., 2002).",3.5 Features,[0],[0]
"Specifically, we consider the following features defined over the inputs:
• Words (and POS tags, if available) that appear around the current word (with position information), with a window of size 3.",3.5 Features,[0],[0]
•,3.5 Features,[0],[0]
"Word n-grams (and POS n-grams, if available)
that contain the current word (with position information), for n = 2, 3, 4. •",3.5 Features,[0],[0]
"Bag of words around the current word, with a
window of size 5.",3.5 Features,[0],[0]
"• Word pattern features 2.
",3.5 Features,[0],[0]
Note that these are the indicator functions defined over the inputs.,3.5 Features,[0],[0]
"The final set of features are defined over (x,y) tuples, which is obtained as a cross-product between the above indicator functions and the following indicator function:
•",3.5 Features,[0],[0]
The type of the node (such as T or I).,3.5 Features,[0],[0]
"In addition, we also introduce the following fea-
ture defined over the output structure only:
• The number of such hyperedges that exactly connect one T node and one I node.
",3.5 Features,[0],[0]
We call this feature mention penalty.,3.5 Features,[0],[0]
This feature learns a global preference of the number of mentions that should appear in any input sentence.,3.5 Features,[0],[0]
One additional assumption for the mention extraction and typing task is that each mention comes with a head.,3.6 Joint Modeling of Mention Heads,[0],[0]
A head is strictly a substring of the mention and provides important information about the mention.,3.6 Joint Modeling of Mention Heads,[0],[0]
"It is possible to extend our model to support joint modeling of mention heads, while still maintaining the same time complexity.
",3.6 Joint Modeling of Mention Heads,[0],[0]
"Due to space limitations, we could only give a relatively brief description of this extension in this section.",3.6 Joint Modeling of Mention Heads,[0],[0]
"The idea is to replace the I nodes with three different types of nodes, namely Ij–B nodes (used to represent words that appear within a mention of type j and before its head), Ij–W nodes (used to represent words that appear within the head of a mention of type j), and Ij–A nodes (used to represent words that appear within a mention of type j and after its head).",3.6 Joint Modeling of Mention Heads,[0],[0]
"The hyperedges also need to be established accordingly in order to properly model all possible mention and head
2all-caps, all-digits, all-alphanumeric, contains-digits, contains-dots, contains-hyphen, initial-caps, lonely-initial, punctuaion-mark, roman-number, single-character, URL.
combinations.",3.6 Joint Modeling of Mention Heads,[0],[0]
"Since in such a new hypergraph, at each time step, only a constant number (2) of additional nodes are involved, the time complexity for learning and inference with such a model remains the same, which is in O(mn).",3.6 Joint Modeling of Mention Heads,[0],[0]
One standard evaluation metric for named entity recognition is the F (F1) measure.,3.7 Optimization of F measure,[0],[0]
"In our task, the F measure is defined as the harmonic mean of the precision (P ) and recall (R) scores, where precision is the ratio between the number of correctly predicted mentions and the total number of predicted mentions, and recall is the ratio between the number of correctly predicted mentions and the total number of gold mentions.",3.7 Optimization of F measure,[0],[0]
We will also adopt these metrics in our evaluations later.,3.7 Optimization of F measure,[0],[0]
"Unfortunately, the model only optimizes its objective function defined in Equation 2, which is the negative (regularized) joint log-likelihood.",3.7 Optimization of F measure,[0],[0]
"Previous work showed it was possible to optimize the F measure in a log-linear model (Suzuki et al., 2006).",3.7 Optimization of F measure,[0],[0]
Culotta and McCallum (2004) also proposed a method for optimizing information extraction performance based on confidence estimation.,3.7 Optimization of F measure,[0],[0]
Their work is based on linear-chain CRF and estimate the confidence of extracted fields based on marginal probabilities.,3.7 Optimization of F measure,[0],[0]
The technique is not directly applicable to our task where a hypergraph representation is used to encode overlapping mentions.,3.7 Optimization of F measure,[0],[0]
"In this work, we used a very simple and intuitive technique for optimizing the F measure.",3.7 Optimization of F measure,[0],[0]
"The idea is to further tune the weight of a single parameter – mention penalty based on the development set, after the training process completes.
",3.7 Optimization of F measure,[0],[0]
"This is based on the observation that by increasing the value of the mention penalty, we are essentially forcing our model to predict more mentions.",3.7 Optimization of F measure,[0],[0]
Therefore the recall is a monotonic function with respect to the mention penalty.,3.7 Optimization of F measure,[0],[0]
"Based on this fact, we use a simple search algorithm with a fixed step size (we set it to 0.01) to determine the optimal value of the modified mention penalty so that the F measure of the development set is optimized.",3.7 Optimization of F measure,[0],[0]
"In this section, we present empirical evaluations.",4 Experiments,[0],[0]
Our main experiments were conducted on the standard ACE2004 and ACE2005 datasets which contain overlapping mentions.,4 Experiments,[0],[0]
Two additional experiments on the GENIA and CONLL2003 dataset were also conducted .,4 Experiments,[0],[0]
Our primary experiments were conducted based on the English portion of the ACE2004 dataset3 and the ACE2005 dataset4.,4.1 Results on ACE,[0],[0]
"Following previous work, for ACE2004, we considered all documents from arabic treebank, bnews, chinese treebank, and nwire, and for ACE2005, we considered all documents from bc, bn, nw, and wl .",4.1 Results on ACE,[0],[0]
"We randomly split the documents for each dataset into three portions: 80% for training, 10% for development, and the remaining 10% for evaluations.",4.1 Results on ACE,[0],[0]
The statistics of the datasets are summarized in Table 15.,4.1 Results on ACE,[0],[0]
"We
3https://catalog.ldc.upenn.edu/LDC2005T09 4https://catalog.ldc.upenn.edu/LDC2006T06 5Exact train/dev/test splits information can be found on
http://statnlp.org/research/ie/.
can observe that overlapping mentions are common – over 30% of the sentences contain overlapping mentions (see row 3 of the table).",4.1 Results on ACE,[0],[0]
"Mentions can also be very long – over 5% of the mentions consist of more than 6 words, and the longest mention consists of 57 words.
",4.1 Results on ACE,[0],[0]
We compared our system’s performance with those of several baseline approaches.,4.1 Results on ACE,[0],[0]
We first built two simple baseline approaches based on sequence labelling models using the conditional random fields (CRFs).,4.1 Results on ACE,[0],[0]
Such approaches can not handle overlapping mentions.,4.1 Results on ACE,[0],[0]
"To train such models, whenever two mentions overlap with one another in the training set, we remove the mention that is shorter in length.",4.1 Results on ACE,[0],[0]
"Following (Ratinov and Roth, 2009), we considered the BIO (Begin, Inside, Outside) approach and the BILOU (Begin, Inside, Last, Outside, Unit) approach for designing the output labels.",4.1 Results on ACE,[0],[0]
Results show the BILOU approach yields better results.,4.1 Results on ACE,[0],[0]
"Similar observations were reported in Ratinov and Roth (2009).
",4.1 Results on ACE,[0],[0]
"In the work of (Alex et al., 2007), the authors proposed several approaches for building models to handle nested named entities in biomedical texts.",4.1 Results on ACE,[0],[0]
Their best results were obtained from a cascaded approach where they built one model for each named entity class.,4.1 Results on ACE,[0],[0]
Outputs from one model can then served as the inputs to the next model for predicting the named entity class of a different type.,4.1 Results on ACE,[0],[0]
One fundamental limitation of such an approach is that it being unable to handle overlapping mentions of the same type.,4.1 Results on ACE,[0],[0]
"Nevertheless, this approach worked very well on both datasets.",4.1 Results on ACE,[0],[0]
"The results are shown in the row of “CRF (CC)”.6
Another class of models that is often used in information extraction are the semi-Markov conditional random fields (semi-CRFs) (Sarawagi and Cohen, 2004).",4.1 Results on ACE,[0],[0]
Semi-CRF models are able to capture the non-Markovian properties of mentions.,4.1 Results on ACE,[0],[0]
"However, they are unable to handle nested or overlapping mentions.",4.1 Results on ACE,[0],[0]
We thus used the same method as discussed above to exclude certain mentions for training.,4.1 Results on ACE,[0],[0]
Such semi-CRF models typically assume there is a length restriction for the mentions – each mention can consist of up to c words – in order to scale linearly.,4.1 Results on ACE,[0],[0]
"When such a restriction is lifted, the time complexity of such models becomes quadratic in the number of words in the in-
6For all such linear chain CRF-related experiments, we used the CRF++ toolkit (https://code.google.com/p/crfpp/) with L-BFGS, which gives us the most competitive results over several different CRF implementations (see: http://www.chokkan.org/software/crfsuite/benchmark.html).
put sentence.",4.1 Results on ACE,[0],[0]
"We train two models: one with a length restriction, where c = 6, and the other without a length restriction (c = ∞).",4.1 Results on ACE,[0],[0]
"For features defined over the inputs, besides the Markovian features described in Sec 3.5, we also used the surface forms of complete mention spans as features.",4.1 Results on ACE,[0],[0]
"The results of these two models are reported in the fourth and fifth row of Table 2, respectively.",4.1 Results on ACE,[0],[0]
"Interestingly, imposing the length restriction appears to be helpful for precision, and as a result it makes a positive contribution towards the final F measure.
",4.1 Results on ACE,[0],[0]
Our basic model (MH: mention hypergraph) that optimizes the negative joint log likelihood is able to obtain the best precision across these two datasets.,4.1 Results on ACE,[0],[0]
When the model is further augmented with the F measure optimization step described in Sec 3.7 (MH (F )) it consistently yields the best results in terms of both recall score and F measure across these two datasets.,4.1 Results on ACE,[0],[0]
We also conducted controlled experiments to report the actual execution time of our model and make a comparison with the linear-chain CRF model (BILOU approach).,4.1.1 Running Time,[0],[0]
The experiments are all conducted on the ACE2004 dataset on the same machine.,4.1.1 Running Time,[0],[0]
"To make a proper comparison here, we implemented the linear-chain CRF model using Java (the same language is used when implementing our model), and employed the same data structures for creating features as well as the same learning and inference routines used by our mention hypergraph model.
",4.1.1 Running Time,[0],[0]
"To understand how the features and speed change as we increase the number of mention types (i.e., semantic types), we also conducted experiments where we increase the number of possible mention types.",4.1.1 Running Time,[0],[0]
"Specifically, we created subtypes from each original type annotated in the dataset.",4.1.1 Running Time,[0],[0]
"For example, we randomly replaced the type “GPE” by sub-types “GPE1” or “GPE2” in the dataset.",4.1.1 Running Time,[0],[0]
This gave us 14 different mention types.,4.1.1 Running Time,[0],[0]
"Similarly, we could randomly replace the type “GPE” by sub-types “GPE1” – “GPE4”, re-
sulting in 28 different mention types in total.",4.1.1 Running Time,[0],[0]
Our purpose of doing so is to understand how the models behave when the number of possible mention types becomes large.,4.1.1 Running Time,[0],[0]
We found that training on the entire training set of ACE2004 using the linearchain CRF model with a large number of mention types was very expensive due to the extremely large number of features involved.,4.1.1 Running Time,[0],[0]
"We instead trained the models on the development set and presented decoding time on the test set.
",4.1.1 Running Time,[0],[0]
Table 3 shows the results.,4.1.1 Running Time,[0],[0]
We empirically captured the relationship between the speed of each system (average number of words processed per second) and the number of mention types.,4.1.1 Running Time,[0],[0]
"Specifically, we found that as we linearly increased the number of mention types, for the linear-chain CRF model, the number of features grew quadratically and the speed dropped quadratically, whereas for our model, the number of features grew linearly and the speed dropped linearly.",4.1.1 Running Time,[0],[0]
"This indicates that our model is more scalable to large, practical datasets with a large number of fine-grained mention types.",4.1.1 Running Time,[0],[0]
"We also conducted experiments on these two datasets for the task of joint modeling of mention boundaries, types and heads.",4.1.2 Joint Modeling of Heads,[0],[0]
We used the same training and tuning methodology for optimizing the F measure.,4.1.2 Joint Modeling of Heads,[0],[0]
"In such experiments, we adopted a very strict evaluation criterion: a predicted mention is regarded as correct iff and only if its boundaries, type and head all exactly match those of the gold standard.
",4.1.2 Joint Modeling of Heads,[0],[0]
We compared our system’s results with those of several baseline approaches based on CRF where the cascaded BILOU approach described above was always used.,4.1.2 Joint Modeling of Heads,[0],[0]
"Specifically, we considered approaches that always regarded the complete span (CC-S), the first word (CC-F), and the last word (CC-L) as the predicted mention’s head, respectively.",4.1.2 Joint Modeling of Heads,[0],[0]
"We also considered a cascaded approach (CC-CC) where we first predicted mentions, and
then predicted their heads by following a similar approach used for predicting overlapping mentions discussed above.",4.1.2 Joint Modeling of Heads,[0],[0]
The first four rows of Table 4 give the results of these baseline approaches.,4.1.2 Joint Modeling of Heads,[0],[0]
We can observe that always predicting the last word as the head gives the best performance.,4.1.2 Joint Modeling of Heads,[0],[0]
"Inspired by this, we performed a simple approach by training a model presented in the previous section without considering head information.",4.1.2 Joint Modeling of Heads,[0],[0]
"When making predictions, we always regarded the last word of each predicted mention as its head.",4.1.2 Joint Modeling of Heads,[0],[0]
The results for such an approach are given in the fifth row of Table 4.,4.1.2 Joint Modeling of Heads,[0],[0]
The sixth row shows the results obtained by optimizing our model’s objective function.,4.1.2 Joint Modeling of Heads,[0],[0]
The last row gives the results obtained by tuning the mention penalty based on the development set.,4.1.2 Joint Modeling of Heads,[0],[0]
"As seen, our joint models significantly outperformed all those baseline approaches.",4.1.2 Joint Modeling of Heads,[0],[0]
"We are not aware of any prior work in the literature that performs joint modeling of mention boundaries, types, and heads.",4.1.2 Joint Modeling of Heads,[0],[0]
"We also additionally evaluated on the GENIA dataset (v3.02) whose focus was on biomedical related named entity recognition and classification, where the entities may overlap with one another.",4.2 Additional Experiments,[0],[0]
"Furthermore, to see how our model works on datasets where mentions do not overlap with one another, we also conducted evaluations on the standard CONLL2003 NER dataset.",4.2 Additional Experiments,[0],[0]
We followed the description of Finkel and Manning (2009) to set up our experiments on the GENIA dataset.,4.2.1 Results on GENIA,[0],[0]
"Specifically, we used the first 90% of the sentences as the training data and the remaining 10% as the evaluation data.",4.2.1 Results on GENIA,[0],[0]
We also adhered to the paper’s prescription of collapsing all DNA subtypes into DNA; RNA subtypes into RNA; and all protein subtypes into protein.,4.2.1 Results on GENIA,[0],[0]
"We kept cell line and cell type, and removed all other entities.
",4.2.1 Results on GENIA,[0],[0]
"To optimize the F measure, we further split the
training set into two portions.",4.2.1 Results on GENIA,[0],[0]
"We trained a model using the first 90% of the training data, and used the remaining 10% for development.",4.2.1 Results on GENIA,[0],[0]
"For features, no POS and no bag-of-words features are used.
",4.2.1 Results on GENIA,[0],[0]
"We compared our model’s performance with that of a model based on a constituency parser proposed by (Finkel and Manning, 2009), as well as the semi-CRF model reported there.",4.2.1 Results on GENIA,[0],[0]
The results are shown in Table 5.,4.2.1 Results on GENIA,[0],[0]
"Our model yields a better F measure than the semi-CRF model, but gives a lower performance than the model of (Finkel and Manning, 2009).",4.2.1 Results on GENIA,[0],[0]
"We note that, however, these results are not directly comparable.",4.2.1 Results on GENIA,[0],[0]
"Specifically, both of these two previous models relied on an additional 200 million words from PubMed abstracts to learn word clusters as additional features, which we do not have access to.
",4.2.1 Results on GENIA,[0],[0]
One distinctive advantage of our model is the efficiency and scalability.,4.2.1 Results on GENIA,[0],[0]
"The model of (Finkel and Manning, 2009) had a time complexity that is cubic in the number of words in the input sentence.",4.2.1 Results on GENIA,[0],[0]
"In contrast, our model scales linearly as the length of the input sentence increases.",4.2.1 Results on GENIA,[0],[0]
7,4.2.1 Results on GENIA,[0],[0]
"To understand how well our model works on datasets where mentions or entities do not overlap with one another, we conducted additional experiments on the standard dataset used in the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003), where the named entities strictly do not overlap with one another.",4.2.2 Results on CONLL2003,[0],[0]
"We compared our system’s performance against that of a baseline version of the state-of-the-art Illinois NER system (Ratinov and Roth, 2009).",4.2.2 Results on CONLL2003,[0],[0]
Their system performed sequential prediction over the input words and adopted the BILOU approach.,4.2.2 Results on CONLL2003,[0],[0]
"Their full model also incorporates external knowledge resources (e.g., gazetteers and word class).
",4.2.2 Results on CONLL2003,[0],[0]
"In order to make a proper comparison with the baseline version of their model, besides the general features we mentioned earlier, we also fol-
7In our experiments, for this dataset our model tagged over 5,000 words/second.",4.2.2 Results on CONLL2003,[0],[0]
"In (Finkel and Manning, 2009), the authors mentioned that their model tagged about 38 words/second, and the semi-CRF model tagged about 45 words/second.",4.2.2 Results on CONLL2003,[0],[0]
"However, we note these numbers are not directly comparable due to the advancement of CPU speed.
lowed (Ratinov and Roth, 2009) in incorporating word’s prefixes and suffixes (of length up to 5) as features, and normalized words referring to months, dates and numbers.",4.2.2 Results on CONLL2003,[0],[0]
"Table 6 shows that our system gives an F measure that is comparable to that of the baseline version of their system, where no external resources are used.
",4.2.2 Results on CONLL2003,[0],[0]
"This additional experiment showed that while our model is designed for handling more realistic scenarios where mentions can overlap, it yields a performance competitive to a state-of-theart system which only handles datasets with nonoverlapping mentions.",4.2.2 Results on CONLL2003,[0],[0]
"In this work, we have introduced a novel model for the task of joint modeling of mention boundaries, types, as well as their heads.",5 Conclusions,[0],[0]
"Unlike many previous research efforts for mention extraction and classification, our novel mention hypergraph representations for compactly representing exponentially many possible mentions enables a mention’s boundaries, type and head information to be jointly learned in a single framework.",5 Conclusions,[0],[0]
"The model scales linearly with respect to the number of words in the input sentence, and performs exact learning where a unique global optimum can be found.",5 Conclusions,[0],[0]
"Empirically, we have demonstrated the effectiveness of such a model across several standard datasets.
",5 Conclusions,[0],[0]
"Future work include explorations of efficient algorithms for other information extraction tasks, such as joint mention and relation extraction (Li and Ji, 2014) and event extraction (Li et al., 2013).",5 Conclusions,[0],[0]
Our system and code can be downloaded from http://statnlp.org/research/ie/.,5 Conclusions,[0],[0]
"We would like to thank Kian Ming A. Chai, Hai Leong Chieu and the three anonymous reviewers for their comments on this work.",Acknowledgements,[0],[0]
"This work is supported by Temasek Lab of Singapore University of Technology and Design project IGDSS1403011 and IGDST1403013, and is partly supported by DARPA (under agreement number FA8750-13-20008).",Acknowledgements,[0],[0]
We present a novel model for the task of joint mention extraction and classification.,abstractText,[0],[0]
"Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths.",abstractText,[0],[0]
"The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes.",abstractText,[0],[0]
Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity.,abstractText,[0],[0]
We demonstrate the effectiveness of our model through extensive experiments on standard datasets.,abstractText,[0],[0]
Joint Mention Extraction and Classification with Mention Hypergraphs,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 974–984 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1090",text,[0],[0]
"Goal-oriented dialogues, such as meetings, negotiations, or customer service transcripts, play an important role in our daily life.",1 Introduction,[0],[0]
"Automatically extracting the critical points and important outcomes from dialogues would facilitate generating summaries for complicated conversations, understanding the decision-making process of meetings, or analyzing the effectiveness of collaborations.
",1 Introduction,[0],[0]
"We are interested in a specific type of dialogues — spoken meetings, which is a common way for collaboration and idea sharing.",1 Introduction,[0],[0]
"Previous work (Kirschner et al., 2012) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings.",1 Introduction,[0],[0]
"Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse.",1 Introduction,[0],[0]
"Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse relation understanding.",1 Introduction,[0],[0]
"Take the meeting snippet from
AMI corpus (Carletta et al., 2006) in Figure 1 as an example.",1 Introduction,[0],[0]
"This discussion is annotated with discourse structure based on the Twente Argumentation Schema (TAS) by Rienks et al. (2005), which focuses on argumentative discourse information.",1 Introduction,[0],[0]
"As can be seen, meeting participants evaluate different options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giving feedback.",1 Introduction,[0],[0]
"The discourse information helps with the identification of the key discussion point, i.e., “which type of battery to use”, by revealing the discussion flow.
",1 Introduction,[0],[0]
"To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009).",1 Introduction,[0],[0]
"However, automatic discourse parsing in dialogues is still a challenging problem (Perret et al., 2016).",1 Introduction,[0],[0]
"Moreover, acquiring human annotation on discourse relations is a timeconsuming and expensive process, and does not
974
scale for large datasets.
",1 Introduction,[0],[0]
"In this paper, we propose a joint modeling approach to select salient phrases reflecting key discussion points as well as label the discourse relations between speaker turns in spoken meetings.",1 Introduction,[0],[0]
We hypothesize that leveraging the interaction between content and discourse has the potential to yield better prediction performance on both phrase-based content selection and discourse relation prediction.,1 Introduction,[0],[0]
"Specifically, we utilize argumentative discourse relations as defined in Twente Argument Schema (TAS) (Rienks et al., 2005), where discussions are organized into tree structures with discourse relations labeled between nodes (as shown in Figure 1).",1 Introduction,[0],[0]
Algorithms for joint learning and joint inference are proposed for our model.,1 Introduction,[0],[0]
We also present a variation of our model to treat discourse relations as latent variables when true labels are not available for learning.,1 Introduction,[0],[0]
"We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (Wang and Cardie, 2013; Mehdad et al., 2014).",1 Introduction,[0],[0]
"Combined with the predicted discourse structure, a visualization tool can be exploited to display conversation flow to support intelligent meeting assistant systems.
",1 Introduction,[0],[0]
"To the best of our knowledge, our work is the first to jointly model content and discourse relations in meetings.",1 Introduction,[0],[0]
"We test our model with two meeting corpora — the AMI corpus (Carletta et al., 2006) and the ICSI corpus (Janin et al., 2003).",1 Introduction,[0],[0]
"Experimental results show that our model yields an accuracy of 63.2 on phrase selection, which is significantly better than a classifier based on Support Vector Machines (SVM).",1 Introduction,[0],[0]
Our discourse prediction component also obtains better accuracy than a state-of-the-art neural networkbased approach (59.2 vs. 54.2).,1 Introduction,[0],[0]
"Moreover, our model trained with latent discourse outperforms SVMs on both AMI and ICSI corpora for phrase selection.",1 Introduction,[0],[0]
We further evaluate the usage of selected phrases as extractive meeting summaries.,1 Introduction,[0],[0]
"Results evaluated by ROUGE (Lin and Hovy, 2003) demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in Liu et al. (2009).
",1 Introduction,[0],[0]
"Moreover, since both content and discourse structure are critical for building shared understanding among participants (Mulder et al., 2002;
Mercer, 2004), we further investigate whether our learned model can be utilized to predict the consistency among team members’ understanding of their group decisions.",1 Introduction,[0],[0]
"This task is first defined as consistency of understanding (COU) prediction by Kim and Shah (2016), who have labeled a portion of AMI discussions with consistency or inconsistency labels.",1 Introduction,[0],[0]
We construct features from our model predictions to capture different discourse patterns and word entrainment scores for discussion with different COU level.,1 Introduction,[0],[0]
"Results on AMI discussions show that SVM classifiers trained with our features significantly outperform the state-ofthe-art results (Kim and Shah, 2016) (F1: 63.1 vs. 50.5) and non-trivial baselines.
",1 Introduction,[0],[0]
The rest of the paper is structured as follows: we first summarize related work in Section 2.,1 Introduction,[0],[0]
The joint model is presented in Section 3.,1 Introduction,[0],[0]
"Datasets and experimental setup are described in Section 4, which is followed by experimental results (Section 5).",1 Introduction,[0],[0]
We then study the usage of our model for predicting consistency of understanding in groups in Section 6.,1 Introduction,[0],[0]
We finally conclude in Section 7.,1 Introduction,[0],[0]
"Our model is inspired by research work that leverages discourse structure for identifying salient content in conversations, which is still largely reliant on features derived from gold-standard discourse labels (McKeown et al., 2007; Murray et al., 2010; Bokaei et al., 2016).",2 Related Work,[0],[0]
"For instance, adjacency pairs, which are paired utterances with question-answer or offer-accept relations, are found to frequently appear in meeting summaries together and thus are utilized to extract summary-worthy utterances by Galley (2006).",2 Related Work,[0],[0]
There is much less work that jointly predicts the importance of content along with the discourse structure in dialogus.,2 Related Work,[0],[0]
Oya and Carenini (2014) employs Dynamic Conditional Random Field to recognize sentences in email threads for use in summary as well as their dialogue acts.,2 Related Work,[0],[0]
Only local discourse structures from adjacent utterances are considered.,2 Related Work,[0],[0]
"Our model is built on tree structures, which captures more global information.
",2 Related Work,[0],[0]
Our work is also in line with keyphrase identification or phrase-based summarization for conversations.,2 Related Work,[0],[0]
"Due to the noisy nature of dialogues, recent work focuses on identifying summary-worthy phrases from meetings (Fernández et al., 2008; Riedhammer et al., 2010) or email threads (Loza
et al., 2014).",2 Related Work,[0],[0]
"For instance, Wang and Cardie (2012) treat the problem as an information extraction task, where summary-worthy content represented as indicator and argument pairs is identified by an unsupervised latent variable model.",2 Related Work,[0],[0]
"Our work also targets at detecting salient phrases from meetings, but focuses on the joint modeling of critical discussion points and discourse relations held between them.
",2 Related Work,[0],[0]
"For the area of discourse analysis in dialogues, a significant amount of work has been done in predicting local discourse structures, such as recognizing dialogue acts or social acts of adjacent utterances from phone conversations (Stolcke et al., 2000; Kalchbrenner and Blunsom, 2013; Ji et al., 2016), spoken meetings (Dielmann and Renals, 2008), or emails (Cohen et al., 2004).",2 Related Work,[0],[0]
"Although discourse information from non-adjacent turns has been studied in the context of online discussion forums (Ghosh et al., 2014) and meetings (HakkaniTur, 2009), none of them models the effect of discourse structure on content selection, which is a gap that this work fills in.",2 Related Work,[0],[0]
"In this section, we first present our joint model in Section 3.1.",3 The Joint Model of Content and Discourse Relations,[0],[0]
"The algorithms for learning and inference are described in Sections 3.2 and 3.3, followed by feature description (Section 3.4).",3 The Joint Model of Content and Discourse Relations,[0],[0]
Our proposed model learns to jointly perform phrase-based content selection and discourse relation prediction by making use of the interaction between the two sources of information.,3.1 Model Description,[0],[0]
"Assume that a meeting discussion is denoted as x, where x consists of a sequence of discourse units x = {x1, x2, · · · , xn}.",3.1 Model Description,[0],[0]
Each discourse unit can be a complete speaker turn or a part of it.,3.1 Model Description,[0],[0]
"As demonstrated in Figure 1, a tree-structured discourse diagram is constructed for each discussion with each discourse unit xi as a node of the tree.",3.1 Model Description,[0],[0]
"In this work, we consider the argumentative discourse structure by Twente Argument Schema (TAS) (Rienks et al., 2005).",3.1 Model Description,[0],[0]
"For each node xi, it is attached to another node xi′ (i′ < i) in the discussion, and a discourse relation di is hold on the link 〈xi, xi′〉 (di is empty if xi is the root).",3.1 Model Description,[0],[0]
"Let t denote the set of links 〈xi, xi′〉 in x.",3.1 Model Description,[0],[0]
"Following previous work on discourse analysis in meetings (Rienks et al., 2005;
Hakkani-Tur, 2009), we assume that the attachment structure between discourse units are given during both training and testing.
",3.1 Model Description,[0],[0]
"A set of candidate phrases are extracted from each discourse unit xi, from which salient phrases that contain gist information will be identified.",3.1 Model Description,[0],[0]
"We obtain constituent and dependency parses for utterances using Stanford parser (Klein and Manning, 2003).",3.1 Model Description,[0],[0]
"We restrict eligible candidate to be a noun phrase (NP), verb phrase (VP), prepositional phrase (PP), or adjective phrase (ADJP) with at most 5 words, and its head word cannot be a stop word.1",3.1 Model Description,[0],[0]
"If a candidate is a parent of another candidate in the constituent parse tree, we will only keep the parent.",3.1 Model Description,[0],[0]
We further merge a verb and a candidate noun phrase into one candidate if the later is the direct object or subject of the verb.,3.1 Model Description,[0],[0]
"For example, from utterance “let’s use a rubber case as well as rubber buttons”, we can identify candidates “use a rubber case” and “rubber buttons”.",3.1 Model Description,[0],[0]
"For xi, the set of candidate phrases are denoted as ci = {ci,1, ci,2, · · · , ci,mi}, where mi is the number of candidates.",3.1 Model Description,[0],[0]
"ci,j takes a value of 1 if the corresponding candidate is selected as salient phrase; otherwise, ci,j is equal to 0.",3.1 Model Description,[0],[0]
"All candidate phrases in discussion x are represented as c.
We then define a log-linear model with feature parameters w for the candidate phrases c and discourse relations d in x as:
p(c,d|x,w) ∝",3.1 Model Description,[0],[0]
"exp[w · Φ(c,d,x)]
∝ exp[w · n∑
i=1,<xi,xi′>∈t φ(ci, di, di′ ,x)]
∝",3.1 Model Description,[0],[0]
"exp[ n∑
i=1,<xi,xi′>∈t (wc ·
mi∑
j=1
φc(ci,j ,x)
+ wd · φd(di, di′ ,x) + wcd · mi∑
j=1
φcd(ci,j , di,x))",3.1 Model Description,[0],[0]
"]
(1)
Here Φ(·) and φ(·) denote feature vectors.",3.1 Model Description,[0],[0]
"We utilize three types of feature functions: (1) content-only features φc(·), which capture the importance of phrases, (2) discourse-only features φd(·), which characterize the (potentially higherorder) discourse relations, and (3) joint features of content and discourse φcd(·), which model the interaction between the two.",3.1 Model Description,[0],[0]
"wc, wd, and wcd are
1Other methods for mining candidate phrases, such as frequency-based method (Liu et al., 2015), will be studied for future work.
",3.1 Model Description,[0],[0]
corresponding feature parameters.,3.1 Model Description,[0],[0]
Detailed feature descriptions can be found in Section 3.4.,3.1 Model Description,[0],[0]
Discourse Relations as Latent Variables.,3.1 Model Description,[0],[0]
"As we mentioned in the introduction, acquiring labeled training data for discourse relations is a timeconsuming process since it would require human annotators to inspect the full discussions.",3.1 Model Description,[0],[0]
"Therefore, we further propose a variation of our model where it treats the discourse relations as latent variables, so that p(c|x,w) = ∑d p(c,d|x,w).",3.1 Model Description,[0],[0]
Its learning algorithm is slightly different as described in the next section.,3.1 Model Description,[0],[0]
"For learning the model parameters w, we employ an algorithm based on SampleRank (Rohanimanesh et al., 2011), which is a stochastic structure learning method.",3.2 Joint Learning for Parameter Estimation,[0],[0]
"In general, the learning algorithm constructs a sequence of configurations for sample labels as a Markov chain Monte Carlo (MCMC) chain based on a task-specific loss function, where stochastic gradients are distributed across the chain.
",3.2 Joint Learning for Parameter Estimation,[0],[0]
The full learning procedure is described in Algorithm 1.,3.2 Joint Learning for Parameter Estimation,[0],[0]
"To start with, the feature weights w is initialized with each value randomly drawn from [−1, 1].",3.2 Joint Learning for Parameter Estimation,[0],[0]
Multiple epochs are run through all samples.,3.2 Joint Learning for Parameter Estimation,[0],[0]
"For each sample, we randomly initialize the assignment of candidate phrases labels c and discourse relations d.",3.2 Joint Learning for Parameter Estimation,[0],[0]
Then an MCMC chain is constructed with a series of configurations σ =,3.2 Joint Learning for Parameter Estimation,[0],[0]
"(c, d): at each step, it first samples a discourse structure d based on the proposal distribution q(d′|d,x), and then samples phrase labels conditional on the new discourse relations and previous phrase labels based on q(c′|c,d′,x).",3.2 Joint Learning for Parameter Estimation,[0],[0]
Local search is used for both proposal distributions.2 The new configuration is accepted if it improves on the score by ω(σ′).,3.2 Joint Learning for Parameter Estimation,[0],[0]
"The parameters w are updated accordingly.
",3.2 Joint Learning for Parameter Estimation,[0],[0]
"For the scorer ω, we use a weighted combination of F1 scores of phrase selection (F1c) and discourse relation prediction (F1d): ω(σ) = α · F1c + (1− α) · F1d.",3.2 Joint Learning for Parameter Estimation,[0],[0]
"We fix α to 0.1.
",3.2 Joint Learning for Parameter Estimation,[0],[0]
"When discourse relations are treated as latent, we initialize discourse relations for each sample with a label in {1, 2, . . .",3.2 Joint Learning for Parameter Estimation,[0],[0]
",K} if there are K relations indicated, and we only use F1c as the scorer.
",3.2 Joint Learning for Parameter Estimation,[0],[0]
"2For future work, we can explore other proposal distributions that utilize the conditional distribution of salient phrases given sampled discourse relations.
",3.2 Joint Learning for Parameter Estimation,[0],[0]
"Input : X = {x}: discussions in the training set, η: learning rate, : number of epochs, δ: number of sampling rounds, ω(·): scoring function, Φ(·): feature functions Output: feature weights 1|W| ∑ w∈W",3.2 Joint Learning for Parameter Estimation,[0],[0]
w,3.2 Joint Learning for Parameter Estimation,[0],[0]
Initialize,3.2 Joint Learning for Parameter Estimation,[0],[0]
"w; W ← {w}; for e = 1 to do
for x in X do // Initialize configuration for
x Initialize c and d; σ =",3.2 Joint Learning for Parameter Estimation,[0],[0]
"(c,d); for s = 1 to δ do
// New configuration via local search d′ ∼ qd(·|x,d); c′ ∼ qd(·|x, c,d′); σ′ = (c′,d′); σ+ = arg maxσ̃∈{σ,σ′} ω(σ̃); σ− = arg minσ̃∈{σ,σ′} ω(σ̃);",3.2 Joint Learning for Parameter Estimation,[0],[0]
"∇̂ = Φ(σ+)− Φ(σ−); ∆ω = ω(σ+)− ω(σ−); // Update parameters if w · ∇̂ < ∆ω & ∆ω 6= 0 then
w← w + η · ∇̂; Add w inW;
end //",3.2 Joint Learning for Parameter Estimation,[0],[0]
"Accept or reject new
configuration if σ+ == σ′ then
σ = σ′ end
end end
end Algorithm 1: SampleRank-based joint learning.",3.2 Joint Learning for Parameter Estimation,[0],[0]
"Given a new sample x and learned parameters w, we predict phrase labels and discourse relations as arg maxc,d p(c,d|x,w).
",3.3 Joint Inference for Prediction,[0],[0]
"Dynamic programming can be employed to carry out joint inference, however, it would be time-consuming since our objective function has a large search space for both content and discourse labels.",3.3 Joint Inference for Prediction,[0],[0]
Hence we propose an alternating optimizing algorithm to search for c and d iteratively.,3.3 Joint Inference for Prediction,[0],[0]
"Concretely, for each iteration, we first optimize on d by maximizing
∑n i=1,<xi,x′i>∈t(wd · φd(di, di′ ,x) +",3.3 Joint Inference for Prediction,[0],[0]
"wcd ·∑mi
j=1 φcd(ci,j , di,x)).",3.3 Joint Inference for Prediction,[0],[0]
"Message-passing (Smith and Eisner, 2008) is used to find the best d.
In the second step, we search for c that maximizes ∑n i=1,<xi,x′i>∈t(wc · ∑mi j=1 φc(ci,j ,x) +
wcd · ∑mi
j=1 φcd(ci,j , di,x)).",3.3 Joint Inference for Prediction,[0],[0]
We believe that candidate phrases based on the same concepts should have the same predicted label.,3.3 Joint Inference for Prediction,[0],[0]
"Therefore, candidates of the same phrase type and sharing the same head word are grouped into one cluster.",3.3 Joint Inference for Prediction,[0],[0]
"We then cast our task as an integer linear programming
problem.3",3.3 Joint Inference for Prediction,[0],[0]
"We optimize our objective function under constraints: (1) ci,j = ci′,j′ if ci,j and ci′,j′ are in the same cluster, and (2) ci,j ∈ {0, 1}, ∀i, j.
The inference process is the same for models trained with latent discourse relations.",3.3 Joint Inference for Prediction,[0],[0]
"We use features that characterize content, discourse relations, and the combination of both.",3.4 Features,[0],[0]
Content Features.,3.4 Features,[0],[0]
"For modeling the salience of content, we calculate the minimum, maximum, and average of TF-IDF scores of words and number of content words in each phrase based on the intuition that important phrases tend to have more content words with high TF-IDF scores (Fernández et al., 2008).",3.4 Features,[0],[0]
"We also consider whether the head word of the phrase has been mentioned in preceding turn, which implies the focus of a discussion.",3.4 Features,[0],[0]
The size of the cluster each phrase belongs to is also included.,3.4 Features,[0],[0]
Number of POS tags and phrase types are counted to characterize the syntactic structure.,3.4 Features,[0],[0]
"Previous work (Wang and Cardie, 2012) has found that a discussion usually ends with decision-relevant information.",3.4 Features,[0],[0]
We thus identify the absolute and relative positions of the turn containing the candidate phrase in the discussion.,3.4 Features,[0],[0]
"Finally, we record whether the candidate phrase is uttered by the main speaker, who speakers the most words in the discussion.",3.4 Features,[0],[0]
Discourse Features.,3.4 Features,[0],[0]
"For each discourse unit, we collect the dialogue act types of the current unit and its parent node in discourse tree, whether there is any adjacency pair held between the two nodes (Hakkani-Tur, 2009), and the Jaccard similarity between them.",3.4 Features,[0],[0]
"We record whether two turns are uttered by the same speaker, for example, ELABORATION is commonly observed between the turns from the same participant.",3.4 Features,[0],[0]
We also calculate the number of candidate phrases based on the observation that OPTION and SPECIALIZATION tend to contain more informative words than POSITIVE feedback.,3.4 Features,[0],[0]
Length of the discourse unit is also relevant.,3.4 Features,[0],[0]
"Therefore, we compute the time span and number of words.",3.4 Features,[0],[0]
"To incorporate global structure features, we encode the depth of the node in the discourse tree and the
3We use lpsolve: http://lpsolve.",3.4 Features,[0],[0]
"sourceforge.net/5.5/.
number of its siblings.",3.4 Features,[0],[0]
"Finally, we include an order-2 discourse relation feature that encodes the relation between current discourse unit and its parent, and the relation between the parent and its grandparent if it exists.",3.4 Features,[0],[0]
Joint Features.,3.4 Features,[0],[0]
"For modeling the interaction between content and discourse, the discourse relation is added to each content feature to compose a joint feature.",3.4 Features,[0],[0]
"For example, if candidate c in discussion x has a content feature",3.4 Features,[0],[0]
"φ[avg−TFIDF ](c,x) with a value of 0.5, and its discourse relation d is POSITIVE, then the joint feature takes the form of φ[avg−TFIDF,Positive](c, d,x) = 0.5.",3.4 Features,[0],[0]
Meeting Corpora.,4 Datasets and Experimental Setup,[0],[0]
"We evaluate our joint model on two meeting corpora with rich annotations: the AMI meeting corpus (Carletta et al., 2006) and the ICSI meeting corpus (Janin et al., 2003).",4 Datasets and Experimental Setup,[0],[0]
"AMI corpus consists of 139 scenario-driven meetings, and ICSI corpus contains 75 naturally occurring meetings.",4 Datasets and Experimental Setup,[0],[0]
"Both of the corpora are annotated with dialogue acts, adjacency pairs, and topic segmentation.",4 Datasets and Experimental Setup,[0],[0]
"We treat each topic segment as one discussion, and remove discussions with less than 10 turns or labeled as “opening” and “chitchat”.",4 Datasets and Experimental Setup,[0],[0]
"694 discussions from AMI and 1139 discussions from ICSI are extracted, and these two datasets are henceforth referred as AMI-FULL and ICSIFULL.",4 Datasets and Experimental Setup,[0],[0]
Acquiring Gold-Standard Labels.,4 Datasets and Experimental Setup,[0],[0]
Both corpora contain human constructed abstractive summaries and extractive summaries on meeting level.,4 Datasets and Experimental Setup,[0],[0]
"Short abstracts, usually in one sentence, are constructed by meeting participants — participant summaries, and external annotators — abstractive summaries.",4 Datasets and Experimental Setup,[0],[0]
"Dialogue acts that contribute to important output of the meeting, e.g. decisions, are identified and used as extractive summaries, and some of them are also linked to the corresponding abstracts.
",4 Datasets and Experimental Setup,[0],[0]
"Since the corpora do not contain phrase-level importance annotation, we induce gold-standard labels for candidate phrases based on the following rule.",4 Datasets and Experimental Setup,[0],[0]
A candidate phrase is considered as a positive sample if its head word is contained in any abstractive summary or participant summary.,4 Datasets and Experimental Setup,[0],[0]
"On average, 71.9 candidate phrases are identified per discussion for AMI-FULL with 31.3% labeled as positive, and 73.4 for ICSI-FULL with 24.0% of them as positive samples.
",4 Datasets and Experimental Setup,[0],[0]
"Furthermore, a subset of discussions in AMI-
FULL are annotated with discourse structure and relations based on Twente Argumentation Schema (TAS) by Rienks et al. (2005)4.",4 Datasets and Experimental Setup,[0],[0]
A tree-structured argument diagram (as shown in Figure 1) is created for each discussion or a part of the discussion.,4 Datasets and Experimental Setup,[0],[0]
"The nodes of the tree contain partial or complete speaker turns, and discourse relation types are labeled on the links between the nodes.",4 Datasets and Experimental Setup,[0],[0]
"In total, we have 129 discussions annotated with discourse labels.",4 Datasets and Experimental Setup,[0],[0]
This dataset is called AMI-SUB hereafter.,4 Datasets and Experimental Setup,[0],[0]
Experimental Setup.,4 Datasets and Experimental Setup,[0],[0]
5-fold cross validation is used for all experiments.,4 Datasets and Experimental Setup,[0],[0]
"All real-valued features are uniformly normalized to [0,1].",4 Datasets and Experimental Setup,[0],[0]
"For the joint learning algorithm, we use 10 epochs and carry out 50 sampling for MCMC for each training sample.",4 Datasets and Experimental Setup,[0],[0]
The learning rate is set to 0.01.,4 Datasets and Experimental Setup,[0],[0]
"We run the learning algorithm for 20 times, and use the average of the learned weights as the final parameter values.",4 Datasets and Experimental Setup,[0],[0]
"For models trained with latent discourse relations, we fix the number of relations to 9.",4 Datasets and Experimental Setup,[0],[0]
Baselines and Comparisons.,4 Datasets and Experimental Setup,[0],[0]
"For both phrasebased content selection and discourse relation prediction tasks, we consider a baseline that always predicts the majority label (Majority).",4 Datasets and Experimental Setup,[0],[0]
"Previous work has shown that Support Vector Machines (SVMs)-based classifiers achieve state-of-the-art performance for keyphrase selection in meetings (Fernández et al., 2008; Wang and Cardie, 2013) and discourse parsing for formal text (Hernault et al., 2010).",4 Datasets and Experimental Setup,[0],[0]
"Therefore, we compare with linear SVM-based classifiers, trained with the same feature set of content features or discourse features.",4 Datasets and Experimental Setup,[0],[0]
We fix the trade-off parameter to 1.0 for all SVM-based experiments.,4 Datasets and Experimental Setup,[0],[0]
"For discourse relation prediction, we use one-vs-rest strategy to build multiple binary classifiers.5",4 Datasets and Experimental Setup,[0],[0]
"We also compare with a state-of-the-art discourse parser (Ji et al., 2016), which employs neural language model to predict discourse relations.",4 Datasets and Experimental Setup,[0],[0]
Here we present the experimental results on phrase-based content selection and discourse relation prediction.,5.1 Phrase Selection and Discourse Labeling,[0],[0]
"We experiment with two variations of our joint model: one is trained on goldstandard discourse relations, the other is trained by
4There are 9 types of relations in TAS: POSITIVE, NEGATIVE, UNCERTAIN, REQUEST, SPECIALIZATION, ELABORATION, OPTION, OPTION EXCLUSION, and SUBJECT-TO.
5Multi-class classifier was also experimented with, but gave inferior performance.
",5.1 Phrase Selection and Discourse Labeling,[0],[0]
treating discourse relations as latent models as described in Section 3.1.,5.1 Phrase Selection and Discourse Labeling,[0],[0]
"Remember that we have gold-standard argument diagrams on the AMISUB dataset, we can thus conduct experiments by assuming the True Attachment Structure is given for latent versions.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"When argument diagrams are not available, we build a tree among the turns in each discussion as follows.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
Two turns are attached if there is any adjacency pair between them.,5.1 Phrase Selection and Discourse Labeling,[0],[0]
"If one turn is attached to more than one previous turns, the closest one is considered.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"For the rest of the turns, they are attached to the preceding turn.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"This construction is applied on AMI-FULL and ICSIFULL.
",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"We also investigate whether joint learning and joint inference can produce better prediction per-
formance.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"We consider joint learning with separate inference, where only content features or discourse features are used for prediction (SeparateInference).",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"We further study learning separate classifiers for content selection and discourse relations without joint features (Separate-Learn).
",5.1 Phrase Selection and Discourse Labeling,[0],[0]
We first show the phrase selection and discourse relation prediction results on AMI-SUB in Tables 1 and 2.,5.1 Phrase Selection and Discourse Labeling,[0],[0]
"As shown in Table 1, our models, trained with gold-standard discourse relations or latent ones with true attachment structure, yield significant better accuracy and F1 scores than SVM-based classifiers trained with the same feature sets for phrase selection (paired t-test, p < 0.05).",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"Our joint learning model with separate inference also outperforms neural network-based discourse parsing model (Ji et al., 2016) in Table 2.
",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"Moreover, Tables 1 and 2 demonstrate that joint learning usually produces superior performance for both tasks than separate learning.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
"Combined with joint inference, our model obtains the best accuracy and F1 on phrase selection.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
This indicates that leveraging the interplay between content and discourse boost the prediction performance.,5.1 Phrase Selection and Discourse Labeling,[0],[0]
"Similar results are achieved on AMI-FULL and ICSIFULL in Table 3, where latent discourse relations without true attachment structure are employed for training.",5.1 Phrase Selection and Discourse Labeling,[0],[0]
We further evaluate whether the prediction of the content selection component can be used for summarizing the key points on discussion level.,5.2 Phrase-Based Extractive Summarization,[0],[0]
"For each discussion, salient phrases identified by our model are concatenated in sequence for use as the summary.",5.2 Phrase-Based Extractive Summarization,[0],[0]
We consider two types of gold-standard summaries.,5.2 Phrase-Based Extractive Summarization,[0],[0]
"One is utterance-level extractive summary, which consists of human labeled summaryworthy utterances.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"The other is abstractive sum-
mary, where we collect human abstract with at least one link from summary-worthy utterances.
",5.2 Phrase-Based Extractive Summarization,[0],[0]
"We calculate scores based on ROUGE (Lin and Hovy, 2003), which is a popular tool for evaluating text summarization (Gillick et al., 2009; Liu and Liu, 2010).",5.2 Phrase-Based Extractive Summarization,[0],[0]
ROUGE-1 (unigrams) and ROUGE-SU4 (skip-bigrams with at most 4 words in between) are used.,5.2 Phrase-Based Extractive Summarization,[0],[0]
"Following previous work on meeting summarization (Riedhammer et al., 2010; Wang and Cardie, 2013), we consider two dialogue act-level summarization baselines: (1) LONGEST DA in each discussion is selected as the summary, and (2) CENTROID DA, the one with the highest TF-IDF similarity with all DAs in the discussion.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"We also compare with an unsupervised keyword extraction approach by Liu et al. (2009), where word importance is estimated by its TF-IDF score, POS tag, and the salience of its corresponding sentence.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"With the same candidate phrases as in our model, we extend Liu et al. (2009) by scoring each phrase based on its average score of the words.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"Top phrases, with the same number of phrases output by our model, are included into the summaries.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"Finally, we compare with summaries consisting of salient phrases predicted by an SVM classifier trained with our content features.
",5.2 Phrase-Based Extractive Summarization,[0],[0]
"From the results in Table 4, we can see that phrase-based extractive summarization methods can yield better ROUGE scores for recall and F1 than baselines that extract the whole sentences.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"Meanwhile, our system significantly out-
performs the SVM-based classifiers when evaluated on ROUGE recall and F1, while achieving comparable precision.",5.2 Phrase-Based Extractive Summarization,[0],[0]
"Compared to Liu et al. (2009), our system also yields better results on all metrics.
",5.2 Phrase-Based Extractive Summarization,[0],[0]
Sample summaries by our model along with two baselines are displayed in Figure 2.,5.2 Phrase-Based Extractive Summarization,[0],[0]
Utterancelevel extract-based baselines unavoidably contain disfluency and unnecessary details.,5.2 Phrase-Based Extractive Summarization,[0],[0]
Our phrasebased extractive summary is able to capture the key points from both the argumentation process and important outcomes of the conversation.,5.2 Phrase-Based Extractive Summarization,[0],[0]
This implies that our model output can be used as input for an abstractive summarization system.,5.2 Phrase-Based Extractive Summarization,[0],[0]
It can also facilitate the visualization of decision-making processes.,5.2 Phrase-Based Extractive Summarization,[0],[0]
Features Analysis.,5.3 Further Analysis and Discussions,[0],[0]
We first discuss salient features with top weights learned by our joint model.,5.3 Further Analysis and Discussions,[0],[0]
"For content features, main speaker tends to utter more salient content.",5.3 Further Analysis and Discussions,[0],[0]
"Higher TF-IDF scores also
indicate important phrases.",5.3 Further Analysis and Discussions,[0],[0]
"If a phrase is mentioned in previous turn and repeated in the current turn, it is likely to be a key point.",5.3 Further Analysis and Discussions,[0],[0]
"For discourse features, structure features matter the most.",5.3 Further Analysis and Discussions,[0],[0]
"For instance, jointly modeling the discourse relation of the parent node along with the current node can lead to better inference.",5.3 Further Analysis and Discussions,[0],[0]
An example is that giving more details on the proposal (ELABORATION) tends to lead to POSITIVE feedback.,5.3 Further Analysis and Discussions,[0],[0]
"Moreover, REQUEST usually appears close to the root of the argument diagram tree, while POSITIVE feedback is usually observed on leaves.",5.3 Further Analysis and Discussions,[0],[0]
Adjacency pairs also play an important role for discourse prediction.,5.3 Further Analysis and Discussions,[0],[0]
"For joint features, features that composite “phrase mentioned in previous turn” and relation POSITIVE feedback or REQUEST yield higher weight, which are indicators for both key phrases and discourse relations.",5.3 Further Analysis and Discussions,[0],[0]
We also find that main speaker information composite with ELABORATION and UNCERTAIN are associated with high weights.,5.3 Further Analysis and Discussions,[0],[0]
Error Analysis and Potential Directions.,5.3 Further Analysis and Discussions,[0],[0]
"Taking a closer look at our prediction results, one major source of incorrect prediction for phrase selection is based on the fact that similar concepts might be expressed in different ways, and our model predicts inconsistently for different variations.",5.3 Further Analysis and Discussions,[0],[0]
"For example, participants use both “thick” and “two centimeters” to talk about the desired shape of a remote control.",5.3 Further Analysis and Discussions,[0],[0]
"However, our model does not group them into the same cluster and later makes different predictions.",5.3 Further Analysis and Discussions,[0],[0]
"For future work, semantic similarity with context information can be leveraged to produce better clustering results.",5.3 Further Analysis and Discussions,[0],[0]
"Furthermore, identifying discourse relations in dialogues is still a challenging task.",5.3 Further Analysis and Discussions,[0],[0]
"For instance, “I wouldn’t choose a plastic case” should be labeled as OPTION EXCLUSION, if the previous turns talk about different options.",5.3 Further Analysis and Discussions,[0],[0]
"Otherwise, it can be labeled as NEGATIVE.",5.3 Further Analysis and Discussions,[0],[0]
"Therefore, models that better handle semantics and context need to be considered.",5.3 Further Analysis and Discussions,[0],[0]
"As discussed in previous work (Mulder et al., 2002; Mercer, 2004), both content and discourse structure are critical for building shared understanding among discussants.",6 Predicting Consistency of Understanding,[0],[0]
"In this section, we test whether our joint model can be utilized to predict the consistency among team members’ under-
standing of their group decisions, which is defined as consistency of understanding (COU) in Kim and Shah (2016).
",6 Predicting Consistency of Understanding,[0],[0]
"Kim and Shah (2016) establish gold-standard COU labels on a portion of AMI discussions, by comparing participant summaries to determine whether participants report the same decisions.",6 Predicting Consistency of Understanding,[0],[0]
"If all decision points are consistent, the associated topic discussion is labeled as consistent; otherwise, the discussion is identified as inconsistent.",6 Predicting Consistency of Understanding,[0],[0]
Their annotation covers the AMI-SUB dataset.,6 Predicting Consistency of Understanding,[0],[0]
"Therefore, we run the prediction experiments on AMI-SUB by using the same annotation.",6 Predicting Consistency of Understanding,[0],[0]
"Out of total 129 discussions in AMI-SUB, 86 discussions are labeled as consistent and 43 are inconsistent.
",6 Predicting Consistency of Understanding,[0],[0]
We construct three types of features by using our model’s predicted labels.,6 Predicting Consistency of Understanding,[0],[0]
"Firstly, we learn two versions of our model based on the “consistent” discussions and the “inconsistent” ones in the training set, with learned parameters wcon and wincon.",6 Predicting Consistency of Understanding,[0],[0]
"For a discussion in the test set, these two models output two probabilities pcon = maxc,d P (c,d|x,wcon) and pincon = maxc,d P (c,d|x,wincon).",6 Predicting Consistency of Understanding,[0],[0]
"We use pcon − pincon as a feature.
",6 Predicting Consistency of Understanding,[0],[0]
"Furthermore, we consider discourse relations of length one and two from the discourse structure tree.",6 Predicting Consistency of Understanding,[0],[0]
"Intuitively, some discourse relations, e.g., ELABORATION followed by multiple POSITIVE feedback, imply consistent understanding.
",6 Predicting Consistency of Understanding,[0],[0]
"The third feature is based on word entrainment, which has been shown to correlate with task success for groups (Nenkova et al., 2008).",6 Predicting Consistency of Understanding,[0],[0]
"Using the formula in Nenkova et al. (2008), we compute the average word entrainment between the main speaker who utters the most words and all the other participants.",6 Predicting Consistency of Understanding,[0],[0]
The content words in the salient phrases predicted by our model is considered for entrainment computation.,6 Predicting Consistency of Understanding,[0],[0]
Results.,6 Predicting Consistency of Understanding,[0],[0]
Leave-one-out is used for experiments.,6 Predicting Consistency of Understanding,[0],[0]
"For training, our features are constructed from gold-standard phrase and discourse labels.",6 Predicting Consistency of Understanding,[0],[0]
Predicted labels by our model is used for constructing features during testing.,6 Predicting Consistency of Understanding,[0],[0]
SVM-based classifier is used for experimenting with different sets of features output by our model.,6 Predicting Consistency of Understanding,[0],[0]
A majority class baseline is constructed as well.,6 Predicting Consistency of Understanding,[0],[0]
We also consider an SVM classifier trained with ngram features (unigrams and bigrams).,6 Predicting Consistency of Understanding,[0],[0]
"Finally, we compare with the state-of-the-art method in Kim and Shah (2016), where discourse-relevant features and head ges-
ture features are utilized in Hidden Markov Models to predict the consistency label.
",6 Predicting Consistency of Understanding,[0],[0]
The results are displayed in Table 5.,6 Predicting Consistency of Understanding,[0],[0]
All SVMs trained with our features surpass the ngrams-based baseline.,6 Predicting Consistency of Understanding,[0],[0]
"Especially, the discourse features, word entrainment feature, and the combination of the three, all significantly outperform the state-of-theart system by Kim and Shah (2016).6",6 Predicting Consistency of Understanding,[0],[0]
We presented a joint model for performing phraselevel content selection and discourse relation prediction in spoken meetings.,7 Conclusion,[0],[0]
Experimental results on AMI and ICSI meeting corpora showed that our model can outperform state-of-the-art methods for both tasks.,7 Conclusion,[0],[0]
Further evaluation on the task of predicting consistency-of-understanding in meetings demonstrated that classifiers trained with features constructed from our model output produced superior performance compared to the state-of-the-art model.,7 Conclusion,[0],[0]
This provides an evidence of our model being successfully applied in other prediction tasks in spoken meetings.,7 Conclusion,[0],[0]
This work was supported in part by National Science Foundation Grant IIS-1566382 and a GPU gift from Nvidia.,Acknowledgments,[0],[0]
"We thank three anonymous reviewers for their valuable suggestions on various aspects of this work.
",Acknowledgments,[0],[0]
"6We also experiment with other popular classifiers, e.g. logistic regression or decision tree, and similar trend is respected.",Acknowledgments,[0],[0]
We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns.,abstractText,[0],[0]
A variation of our model is also discussed when discourse relations are treated as latent variables.,abstractText,[0],[0]
Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrasebased content selection and discourse relation prediction tasks.,abstractText,[0],[0]
We also evaluate our model on predicting the consistency among team members’ understanding of their group decisions.,abstractText,[0],[0]
Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.,abstractText,[0],[0]
Joint Modeling of Content and Discourse Relations in Dialogues,title,[0],[0]
"With a corpus of scientific literature, we can observe the complex and intricate process of scientific progress.",1 Introduction,[0],[0]
"We can learn the major topics in journal articles and conference proceedings, follow authors who are prolific and influential, and find papers that are highly cited.",1 Introduction,[0],[0]
"The huge number of publications
and authors, however, makes it practically impossible to attain any deep or detailed understanding beyond the very broad trends.",1 Introduction,[0],[0]
"For example, if we want to identify authors who are particularly influential in a specific research field, it is difficult to do so without the aid of automatic analysis.
",1 Introduction,[0],[0]
"Online publication archives, such as Google Scholar, provide near real-time metrics of schol-
ar X
iv :1
70 6.
00 59
3v 1
[ cs
.C L
] 2
J un
2 01
arly impact, such as the h-index (Hirsch, 2005), the journal impact factor (Garfield, 2006), and citation count.",1 Introduction,[0],[0]
"Those indices, however, are still at a coarse level of granularity.",1 Introduction,[0],[0]
"For example, both Michael Jordan and Richard Sutton are researchers with very high citation count and h-index, but they are authoritative in different topics, Jordan in the more general machine learning topic of statistical learning, and Sutton in the topic of reinforcement learning.",1 Introduction,[0.9998786544220722],"['For example, both Michael Jordan and Richard Sutton are researchers with very high citation counts and h-index, but they are authoritative in different topics, Jordan in the more general machine learning topic of statistical learning, and Sutton in the topic of reinforcement learning.']"
"It would be much more helpful to know that via topical authority scores, as shown in Figure 1.
",1 Introduction,[0],[0]
"Fortunately, various academic publication archives contain the full contents, references, and meta-data including titles, venues, and authors.",1 Introduction,[1.0],"['Fortunately, various academic publication archives contain the full contents, references, and meta-data including titles, venues, and authors.']"
"With such data, we can build and fit a model to partition researchers’ scholarly domain into topics at a much finer-grain and discover their academic authority within each topic.",1 Introduction,[0.9997764492821942],"['With such data, we can build and fit a model to partition researchers’ scholarly domains into topics at a much finer-grain and discover their academic authority within each topic.']"
"To do that, we propose a model named Latent Topical-Authority Indexing (LTAI), based on the latent Dirichlet allocation, to jointly model the topics, authors’ topical authority, and citations among the publications.
",1 Introduction,[0.9991899473103409],"['To do that, we propose a model named Latent Topical-Authority Indexing (LTAI), based on the LDA, to jointly model the topics, authors’ topical authority, and citations among the publications.']"
"We illustrate the modeling power of the LTAI with four corpora encompassing a diverse set of academic fields: CORA, Arxiv Physics, PNAS, and Citeseer.",1 Introduction,[0],[0]
"To show the improvements over other related models, we carry out prediction tasks on word, citation and authorship using the LTAI and compare the results with those of latent Dirichlet allocation (Blei et al., 2003), relational topic model (Chang and Blei, 2010), author-link topic model, and dynamic authorcite topic model (Kataria et al., 2011), as well as simple baselines of topical h-index.",1 Introduction,[0],[0]
"The results show that the LTAI outperforms these other models for all prediction tasks.
",1 Introduction,[0],[0]
The rest of this paper is organized as follows.,1 Introduction,[0],[0]
"In section 2, we describe related work, including models that are most similar to the LTAI, and describe how the LTAI fits in and contributes to the field.",1 Introduction,[0],[0]
"In section 3, we describe the LTAI model in detail and present the generative process.",1 Introduction,[0],[0]
"In section 4, we explain the algorithm for approximate inference, and in section 5, we present a faster algorithm for scalability.",1 Introduction,[0],[0]
"In section 6, we describe the experimental setup and in section 7, we present the results to show that the LTAI performs better than other related models for word, citation and authorship prediction.",1 Introduction,[0],[0]
"In this section, we review related papers, first in the field of NLP and ML-based analysis of scientific corpora, then the approaches based on the Bayesian topic models for academic corpora, and lastly joint models of topics, authors, and citations.",2 Related Work,[0],[0]
"In analyzing scientific corpora, previous research presents classifying scientific publications (Caragea et al., 2015), recommending yet unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al., 2014), triggering better model fit (He et al., 2015), incorporating authorship information to increase the content and link predictability (Sim et al., 2015), estimating a paper’s potential influence on academic community (Dong et al., 2015), and finding and classifying different functionalities of citation practices (Moravcsik and Murugesan, 1975; Teufel et al., 2006; Valenzuela et al., 2015).
",2 Related Work,[0],[0]
Several variants of topic modeling consider the relationship between topics and citations in academic corpora.,2 Related Work,[0],[0]
"Topic models that use text and citation network are divided into two types: (a) models that generate text given citation network (Dietz et al., 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al., 2008; Liu et al., 2009; Chang and Blei, 2010).",2 Related Work,[0],[0]
"While our model falls into the latter category, we also take into account the influence of the authors on the citation structure.
",2 Related Work,[0],[0]
"Most closely related to the LTAI are the citation author topic model (Tu et al., 2010), the authorlink topic model, and the dynamic author-cite topic model (Kataria et al., 2011).",2 Related Work,[0],[0]
"Similar to the LTAI, they are designed to capture the influence of the authors.",2 Related Work,[0],[0]
"However, these models infer authority by referencing only the citing papers’ text, while our authority is based on the predictive modeling of comparing both the citing and the cited papers.",2 Related Work,[0],[0]
"Furthermore, the LTAI defines a generative model of citations and publications by introducing a latent authority index, whereas the previous models assume the citation structure is given.",2 Related Work,[0],[0]
"the LTAI thus explicitly gives a topical authority index, which directly answers the question of which author increases the probability of a paper being cited.",2 Related Work,[0],[0]
"The LTAI models the complex relationship among the topics of publications, the topical authority of the authors, and the citations among these publications.",3 Latent Topical-Authority Indexing,[0],[0]
The generative process of the LTAI can be divided into two parts: content generation and citation network generation.,3 Latent Topical-Authority Indexing,[0],[0]
We make several assumptions in the LTAI to model citation structure of academic corpora.,3 Latent Topical-Authority Indexing,[0],[0]
"First, we assume a citation is more likely to occur between two papers that are similar in their topic proportions.",3 Latent Topical-Authority Indexing,[0],[0]
"Second, we assume that an author differs in their authority (i.e., potential to induce citation) for each topic, and an author’s topical authority positively correlates with the probability of citation among publications.",3 Latent Topical-Authority Indexing,[0],[0]
"Also, in the LTAI, when there are multiple authors in a single cited publication, their contribution of forming citations with respect to different citing papers varies according to their topical authority.",3 Latent Topical-Authority Indexing,[1.0],"['Also, in the LTAI, when there are multiple authors in a single cited publication, their contribution of forming citations with respect to different citing papers varies according to their topical authority.']"
"Lastly, we assign different concentration parameters for a pair of papers with and without citation.",3 Latent Topical-Authority Indexing,[0],[0]
"In this paper, we use terms positive and negative links to denote pairs of papers with and without citations respectively.
",3 Latent Topical-Authority Indexing,[0],[0]
"Figure 2 illustrates the graphical model of the LTAI, and we summarize the generative process of the LTAI, where the variables of the model are explained in the remainder of this section, as follows:
1.",3 Latent Topical-Authority Indexing,[0],[0]
"For each topic k, draw topic βk ∼ Dir(αβ).
2.",3 Latent Topical-Authority Indexing,[0],[0]
"For each document i:
(a) Draw topic proportion θi ∼ Dir(αθ).",3 Latent Topical-Authority Indexing,[0],[0]
"(b) For each word win:
i. Draw topic assignment zin|θi ∼ Mult(θi).",3 Latent Topical-Authority Indexing,[0],[0]
ii.,3 Latent Topical-Authority Indexing,[0],[0]
"Draw word win|zin, β1:K ∼ Mult(βzin).
",3 Latent Topical-Authority Indexing,[0],[0]
3.,3 Latent Topical-Authority Indexing,[0],[0]
"For each author a and topic k:
(a) Draw authority index ηak ∼ N (0, α−1η ).
",3 Latent Topical-Authority Indexing,[0],[0]
4.,3 Latent Topical-Authority Indexing,[0],[0]
"For each document pair from i to j:
(a) Draw influence proportion parameter πi←j ∼ Dir(πi).",3 Latent Topical-Authority Indexing,[0],[0]
(b),3 Latent Topical-Authority Indexing,[0],[0]
Draw author ai|πi←j ∼ Mult(πi←j).,3 Latent Topical-Authority Indexing,[0],[0]
(c),3 Latent Topical-Authority Indexing,[0],[0]
"Draw link xi←j ∼ N ( ∑
k ηaikz̄ikz̄jk, c −1 i←j).",3 Latent Topical-Authority Indexing,[0],[0]
"To model the content of publications, we follow a standard document generative process of latent Dirichlet allocation (LDA) (Blei et al., 2003).",3.1 Content Generation,[0],[0]
"Also, we inherit notations for variables from LDA; θ is the per-document topic distribution, β is the per-topic word distribution, z is the topic for each word in a document where w is the corresponding word, and αθ, αβ are the Dirichlet parameters of θ and β respectively.",3.1 Content Generation,[0],[0]
Let xi←j be a binary valued variable which indicates that publication j cites publication i. We formulate a continuous variable ri←j which is a linear combination of the authority variable and the topic proportion variable to approximate xi←j by minimizing the sum of squared errors between the two variables.,3.2 Citation Generation,[0],[0]
"There is a body of research on using continuous user and item-related variables to approximate binary variables in the field of recommender systems (Rennie and Srebro, 2005; Koren et al., 2009).
",3.2 Citation Generation,[0],[0]
"Approximating binary variables using linear combination of continuous variables can be probabilistically generalized (Salakhutdinov and Mnih, 2007).",3.2 Citation Generation,[0],[0]
"Using probabilistic matrix factorization, we approximate probability mass function p(xi←j) using probability density function N (xi←j |ri←j , c−1i←j), where the precision parameter ci←j can be set differently for each pair of papers as will be discussed below.
",3.2 Citation Generation,[0],[0]
"Content Similarity Between Publications: In the LTAI, we model relationship between a random pair of documents i and j. The probability of publication j citing publication i is proportional to the similarity of topic proportions of two publications, i.e., ri←j positively correlates to ∑ k θikθjk.",3.2 Citation Generation,[0],[0]
"Following relational topic model’s approach (Chang and Blei, 2010), we use z̄i = 1Ni ∑ n zi,n",3.2 Citation Generation,[0],[0]
≈ θi instead of topic proportion parameter θi.,3.2 Citation Generation,[0],[0]
Topical Authority of Cited Paper: We introduce a K-dimensional vector ηa for representing the topical authority index of author a. ηak is a real number drawn from the zero-mean normal distribution with variance α−1η .,3.2 Citation Generation,[0],[0]
Given the authority indices ηai for author,3.2 Citation Generation,[0],[0]
"a of cited publication i, the probability of citation is further modeled as ri←j = ∑ k ηaikz̄ikz̄jk, where the authority indices can promote or demote the probability of citation.
",3.2 Citation Generation,[0],[0]
Different Degree of Contribution among Multiple Authors: Academic publications are often written by more than one author.,3.2 Citation Generation,[0],[0]
"Thus, we need to distinguish the influence of each author on a citation between two publications.",3.2 Citation Generation,[0],[0]
"Let Ai be a set of authors of publication i. To measure the influence proportion of author a ∈ Ai on the citation from i to j, we introduce additional parameter πij which is a one-hot vector drawn from a Dirichlet distribution with |Ai|-dimensional parameter πi. πi←ja ∈ {0, 1} is an element of πi←j which measures the influence of author a on the citation from j to i and sums up to one ( ∑ a∈Ai πi←ja = 1) over all authors of publication i.",3.2 Citation Generation,[0],[0]
"We approximate the probability of citation xi←j from publication j to publication i by p(xi←j |z, πij , ai←j , ηa) ≈∑
a∈Ai πi←jaN",3.2 Citation Generation,[0],[0]
"(xi←j | ∑ k ηakz̄ikz̄jk, c −1 i←j) which is a mixture of normal distributions with precision parameter ci←j .",3.2 Citation Generation,[0],[0]
"Therefore, if topic distributions of paper i and j are similar and if η values of the cited paper’s authors are high, the citation formation probability increases; on the other hand, dissimilar or topically irrelevant pair of papers with less authoritative authors on the cited paper will be assigned with low probability of citation formation.
",3.2 Citation Generation,[0],[0]
Different Treatment between Positive and Negative links:,3.2 Citation Generation,[0],[0]
Citation is a binary problem where xi←j is either one or zero.,3.2 Citation Generation,[0],[0]
"When xi←j is zero, this can be interpreted in two ways: 1) the authors of citing publication j are unaware of the publication",3.2 Citation Generation,[0],[0]
"i, or 2) the
publication j is not relevant to publication i. Identifying which case is true is impossible unless we are the authors of the publication.",3.2 Citation Generation,[0],[0]
Therefore the model embraces this uncertainty in the absence of a link between publications.,3.2 Citation Generation,[0],[0]
"We control the ambiguity by the Gaussian distribution with precision parameter cij as follows:
ci←j = { c+ if xi←j = 1 c− if xi←j = 0
(1)
where c+ > c− to ensure that we have more confidence on the observed citations.",3.2 Citation Generation,[0],[0]
"This is an implicit feedback approach that permits using negative examples (xi←j = 0) of sparse observations by mitigating their importance (Hu et al., 2008; Wang and Blei, 2011; Purushotham et al., 2012).",3.2 Citation Generation,[0],[0]
"Setting different values to the precision parameter ci←j according to xi←j induces cyclic dependencies between the two variables, and due to this cycle, the model no longer becomes a Bayesian network, or a directed acyclic graph.",3.2 Citation Generation,[0],[0]
"However, we note that this setting does lead to better experimental results, and we show the pragmatic benefit of the setting in the Evaluation section.",3.2 Citation Generation,[0],[0]
"In the LTAI, the topics and the link structures are simultaneously learned, and thus the content-related variables and the citation-related variables mutually reshape one another during the posterior inference.",3.3 Joint Modeling of the LTAI,[0],[0]
"On the other hand, if content and citation data are modeled separately, the topics would not reflect any information about the document citation structure.",3.3 Joint Modeling of the LTAI,[0],[0]
"Thus, in the LTAI, documents with shared links are more likely to have similar topic distributions which leads to better model fit.",3.3 Joint Modeling of the LTAI,[0],[0]
We develop and explain this joint inference in section 4.,3.3 Joint Modeling of the LTAI,[0],[0]
"In section 7, we illustrate the differences in word-level predictive powers of the LTAI and LDA.",3.3 Joint Modeling of the LTAI,[0],[0]
"We develop a hybrid inference algorithm in which the posterior of content-related parameters θ, z, and β are approximated by variational inference, and author-related parameters π",4 Posterior Inference,[0],[0]
and η are approximated by EM.,4 Posterior Inference,[0],[0]
"In algorithm 1, we summarize the full inference procedure of the LTAI.",4 Posterior Inference,[0],[0]
"Since computing the posterior distribution of the LTAI is intractable, we use variational inference to optimize variational parameters each of which correspond to original content-related variables.",4.1 Content Parameters: Variational Update,[1.0],"['Since computing the posterior distribution of the LTAI is intractable, we use variational inference to optimize variational parameters each of which correspond to original content-related variables.']"
"Following the standard mean-field variational approach, we define fully factorized variational distributions over the topic-related latent variables q(θ, β, z) =∏ i q(θi|Ψin)",4.1 Content Parameters: Variational Update,[0],[0]
"∏ Ni q(zin|γi) ∏ k q(βk|λk) where for each factorized variational distribution, we place the same family of distributions as the original distribution.",4.1 Content Parameters: Variational Update,[0],[0]
"Using the variational distributions, we bound the log-likelihood of the model as follows:
L[q] = Eq[ ∑ k log p(βk|αβ) + ∑ i log p(θi|αθ)
",4.1 Content Parameters: Variational Update,[0],[0]
+ ∑,4.1 Content Parameters: Variational Update,[0],[0]
"i ∑ Ni log p(zin|θd) + log p(win|βzin) (2)
+ ∑ i,j log p(xi←j |zi, zj , πi)]−H[q]
whereH[q] is the negative entropy of q. Taking the derivatives of this lower bound with respect to each variational parameter, we can obtain the coordinate ascent updates.",4.1 Content Parameters: Variational Update,[0],[0]
"The update for the variational Dirichlet parameters γi and the λk is the same as the standard variational update for LDA (Blei et al., 2003).",4.1 Content Parameters: Variational Update,[0],[0]
"The update for the variational multinomial φin is:
φink ∝",4.1 Content Parameters: Variational Update,[0],[0]
"exp {∑
j ∂Eq[log p(xi←j |z̄i, z̄j , πi, η)]",4.1 Content Parameters: Variational Update,[0],[0]
"∂φink
+
∑ j ∂Eq[log p(xj←i|z̄j , z̄i, πj , η)]
∂φink (3)
+ Eq[log θik] + Eq[log βkwin ]}
where the gradient of expected log probabilities of both incoming link xi←j and outgoing link xj←i contribute to the variational parameter.",4.1 Content Parameters: Variational Update,[0],[0]
"The first expectation can be rewritten as
Eq[log p(xi←j |z̄i, z̄j , πi, η)]",4.1 Content Parameters: Variational Update,[0],[0]
"(4) = Eq[log ∑ a∈Ai p(ai←j = a|πi)p(xi←j |z̄i, z̄j , ηa)]
≥ ∑ a∈Ai p(ai←j = a|πi)Eq[log p(xi←j |z̄i, z̄j , ηa)]
Algorithm 1 Posterior inference algorithm for the LTAI
Initialize γ, λ, π, and η randomly Set learning-rate parameter ρt that satisfies Robbins-Monro condition Set subsample sizes SV , SE , SS and SA repeat
Variational update: local publication parameters SS ← SS randomly sampled publications for i in SS",4.1 Content Parameters: Variational Update,[0],[0]
"do
for n = 1 to Ni do S←, S→ ← Set of SV random samples Update φink using Equation 4, 5, 9. end for γi ← αθ + ∑ Ni φin
end for
EM update: local author parameters SA ← SA randomly sampled authors for a in SA do SE ← SE random publication pairs Update ηa using Equation 7, 10 for i in Da and j = 1 to D do
πi←ja ∝ πiaN",4.1 Content Parameters: Variational Update,[0],[0]
"(z̄i>ηaz̄j , c−1i←j) end for
end for
Stochastic variational update for k = 1 to K do
λ̂k ← αβ + DSS ∑SS",4.1 Content Parameters: Variational Update,[0],[0]
d=1,4.1 Content Parameters: Variational Update,[0],[0]
"∑Nd n=1 φ k dnwdn
end for Set λ(t)",4.1 Content Parameters: Variational Update,[0],[0]
"← (1− ρt)λ(t−1) + ρtλ̂
until satisfying converge criteria
where Ai is the set of authors of i. We take the lower bound of the expectation using Jensen’s inequality.",4.1 Content Parameters: Variational Update,[0],[0]
"The last term is approximated by the first order Taylor expansion Eq[log p(xi←j |z̄i, z̄j , ηa)]",4.1 Content Parameters: Variational Update,[0],[0]
"= N (xi←j |φ̄>i diag(ηa)φ̄j , c −1 i←j).",4.1 Content Parameters: Variational Update,[0],[0]
"Finally, the approximated gradient of φink with respect to the incoming directions to document i is∑
j ∂Eq[log p(xi←j |z̄i, z̄j , πi, η)]",4.1 Content Parameters: Variational Update,[0],[0]
"∂φink
≈ (5)∑ j φ̄jkci←j Ni ∑ a∈Ai ηak(xi←j − φ̄>i diag(ηa)φ̄j)p(a|πi)
where diag is a diagonalization operator and φ̄i is∑Ni n=1 φin/Ni.",4.1 Content Parameters: Variational Update,[0],[0]
We can compute the gradient with respect to the outgoing directions in the same way.,4.1 Content Parameters: Variational Update,[0],[0]
"We use the EM algorithm to update author-related parameters π, and η based on the lower bound computed by variational inference.",4.2 Author Parameters: EM Step,[0],[0]
"In the E step, we compute the probability of author contribution to the link between document i and j.
πi←ja = πiaN (z̄i>ηaz̄j , c−1i←j)∑
a′∈Ai πia′N (z̄i>ηa′ z̄j , c−1i←j)
(6)
",4.2 Author Parameters: EM Step,[0],[0]
"In the M step, we optimize the authority parameter η for each author.",4.2 Author Parameters: EM Step,[0],[0]
"Given the other estimated parameters, taking the gradient of L with respect to ηa and setting it to zero leads to the following update equation:
ηa =",4.2 Author Parameters: EM Step,[0],[0]
"(Ψ > a CaΨa + αηI) −1Ψ>a CaXa (7)
",4.2 Author Parameters: EM Step,[0],[0]
Let Da be the set of documents written by author a and Da(i) be the ith document written by a.,4.2 Author Parameters: EM Step,[0],[0]
"Then Ψa is a vertical stack of |Da|matrices ΨDa(i), whose jth row is φ̄Da(i) ◦ φ̄j , the Hadamard product between φ̄Da(i) and φ̄j .",4.2 Author Parameters: EM Step,[0],[0]
"Similarly, Ca is a vertical stack of |Da|matrices CDa(i) whose j th diagonal element is cDa(i)←j , andXa is a vertical stack of |Da| vectors XDa(i) whose j th element is πDa(i)←ja×xDa(i)←j .",4.2 Author Parameters: EM Step,[0],[0]
"Finally, we update πDa(i)a = ∑ j πDa(i)←ja/D.",4.2 Author Parameters: EM Step,[0],[0]
"To model topical authority, the LTAI considers the linkage information.",5 Faster Inference Using Stochastic Optimization,[0],[0]
"If two papers are linked by citation, the topical authority of the cited paper’s authors will increase while the negative link buffers the potential noise of irrelevant topics.",5 Faster Inference Using Stochastic Optimization,[0],[0]
This algorithmic design of the LTAI results in high model complexity.,5 Faster Inference Using Stochastic Optimization,[0],[0]
"To remedy this issue, we adopt the noisy gradient method from the stochastic approximation algorithm (Robbins and Monro, 1951) to subsample negative links for updating per-document topic variational parameter φ and authority parameter η.",5 Faster Inference Using Stochastic Optimization,[0],[0]
"The prior work of using subsampled negative links to reduce computational complexity is introduced in (Raftery et al., 2012).",5 Faster Inference Using Stochastic Optimization,[0],[0]
"Also, we elucidate how stochastic variational inference (Hoffman et al., 2013) is applied in our model to update global per-topic-word variational parameter λ.",5 Faster Inference Using Stochastic Optimization,[0.9921028354268991],"['We elucidate how stochastic variational inference (Hoffman et al., 2013) is applied in our model to update global per-topic-word variational parameter λ.']"
Updating φ̄i for document i in variational update requires iterating over every other document and computing the gradient of link probability.,5.1 Updating φ and η,[0],[0]
"This leads to the time complexity O(DK) for every φ̄i.
To apply the noisy gradient method, we divide the gradient of the expected log probability of link into two parts:∑ j ∂Eq[log p(xi←j |z̄i, z̄j , πi)]",5.1 Updating φ and η,[0],[0]
"∂φink = (8)
∑ j:xi←j=1 ∂Eq[log p(xi←j)]",5.1 Updating φ and η,[0],[0]
∂φink + ∑ j:xi←j=0 ∂Eq[log p(xi←j)],5.1 Updating φ and η,[0],[0]
"∂φink
where the first and the second term of RHS is the gradient sum of positive links (xij = 1) and negative links (xij = 0), respectively.",5.1 Updating φ and η,[0],[0]
"Compared to positive links, the order of negative links is close to the total number of documents, and thus computing the second term results in computational inefficiency.",5.1 Updating φ and η,[0],[0]
"However, in our model, we reduced the importance of the negative links by assigning a larger variance c−1ij compared to the positive links, and the empirical mean of φ̄j for negative links follows the Dirichlet expectation due to the large number of negative links.",5.1 Updating φ and η,[0],[0]
"Therefore, we approximate the expectation of the gradient for the negative links using the noisy gradient as follows:∑ j:xi←j=0 ∂Eq[log p(xi←j)]",5.1 Updating φ and η,[0],[0]
∂φink = D−i SV ∑ SV ∂Eq[log p(xi←s)],5.1 Updating φ and η,[0],[0]
"∂φink
(9)
where D−i is the number of negative links (i.e. xi←j = 0) of document i, and SV is the size of subsamples SV for the variational update.",5.1 Updating φ and η,[0],[0]
"We randomly sample SV documents, compute gradients on the sampled documents, and then scale the average gradient to the size of the negative link D−i .",5.1 Updating φ and η,[0],[0]
"This noisy gradient method reduces the updating time complexity from O(DK) to O(SVK).
",5.1 Updating φ and η,[0],[0]
"Now, we discuss how to approximate author’s topical authority based on Equation 7.",5.1 Updating φ and η,[0],[0]
"When K D × Da, the computational bottleneck is Ψ>a CaΨa which has time complexity O(DDaK2).",5.1 Updating φ and η,[0],[0]
"To alleviate this complexity, we once again approximate the large number of negative links using smaller number of subsamples.",5.1 Updating φ and η,[0],[0]
"Specifically, while keeping the positive link rows Ψa+ intact, we approximate negative link rows in Ψa using smaller matrix Ψa− that
has SE rows, or the size of subsamples for the EM step.",5.1 Updating φ and η,[0],[0]
"Using this approximation, we can represent Ψ>a CaΨa as
Ψ>a CaΨa = c+Ψ >",5.1 Updating φ and η,[0],[0]
"a+Ψa+ +
c−D − a
SE Ψ>a−Ψa− (10)
",5.1 Updating φ and η,[0],[0]
"with the time complexity ofO(SEK2), whereD−a is the number of rows with negative links in Ψa.",5.1 Updating φ and η,[0],[0]
"Also, although we do not incorporate rigorous analysis on the performance of our model given the size of the subsamples, we confirm that the negative link size greater than 100 does not degrade the model performance in any of our experiment.",5.1 Updating φ and η,[0],[0]
"In traditional coordinate ascent based variational inference, the global variational parameter λ is updated infrequently because all the other local parameters φ need to be updated beforehand.",5.2 Updating λ,[0],[0]
"This problem is more noticeable in the LTAI since updating φ using equation 3 is slower than updating φ in vanilla LDA; moreover, per-author topical authority variable η is another local variable that algorithm needs
to update a priori.",5.2 Updating λ,[0],[0]
"However, using the stochastic variational inference, the global parameters are updated after a small portion of local parameters are updated (Hoffman et al., 2013).",5.2 Updating λ,[0],[0]
"Applying stochastic variational inference for the LTAI is straightforward after we calculate the intermediate topic-word variational parameter λ̂ by αβ + DSS ∑SS d=1 ∑Nd n=1 φ k dnwdn from the noisy estimate of the natural gradient with respect to subsampled local parameters where Nd is the number of words for document d, and SS is the subsample size for the minibatch stochastic variational inference.",5.2 Updating λ,[0],[0]
The final global parameter for the tth iteration λ(t) is updated by (1− ρt)λ(t−1) +,5.2 Updating λ,[0],[0]
ρtλ̂ where ρt is the learning-rate.,5.2 Updating λ,[0],[0]
Posterior inference is guaranteed to converge at local optimum when the learning rate satisfies the condition ∑∞ t=1,5.2 Updating λ,[0],[0]
"ρt =
∞, ∑∞
t=1",5.2 Updating λ,[0],[0]
ρ 2 t < ∞,5.2 Updating λ,[0],[0]
"(Robbins and Monro, 1951).",5.2 Updating λ,[0],[0]
"In
Figure 3, we confirm that stochastic variational inference is applicable for the LTAI and reduces the training time compared to using the batch counterpart, while maintaining similar performance.",5.2 Updating λ,[0],[0]
"In this section, we introduce the four academic corpora used to fit the LTAI, describe comparison models, and provide information about the evaluation metric and parameter settings for the LTAI1.",6 Experimental Settings,[0],[0]
"We experiment with four academic corpora: CORA (McCallum et al., 2000), Arxiv-Physics (Gehrke et al., 2003), the Proceedings of the National Academy of Sciences (PNAS), and Citeseer (Lu and Getoor, 2003).",6.1 Datasets,[0],[0]
"CORA, Arxiv-Physics, and PNAS datasets contain abstracts only, and the locations of the citations within each paper are not preserved, whereas the Citeseer dataset contains the citation locations.",6.1 Datasets,[0],[0]
"For CORA, Arxiv-Physics, and PNAS, we lemmatize words, remove stop words, and discard words that occur fewer than four times in the corpus.",6.1 Datasets,[0],[0]
Table 1 describes the datasets in detail.,6.1 Datasets,[0],[0]
"Note that we obtain citation data from the entire document, not only from the abstract.",6.1 Datasets,[0],[0]
"Also, we consider withincorpus citation only, which leads to less than 13 average citation counts per document for all corpora.
",6.1 Datasets,[0],[0]
1Code and datasets are available at http://uilab.,6.1 Datasets,[0],[0]
kaist.ac.kr/research/TACL2017/,6.1 Datasets,[0],[0]
We compare predictive performance of the LTAI with five other models.,6.2 Comparison Models,[0],[0]
"Different comparison models have different degrees of expressive powers; each model conducts a certain type of prediction task; while RTM, ALTM, and DACTM predicts citation structures, the topical h-index predicts authorship information.",6.2 Comparison Models,[0],[0]
"Also, the baseline topic models are implemented based on the inference methods suggested in the corresponding papers; LDA, RTM and the LTAI variants use variational inference, while ALTM and DACTM use collapsed Gibbs sampling.",6.2 Comparison Models,[0],[0]
"Finally, all the conditions for implementation such as the choice of programming language and modules, except for parts that convey each model’s unique assumption, are identically set; thus, the performance differences between models are due to their model assumption and different degrees of data usage, rather than the implementation technicalities.
",6.2 Comparison Models,[0],[0]
"Latent Dirichlet Allocation: LDA (Blei et al., 2003) discovers topics and represents each publication by mixture of the topics.",6.2 Comparison Models,[0],[0]
"Compared to other models, LDA only uses the content information.
",6.2 Comparison Models,[0.999999997454054],"['Compared to other models, LDA only uses the content information.']"
LTAI-n%:,6.2 Comparison Models,[0],[0]
"In LTAI-n%, we remove n% of actual citations and displace them with arbitrarily selected false connections.",6.2 Comparison Models,[0],[0]
"Note that the link structures are displaced rather than removed; if the citation links are just removed, the LTAI and LTAI-n% cannot be fairly compared as the density of the citation structures will be affected and each model needs different concentration values.",6.2 Comparison Models,[0.9907385632055102],"['If the citation links are just removed, the LTAI and LTAIn% cannot be fairly compared as the density of the citation structures will be affected and each model needs different concentration values.']"
"Performance difference between the LTAI and this indicates that under identical conditions, using the correct linkage information is indeed beneficial for prediction.
",6.2 Comparison Models,[0],[0]
"LTAI-C: In LTAI-C the precision parameter cij has constant value, rather than assigning different values according to xij as discussed in section 3.
",6.2 Comparison Models,[0],[0]
"LTAI-SEP: LTAI-SEP has an identical structure as the LTAI, but the topic and the authority variables are separately learned.",6.2 Comparison Models,[0],[0]
"Once the topic variables are learned using the vanilla LDA, authority and citation variables are then inferred consecutively.",6.2 Comparison Models,[0],[0]
"Thus, the performance edge of the LTAI over LTAI-SEP highlights the necessity of the LTAI’s joint modeling in which both topic and authority related variables reshape one another in an iterative fashion.
",6.2 Comparison Models,[1.0000000524269235],"['Thus, the performance edge of the LTAI over LTAI-SEP highlights the necessity of the LTAI’s joint modeling in which both topic and authority related variables reshape one another in an iterative fashion.']"
"Relational Topic Model: RTM (Chang and Blei, 2010) jointly models content and citation, and thus, topic proportions of a pair of publications become similar if the pair is connected by citations.",6.2 Comparison Models,[0],[0]
"Compared to the LTAI, the author information is not considered, the link structure does not have directionality and the model does not consider negative links.
",6.2 Comparison Models,[0],[0]
"Author-Link Topic Model: ALTM (Kataria et al., 2011) is a variation of author topic model (ATM) (Rosen-Zvi et al., 2004) that models both topical interests and influence of authors in scientific corpora.",6.2 Comparison Models,[1.0],"['Author-Link Topic Model: ALTM (Kataria et al., 2011) is a variation of author topic model (ATM) (Rosen-Zvi et al., 2004) that models both topical interests and influence of authors in scientific corpora.']"
The model uses content information of citing papers and names of the cited authors as word tokens.,6.2 Comparison Models,[0],[0]
"ALTM outputs per-topic author distribution that functions as author influence indices.
",6.2 Comparison Models,[0],[0]
"Dynamic Author-Citation Topic Model: DACTM (Kataria et al., 2011) is an extension of ALTM that requires publication corpora which preserve sentence structures.",6.2 Comparison Models,[0.9997038480856322],"['Dynamic Author-Citation Topic Model: DACTM (Kataria et al., 2011) is an extension of ALTM that requires publication corpora which preserves sentence structures.']"
"To model author influence, DACTM selectively uses words that are close to the point where the citation is presented.
",6.2 Comparison Models,[0],[0]
"100 200 300 400
Number of Topics
0.02
0.05 0.08 M R R
(a) CORA
100 200 300 400
Number of Topics
0.010
0.025
",6.2 Comparison Models,[0],[0]
"0.040
M R R (b) Arxiv-Physics
LTAI RTM
LTAI-C DACTM
LTAI-SEP ALTM
",6.2 Comparison Models,[0],[0]
"In our corpora, only Citeseer dataset preserves the sentence structure.
",6.2 Comparison Models,[0],[0]
"Topical h-index: To compute topical h-index, we separate the papers into several clusters using LDA and calculate the h-index within each cluster.",6.2 Comparison Models,[0],[0]
"Topical h-index is used for author prediction in the same manner as we did for our model, except the topic proportions are replaced to the LDA’s result and η is replaced to the topical h-index values.",6.2 Comparison Models,[0],[0]
"We use mean reciprocal rank (MRR) (Voorhees, 1999) to measure the predictive performance of the LTAI and the comparison models.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
"MRR is a widely used metric for evaluating link prediction tasks (Balog and De Rijke, 2007; Diehl et al., 2007; Radlinski et al., 2008; Huang et al., 2015).",6.3 Evaluation Metric and Parameter Settings,[0],[0]
"When the models
outputs the correct answers as ranks, MRR is the inverse of the harmonic mean of such ranks.
",6.3 Evaluation Metric and Parameter Settings,[0],[0]
We report the parameter values used for evaluations.,6.3 Evaluation Metric and Parameter Settings,[0],[0]
"For all datasets, we set c− to 1.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
"To predict citation, we set c+ to 10,000, 100, 1,000, 10, and to predict authorship, we set c+ to 1,000, 1,000, 10,000, 1,000 for CORA, Arxiv-Physics, PNAS, and Citeseer datasets.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
These values are obtained through exhaustive parameter analysis.,6.3 Evaluation Metric and Parameter Settings,[0],[0]
"We set αθ to 1, and αβ to 0.1.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
We fix the subsample sizes to 5002.,6.3 Evaluation Metric and Parameter Settings,[0],[0]
"For fair comparison, all the parameters that the LTAI and the baseline models share are set to have the same values, and for other parameters that uniquely belong to the baseline models, the values are exhaustively tuned as done in the LTAI.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
"Finally, we note that all parameters are tuned using the training set, and test dataset is used only for the testing purpose.",6.3 Evaluation Metric and Parameter Settings,[0],[0]
"We conduct the evaluation of the LTAI with three different quantitative tasks, along with one qualitative analysis.",7 Evaluation,[0],[0]
"In the first task, we check whether using citation and authorship information in the LTAI helps increase the word-level predictive performance.",7 Evaluation,[0],[0]
"In the second and third tasks, we measure the predictability of the LTAI regarding missing publication-publication linkage and authorpublication linkage; with these two tasks, we compare the predictive power of the LTAI with other comparison models and use MRR as evaluation metric.",7 Evaluation,[0],[0]
"Finally, we observe famous researchers’ topical authority scores generated by the LTAI and investigate how these scores capture notable academic characteristics of the researchers.",7 Evaluation,[0],[0]
"In the LTAI, citation and authorship information affect per-document topic proportions, as can be confirmed in equation 3.",7.1 Word-level Prediction,[0],[0]
"This joint modeling of content and linkage structure, compared to vanilla LDA that uses content data only, yields better performance in terms of predicting missing words in documents.",7.1 Word-level Prediction,[0],[0]
"In this task, we use log-predictive probability, a metric that is widely used in other researches for measuring model fitness (Teh et al., 2006; Asuncion et
2Although we do not present thorough sensitivity analysis in this paper, we confirm that the performance of our model was robust against adjusting the parameters within a factor of 2.
al., 2009; Hoffman et al., 2013).",7.1 Word-level Prediction,[0],[0]
"For each corpus, we separate one third of documents as test set, and for all documents in each test set, we use half of the words for training per-document topic proportion θ and predict the probability of word occurrence regarding the remaining half.",7.1 Word-level Prediction,[0],[0]
"Specifically, the predictive probability for a word in a test set wnew with respect to the given words wobs and the training document Dtrain is computed using equation p(wnew|Dtrain, wobs) =",7.1 Word-level Prediction,[0],[0]
"∑K k=1 Eq[θk]Eq[βk,wnew ].
",7.1 Word-level Prediction,[0],[0]
Figure 4 illustrates the per-word log-predictive probability in each corpus.,7.1 Word-level Prediction,[0],[0]
"We confirm that when using the LTAI, the log predictive probability converges at higher value compared to the result using LDA.",7.1 Word-level Prediction,[0],[0]
"Also, when we corrupt the link structure from 10% to 30% the predictive performances of the LTAI gradually decrease.",7.1 Word-level Prediction,[0],[0]
"Thus, the LTAI’s superior predictive performance is attributed to its usage of correct citations rather than the algorithmic bias.",7.1 Word-level Prediction,[0],[0]
We evaluate model predictability regarding which publication is originally citing a certain publication.,7.2 Citation Prediction,[0],[0]
"Specifically, we randomly remove one citation from each of the documents in the test set.",7.2 Citation Prediction,[0],[0]
"To predict the citation link between publications, we first compute the probability that publication j cites i from p(xi←j |z,Ai, πi) ∝∑
a∈Ai πi←jaN",7.2 Citation Prediction,[0],[0]
(xi←j |z̄ >,7.2 Citation Prediction,[0],[0]
"i diag(ηa)z̄j , c −1 + ).",7.2 Citation Prediction,[0],[0]
"Given the topic proportion of the cited publication θi and the topical authorities of the authors ηa, we compute which publication is more likely to cite the publication.",7.2 Citation Prediction,[0],[0]
"Based on our model assumption in subsection 3.2, using topical authority increases the performance of predicting linkage structure.
",7.2 Citation Prediction,[0],[0]
"In Figure 5, the LTAI yields better citation prediction performance than other models for all datasets and with most number of topics.",7.2 Citation Prediction,[0],[0]
"Since the LTAI incorporates topical authority for predicting citations, it performs better than RTM, which does not discover topical authority.",7.2 Citation Prediction,[0],[0]
We can attribute the better performance of the LTAI compared to ALTM and DACTM to the LTAI’s multiple model assumptions explained in section 3.,7.2 Citation Prediction,[0],[0]
"We note that DACTM requires additional information such as citation location and sentence structure, and thus, is only applicable for limited kinds of datasets.",7.2 Citation Prediction,[0],[0]
"For author prediction, we randomly remove one of the authors from documents in the test set while preserving citation structures.",7.3 Author Prediction,[0],[0]
"Similar to citation prediction, we predict which author is more likely to write the cited publication based on the topic proportions of cited publication i and a set of citing publications J .",7.3 Author Prediction,[1.0],"['Similar to citation prediction, we predict which author is more likely to write the cited publication based on the topic proportions of cited publication i and a set of citing publications J .']"
"We approximate the probability of researcher a being an author of publication i from p(a|z, ηa, xi←j) ∝∏ j∈J N (xi←j |z̄>i diag(ηa)z̄j , c −1 + ).",7.3 Author Prediction,[0],[0]
"Because the mixture proportion of an unknown author πi←ja cannot be obtained during posterior inference, we assume the cited publication is written by a single author to approximate the probability.",7.3 Author Prediction,[0],[0]
"For author prediction, we choose the author that maximizes the above probability.",7.3 Author Prediction,[1.0],"['For author prediction, we choose the author that maximizes the above probability.']"
"In Figure 6, the LTAI outperforms the comparison models in most of the settings.",7.3 Author Prediction,[0],[0]
"To stress our model’s additional characteristics that are not observed in the quantitative analysis, we look at the assigned topical authority indices as well as other statistics of some researchers in the dataset.",7.4 Qualitative Analysis,[0],[0]
"In the analyses, we set the number of topics to 100, and use CORA dataset for demonstration.
",7.4 Qualitative Analysis,[0],[0]
We first demonstrate famous authors’ authoritative topics that can be unveiled using our model.,7.4 Qualitative Analysis,[0],[0]
"In Table 2, we list top 10 authors with highest h-indices along with their number of citations, number of papers, and their representative topics.",7.4 Qualitative Analysis,[0],[0]
Authors’ representative topics are the topics with highest authority scores.,7.4 Qualitative Analysis,[0],[0]
"In the table, we observe that all authors with top h-indices have wrote at least 18 papers and earned at least 207 citations, which are the top 0.8% and 0.2% values respectively.",7.4 Qualitative Analysis,[0.9994820389159875],"['In the table, we observe that all authors with top h-indices have written at least 18 papers and earned at least 207 citations, which are the top 0.8% and 0.2% values respectively.']"
"However, their authoritative topics retrieved by the LTAI do not overlap for any of the authors.",7.4 Qualitative Analysis,[0],[0]
"This table illustrates that each of the top authors in the table exerts authority on different academic topics that can be captured by the LTAI, while the authors commonly have highest h-index scores as well as other statistics.
",7.4 Qualitative Analysis,[0],[0]
We now stress attributes of topical authority index that are different from other topic irrelevant statistics.,7.4 Qualitative Analysis,[1.0],['We now stress attributes of topical authority index that are different from other topic irrelevant statistics.']
"From Tables 3 to 5, we show four example topics extracted by our model and list notable authors within each topic with their topical authority indices, h-indices, number of citations, and number of papers.",7.4 Qualitative Analysis,[1.0],"['From Tables 3 to 5, we show four example topics extracted by our model and list notable authors within each topic with their topical authority indices, h-indices, number of citations, and number of papers.']"
"In the tables, we first find that all four
authors with highest topical authority values, Monica Lam, Alex Pentland, Michael Jordan, and Mihir Bellare are also listed in the topic-irrelevant authority rankings in Table 2.",7.4 Qualitative Analysis,[0.9999999909782897],"['In the tables, we first find that all four authors with highest topical authority values, Monica Lam, Alex Pentland, Michael Jordan, and Mihir Bellare are also listed in the topic-irrelevant authority rankings in Table 2.']"
"From this, we confirm that authority score of the LTAI has a certain degree of correlation to other statistics, while it splits the authors by their authoritative topics.
",7.4 Qualitative Analysis,[0],[0]
"At the same time, the topical authority score correlates less with topic-irrelevant statistics than those statistics correlate with themselves; in Table 5, Oded Goldreich has lower topical authority score for the computer security topic while having higher topic irrelevant scores than the above four researchers, because his main research filed is in the theory of computation and randomness.",7.4 Qualitative Analysis,[0],[0]
"Also, we can spot authors who exert high authority on multiple academic fields, such as Tomaso Poggio in Table 3 and in Table 4.",7.4 Qualitative Analysis,[0],[0]
"Similarity, when comparing Federico Girosi and Tomaso Poggio in Table 4, the two researchers have similar authority indices for this topic while Tomaso Poggio has higher values for the other three topic-irrelevant indices.",7.4 Qualitative Analysis,[1.0],"['Similarity, when comparing Federico Girosi and Tomaso Poggio in Table 4, the two researchers have similar authority indices for this topic while Tomaso Poggio has higher values for the other three topic-irrelevant indices.']"
This is a reasonable outcome when we investigate the two researchers’ publication history.,7.4 Qualitative Analysis,[0],[0]
"Federico Girosi has relatively focused academic interest, with his publication history being skewed towards machine-learning-related subjects, while Tomaso Poggio has broader topical interests that include computer vision and statistical learning, while also co-authoring most of the papers that Federico Girosi wrote.",7.4 Qualitative Analysis,[1.0],"['Federico Girosi has relatively focused academic interest, with his publication history being skewed towards machine-learning-related subjects, while Tomaso Poggio has broader topical interests that include computer vision and statistical learning, while also co-authoring most of the papers that Federico Girosi wrote.']"
"Thus, Federico Girosi
has similar authority index for this topic but has lower authority indices for other topics than Tomaso Poggio.
",7.4 Qualitative Analysis,[0],[0]
"Also, our model is able to capture topic-specific authoritative researchers that have relatively low topic-irrelevant scores.",7.4 Qualitative Analysis,[0],[0]
"For example, researchers such as Stan Sclaroff and Kentaro Toyama are the top 5 authoritative researchers in computer vision topic according to the LTAI, but it is difficult to detect these researchers out of many other authoritative authors using the topic-irrelevant scores.
",7.4 Qualitative Analysis,[0],[0]
"Finally, the LTAI detect researchers’ topical authority that is peripheral but not negligible.",7.4 Qualitative Analysis,[0],[0]
"Mark Jones in Table 4, who has high h-index, number of citations, and wrote many papers, is a researcher whose academic interest lies in programming language design and application.",7.4 Qualitative Analysis,[0],[0]
"However, while most of his papers’ main topics are about programming language, he often uses inference techniques and algorithms in machine learning in his papers.",7.4 Qualitative Analysis,[0],[0]
Our model captures that tendency and assigns some authority score for machine learning to him.,7.4 Qualitative Analysis,[0],[0]
We proposed Latent Topical Authority Indexing (LTAI) to model the topical-authority of academic researchers.,8 Conclusion and Discussion,[1.0],['We proposed Latent Topical Authority Indexing (LTAI) to model the topical-authority of academic researchers.']
"Based on the hypothesis that authors play an important role in citation, we specifically focus on their authority and develop a Bayesian model to capture the authority.",8 Conclusion and Discussion,[0],[0]
"With model assumptions that are necessary for extracting convincing and interpretable topical authority values for authors, we have proposed speed-up methods that are based on stochastic optimization.
",8 Conclusion and Discussion,[0],[0]
"While there is prior research in topic modeling that provides topic-specific indices when modeling the link structure, these do not extend to individual indices, and most previous citation-based indices are defined for each individual but without considering topics.",8 Conclusion and Discussion,[0],[0]
"On the other hand, our model combines the merits of both topic-specific and individual-specific indices to provide topical authority information for academic researchers.
",8 Conclusion and Discussion,[0.9999999418291493],"['On the other hand, our model combines the merits of both topic-specific and individual-specific indices to provide topical authority information for academic researchers.']"
"With four academic datasets, we demonstrated that the joint modeling of publication and author related variables improve topic quality, when compared to vanilla LDA.",8 Conclusion and Discussion,[0],[0]
"Also, we quantitatively manifested that including authority variables increases the predictive performance in terms of citation and author predictions.",8 Conclusion and Discussion,[0],[0]
"Finally, we qualitatively demonstrated the interpretability by topical-authority outcomes of the LTAI from the CORA corpus.
",8 Conclusion and Discussion,[0.9999999555880911],"['Finally, we qualitatively demonstrated the interpretability by topical-authority outcomes of the LTAI from the CORA corpus.']"
"Finally, there are issues that can be dealt in future work.",8 Conclusion and Discussion,[0.9954092068639597],"['Finally, there are issues that can be dealt with in future work.']"
"In our model, we do not consider time information in terms of when papers are published and when pairs of papers are linked; we can use datasets that incorporate timestamps to enhance the model capability to predict future citations and authorships.",8 Conclusion and Discussion,[0.9915882032346356],['We do not consider time information in terms of when papers are published and when pairs of papers are linked; we can use datasets that incorporate timestamps to enhance the model capability to predict future citations and authorships.']
"We thank Jae Won Kim for his help on collecting, refining the dataset and contributing to the early version of the manuscript, anonymous reviewers as well as the TACL editor Noah Smith for detailed and thoughtful comments, and Joon Hee Kim and other UILab members for providing helpful insights in the research.",Acknowledgments,[0],[0]
"This work was supported by Institute for Information & communications Technology Promotion(IITP) grant funded by the Korea government(MSIP) (No.B0101-15-0307, Basic Software Research in Human-level Lifelong Machine Learning (Machine Learning Center)).",Acknowledgments,[0],[0]
"Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult.",abstractText,[0],[0]
We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics.,abstractText,[0],[0]
"We present Latent Topical-Authority Indexing (LTAI) for jointly modeling the topics, citations, and topical authority in a corpus of academic papers.",abstractText,[0],[0]
"Compared to previous models, LTAI differs in two main aspects.",abstractText,[0],[0]
"First, it explicitly models the generative process of the citations, rather than treating the citations as given.",abstractText,[0],[0]
"Second, it models each author’s influence on citations of a paper based on the topics of the cited papers, as well as the citing papers.",abstractText,[0],[0]
"We fit LTAI to four academic corpora: CORA, Arxiv Physics, PNAS, and Citeseer.",abstractText,[0],[0]
"We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation topic model.",abstractText,[0],[0]
"The results show that LTAI achieves improved accuracy over other similar models when predicting words, citations and authors of publications.",abstractText,[0],[0]
"Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora",title,[0],[0]

{"sections": [{"heading": "1. Introduction", "text": "Algorithmic decision-making process now affects many aspects of our lives. Emails are spam-filtered by classifiers, images are automatically tagged and sorted, and news articles are clustered and ranked. These days, even decisions regarding individual people are being made algorithmically. For example, computer-generated credit scores are popular in many countries, and job interviewees are sometimes evaluated by assessment algorithms. However, a potential loss of transparency, accountability, and fairness arises when decision making is conducted on the basis of past data. If a dataset indicates that specific groups based on sensitive attributes (e.g., gender, race, and religion) are of higher risk\n1The University of Tokyo, Tokyo, Japan. 2RIKEN AIP, Tokyo, Japan. 3Santa Fe Institute, New Mexico, United States. Correspondence to: Junpei Komiyama <junpei@komiyama.info>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nin defaulting on loans, direct application of machine learning algorithm would highly likely result in loan applicants on those groups being rejected.\nThis could be viewed as an algorithmic version of disparate treatment1, where decisions are made on the basis of these sensitive attributes. However, removing sensitive attributes from the dataset is not a sufficient solution as it has a disparate impact: In 1970s, the U.S. Supreme Court ruled that the hiring decision at the center of the Griggs v. Duke Power Co. case2 was illegal because it disadvantaged an application of an applicant of certain race, even though the decision was not explicitly determined on the basis of race. Duke Power Co. was subsequently forced to stop using test scores and diplomas, which are highly correlated with race, in its hiring decisions. In this paper, we consider fair machine learning algorithms that remove disparate impact that arises from the correlation between the sensitive and non-sensitive attributes.\nMost of existing fairness-aware machine learning algorithms are for classification. While such classifiers are naturally applied in decision making, regressors provide more useful information in some of the human-related tasks. For example, in the case of criminal records (Calders et al., 2013; Angwin et al., 2016), assessing the risk of reoffending of each criminal is reasonable. In hiring decisions, an employer would naturally consider the productivity of a job applicant. Moreover, in recommendation tasks, the preference of items are usually represented as numeric values.\nTaking above into consideration, we study a fair regressor. By definition, a fair algorithm tries to treat several groups equally, and thus it sacrifices some accuracy that could be achieved if it had treated these groups unequally. Therefore, the challenge lies in balancing the regression accuracy and fairness. As discussed in Zafar et al. (2017a), depending on each business necessity, a user of an algorithm can justify some degree of disparate impact to increase the predictive power of the algorithm. Such a degree of unfair impact should be strictly controlled.\nA natural interest is how to define fairness of algorithm. In\n1The U.S. Civil Rights Act, July 2, 1964. 2Case: 401 U.S. 424, March 8, 1971.\nthis paper, we consider a coefficient of determination (CoD) of the sensitive attributes as a constraint. Let s be the sensitive attributes, and x be the non-sensitive attributes. In general, x is highly correlated with s, and we construct u from x by removing its correlation with s. Let y be the target variable to predict, and y\u0302 = y\u0302(s,u) be its estimator. CoD is defined as the proportion of the variance of the estimator y\u0302 that is predictable from s. In fact, CoD defined in such a way is a natural extension the correlation coefficient to multiple sensitive attributes (Section 2.2).\nWhile CoD is a natural measure of the predictive power, no literature on a fair estimator with CoD as a constraint exists presumably due to its inherent nonconvexity: Figure 1 shows that the feasible region of linear regressors is nonconvex even in the case of single s. As a result, off-the-shelf tools for convex optimization, such as gradient methods, do not give a global solution.\nIn the context of fairness-aware machine learning, strictly complying with the fairness constraint is of primal importance. However, obtaining an exact solution in nonconvex optimizations is generally hard: For example, even one negative eigenvalue makes a quadratic programming NP-hard (Pardalos & Vavasis, 1991). Fortunately, the optimization under CoD constraint can be solved exactly unlike most of these nonconvex optimizations: We propose two optimization methods by utilizing tools of global optimization theory. The first one is based on a Lagrangian dual that boils down the problem into a semidefinite programming (SDP). Although the Lagrangian dual is efficiently computed and yields an exact optimal value in the optimization, recover-\ning an optimal solution in this problem is not always possible due to a relaxed solution space. To address this issue, we show another optimization method that converts the original nonconvex quadratically constrained quadratic program (QCQP) into a convex QCQP, which yields an exact solution of the problem.\nFurthermore, we show that our optimization framework is extended to capture non-linearity by proposing the kernel extension of our framework that is also exactly solvable. As a result, our framework allows us to remove disparate impact that is non-linear to a numeric sensitive attribute (e.g., an unfair deal for young and old people that favors the people in between).\nThe proposed method is empirically evaluated by four realworld datasets. Unlike most methods, our method is capable of considering the possibly non-linear interaction of numeric sensitive attributes with the target variable. As we consider nonconvexity that naturally arises in measuring a correlation between s and y, we think this result is a first step that ties the study of nonconvex optimization in the context of fairness-aware machine learning."}, {"heading": "1.1. Related Work", "text": "Most of the tasks in fairness-aware machine learning and data mining fields are divided into two categories (Ruggieri et al., 2010): The former is to discover unfairness (Adebayo & Kagal, 2016; Adler et al., 2018), whereas the latter is to prevent unfair treatments. Classification, regression, and other tasks such as recommendations (Kamishima et al., 2012b; 2016), voting (Bredereck et al., 2018), data summarization(Celis et al., 2018), dimensional reduction (Pe\u0301rezSuay et al., 2017), and representational learning (Bolukbasi et al., 2016) are categorized into the latter one. As the goal of this paper is to build a fair regressor, this paper is also categorized into the latter.\nMost of the existing papers in the latter category (Kamiran & Calders, 2010; Zliobaite et al., 2011; Kamishima et al., 2012a; Ristanoski et al., 2013; Fish et al., 2015; Hardt et al., 2016; Goh et al., 2016; Zafar et al., 2017a) deal with classification tasks, and thus cannot directly deal with regression tasks. Note that there are several papers that take pre-processing strategy, which makes the data into fair representation so that we can put them into off-the-shelf machine learning algorithms. Among this approach, Zemel et al. (2013) segregated the data by mapping them into finite sets. Feldman et al. (2015) merged distribution of datapoints with binary sensitive attribute s = 1 and s = 0 into a single distribution. Calmon et al. (2017) characterized a class of convex data preprocessing related to nondiscrimination. While the methods in these papers are general enough to deal with regression tasks, this approach treats the algorithm as a black box and could potentially\nreduce the predictive power the algorithm by excessively reducing the information in the original dataset.\nA few papers considered fairness in regression problems. Fukuchi et al. (2013) considered a generative model that is neutral to a finite set of viewpoints. Calders et al. (2013) introduced a propensity score based approach that enables us to divide people into several clusters on the basis of explainable attributes. Kamishima et al. (2012a) introduced a regularizer that encourages fairness. Berk et al. (2017) considered a convex framework where fairness is imposed by the regularizer, and Pe\u0301rez-Suay et al. (2017) introduced a reguralizer inspired by the Hilbert-Schmidt Independence Criteria (Gretton et al., 2005). Unlike the existing approaches, our method (i) is capable of not only discrete sensitive attributes (e.g., gender, races) but also numeric sensitive attributes such as ages and (ii) enables strict control of fairness by posing the fairness as an explicit constraint."}, {"heading": "2. Problem Setup", "text": "Each d-dimensional vector in this paper is a column vector and is identified as a d \u00d7 1 matrix. Let n be the number of datapoints. The i-th datapoint is comprised of a tuple (si,xi, yi), where si \u2208 Rds is the sensitive attributes of ds dimensions that require special care (e.g., gender, race, and age), xi \u2208 Rdx is the normal (non-sensitive) attributes of dx dimensions, and yi \u2208 R is the target attribute to predict. Given a training dataset of {(si,xi, yi)}ni=1, a fairnessaware algorithm outputs y\u0302(s,x), which is an estimator of y that complies with the fairness criteria. We also denote y = (y1, y2, . . . , yn)\n\u22a4 \u2208 Rn\u00d71,X = (x1,x2, . . . ,xn)\u22a4 \u2208 Rn\u00d7dx ,S = (s1, s2, . . . , sn)\u22a4 \u2208 Rn\u00d7ds to denote a sequence of n datapoints. We assume that each feature in s and x, and y is zero-mean. If not, we can always remove their (empirical) means."}, {"heading": "2.1. Preprocessing and An Asymptotically Fair Regressor", "text": "In practice, s has a strong predictive power and highly correlated with x (e.g., gender is highly correlated with occupation), and thus using x in estimating y leads to a disparate impact. Such a correlation is removed by conducting a regression as follows: Namely,\nB\u0302 = (S\u22a4S)\u22121S\u22a4X \u2208 Rds\u00d7dx\nU = X\u2212 B\u0302\u22a4S \u2208 Rn\u00d7dx (2.1)\nand we define ui as the i-th datapoint of U. The value B\u0302\u22a4S is a part of x that is explainable by s. The following theorem states the learnability of the linear relation between x and s.\nTheorem 1. (Asymptotic fairness of a preprocesssed regressor) Assume a linear relation between s and x such\nthat xi = B \u22a4si + \u03f5i,\nwhere \u03f5i is a zero mean noise E[\u03f5i|X] = 0. Then, B\u0302 \u2192 B in probability.\nThe proof of Theorem 1 directly follows from the fact that each of l-th column of B is an ordinary linear regression (OLS) from s to the l-th column of x and standard asymptotic normality of OLS (e.g., Theorem 5.1 in Wooldridge, 2013). Note that, since the linear regression is a parametric model, one can easily see that the correlation between s and u is O(1/ \u221a n) while (s,u) has the same information as (s,x).\nThe discussion above implies that, if we devise a linear regressor y\u0302 = y\u0302(u), the regressor is asymptotically fair in the sense that Cov(y\u0302, s) approaches zero as n \u2192 \u221e. Although such a regressor maximizes fairness, it sacrifices the predictive power that stems from s. Instead, the rest of this paper maximizes the predictive power of y\u0302 subject to a userdefined level of fairness. Given asymptotically fair features u, the next section defines the coefficient of determination, which measures the explainable power of s over y\u0302."}, {"heading": "2.2. Coefficient of Determination", "text": "The coefficient of determination (CoD) is widely used to measure the predictive power of features to a target variable. Here, our interest lies in measuring the contribution of s to the estimator y\u0302 of the target variable y. Namely, let\ny\u0302 = s\u22a4\u03b1+ u\u22a4\u03b2\nbe the estimator of y. Given s and u are zero-mean and not correlated to each other, the best estimator of y\u0302 by using only non-sensitive features u is y\u0304 = u\u22a4\u03b2 in view of the mean squared error. The variance of y\u0302 is \u03b1\u22a4Vs\u03b1 + \u03b2\u22a4Vu\u03b2, where Vs \u2208 Rds\u00d7ds and Vu \u2208 Rdx\u00d7dx are the covariances of s and u, respectively. Morevoer, the variance of y\u0302 \u2212 y\u0304 is \u03b1\u22a4Vs\u03b1. The CoD (or the R-squared) of sensitive attribute s over y\u0302 is defined as\nR2 = Var(y\u0302 \u2212 y\u0304) Var(y\u0302) = \u03b1\u22a4Vs\u03b1 \u03b1\u22a4Vs\u03b1+ \u03b2\u22a4Vu\u03b2 .\nCoD and the correlation coefficient: Let there be only one sensitive attribute (i.e. s, \u03b1 \u2208 R and Vs = Var(s)). In this case, CoD matches the correlation coefficient: The correlation coefficient \u03c1(y\u0302, s) is transformed as\n\u03c1(y\u0302, s) = Cov(y\u0302, s)\u221a Var(y\u0302)Var(s)\n= \u03b1Var(s)\u221a \u03b1\u22a4Vs\u03b1+ \u03b2\u22a4Vu\u03b2 \u221a Var(s) = \u03b1 \u221a Vs\u221a\n\u03b1\u22a4Vs\u03b1+ \u03b2\u22a4Vu\u03b2 = R. (2.2)\nNote also that, the mean difference (MD) (Calders et al., 2013) is very similar to the correlation coefficient with binary s (See Appendix D). In summary, CoD is a multiattribute generalization of the correlation coefficient for vector s in the least square regression."}, {"heading": "2.3. Least Square Regression with Coefficient of Determination Constraints", "text": "In this paper, we consider the least square regression with CoD constraint. Namely,\nmin E[(y \u2212 y\u0302)2] s.t. R2 \u2264 \u03f5, (2.3)\nwhere \u03f5 \u2208 [0, 1] is a user-defined value that determines how fair the estimator is. The value \u03f5 = 0 corresponds to a fully fair regressor, whereas \u03f5 = 1 corresponds to a completely fairness-ignorant regressor that solely maximizes the predictive power."}, {"heading": "3. Optimization", "text": "The optimization problem in Eqn. (2.3) is equivalently written as:\nmin \u03b1\u22a4Vs\u03b1+ \u03b2\u22a4Vu\u03b2 \u2212 2(E[ys\u22a4\u03b1] + E[yu\u22a4\u03b2]) s.t. (1\u2212 \u03f5)\u03b1\u22a4Vs\u03b1\u2212 \u03f5\u03b2\u22a4Vu\u03b2 \u2264 0, (3.1)\nwhere Vs,Vu, and the expectations are taken with the true data generating distribution. Given limited number of training datapoints, we replace them with the empirical analogues. That is, the (l,m)-entry of Vs is (1/n) \u2211n i=1 s (l) i s (m) i , where we assume that s is normalized to be zero-mean. Let qs = En[ys] \u2208 Rds , and qu = En[yu] \u2208 Rdx , where En is a sample mean such as En[ys] = (1/n) \u2211n i=1 yisi. Then, the optimization problem (3.1) is explicitly written as:\nmin \u03b1,\u03b2\n[ \u03b1\u22a4\u03b2\u22a4 ] [Vs 0 0 Vu ] [ \u03b1 \u03b2 ] \u2212 2 [ q\u22a4s q \u22a4 u ] [\u03b1 \u03b2 ] s.t. [ \u03b1\u22a4\u03b2\u22a4 ] [(1\u2212 \u03f5)Vs 0 0 \u2212\u03f5Vu ] [ \u03b1 \u03b2 ] \u2264 0,\n(3.2)\nwhere we use 0 to denote a matrix block of zeros.\nFor ease of discussion, we assume the following condition:\nAssumption 1. (Regularity condition) Covariance matrices Vs and Vu are full rank.\nWe may expect that Assumption 1 always holds because we may remove some of the redundant features if the assumption is violated. Note that Assumption 1 implies the existence of an interior solution: {(\u03b1,\u03b2) : (1 \u2212 \u03f5)\u03b1\u22a4Vs\u03b1 \u2212\n\u03f5\u03b2\u22a4Vu\u03b2 < 0} \u0338= \u2205. The optimization problem (3.2) is nonconvex due to the negative definiteness of the lower right block \u2212\u03f5Vu of the quadratic constraints. In the rest of this section, we propose two methods for solving this problem. The first one solves the Lagrangian dual problem, which boils down to a semidefinite programming (SDP). Unfortunately, solving SDP does not always give the solution of the original problem. The second method exploits the structure of the quadratically constrained quadratic programs (QCQP) and makes it convex. From this optimization we can recover the solution of the original problem unlike the SDP-based method. Note that, both methods give the exact optimal objective value to the target optimization problem as shown later in Sections 3.1 and 3.2."}, {"heading": "3.1. Lagrangian Dual and SDP-based Optimization", "text": "The Lagrangian dual problem of (3.1) is written as\nmax \u03be\u22650 \u03d5(\u03be), (3.3)\nwhere \u03d5(\u03be) is the optimal function defined as\n\u03d5(\u03be)=min \u03b1,\u03b2\n[ \u03b1\u22a4\u03b2\u22a4 ] [Vs 0 0 Vu ] [ \u03b1 \u03b2 ] \u2212 2 [ q\u22a4s q \u22a4 u ] [\u03b1 \u03b2 ] + \u03be [ \u03b1\u22a4\u03b2\u22a4 ] [Vs 0 0 \u2212\u03f5Vu ] [ \u03b1 \u03b2 ] .\nThe biggest advantage in considering the Lagrangian dual lies in the convexity of the optimal value function \u03d5(\u03be) even though the original problem is nonconvex. Although a Lagrangian dual has a duality gap in general, the following theorem, which is well-known in the context of the control theory, assures the inexistence of the duality gap.\nTheorem 2. (No duality gap, Theorem 1 in Sturm & Zhang 2003) Under Assumption 1, the original optimization (3.2) and its Lagrangian dual (3.3) gives the same optimal value.\nMoreover, a standard discussion on the Schur complement (details are in Appendix A) boils the problem down to the following equivalent optimization\nmax \u03b3,\u03be \u03b3\ns.t.  0 \u2212q\u22a4s \u2212q\u22a4u\u2212qs Vs 0 \u2212qu 0 Vu \u2212 \u03b3 1 0 00 0 0 0 0 0  + \u03be\n0 0 00 (1\u2212 \u03f5)Vs 0 0 0 \u2212\u03f5Vu  \u2ab0 0, \u03be \u2265 0, (3.4) where \u2ab0 0 denotes the positive-definiteness of a matrix. Solving (3.4) only yields the Lagrange coefficient that is\nnot very useful. Instead, we solve the following dual problem of (3.4) defined as the optimization over a matrix A \u2208 R(1+ds+dx)\u00d7(1+ds+dx):\nmax A\u2ab00  0 \u2212q\u22a4s \u2212q\u22a4u\u2212qs Vs 0 \u2212qu 0 Vu  \u00b7A s.t. \u03bb\n0 0 00 (1\u2212 \u03f5)Vs 0 0 0 \u2212\u03f5Vu  \u00b7A \u2264 0, 1 0 00 0 0 0 0 0\n \u00b7A = 1, (3.5) where A \u00b7 B := \u2211 i,j Ai,jBi,j is the element-wise inner product between matrices. Note that Assumption 1 implies the existence of the interior of the feasible region, which leads to the Slater condition of (3.4). As is well-known, the Slater condition suffices for a large class of (possibly nonconvex) optimizations including our ones to have no duality gap, thus leads the following theorem.\nTheorem 3. Under Assumption 1, optimization (3.4) and its dual (3.5) gives the same objective value.\nIn summary, the original optimization problem (2.3) boils down to solving (3.5), which is a semidefinite optimization that off-the-shelf solvers can deal with."}, {"heading": "3.2. Convex QCQP Optimization", "text": "Although solving the dual of SDP in (3.5) yields the exact objective value, it does not always yield an exact solution of the original problem. If the solution is rank-one, decomposing the solution of SDP into A = \u03b8\u03b8\u22a4 recovers the desired solution of \u03b1,\u03b2. Moreover, how A is close to rank-one can be verified by conducting the singular value decomposition (SVD) to A and checking whether or not the second and subsequent eigenvalues are sufficiently small or not. Even if the solution is not exactly rank-one, one can still consider the first eigenvalue and the corresponding eigenvector as an approximated solution by using SVD3. However, such a solution possibly violates the constraint of the original problem, and recovering a solution that complies with the constraint is hard when A is not rank-one. Note that the interior-point method, which is used in solving SDP, tends to find an interior point that is not rank-one solution. Taking the above discussion into consideration, we also propose another optimization method.\nThe original problem (3.2) is nonconvex QCQP and easily converted into the following equivalent optimization:\n3Conducting SVD yields a primal eigenvalue \u03bb and the corresponding eigenvector v \u2208 R1+ds+dx . The solution (\u03b1,\u03b2) is the last ds + dx dimension of \u2212 \u221a \u03bbv.\nmin \u03b1,\u03b2,\u03b3 \u03b3\ns.t. [ \u03b1\u22a4\u03b2\u22a4 ] [Vs 0 0 Vu ] [ \u03b1 \u03b2 ] \u2212 2 [ q\u22a4s q \u22a4 u ] [\u03b1 \u03b2 ] \u2212 \u03b3 \u2264 0,\n[ \u03b1\u22a4\u03b2\u22a4 ] [(1\u2212 \u03f5)Vs 0 0 \u2212\u03f5Vu ] [ \u03b1 \u03b2 ] \u2264 0. (3.6)\nThe following theorem, which is derived in the context of global optimization (Yamada & Takeda, 2018), converts the nonconvex QCQP into a convex QCQP:\nTheorem 4. (Reduction to a convex problem) Assume that there exist at least one (\u03b1,\u03b2) such that (1\u2212 \u03f5)\u03b1\u22a4Vs\u03b1\u2212 \u03f5\u03b2\u22a4Vu\u03b2 < 0. Then, the feasible region of the following relaxed problem is the convex hull of the feasible region of (3.6):\nmin \u03b1,\u03b2,\u03b3 \u03b3\ns.t. [ \u03b1\u22a4\u03b2\u22a4 ] [Vs 0 0 Vu ] [ \u03b1 \u03b2 ] \u2212 2 [ q\u22a4s q \u22a4 u ] [\u03b1 \u03b2 ] \u2212 \u03b3 \u2264 0,\n[ \u03b1\u22a4\u03b2\u22a4 ] [ 1 \u03f5Vs 0 0 0 ] [ \u03b1 \u03b2 ] \u2212 2 [ q\u22a4s q \u22a4 u ] [\u03b1 \u03b2 ] \u2212 \u03b3 \u2264 0.\n(3.7)\nProof sketch of Theorem 4. Note that the second constraint in (3.7) is a linear combination of the two constraints of (3.6), which implies that the feasible region of (3.7) includes the feasible region of (3.6). For each feasible point (\u03b10,\u03b20, \u03b30) of (3.7) that is infeasible in (3.6), we explicitly construct two points that lie in the feasible region of (3.6) such that (\u03b10,\u03b20, \u03b30) is a linear combination of the two points. The formal proof follows directly from Theorem 2 in Yamada & Takeda (2018) by putting t = \u03b3, x = (\u03b1,\u03b2), \u03c3 = 0, \u03c3 = 1/\u03f5.\nNote that that Assumption 1 implies the conditions required in Theorem 4. The linearity of the objective, combined with Theorem 4 states that solving (3.7) yields an optimal solution of (3.6).\nIn summary, Theorem 4 allows us to relax the constraint so that the new feasible region is convex without compromising its objective value. As a result, (3.7), which is a convex QCQP, is computed efficiently by off-the-shelf optimizers."}, {"heading": "3.3. Computational Complexity", "text": "The proposed optimization runs in time O(n): Building U requires O((d2sn + d 3 s)dx) time because for each feature in x we train a linear regressor from s to x that yields each feature of u. Moreover, optimization in SDP and convex QCQP requires empirical variance Vs and Vu that are computed in O((d2x + d 2 s)n). The sizes of matrices in SDP and QCQP are O((dx + ds) \u00d7 (dx + ds)), which is\nconstant to n. One can check that the required memory is O((dx + ds) 2 + (dx + ds)n).\nNote that, the interior point method is known as a polynomial-time method for finding solutions for SDPs and convex QCQPs with arbitrary precision. The complexity of SDP and convex 2-QCQP are O((ds + dx)3.5) and O((ds + dx)\n3), respectively (see Section 6.6.1 in Ben-Tal & Nemirovskiaei 2001). In practice, our simulation in Appendix B shows SDP and convex QCQP appear to scale more similarly to O((ds + dx)2) around 10 \u2264 ds + dx \u2264 3, 000, which is not very surprising because many instances scale better than the worst-case."}, {"heading": "3.4. Regularization", "text": "It is straightforward to add a regularizer into our optimization problem described in Section 3: That is, we can incorporate regularization term (\u03bb/n)(\u03b1T\u03b1+ \u03b2\u22a4\u03b2), where a larger \u03bb > 0 induces a stronger regularization toward smaller parameters. The regularizer increases the diagonal entries as Vs + (\u03bb/n)Is and Vu + (\u03bb/n)Iu, and does not change positive definite property of Vs and Vu."}, {"heading": "3.5. Approximated Kernelization", "text": "The kernelized least squared regression with fairness constraint is formalized as follows. Let Zs(s) (resp. Zu(u)) be the functions that map s (resp. u) into high-dimensional spaces, and Ks(si, sj) = Z\u22a4s (si)Zs(sj) \u2208 R (resp. Ku(ui,uj) = Z \u22a4 u (ui)Zu(uj) \u2208 R) be the corresponding positive-definite kernel functions. The representer theorem implies that the estimator y\u0302i of datapoint i is written as a linear combination of the kernel functions as\ny\u0302i = n\u2211 j=1 cj,sKs(si, sj) + cj,uKu(ui,uj),\nwhere cj,s, cj,u \u2208 R are the weight parameters associated with each datapoint j. With an abuse of notation, let Ks and Ku be the corresponding n\u00d7n matrices, and cs, cu be corresponding size-n vectors. Let\nSs = c \u22a4 s K 2 scs, Su = c \u22a4 uK 2 ucu,\nss = c \u22a4 s Ksy, su = c \u22a4 uKuy, (3.8)\nthen the corresponding optimization is:\nmin Ss + Su \u2212 2ss \u2212 2su s.t. (1\u2212 \u03f5)Ss \u2212 \u03f5Su \u2264 0. (3.9)\nUnfortunately, the following two issues make the optimization in (3.9) impractical: (i) As is customary with kernel\nlearning, solving (3.9) is computationally prohibiting with large n because the corresponding optimizations involve O(n \u00d7 n) matrices. Moreover, (ii) removing the correlation between s and u on the (possibly infinite) representation space Zs(s) and Zu(u) is highly non-trivial.\nTo address the issues above, an approximated kernel representation methods apply: Nystro\u0308m methods (Rasmussen & Williams, 2006) and the random Fourier features (Rahimi & Recht, 2008) provide us a finite representation of Ks(si, sj) = Z\u22a4s (si)Zs(sj) and Ku(ui,uj) = Z\u22a4u (ui)Zu(uj). With these representation we no longer use the gram matrices Ks and Ku: We solve the original optimization (3.2) with converted features Z\u22a4s (si) and Z\u22a4u (ui). Moreover, to remove the correlation between s and u, we first map x into the representation space Zu(x), and then remove correlation between Zs(s) and Zu(x) by applying linear regression on the finite representation space. Assuming that the dimension of Zs (resp. Zu) is ps (resp. pu), the new optimization involves matrices of O((ps + pu)\u00d7 (ps + pu)). Therefore, if we choose ps, pu as constants with respect to n, the optimizations scale with a large dataset."}, {"heading": "4. Experiment", "text": "This section verifies the performance of the proposed method in four real-world datasets.\nComputation environment: The simulation here was conducted by using modern Xeon-core PC servers4. Preliminary experiment (Appendix B) revealed that the running times of SDP and convex QCQP optimization are more or less the same. Taking the fact that the convex QCQP always yields an exact solution into consideration, we adapted it in the subsequent simulations. We solved the convex QCQP optimization by using the Gurobi optimizer5.\n4The source code used in the simulation is available at https://github.com/jkomiyama/fairregresion.\n5http://www.gurobi.com/\nDatasets: The Communities and Crime (C&C) dataset combines socio-economic data and crime rate data on communities in the United States where each datapoint corresponds to a community. The target y is the normalized violent crime rate of each community and s(1), s(2) are the ratio of African American people and foreign-born people, respectively. The COMPAS dataset (Angwin et al., 2016) is a collection of criminal offenders screened in Florida U.S. during 2013\u20132014, where x is a demographic and criminal records of offenders and y is whether or not a person recidivated within two years after the screening, and s(1), s(2) are the gender and race, respectively. The National Longitudinal Survey of Youth (NLSY) dataset6 involves survey results of the U.S. Bureau of Labor Statistics that is intended to gather information on the labor market activities and other life events of several groups, where y is the income of each person in 1990 and s(1), s(2) are the gender and age, respectively. The Law School Admissions Council (LSAC) dataset7 is a survey among students attending law schools in the U.S. in 1991, where y indicates the GPA score of each student, and s(1), s(2) are the race and the age, respectively. Statistics of the datasets are in Table 1, and further details of the datasets are in Appendix C.\nEvaluation settings: We split the data into 5-folds: One was for validation dataset that was used to optimize the hyperparameters, and another was for the test dataset. The resting three folds were the training dataset. All the reported results are the ones of the test dataset averaged over the 5 runs with different choices of the folds. The features u were built from x by de-correlating it from s by using regularized least square regression. The hyperparameters were optimized in validation datasets among \u03bb = {1.0, 10.0, 100.0} and \u03b3 = {0.1, 1.0, 10.0, 100.0}, where \u03b3 was the hyper-parameter of the RBF kernel K(x,y) = exp(\u2212\u03b3(x\u2212 y)2)."}, {"heading": "4.1. Results", "text": "Figure 2 shows the results of our simulations. The following summarizes our observation: (i) In all datasets, there was a clear tradeoff between the predictive power (i.e., RMSE) and the degree of fairness measured by \u03f5. (ii) The advantage of non-linear representation varied: In C&C and NLSY, the linear method performs as good as the two kernelized methods, whereas in COMPAS and LSAC the kernel methods significantly outperformed the linear. (iii) The correlation coefficient was saturated at some point to which the predictive power of s is fully utilized. (iv) While two kernel methods performed similarily in the first three datasets, \u201cKernel-rff-full\u201d significantly outperformed \u201cKernel-rff-half\u201d in the LSAC dataset. In other words, the\n6https://www.bls.gov/nls/ 7http://www2.law.ucla.edu/sander/Systemic/Data.htm\nadvantage of the non-linear sensitive attributes s was observed in LSAC: This dataset involved a numeric sensitive attribute (i.e., age) from which the method exploited the non-linear relationship between s and y. (v) The correlation between s(l) and y varied among sensitive features {s(1), s(2)}: For example, in the NLSY dataset, gender was more predictive than age, and thus the regressor exploited more on the former attribute than the latter."}, {"heading": "5. Conclusion", "text": "We have focused on the optimization perspective of fair regression. We considered CoD that is a natural extension of the correlation coefficient into multiple sensitive attributes as a fairness criterion. Although the least square regressor subject to a CoD constraint involves a nonconvex feasible region, it boils down to exactly-solvable convex optimizations. The proposed method has the following aspects: (i) The exact control on the fairness level as a constraint, (ii) a capability of dealing with numeric and multiple s and (iii) an extension that captures non-linear interaction between sensitive and non-sensitive attributes. We consider this result as a first step that controls the nonconvexity that naturally appears in considering fairness related constraints.\nWhile the prevention of disparate impact is justified by the legal contexts, some alternative criteria of fairness, such as the equality odds condition (Hardt et al., 2016; Zafar et al., 2017b), have been proposed. Considering them as a constraint would be interesting."}, {"heading": "Acknowledgements", "text": "The authors sincerely thank the anonymous reviewers for their useful comments. The authors are grateful to Toshihiro Kamishima for pointing out related papers. This work was supported in part by JSPS KAKENHI Grant Number 17K12736, 18K17998 and Inamori Foundation Research Grant."}], "year": 2018, "references": [{"title": "Iterative orthogonal feature projection for diagnosing bias in black-box models. In Fairness, Accountability, and Transparency in Machine Learning (FATML), 2016", "authors": ["Adebayo", "Julius", "Kagal", "Lalana"], "year": 2016}, {"title": "Auditing blackbox models for indirect influence", "authors": ["Adler", "Philip", "Falk", "Casey", "Friedler", "Sorelle A", "Nix", "Tionney", "Rybeck", "Gabriel", "Scheidegger", "Carlos", "Smith", "Brandon", "Venkatasubramanian", "Suresh"], "venue": "Knowl. Inf. Syst.,", "year": 2018}, {"title": "Machine Bias: Theres software used across the country to predict future criminals", "authors": ["Angwin", "Julia", "Larson", "Jeff", "Mattu", "Surya", "Kirchner", "Lauren"], "year": 2016}, {"title": "Lectures on Modern Convex Optimization: Analysis, Algorithms, and Engineering Applications", "authors": ["Ben-Tal", "Aharon", "Nemirovskiaei", "Arkadiaei Semenovich"], "venue": "Society for Industrial and Applied Mathematics,", "year": 2001}, {"title": "A convex framework for fair regression. In Fairness, Accountability, and Transparency in Machine Learning (FATML), 2017", "authors": ["Berk", "Richard", "Heidari", "Hoda", "Jabbari", "Shahin", "Joseph", "Matthew", "Kearns", "Michael", "Morgenstern", "Jamie", "Neel", "Seth", "Roth", "Aaron"], "year": 2017}, {"title": "Controlling attribute effect in linear regression", "authors": ["Calders", "Toon", "Karim", "Asim", "Kamiran", "Faisal", "Ali", "Wasif", "Zhang", "Xiangliang"], "venue": "IEEE 13th International Conference on Data Mining, pp", "year": 2013}, {"title": "Fair boosting: a case study", "authors": ["Fish", "Benjamin", "Kun", "Jeremy", "Lelkes", "\u00c1d\u00e1m D\u00e1niel"], "venue": "In Workshop on Fairness, Accountability, and Transparency in Machine Learning (FATML),", "year": 2015}, {"title": "Prediction with model-based neutrality. In Machine Learning and Knowledge Discovery in Databases - European Conference", "authors": ["Fukuchi", "Kazuto", "Sakuma", "Jun", "Kamishima", "Toshihiro"], "venue": "ECML PKDD,", "year": 2013}, {"title": "Satisfying real-world goals with dataset constraints", "authors": ["Goh", "Gabriel", "Cotter", "Andrew", "Gupta", "Maya R", "Friedlander", "Michael P"], "venue": "In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems,", "year": 2016}, {"title": "Measuring statistical dependence with hilbert-schmidt norms", "authors": ["Gretton", "Arthur", "Bousquet", "Olivier", "Smola", "Alexander J", "Sch\u00f6lkopf", "Bernhard"], "venue": "In Algorithmic Learning Theory, 16th International Conference,", "year": 2005}, {"title": "Equality of opportunity in supervised learning", "authors": ["Hardt", "Moritz", "Price", "Eric", "Srebro", "Nati"], "venue": "In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems,", "year": 2016}, {"title": "Classification with no discrimination by preferential sampling", "authors": ["Kamiran", "Faisal", "T. Calders"], "venue": "In The annual machine learning conference of Belgium and The Netherlands (BENELEARN),", "year": 2010}, {"title": "Enhancement of the neutrality in recommendation", "authors": ["Kamishima", "Toshihiro", "Akaho", "Shotaro", "Asoh", "Hideki", "Sakuma", "Jun"], "venue": "In Proceedings of the 2nd Workshop on Human Decision Making in Recommender Systems,", "year": 2012}, {"title": "Model-based approaches for independenceenhanced recommendation", "authors": ["Kamishima", "Toshihiro", "Akaho", "Shotaro", "Asoh", "Hideki", "Sato", "Issei"], "venue": "In IEEE International Conference on Data Mining Workshops,", "year": 2016}, {"title": "Quadratic programming with one negative eigenvalue is np-hard", "authors": ["Pardalos", "Panos M", "Vavasis", "Stephen A"], "venue": "J. Global Optimization,", "year": 1991}, {"title": "Fair kernel learning. In Machine Learning and Knowledge Discovery in Databases ", "authors": ["P\u00e9rez-Suay", "Adri\u00e1n", "Laparra", "Valero", "Mateo-Garcia", "Gonzalo", "Mu\u00f1oz-Mar\u0131", "Jordi", "G\u00f3mez-Chova", "Luis", "Camps-Valls", "Gustau"], "venue": "European Conference, ECML PKDD 2017,", "year": 2017}, {"title": "Gaussian processes for machine learning. Adaptive computation and machine learning", "authors": ["Rasmussen", "Carl Edward", "Williams", "Christopher K. I"], "venue": "ISBN 026218253X. URL http://www.worldcat.org/ oclc/61285753", "year": 2006}, {"title": "Discrimination aware classification for imbalanced datasets", "authors": ["Ristanoski", "Goce", "Liu", "Wei", "Bailey", "James"], "venue": "In 22nd ACM International Conference on Information and Knowledge Management,", "year": 2013}, {"title": "Data mining for discrimination", "authors": ["Ruggieri", "Salvatore", "Pedreschi", "Dino", "Turini", "Franco"], "venue": "discovery. TKDD,", "year": 2010}, {"title": "On cones of nonnegative quadratic functions", "authors": ["Sturm", "Jos F", "Zhang", "Shuzhong"], "venue": "Math. Oper. Res.,", "year": 2003}, {"title": "Introductory Econometrics: A Modern Approach. South-Western", "authors": ["Wooldridge", "Jeffrey M"], "venue": "Cengage Learning, 5th edition,", "year": 2013}, {"title": "Successive lagrangian relaxation algorithm for nonconvex quadratic optimization", "authors": ["Yamada", "Shinji", "Takeda", "Akiko"], "venue": "Journal of Global Optimization,", "year": 2018}, {"title": "Fairness constraints: Mechanisms for fair classification", "authors": ["Zafar", "Muhammad Bilal", "Valera", "Isabel", "Gomez-Rodriguez", "Manuel", "Gummadi", "Krishna P"], "venue": "In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,", "year": 2017}, {"title": "Learning fair representations", "authors": ["Zemel", "Richard S", "Wu", "Yu", "Swersky", "Kevin", "Pitassi", "Toniann", "Dwork", "Cynthia"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "year": 2013}, {"title": "Handling conditional discrimination", "authors": ["Zliobaite", "Indre", "Kamiran", "Faisal", "Calders", "Toon"], "venue": "IEEE International Conference on Data Mining, pp", "year": 2011}], "id": "SP:9d6fcd30b6af9049658588bd3f6b30f748488566", "authors": [{"name": "Junpei Komiyama", "affiliations": []}, {"name": "Akiko Takeda", "affiliations": []}, {"name": "Junya Honda", "affiliations": []}, {"name": "Hajime Shimao", "affiliations": []}], "abstractText": "The unfairness of a regressor is evaluated by measuring the correlation between the estimator and the sensitive attribute (e.g., race, gender, age), and the coefficient of determination (CoD) is a natural extension of the correlation coefficient when more than one sensitive attribute exists. As is well known, there is a trade-off between fairness and accuracy of a regressor, which implies that a perfectly fair optimizer does not always yield a useful prediction. Taking this into consideration, we optimize the accuracy of the estimation subject to a user-defined level of fairness. However, a fairness level as a constraint induces a nonconvexity of the feasible region, which disables the use of an off-the-shelf convex optimizer. Despite such nonconvexity, we show that an exact solution is available by using tools of global optimization theory. Unlike most of existing fairness-aware machine learning methods, our method allows us to deal with numeric and multiple sensitive attributes.", "title": "Nonconvex Optimization for Regression with Fairness Constraints"}
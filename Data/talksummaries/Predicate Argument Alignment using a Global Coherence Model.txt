8	16	We treat this task as a global inference problem, leveraging multiple sources of semantic information identified at the document level.
9	31	Global inference for this problem is mostly unexplored, with the exception of Lee et al. (2012) (discussed in § 8).
28	122	The result may be links that conflict in their interpretation of the document.
30	45	The global nature of this task is similar to word alignment for machine translation (MT).
41	19	Notation An alignment between an item indexed by i in the source document and j in the target document is represented by variable zij ∈ {0, 1}, where zij = 1 indicates that items i and j are aligned.
46	32	sij = w · f(zij) (1) where sij is the score of linking items i and j.
54	17	Our goal is to develop joint factors that improve over the feature rich local factors baseline by considering global information.
82	16	Predicate-centric We begin with a predicatecentric factor, which views scores an alignment between predicates based on their arguments, i.e. the two predicates share the same arguments.
83	56	Ideally, two predicates can only align when their arguments are coreferent.
84	29	However, in practice we may incorrectly resolve argument links, or there may be implicit arguments that do not appear as syntactic dependencies of the predicate trigger.
86	56	For every predicate alignment zpij , we add a factor φpsa whose score spsa is a penalty for having no argument overlap; predicates share arguments (psa).
88	29	Entity-centric We expect similar behavior from arguments (entities).
92	29	Temporal Information Temporal ordering, in contrast to textual ordering, can indicate when predicates cannot align: we expect aligned predicates in both documents to share the same temporal relations.
93	32	SemEval 2013 included a task on predicting temporal relations between events (UzZaman et al., 2013).
99	50	Given this configuration the following alignments conflict with the in-doc relations: zax zby zay zbx In-Doc Relations * * 1 1 R1 = R2 1 1 * * R1 = R−12 where 1 means there is a link and * means there is a link or no link (wildcard).
101	32	We introduce a factor that penalizes these conflicting configurations.
102	125	In every instance where the predicted temporal relation for a pair of predicate alignments matches one of the conflict patterns above, we add a factor using zφtemp : zφtemp ≥ zayzbx if paR1pb, pxR2py, R1 = R2 zφtemp ≥ zaxzby if paR1pb, pxR2py, R1 = R−12 (8) Thus sφtemp is the cost of disagreeing with the indoc temporal relations.
109	31	There is a local similarity score def train(alignments): w = init_weights() working_set = set() while True: xi = solve_ILP(w, working_set) c = most_violated_constraint(w, alignments) working_set.add(c) if hinge(c, w) < xi: break coefficient on every alignment variable, and a joint factor similarity score on every quadratic variable.
110	20	These quadratic variables are constrained by products of the original alignment variables.
116	46	When we decode, we take the product of the weights and the features to get the costs for the ILP (e.g. sφ = w · f(φ)).
117	55	When we optimize our SVM objective, we take the product of the alignment variables and the features to get modified features for the SVM: f(z) = ∑ ij zijf(zij) + ∑ φ∈Φ zφf(φ) (11) Since we cannot iterate over the exponentially many margin constraints, we solve for this optimization using the cutting-plane learning algorithm.
118	37	This algorithm repeatedly asks the “separation oracle” for the most violated SVM constraint, which finds this constraint by solving: arg max ẑ1...ẑN ∑ i w · f(ẑi) + ∆(zi, ẑi) (12) subject to the constraints defined by the joint factors.
119	24	When the separation oracle returns a constraint that is not violated or is already in the working set, then we have a guarantee that we solved the original SVM problem with exponentially many constraints.
148	25	Systems Following Roth and Frank (2012) and Wolfe et al. (2013) we include a Lemma baseline for identifying alignments which will align any two predicates or arguments that have the same lemmatized head word.6 The Local baseline uses the same features as Wolfe et al., but none of our joint factors.
157	17	Fertility factors provide the largest improvements from any single constraint.
174	26	While each of the joint factors all improve over the baselines on RF, the full model with all the joint factors does not perform as well as with some factors excluded.
200	47	Overall, this work demonstrates the benefits of considering global document information as part of natural language understanding.
202	17	This problem formulation would capture the evolution of a breaking news story, which closely matches the type of data (news articles) considered in this work (EECB and RF datasets).
203	55	This formulation ties into existing work on news summarization, topic detection and tracking, an multi-document NLU.
204	19	This goes hand with work on better intra-document relation prediction methods, such as the temporal relation model used in this work, to lead to better joint linking decisions.

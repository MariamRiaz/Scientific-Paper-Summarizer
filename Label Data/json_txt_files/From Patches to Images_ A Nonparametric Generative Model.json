{"sections": [{"heading": "1. Introduction", "text": "Models of the statistical structure of natural images play a key role in computer vision and image processing (Srivastava et al., 2003). Due to the high dimensionality of the images captured by modern cameras, a rich research literature instead models the statistics of small image patches. For example, the K-SVD method (Elad & Aharon, 2006) generalizes K-means clustering to learn a dictionary for sparse coding of image patches. The state-of-the-art learned simultaneous sparse coding (LSSC, Mairal et al. (2009)) and block matching and 3D filtering (BM3D, Dabov et al. (2008)) methods integrate clustering, dictionary learning,\n1Brown University, Providence, RI, USA. 2Harvard University, Cambridge, MA, USA. 3University of California, Irvine, CA, USA. Correspondence to: Geng Ji <gji@cs.brown.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nand denoising to extract information directly from a single corrupted image. Alternatively, the accurate expected patch log-likelihood (EPLL, Zoran & Weiss (2011)) method maximizes the log-likelihood of overlapping image patches under a finite Gaussian mixture model learned from uncorrupted natural images.\nWe show that with minor modifications, the objective function underlying EPLL is equivalent to a variational loglikelihood bound for a novel generative model of whole images. Our model coherently captures overlapping image patches via a randomly positioned spatial grid. By deriving a rigorous variational bound, we then develop improved nonparametric models of natural image statistics using the hierarchical Dirichlet process (HDP, Teh et al. (2006)). In particular, DP mixtures allow an appropriate model complexity to be inferred from data, while the hierarchical DP captures the patch self-similarities and repetitions that are ubiquitous in natural images (Je\u0301gou et al., 2009). Unlike previous whole-image generative models such as fields of experts (FoE, Roth & Black (2005)), which uses a single set of Markov random field parameters to model all images, our HDP model learns image-specific clusters to accurately model distinctive textures. Coupled with a scalable structured variational inference algorithm, we improve on the excellent denoising accuracy of the LSSC and BM3D algorithms, while providing a Bayesian nonparametric model with a broader range of potential applications."}, {"heading": "2. Expected Patch Log-likelihood", "text": "Our approach is derived from models of small (8\u00d7 8 pixel) patches of a large natural image x. Let Pi be a binary indicator matrix that extracts the G = 82 pixels Pix \u2208 RG in patch i. To reduce sensitivity to lighting variations, a contrast normalizing transform is applied to remove the mean (or \u201cDC component\u201d) of the pixel intensities in each patch:\nvi = Pix\u2212 1G1TPix = BPix, (1)\nfor a \u201czero-centering\u201d matrix B. Zoran & Weiss (2012) show that a finite mixture of K zero-mean Gaussians,\np(vi) = \u2211K k=1 \u03c0kNorm(vi | 0,\u039b\u22121k ), (2)\nis superior to many classic image models in terms of predictive likelihood and patch denoising performance.\nThe widely-used EPLL image restoration framework measures the quality of a reconstruction by the expected patch log-likelihood, \u201cassuming a patch location in the image is chosen uniformly at random\u201d (Zoran & Weiss, 2011). Given a corrupted image y, EPLL estimates a clean image x by minimizing the objective:\nmin x\n\u03bb 2 \u2016x\u2212 y\u20162 \u2212\u2211i log p(BPix). (3)\nHere, the sum ranges over all overlapping, completely visible (uncropped) image patches. The constant \u03bb is determined by the noise level of the corrupted image y.\nDirect optimization of Eq. (3) is challenging, so inspired by half quadratic splitting (Geman & Yang, 1995), the EPLL objective can be reformulated as follows:\nmin x,v\u0304\n\u03bb 2 \u2016x\u2212 y\u20162 + \u2211 i \u03ba 2 \u2016Pix\u2212 v\u0304i\u20162 \u2212 log p(Bv\u0304i). (4)\nEach patch i is allocated an auxiliary variable v\u0304i, which (unlike the vi variable in Eq. (1)) includes an estimate of the mean patch intensity. This augmented objective leads to closed-form coordinate descent updates. Gating. Assign each patch i to some cluster zi:\nzi = arg max k\n\u03c0k Norm ( BPix | 0,\u039b\u22121k + \u03baI ) . (5)\nFiltering. Given an approximate clean image x and cluster assignments z, denoise patches via least squares:\nv\u0304i = ( I + \u03ba\u22121BT\u039bziB )\u22121 Pix. (6)\nMixing. Given a fixed set of auxiliary patches v\u0304 and the noisy image y, a denoised image x is estimated as\nx = ( \u03bbI + \u03ba \u2211 i PTi Pi )\u22121( \u03bby + \u03ba \u2211 i PTi v\u0304i ) . (7)\nAnnealing. Optimal solutions of Eq. (4) approach those of the EPLL objective in Eq. (3) as \u03ba\u2192\u221e. EPLL denoising algorithms slowly increase \u03ba via an annealing schedule that must be tuned for best performance. Justification? Empirically, the intuitive EPLL objective is much more effective than baselines which use only a subset of non-overlapping patches, or average independently denoised patches (Zoran & Weiss, 2011). But why should we optimize the expected log-likelihood, instead of the expected likelihood or another function of patch-specific likelihoods? And how can the EPLL heuristic be generalized to capture more complex statistics of natural images? This paper answers these questions by linking EPLL to a rigorous, nonparametric generative model of whole images."}, {"heading": "3. Mixture Models for Grids of Image Patches", "text": "We now develop the HDP-Grid generative model summarized in Fig. 1, which uses randomly placed patch grids to formalize the EPLL objective, and hierarchical DP mixtures to capture image patch self-similarity."}, {"heading": "3.1. Hierarchical Dirichlet Process Mixtures", "text": "The hierarchical Dirichlet process (HDP, Teh et al. (2006)) is a Bayesian nonparametric prior used to cluster groups of related data; we model natural images as groups of patches. The HDP shares visual structure, such as patches of grass or bricks, by sharing a common set of clusters (called topics in applications to text data) across images. In addition, the HDP models image-specific variability by allowing each image to use this shared set of clusters with unique frequencies; grass might be abundant in one image but absent in another. Via the HDP, we can learn the proper number of hidden clusters from data, and discover new clusters as we collect new images with novel visual textures.\nThe HDP uses a stick-breaking construction to generate a corpus-wide vector \u03c00 = [\u03c001, \u03c002, . . . , \u03c00k, . . .] of frequencies for a countably infinite set of visual clusters:\n\u03b2k \u223c Beta(1, \u03b3), \u03c00k(\u03b2) , \u03b2k \u220fk\u22121 `=1 (1\u2212 \u03b2`). (8) The HDP allocates each image m its own cluster frequencies \u03c0m, where the vector \u03c00 determines the mean of a DP prior on the frequencies of shared clusters:\n\u03c0m \u223c DP(\u03b1\u03c00), E[\u03c0mk] = \u03c00k. (9) When the concentration parameter \u03b1 < 1, we capture the \u201cburstiness\u201d and self-similarity of natural image regions (Je\u0301gou et al., 2009) by placing most probability mass in \u03c0m on a sparse subset of global clusters."}, {"heading": "3.2. Image Generation via Random Grids", "text": "We sample pixels in imagem via a randomly placed grid of patches. When each patch has G pixels, Fig. 2 shows there are exactlyG grid alignments for an image of arbitrary size. The alignment wm \u2208 {1, . . . , G} has a uniform prior: wm \u223c Cat(1/G, . . . , 1/G). (10) Modeling multiple overlapping grids is crucial to capture real image statistics. As the true grid alignment for each image is uncertain, posterior inference will favor images\nthat are likely under all possible wm. Models based on a single, fixed grid produce severe artifacts at patch boundaries, as shown in Fig. 2 of Zoran & Weiss (2011)."}, {"heading": "3.3. Patch Generation via Gaussian Mixtures", "text": "Gaussian mixtures provide excellent density models for natural image patches (Zoran & Weiss, 2012). We associate clusters with zero-mean, full-covariance Gaussian distributions on patches with G pixels. We parameterize cluster k by a precision (inverse covariance) matrix \u039bk \u223c Wish(\u03bd,W ), whose conjugate Wishart prior has \u03bd degrees of freedom and scale matrix W . Given that wm = g, each of the Nmg patches vmgn in grid g is sampled from an infinite mixture with image-specific cluster frequencies:\np(vmgn|wm = g) = \u221e\u2211 k=1 \u03c0mkNorm(vmgn|0,\u039b\u22121k ). (11) Let zmgn | wm = g \u223c Cat(\u03c0m) denote the cluster that generates patch n. To account for the contrast normalization of Eq. (1), the intensities in patch n are shifted by an independent, scalar \u201cDC offset\u201d umgn: p(umgn | wm = g) = Norm(umgn | r, s2). (12) Finally, if wm 6= g so that grid g is unobserved, we sample (zmgn, vmgn, umgn) from some reference distribution\nindependent of the HDP mixture model parameters."}, {"heading": "3.4. From Patches to Corrupted Images", "text": "Given patches vmg with offsets umg generated via grid wm = g, we sample a whole \u201cclean image\u201d xm as\nNorm ( xm | \u2211Nmg n=1 PTmgnv\u0304mgn, \u03b4 2I ) , (13)\nwhere v\u0304mgn , Cmgnvmgn+umgn. Binary indicator matrices Pmgn, as in Sec. 2, stitch together patches in the chosen grid g. Image xm is then generated by adding independent Gaussian noise with small variance \u03b42. Most patches in the chosen grid will be fully observed in xm, but as illustrated in Fig. 2, some may be clipped by the image boundary. Indicator matrices Cmgn are defined so Cmgnvmgn + umgn is a vector containing the observed pixels from patch n.\nFor image restoration tasks, the observed image ym is a corrupted version of some clean image xm that we would like to estimate. Models of natural image statistics are commonly validated on the problem of image denoising, where xm is polluted by additive white Gaussian noise:\np(ym | xm) = Norm(ym | xm, \u03c32I). (14) The variance \u03c32 \u03b42 indicates the noise level. We also validate our model on image inpainting problems (Bertalmio et al., 2000), where some pixels are observed without noise but others are completely missing. By replacing Eq. (14) with other linear likelihood models, our novel generative model for natural images may be easily applied to other tasks including image deblurring (Zoran & Weiss, 2011), image super resolution (Yang & Huang, 2010), and color image demosaicing (Mairal et al., 2009)."}, {"heading": "4. Variational Inference", "text": "We now develop scalable learning algorithms for our nonparametric, grid-based image model. We first examine a baseline DP Grid model in which the same cluster frequencies \u03c00 are shared by all images. Our full HDP Grid model then learns image-specific cluster frequencies \u03c0m, and instantiates new clusters to model unique visual textures."}, {"heading": "4.1. DP Grid: Variational Inference", "text": "Our goal is to infer the DP Grid model parameters that best explain observed images which may be clean (xm) or corrupted by noise (ym). The DP Grid model uses the same cluster probabilities \u03c00, generated from stickbreaking weights \u03b2 as in Eq. (8), for all images.\nLearning from clean images. Given a training set D of uncorrupted images x1, . . . xM , we estimate the posterior distribution p(\u03b2,\u039b, w,\u03a8patch | x) for our global mixture model parameters \u03b2 and \u039b, grid assignment indicators wm, and patch-level latent variables \u03a8patchm = {um, vm, zm}.\nExact posterior inference is intractable, so we instead find an approximate posterior q(\u00b7) = q(\u03b2,\u039b, w,\u03a8patch) minimizing the KL divergence (Wainwright & Jordan, 2008) from the true posterior p(\u00b7|x). Equivalently, our variational method maximizes the following objective L:\nmax q\u2208Q L(q, x) = max q\u2208Q Eq [ log p(x, \u00b7) q(\u00b7) ] \u2264 log p(x). (15)\nWe constrain the solution of our optimization to come from a tractable family of structured mean-field distributions Q, parameterized by free parameters. Unlike na\u0131\u0308ve mean-field methods which assume complete posterior independence, our structured mean-field approximation is more accurate and includes dependencies between some latent variables:\nq(\u00b7) = \u221e\u220f k=1 q(\u039bk)q(\u03b2k) \u00b7 M\u220f m=1 q(wm)q(\u03a8 patch m |wm).\nAs in Hughes & Sudderth (2013), this approximate posterior family contains infinitely many clusters, just like the true posterior. Rather than applying a fixed truncation to the stick-breaking prior (Blei & Jordan, 2006), we dynamically truncate the patch assignment distributions q(z) to only use the first K clusters to explain the M observed images. Clusters with indices k > K then have factors q(\u039bk) set to the prior, and need not be explicitly represented.\nGlobal mixture model. The global cluster weights \u03b2 and precision matrices \u039b have standard exponential family forms (free parameters are marked by hats):\nq(\u039bk) = Wish ( \u03bd\u0302k, W\u0302k ) , q(\u03b2k) = Beta ( \u03c1\u0302k\u03c9\u0302k, (1\u2212 \u03c1\u0302k)\u03c9\u0302k ) .\nHere \u03c1\u0302k = Eq[\u03b2k], and \u03c9\u0302k controls the variance of q(\u03b2k).\nImage-specific alignment. For natural images, all grid alignments are typically of similar quality, so we fix a uniform alignment posterior q(wm) = Cat ( 1 G , . . . , 1 G ) . This simplifies many updates while still avoiding artifacts that would arise from a single, non-overlapping patch grid.\nPatch-specific factors. The patch-specific variables \u03a8patch have structured posteriors, conditioned on the value of the grid indicator wm for the current image:\nq(zmgn | wm = g) = Categorical ( r\u0302mgn1, ..., r\u0302mgnK ) ,\nq(umgn | wm = g) = Norm ( u\u0302mgn, \u03c6\u0302 u mgn ) ,\nq(vmgn | wm = g,zmgn = k) = Norm ( v\u0302mgnk, \u03c6\u0302 v mgnk ) .\nBelow, we let Eq[\u00b7] denote the conditional expectation with respect to the variational distribution q, given wm.\nLearning. Given clean images x, we perform coodinate ascent on the objective L, alternatively updating one factor among q(\u03b2)q(\u039b)q(w)q(\u03a8patch). Most updates have closed forms due to the exponential families defining Q (see supplement). As one intuitive example, consider the update for\nthe cluster precision matrix posterior q(\u039bk|\u03bd\u0302k, W\u0302k):\n\u03bd\u0302k = \u03bd + 1\nG Nk, Nk = M\u2211 m=1 G\u2211 g=1 Nmg\u2211 n=1 r\u0302mgnk, (16)\nW\u0302k = W + 1\nG M\u2211 m=1 G\u2211 g=1 Nmg\u2211 n=1 Eq [ 1k(zmgn)vmgnv T mgn ] .\ufe38 \ufe37\ufe37 \ufe38\nSk\nStatistic Nk(r\u0302) counts patches assigned to cluster k, while Sk(r\u0302, v\u0302, \u03c6\u0302\nv) aggregates second moments. These updates follow the standard form of prior parameter plus expected sufficient statistic, except the statistics are averaged (not simply added) across the G grid alignments."}, {"heading": "4.2. Image Denoising and Connections to EPLL", "text": "Given a corrupted image ym, we seek to compute the posterior p(xm | ym,D), where we condition on the training set D. Our variational posterior family Q now includes an additional factor for the unobserved, \u201cclean\u201d image xm:\nq(xm) = Norm ( xm | x\u0302m, \u03c6\u0302xm ) . (17)\nThe variational inference objective becomes\nmax q\u2208Q\nEq [ log\np(D, ym, xm, \u00b7) q(xm, \u00b7)\n] \u2264 log p(ym,D), (18)\nand the coordinate ascent update for q(xm) equals\nx\u0302m = \u03c6\u0302 x m (ym \u03c32 + hm \u03b42 ) , \u03c6\u0302xm = \u03b42\u03c32 \u03b42 + \u03c32 I. (19)\nThe updated covariance is diagonal, improving computational efficiency. The mean depends on the average image vector across all patches in all grids, denoted by hm:\nhm , 1\nG G\u2211 g=1 Nmg\u2211 n=1 PTmgn(CmgnEq[vmgn] + u\u0302mgn). (20)\nNote that the update for x\u0302m in Eq. (19) is similar to the EPLL update in Eq. (7), except that some terms involving projection matrices become constants because we account for partially observed patches. Modeling partial patches is necessary to produce a valid likelihood bound in Eq. (18).\nIn fact, as we show below all three terms in the EPLL objective in Eq. (4) are very similar to our proposed minimization objective function \u2212L, up to a scale factor of G. Of course, a key difference is that our objective seeks full posteriors rather than point estimates, and enables the HDP model of multiple images detailed in Sec. 4.3.\nEPLL Term 1. When we set \u03bb , G\u03c32 , the first term of the EPLL objective in Eq. (4) becomes\nG \u00b7 12\u03c32 (x\u2212 y)T (x\u2212 y). (21) Similarly, suppressing the subscript m denoting the image for simplicity, Eq[\u2212 log p(y|x)] in our \u2212L simplifies as\n1 2\u03c32Eq[(x\u2212 y)T (x\u2212 y)]. (22)\nEPLL Term 2. Taking the second term in Eq. (4) and substituting \u03ba = 1/\u03b42, we have:\n1 2\u03b42 \u2211 i(Pix\u2212 v\u0304i)T (Pix\u2212 v\u0304i). (23)\nThe corresponding term Eq[\u2212 log p(x|w, u, v)] in our objective \u2212L can be written similarly up to a scaling by G:\n1\nG\n1\n2\u03b42 G\u2211 g=1 Ng\u2211 n=1 Eq [ (Pgnx\u2212 v\u0304gn)T (Pgnx\u2212 v\u0304gn) ] . (24)\nEPLL Term 3. The third EPLL term assumes zerocentered patches Bv\u0304i are drawn from Gaussian mixtures:\n\u2212\u2211i log p(Bv\u0304i | \u03c00,\u039b). (25) Similarly, in our minimization objective \u2212L we draw vgn from a DP mixture model. Explicitly including the cluster assignment zgn, Eq[\u2212 log p(v, z|w)] equals\n\u2212 1 G G\u2211 g=1 Ng\u2211 n=1 Eq[log p(vgn, zgn | \u03c00,\u039b)]. (26)\nEPLL is similar, but maximizes assignments (Eq. (5)) rather than computing posterior assignment probabilities."}, {"heading": "4.3. HDP Grid: Variational Inference", "text": "Image-specific frequencies. The DP model above, and the parametric EPLL objective it generalizes, assume the same cluster frequency vector \u03c00 for each image m. Our HDP Grid model allows image-specific frequencies \u03c0m to be learned from data, via the hierarchical regularization of the HDP prior (Teh et al., 2006). Our approximate posterior family Q now has the following HDP-specific factors:\nq(\u03b2) = \u220f\u221e k=1 Beta (\u03b2k | \u03c1\u0302k\u03c9\u0302k, (1\u2212 \u03c1\u0302k)\u03c9\u0302k) , (27)\nq([\u03c0m1 . . .\u03c0mK \u03c0m>K ]) = Dir(\u03b8\u0302m1 . . . \u03b8\u0302mK , \u03b8\u0302m>K). This approximate posterior represents infinitely many clusters via a finite partition of \u03c0m into K + 1 terms: one for each of theK active clusters, and a remainder term at index >K that aggregates the mass of all inactive clusters. The free parameter \u03b8\u0302m is also a vector of size K + 1 whose last entry represents all inactive clusters. We follow Hughes et al. (2015) to obtain a closed-form update for \u03b8\u0302m, and gradient-based updates for \u03c1\u0302, \u03c9\u0302; see the supplement for details. We highlight that the \u03b8\u0302m update naturally includes a 1G rescaling of count sufficient statistics as in Eq. (16). Other factors remain unchanged from the DP Grid model.\nImage-specific clusters. Due to the heavy-tailed distribution of natural images (Ruderman, 1997), even with large training sets, test images may still contain unique textural patterns like the striped scarf in the Barbara image in Fig. 3. Fortunately, our Bayesian nonparametric HDP Grid model provides a coherent way to capture such patterns by appending K \u2032 novel, image-specific clusters to the original K clusters learned from training images. These novel clusters lead to more accurate posterior approximations q \u2208 Q that better optimize our objective L.\nWe initialize inference by creating K \u2032 = 100 imagespecific clusters with the k-means++ algorithm (Arthur & Vassilvitskii, 2007), which minimizes the cost function\nJ (z\u2032,\u039b\u2032) = \u2211i\u2211K\u2032k=1 1k(z\u2032i)D(v\u0303iv\u0303Ti ,\u039b\u2032k), (28) where the first sum is over the set of fully-observed patches within the image. The function D is the Bregman divergence associated with our zero-mean Gaussian likelihood (Banerjee et al., 2005), and v\u0303i = BPiy is a zerocentered patch. We initialize the algorithm by sampling K \u2032 diverse patches in a distance-biased fashion, and refine with 50 iterations of coordinate descent updates of z\u2032 and \u039b\u2032.\nThen we expand the variational posterior q(\u039b) intoK+K \u2032 clusters. The first K indices are kept the same as training, and the last K \u2032 indices are set via Eq. (16) using sufficient statistics N \u2032, S\u2032 derived from hard assignments z\u2032:\nN \u2032k\u2032 \u2190 \u2211 i 1k\u2032(z \u2032 i), S \u2032 k\u2032 \u2190 [\u2211 i 1k\u2032(z \u2032 i)v\u0303iv\u0303 T i \u2212Nk\u2032\u03c32I ] + . Here, following Portilla et al. (2003) and Kivinen et al. (2007), S\u2032k\u2032 estimates the clean data statistic Sk\u2032 by subtracting the expected noise covariance. The [\u00b7]+ operator thresholds any negative eigenvalues to zero.\nSimilarly, the other global variational factor q(\u03b2) is also expanded to K + K \u2032 clusters via sufficient statistics N \u2032 and counts of cluster usage from training data. Given {\u03b2,\u039b}K+K\u2032k=1 , each factor in q may then be updated in turn to maximize the variational objective L (see supplement). Finally, while we initialize K \u2032 to a large number to avoid local optima, this may lead to extraneous clusters. We thus delete new clusters that our sparsity-biased variational updates do not assign to any patch. In the Barbara image in Fig. 3, this leaves 9 image-specific clusters. Deletion improves model interpretability and algorithm speed, because costs scale linearly with the number of instantiated clusters."}, {"heading": "5. Experiments", "text": "Following EPLL, we train our HDP-Grid model using 400 clean training and validation images from the Berkeley segmentation dataset (BSDS, Martin et al. (2001)). We fix \u03b4 = 0.5/255 to account for the quantization of image intensities to 8-bit integers. Observed DC offsets u provide maximum likelihood estimates of the mean r and variance s2 in Eq. (12). Similarly, we compute empirical covariance matrices for patches in the same image segments to estimate hyperparameters W and \u03bd in Eq. (16). Using variational learning algorithms that adapt the number of clusters to the observed data (Hughes & Sudderth, 2013), we discover K = 449 clusters for the DP-Grid model, which we use to initialize our HDP model. We set our annealing schedule for \u03ba to match that used by the public EPLL code.\nImage denoising methods are often divided into two types (Zontak & Irani, 2011): external methods (like\nEPLL) that learn all parameters from a training database of clean images, and internal methods that denoise patches using other patches of the single noisy image. For example, the K-SVD (Elad & Aharon, 2006) has an external variant that uses a dictionary learned from clean images, and an internal variant that learns its dictionary from the noisy image. A major contribution of our paper is to show that the hierarchical DP leads to a principled hybrid of internal and external methods, in which cues from clean and noisy images are automatically combined in an adaptive way."}, {"heading": "5.1. Image Denoising", "text": "We test our algorithm on 12 \u201cclassic\u201d images used in many previous denoising papers (Mairal et al., 2009; Zoran & Weiss, 2011), as well as the 68 BSDS test images used by (Roth & Black, 2005; Zoran & Weiss, 2011). We evaluate\nthe denoising performance by the peak signal-to-noise ratio (PSNR), a logarithmic transform of the mean squared error (MSE) between images with normalized intensities,\nPSNR , \u221220 log10 MSE. (29) We also evaluate the structural similarity index (SSIM, Wang et al. (2004)), which quantifies image quality degradation via changes in structure, luminance, and contrast.\nInternal vs. external clusters. In result figures, we use eDP to refer to our DP-Grid model trained solely on external clean images and HDP to refer to the HDP-Grid model that also learns novel image-specific clusters. We also train an internal DP-Grid model, referred to as iDP, using only information from the noisy test image. The first four columns of Table 1 compare their average denoising performance, where EPLL can be viewed as a simplification of eDP. For all noise levels and datasets, the HDP model has superior performance. As shown in Fig. 6, HDP is more accurate than EPLL and eDP for every single classic-12 image. Also, the consistent gain in performance from EPLL to eDP demonstrates the benefits of Bayesian nonparametric learning of an appropriate model complexity (for EPLL, the number of clusters was arbitrarily fixed at K = 200).\nFig. 3 further illustrates the complementary role of internal\nTable 1. Average PSNR and SSIM values on benchmark datasets (larger values indicate better denoising). Methods are highlighted if they are indistinguishable with 95% confidence, according to a Wilcoxon signed-rank test on the fraction of images where one method outperforms another. For all noise levels the patch size of BM3D is fixed to 8\u00d7 8 and LSSC is fixed to 9\u00d7 9.\nmetric dataset \u03c3 iDP EPLL eDP HDP FoE eKSVD iKSVD BM3D LSSC\nPSNR\nclassic-12 10 33.66 33.68 33.77 33.99 33.11 33.45 33.62 33.98 34.05 25 29.02 29.39 29.47 29.68 28.32 28.89 29.11 29.73 29.74 50 25.44 26.22 26.28 26.42 24.69 25.44 25.64 26.55 26.43 BSDS-68 10 33.10 33.37 33.42 33.47 32.69 33.06 33.08 33.26 33.45 25 28.33 28.72 28.76 28.82 27.76 28.28 28.28 28.55 28.70 50 25.10 25.72 25.75 25.83 24.48 25.17 25.17 25.59 25.50\nSSIM\nclassic-12 10 0.9118 0.9136 0.9143 0.9169 0.8962 0.9084 0.9111 0.9168 0.9185 25 0.8189 0.8286 0.8299 0.8337 0.8018 0.8082 0.8131 0.8357 0.8359 50 0.6962 0.7301 0.7316 0.7366 0.6885 0.6926 0.6975 0.7425 0.7390 BSDS-68 10 0.9119 0.9219 0.9224 0.9230 0.8971 0.9128 0.9135 0.9157 0.9206 25 0.7964 0.8090 0.8103 0.8131 0.7804 0.7859 0.7879 0.8010 0.8109 50 0.6636 0.6870 0.6880 0.6962 0.6585 0.6544 0.6539 0.6840 0.6885\n1 1.5 2\nELBO/pixel\n26\n28\n30\n32\nP S\nN R\neDP HDP\nFigure 6. Clean-image evidence lower bound (ELBO) versus output PSNR (\u03c3 = 25) for 12 \u201cclassic\u201d images. The horizontal axis plots log p(xtest|xtrain) \u2248 L(xtest, xtrain)\u2212L(xtrain), divided by the number of pixels. Our HDP is uniformly superior to the eDP.\nand external clusters for a single test image (\u201cBarbara\u201d). The internal iDP perfectly captures some unique textures like the striped clothing, but produces artifacts in smooth background regions. The external EPLL and eDP better represent smooth surfaces and contours, which are common in training data, but poorly recover striped textures.\nAs shown in Fig. 5, while the relative accuracy of the eDP and iDP models varies depending on image statistics, the HDP model adaptively combines external and internal clusters for superior performance at all noise levels. By capturing the expected self-similarity of image patches, the HDP model also reduces artifacts in large regions with regular textures, such as the smoothly shaded areas of Fig. 4.\nComputational speed. To denoise a 512\u00d7 512 pixel image on a modern laptop, our Python code for eDP inference with K = 449 clusters takes about 12 min. The public EPLL Matlab code (Zoran & Weiss, 2011) with K = 200 clusters takes about 5 min. With equal numbers of clusters, the two methods have comparable runtimes. Our open-source Python code is available online at\nOriginal FoE\nEPLL HDP\nFigure 7. A qualitative comparison of image inpainting algorithms. As illustrated in the three close-up views, the HDP exploits patch self-similarity to better recover fine details.\ngithub.com/bnpy/hdp-grid-image-restoration.\nLearning image-specific clusters for the HDP model is more expensive: our non-optimized Python denoising code currently requires about 30 min. per image. Nearly all of the extra time is spent on the k-means++ initialization of Eq. (28). We expect this can be sped up significantly by coding core routines in C, parallelizing some sub-steps (possibly via GPUs), using fewer internal clusters (100 is often too many), or using faster initialization heuristics.\nPerformance. We compare our HDP model to other patch-based denoising methods in Table 1. On classic-12, where many top methods have been hand-tuned to perform well, our model is statistically indistinguishable from the best baselines. On the larger BSDS-68, our performance is superior to the state-of-the-art, showing the value of nonparametric learning from large image collections. See Fig. 8 for examples. At higher noise levels (\u03c3 = 50), LSSC has modestly improved performance (0.2 dB in PSNR) when modeling 12\u00d7 12 patches (Mairal et al., 2009). HDP models of larger patches are a promising research area."}, {"heading": "5.2. Image Inpainting", "text": "While many image processing systems are designed for just one problem, our generative model is useful for many tasks. For example, we can \u201cinpaint\u201d occluded image regions (like the red pixels in Fig. 7) by modifying Eq. (14) to\nlet \u03c32 \u2192\u221e for only those regions and setting \u03c32 = 0 elsewhere. To process color images, we follow the approach of FoE and EPLL and convert to the YCbCr color space before independently inpainting each channel. While ground truth is unavailable for the classic image in Fig. 7, our gridbased HDP produces fewer visual artifacts than baselines."}, {"heading": "6. Conclusion", "text": "We have developed a coherent Bayesian nonparametric model that, via randomly positioned grids of image patches, provides a novel statistical foundation for the popular EPLL method. We show that HDP mixture models of visual textures can grow in complexity as additional images are observed and capture the self-similarity of natural images. Our HDP-grid image denoising and inpainting algorithms are competitive with the state-of-the-art, and our model is applicable to many other computer vision tasks."}, {"heading": "Acknowledgements", "text": "This research supported in part by NSF CAREER Award No. IIS-1349774. MCH supported in part by Oracle Labs."}], "year": 2017, "references": [{"title": "k-means++: The advantages of careful seeding", "authors": ["D. Arthur", "S. Vassilvitskii"], "venue": "In ACM-SIAM Symposium on Discrete Algorithms,", "year": 2007}, {"title": "Clustering with Bregman divergences", "authors": ["A. Banerjee", "S. Merugu", "I.S. Dhillon", "J. Ghosh"], "venue": "Journal of Machine Learning Research,", "year": 2005}, {"title": "Image inpainting", "authors": ["M. Bertalmio", "G. Sapiro", "V. Caselles", "C. Ballester"], "venue": "In Computer Graphics and Interactive Techniques,", "year": 2000}, {"title": "Variational inference for Dirichlet process mixtures", "authors": ["D.M. Blei", "M.I. Jordan"], "venue": "Bayesian Analysis,", "year": 2006}, {"title": "Image restoration by sparse 3d transform-domain collaborative filtering", "authors": ["K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian"], "venue": "In Electronic Imaging,", "year": 2008}, {"title": "Image denoising via sparse and redundant representations over learned dictionaries", "authors": ["M. Elad", "M. Aharon"], "venue": "IEEE Transactions on Image Processing,", "year": 2006}, {"title": "Nonlinear image recovery with half-quadratic regularization", "authors": ["D. Geman", "C. Yang"], "venue": "IEEE Transactions on Image Processing,", "year": 1995}, {"title": "Memoized online variational inference for Dirichlet process mixture models", "authors": ["M.C. Hughes", "E.B. Sudderth"], "venue": "In Neural Information Processing Systems,", "year": 2013}, {"title": "Reliable and scalable variational inference for the hierarchical Dirichlet process", "authors": ["M.C. Hughes", "D.I. Kim", "E.B. Sudderth"], "venue": "In Artificial Intelligence and Statistics,", "year": 2015}, {"title": "On the burstiness of visual elements", "authors": ["H. J\u00e9gou", "M. Douze", "C. Schmid"], "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,", "year": 2009}, {"title": "Image denoising with nonparametric hidden Markov trees", "authors": ["J.J. Kivinen", "E.B. Sudderth", "M.I. Jordan"], "venue": "In International Conference on Image Processing,", "year": 2007}, {"title": "Non-local sparse models for image restoration", "authors": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro", "A. Zisserman"], "venue": "In International Conference on Computer Vision,", "year": 2009}, {"title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics", "authors": ["D. Martin", "C. Fowlkes", "D. Tal", "J. Malik"], "venue": "In International Conference on Computer Vision,", "year": 2001}, {"title": "Image denoising using scale mixtures of Gaussians in the wavelet domain", "authors": ["J. Portilla", "V. Strela", "M.J. Wainwright", "E.P. Simoncelli"], "venue": "IEEE Transactions on Image Processing,", "year": 2003}, {"title": "Fields of experts: A framework for learning image priors", "authors": ["S. Roth", "M.J. Black"], "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,", "year": 2005}, {"title": "Origins of scaling in natural images", "authors": ["D.L. Ruderman"], "venue": "Vision Research,", "year": 1997}, {"title": "On advances in statistical modeling of natural images", "authors": ["A. Srivastava", "A.B. Lee", "E.P. Simoncelli", "S. Zhu"], "venue": "Journal of Mathematical Imaging and Vision,", "year": 2003}, {"title": "Hierarchical Dirichlet processes", "authors": ["Y.W. Teh", "M.I. Jordan", "M.J. Beal", "D.M. Blei"], "venue": "Journal of the American Statistical Association,", "year": 2006}, {"title": "Graphical models, exponential families, and variational inference", "authors": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Foundations and Trends in Machine Learning,", "year": 2008}, {"title": "Image quality assessment: From error visibility to structural similarity", "authors": ["Z. Wang", "A.C. Bovik", "H.R. Sheikh", "E.P. Simoncelli"], "venue": "IEEE Transactions on Image Processing,", "year": 2004}, {"title": "Image super-resolution: Historical overview and future challenges", "authors": ["J. Yang", "T. Huang"], "venue": "Super-resolution imaging,", "year": 2010}, {"title": "Internal statistics of a single natural image", "authors": ["M. Zontak", "M. Irani"], "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,", "year": 2011}, {"title": "From learning models of natural image patches to whole image restoration", "authors": ["D. Zoran", "Y. Weiss"], "venue": "In International Conference on Computer Vision,", "year": 2011}, {"title": "Natural images, Gaussian mixtures and dead leaves", "authors": ["D. Zoran", "Y. Weiss"], "venue": "In Neural Information Processing Systems,", "year": 2012}], "id": "SP:b01114b48fd2b027649dce64d5fe50b93328f5e1", "authors": [{"name": "Geng Ji", "affiliations": []}, {"name": "Michael C. Hughes", "affiliations": []}, {"name": "Erik B. Sudderth", "affiliations": []}], "abstractText": "We propose a hierarchical generative model that captures the self-similar structure of image regions as well as how this structure is shared across image collections. Our model is based on a novel, variational interpretation of the popular expected patch log-likelihood (EPLL) method as a model for randomly positioned grids of image patches. While previous EPLL methods modeled image patches with finite Gaussian mixtures, we use nonparametric Dirichlet process (DP) mixtures to create models whose complexity grows as additional images are observed. An extension based on the hierarchical DP then captures repetitive and self-similar structure via imagespecific variations in cluster frequencies. We derive a structured variational inference algorithm that adaptively creates new patch clusters to more accurately model novel image textures. Our denoising performance on standard benchmarks is superior to EPLL and comparable to the state-ofthe-art, and we provide novel statistical justifications for common image processing heuristics. We also show accurate image inpainting results.", "title": "From Patches to Images: A Nonparametric Generative Model"}
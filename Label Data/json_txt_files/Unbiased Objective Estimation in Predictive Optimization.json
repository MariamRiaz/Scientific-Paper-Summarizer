{"sections": [{"heading": "1. Introduction", "text": "Data-driven decision-making has become the subject of increased interest and been used in a number of practical applications. One of the most promising approaches is mathematical programming based on predictive models generated by machine learning. Recent advances in machine learning have made it easier to create accurate predictive models, and resulting predictions have been used to build mathematical programming problems (we refer to such approaches as predictive optimization). Predictive optimization is employed in applications for which frequent trial-and-error process are not practical, such as water distribution optimization (Draper et al., 2003), energy generation planning (Baos et al., 2011), retail price optimization (Johnson\n1NEC Corporation. Correspondence to: Shinji Ito <sito@me.jp.nec.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\net al., 2016; Ito & Fujimaki, 2016), supply chain management (Thomas et al., 1996; Jung et al., 2004; Bertsimas & Thiele, 2004), and portfolio optimization (Markowitz, 1952; Chan et al., 1999; Konno & Yamazaki, 1991). Another important use for data-driven decision-making is in reinforcement learning (Kaelbling et al., 1996; Sutton & Barto, 2013). Here it is employed in situations mainly in which frequent trial-and-error operations are possible, except for batch reinforcement learning (Lange et al., 2012). The focus of this paper is on the first approach, i.e., predictive optimization.\nIn many practical applications of predictive optimization, it is essential to estimate the quality of the computed strategy because executing a strategy is often costly and risky. For example, predictive price optimization has been used to estimate revenue functions through regressions of demand as functions of product prices, and then, to optimize pricing strategies by maximizing estimated revenue functions (Johnson et al., 2016; Ito & Fujimaki, 2016; 2017; Yabe et al., 2017). In practice, users need to assess the return for the computed \u201coptimal\u201d strategy before changing prices, in order to prevent unforeseen heavy losses. In a situation in which costs for trial-and-error processes are unrealistically high, a key challenge in predictive optimization is how to assess the quality (or expected return) of the \u201coptimal\u201d solution by means of an estimated objective function.\nPredictive optimization consists of two steps: estimation and optimization. In the estimation step, we construct an estimated objective function f(z, \u03b8\u0302) for the true objective function f(z, \u03b8\u2217), where \u03b8 is a parameter of f , and z is a decision variable corresponding to the strategy to be optimized. In the optimization step, we compute the estimated optimal strategy z\u0302 = arg maxz\u2208Z f(z, \u03b8\u0302), where Z is the domain of z. Because it would be expensive to observe f(z\u0302, \u03b8\u2217) (i.e., to perform z\u0302 in a real environment), we usually estimate it by f(z\u0302, \u03b8\u0302), which we call simple evaluation, in order to assess the quality of z\u0302.\nIt has been empirically seen, however, that this simple evaluation tends to be too optimistic. For example, in the contexts of algorithmic investment and portfolio optimization, it has been reported (Michaud, 1989; Chapados, 2011; Harvey & Liu, 2015) that f(z\u0302, \u03b8\u0302) is much better than the acutual return. Michaud (Michaud, 1989) argued that this bias ap-\npears because the mean-variance optimizers act as \u201cerror maximizers\u201d, i.e., optimizers tend to choose solutions containing large errors. According to (Harvey & Liu, 2015), a common practice in evaluating trading strategies is simple heuristics that discount the estimated objective to 50%, i.e., consider 0.5f(z\u0302, \u03b8\u0302) to be an estimator of f(z\u0302, \u03b8\u2217). Heuristics referred to as portfolio resampling techniques (Michaud, 1998; Scherer, 2002) have been studied for nearly 20 years but have not yet to be theoretically justified. A few recent studies (Bailey & Marcos, 2016; Bailey et al., 2014; Harvey & Liu, 2015) have statistically analyzed and proposed algorithms to mitigate the bias issue, but their algorithms are restricted to particular applications (e.g., algorithmic investment) and, as far as we know, there exists no principled algorithm for an unbiased estimator of f(z, \u03b8\u2217) in general predictive optimization problems.\nThe goal of this study is to address this optimistic bias issue, and to propose methods for unbiased estimation of true objective values. Our key contributions are summarized as follows.\nFirst, we prove that the estimated optimal value f(z\u0302, \u03b8\u0302) is biased even if the estimated objective function f(z, \u03b8\u0302) is an unbiased estimator of the true objective function f(z, \u03b8\u2217). Further, we correlate the bias issue to overfitting in machine learning, which yields a valuable insight into bias correction methods.\nSecond, we propose two algorithms for estimating the value of true objective functions under mild assumptions. The first algorithm is based on a procedure similar to crossvalidation and has been inspired by the analogy between our problem and overfitting in supervised learning. This algorithm corrects the optimistic bias, but suffers from pessimistic bias, i.e., the estimated value is biased in a direction suggesting a poorer result, similar to that which occurs in cross-validation. The magnitude of this pessimistic bias tends to be larger than that of cross-validation, and hence, it is not negligible in many cases. To mitigate this issue, we propose another algorithm, which we refer to as a parameter perturbation method. This algorithm employs a resampling technique and is theoretically proven here to achieve asymptotically unbiased estimation.\nOur experimental results show that the proposed algorithms are able to estimate the value of a true objective function more accurately than a state-of-the-art hold-out validation technique commonly used in algorithmic investment (Bailey & Marcos, 2016; Bailey et al., 2014). In a simulation experiment with real-world retail datasets for price optimization, we have observed that our evaluation algorithms estimate a 17% increase in the gross profit, which seems to be more realistic and convincing than the value estimated without bias correction.\nThe remainder of this paper is structured as follows. In Section 2, we introduce the framework of the combination of machine learning and mathematical optimization in examples of usage. We also show that such a framework suffers from bias w.r.t. optimal values. Section 4 gives solutions to this problem and theoretical guarantees for them. In Section 5, the empirical performance of our algorithms is demonstrated."}, {"heading": "2. Predictive Optimization", "text": "Suppose we have a sequence of training data x = (x1, . . . , xN ) \u2208 XN , where N is the number of data instances. Each xn is generated from a probabilistic model {p(x|\u03b8) : \u03b8 \u2208 \u0398} parameterized by \u03b8 \u2208 \u0398. We further suppose having a set of objective functions {f(z, \u03b8) : \u03b8 \u2208 \u0398} where z \u2208 Z is a decision variable that corresponds to strategies to be optimized. The goal of predictive optimization is to find z\u2217 \u2208 arg maxz\u2208Z f(z, \u03b8\u2217), where \u03b8\u2217 is the true parameter. However, such a true parameter is unknown in practice, and therefore we estimate \u03b8\u2217 by \u03b8\u0302 from x, and compute the estimated optimal solution z\u0302 \u2208 arg maxz\u2208Z f(z, \u03b8\u0302) rather than z\u2217. This section discusses three examples of predictive optimization problems in order to provide a better picture of the process.\nExample 1 (Coin-Tossing). Suppose that we have a coin coming up heads with probability \u03b8\u2217 and tails with probability 1\u2212 \u03b8\u2217, where \u03b8\u2217 \u2208 \u0398 := [0, 1]. Consider predicting heads or tails for this coin. If we predict the subsequent face correctly, we win $1, and, otherwise, nothing. Predicting heads, then, will result in earning $1 with probability \u03b8\u2217 and $0 with probability 1 \u2212 \u03b8\u2217, and hence, the expectation value of the earnings for predicting heads is f(\u2018head\u2019, \u03b8\u2217) = 1 \u00b7 \u03b8\u2217+ 0 \u00b7 (1\u2212 \u03b8\u2217) = \u03b8\u2217. Similarly, the expected earnings for predicting tails is f(\u2018tail\u2019, \u03b8\u2217) = 1\u2212 \u03b8\u2217. If we knew the true parameter \u03b8\u2217, we could maximize the expected earnings by choosing z\u2217 \u2208 arg maxz\u2208Z f(z, \u03b8\u2217), where Z = {\u2018head\u2019, \u2018tail\u2019} stands for a set of feasible strategies. Since we do not know the true parameter \u03b8\u2217, however, we use, rather, past data x \u2208 XN := {\u2018head\u2019, \u2018tail\u2019}N of N tossings, for estimating \u03b8\u2217.\nTable 1 illustrates how the optimistic bias occurs in predictive optimization. Suppose \u03b8\u2217 = 1/2 (a) and that there are four cases of the observed pattern for three tossings (b). The estimators of \u03b8\u2217 might then be obtained as (c), using maximum likelihood estimation. On the basis of \u03b8\u0302, the \u201cbest\u201d strategies are estimated as (d), and the estimated and true optimal values are summarized in (e) and (f). It is worth noting that the expectation of (e) over four cases (bottom middle), which is 3/4, is larger than the true expectation (bottom right), which is 1/2 even if the \u03b8\u0302 is unbiased, i.e., the expectation of \u03b8\u0302 matches \u03b8\u2217 (bottom left).\nExample 2 (Portfolio optimization (Markowitz, 1952)).\nSuppose that there are d assets, and let Rj stand for the return on each component asset for j \u2208 {1, . . . , d}. Let \u00b5\u2217 = (\u00b5\u22171, . . . , \u00b5 \u2217 d) > \u2208 Rd be the expected return for each asset, i.e., \u00b5\u2217j = E[Rj ]. Then the portfolio expressed as Rz = \u2211d j=1 zjRj , where zj \u2265 0 is the weighting of the j-th component asset and z = (z1, . . . , zd)> \u2208 Rd\u22650, has expected return E[Rz] = \u2211d j=1 zj\u00b5 \u2217 j = \u00b5\n\u2217>z. Variance in the portfolio return can be expressed as var[Rz] = z>\u03a3\u2217z, where \u03a3\u2217 is the covariance matrix of (R1, . . . , Rd). Denote \u03b8\u2217 = (\u00b5\u2217,\u03a3\u2217). Then, with a given risk tolerance \u03bb \u2265 0, the optimal portfolio is obtained as the solution of the following problem:\nMaximize f(z, \u03b8\u2217) := \u00b5\u2217>z \u2212 \u03bbz>\u03a3\u2217z, (1) subject to d\u2211 j=1 zj = 1, zj \u2265 0 (j = 1, . . . , d).\nIn practice, however, since \u03b8\u2217 is never available, we estimate it from historical data x = (x1, . . . , xN ), where xn \u2208 Rd is an observation of past returns for individual component assets (Qiu et al., 2015; Agarwal et al., 2006; Li & Hoi, 2012). Under the assumption that xn follow the same distribution,1 the estimators of \u00b5\u2217 and \u03a3\u2217 are obtained by \u00b5\u0302 = 1N \u2211N n=1 xn and \u03a3\u0302 = 1 N\u22121 \u2211N n=1(xn\u2212 \u00b5\u0302)(xn\u2212 \u00b5\u0302)>. We obtain the optimal solution by solving (1) with the replacement of \u00b5\u2217 and \u03a3\u2217 by \u00b5\u0302 and \u03a3\u0302, respectively.\nExample 3 (Predictive price optimization(Ito & Fujimaki, 2017; 2016)). Suppose we have d products whose prices are denoted by z = (z1, . . . , zd). Let us denote their sales quantities by q\u2217(z) = (q\u2217j (z)) d j=1 \u2208 Rd, which are functions of the price z. The gross revenue function is then defined by f(z, \u03b8\u2217) = q\u2217(z)>z, and the true optimal solution is obtained by solving the following problem:\nMaximize q\u2217(z)>z subject to z \u2208 Z, (2)\nwhere Z \u2286 Rd is a pre-defined domain of prices (e.g., list price, 3%-off, 5%-off, and so on). However, we can never know the true demand-price relationship q\u2217(z), and\n1This condition can easily be relaxed.\nthe predictive price optimization approximates q\u2217(z) by the following regression functions:\nq(z, \u03b8) = K\u2211 k=1 \u03b8k\u03c8k(z) + , \u223c N(0,\u03a3), (3)\nwhere {\u03c8k : Rd \u2192 Rd}Kk=1 are fixed basis functions and {\u03b8k}Kk=1 \u2286 R are regression coefficients. We estimate \u03b8 = (\u03b81, . . . , \u03b8K) as a standard regression problem and then solve (2) after replacing q\u2217(z) by q(z, \u03b8\u0302), where \u03b8\u0302 is the estimator of \u03b8\u2217."}, {"heading": "3. Optimistic Bias in the Optimal Value", "text": ""}, {"heading": "3.1. Existence of Optimistic Bias", "text": "This section formally proves the existence of optimistic bias in estimated optimal values. In the above examples, the objective functions f(z, \u03b8) w.r.t. \u03b8 were affine functions and \u03b8\u0302 were unbiased estimators of \u03b8\u2217. Hence, the constructed objective function f(z, \u03b8\u0302) was an unbiased estimator of the true objective function f(z, \u03b8\u2217), i.e., it holds that\nEx[f(z, \u03b8\u0302)] = Ex[f(z, \u03b8\u2217)], z \u2208 Z. (4)\nFrom this equation, one might expect that Ex[f(z\u0302, \u03b8\u0302)] and f(z\u0302, \u03b8\u0302) would be reasonable estimators of Ex[f(z\u0302, \u03b8\u2217)] and f(z\u0302, \u03b8\u2217), respectively. However, the following proposition contradicts this intuition.\nProposition 1 (Optimistic Bias). Suppose (4) holds. For z\u0302 \u2208 arg maxz\u2208Z f(z, \u03b8\u0302) and z\u2217 \u2208 arg maxz\u2208Z f(z, \u03b8\u2217), it holds that\nEx[f(z\u0302, \u03b8\u0302)] \u2265 f(z\u2217, \u03b8\u2217) \u2265 Ex[f(z\u0302, \u03b8\u2217)]. (5)\nThe right inequality is strict if z\u0302 is suboptimal w.r.t. the true objective function f(z, \u03b8\u2217) with non-zero probability.\nProof. By taking the expectation of both sides of f(z\u0302, \u03b8\u0302) \u2265 f(z\u2217, \u03b8\u0302), we obtain the left inequality of (5) as follows:\nEx[f(z\u0302, \u03b8\u0302)] \u2265 Ex[f(z\u2217, \u03b8\u0302)] = f(z\u2217, \u03b8\u2217),\nwhere the equality comes from (4). Similarly, the right inequality of (5) comes from f(z\u2217, \u03b8\u2217) \u2265 f(z\u0302, \u03b8\u2217). Further, if z\u0302 /\u2208 arg maxz\u2208Z f(z, \u03b8\u2217) holds with non-zero probability, then f(z\u2217, \u03b8\u2217) > f(z\u0302, \u03b8\u2217) holds with non-zero probability and f(z\u2217, \u03b8\u2217) \u2265 f(z\u0302, \u03b8\u2217) always holds, which implies f(z\u2217, \u03b8\u2217) > E[f(z\u0302, \u03b8\u2217)].\nThis proposition implies that the estimated optimal value f(z\u0302, \u03b8\u0302) is not an unbiased estimator of f(z\u0302, \u03b8\u2217) even if the estimated objective function f(z, \u03b8\u0302) is an unbiased estimator of the true objective function f(z, \u03b8\u2217). This optimistic bias\nhas been empirically learned in the context of portfolio optimization (Michaud, 1989). Recently, (Harvey & Liu, 2015; Harvey et al., 2016) have proposed bias correction methods based on statistical tests, though their methods are applicable only to cases in which the objective function is the Sharpe ratio. Other recent studies (Bailey & Marcos, 2016; Bailey et al., 2014) have also focused on the Sharpe ratio and proposed a hold-out validation method. Although their methods apply to general predictive optimization problems, they have not been proven to obtain unbiased estimators. Note that a similar inequality has been discovered in the context of stochastic programs,2 one that corresponds to the left inequality of (5). For the special case in which Z is a finite set, the same inequality as (5) has been shown in the context of decision analysis (Smith & Winkler, 2006)."}, {"heading": "3.2. Connection to Empirical Risk Minimization", "text": "This subsection discusses the connection of the optimistic bias issue to overfitting in machine learning, which connection has led to the ideas underlying our proposed algorithms. In supervised machine learning, we choose the prediction rule h\u0302 from a hypothesis space H by minimizing the empirical error, i.e., we let h\u0302 \u2208 arg minh\u2208H 1 n \u2211N n=1 `(h, xn), where xn is the observed data generated from a distribution D and ` is a loss function. The empirical error 1N \u2211N n=1 `(h, xn) is an unbiased estimator of the generalization error `D(h) := Ex\u223cD[`(h, x)] for arbitrary fixed prediction rule h, i.e., it holds that Exn\u223cD[ 1N \u2211N n=1 `(h, xn)] = `D(h) for any fixed h. De-\nspite this equation, the empirical error 1N \u2211N n=1 `(h\u0302, xn) for the computed parameter h\u0302 is smaller than the generalization error `D(h\u0302) in most cases, because h\u0302 overfits the observed samples, as is well known (Vapnik, 2013). The analogy between the optimistic bias in our setting and the overfitting issue in machine learning suggests the reuse of datasets for estimation of their objective functions and evaluation of objective values.\nA comparison between empirical risk minimization (ERM) and our prediction-based optimization is summarized in Table 2. As is shown in the Table, our problem concerning bias in predictive optimization has a structure similar to that of the problem of overfitting in empirical risk minimization. Typical methods for estimating generalization error in machine learning would be cross-validation and such asymptotic bias correction as AIC (Akaike, 1973). This paper follows the concept of cross-validation in the context of predictive optimization and, in the following section, proposes a more accurate algorithm.\n2 In stochastic programs, the objective is a random function, and it has been shown in, e.g., (Mak et al., 1999), that the expectation of the minimum of the objective is a lower bound of the minimum of the expectation of the objective."}, {"heading": "4. Bias Correction Algorithms", "text": "Our goal is to construct unbiased estimators for the value f(z\u0302, \u03b8\u2217) of the true objective function, i.e., to construct \u03c1 : Xn \u2192 R such that Ex[\u03c1(x)] = Ex[f(z\u0302, \u03b8\u2217)], where z\u0302 \u2208 arg max\nz\u2208Z f(z, \u03b8\u0302) is the computed strategy. We assume\nthe following conditions.\nAssumption 2. (i) f(z, \u03b8) is affine in \u03b8, i.e., \u2203a : Z \u2192 R, \u2203b : Z \u2192 R, f(z, \u03b8) = \u03b8>a(z) + b(z).\n(ii) The optimal solution z(\u03b8) \u2208 arg maxz\u2208Z f(z, \u03b8) is uniquely determined for almost all \u03b8.\n(iii) One of the following holds: (iii.a) Z is a finite set, or (iii.b) Z is a compact subset of Rd, and z 7\u2192 (a(z), b(z)) is a continuous injective function.\n(iv) \u03b8\u0302 is an unbiased estimator of \u03b8\u2217, i.e., we have Ex[\u03b8\u0302] = \u03b8\u2217.\nThe assumptions (i)-(iii) are conditions on mathematical programming problems, and such typical ones as (mixedinteger) linear/quadratic/semidefinite programming problems satisfy these conditions. Assumption (iv) is a condition on the machine learning algorithm for estimating the objective function in the optimization problem, and we can employ any standard unbiased estimation algorithm. Note that the examples in Section 3 satisfy all these assumptions. We assume (i) and (iv) in Section 4.1, and assume (i)-(iv) in Section 4.2."}, {"heading": "4.1. Cross-Validation Method", "text": "As noted in Section 3.2, our problem is closely related to the problem of estimating generalization error. Inspired by the cross-validation method, one of the most popular methods for estimating generalization error in machine learning, we propose a cross-validation method for estimating the value of the true objective function in predictive optimization. In the context of algorithmic investment, a similar method, referred to as the hold-out method is mentioned in (Bailey et al., 2014). The method discussed below is essentially an extension of the hold-out method for general predictive optimization problems.\nOne of the reasons that the value f(z\u0302, \u03b8\u0302) contains biases is that z\u0302 and \u03b8\u0302 are dependent random variables. Indeed,\nAlgorithm 1 k-fold cross-validation Input: data x \u2208 XN , the number K \u2265 2 of partition Divide data x into K parts x1, . . . ,xK . for k = 1 to K do\nCompute \u03b8\u0302k, \u03b8\u0303k from xk,x\u2212k respectively, where we define x\u2212k to be all samples in x except for xk, and compute z\u0303k \u2208 arg maxz\u2208Z f(z, \u03b8\u0303k).\nend for Output \u03c1CV (x) := 1K \u2211K k=1 f(z\u0303k, \u03b8\u0302k).\nif z\u0302 and \u03b8\u0302 are independent, Ex[f(z\u0302, \u03b8\u0302)] = Ex[f(z\u0302, \u03b8\u2217)] straightforwardly holds from assumptions (i) and (iv). The main idea of the cross-validation method (as with the standard cross-validation in machine learning) is to divide the data x \u2208 XN into two parts x1 \u2208 XN1 ,x2 \u2208 XN2 , where N1 + N2 = N . Note that each element in x1 and x2 follows p(x, \u03b8\u2217) independently, and, hence, x1 and x2 are independent random variables. Let us denote the estimators based on x1 and x2 by \u03b8\u03021 and \u03b8\u03022, respectively. Also, the optimal strategy on each estimator is denoted by z\u0302i := arg maxz\u2208Z f(z, \u03b8\u0302i) for i = 1, 2. Then z\u03021 and \u03b8\u03022 are independent (the opposite also holds), and we have Ex[f(z\u03021, \u03b8\u03022)] = Ex1 [f(z\u03021,Ex2 [\u03b8\u03022])] = Ex1 [f(z\u03021, \u03b8\u2217)]. Further, if N1 is sufficiently close to N , Ex1 [f(z\u03031, \u03b8\u2217)] is close to Ex[f(z\u0302, \u03b8\u2217)]. This idea can be extended to k-fold cross-validation, in which we divide data x \u2208 RN into K parts x1, . . . ,xK \u2208 RN \u2032 , where KN \u2032 = N . We compute z\u0303k from {x1, . . . ,xK} \\ {xk}, and compute \u03b8\u0302k from xk. Then the value \u03c1CV (x) := 1K \u2211K k=1 f(z\u0303k, \u03b8\u0302k) satisfies\nEx[\u03c1CV (x)] = Ex\u2032 [f(z\u0303, \u03b8\u2217)], (6)\nwhere z\u0303 stands for the strategy computed from (K \u2212 1)N \u2032 samples, under assumptions (i) and (iv).\nA major drawback to Algorithm 1 is that it can only estimate the objective value attained byN \u2212N \u2032 samples, as is shown in (6), even though the value attained by all N samples is desired. In machine learning, to mitigate this gap, a leave-one-out method (i.e., setting N \u2032 = 1) can be used. In predictive optimization, however, the number N \u2032 of holdout samples needs to be large enough to compute another estimator, \u03b8\u0302k, which limits the accuracy of the estimation of f(z\u0302, \u03b8\u2217). The accuracy of Algorithm 1 is considered in Sec. 5 in an empirical evaluation."}, {"heading": "4.2. Parameter perturbation method", "text": "This subsection proposes another algorithm that addresses the drawbacks of Algorithm 1. Denote the error in the estimated parameter by \u03b4 := \u03b8\u0302\u2212\u03b8\u2217. The error \u03b4 depends on the training data x and can be regarded as a random variable when x is considered to be a random variable. For \u03b3 \u2265 0,\nlet us first define \u03b7(\u03b3) as follows:\n\u03b7(\u03b3) = E\u03b4[f(z(\u03b8\u2217 + \u03b3\u03b4), \u03b8\u2217)],\nwhere z(\u03b8) := arg maxz\u2208Z f(z, \u03b8). Since z\u0302 = z(\u03b8\u0302) = z(\u03b8\u2217 + \u03b4), we have \u03b7(1) = E[f(z\u0302, \u03b8\u2217)]. Hence, our goal, unbiased estimation of f(z\u0302, \u03b8\u2217), is equivalent to unbiased estimation of \u03b7(1). Let us next define \u03c6(\u03b3) as follows:\n\u03c6(\u03b3) = E\u03b4[f(z(\u03b8\u2217 + \u03b3\u03b4), \u03b8\u2217 + \u03b3\u03b4)]. (7)\nNote that we have \u03c6(1) = E[f(z\u0302, \u03b8\u0302)]. Further, \u03c6(\u03b3) and \u03b7(\u03b3) satisfy \u03c6(0) = \u03b7(0) = f(z\u2217, \u03b8\u2217) and \u03c6(\u03b3) \u2265 f(z\u2217, \u03b8\u2217) \u2265 \u03b7(\u03b3) for all \u03b3 \u2265 0, which can be proved in a way similar to that of the proof of Proposition 1.\nThe following proposition plays a key role in our second algorithm. Proposition 3. Suppose that assumptions (i)-(iv) hold. For all \u03b3 > 0, \u03c6(\u03b3) is differentiable, and its derivative \u03c6\u2032(\u03b3) satisfies\n\u03b7(\u03b3) = \u03c6(\u03b3)\u2212 \u03b3\u03c6\u2032(\u03b3). (8)\nThe proof of this proposition is summarized in the supplementary material.\nLet us explain this proposition using Figure 1, which is based on the simulation experiment for portfolio optimization used in Section 5 and shows how the values of \u03c6 and \u03b7 behave for some \u03b3 \u2265 0. The tangent to \u03c6(\u03b3) at \u03b3 = \u03b30 (the blue broken-line) has a y-intercept (the red broken-line) equal to the value of \u03b7(\u03b30), for all \u03b30 > 0. From this relationship, the derivative \u03c6\u2032(1) of \u03c6(\u03b3) at \u03b3 = 1 satisfies \u03c6\u2032(1) = \u03c6(1) \u2212 \u03b7(1) = E[f(z\u0302, \u03b8\u0302)] \u2212 E[f(z\u0302, \u03b8\u2217)], i.e., the value of \u03c6\u2032(1) is equal to the value of the bias in our predictive optimization problem.\nOur problem is now to obtain an unbiased estimator \u03b6 of \u03c6\u2032(1) that will give us an unbiased estimator of f(z\u0302, \u03b8\u2217), i.e. \u03c1 = f(z\u0302, \u03b8\u0302)\u2212 \u03b6. From the definition of the derivative, the value of \u03c6\u2032(1) can be approximated by (\u03c6(1+h)\u2212\u03c6(1))/h for small h. Further, from the definition of \u03c6, the estimated optimal value f(z\u0302, \u03b8\u0302) is an unbiased estimator of \u03c6(1). Also, the value of \u03c6(1 + h) = E[maxz\u2208Z f(z, \u03b8\u2217 + (1 + h)\u03b4)] is the expectation of the optimal value for the objective function with a parameter having an \u201cenhanced\u201d error. If we get samples \u03b8\u0302h following the distribution of \u03b8\u2217 + (1 + h)\u03b4, we can develop an estimator of \u03c6(1 + h), and accordingly, we can estimate \u03b7(1) = E[f(z\u0302, \u03b8\u2217)].\nSuppose that \u03b8\u0302(1)h , . . . , \u03b8\u0302 (s) h follows the distribution of \u03b8 \u2217 + (1 + h)\u03b4, and define\n\u03c1h := 1 + h\nh max z\u2208Z f(z, \u03b8\u0302)\u2212 1 hs s\u2211 j=1 max z\u2208Z f(z, \u03b8\u0302 (j) h ). (9)\nThe value \u03c1h, then, has the following property.\nAlgorithm 2 Parameter perturbation method Input: data x \u2208 Xn, parameters h > 0, s \u2208 {1, 2, . . .} Compute \u03b8\u0302 from x and set v\u03020 = maxz\u2208Z f(z, \u03b8\u0302). Generate {\u03b8\u0302(j)h }sj=1 by (i) for asymptotic normal estimators or (ii) for M-estimators.\n(i) Set \u03b8\u0302(j)h to be the estimator computed from N/(1 + h)2 samples randomly chosen from x without replacement.\n(ii) Generate \u03b4\u0302j by (10), and set \u03b8\u0302 (j) h = \u03b8\u0302 + \u03b4\u0302j .\nfor j = 1 to s do Set v\u0302j = maxz\u2208Z f(z, \u03b8\u0302 (j) h ). end for Output \u03c1h := 1+hh v\u03020 \u2212 1 hs \u2211s j=1 v\u0302j .\nProposition 4. Under assumptions (i)-(iv), the value \u03c1h defined by (9) is an asymptotically unbiased estimator of f(z\u0302, \u03b8\u2217), i.e., it holds that limh\u21920 E [\u03c1h] = E[f(z\u0302, \u03b8\u2217)].\nProof. From the definition of \u03c1h and \u03c6(\u03b3), we have E[\u03c1h] = \u03c1(1) \u2212 \u03c6(1+h)\u2212\u03c6(1)h . Hence, we have limh\u21920 E [\u03c1h] = \u03c6(1) \u2212 \u03c6\u2032(1). From Proposition 3, this value is equal to \u03b7(1) = E[f(z\u0302, \u03b8\u2217)].\nThe remaining problem is how to obtain samples \u03b8\u0302h, with enhanced errors, from the distribution of \u03b8\u2217+(1+h)\u03b4. If \u03b8\u0302 is an asymptotically normal estimator of \u03b8\u2217, its distribution can be approximated by the normal distribution N (\u03b8\u2217, 1N\u03a3\n\u2217), where \u03a3\u2217 is a constant matrix not dependent on N . Further, when we compute an estimator \u03b8\u0302h fromN/(1+h)2 data, the distribution of \u03b8\u0302h can be approximated byN (\u03b8\u2217, (1+h) 2 N \u03a3 \u2217). This is an approximation of the distribution of \u03b8\u2217 + (1 + h)\u03b4. This procedure for generating \u03b8\u0302h is used in (i) of Algorithm 2.\nIf \u03b8\u0302 is an M-estimator, an asymptotically normal estimator commonly used in machine learning, we can eliminate repetitive computation in (i) of Algorithm 2. For M-estimators,\n\u03a3\u0302 is given in a closed form, as described in (van der Vaart, 1998), such that N (0, 1N \u03a3\u0302) approximates the error distribution of the estimator. Once we have computed \u03a3\u0302, we generate samples from an approximated distribution of \u03b8\u2217 + (1 + h)\u03b4, by adding \u03b4\u0302 to \u03b8\u0302, which is obtained by\n\u03b4\u0302 \u223c N (0, (1 + h) 2 \u2212 1\nN \u03a3\u0302). (10)\nWe can, in fact, confirm that the distribution of \u03b8\u0302+ \u03b4\u0302 approximates that of \u03b8\u2217+ (1 +h)\u03b4 by applying the normal approximation to \u03b8\u0302\u2212 \u03b8\u2217 = \u03b4. From the normal approximation \u03b4 \u223c N (0, 1N \u03a3\u0302), we obtain \u03b8 \u2217+(1+h)\u03b4 \u223c N (\u03b8\u2217, (1+h) 2 N \u03a3\u0302) and \u03b8\u0302+ \u03b4\u0302 \u223c N (\u03b8\u2217+0, 1N \u03a3\u0302+ (1+h)2\u22121 N \u03a3\u0302) = N (\u03b8 \u2217, (1+h) 2\nN \u03a3\u0302). This procedure corresponds to (ii) in Algorithm 2."}, {"heading": "5. Experiments", "text": "We have compared our Algorithm 1 and Algorithm 2 with the hold-out method (Bailey & Marcos, 2016; Bailey et al., 2014) and the portfolio resampling method (Scherer, 2002) by means of the simulation models of the examples in Section 2. We used GUROBI Optimizer 6.0.43 for portfolio optimization, and the algorithm in (Ito & Fujimaki, 2016) for price optimization."}, {"heading": "5.1. Predictive Portfolio Optimization", "text": "The portfolio optimization problem described in Example 2 of Section 2 was constructed with \u03b8\u2217 = (\u00b5\u2217,\u03a3\u2217) defined by \u00b5\u2217 = 1 + and \u03a3\u2217 = X>X , where \u2208 Rd were generated by N(0, I) and each entry of X \u2208 RD\u00d7D was drawn from N (0, D\u22121). We generated datasets {xn}Nn=1 following N (\u00b5\u2217,\u03a3\u2217), from which we computed \u03b8\u0302, as in Example 2, and solved the optimization problem (1) with \u03b8\u2217 replaced by \u03b8\u0302, to obtain z\u0302. We chose D = 50, N = 20, and \u03bb = 1.0 for our simulation experiments. When using the portfolio resampling method, we computed z\u0304 by means of 10 bootstrap resamplings and outputted f(z\u0304, \u03b8\u0302) \u2264 f(z\u0302, \u03b8\u0302). For details regarding portfolio resampling, see, e.g., (Scherer, 2002). For the hold-out validation, we first divided N data into N \u2032 and N \u2212N \u2032, then computed z\u03021 from the former N \u2032 data and estimated \u03b8\u03022 from the letter N \u2212N \u2032 data, and then calculated f(z\u03021, \u03b8\u03022).\nAccuracy Comparisons Figure 2 shows the means and the standard deviations of computed values of f(z\u2217, \u03b8\u2217), f(z\u0302, \u03b8\u0302) and f(z\u0302, \u03b8\u2217) for 400 randomly-initialized datasets. We have observed that:\n\u2022 f(z\u0302, \u03b8\u0302) was much larger than f(z\u0302, \u03b8\u2217), which is consistent with Proposition 1. \u2022 The hold-out method performed much worse than our 3 http://www.gurobi.com/\nCV and perturbation methods, though its performance improved with an increasingN \u2032. Also, the variance in the proposed methods was much smaller. Note that we could not set N \u2032 to be larger than N \u2032 = 18 since the estimation of \u03b8\u03021 and \u03b8\u03022 would fail. \u2022 The portfolio resampling method computed slightly less optimistic value than f(z\u0302, \u03b8\u0302), but a large amount of optimistic bias remained. \u2022 The perturbation method corrected bias better than the CV method w.r.t. both bias and variance. Indeed, it almost perfectly corrected the optimistic bias in expectation. Note that K = 10 was the largest possible value because at least two samples are necessary for estimating the covariance matrix. This means that the value of CV (K = 10) achieved the minimum bias for the CV method. \u2022 The CV method and the hold-out method produced\nconservative estimates. The pessimistic bias in the CV method came from the difference between z\u0302 \u2208 arg maxz\u2208Z f(z, \u03b8\u0302) and z\u0303 in (6).\nNote that E[f(z\u0302, \u03b8\u2217)] was poorer than E[f(z\u2217, \u03b8\u2217)], where the former was the best objective value achieved with the available finite training samples. This negative difference is unavoidable with our bias correction, which appears to raise an interesting open challenge w.r.t. the combination of our bias correction with robust optimization (Bertsimas et al., 2011), i.e., the former mitigates the optimistic bias, and the later mitigates uncertainty in objective functions.\nSensitivity of the Perturbation Method We investigated the sensitivity of the perturbation method w.r.t. h > 0, which is the important trade-off parameter in bias and variance. We applied it to 100 different randomly-initialized datasets, for which we set h = 0.05, 0.10, . . . , 0.50. Because s is not sensitive, we fixed it to s = 10. Figure 3 demonstrates the changes in bias and variance (top figure) and RMSE against f(z\u0302, \u03b8\u2217), over h. As the value\nof h increased, the bias increased though the variance decreased (top figure), as was implied in Proposition 4, and this resulted in significantly larger RMSE values with smaller values of h. This observation indicates that an appropriate balance between bias and variance must be determined, and that a variance-sensitive measure such as RMSE can be used as a guide to determine the trade-off."}, {"heading": "5.2. Predictive Price Optimization", "text": "We applied our algorithms to the predictive price optimization discussed as Example 3 in Section 2. As reported in (Ito & Fujimaki, 2017), the optimal value in this problem contains optimistic bias, which is consistent with Proposition 1. Unlike in the portfolio optimization, the parameter \u03b8\u0302 is estimated by regression techniques, and the set of feasible strategies Z is discrete.\nSimulation Experiment In this experiment, we investigated the effect of the optimistic bias and our bias correction over parameter dimensionality, i.e., the number of products d. We generated the same simulation data as in (Ito & Fujimaki, 2017). The sales quantity qi of the i-th product was generated from the regression model qi = \u03b1i + \u2211d j=1 \u03b2ijpj , where \u03b1i and \u03b2ij were generated by uniform distributions, where \u03b1i \u2208 [d, 3d], \u03b2ij \u2208 [0, 2] for i 6= j, and \u03b2ii \u2208 [\u22122d,\u2212d]. The feasible region Z was defined by Z = {0.6, 0.7, . . . , 1.0}d. We chose N = 500 for our experiments.\nFigure 4 shows the change in the objective values normalized by the ideal objective value f(z\u2217, \u03b8\u2217) over the number\nof products d. For Algorithm 1 (CV method), we chose K = 2 so that the hold-out samples would be sufficient to estimate parameters {\u03b1i} and {\u03b2ij}. We observed that:\n\u2022 f(z\u0302, \u03b8\u2217) degraded against f(z\u2217, \u03b8\u2217) with increasing d because the estimation error in machine learning increased. \u2022 The optimistic bias, f(z\u0302, \u03b8\u0302)\u2212 f(z\u0302, \u03b8\u2217), rapidly increased because f(z\u0302, \u03b8\u0302)\u2212 f(z\u2217, \u03b8\u2217) also increased in addition to the increase in f(z\u2217, \u03b8\u2217)\u2212 f(z\u0302, \u03b8\u2217). \u2022 The CV method suffered from pessimistic bias, which increased as d increased. \u2022 The perturbation method corrected the bias accurately even if the parameter dimensionality, i.e., d, increased.\nThese results confirm the robustness of our proposed method over parameter dimensionality and also its general applicability to a wide range of problems (the portfolio optimization in Section 5.1 is continuous and convex while the price optimization in this section is discrete and non-convex).\nReal-World Retail Dataset The real-world retail dataset used in (Ito & Fujimaki, 2017; 2016) contains sales information for a middle-size supermarket located in Tokyo.4 Using this information, we selected 50 regularly-sold beer products. The data range was approximately the three years from 2012/01 to 2014/11. We used the first 35 months (1063 samples) for training regression models and simulated the best price strategy for the next day 2014/12/1. We estimated parameters in regression models, using the least squares method. The other settings were same as in (Ito & Fujimaki, 2016).\nThe actual (non-optimized) gross profit in the past data was 106, 348 JPY, while the estimated optimal value f(z\u0302, \u03b8\u0302) was 490, 502 JPY, which represents an approximately 361% increase in gross profit, but this value was obviously unreal-\n4 The data were provided by KSP-SP Co., LTD, http:// www.ksp-sp.com.\nistically huge and unreliable (price changes alone could not increase a profit 4.6 by times!). The bias-corrected optimal gross profit with the perturbation method at h = 0.1 and s = 100 was 124, 477 JPY, which represents an approximately 17% increase in the gross profit. Although we were unable to confirm the validity of this value since this experiment was conducted on past historical data, intuitively speaking, a 17% increase in gross profit seems much more realistic than one of 361%, and considering the facts noted in the simulation studies, our result would surely seem more convincing to domain users. One of important remaining issues in real applications is the estimation of the confidence region. As noted above, we can never learn the value of f(z\u0302, \u03b8\u2217) without performing z\u0302, but the user has to make a decision as to whether to perform it or not without knowing the value. In such a case, it would be helpful to provide a confidence region w.r.t. the bias-corrected optimal value, which is available with neither the CV method nor the perturbation method."}, {"heading": "6. Conclusion", "text": "In this paper, we have focused on the framework of a combination of mathematical optimization and machine learning with which we solve an optimization problem whose objective is formulated with the aid of predictive models or estimators. We have demonstrated that such a framework suffers from a kind of bias w.r.t. optimal values because of overfitting of the solution to the constructed objective function. We have proposed a solution to this bias problem by means of developed methods that are guaranteed to compute an asymptotically unbiased estimator of the value of the true objective function. Empirical results have demonstrated that the proposed approach results in successful estimates of the value of the true objective function.\nA major open question remaining in this work is how to evaluate and reduce variance in the estimators of objective functions. The variance in estimators, i.e., uncertainty in estimation, is essential information for decision makers in many situations, and reducing variance in the estimator would help them make better decisions."}], "year": 2018, "references": [{"title": "Algorithms for portfolio management based on the Newton method", "authors": ["A. Agarwal", "E. Hazan", "S. Kale", "R.E. Schapire"], "venue": "Proceedings of the 23rd international conference on Machine learning - ICML", "year": 2006}, {"title": "Information theory and an extension of the maximum likelihood principle", "authors": ["H. Akaike"], "venue": "In International Symposium on Information Theory, pp", "year": 1973}, {"title": "Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance", "authors": ["D.H. Bailey", "J.M. Borwein", "M. L\u00f3pez de Prado", "Q.J. Zhu"], "venue": "Notices of the AMS,", "year": 2014}, {"title": "Optimization methods applied to renewable and sustainable energy: A review", "authors": ["R. Baos", "F. Manzano-Agugliaro", "F. Montoya", "C. Gil", "A. Alcayde", "J. Gmez"], "venue": "Renewable and Sustainable Energy Reviews,", "year": 2011}, {"title": "A robust optimization approach to supply chain management", "authors": ["D. Bertsimas", "A. Thiele"], "venue": "Integer programming and combinatorial optimization,", "year": 2004}, {"title": "On portfolio optimization: Forecasting covariances and choosing the risk model", "authors": ["L.K.C. Chan", "J. Karceski", "J. Lakonishok"], "venue": "Review of Financial Studies,", "year": 1999}, {"title": "Portfolio choice problems: An introductory survey of single and multiperiod models", "authors": ["N. Chapados"], "venue": "Springer Science & Business Media,", "year": 2011}, {"title": "Economic-Engineering Optimization for California Water Management", "authors": ["A.J. Draper", "M.W. Jenkins", "K.W. Kirby", "J.R. Lund", "R.E. Howitt"], "venue": "Journal of water resources planning and management,", "year": 2003}, {"title": "..and the Cross-Section of Expected Returns", "authors": ["C.R. Harvey", "Y. Liu", "H. Zhu"], "venue": "Review of Financial Studies,", "year": 2016}, {"title": "Large-scale price optimization via network flow", "authors": ["S. Ito", "R. Fujimaki"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2016}, {"title": "Optimization beyond prediction: Prescriptive price optimization", "authors": ["S. Ito", "R. Fujimaki"], "venue": "In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "year": 2017}, {"title": "Analytics for an Online Retailer : Demand Forecasting and Price Optimization", "authors": ["K. Johnson", "B. Hong", "A. Lee", "D. Simchi-levi"], "venue": "Manufacturing & Service Operations Management,", "year": 2016}, {"title": "A simulation based optimization approach to supply chain management under demand uncertainty", "authors": ["J.Y. Jung", "G. Blau", "J.F. Pekny", "G.V. Reklaitis", "D. Eversdyk"], "venue": "Computers and Chemical Engineering,", "year": 2004}, {"title": "Reinforcement learning: A survey", "authors": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"], "venue": "Journal of Artificial Intelligence Research,", "year": 1996}, {"title": "Mean-absolute deviation portfolio optimization model and its applications to tokyo stock market", "authors": ["H. Konno", "H. Yamazaki"], "venue": "Management science,", "year": 1991}, {"title": "Batch reinforcement learning", "authors": ["S. Lange", "T. Gabel", "M. Riedmiller"], "venue": "In Reinforcement learning,", "year": 2012}, {"title": "On-Line Portfolio Selection with Moving Average Reversion", "authors": ["B. Li", "S.C.H. Hoi"], "venue": "Proceedings of the 29th International Conference on Machine Learning", "year": 2012}, {"title": "Monte Carlo bounding techniques for determining solution quality in stochastic programs", "authors": ["W.K. Mak", "D.P. Morton", "R.K. Wood"], "venue": "Operations Research Letters,", "year": 1999}, {"title": "Portfolio Selection", "authors": ["H. Markowitz"], "venue": "The Journal of Finance,", "year": 1952}, {"title": "Efficient asset management: a practical guide to stock portfolio management and asset allocation. Financial Management Association, Survey and Synthesis Series", "authors": ["R. Michaud"], "year": 1998}, {"title": "The markowitz optimization enigma: Is optimized optimal", "authors": ["R.O. Michaud"], "venue": "ICFA Continuing Education Series,", "year": 1989}, {"title": "Robust portfolio optimization", "authors": ["H. Qiu", "F. Han", "H. Liu", "B. Caffo"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "Portfolio resampling: Review and critique", "authors": ["B. Scherer"], "venue": "Financial Analysts Journal, pp", "year": 2002}, {"title": "The optimizers curse: Skepticism and postdecision surprise in decision analysis", "authors": ["J.E. Smith", "R.L. Winkler"], "venue": "Management Science,", "year": 2006}, {"title": "Draft-2] Reinforcement learning : an introduction", "authors": ["R.S. Sutton", "A.G. Barto"], "venue": "Neural Networks IEEE Transactions on,", "year": 2013}, {"title": "Coordinated supply chain management", "authors": ["D.J. Thomas", "P.M. Griffin"], "venue": "European Journal of Operational Research,", "year": 1996}, {"title": "The nature of statistical learning theory", "authors": ["V. Vapnik"], "venue": "Springer science & business media,", "year": 2013}, {"title": "Robust quadratic programming for price optimization", "authors": ["A. Yabe", "S. Ito", "R. Fujimaki"], "venue": "In IJCAI ProceedingsInternational Joint Conference on Artificial Intelligence,", "year": 2017}], "id": "SP:409f5b8f5176c7dc9c2ffbea4fc4c0c9c37331c7", "authors": [{"name": "Shinji Ito", "affiliations": []}, {"name": "Akihiro Yabe", "affiliations": []}, {"name": "Ryohei Fujimaki", "affiliations": []}], "abstractText": "For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data. Predictive optimization, however, suffers from the problem of a calculated optimal solution\u2019s being evaluated too optimistically, i.e., the value of the objective function is overestimated. This paper investigates such optimistic bias and presents two methods for correcting it. The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value. Our second method employs resampling techniques to avoid both overestimation and underestimation. We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation. Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.", "title": "Unbiased Objective Estimation in Predictive Optimization"}
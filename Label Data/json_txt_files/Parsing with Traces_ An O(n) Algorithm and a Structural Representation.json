{"sections": [{"text": "General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons. We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference. In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena. We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner. Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank. We also implement a proofof-concept parser that recovers a range of null elements and trace types."}, {"heading": "1 Introduction", "text": "Many syntactic representations use graphs and/or discontinuous structures, such as traces in Government and Binding theory and f-structure in Lexical Functional Grammar (Chomsky 1981; Kaplan and Bresnan 1982). Sentences in the Penn Treebank (PTB, Marcus et al. 1993) have a core projective tree structure and trace edges that represent control structures, wh-movement and more. However, most parsers and the standard evaluation metric ignore these edges and all null elements. By leaving out parts of the structure, they fail to provide key relations to downstream tasks such as question answering. While there has been work on capturing\nsome parts of this extra structure, it has generally either been through post-processing on trees (Johnson 2002; Jijkoun 2003; Campbell 2004; Levy and Manning 2004; Gabbard et al. 2006) or has only captured a limited set of phenomena via grammar augmentation (Collins 1997; Dienes and Dubey 2003; Schmid 2006; Cai et al. 2011).\nWe propose a new general-purpose parsing algorithm that can efficiently search over a wide range of syntactic phenomena. Our algorithm extends a non-projective tree parsing algorithm (Pitler et al. 2013; Pitler 2014) to graph structures, with improvements to avoid derivational ambiguity while maintaining an O(n4) runtime. Our algorithm also includes an optional extension to ensure parses contain a directed projective tree of non-trace edges.\nOur algorithm cannot apply directly to constituency parses\u2013it requires lexicalized structures similar to dependency parses. We extend and improve previous work on lexicalized constituent representations (Shen et al. 2007; Carreras et al. 2008; Hayashi and Nagata 2016) to handle traces. In this form, traces can create problematic structures such as directed cycles, but we show how careful choice of head rules can minimize such issues.\nWe implement a proof-of-concept parser, scoring 88.1 on trees in section 23 and 70.6 on traces. Together, our representation and algorithm cover 97.3% of sentences, far above the coverage of projective tree parsers (43.9%)."}, {"heading": "2 Background", "text": "This work builds on two areas: non-projective tree parsing, and parsing with null elements.\nNon-projectivity is important in syntax for rep-\n441\nTransactions of the Association for Computational Linguistics, vol. 5, pp. 441\u2013454, 2017. Action Editor: Marco Kuhlmann. Submission batch: 4/2017; Published 11/2017.\nc\u00a92017 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.\nresenting many structures, but inference over the space of all non-projective graphs is intractable. Fortunately, in practice almost all parses are covered by well-defined subsets of this space. For dependency parsing, recent work has defined algorithms for inference within various subspaces (Go\u0301mezRodr\u0131\u0301guez and Nivre 2010; Pitler et al. 2013). We build upon these algorithms and adapt them to constituency parsing. For constituency parsing, a range of formalisms have been developed that are mildlycontext sensitive, such as CCG (Steedman 2000), LFG (Kaplan and Bresnan 1982), and LTAG (Joshi and Schabes 1997).\nConcurrently with this work, Cao et al. (2017) also proposed a graph version of Pitler et al. (2013)\u2019s One-Endpoint Crossing (1-EC) algorithm. However, Cao\u2019s algorithm does not consider the direction of edges1 and so it could produce cycles, or graphs with multiple root nodes. Their algorithm also has spurious ambiguity, with multiple derivations of the same parse structure permitted. One advantage of their algorithm is that by introducing a new item type it can handle some cases of the Locked-Chain we define below (specifically, when N is even), though in practise they also restrict their algorithm to ignore such cases. They also show that the class of graphs they generate corresponds to the 1-EC pagenumber-2 space, a property that applies to this work as well2.\nParsing with Null Elements in the PTB has taken two general approaches. The first broadly effective system was Johnson (2002), which post-processed the output of a parser, inserting extra elements. This was effective for some types of structure, such as null complementizers, but had difficulty with long distance dependencies. The other common approach has been to thread a trace through the tree structure on the non-terminal symbols. Collins (1997)\u2019s third model used this approach to recover wh-traces, while Cai et al. (2011) used it to recover null pronouns, and others have used it for a range of movement types (Dienes and Dubey 2003; Schmid 2006). These approaches have the disadvantage that each\n1 To produce directed edges, their parser treats the direction as part of the edge label.\n2 This is a topological space with two half-planes sharing a boundary. All edges are drawn on one of the two half-planes and each half-plane contains no crossings.\nadditional trace dramatically expands the grammar. Our representation is similar to LTAG-Spinal (Shen et al. 2007) but has the advantage that it can be converted back into the PTB representation. Hayashi and Nagata (2016) also incorporated null elements into a spinal structure but did not include a representation of co-indexation. In related work, dependency parsers have been used to assist in constituency parsing, with varying degrees of representation design, but only for trees (Hall, Nivre, and Nilsson 2007; Hall and Nivre 2008; Ferna\u0301ndezGonza\u0301lez and Martins 2015; Kong et al. 2015).\nKato and Matsubara (2016) described a new approach, modifying a transition-based parser to recover null elements and traces, with strong results, but using heuristics to determine trace referents."}, {"heading": "3 Algorithm", "text": "Our algorithm is a dynamic program, similar at a high level to CKY (Kasami 1966; Younger 1967; Cocke 1969). The states of our dynamic program (items) represent partial parses. Usually in CKY, items are defined as covering the n words in a sentence, starting and ending at the spaces between words. We follow Eisner (1996), defining items as covering the n\u22121 spaces in a sentence, starting and ending on words, as shown in Figure 1. This means that we process each word\u2019s left and right dependents separately, then combine the two halves.\nWe use three types of items: (1) a single edge, linking two words, (2) a continuous span, going from one word to another, representing all edges linking pairs of words within the span, (3) a span (as defined in 2) plus an additional word outside the span, enabling the inclusion of edges between that word and words in the span.\nWithin the CKY framework, the key to defining our algorithm is a set of rules that specify which items are allowed to combine. From a bottom-up perspective, a parse is built in a series of steps, which come in three types: (1) adding an edge to an item, (2) combining two items that have non-overlapping adjacent spans to produce a new item with a larger span, (3) combining three items, similarly to (2).\nExample: To build intuition for the algorithm, we will describe the derivation in Figure 1. Note, item sub-types (I, X, and N) are defined below, and in-\ncluded here for completeness. (1) We initialize with spans of width one, going between adjacent words, e.g. between ROOT and We. \u2205 7\u2192 I0,1 (2) Edges can be introduced in exactly two ways, either by linking the two ends of a span, e.g. like\u2013 running, or by linking one end of a span with a word outside the span, e.g. like\u2013. (which in this case forms a new item that has a span and an external word).\nI2,3 \u2227 like\u2013running 7\u2192 I2,3 I3,4 \u2227 like\u2013. 7\u2192 X3,4,2\n(3) We add a second edge to one of the items. I1,2 \u2227 running\u2013We 7\u2192 X1,2,3 (4) Now that all the edges to We have been added, the two items either side of it are combined to form an item that covers it. I0,1 \u2227 X1,2,3 7\u2192 N0,2,3 (5) We add an edge, creating a crossing because We is an argument of a word to the right of like. N0,2,3 \u2227 ROOT\u2013like 7\u2192 N0,2,3 (7) We use a ternary rule to combine three adjacent items. In the process we create another crossing.\nN0,2,3 \u2227 I2,3 \u2227 X3,4,2 7\u2192 I0,6"}, {"heading": "3.1 Algorithm definition", "text": "Notation Vertices are p, q, etc. Continuous ranges are [pq], [pq), (pq], or (pq), where the brackets indicate inclusion, [ ], or exclusion, ( ), of each endpoint. A span [pq] and vertex o that are part of the same item are [pq.o]. Two vertices and an arrow indicate an edge, ~pq. Two vertices without an arrow are an edge in either direction, pq. Ranges and/or vertices connected by a dash define a set of edges, e.g. the\nset of edges between o and (pq) is o\u2013(pq) (in some places we will also use this to refer to an edge from the set, rather than the whole set). If there is a path from p to q, q is reachable from p.\nItem Types As shown in Figure 1, our items start and end on words, fully covering the spaces in between. Earlier we described three item types: an edge, a span, and a span plus an external vertex. Here we define spans more precisely as I , and divide the span plus an external point case into five types differing in the type of edge crossing they contain: p qI , Interval A span for which there are no edges sr : r \u2208 (pq) and s /\u2208 [pq].\no X , Exterval An interval and either op or oq, where o /\u2208 [pq]. B, Both A span and vertex [pq.o], for which there are no edges sr : r \u2208 (pq) and s /\u2208 [pq] \u222a o. Edges o\u2013[pq] may be crossed by pq, p\u2013(pq) or q\u2013(pq), and at least one crossing of the second and third types occurs. Edges o\u2013(pq) may not be crossed by (pq)\u2013(pq) edges. L, Left Same as B, but o\u2013(pq) edges may only cross p\u2013(pq] edges. R, Right Symmetric with L. N , Neither An interval and a vertex [pq.o], with at least one o\u2013(pq) edge, which can be crossed by pq, but no other [pq]\u2013[pq] edges.\nItems are further specified as described in Alg. 1. Most importantly, for each pair of o, p, and q in an item, the rules specify whether one is a parent of the other, and if they are directly linked by an edge.\nFor an item H with span [ij], define covered(H) as (ij), and define visible(H) as {i, j}. When an external vertex x is present, it is in visible(H). Call the union of multiple such sets covered(F,G,H), and visible(F,G,H).\nDeduction Rules To make the deduction rules manageable, we use templates to define some constraints explicitly, and then use code to generate the rules. During rule generation, we automatically apply additional constraints to prevent rules that would leave a word in the middle of a span without a parent or that would form a cycle (proven possible below). Algorithm 1 presents the explicit constraints. Once expanded, these give rules that specify all properties for each item (general type, external vertex position\nAlgorithm 1 Dynamic program for Lock-Free, One-Endpoint Crossing, Directed, Acyclic graph parsing. Adding Edges: Consider a span [lr] and vertex x /\u2208 [lr]. Edges between l and r can be added to items I , N , L, R, and B (making L\u0302 and N\u0302 in those cases). Edges between l and x can be added to items I (forming an X), R, and N . Edges between r and x can be added to items I (forming an X), L, and N . The l\u2013r edge cannot be added after another edge, and N items cannot get both l\u2013x and r\u2013x edges. Combining Items: In the rules below the following notation is used: For this explanation items are T [lr crl clr] and T [lrx crl cxl clr cxr clx crx]. T is the type of item. Multiple letters indicate any of those types are allowed. For the next three types of notation, if an item does not have a mark, either option is valid. \u02d9 T and T : indicate the number of edges between the external vertex and the span: one or more than one respectively. \u00b7T and T \u00b7 indicate the position of the external vertex relative to the item\u2019s span (left or right respectively). T\u0302 indicates for N and L that \u2200p \u2208 (ij)\u2203rs : i\u2264r<p<s\u2264j. In (11) and (12) it is optional, but true for output iff true for input. l, r, and x: the position of the left end of the span, the right end, and the external vertex, respectively. crl, cxl, etc: connectivity of each pair of visible vertices, from the first subscript to the second. Using crl as an example, these can be . (unconstrained), d ( ~rl must exist), p (l is reachable from r, but ~rl does not exist), n (l is not reachable from r), d (= p \u2228 n), n (= d \u2228 p). Note: In the generated rules every value is d, p, or n, leading to multiple rules per template below.\nI[ij nd]\u2190 max   (Init) j = i+1 (1) I[i i+1 nn] I[i+1 j nn] maxk\u2208(i,j)   (2) I[ik nd] I[kj ..] (3) BLRN \u00b7 [ikj nndddd] I[kj ..] maxl\u2208(k,j){ (4) RN \u00b7 [ikl nndddd] I[kl ..] \u00b7LNX[ljk .d..d.] (5) BLRN \u00b7 [ikl nndddd] I[kl ..] I[lj ..] maxl\u2208(i,k){ (6) I[il n.] \u00b7LN [lki .d.dnn] \u00b7N : [kjl ddd.d.]\n(7) RNX\u00b7 [ilk nn.ddd] I[lk ..] \u00b7LN :: [kjl .d..d.]\nB\u00b7 [ijx nndddd]\u2190 maxk\u2208(i,j)  \n(8) L\u0302N\u0302 \u00b7 [ikx nn.ddd] R\u00b7 [kjx ...d.d] (9) L\u0302N\u0302 \u00b7 [ikx nn.ddd] N \u00b7 [kjx d.dd.d] (10) L\u0302N\u0302 \u00b7 [ikx nn.ddd] N \u00b7 [kjx d.dd.d]\n\u02d9 L\u0302[ijx dddddd]\u2190 maxk\u2208(i,j){\n(11) X[ikx .d.dnn] \u00b7 L\u0302N\u0302 [kji .d.ddd] (12) X[ikx .d.ddd] \u00b7 L\u0302N\u0302 [kji .d.ddd]\nL : [ijx dddddd]\u2190 maxk\u2208(i,j)   (13) LN [ikx .d.ddd] \u00b7N [kji dddddd] (14) LN [ikx .d.ddd] \u00b7N [kji dddddd] (15) L[ikx .d.ddd] I[kj ..] (16) L[ikx .d.ddd] I[kj ..] (17) N [ikx dddddd] I[kj ..] (18) N [ikx dddddd] I[kj ..] (19) N [ikx dddddd] I[kj ..]\n(20) N [ikx dddddd] I[kj ..]\nN : [ijx dddddd]\u2190 maxk\u2208(i,j)   (21) \u00b7N [ikx dddddd] I[kj ..] (22) \u00b7N [ikx dddddd] I[kj ..] (23) I[ik ..] N \u00b7 [kjx dddddd] (24) I[ik ..] N \u00b7 [kjx dddddd]\n\u02d9 N [ijx dddddd]\u2190 maxk\u2208(i,j)   (25) \u00b7X[ikx .d.ddd] I[kj ..] (26) \u00b7X[ikx .d.ddd] I[kj ..] (27) I[ik ..] X\u00b7 [kjx .d.ddd] (28) I[ik ..] X\u00b7 [kjx .d.ddd]\nI[ij pn], \u00b7B[ijx ddnndd], R : [ijx dddddd], and \u02d9 R[ijx dddddd] are symmetric with cases above.\nrelative to the item spans, connectivity of every pair of vertices in each item, etc).\nThe final item for n vertices is an interval where the left end has a parent. For parsing we assume there is a special root word at the end of the sentence."}, {"heading": "3.2 Properties", "text": "Definition 1. A graph is One-Endpoint Crossing if, when drawn with vertices along the edge of a halfplane and edges drawn in the open half-plane above, for any edge e, all edges that cross e share a vertex. Let that vertex be Pt(e).\nAside from applying to graphs, this is the same as\nPitler et al. (2013)\u2019s 1-EC tree definition.\nDefinition 2. A Locked-Chain (shown in Fig. 2) is formed by a set of consecutive vertices in order from 0 to N , where N > 3, with edges {(0, N\u22121), (1, N)} \u222a {(i, i+2)\u2200i \u2208 [0, N\u22122]}. Definition 3. A graph is Lock-Free if it does not contain edges that form a Locked-Chain.\nNote that in practice, most parse structures satisfy 1-EC, and the Locked-Chain structure does not occur in the PTB when using our head rules.\nTheorem 1. For the space of Lock-Free OneEndpoint Crossing graphs, the algorithm is sound, complete and gives unique decompositions.\nOur proof is very similar in style and structure to Pitler et al. (2013). The general approach is to consider the set of structures an item could represent, and divide them into cases based on properties of the internal structure. We then show how each case can be decomposed into items, taking care to ensure all the properties that defined the case are satisfied. Uniqueness follows from having no ambiguity in how a given structure could be decomposed. Completeness and soundness follow from the fact that our rules apply equally well in either direction, and so our top-down decomposition implies a bottom-up formation. To give intuition for the proof, we show the derivation of one rule below. The complete proof can be found in Kummerfeld (2016). We do not include it here due to lack of space.\nWe do provide the complete set of rule templates in Algorithm 1, and in the proof of Lemma 2 we show that the case in which an item cannot be decomposed occurs if and only if the graph contains a Locked-Chain. To empirically check our rule generation code, we checked that our parser uniquely decomposes all 1-EC parses in the PTB and is unable to decompose the rest.\nNote that by using subsets of our rules, we can restrict the space of structures we generate, giving parsing algorithms for projective DAGs, projective trees (Eisner 1996), or 1-EC trees (Pitler et al. 2013). Versions of these spaces with undirected edges could also be easily handled with the same approach.\np qs t Derivation of rule (4) in Algorithm 1: This rule applies to intervals with the substructure shown, and with no parent in this item for p. They have at least one p\u2013(pq) edge (otherwise rule 1 applies). The longest p\u2013(pq) edge, ps, is crossed (otherwise rule 2 applies). Let C be the set of (ps)\u2013(sq) edges (note: these cross ps). Either all of the edges in C have a common endpoint t \u2208 (sq), or if |C| = 1 let t be the endpoint in (sq) (otherwise rule 6 or 7 applies). Let D be the set of s\u2013(tq) edges. |D| > 0 (otherwise rule 3 or 5 applies).\nWe will break this into three items. First, (st)\u2013(tq] edges would violate the 1-EC property and (st)\u2013[ps) edges do not exist by construction. Therefore, the middle item is an Interval [st], the left item is [ps.t], and the right item is [tq.s] (since |C| > 0 and |D| > 0). The left item can be either\nan N or R, but not an L or B because that would violate the 1-EC property for the C edges. The right item can be an X , L, or N , but not an R or B because that would violate the 1-EC property for the D edges. We will require edge ps to be present in the first item, and not allow pt. To avoid a spurious ambiguity, we also prevent the first or third items from having st (which could otherwise occur in any of the three items). Now we have broken down the original item into valid sub-items, and we have ensured that those sub-items contain all of the structure used to define the case in a unique way.\nNow we will further characterize the nature of the Lock-Free restriction to the space of graphs.\nLemma 1. No edge in a Locked-Chain in a 1-EC graph is crossed by edges that are not part of it. Proof. First, note that: Pt((0, N\u22121)) = N , Pt((1, N)) = 0, and {Pt((i, i+2)) = i+1 \u2200i \u2208 [0, N\u22122]} Call the set {(i, i+2)\u2200i \u2208 [0, N\u22122]}, the chain.\nConsider an edge e that crosses an edge f in a Locked-Chain. Let ein be the end of e that is between the two ends of f , and eout be the other end. One of e\u2019s endpoints is at Pt(f), and Pt(e) is an endpoint of f . There are three cases:\n(i) f = (1, N). Here, eout = Pt(f) = 0, and ein \u2208 (1, N). For all vertices v \u2208 (1, N) there is an edge g in the chain such that v is between the endpoints of g. Therefore, e will cross such an edge g. To satisfy the 1-EC property, g must share an endpoint with f , which means g is either (1, 3) or (N\u22122, N). In the first case, the 1-EC property forces e = (0, 2), and in the second e = (0, N\u22121), both of which are part of the Locked-Chain.\n(ii) f = (0, N\u22121), symmetrical with (i). (iii) f = (i, i+2), for some i \u2208 [0, N\u22122]. Here, ein = Pt(f) = i+1. We can assume e does not cross (0, N\u22121) or (1, N), as those cases are covered by (i). As in (i), e must cross another edge in the chain, and that edge must share an endpoint with f .\nThis forces e to be either (i\u22121, i+1) or (i+1, i+3) (excluding one or both if they cross (0, N\u22121) or (1, N)), which are both in the Locked-Chain.\nOur rules define a unique way to decompose almost any item into a set of other items. The exception is B, which in some cases can not be divided into two items (i.e. has no valid binary division).\nLemma 2. A B[ij.x] has no valid binary division if and only if the graph has a Locked-Chain. Proof. Consider the k and l that give the longest ik and lj edges in a B with no valid binary division (at least one edge of each type must exist by definition). No vertex in (ik) or (jl) is a valid split point, as they would all require one of the items to have two external vertices.\nNow, consider p \u2208 [kj]. If there is no edge l1r1, where i \u2264 l1 < p < r1 \u2264 j, then p would be a valid split point. Therefore, such an edge must exist. Consider l1, either l1 \u2208 (ik) or there is an edge l2c, where i \u2264 l2 < l1 < c \u2264 j (by the same logic as for l1r1). Similarly, either r1 \u2208 (jl) or there is an edge cr2 (it must be c to satisfy 1-EC). We can also apply this logic to edges l2c and cr2, giving edges l3l1 and r1r3. This pattern will terminate when it reaches lu \u2208 (ik) and rv \u2208 (jl) with edges lulu\u22122 and rv\u22122rv. Note that k = lu\u22121 and l = rv\u22121, to satisfy 1-EC.\nSince it is a B, there must be at least two x\u2013(ij) edges. To satisfy 1-EC, these end at lu\u22121 and rv\u22121.\nLet x be to the right (the left is symmetrical), and call i = 0, j = N\u22121, and x = N . Comparing with the Locked-Chain definition, we have all the edges except one: 0 to N\u22121. However, that edge must be present in the overall graph, as all B items start with an ij edge (see rules 3 and 5 in Algorithm 1). Therefore, if there is no valid split point for a B, the overall graph must contain a Locked-Chain.\nNow, for a graph that contains a Locked-Chain, consider the items that contain the Locked-Chain. Grouping them by their span [ij], there are five valid options: [0, N\u22121], [1, N ], [0, N ], (i \u2264 0 \u2227 j > N ), and (i < 0 \u2227 j \u2265 N ). Items of the last three types would be divided by our rules into smaller items, one of which contains the whole Locked-Chain. The first two are Bs of the type discussed above.\nNow we will prove that our code to generate rules from the templates can guarantee a DAG is formed.\nLemma 3. For any item H , \u2200v \u2208 covered(H) \u2203u \u2208 visible(H) : v is reachable from u. Proof. This is true for initial items because covered(H) = \u2205. To apply induction, consider adding edges and combing items. The lemma clearly remains true when adding an edge. Consider combining items E, F , G to form H[ij.x], and assume the lemma is true for E, F , and G (the binary case is similar). Since all vertices are reachable from visible(E,F,G), we only need to ensure that \u2200v \u2208 visible(E,F,G) \u2203u \u2208 visible(H) : v is reachable from u. The connectivity between all pairs {(u, v) | u \u2208 visible(H), v \u2208 visible(E,F,G)} can be inferred from the item definitions, and so this requirement can be enforced in rule generation.\nLemma 4. The final item is a directed acyclic graph. Proof. First, consider acyclicity. Initial items do not contain any edges and so cannot contain a cycle. For induction, there are two cases:\n(i) Adding an Edge ~pq to an item H: Assume that H does not contain any cycles. ~pq will create a cycle if and only if p is reachable from q. By construction, p and q \u2208 visible(H), and so the item definition contains whether p is reachable from q.\n(ii) Combining Items: Assume that in isolation, none of the items being combined contain cycles. Therefore, a cycle in the combined item must be composed of paths in multiple items. A path in one item can only continue in another item by passing through a visible vertex. Therefore, a cycle would have to be formed by a set of paths between visible vertices. But the connectivity of every pair of visible vertices is specified in the item definitions.\nIn both cases, rules that create a cycle can be excluded during rule generation.\nBy induction, the items constructed by our algorithm do not contain cycles. Together with Lemma 3 and the final item definition, this means the final structure is an acyclic graph with all vertices reachable from vertex n.\nNext, we will show two properties that give intuition for the algorithm. Specifically, we will prove which rules add edges that are crossed in the final derivation.\nLemma 5. An edge ij added to I[ij] is not crossed. Proof. First, we will show three properties of any pair of items in a derivation (using [ij.x] and [kl.y]).\n(1) It is impossible for either i < k < j < l or k < i < l < j, i.e., items cannot have partially overlapping spans. As a base case, the final item is an interval spanning all vertices, and so no other item can partially overlap with it. Now assume it is true for an item H and consider the rules in reverse, breaking H up. By construction, each rule divides H into items with spans that are adjacent, overlapping only at their visible vertices. Since the new items are nested within H , they do not overlap with any items H did not overlap with. By induction, no pair of items have partially overlapping spans.\n(2) For items with nested spans (i \u2264 k < l \u2264 j), y \u2208 [ij]\u222a{x}. Following the argument for the previous case, the [ij.x] item must be decomposed into a set of items that includes [kl.y]. Now, consider how those items are combined. The rules that start with an item with an external vertex produce an item that either has the same external vertex, or with the external vertex inside the span of the new item. Therefore, y must either be equal to x or inside [ij].\n(3) For items without nested spans, x /\u2208 (kl). Assume x \u2208 (kl) for two items without nested spans. None of the rules combine such a pair of items, or allow one to be extended so that the other is nested within it. However, all items are eventually combined to complete the derivation. By contradiction, x /\u2208 (kl).\nTogether, these mean that given an interval H with span [ij], and another item G, either \u2200v \u2208 visible(G), v \u2208 [ij] or \u2200v \u2208 visible(G), v /\u2208 (ij). Since edges are only created between visible vertices, no edge can cross edge ij.\nLemma 6. All edges aside from those considered in Lemma 5 are crossed.\nProof. First, consider an edge ij added to an item [ij.x] of type B, L, R, or N. This edge is crossed by all x\u2013(ij) edges, and in these items |x\u2013(ij)| \u2265 1 by definition. Note, by the same argument as Lemma 5, the edge is not crossed later in the derivation.\nSecond, consider adding e \u2208 {xi, xj}, to H , an item with [ij] or [ij.x], forming an item G[ij.x]. Note, e does not cross any edges in H . Let E(F [kl.y]) be the set of y\u2013[kl] edges in some item F . Note that e \u2208 E(G). We will show how this set of edges is affected by the rules and what that implies for e. Consider each input item A[kl.y] in each\nrule, with output item C. Every item A falls into one of four categories: (1) \u2200f \u2208 E(A), f is crossed by an edge in another of the rule\u2019s input items, (2) E(A) \u2286 E(C), (3) A\u2227 kl 7\u2192 C and there are no ky or ly edges in A, (4) A contains edge kl and there are no ky or ly edges in A.\nCases 2-4 are straightforward to identify. For an example of the first case, consider the rightmost item in rule 4. The relevant edges are k\u2013(lj] (by construction, kl is not present). Since the leftmost item is either an R or N, |l\u2013(ik)| \u2265 1. Since i < k < l < j, all k\u2013(lj] edges will cross all l\u2013[ik) edges. Therefore applying this rule will cross all k\u2013(lj] edges in the rightmost item.\nInitially, e is not crossed and e \u2208 E(G). For each rule application, edges in E(A) are either crossed (1 and 3), remain in the set E(C) (2), or must already be crossed (4). Since the final item is an interval and E(Interval) = \u2205, there must be a subsequent rule that is not in case 2. Therefore e will be crossed."}, {"heading": "3.3 Comparison with Pitler et al. (2013)", "text": "Our algorithm is based on Pitler et al. (2013), which had the crucial idea of One-Endpoint crossing and a complete decomposition of the tree case. Our changes and extensions provide several benefits:\nExtension to graphs: By extending to support multiple parents while preventing cycles, we substantially expand the space of generatable structures.\nUniqueness: By avoiding derivational ambiguity we reduce the search space and enable efficient summing as well as maxing. Most of the cases in which ambiguity arises in Pitler et al. (2013)\u2019s algorithm are due to symmetry that is not explicitly broken. For example, the rule we worked through in the previous section defined t \u2208 (sq) when |C| = 1. Picking t \u2208 (ps) would also lead to a valid set of rules, but allowing either creates a spurious ambiguity. This ambiguity is resolved by tracking whether there is only one edge to the external vertex or more than one, and requiring more than one in rules 6 and 7. Other changes include ensuring equivalent structures cannot be represented by multiple item types and enforcing a unique split point in B items.\nMore concise algorithm definition: By separating edge creation from item merging, and defining our rules via a combination of templates and code, we are able to define our algorithm more concisely."}, {"heading": "3.4 Algorithm Extensions", "text": ""}, {"heading": "3.4.1 Edge Labels and Word Labels", "text": "Edge labels can be added by calculating either the sum or max over edge types when adding each edge. Word labels (e.g., POS Tags) must be added to the state, specifying a label for each visible word (p, q and o). This state expansion is necessary to ensure agreement when combining items."}, {"heading": "3.4.2 Ensuring a Structural Tree is Present", "text": "Our algorithm constrains the space of graph structures, but we also want to ensure that our parse contains a projective tree of non-trace edges.\nTo ensure every word gets one and only one structural parent, we add booleans to the state, indicating whether p, q and o have structural parents. When adding edges, a structural edge cannot be added if a word already has a structural parent. When combining items, no word can receive more than one structural parent, and words that will end up in the middle of the span must have exactly one. Together, these constraints ensure we have a tree.\nTo ensure the tree is projective, we need to prevent structural edges from crossing. Crossing edges are introduced in two ways, and in both we can avoid structural edges crossing by tracking whether there are structural o\u2013[pq] edges. Such edges are present if a rule adds a structural op or oq edge, or if a rule combines an item with structural o\u2013[pq] edges and o will still be external in the item formed by the rule.\nFor adding edges, every time we add a pq edge in the N , L, R and B items we create a crossing with all o\u2013(pq) edges. We do not create a crossing with oq or op, but our ordering of edge creation means these are not present when we add a pq edge, so tracking structural o\u2013[pq] edges gives us the information we need to prevent two structural edges crossing.\nFor combining items, in Lemma 6 we showed that during combinations, o\u2013[pq] edges in each pair of items will cross. As a result, knowing whether any o\u2013[pq] edge is structural is sufficient to determine whether two structural edges will cross."}, {"heading": "3.5 Complexity", "text": "Consider a sentence with n tokens, and let E and S be the number of edge types and word labels in our grammar respectively.\nParses without word or edge labels: Rules have up to four positions, leading to complexity of O(n4). Note, there is also an important constant\u2013once our templates are expanded, there are 49,292 rules.\nWith edge labels: When using a first-order model, edge labels only impact the rules for edge creation, leading to a complexity of O(n4 + En2).\nWith word labels: Since we need to track word labels in the state, we need to adjust every n by a factor of S, leading to O(S4n4 + ES2n2)."}, {"heading": "4 Parse Representation", "text": "Our algorithm relies on the assumption that we can process the dependents to the left and right of a word independently and then combine the two halves. This means we need lexicalized structures, which the PTB does not provide. We define a new representation in which each non-terminal symbol is associated with a specific word (the head). Unlike dependency parsing, we retain all the information required to reconstruct the constituency parse.\nOur approach is related to Carreras et al. (2008) and Hayashi and Nagata (2016), with three key differences: (1) we encode non-terminals explicitly, rather than implicitly through adjunction operations, which can cause ambiguity, (2) we add representations of null elements and co-indexation, (3) we modify head rules to avoid problematic structures.\nFigure 3 shows a comparison of the PTB representation and ours. We add lexicalization, assigning each non-terminal to a word. The only other changes are visual notation, with non-terminals moved to be directly above the words to more clearly show the distinction between spines and edges.\nSpines: Each word is assigned a spine, shown im-\nmediately above the word. A spine is the ordered set of non-terminals that the word is the head of, e.g. SVP for like. If a symbol occurs more than once in a spine, we use indices to distinguish instances.\nEdges: An edge is a link between two words, with a label indicating the symbols it links in the child and parent spines. In our figures, edge labels are indicated by where edges start and end.\nNull Elements: We include each null element in the spine of its parent, unlike Hayashi and Nagata (2016), who effectively treated null elements as words, assigning them independent spines. We also considered encoding null elements entirely on edges but found this led to poorer performance.\nCo-indexation: The treebank represents movement with index pairs on null elements and nonterminals, e.g. *1 and NP1 in Figure 3. We represent co-indexation with edges, one per reference, going from the null element to the non-terminal. There are three special cases of co-indexation: (1) It is possible for trace edges to have the same start and end points as a non-trace edge. We restrict this case to allow at most one trace edge. This decreases edge coverage in the training set by 0.006%. (2) In some cases the reference non-terminal only spans a null element, e.g. the WHNP in Figure 4a. For these we use a reversed edge to avoid creating a cycle. Figure 4a shows a situation where the trace edge links two positions in the same spine, which we assign with the spine during parsing. (3) For parallel constructions the treebank coindexes arguments that fulfill the same roles (Fig. 4b). These are distinct from the previous cases because neither index is on a null element. We considered two options: add edges from the repetition\nto the referent (middle), or add edges from the repetition to the parent of the first occurrence (bottom). Option two produces fewer non-1-EC structures and explicitly represents all predicates, but only implicitly captures the original structure."}, {"heading": "4.1 Avoiding Adjunction Ambiguity", "text": "Prior work on parsing with spines has used radjunction to add additional non-terminals to spines. This introduces ambiguity, because edges modifying the same spine from different sides may not have a unique order of application. We resolve this issue by using more articulated spines with the complete set of non-terminals. We found that 0.045% of spine instances in the development set are not observed in training, though in 70% of those cases an equivalent spine sans null elements is observed in training."}, {"heading": "4.2 Head Rules", "text": "To construct the spines, we lexicalize with head rules that consider the type of each non-terminal and its children. Different heads often represent more syntactic or semantic aspects of the phrase. For trees, all head rules generate valid structures. For graphs, head rules influence the creation of two problematic structures:\nCycles: These arise when the head chosen for a phrase is also an argument of another word in the phrase. Figure 5a shows a cycle between which and proposed. We resolve this by changing the head of an SBAR to be an S rather than a Wh-noun phrase.\nOne-Endpoint Crossing Violations: Figure 5b shows an example, with the trace from CEO to Page crossing two edges with no endpoints in common. We resolve this case by changing the head for VPs to be a child VP rather than an auxiliary."}, {"heading": "5 Results", "text": "Algorithm Coverage: In Table 1 we show the impact of design decisions for our representation. The percentages indicate how many sentences in the training set are completely recoverable by our algorithm. Each row shows the outcome of an addition to the previous row, starting from no traces at all, going to our representation with the head rules of Carreras et al. (2008), then changing the head rules, reversing null-null edges, and changing the target of edges in parallel constructions. The largest gain comes from changing the head rules, which is unsurprising since Carreras et al. (2008)\u2019s rules were designed for trees (any set of rules form valid structures for trees).\nProblematic Structures: Of the sentences we do not cover, 54% contain a cycle, 45% contain a 1- EC violation, and 1% contain both. To understand these problematic sentences, we manually inspected a random sample of twenty parses that contained a cycle and twenty parses with a 1-EC violation (these forty are 6% of all problematic parses, enough to identify the key remaining challenges).\nFor the cycles, eleven cases related to sentences containing variations of NP said interposed between two parts of a single quote. A cycle was present because the top node of the parse was co-indexed with a null argument of said while said was an argument of the head word of the quote. The remaining cases were all instances of pseudo-attachment, which the treebank uses to show that non-adjacent constituents are related (Bies et al. 1995). These cases were split between use of Expletive (5) and Interpret Constituent Here (4) traces.\nIt was more difficult to determine trends for cases where the parse structure has a 1-EC violation. The same three cases, Expletive, Interpret Constituent Here, and NP said accounted for half of the issues."}, {"heading": "5.1 Implementation", "text": "We implemented a parser with a first-order model using our algorithm and representation. Code for the parser, for conversion to and from our representation, and for our metrics is available3. Our parser uses a linear discriminative model, with features based on McDonald et al. (2005). We train\n3 https://github.com/jkkummerfeld/ 1ec-graph-parser\nwith an online primal subgradient approach (Ratliff et al. 2007) as described by Kummerfeld, BergKirkpatrick, et al. (2015), with parallel lock-free sparse updates.\nLoss Function: We use a weighted Hamming distance for loss-augmented decoding, as it can be efficiently decomposed within our dynamic program. Calculating the loss for incorrect spines and extra edges is easy. For missing edges, we add when a deduction rule joins two spans that cover an end of the edge, since if it does not exist in one of those items it is not going to be created in future. To avoid double counting we subtract when combining two halves that contain the two ends of a gold edge4.\nInside\u2013Outside Calculations: Assigning scores to edges is simple, as they are introduced in a single item in the derivation. Spines must be introduced in multiple items (left, right, and external positions) and must be assigned a score in every case to avoid ties in beams. We add the score every time the spine is introduced and then subtract when two items with a spine in common are combined.\nAlgorithm rule pruning: Many 1-EC structures are not seen in our data. We keep only the rules used in gold training parses, reducing the set of 49,292 from the general algorithm to 627 (including rules for both adding arcs and combining items). Almost every template in Algorithm 1 generates some unnecessary rules, and no items of type B are needed.\n4 One alternative is to count half of it on each end, removing the need for subtraction later. Another is to add it during the combination step.\nThe remaining rules still have high coverage of the development set, missing only 15 rules, each applied once (out of 78,692 rule applications). By pruning in this way, we are considering the intersection of 1-EC graphs and the true space of structures used in language.\nChart Pruning: To improve speed we use beams and cube pruning (Chiang 2007), discarding items based on their Viterbi inside score. We divide each beam into sub-beams based on aspects of the state. This ensures diversity and enables consideration of only compatible items during binary and ternary compositions.\nCoarse to Fine Pruning: Rather than parsing immediately with the full model we use several passes with progressively richer structure (Goodman 1997): (1) Projective parsing without traces or spines, and simultaneously a trace classifier, (2) Non-projective parsing without spines, and simultaneously a spine classifier, (3) Full structure parsing. Each pass prunes using parse max-marginals and classifier scores, tuned on the development set. The third pass also prunes spines that are not consistent with any unpruned edge from the second pass. For the spine classifier we use a bidirectional LSTM tagger, implemented in DyNet (Neubig et al. 2017).\nSpeed: Parsing took an average of 8.6 seconds per sentence for graph parsing and 0.5 seconds when the parser is restricted to trees5. Our algorithm is also amenable to methods such as semi-supervised and adaptive supertagging, which can improve the speed of a parser after training (Kummerfeld, Roesner, et al. 2010; Lewis and Steedman 2014).\nTree Accuracy: On the standard tree-metric, we score 88.1. Using the same non-gold POS tags as input, Carreras et al. (2008) score 90.9, probably due to their second-order features and head rules tuned for performance6. Shifting to use their head rules, we score 88.9. Second-order features could be added to our model through the use of forest reranking, an improvement that would be orthogonal to this paper\u2019s contributions.\nWe can also evaluate on spines and edges. Since their system produces regular PTB trees, we con-\n5 Using a single core of an Amazon EC2 m4.2xlarge instance (2.4 GHz Xeon CPU and 32 Gb of RAM).\n6 Previous work has shown that the choice of head can significantly impact accuracy (Schwartz et al. 2012).\nvert its output to our representation and compare its results with our system using their head rules. We see slightly lower accuracy for our system on both spines (94.0 vs. 94.3) and edges (90.4 vs. 91.1).\nTrace Accuracy: Table 2 shows results using Johnson (2002)\u2019s trace metric. Our parser is competitive with previous work that has highly-engineered models: Johnson\u2019s system has complex non-local features on tree fragments, and similarly Kato and Matsubara (K&M 2016) consider complete items in the stack of their transition-based parser. On co-indexation our results fall between Johnson and K&M. Converting to our representation, our parser has higher precision than K&M on trace edges (84.1 vs. 78.1) but lower recall (59.5 vs. 71.3). One modeling challenge we observed is class imbalance: of the many places a trace could be added, only a small number are correct, and so our model tends to be conservative (as shown by the P/R tradeoff)."}, {"heading": "6 Conclusion", "text": "We propose a representation and algorithm that cover 97.3% of graph structures in the PTB. Our algorithm is O(n4), uniquely decomposes parses, and enforces the property that parses are composed of a core tree with additional traces and null elements. A proof of concept parser shows that our algorithm can be used to parse and recover traces."}, {"heading": "Acknowledgments", "text": "We thank Greg Durrett for advice on parser implementation and debugging, and the action editor and anonymous reviewers for their helpful feedback. This research was partially supported by a General Sir John Monash Fellowship and the Office of Naval\nResearch under MURI Grant No. N000140911081."}], "year": 2017, "references": [{"title": "Bracketing Guidelines for Treebank 2 Style Penn Treebank Project", "authors": ["Ann Bies", "Mark Ferguson", "Karen Katz", "Robert MacIntyre", "Victoria Tredinnick", "Grace Kim", "Mary Ann Marcinkiewicz", "Britta Schasberger"], "venue": "Tech. rep.", "year": 1995}, {"title": "Language-Independent Parsing with Empty Elements", "authors": ["Shu Cai", "David Chiang", "Yoav Goldberg"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT). https://www.", "year": 2011}, {"title": "Using Linguistic Principles to Recover Empty Categories", "authors": ["Richard Campbell"], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL). https://www.aclweb. org/anthology/P/P04/P04-1082.pdf.", "year": 2004}, {"title": "Parsing to 1-Endpoint-Crossing, Pagenumber2 Graphs", "authors": ["Junjie Cao", "Sheng Huang", "Weiwei Sun", "Xiaojun Wan"], "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL).", "year": 2017}, {"title": "TAG, Dynamic Programming, and the Perceptron for Efficient, Feature-rich Parsing", "authors": ["Xavier Carreras", "Michael Collins", "Terry Koo"], "venue": "Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL). https : / / www .", "year": 2008}, {"title": "Hierarchical Phrase-Based Translation", "authors": ["David Chiang"], "venue": "Computational Linguistics 33.2, pp. 201\u2013228. https://www.aclweb.org/anthology/J/ J07/J07-2003.pdf.", "year": 2007}, {"title": "Programming Languages and Their Compilers: Preliminary Notes", "authors": ["John Cocke"], "venue": "Tech. rep. Courant Institute of Mathematical Sciences, New York University.", "year": 1969}, {"title": "Three Generative, Lexicalised Models for Statistical Parsing", "authors": ["Michael Collins"], "venue": "Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL). https://www.aclweb. org/anthology/P/P97/P97-1003.pdf.", "year": 1997}, {"title": "Deep Syntactic Processing by Combining Shallow Methods", "authors": ["P\u00e9tr Dienes", "Amit Dubey"], "venue": "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL). https://www.", "year": 2003}, {"title": "Three New Probabilistic Models for Dependency Parsing: An Exploration", "authors": ["Jason Eisner"], "venue": "Proceedings of the 16th International Conference on Computational Linguistics (CoLing). http : / / www . aclweb.org/anthology/C/C96/C96-1058.", "year": 1996}, {"title": "Parsing as Reduction", "authors": ["Daniel Fern\u00e1ndez-Gonz\u00e1lez", "Andr\u00e9 F.T. Martins"], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-", "year": 2015}, {"title": "Fully Parsing the Penn Treebank", "authors": ["Ryan Gabbard", "Mitchell Marcus", "Seth Kulick"], "venue": "Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (NAACL-HLT). https://www.aclweb.org/anthology/N/", "year": 2006}, {"title": "A Transition-based Parser for 2-Planar Dependency Structures. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL)", "authors": ["Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Joakim Nivre"], "year": 2010}, {"title": "Global Thresholding and Multiple-Pass Parsing", "authors": ["Joshua Goodman"], "venue": "Processings of the Second Conference on Empirical Methods in Natural Language Processing (EMNLP). https : / / www . aclweb.org/anthology/W/W97/W97-0302.", "year": 1997}, {"title": "A DependencyDriven Parser for German Dependency and Constituency Representations", "authors": ["Johan Hall", "Joakim Nivre"], "venue": "Proceedings of the Workshop on Parsing German. https://www.aclweb. org/anthology/W/W08/W08-1007.pdf.", "year": 2008}, {"title": "A Hybrid Constituency-Dependency Parser for Swedish", "authors": ["Johan Hall", "Joakim Nivre", "Jens Nilsson"], "venue": "Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA). https : / / www.aclweb.org/anthology/W/W07/W07-", "year": 2007}, {"title": "Empty Element Recovery by Spinal Parser Operations", "authors": ["Katsuhiko Hayashi", "Masaaki Nagata"], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL, Volume 2: Short Papers). https://www.aclweb.org/", "year": 2016}, {"title": "Finding Non-local Dependencies: Beyond Pattern Matching", "authors": ["Valentin Jijkoun"], "venue": "The Companion 452", "year": 2003}, {"title": "A Simple Pattern-matching Algorithm for Recovering Empty Nodes and Their Antecedents", "authors": ["Mark Johnson"], "venue": "Proceedings of the 40th Annual Meeting on Association for Computational Linguistics. https://www.aclweb.org/anthology/P/", "year": 2002}, {"title": "Handbook of Formal Languages: Volume 3 Beyond Words", "authors": ["Aravind K. Joshi", "Yves Schabes"], "venue": "In. Springer Berlin Heidelberg. Chap. Tree-Adjoining Grammars, pp. 69\u2013123.", "year": 1997}, {"title": "Lexical-Functional Grammar: A Formal System for Grammatical Representation", "authors": ["R.M. Kaplan", "J. Bresnan"], "venue": "The Mental Representation of Grammatical Relations. MIT Press, pp. 173\u2013281.", "year": 1982}, {"title": "An Efficient Recognition and Syntax-Analysis Algorithm for Context-Free Languages", "authors": ["Tadao Kasami"], "venue": "Tech. rep. University of Illinois at UrbanaChampaign.", "year": 1966}, {"title": "Transition-Based Left-Corner Parsing for Identifying PTB-Style Nonlocal Dependencies", "authors": ["Yoshihide Kato", "Shigeki Matsubara"], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL, Volume 1: Long Papers).", "year": 2016}, {"title": "Transforming Dependencies into Phrase Structures", "authors": ["Lingpeng Kong", "Alexander M. Rush", "Noah A. Smith"], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-", "year": 2015}, {"title": "Algorithms for Identifying Syntactic Errors and Parsing with Graph Structured Output", "authors": ["Jonathan K. Kummerfeld"], "venue": "PhD thesis. EECS Department, University of California, Berkeley. http://www2.eecs. berkeley . edu / Pubs / TechRpts / 2016 /", "year": 2016}, {"title": "An Empirical Analysis of Optimization for Max-Margin NLP", "authors": ["Jonathan K. Kummerfeld", "Taylor Berg-Kirkpatrick", "Dan Klein"], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://www.", "year": 2015}, {"title": "Faster Parsing by Supertagger Adapta", "authors": ["Jonathan K. Kummerfeld", "Jessica Roesner", "Tim Dawborn", "James Haggerty", "James R. Curran", "Stephen Clark"], "year": 2010}, {"title": "Deep Dependencies from Context-free Statistical Parsers: Correcting the Surface Dependency Approximation", "authors": ["Roger Levy", "Christopher D. Manning"], "venue": "Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL\u201904), Main", "year": 2004}, {"title": "Improved CCG Parsing with Semi-supervised Supertagging", "authors": ["Mike Lewis", "Mark Steedman"], "venue": "Transactions of the Association for Computational Linguistics 2, pp. 327\u2013338. ISSN: 2307-387X. https:// transacl . org / ojs / index . php / tacl /", "year": 2014}, {"title": "Building a Large Annotated Corpus of English: The Penn Treebank", "authors": ["Mitchell P. Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz"], "venue": "Computational Linguistics 19.2, pp. 313\u2013330. https : / / www.aclweb.org/anthology/J/J93/J93-", "year": 1993}, {"title": "Online Large-Margin Training of Dependency Parsers", "authors": ["Ryan McDonald", "Koby Crammer", "Fernando Pereira"], "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL). https://www.aclweb.org/anthology/P/", "year": 2005}, {"title": "A Crossing-Sensitive Third-Order Factorization for Dependency Parsing", "authors": ["Emily Pitler"], "venue": "Transactions of the Association for Computational Linguistics 2, pp. 41\u201354. https : / / transacl . org / ojs / index.php/tacl/article/view/193.", "year": 2014}, {"title": "Finding Optimal 1-Endpoint-Crossing Trees", "authors": ["Emily Pitler", "Sampath Kannan", "Mitchell Marcus"], "venue": "Transactions of the Association for Computational Linguistics 1, pp. 13\u201324. https://www.aclweb. org/anthology/Q/Q13/Q13-1002.pdf.", "year": 2013}, {"title": "Trace Prediction and Recovery with Unlexicalized PCFGs and Slash Features", "authors": ["Helmut Schmid"], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL).", "year": 2006}, {"title": "Learnability-Based Syntactic Annotation Design", "authors": ["Roy Schwartz", "Omri Abend", "Ari Rappoport"], "venue": "Proceedings of COLING 2012. http : / / www . aclweb.org/anthology/C/C12/C12-1147. pdf.", "year": 2012}, {"title": "LTAG-spinal and the Treebank", "authors": ["Libin Shen", "Lucas Champollion", "Aravind K. Joshi"], "venue": "Language Resources and Evaluation 42.1, pp. 1\u201319.", "year": 2007}, {"title": "The Syntactic Process", "authors": ["Mark Steedman"], "venue": "MIT Press.", "year": 2000}, {"title": "Recognition and Parsing of Context-Free Languages in Time n3", "authors": ["Daniel H. Younger"], "venue": "Information and Control 10.2, pp. 189\u2013208.", "year": 1967}], "id": "SP:34002ed9cea747007e2594917aa6a5d9d8fa0098", "authors": [{"name": "Jonathan K. Kummerfeld", "affiliations": []}, {"name": "Dan Klein", "affiliations": []}], "abstractText": "General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons. We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference. In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena. We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner. Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank. We also implement a proofof-concept parser that recovers a range of null elements and trace types.", "title": "Parsing with Traces: An O(n) Algorithm and a Structural Representation"}
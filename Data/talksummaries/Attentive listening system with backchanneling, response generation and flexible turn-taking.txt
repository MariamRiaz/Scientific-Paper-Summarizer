6	29	Towards this goal, we use the autonomous android named Erica.
7	45	Our long-term goal is for Erica to be able to participate in a conversation with a human user while displaying human-like speech and gesture.
8	33	In this work we focus on integrating an attentive listener function into Erica and describe a new approach for this application.
9	24	The approaches to these kind of dialogue systems have focused mainly on backchanneling behavior and have been implemented in large-scale projects such as SimSensei (DeVault et al., 2014), Sensitive Artificial Listeners (Bevacqua et al., 2012) and active listening robots (Johansson et al., 2016).
16	44	Meanwhile, the statement response system detects focus words of the user’s utterance and uses them to generate responses as a wh-question or by repeating it back to the user.
17	24	We also introduce a novel approach to turn-taking which uses 127 backchannels and fillers to indicate confidence in taking the speaking turn.
42	26	This is because the user may wish to keep talking and the system should not interrupt.
52	28	We trained the model using a counseling corpus.
54	42	The model makes a prediction every 100ms by using windows of prosodic features of sizes 100, 200, 500, 1000 and 2000 milliseconds.
74	33	The audio channel of the counselor’s voice was separated and so could be removed.
75	72	When the model determined that a backchannel should be generated at a timepoint, we manually inserted the backchannel pattern into the speaker’s channel using audio editing software, effectively replacing the counselor’s voice.
78	18	Each measure was rated using a 7-point Likert scale.
80	21	Our proposed model outperformed the baseline models and was comparable to the counselor condition.
81	26	The results of both evaluations show the need for backchannel timing to be done continuously and not just at the end of utterances.
84	38	The statement response tries to use a question phrase which repeats a word that the user has previously said.
104	46	If no focus phrase is found we match the predicate of the utterance to a question word using the same method as above.
113	26	However, in the case of a focus word being unable to be found correctly identifying a question word for a predicate is a challenge.
114	26	Next, we evaluated our statement response system by testing if it could reduce the number of fallback responses used by the system.
124	21	The system decides when it should take the turn using a decision model.
136	41	Fillers are known to indicate a willingness to take the turn (Clark and Tree, 2002; Ishi et al., 2006) and so are used to grab the turn from the user.
142	35	Our proposed model requires two likelihood score thresholds (T1 and T2) to decide whether or not to be silent (≤ T1) or take the turn (≥ T2).
158	28	Instead we use a spherical microphone array placed on a table between Erica and the user.
163	17	We have observed from previous demonstrations that users often do not speak with Erica as if she is an attentive listener.
165	34	To overcome this issue in order to evaluate the statement response system, we first provided the subjects with dialogue prompts in the form of scripts.
168	38	The first task was to read from four conversational scripts of 3 to 5 turns each.
169	25	These scripts were not hand-crafted, but taken from a corpus of real attentive listening conversations with a Wizard-of-Oz controlled robot.
170	43	Subjects were instructed to pause after each sentence in the script to wait for a statement response.
171	399	If Erica replied with a question they could answer it before con- tinuing the scripted conversation.
181	60	This is because the script readings were taken from conversations which used more complex sentences than the free talk, and focus nouns for which a suitable question word could not be reliably matched.
184	72	The evaluators rated each of Erica’s backchannels and statement responses in terms of coherence (coherent, somewhat coherent, or incoherent) and timing (fast, appropriate, or slow).

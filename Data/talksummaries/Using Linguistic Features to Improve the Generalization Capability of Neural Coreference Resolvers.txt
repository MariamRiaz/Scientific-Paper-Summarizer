0	15	Coreference resolution is the task of recognizing different expressions that refer to the same entity.
31	31	The first step is to train a decision tree on a dataset in which each sample consists of features describing a mention pair.
44	21	The mention-ranking model of deepcoref has three variations: (1) “ranking” uses the slack-rescaled max-margin training objective of Wiseman et al. (2015), (2) “reinforce” is a variation of the “ranking” model in which the hyperparameters are set in a reinforcement learning framework (Sutton and Barto, 1998), and (3) “top- pairs” is a simple variation of the “ranking” model that uses a probabilistic objective function and is used for pretraining the “ranking” model.
45	39	e2e-coref is an end-to-end system that jointly models mention detection and coreference resolution.
47	19	Apart from a single model, e2e-coref includes an ensemble of five models.
51	38	The examined linguistic features include string match, syntactic, shallow semantic and discourse features.
52	13	Mention-based features include: – Mention type: proper, nominal or pronominal – Fine mention type: proper, definite or indefinite nominal, or the citation form of pronouns – Gender: female, male, neutral, unknown – Number: singular, plural, unknown – Animacy: animate, inanimate, unknown – Named entity type: person, location, organization, date, time, number, etc.
53	20	– Dependency relation: enhanced dependency relation (Schuster and Manning, 2016) of the head word to its parent – POS tags of the first, last, head, two words preceding and following of each mention Pairwise features include: – Head match: both mentions have the same head, e.g. “red hat” and “the hat” – String of one mention is contained in the other, e.g. “Mary’s hat” and “Mary” – Head of one mention is contained in the other, e.g. “Mary’s hat” and “hat” – Acronym, e.g. “Heidelberg Institute for Theoretical Studies” and “HITS” 6 The CoNLL score of the e2e-coref single model on the CoNLL development set drops from 67.36 to 65.81, while that of the deep-coref “ranking” model is 66.09.
54	9	– Compatible pre-modifiers: the set of premodifiers of one mention is contained in that of the other, e.g. “the red hat that she is wearing” and “the red hat” – Compatible7 gender, e.g. “Mary” and “women” – Compatible number, e.g. “Mary” and “John” – Compatible animacy, e.g. “those hats” and “it” – Compatible attributes: compatible gender, number and animacy, e.g. “Mary” and “she” – Closest antecedent that has the same head and compatible premodifiers, e.g. “this new book” and “This book” in “Take a look at this new book.
55	11	This book is one of the best sellers.” – Closest antecedent that has compatible attributes, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “John saw Mary, and she was in a hurry” – Closest antecedent that has compatible attributes and is a subject, e.g. the antecedent “Mary” and the anaphor “she” in the sentence “Mary saw John, but she was in a hurry” – Closest antecedent that has compatible attributes and is an object, e.g. “Mary” and “she” in “John saw Mary, and she was in a hurry” The last three features are similar to the discourselevel features discussed by Uryupina (2007), which are created by combining proximity, agreement and salience properties.
60	18	All features are extracted using Stanford CoreNLP (Manning et al., 2014).
63	11	The results of employing those features in deepcoref’s “ranking” and “top-pairs” models on the CoNLL development set are reported in Table 1.
68	30	We observe that incorporating all the linguistic features bridges the gap between the performance of “top-pairs” and “ranking”.
74	18	As discussed by Moosavi and Strube (2017a), there is a large lexical overlap between the coreferring mentions of the CoNLL training and evaluation sets.
76	51	For linguistic features to be more effective in current coreference resolvers, which rely heavily on lexical features, they should also provide a strong signal for coreference resolution.
78	21	Besides, for features with multiple values, e.g. mention-based features, only a small subset of values may be informative.
79	55	To better exploit linguistic features, we only employ (feature, value) pairs9 that are informative for coreference resolution.
82	88	We use a discriminative pattern mining approach (Cheng et al., 2007, 2008; Batal and Hauskrecht, 2010) that examines all combinations of feature-values, up to a certain length, and determines which feature-values are informative when they are considered in combination.
92	14	For representing the input samples, we use the Frequent Pattern Tree (FP-Tree) structure that is the data structure of the FP-Growth algorithm (Han et al., 2004), i.e. one of the most common algorithms for frequent pattern mining.
124	11	For each ai ∈ Aj , the algorithm builds new pattern q by combining ai with p. frequent(q) checks whether q meets the frequency condition.
172	63	By setting Θl to five,12 EPM results in 13 pairwise feature-values, 112 POS tags, i.e. 53 POS for anaphors and 59 for antecedents, 25 dependency relations, 26 mention types (mention types or fine mention types), and finally, 14 named entity tags.13 Based on the observation in Section 5, we use the top-pairs model of deep-coref as the baseline to employ additional features, i.e. “+EPM” is the top-pairs model in which EPM feature-values are incorporated.
187	16	The results of the first evaluation setup are shown in Table 6.
188	22	The best performance on WikiCoref is achieved by Ghaddar and Langlais (2016a) (“G&L” in Table 6) who introduced WikiCoref and design a domain-specific coreference resolver that makes use of the Wikipedia markups of a document as well as links to Freebase, which are annotated in WikiCoref.
190	14	While “+EPM” does not use the WikiCoref data during training, and unlike “G&L”, it does not employ any domain-specific features, it achieves onpar performance with that of “G&L”.
193	83	“in-domain” columns show the results when the evaluation genres were included in training and development sets while the “out-of-domain” columns show the results when the evaluation genres were excluded.
194	13	As we can see, “+EPM” generalizes best, and in out-ofdomain evaluations, it considerably outperforms the ensemble model of e2e-coref, which has the best performance on the CoNLL test set.
195	47	In this paper, we show that employing linguistic features in a neural coreference resolver significantly improves generalization.
196	97	However, the incorporated features should be informative enough to be taken into account in the presence of lexical features, which are very strong features in the CoNLL dataset.
197	16	We propose an efficient algorithm to determine informative feature-values in large datasets.
198	26	As a result of a better generalization, we achieve state-of-the-art results in all examined outof-domain evaluations.

0	27	Cross-lingual semantic word similarity addresses the task of detecting words that refer to similar semantic concepts and convey similar meanings across languages.
2	21	Such lexicons and semantically similar words serve as important resources in cross-lingual knowledge induction (e.g., Zhao et al. (2009)), statistical machine translation (Och and Ney, 2003) and cross-lingual information retrieval (Ballesteros and Croft, 1997; Levow et al., 2005).
3	28	From parallel corpora, semantically similar words and bilingual lexicons are induced on the basis of word alignment models (Brown et al., 1993; Och and Ney, 2003).
13	46	In this work, we propose a new approach to constructing the shared cross-lingual semantic space that relies on a paradigm of semantic word responding or free word association.
15	114	Semantic word responding addresses a task that requires participants to produce first words that come to their mind that are related to a presented cue word (Nelson et al., 2000; Steyvers et al., 2004).
17	49	Each axis in the space denotes a semantic word response.
18	58	The similarity between two words is then computed as the similarity between the vectors comprising their semantic word responses using any of existing SF -s. Two words are considered semantically similar if they are likely to generate similar semantic word responses and assign similar importance to them.
22	30	• We present how to estimate and quantify semantic word responses by means of a multilingual probabilistic topic model.
24	17	• We show that the response-based model of similarity is more robust and obtains better results for BLE than the models that operate in the semantic space spanned by latent semantic concepts, i.e., cross-lingual topics directly.
35	30	Since the method utilizes the concept of multilingual probabilistic topic modeling, we first provide a very short overview of that concept, then present the intuition behind the approach, and finally describe our method in detail.
37	21	A multilingual probabilistic topic model (Mimno et al., 2009; De Smet and Moens, 2009; Boyd-Graber and Blei, 2009; Ni et al., 2009; Jagarlamudi and Daumé III, 2010; Zhang et al., 2010) of a multilingual corpus C is defined as a set of semantically coherent multinomial distributions of words with values Pj(w j i |zk), j = 1, .
41	49	The probability scores Pj(w j i |zk) build per-topic word distributions, and they consti- tute a language-specific representation (e.g., a probability value is assigned only for words from V j) of a language-independent cross-lingual latent concept, that is, latent cross-lingual topic zk ∈ Z .
45	89	Each cross-lingual topic from the set Z can be observed as a latent language-independent concept present in the multilingual corpus, but each language in the corpus uses only words from its own vocabulary to describe the content of that concept.
65	27	To model semantic word responses via the shared space of cross-lingual topics, we have to set a probabilistic mass that quantifies the degree of association.
66	51	Given two words w1, w2 ∈ V S ∪ V T , a natural way of expressing the asymmetric semantic association is by modeling the probability P (w2|w1) (Griffiths et al., 2007), that is, the probability to generate word w2 as a response given word w1.
67	17	After the training of a multilingual topic model on a multilingual corpus, we obtain per-topic word distributions with scores PS(wSi |zk) and PT (wTi |zk) (see Sect.
69	21	The probability scores P (zk|w1) ensure that topics zk that are semantically relevant to the given word w1 dominate the sum, so the overall high score Resp(w1, w2) of the semantic word response is assigned only to highly descriptive words of the semantically related topics.
70	46	Using the shared space of cross-lingual topics, semantic response scores can be derived for any two words w1, w2 ∈ V S ∪ V T .1 The generative model closely resembles the actual process in the human brain - when we generate semantic word responses, we first tend to associate that word with a related semantic/cognitive concept, in this case a cross-lingual topic (the factor P (zk|w1)), and then, after establishing the concept, we output a list of words that we consider the most prominent/descriptive for that concept (words with high scores in the factor P (w2|zk)) (Nelson et al., 2000; Steyvers et al., 2004).
88	24	We have created a language-independent cross- lingual semantic space spanned by all vocabulary words in both languages.
89	25	Each feature corresponds to one word from vocabularies V S and V T , while the exact score for each feature in the context vector cv(wi) is precisely the probability that this word/feature will be generated as a word response given word wi.
92	25	Therefore, the real synonyms and translations should occur as top candidates in the lists of similar words obtained by the response-based method.
109	22	In a typical setting for mining semantically similar words using latent topic models in both monolingual (Griffiths et al., 2007; Dinu and Lapata, 2010) and cross-lingual setting (Vulić et al., 2011), the best results are obtained with the number of topics set to a few thousands (≈ 2000).
111	23	Other parameters of the model are set to the standard values according to Steyvers and Griffiths (2007): α = 50/K and β = 0.01.
112	21	We are aware that different hyper-parameter settings (Asuncion et al., 2009; Lu et al., 2011), might have influence on the quality of learned cross-lingual topics, but that analysis is out of the scope of this paper.
118	19	3) The best scoring similarity method from Vulić et al. (2011) named TI+Cue.
141	17	Example lists of semantically similar words over all 3 language pairs are shown in Table 3.
144	17	The overall quality of the crosslingual word similarities and lexicons extracted by the method is dependent on the quality of estimated semantic response vectors.
153	18	(iv) The effect of word frequency is clearly visible when comparing the results obtained on IT-ENW with the results obtained on the other Wikipedia corpora.
163	36	We have proposed a new statistical approach to identifying semantically similar words across languages that relies on the paradigm of semantic word responding previously defined in cognitive science.
165	22	That effectively makes it applicable to any language pair.

0	75	Stance classification is the task of automatically identifying users’ positions about a specific target from text (Mohammad et al., 2017).
1	16	Table 1 shows an example of this task, where the stance of the sentence is recognized as favorable on the target climate change is concern.
2	48	Traditionally, this task is approached by learning a target-specific classifier that is trained for prediction on the same target of interest (Hasan and Ng, 2013; Mohammad et al., 2016; Ebrahimi et al., 2016).
5	11	For example, in our project we are interested in online users’ stances on the approvals of particular mining projects in the country.
6	21	It might be useful to start with a classifier that is adapted from a related target such as climate change is concern (presumably available and annotated), as in both cases users could discuss the impacts from the targets to some common issues, such as the environment or communities.
8	26	However, for some targets that can be recognized as being related to the same and more general domains, it could be possible to generalize through certain aspects of the domains that reflect users’ major concerns.
9	36	For example, from the following sentence, whose stance is against the approval of a mining project, “Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef”, it can be seen that both this sentence and the one in Table 1 mention the same aspect “reef destruction/damage”, which is closely related to the “environment” domain.
13	7	Our preliminary analysis shows that the proposed model can find useful domain-specific information from a stancebearing sentence and that the classification performance is improved in certain domains.
14	8	In this section, we introduce the proposed model, CrossNet, for cross-target stance classification.
16	8	It consists of four layers from the Embedding Layer (bottom) to the Prediction Layer (top).
17	13	It works by taking a stance-bearing sentence and a target as input and yielding the predicted stance label as output.
24	35	Moreover, to account for the impact of the target on stance inference, we borrow the idea of conditional encoding (Augenstein et al., 2016) to model the dependency of the sentence on the target.
25	27	Formally, we first use a BiLSTMT to encode the target: [ −→ h Ti −→c Ti ] = −−−−→ LSTMT (ti, −→ h Ti−1, −→c Ti−1) [ ←− h Ti ←−c Ti ] = ←−−−− LSTMT (ti, ←− h Ti+1, ←−c Ti+1) (1) where h ∈ Rh and c ∈ Rh are the hidden state and cell state of LSTM.
33	27	Based on this observation, the perception of the domain aspects can be boiled down to finding the sentence parts that not only carry the core idea of a stance-bearing sentence but also tend to be recurring in the corpus.
35	13	Then, we utilize self-attention to signal the core parts of a stance-bearing sentence.
40	11	Next, we compute the attention weight ai for each hPi based on its compatibility score via softmax operation: ai = exp(ci)∑|P | j=1 exp(cj) (4) Finally, we can obtain the domain aspect encoded representation based on the attention weights: AP = |P |∑ i=1 aih P i (5) where AP ∈ R2h is the domain aspect encoding for sentence P and also the output of this layer.
41	27	We predict the stance label of the sentence based on its domain aspect encoding: ŷ = softmax(MLP(AP )) (6) where we use a multilayer perceptron (MLP) to consume the domain aspect encoding AP and apply the softmax to get the predicted probability for each of the C classes, ŷ = {y1, ..., yC}.
46	11	SemEval-2016: the first dataset is from SemEval2016 Task 6 on Twitter stance detection, which contains stance-bearing tweets on different targets.
47	7	We use the following five targets for our experiments: Climate Change is Concern (CC), Feminist Movement (FM), Hillary Clinton (HC), Legalization of Abortion (LA), and Donald Trump (DT).
53	9	To align with our scenario, the above targets can be categorized into three different domains: Women’s Rights (FM, LA), American Politics (HC, DT), and Environments (CC, AM).
56	10	To evaluate the effectiveness of target adaptation, we use the metric transfer ratio (Glorot et al., 2011) to compare the cross-target and in-target performance of a model: Q = F (S,D)Fb(D,D) , where F (S,D) is the cross-target F1-score of a model trained on the source target S and tested on the destination target D, and Fb(D,D) is the in-target F1-score of a baseline model trained and tested on the same target D, which serves as the performance calibration for target adaptation.
72	17	First, it is observed that MITRE outperforms BiLSTM over all target configurations, suggesting that, compared to simple concatenation, the conditional encoding of the target information could be more helpful to capture the dependency of the sentence on the target.
73	50	Second, our model is shown to achieve better results than the two baselines in almost all cases (only slightly worse than MITRE on LA under the in-target setting, and the difference is not statistically significant), which implies that the aspect attention mechanism adopted in our model could benefit target-level generalization while it does not hurt the in-target performance.
74	62	Moreover, by comparing the performance of our model under different target configurations, we see that the improvements brought by our model are more significant on the cross-target task than they are on the intarget task, with an average improvement of 6.6% (cross-target) vs. 3.0% (in-target) over MITRE in F1-score, which demonstrates a greater advantage of our model in the cross-target task.
76	8	To show that our model can select sentence parts that are related to domain aspects, we visualize the self-attention results on some tweet examples that are correctly classified by our model in Table 4.
77	33	We can see that the most highlighted parts in each example are relevant to the respective domain.
78	12	For example, “feminist”, “rights”, and “equality” are commonly used when talking about women’s rights, and “president” and “dreams” of- ten appear in text about politics.
79	30	It is also interesting to note that words that are specific to the destination target may not be captured by the model learned from the source target, such as “abortion” in sentence 1 and “trumps” in sentence 3.
81	31	Finally, for our project, we can see from the last two sentences that the model learned from climate change is concern is able to concentrate on words that are central to understanding the authors’ stances on the approval of the mining project, such as “reef”, “destroy”, “environmental”, and “disaster”.
82	69	Overall, the above visualization demonstrates that our model could benefit stance inference across related targets through capturing domain-specific information.

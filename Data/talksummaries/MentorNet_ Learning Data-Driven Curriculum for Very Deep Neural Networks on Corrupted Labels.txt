0	14	Zhang et al. (2017a) found that deep convolutional neural networks (CNNs) are capable of memorizing the entire data even with corrupted labels, where some or all true labels are replaced with random labels.
4	63	This paper studies how to overcome the corrupted label for deep CNNs, so as to improve generalization performance on the clean test data.
5	33	Although learning models on weakly labeled data might not be novel, improving deep CNNs on corrupted labels is clearly an under-studied problem and worthy of exploration, as deep CNNs are more prone to overfitting and memorizing corrupted labels (Zhang et al., 2017a).
6	17	To address this issue, we focus on training very deep CNNs from scratch, such as resnet-101 (He et al., 2016) or inception-resnet (Szegedy et al., 2017) which has a few hundred layers and orders-of-magnitude more parameters than the number of training samples.
7	14	These networks can achieve the state-of-the-art result but perform poorly when trained on corrupted labels.
8	11	Inspired by the recent success of Curriculum Learning (CL), this paper tackles this problem using CL (Bengio et al., 2009), a learning paradigm inspired by the cognitive process of human and animals, in which a model is learned gradually using samples ordered in a meaningful sequence.
25	13	It takes into account of the feedback from StudentNet and can be dynamically adjusted during training.
26	21	Intuitively, this resembles a “collaborative” learning paradigm, where the curriculum is determined by the teacher and student together.
47	13	When w is fixed, we compute vk = arg minv F(vk−1,wk) using the most recently updated wk at epoch k. For example, Kumar et al. (2010) employed G(v) = −λ‖v‖1.
53	16	When λ is small, only samples of small loss will be considered.
55	24	As shown, the function G specifies a curriculum, i.e., a sequence of samples with their corresponding weights to be used in training.
56	12	When w is fixed, its optimal solution, e.g. Eq.
64	13	Such predefined curriculums cannot be adjusted accordingly, taking into account of the feedback from the student.
65	11	This section discusses a new way to learn data-driven curriculum by a neural network, called MentorNet.
66	27	The MentorNet gm is learned to compute time-varying weights for each training sample.
68	13	Given a fixed w, our goal is to learn an Θ∗ to compute the weight: gm(zi; Θ ∗) = arg min vi∈[0,1] F(w,v),∀i ∈ [1, n] (3) where zi = φ(xi, yi,w) indicates the input feature to MentorNet about the i-th sample.
88	14	Our next task is to learn a curriculum solely derived from labeled data.
91	13	In this paper, we assign binary labels to v∗i , where v ∗ i = 1 iff yi is a correct label.
96	10	The information on the correct label may not always be available on the target dataset D. In this case, we learn the curriculum on a different small dataset where the correct labels are available.
123	21	It is interesting to analyze why the learned curriculum can improve the generalization performance.
144	12	On noisy data, the effect of the robust objective is evident, i.e., preventing StudentNet from being dominated by corrupted labels.
176	12	In experiments, we update Θ twice after the learning rate is changed.
196	17	We employ 3 recent deep CNNs as our StudentNets: inception (Szegedy et al., 2016), resnet-101 (He et al., 2016) with wide filters (Zagoruyko & Komodakis, 2016) and inceptionresnet v2 (Szegedy et al., 2017).
270	15	As we see, the proposed MentorNet significantly improves baseline methods on real-world noisy labels.
274	14	To the best of our knowledge, it achieves the best-published result on the WebVision (Li et al., 2017a) benchmark.
298	10	In this paper, we presented a novel method for training deep CNNs on corrupted labels.
299	44	Our work was built on curriculum learning and advanced the methodology by proposing to learn data-driven curriculum via a neural network called MentorNet.
300	18	We proposed an algorithm for jointly optimizing deep CNNs with MentorNet on large-scale data.
301	39	We conducted comprehensive experiments on datasets of controlled and real-world noise.
302	48	Our empirical results showed that generalization performance of deep CNNs trained on corrupted labels can be effectively improved by the learned data-driven curriculum.

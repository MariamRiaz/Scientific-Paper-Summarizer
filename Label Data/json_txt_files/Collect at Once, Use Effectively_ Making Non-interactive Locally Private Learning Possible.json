{"sections": [{"heading": "1. Introduction", "text": "Data privacy has become an increasingly important issue in the age of data science. Differential Privacy (DP), proposed in 2006 by Dwork et al.,(Dwork et al., 2006), provide a solid foundation and rigorous standard for private data analysis. Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering (Hardt & Rothblum, 2010; Hardt et al., 2012; Thaler et al., 2012; Wang\n*Equal contribution 1Key Laboratory of Machine Perception, MOE, School of EECS, Peking University, Beijing, China. Correspondence to: Kai Zheng <zhengk92@pku.edu.cn>, Wenlong Mou <mouwenlong@pku.edu.cn>, Liwei Wang <wanglw@cis.pku.edu.cn>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\net al., 2016), machine learning (Chaudhuri & Monteleoni, 2008; Chaudhuri et al., 2011; Rubinstein et al., 2012; Wang et al., 2015), and statistical inference (Lei, 2011; Smith, 2011). For more details on DP results, please refer to the excellent monograph written by Dwork and Roth (Dwork & Roth, 2014). Intuitively, a DP algorithm uses randomized response to defend against adversary, so that change of one of data points could not be detected.\nDespite the prevailing success of this notion in academia, its applicability in data science practice could be limited. For example, if data analysts just promise to follow the differential privacy constraints, user will not feel their privacy are preserved. The promise could not be validated; the mechanisms are complicated; and even worse: users do not trust the data collector at all. Unfortunately, most of differential privacy algorithms are based on adding noise calibrated to stability of loss function, which essentially requires access to original data.\nBorrowing ideas from classical wisdom on collecting sensitive survey data (Warner, 1965), Local Differential Privacy (LDP) (Kasiviswanathan et al., 2008; Duchi et al., 2013b) was proposed as a stronger notion of privacy to resolve this problem. LDP requires each of data points to be passed through a noisy channel during collection. This channel will ensure one can hardly tell anything about the user based on what he have sent. The practical advantage of LDP is obvious: users will be comfortable sending their sensitive information through noisy channels, which are transparent and reliable; additionally, users can choose their own privacy parameters, making it possible to associate with economic value. Therefore, this line of research has attracted lots of attention (Duchi et al., 2013a;b; Kairouz et al., 2014; Bassily & Smith, 2015; Kairouz et al., 2016).\nDespite the analogy in definition, the way in which LDP achieves accurate results are fundamentally different from classical DP. Essentially, the information collected from each user is almost completely noisy, from which one needs to obtain accurate results. The only way to do that is to make the independently distributed noise cancel out with each other in some sense. With sand being washed away by waves, golds begin to appear.\nTwo local privacy notions have been discussed in existing literature: the interactive model allows the algorithm to collect data sequentially, and decide what to ask based on information from previously asked users. The non-interactive model, on the contrary, requires all data to be collected at once, with no interactive queries allowed. Apparently the non-interactive model is strictly stronger, and prohibition on interactive queries rules out most of SGD-type approaches, making the problem significantly harder. However, non-interactive LDP is more useful in real-world applications, as opportunities of interactive queries may not be available in most settings.\nIn existing literature, learning and inference under interactive and non-interactive LDP therefore are exhibiting different appearances. In the interactive world, LDP is promised with connection to Statistical Query (SQ) model (Kearns, 1998), from its very beginning (Kasiviswanathan et al., 2011). SQ algorithms for a wide range of convex ERM problems were proposed by (Feldman et al., 2017), implying good risk bounds for LDP. (Duchi et al., 2013b) established matching upper and lower bounds for convex risk minimization problems. On the other hand, very few has been done in the non-interactive setting. Existing works primarily focus on basic estimation problems such as means and discrete densities (Duchi et al., 2013a; 2016; Bassily & Smith, 2015), or some function calculations (Kairouz et al., 2015b). Most of important modern learning and inference tasks, including estimation in linear models and convex ERM, are still poorly understood in non-interactive local DP settings.\nFor the high-dimensional world, where d n while some low-complexity constraints are imposed, we may hope the error induced by privacy constraints to be logarithmically dependent upon d. In classical differential privacy literature, this has been be addressed using different techniques, guarantee error bounds logarithmically dependent on dimension (Talwar et al., 2015; Smith & Thakurta, 2013). However, lower bounds have been shown in local privacy model even for high-dimensional 1-sparse mean estimation, ruling out any good guarantees (Duchi et al., 2016). The lower bound result illustrates fundamental difficulties of local differential privacy. But if we still want to do highdimensional learning under local privacy, are there additional assumptions that helps?\nTherefore, the starting point of this work lies on making learning possible under the non-interactive LDP setting, which is the hardest yet the most useful. We initiate the first attempt towards a broad range of learning tasks beyond simple distribution estimation. In particular, we investigate two important classes of problems under non-interactive LDP: (1) High-dimensional sparse linear regression and mean estimation; (2) Generalized linear models. Our fo-\ncus is to design corresponding mechanisms and study their convergence rates with respect to the number and dimension of data. One can also consider optimal mechanisms in terms of privacy parameters like (Geng & Viswanath, 2014), which is of independent interests.\nOur Contributions: In this paper, we propose several efficient algorithms for learning and estimation problems under non-interactive LDP model, with good theoretical guarantees. In the following we summarize our contributions.\n(1) High Dimensional Estimation: One of exciting findings in this paper is about local privacy for highdimensional data. Roughly speaking, convergence rate with logarithmic dependence on the dimension can be attained under LDP, if we assume data points are `2 bounded. This is in sharp contrast with information-theoretic lower bounds for 1-sparse mean estimation for `\u221e bounded data (Duchi et al., 2016). Valid algorithms are presented for both sparse mean estimation and sparse linear regression, respectively. Intuitively, non-interactivity doesn\u2019t bring about additional difficulties, since the loss functions are quadratic forms. However, if we directly add noise to each of data points and send it to the server, the aggregated noise will lead to linear dependence on the dimension. Thus we adopt the random projection technique, and send the noisy version of projected data to the server. Based on the aggregated information, we can approximately recover the optimal solution via linear inverse problem.\n(2) Learning Smooth Generalized Linear Models: Generalized linear problems which has additional smooth properties (we call the loss with respect to it as smooth generalized linear loss (SGLL), see rigorous definition in section 2) include many common loss functions, such as logistic loss, square loss, etc. Optimizing such losses are intuitively much more difficult in non-interactive LDP model, as the loss can be an arbitrary function wTx. This even makes it difficult for us to obtain an unbiased estimator for objective function, or its gradient. As a result, when we aggregate the loss of noisy data together, it is even hard to ensure it converge to the population loss. Approximation theory techniques are introduced to tackle this problem. In particular, we use polynomials of wTx to approximate nonlinear coefficients of gradients. Chebyshev bases, instead of Taylor series, are used to get faster convergence within an arbitrary domain. Then we are able to build inexact stochastic gradient oracles to arbitrarily specified accuracy. SIGM algorithm in (Dvurechensky & Gasnikov, 2016) is exploited to find the minimizer with inexact gradients.\nOther Related Work: Local privacy dates back to (Warner, 1965), who uses random responses to protect privacy in surveys. In recent LDP literature, both (Duchi et al., 2013a) and (Kairouz et al., 2016) studied density estimation methods and their theoretical behaviors in\nLDP model. Rather than statistical setting in above two work, (Bassily & Smith, 2015) considered how to produce frequent items and corresponding frequencies of a dataset in local model. Besides, (Kairouz et al., 2014) investigated optimality of LDP mechanisms based on information theoretical measures for statistical discrimination.\nApproximation techniques are commonly used in DP literature. (Thaler et al., 2012) employed polynomials for marginal queries. (Wang et al., 2016) leveraged trigonometric polynomials to answer smooth queries. (Zhang et al., 2012) also used polynomial approximations and get basic convergence results in standard DP model. Besides, the random projection and recovery has also been used in DP learning (Kasiviswanathan & Jin, 2016) and local DP histogram estimation (Bassily & Smith, 2015).\nIn standard DP model, both high-dimensional sparse estimation and generalized linear model have been intensively studied. (Kifer et al., 2012) and (Smith & Thakurta, 2013) considered the convergence of private LASSO estimator under RSC and incoherence assumptions. (Talwar et al., 2015) considered constrained ERM of sparse linear regression, and obtained O\u0303(log d/n2/3) rate using private Frank-Wolfe. Above results assume `\u221e-bounded data. By stronger assumption of `2 bounded data, (Kasiviswanathan & Jin, 2016) gave a general framework for high dimensional empirical risk minimization (ERM) problem. There are several works to estimate generalized linear model under DP, with a particular emphasis on logistic regression. Objective and output perturbation are used to get low excess risks (Chaudhuri & Monteleoni, 2008; Chaudhuri et al., 2011). Both (Bassily et al., 2014) and (Zhang et al., 2017) considered concrete private algorithms to solve ERM. None of these existing results extends directly to non-interactive LDP setting."}, {"heading": "2. Preliminaries", "text": "Some notations: [p] = {1, 2, \u00b7 \u00b7 \u00b7 , p}. Vectors are written in bold symbol, such as x,w. x represents univariate number, which has no relation with x. For a vector x = [x1, x2, \u00b7 \u00b7 \u00b7 , xd]T , xk represents the power of each element. B2(r) = {x| \u2016x\u20162 6 r}. Denote S+ as the semipositive matrix space, ProjS+(\u00b7) means projecting a matrix to S+ in terms of Frobenius norm (i.e. eliminate all negative eigenvalues). For an univariate function f(x), f (k)(x) represents its k-th derivative, and define\u2225\u2225f (k)\u2225\u2225 T := \u222b 1 \u22121 |f(k+1)(x)|\u221a\n1\u2212x2 dx. For the reason of limited space, all omitted proof can be found in the supplementary."}, {"heading": "2.1. Local Differential Privacy", "text": "Here we adopt the LDP definition given in (Bassily & Smith, 2015).\nDefinition 1. A mechanismQ : V \u2192 Z is said to be ( , \u03b4)local differential private or ( , \u03b4)-LDP, if for any v,v\u2032 \u2208 V , and any (measurable) subset S \u2282 Z , there is\nPr[Q(v) \u2208 S] 6 e Pr[Q(v\u2032) \u2208 S] + \u03b4\nJust the same with basic results in DP (Dwork & Roth, 2014), there are corresponding basic results for LDP: Lemma 1 (Gaussian Mechanism). If V = {v \u2208 Rd| \u2016v\u20162 6 1}, then Q(v) = v + e is ( , \u03b4)-LDP, where e \u2208 Rd, and e \u223c N (0, \u03c32Id), \u03c3 = 2 \u221a 2 ln(1.25/\u03b4)/ . Lemma 2 (Composition Theorem1). Let Qi : V \u2192 Zi be an ( i, \u03b4i)-LDP mechanism for i \u2208 [k]. Then if Q[k] : V \u2192\u220fk i=1Zi is defined to be Q[k](v) = (Q1(v), . . . ,Qk(v)),\nthen Q[k] is ( \u2211k i=1 i, \u2211k i=1 \u03b4i)-LDP.\nThe following simple mechanism add Gaussian noise to preserve LDP of a vector, which serves as a basic tool in LDP learning and estimation.\nAlgorithm 1 Basic Private Vector mechanism Input: A vector x \u2208 Rd, privacy parameter , \u03b4 for LDP Output: Private vector z\n1: Setting \u03c3 = \u221a 2 ln(1.25/\u03b4) 2: if \u2016x\u20162 > 1 then 3: x = x/ \u2016x\u20162 4: end if 5: z \u2190 x+ e, where e \u223c N (0, \u03c32Id)\nTheorem 1. Algorithm 1 preserves ( , \u03b4)-LDP."}, {"heading": "3. High Dimensional and Non-parametric Learning via Random Projections", "text": "In this section we consider three learning problems under non-interactive LDP: Mean Estimation and Linear Regression in High-dimensions, as well as Kernel Ridge Regression. Using random projection techniques, we are able to get logarithmic dependence on d in high-dimensional settings, and also to get good guarantees for Kernel version. The first problem is considered in statistical settings, as we need to assume a sparse mean vector. The latter two problems are considered as ERM problems, which can easily be translated to population risk using uniform convergence."}, {"heading": "3.1. High-dimensional Mean Estimation", "text": "In this section, we propose a non-interactive LDP mechanism for high-dimensional sparse mean estimation problem. By assuming `2 bounded data points, and `1 bounded\n1Note one can also use the advanced composition mechanism (Kairouz et al., 2015a) with a refined analysis, but the main dependence over n and d will remain nearly the same.\npopulation mean, we can get error rates with logarithmic dependence on d. Our results are in sharp contrast with the lower bound for `2-bounded general mean estimation under standard DP (Bassily et al., 2014), as well as the lower bound for `\u221e-bounded 1-sparse mean estimation under local DP (Duchi et al., 2016). It can be easily seen that our method extends to mean estimation problem for arbitrary low-complexity constraint set in high dimensions. We state our results in `1 setting to keep the arguments clear. Our problem adopts a statistical estimation setting as follows:\n`2-bounded sparse mean estimation Suppose there is an unknown distribution D supported on B(0, 1), with \u2016ED(x)\u20161 \u2264 \u039b. The `2-bounded sparse mean estimation problem requires us to produce an estimator \u03b8\u0302 that makes \u2016\u03b8 \u2212 ED(x)\u20162 small with high probability.\nAlgorithm 2 LDP `1 Constrained Mean Estimation Input: x1,x2, \u00b7 \u00b7 \u00b7 ,xn \u223c i.i.d.D Output: Estimator z\nSet p = d\u039b \u221a ne, and m = d18 log 1\u03b4 e Sample G \u223c 1\u221apN (0, 1) p\u00d7d. for User i do Collect yi = Gxi + ri, with ri \u223c i.i.d.N (0, 2 log(1.25/\u03b4) 2 Ip) end for for j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 ,m} do Sj = { 1 + (j\u22121)nm , 2 + (j\u22121)n m , \u00b7 \u00b7 \u00b7 , jn m } .\nLet \u00b5j = 1|Sj | \u2211 i\u2208Sj yi.\nend for LetM = {\u00b51,\u00b52, \u00b7 \u00b7 \u00b7 ,\u00b5m}. for j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 ,m} do\nLet rj = min { r : |B`1(\u00b5j , r) \u2229M| \u2265 m2 } .\nend for Let j\u2217 = arg minj rj , and u = \u00b5j\u2217 Solve the following convex program:\narg min z \u2016z\u20161\ns.t.\u2016Gz \u2212 u\u20161 \u2264 100p log(nd/\u03b4)\n\u221a m\nn\n(1)\nIn Algorithm 2 we describe our data collection procedure and estimation algorithm. We are primarily using two techniques: random projection and recovery from lowcomplexity structures; median-of-mean estimator to boost failure probability. The privacy argument is directly implication of Theorem 1.\nIntuitively, adding noise to each entry of mean vector will result in error rate\u2019s linear dependence on d. Thus we adopt the random projection technique to send a compressed version of data vector through the noisy chan-\nnel. This locally private estimation procedure can be viewed as a variant of noisy compressed sensing, where `2 recovery rate is fundamentally controlled by the Gaussian Mean Width of constraint set (Vershynin, 2015). Though the distribution has bounded support, the concentration for mean estimation is dimension-dependent, while dimension-independent Markov Inequalities hold. To tackle this problem, we employ Median-of-Mean estimator to get exponential tails (Hsu & Sabato, 2016).\nWe first give the following bound on the error in projected space.\nLemma 3. Let x1,x2, \u00b7 \u00b7 \u00b7 ,xn \u223c i.i.d.D with \u00b5 = ED[x] and supp(D) \u2286 B(0, 1). Let G and {yi}ni=1 defined in the above procedure. For each of group Sj fixed, we have the following with probability 2/3:\u2225\u2225\u2225 1|Sj | \u2211\nyi\u2208Sj\nyi \u2212G\u00b5 \u2225\u2225\u2225 1 \u2264 O ( p log(nd) \u221a |Sj | ) (2)\nThe aggregation step in Algorithm 2 is a high-dimensional generalization of Median-of-Mean estimator used in heavy-tailed statistics. The tail properties are guaranteed in the following lemma:\nLemma 4 (Proposition 9 in (Hsu & Sabato, 2016)). Suppose in metric space X , a set of points M = [\u03b81,\u03b82, \u00b7 \u00b7 \u00b7 ,\u03b8m] \u223c i.i.d.D, with Pr[dX (\u03b8i,\u03b8) \u2265 ] \u2264 23 . Let \u03b8\u0302 be generated from the following procedure: ri = min { r : |BX (\u03b8i, r) \u2229M| \u2265 m2 } ,and \u03b8\u0302 = arg min\u03b8i ri. Then we have:\nPr[dX (\u03b8\u0302,\u03b8) \u2265 3 ] \u2264 e\u2212 m 18\nSince the original data are i.i.d. samples from underlying distribution, small group with fixed indices should also be i.i, d.. Therefore \u00b51,\u00b52, \u00b7 \u00b7 \u00b7 ,\u00b5k are i.i.d.. Combining Lemma 3 and Lemma 4 we get the following result:\nCorollary 1. The vector u constructed in Algorithm 2 satisfies the following with probability 1\u2212 \u03b4:\n\u2016u\u2212G\u00b5\u20161 \u2264 O ( p log(nd/\u03b4) \u221a m\nn\n) (3)\nThen we turn to the recovery of original mean estimator. The primary tool we are using are General M\u2217 bound in (Vershynin, 2015).\nLemma 5 (Theorem 6.2 in (Vershynin, 2015), High Probability Version). For unknown vector x \u2208 K \u2286 Rd, let G \u223c 1\u221apN (0, 1)\np\u00d7d. Noisy vector \u03bd \u2208 Rp with \u2016\u03bd\u20161 \u2264 \u03c3. Let y = Gx + \u03bd. By solving the following optimization problem:\narg min x\u2032 \u2016x\u2032\u2016K s.t. \u2016Gx\u2032 \u2212 y\u20161 \u2264 \u03c3 (4)\nwhere \u2016\u00b7\u2016K denotes the Minkowski functional of K. Then we can get the following with probability 1\u2212 \u03b4\n\u2016x\u2212 x\u2032\u20162 \u2264 O ( w(K) + \u03c3 + log 1\u03b4\u221a\np ) where w(K) denotes the Gaussian width of K.\nBy putting these results together we get the bound on estimation loss:\nTheorem 2. Algorithm 2 outputs z satisfying the following with probability 1\u2212 \u03b4:\n\u2016z \u2212 \u00b5\u20162 \u2264 O ( log nd\n\u03b4\n\u221a log 1\n\u03b4\n( \u039b2\n2n\n) 1 4 )"}, {"heading": "3.2. Sparse Linear Regression", "text": "In this section, we consider empirical loss of sparse linear regression, i.e. L(w;D) = 12n \u2211n i=1(x T i w \u2212 yi)2, where D = {(xi, yi)|i \u2208 [n]}, \u2016xi\u20162 6 1, yi \u2208 [\u22121, 1]. 2.\nDefine w\u2217 = argminw\u2208C L(w;D), where C = {w| \u2016w\u20161 6 1}. We want to obtain a vector wpriv \u2208 C within non-interactive LDP model, such that the empirical excess risk L(wpriv;D) \u2212 L(w\u2217;D) has polynomial dependences on log d and 1n .\nAs in the case of high-dimensional mean estimation, directly manipulating in the original high dimensional feature space will introduce large noise, hence we use a subGaussian random matrix \u03a6 \u2208 Rm\u00d7d to project original data (i.e. vectors in Rd) into the low dimensional space (i.e. Rm) first, then perturb each data in low dimensional space (i.e. Basic Private Vector mechanism given in Algorithm 1) which protects local privacy, and send it to the server.\nHaving obtained private synopsis, the server then reconstruct an unbiased estimator for objective function according to these private synopsis. We subtract a quadratic term to ensure unbiasedness and project to PSD matrices to preserve convexity. To show good approximation guarantee, we make use of RIP bounds for random projection. As the loss function is determined by inner products between w and data, it could be uniformly preserved in projected space, which guarantees the accuracy of solution estimated with local privacy. Apparently, our methods also imply bounds with general low-complexity constraint set that preserves RIP.\nOur private learning mechanism is given in Algorithm 3 and any random projection matrix can be used here. The privacy argument directly follows from Private Vector Mechanism and composition.\n2Our methods suits to any radius of x and y.\nAlgorithm 3 LDP `1 Constrained Linear Regression Input: Personal data (x, y), parameter , \u03b4, projection ma-\ntrix \u03a6 \u2208 Rd\u00d7m Output: Learned classifier wpriv \u2208 Rd\n1: for Each user i = 1, . . . , n do 2: zi \u2190 Basic Private Vector (\u03a6Txi, /2, \u03b4/2) 3: vi \u2190 Basic Private Vector (yi, /2, \u03b4/2) 4: end for 5: Setting Z = [z1, \u00b7 \u00b7 \u00b7 , zn]T , \u03c3 = 2 \u221a 2 ln(2.5/\u03b4)\n, Q = ProjS+(Z\nTZ \u2212 n\u03c32Im),v = [v1, \u00b7 \u00b7 \u00b7 , vn]T 6: wpriv \u2190 argminw\u2208C L\u0302(w;Z,v), where L\u0302(w;Z,v) := 12n (\u03a6 Tw)TQ(\u03a6Tw)\u2212 1nv TZ\u03a6Tw\nIn fact, as original data is in L2 ball, and random projection preserves norms with high probabilty, hence steps 2-4 in Algorithm 1 will be executed with very low probability.\nDenote the true objective function in low dimensional space L\u0304(w; X\u0304,y) := 12n \u2225\u2225X\u0304\u03a6Tw\u2225\u22252 \u2212 1nyT X\u0304\u03a6Tw, where X\u0304 = [x1, \u00b7 \u00b7 \u00b7 ,xn]T\u03a6,w \u2208 C. Let w\u0302\u2217 := argminw\u2208C L\u0304(w; X\u0304,y). The following lemma gives the accuracy of private solution wpriv when reduced into low dimensional space:\nLemma 6. Under the assumptions made in this section, given projection matrix \u03a6, with high probability over the randomness of private mechanism, we have\nL\u0304(wpriv; X\u0304,y)\u2212 L\u0304(w\u0302\u2217; X\u0304,y) 6 O\u0303 (\u221a m\nn 2\n) (5)\nNow, combined with RIP bound for random projection, we can move on to prove the empirical excess risk of sparse linear regression: Theorem 3. Under the assumption in this section, setm = \u0398 (\u221a n 2 log d ) , then with high probability , there is\nL(wpriv)\u2212 L(w\u2217) = O\u0303\n(( log d\nn 2\n)1/4)\nNote (Talwar et al., 2015) assume data is in L\u221e ball, while both (Kasiviswanathan & Jin, 2016) and ours assume data is in L2 ball. However, in LDP model, (Duchi et al., 2016) show it was impossible to obtain polynomial dependences over log d for `0 mean estimation problem if data is in L\u221e ball."}, {"heading": "3.3. Infinite Dimension: Kernel Ridge Regression", "text": "Previous method mainly applies to data with finite dimensional features. However, it is common to use kernel trick in practice. This brings about new difficulties for LDP learning, as we could not add noise in the Hilbert space.\nIn this subsection, we take kernel ridge regression as an example to show how to use Random Fourier Features (RFF) (Rahimi et al., 2007) to deal with such cases caused by shift-invariant kernels (i.e. k(x,y) = k(x \u2212 y)). Note our technique also suits to similar problems.\nFix a shift-invariant kernel k(\u00b7, \u00b7), denote the Hilbert space implicitly defined asH , and the corresponding feature map as \u03a6 : Rd \u2192 H . Let the Hilbert space corresponding to the random Fourier feature map be H\u0302 \u2282 Rdp , and its feature map \u03a6\u0302 : Rd \u2192 H\u0302 , where dp is the RFF projection dimension. Given a subset X \u2282 Rd and data D = {(xi, yi)|xi \u2208 X , i \u2208 [n]}, for any f \u2208 H, g \u2208 H\u0302 , define loss functions in H and H\u0302 as follows:\nLH(f) := C\n2n \u2211 i \u2225\u2225fT\u03a6(xi)\u2212 yi\u2225\u222522 + 12 \u2016f\u20162H (6) LH\u0302(g) := C\n2n \u2211 i \u2225\u2225\u2225gT \u03a6\u0302(xi)\u2212 yi\u2225\u2225\u22252 2 + 1 2 \u2016g\u20162H\u0302 (7)\nwhere C is the regularization parameter. Denote f\u2217 = argminf\u2208H LH(f), g\n\u2217 = argming\u2208H\u0302 LH\u0302(g), G as the Lipschitz constant of square loss, which depends on the bounded norm of features. Kernel ridge regression try to optimize formula (6), while after using RFF, we try to solve formula (7) in non-interactive LDP model, which can be easily tackled with similar mechanisms like sparse linear regression above. Borrow the key result in (Rubinstein et al., 2012) (restated in lemma 7 below), which used RFF to design private mechanims for SVM in DP model, it becomes easy to prove guarantees for kernel ridge regression in our setting (see Corollary 2).\nLemma 7 ((Rubinstein et al., 2012)). Suppose dual variables with respect to f\u2217, g\u2217 are L1 norm bounded by some r > 0, and supx1,x2\u2208X |\u03a6(x1)\nT\u03a6(x2) \u2212 (\u03a6\u0302(x1))\nT \u03a6\u0302(x2)| 6 \u03b3, then there is supx\u2208X |\u03a6(x)T f\u2217 \u2212 (\u03a6\u0302(x))T g\u2217| 6 r\u03b3 + 2 \u221a (CG+ r/2)r\u03b3.\nCorollary 2. Algorithm 4 satisfies ( , \u03b4)-LDP, and by setting dp = O\u0303 (\u221a dn 2 ) , with high probability, there is\nLH\u0302(w\u0302 priv)\u2212LH(f\u2217) 6 O\u0303\n(( d\nn 2\n)1/4)\nsup x\u2208X |\u03a6(x)T f\u2217\u2212(\u03a6\u0302(x))T w\u0302priv| 6 O\u0303\n(( d\nn 2\n)1/8)"}, {"heading": "4. Learning Smooth Generalized Linear Model", "text": "In this section, we consider learning smooth generalized linear model in non-interactive LDP setting. Noninteractive LDP learning for this problem is essentially difficult, as it is even hard to obtain an unbiased estimator of\nAlgorithm 4 LDP kernel mechanism Input: Personal data (xi, yi), i \u2208 [n], random feature\u2019s\ndimension dp, shift-invariant kernel k(x1,x2) = k(x1 \u2212 x2) with Fourier transform f(s) = 1 2\u03c0 \u222b e\u2212js\nTxk(x)dx, privacy parameter , \u03b4 Output: Private output w\u0302priv \u2208 Rdp\n1: Draw i.i.d. samples s1, s2, . . . , sdp \u2208 Rd from f(s) and b1, b2, . . . , bdp \u2208 R from the uniform distribution on [0, 2\u03c0] 2: for i = 1, . . . , n do 3: Construct low dimensional random feature \u03a6\u0302(xi) =\u221a\n1 dp [ cos(sT1 xi + b1), . . . , cos(s T dp xi + bdp) ]\u2032 \u2208\nC\u0302 := [ \u2212 \u221a 1 dp , \u221a 1 dp ]dp \u2282 Rdp\n4: zi \u2190 Basic Private Vector (\u03a6\u0302(xi), /2, \u03b4/2) 5: vi \u2190 Basic Private Vector (yi, /2, \u03b4/2) 6: end for 7: Setting Z = [z1, \u00b7 \u00b7 \u00b7 , zn]T , \u03c3 = 2 \u221a 2 ln(2.5/\u03b4)\n, Q = ProjS+(Z TZ \u2212 n\u03c32Idp),v = [v1, \u00b7 \u00b7 \u00b7 , vn]T\n8: w\u0302priv \u2190 argminw\u0302 L\u0302(w\u0302;Z,v), where L\u0302(w\u0302;Z,v) := 12nw\u0302 TQw\u0302 \u2212 1nv TZw\u0302\ngradient. We resolve this problem using Chebyshev polynomial expansion, which requires additional smoothness assumptions. Fortunately these assumptions are naturally satisfied by a broad range of learning tasks.\nWe will first define the Smooth GLM loss family with appropriate assumptions. Our definition could be shown with connection to exponential family GLM, which is commonly used in machine learning. We also illustrate our algorithm and guarantees with logistic regression.\nDefinition 2. (Absolutely Smooth Functions) We say that an univariate function h(x) is absolutely smooth, if for any r > 0, f(x) := h(rx) satisfies the following properties: there exist functions \u00b51(k; r), \u00b52(k; r), which are polynomial on k and \u00b52(k; r) = O(kr), such that for any k \u2208 N+, there is:\n(1) f(x), f \u2032(x), . . . , f (k\u22121)(x) are absolutely continuous on [\u22121, 1];\n(2) \u2225\u2225f (k)(x)\u2225\u2225\nT 6 \u00b51(k; r) \u00b7 \u00b52(k; r)k.\nDefinition 3. (Smooth Generalized Linear Loss, SGLL) A loss function `(w;x, y), is called smooth generalized linear loss, if for any given data (x, y), `(w;x, y) is convex and \u03b2-smooth with respect tow, and there exist absolutely smooth functions h1(x), h2(x), such that `(w;x, y) = \u2212yh1(xTw) + h2(xTw).\nIt will be convenient to consider population risk directly. Now, we adopt standard setting of learning problems,\nwhere each data point (x, y) is drawn from some underlying unknown distribution D and \u2016x\u20162 6 1. Given a SGLL `(w;x, y), the population loss is defined as L(w) := E(x,y)\u223cD`(w;x, y). For simplicity, instead of assuming w belongs to B2(r), we use the following equivalent notation: `(w;x, y) = \u2212yh1(rxTw) + h2(rx\nTw), and the constraint set for w is C = B2(1). Denote G(w;x, y) = \u2207`(w;x, y) = rm(w;x, y)x, where m(w;x, y) = h\u20322(rx\nTw) \u2212 yh\u20321(rxTw). Suppose E(x,y)\u223cD[\u2016G(w;x, y)\u2212 g(w)\u2016 2 2] 6 \u03c3 2 0 , where g(w) = \u2207L(w). This is a common assumption in stochastic optimization literature, such as (Bubeck et al., 2015).\nGiven any \u03b1 > 0, we hope to design a noninteractive local DP mechanism with low sample complexity, such that the final output point wpriv satisfies L(wpriv)\u2212 L(w\u2217) 6 \u03b1.\nFor GLM loss functions, it is easy to see that the stochastic gradient evaluated on w with data point xi is at the same direction with xi. So adding isotropic noise to xi provides \u201dunbiased\u201d information about direction of stochastic gradient. However, the magnitude is a nonlinear function of wTxi, making it hard for SGD even to converge to population minimizer. This is why we seek to find polynomial approximation of the magnitude of gradients.\nTo estimate the magnitude of gradients, we use Chebyshev polynomials to approximate nonlinear univariate function fi(x) = h \u2032 i(rx), where x \u2208 [\u22121, 1]. For brevity of notations, we just use f(x) to represent either f1(x) or f2(x). Denote the Chebyshev approximation with degree p as f\u0302p(x) = 12 + \u2211p k=1 akTk(x), where Tk(x) is the k-\nth Chebyshev polynomial, and ak = 2\u03c0 \u222b 1 \u22121 f(x)Tk(x)\u221a 1\u2212x2 dx is the corresponding coefficient. According to existing results about Chebyshev approximations and some calculations, we have the following lemma:\nLemma 8. Given any \u03b1 > 0, by setting k = c ln 1\u03b1 , p = dk+ e\u00b52(k; r)e, where c is a constant, we have\u2225\u2225\u2225f\u0302p(x)\u2212 f(x)\u2225\u2225\u2225\n\u221e 6 \u03b1\nThe Chebyshev approximations with degree p for fi(x) (i = 1, 2) are denoted as f\u0302ip(x) = 12 + \u2211p k=1 aikTk(x) =\u2211p\nk=0 cikx k, where cik is the coefficient of term xk. Now\nwe approximate m(w;x, y) and G(w;x, y) as follows:\nm\u0302(w;x, y) :=\u2212 yf\u03021p(rxTw) + f\u03022p(rxTw)\n= p\u2211 k=0 (c2k \u2212 c1ky)(rxTw)k\nG\u0302(w;x, y) :=rm\u0302(w;x, y)x\nWith these approximations, we state our mechanism in Algorithm 5, where Basic Private Vector mechanism is given\nin Algorithm 1. Note an important trick in Step 6-8 of Algorithm 5, is that: we run basic private mechanism p times, to obtain fresh private copies of the same vector x, which are then used to calculate an unbiased estimation of G\u0302(w;x, y) with variance as low as possible (i.e. line 8 in Algorithm 6).The LDP property of Algorithm 5 is given as follows: The privacy proof directly follows from Basic\nAlgorithm 5 LDP SGLD Mechanism - Collection Input: Personal data (x, y), expansion order p, privacy pa-\nrameter , \u03b4 Output: Private synopsis b = {zyi, zj |i \u2208 {0} \u222a [p], j \u2208\n[p(p+ 1)/2]} sent to the server 1: Setting y = 4(p+1) , \u03b4y = \u03b4 4(p+1) , 1 = p(p+1) , \u03b41 =\n\u03b4 p(p+1)\n2: z0 \u2190 Basic Private Vector(x, /4, \u03b4/4) 3: for i = 0, 1, . . . , p do 4: zyj \u2190 Basic Private Vector(y, y, \u03b4y) 5: end for 6: for j = 1, . . . , p(p+1)2 do 7: zj \u2190 Basic Private Vector(x, 1, \u03b41) 8: end for\nVector Mechanism and Composition Theorem.\nTheorem 4. LDP SGLD Mechanism 5 preserves ( , \u03b4)LDP.\nHaving obtained the private synopsis sent by all uers, now the server can construct a stochastic inexact gradient oracle (defined in Defintion 4) for any point w \u2208 C, as stated in Algorithm 6.\nDefinition 4. (Dvurechensky & Gasnikov, 2016) For an objective function f(w), a (\u03b3, \u03b2, \u03c3) stochastic oracle returns a turple (F\u03b3,\u03b2,\u03c3(w; \u03be), G\u03b3,\u03b2,\u03c3(w; \u03be)), such that:\nE\u03be[F\u03b3,\u03b2,\u03c3(w; \u03be)] = f\u03b3,\u03b2,\u03c3(w) E\u03be[G\u03b3,\u03b2,\u03c3(w; \u03be)] = g\u03b3,\u03b2,\u03c3(w)\nE\u03be[\u2016G\u03b3,\u03b2,\u03c3(w; \u03be)\u2212 g\u03b3,\u03b2,\u03c3(w)\u20162] 6 \u03c32\n0 6 h(v,w) 6 \u03b2\n2 \u2016v \u2212w\u20162 + \u03b3,\u2200v,w \u2208 C\nwhere h(v,w) = f(v)\u2212f\u03b3,\u03b2,\u03c3(w)\u2212\u3008g\u03b3,\u03b2,\u03c3(w),v \u2212w\u3009.\nFor any (x, y) in the domain, as loss function `(w;x, y) is convex and \u03b2-smooth with respect to w, we can prove the following lemma:\nLemma 9. For any \u03b3 > 0, setting k = c ln 4r\u03b3 , p = dk + 2\u00b52(k; r)e, then Algorithm 6 outputs a (\u03b3, \u03b2, \u03c3) stochastic oracle defined in Definition 4, where \u03c3 = O\u0303 ( \u03c30 + \u03b3 + p2p+1(4r)p+1 p+2 ) .\nAlgorithm 6 LDP SGLD Mechanism - Learning Input: Private synopsis b = {zy, zj |j \u2208 {0} \u222a [p(p +\n1)/2]} of each user, public coefficients {c1k, c2k|k \u2208 {0} \u222a [p]}, initial point w1 Output: Learned classifier wpriv 1: for s = 1, . . . , n do 2: \\\\ Construct stochastic inexact gradient 3: \\\\ Denote the private synopsis of user s as b above\nfor abbreviation 4: Set t0 = 1 5: for j = 1, . . . , p do 6: tj = \u220fj(j+1)/2 i=j(j\u22121)/2+1(w T s zi) 7: end for\n8: G\u0303(ws; b)\u2190 ( p\u2211 k=0 (c2k \u2212 c1kzyj)tkrk+1 ) z0\n9: \\\\ One update via SIGM 10: Run one iteration of SIGM algorithm with G\u0303(ws, b) and obtain ws+1 11: end for 12: Set wpriv := wn+1\nBased on above (\u03b3, \u03b2, \u03c3) stochastic oracle, and the algorithm proposed in SIGM paper (Dvurechensky & Gasnikov, 2016) (omitted here, due to the limitation of space), our complete learning algorithm is given in Algorithm 6. Before proving our sample complexity, we state the basic convergence result of SIGM algorithm:\nLemma 10 ((Dvurechensky & Gasnikov, 2016)). Assume a function f(w) (suppose constrain set is W) is endowed with a (\u03b3, \u03b2, \u03c3) stochastic oracle, then the sequence wk (corresponds to yk in the original paper) generated by the SIGM algorithm satisfies:\nE[f(wk)]\u2212 f(w\u2217) 6 O ( \u03c3\u221a k + \u03b3 ) where expectation is over the randomness of the stochastic oracle and w\u2217 = argminw\u2208W f(w).\nThe accuracy results directly follows from the quality of inexact stochastic gradient oracle we constructed, and the convergence result of SIGM.\nTheorem 5. Consider smooth generalized linear loss. For any setting \u03b1 > 0, by setting \u03b3 = \u03b12 , k = c ln 4r \u03b3 , p = dk + 2\u00b52(k; r)e in Algorithm 5, 6, if\nn > O ( ( 8r\n\u03b1 )4r ln ln(8r/\u03b1)\n( 4r )2cr ln(8r/\u03b1)+2( 1\n\u03b12 2\n)) ,\nwe can achieve loss guarantee L(wpriv)\u2212 L(w\u2217) 6 \u03b1\nAs we can see, learning in non-interactive LDP model is more difficult than interactive form, especially when loss is\nhighly nonlinear, we even can not obtain an unbiased estimation either for objective function or gradients. However, our method shows it possible to learn smooth GLM with quasi-polynomial sample complexity."}, {"heading": "4.1. Example: Learning Logistic Regression", "text": "Either from the view of exponential family generalized linear model or the concrete loss function, it is not difficult to see logistic loss belongs to SGLL. For example, in logistic regression, `(w;x, y) = log(1 + e\u2212yw Tx) =\n\u2212 ( y 2w Tx ) + ( 1 2w Tx+ ln(1 + e\u2212w Tx) ) . So we let h1(x) = x 2 , h2(x) = x 2 +ln(1+e\n\u2212x). As we know logistic loss is convex and \u03b2-smooth for some parameter \u03b2, and the absolutely smooth property of linear function is obvious, hence once we prove f(x) = ln(1 + e\u2212x) is absolutely smooth, then logistic loss satisfies the definition of SGLL.\nProposition 1. f(x) = ln(1 + e\u2212x) is absolutely smooth with \u00b51(k; r) = r \u221a 4k\u03c03, \u00b52(k; r) = rk e\nHence, we can use private mechanisms (5,6) to learn logistic regression.\nTheorem 6. Consider Logistic regression problem with `(w;x, y) = log(1 + exp(\u2212ywTx)) For any \u03b1 > 0, by setting \u03b3 = \u03b12 , k = c ln 4r \u03b3 , p = dk + 2\u00b52(k; r)e,\nif n > O (\n( 8r\u03b1 ) 4r ln ln(8r/\u03b1)\n( 4r )2cr ln(8r/\u03b1)+2 ( 1 \u03b12 2 )) in\nAlgorithm 5, 6, we can achieve L(wpriv)\u2212 L(w\u2217) 6 \u03b1."}, {"heading": "5. Conclusions", "text": "In this paper, we consider how to design efficient algorithms for common learning and estimation problems under non-interactive LDP model. In particular, for sparse linear regression and mean estimation problem, we propose efficient algorithms and prove the polynomial dependence of excess risk or square error over log d and 1n , which is exactly to be expected in high dimensional case. We also extend our methods to nonparametric case and show good bounds for Kernel Ridge Regression.\nFor more difficult smooth generalized linear loss optimization problems, we use private Chebyshev approximations to estimate gradients of the objective loss, combined with existing inexact gradient descent methods to obtain final outputs. The sample complexity of our mechanism is quasi-polynomial with respect to 1\u03b1 , where \u03b1 is the desired population excess risk.\nAn interesting open problem is whether our theoretical guarantees are optimal. If not, how to improve them while preserving the efficiency in non-interactive LDP model. We think these problems are critical to understand LDP in the future."}, {"heading": "Acknowledgments", "text": "This work was partially supported by National Basic Research Program of China (973 Program) (grant no. 2015CB352502), NSFC (61573026). We would like to thank the anonymous reviewers for their valuable comments on our paper."}], "year": 2017, "references": [{"title": "Local, private, efficient protocols for succinct histograms", "authors": ["Bassily", "Raef", "Smith", "Adam"], "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "year": 2015}, {"title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "authors": ["Bassily", "Raef", "Smith", "Adam", "Thakurta", "Abhradeep"], "venue": "In Foundations of Computer Science (FOCS),", "year": 2014}, {"title": "Privacy-preserving logistic regression", "authors": ["K. Chaudhuri", "C. Monteleoni"], "venue": "In Conference on Neural Information Processing Systems, British Columbia,", "year": 2008}, {"title": "Differentially private empirical risk minimization", "authors": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "The Journal of Machine Learning Research,", "year": 2011}, {"title": "Local privacy and minimax bounds: Sharp rates for probability estimation", "authors": ["Duchi", "John", "Wainwright", "Martin J", "Jordan", "Michael I"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2013}, {"title": "Minimax optimal procedures for locally private estimation", "authors": ["Duchi", "John", "Wainwright", "Martin", "Jordan", "Michael"], "venue": "arXiv preprint arXiv:1604.02390,", "year": 2016}, {"title": "Local privacy and statistical minimax rates", "authors": ["Duchi", "John C", "Jordan", "Michael I", "Wainwright", "Martin J"], "venue": "In Foundations of Computer Science (FOCS),", "year": 2013}, {"title": "Stochastic intermediate gradient method for convex problems with stochastic inexact oracle", "authors": ["Dvurechensky", "Pavel", "Gasnikov", "Alexander"], "venue": "Journal of Optimization Theory and Applications,", "year": 2016}, {"title": "Calibrating noise to sensitivity in private data analysis", "authors": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "In Theory of cryptography,", "year": 2006}, {"title": "The optimal mechanism in differential privacy", "authors": ["Geng", "Quan", "Viswanath", "Pramod"], "venue": "In Information Theory (ISIT),", "year": 2014}, {"title": "A multiplicative weights mechanism for privacy-preserving data analysis", "authors": ["M. Hardt", "G.N. Rothblum"], "venue": "In IEEE Symposium on Foundations of Computer Science,", "year": 2010}, {"title": "A simple and practical algorithm for differentially private data release", "authors": ["M. Hardt", "K. Ligett", "F. Mcsherry"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2012}, {"title": "Loss minimization and parameter estimation with heavy tails", "authors": ["Hsu", "Daniel", "Sabato", "Sivan"], "venue": "Journal of Machine Learning Research,", "year": 2016}, {"title": "Extremal mechanisms for local differential privacy", "authors": ["Kairouz", "Peter", "Oh", "Sewoong", "Viswanath", "Pramod"], "venue": "In Advances in neural information processing systems,", "year": 2014}, {"title": "The composition theorem for differential privacy", "authors": ["Kairouz", "Peter", "Oh", "Sewoong", "Viswanath", "Pramod"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "year": 2015}, {"title": "Secure multi-party differential privacy", "authors": ["Kairouz", "Peter", "Oh", "Sewoong", "Viswanath", "Pramod"], "venue": "In Advances in Neural Information Processing Systems, pp. 2008\u20132016,", "year": 2015}, {"title": "Discrete distribution estimation under local privacy", "authors": ["Kairouz", "Peter", "Bonawitz", "Keith", "Ramage", "Daniel"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "year": 2016}, {"title": "What can we learn privately", "authors": ["S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith"], "venue": "In IEEE Symposium on Foundations of Computer Science,", "year": 2008}, {"title": "What can we learn privately", "authors": ["Kasiviswanathan", "Shiva Prasad", "Lee", "Homin K", "Nissim", "Kobbi", "Raskhodnikova", "Sofya", "Smith", "Adam"], "venue": "SIAM Journal on Computing,", "year": 2011}, {"title": "Efficient noise-tolerant learning from statistical queries", "authors": ["Kearns", "Michael"], "venue": "Journal of the ACM (JACM),", "year": 1998}, {"title": "Private convex empirical risk minimization and highdimensional regression", "authors": ["Kifer", "Daniel", "Smith", "Adam", "Thakurta", "Abhradeep"], "venue": "Journal of Machine Learning Research,", "year": 2012}, {"title": "Differentially private m-estimators", "authors": ["J. Lei"], "venue": "In Advances in Neural Information Processing Systems, pp", "year": 2011}, {"title": "Random features for large-scale kernel machines", "authors": ["Rahimi", "Ali", "Recht", "Benjamin"], "venue": "In NIPS,", "year": 2007}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for svm learning", "authors": ["B. Rubinstein", "P.L. Bartlett", "L. Huang", "N. Taft"], "venue": "Journal of Privacy and Confidentiality,", "year": 2012}, {"title": "Privacy-preserving statistical estimation with optimal convergence rates", "authors": ["A. Smith"], "venue": "In ACM Symposium on Theory of Computing,", "year": 2011}, {"title": "Differentially private model selection via stability arguments and the robustness of the lasso", "authors": ["Smith", "Adam", "Thakurta", "Abhradeep"], "venue": "J Mach Learn Res Proc Track,", "year": 2013}, {"title": "Nearly optimal private lasso", "authors": ["Talwar", "Kunal", "Thakurta", "Abhradeep", "Zhang", "Li"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2015}, {"title": "Faster algorithms for privately releasing marginals", "authors": ["J. Thaler", "J. Ullman", "S. Vadhan"], "venue": "In International Colloquium on Automata, Languages, and Programming,", "year": 2012}, {"title": "Estimation in high dimensions: a geometric perspective", "authors": ["Vershynin", "Roman"], "venue": "In Sampling theory, a renaissance,", "year": 2015}, {"title": "Privacy for free: Posterior sampling and stochastic gradient monte carlo", "authors": ["Y. Wang", "S.E. Fienberg", "A.J. Smola"], "venue": "In International Conference on Machine Learning,", "year": 2015}, {"title": "Differentially private data releasing for smooth queries", "authors": ["Z. Wang", "C. Jin", "K. Fan", "J. Zhang", "J. Huang", "Y. Zhong", "L. Wang"], "venue": "Journal of Machine Learning Research,", "year": 2016}, {"title": "Randomized response: A survey technique for eliminating evasive answer bias", "authors": ["Warner", "Stanley L"], "venue": "Journal of the American Statistical Association,", "year": 1965}, {"title": "Efficient private erm for smooth objectives", "authors": ["Zhang", "Jiaqi", "Zheng", "Kai", "Mou", "Wenlong", "Wang", "Liwei"], "venue": "arXiv preprint arXiv:1703.09947,", "year": 2017}, {"title": "Functional mechanism: regression analysis under differential privacy", "authors": ["Zhang", "Jun", "Zhenjie", "Xiao", "Xiaokui", "Yang", "Yin", "Winslett", "Marianne"], "venue": "Proceedings of the VLDB Endowment,", "year": 2012}], "id": "SP:f158a0828c9956f2888f9aaa4f71c94c28c40a82", "authors": [{"name": "Kai Zheng", "affiliations": []}, {"name": "Wenlong Mou", "affiliations": []}, {"name": "Liwei Wang", "affiliations": []}], "abstractText": "Non-interactive Local Differential Privacy (LDP) requires data analysts to collect data from users through noisy channel at once. In this paper, we extend the frontiers of Non-interactive LDP learning and estimation from several aspects. For learning with smooth generalized linear losses, we propose an approximate stochastic gradient oracle estimated from non-interactive LDP channel using Chebyshev expansion, which is combined with inexact gradient methods to obtain an efficient algorithm with quasi-polynomial sample complexity bound. For the high-dimensional world, we discover that under `2-norm assumption on data points, high-dimensional sparse linear regression and mean estimation can be achieved with logarithmic dependence on dimension, using random projection and approximate recovery. We also extend our methods to Kernel Ridge Regression. Our work is the first one that makes learning and estimation possible for a broad range of learning tasks under noninteractive LDP model.", "title": "Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible"}
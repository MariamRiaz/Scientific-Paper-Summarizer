0	10	A taxonomic view of lexical semantics groups word senses/usages into categories of varying granularities.
1	31	WordNet supersense tags denote coarse semantic classes, including person and artifact (for nouns) and motion andweather (for verbs); these categories can be taken as the top level of a taxonomy.
2	30	Nominal supersense tagging (Ciaramita and Johnson, 2003) is the task of identifying lexical chunks in the sentence for common as well as proper nouns, and labeling each with one of the 25 nominal supersense categories.
5	50	Here we consider the problem of nominal supersense tagging for Arabic, a language with ca.
6	18	300 million speakers and moderate linguistic resources, including a WordNet (Elkateb et al., 2006), annotated datasets (Maamouri et al., 2004; Hovy et al., 2006), monolingual corpora, and large amounts of Arabic-English parallel data.
7	17	The supervised learning approach that is used in state-of-the-art English supersense taggers (Cia- ramita and Altun, 2006) is problematic for Arabic, since there are supersense annotations for only a small amount of Arabic text (65,000 words by Schneider et al., 2012, versus the 360,000 words that are annotated for English).
12	31	A gold standard corpus of sentences annotated with nominal supersenses (as in figure 1) facilitates automatic evaluation of supersense taggers.
13	47	For development and evaluation we use 661 the AQMAR Arabic Wikipedia Supersense Corpus1 (Schneider et al., 2012), which augmented a named entity corpus (Mohit et al., 2012) with nominal supersense tags.
15	11	Schneider et al. (2012) found the distributions of supersense categories in these four topical domains to be markedly different; e.g., most instances of communication (which includes kinds of software) occurred in the technology domain, whereas most substances were found in the science domain.
19	8	Arabic WordNet (AWN) (Elkateb et al., 2006) allows us to recover supersense categories for some 10,500 Arabic nominal types, since many of the synsets in AWN are crossreferenced to English WordNet, and can therefore be associated with supersense categories.
20	20	Further, OntoNotes contains named entity annotations for Arabic (Hovy et al., 2006).
33	9	Both language models were trained using the Gigaword v. 4 corpus.
37	12	Using the lexicon built from AWN and OntoNotes (see §2), our heuristic approach works as follows: 1.
55	17	Preprocess the input Arabic sentence a to match the decoder’s model of Arabic.
57	14	Apply the English supersense tagger to the English translation, discarding any verbal supersense tags.
58	9	Project the supersense tags back to the Arabic sentence, yielding Â: Each Arabic token a ∈ a that is (a) a noun, or (b) an adjective following 0 or more adjectives following a noun is mapped to the first English supersense mention in Ê containing some word aligned to a.
72	9	We further tested simple hybrids combining the lexicon-based and MT-based approaches.
82	37	(3/6) cdec: The .......corn is composed of negative ................shipments ( .................electronics ) cloud hovering over the nucleus of a very small positive ...............shipment in the center .
88	25	For a targeted measure of lexical translation quality of noun expressions, we elicited acceptability judgments from a bilingual annotator for translated and supersense-projected phrases.
91	11	Upwards of 90% of the lexical translations were accepted; as with the automatic MT measures, QCRI slightly outperforms cdec (especially in the technology and sports domains10).
93	10	Others are more nuanced, e.g., shipments for charges and electronics for electrons.
94	13	Transliteration errors included IMAX in place of EMACS and genoa lynx for GNU Linux.
95	42	However, lexical projection precision seems to be a relatively small part of the problem, especially considering that not all translation errors lead to supersense tagging errors.
97	41	Most noun tokens ought to be tagged; 77% is the noun coverage rate in the gold standard.
98	67	In table 1, and translation edit rate (TER) (Snover et al., 2006) 9The judge did not see alignments or supersense categories.
99	22	If QCRI produces better translations, why is cdec more useful for supersense tagging?
100	107	As noted in §3.3, cdec gives word-level alignments (even when the decoder uses large phrasal units for translation), allowing for more precise projections.11 We suspect this is especially important in light of findings that larger phrase sizes are indicative of better translations (Gamon et al., 2005), so these are exactly the cases where we expect the translations to be valuable.
101	52	To our knowledge, this is the first study of automatic Arabic supersense tagging.
102	72	We have shown empirically that an MT-in-the-middle technique is most effective of several approaches that do not require labeled training data.
103	92	Analysis sheds light on several challenges that would need to be overcome for better Arabic lexical semantic tagging.

0,1,label2,summary_sentences
Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location.,1. Introduction,[0],[0]
"It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing.",1. Introduction,[0],[0]
"In a distributed setting, multiple entities/nodes collaboratively work toward a common optimization objective through an
1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Xueru Zhang <xueru@umich.edu>, Mohammad Mahdi Khalili <khalili@umich.edu>, Mingyan Liu <mingyan@umich.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
interactive process of local computation and message passing, which ideally should result in all nodes converging to a global optimum.",1. Introduction,[0],[0]
"Existing approaches to decentralizing an optimization problem primarily consist of subgradientbased algorithms (Nedic et al., 2008; Nedic & Ozdaglar, 2009; Lobel & Ozdaglar, 2011), ADMM-based algorithms (Wei & Ozdaglar, 2012; Ling & Ribeiro, 2014; Shi et al., 2014; Zhang & Kwok, 2014; Ling et al., 2016), and composite of subgradient and ADMM (Bianchi et al., 2014).",1. Introduction,[0],[0]
"It has been shown that ADMM-based algorithms can converge at the rate of O( 1k ) while subgradient-based algorithms typically converge at the rate of O( 1√
k ), where k is the number
of iterations (Wei & Ozdaglar, 2012).",1. Introduction,[0],[0]
"In this study, we will solely focus on ADMM-based algorithms.
",1. Introduction,[0],[0]
"The information exchanged over the iterative process gives rise to privacy concerns if the local training data is proprietary to each node, especially when it contains sensitive information such as medical or financial records, web search history, and so on.",1. Introduction,[0],[0]
"It is therefore highly desirable to ensure such iterative processes are privacy-preserving.
",1. Introduction,[0],[0]
"A widely used notion of privacy is the ε-differential privacy; it is generally achieved by perturbing the algorithm such that the probability distribution of its output is relatively insensitive to any change to a single record in the input (Dwork, 2006).",1. Introduction,[0],[0]
"Several differentially private distributed algorithms have been proposed, including (Hale & Egerstedty, 2015; Huang et al., 2015; Han et al., 2017; Zhang & Zhu, 2017; Bellet et al., 2017).",1. Introduction,[0],[0]
"While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration.",1. Introduction,[0],[0]
"To the best of our knowledge, only (Zhang & Zhu, 2017) applies differential privacy to ADMM, where the noise is either added to the dual variable (dual variable perturbation) or the primal variable (primal variable perturbation) in ADMM updates.",1. Introduction,[0],[0]
"However, (Zhang & Zhu, 2017) could only bound the privacy loss of a single iteration.",1. Introduction,[0],[0]
"Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process.",1. Introduction,[0],[0]
It turns out that the tradeoff between the utility of the algorithm and its privacy preservation over the entire computational process becomes hard using the existing method.,1. Introduction,[0],[0]
"ar X iv :1 80 6.
",1. Introduction,[0],[0]
"02 24
6v 1
[ cs
.L",1. Introduction,[0],[0]
"G
] 6
J un
2 01
8
In this study we propose a perturbation method that could simultaneously improve the accuracy and privacy for ADMM.",1. Introduction,[0],[0]
We start with a modified version of ADMM whereby each node independently decides its own penalty parameter in each iteration; it may also differ from the dual updating step size.,1. Introduction,[0],[0]
For this modified ADMM we establish conditions for convergence and quantify the lower bound of the convergence rate.,1. Introduction,[0],[0]
We then present a penalty perturbation method to provide differential privacy.,1. Introduction,[0],[0]
"Our numerical results show that under this method, by increasing the penalty parameter over iterations, we can achieve stronger privacy guarantee as well as better algorithmic performance, i.e., more stable convergence and higher accuracy.
",1. Introduction,[0],[0]
The remainder of the paper is organized as follows.,1. Introduction,[0],[0]
We present problem formulation and definition of differential privacy and ADMM in Section 2 and a modified ADMM algorithm along with its convergence analysis in Section 3.,1. Introduction,[0],[0]
A private version of this ADMM algorithm is then introduced in Section 4 and numerical results in Section 5.,1. Introduction,[0],[0]
Discussions are given in Section 6 and Section 7 concludes the paper.,1. Introduction,[0],[0]
"Consider a connected network1 given by an undirected graph G(N ,E ), which consists of a set of nodes N = {1, 2, · · · , N} and a set of edges E = {1, 2, · · · , E}.",2.1. Problem Formulation,[0],[0]
Two nodes can exchange information if and only if they are connected by an edge.,2.1. Problem Formulation,[0],[0]
"Let Vi denote node i’s set of neighbors, excluding itself.",2.1. Problem Formulation,[0],[0]
"A node i contains a dataset Di = {(xni , yni )",2.1. Problem Formulation,[0],[0]
"|n = 1, 2, · · · , Bi}, where xni ∈ Rd is the feature vector representing the n-th sample belonging to i, yni ∈ {−1, 1} the corresponding label, and Bi the size of Di.
Consider the regularized empirical risk minimization (ERM) problems for binary classification defined as follows:
",2.1. Problem Formulation,[0],[0]
"min fc OERM (fc, Dall) =",2.1. Problem Formulation,[0],[0]
N∑ i=1,2.1. Problem Formulation,[0],[0]
C Bi Bi∑ n=1 L (yni,2.1. Problem Formulation,[0],[0]
f T c,2.1. Problem Formulation,[0],[0]
x n,2.1. Problem Formulation,[0],[0]
"i )+ρR(fc) (1) where C ≤ Bi and ρ > 0 are constant parameters of the algorithm, the loss function L (·) measures the accuracy of classifier, and the regularizer R(·) helps to prevent overfitting.",2.1. Problem Formulation,[0],[0]
The goal is to train a (centralized) classifier fc ∈ Rd over the union of all local datasets Dall = ∪i∈N,2.1. Problem Formulation,[0],[0]
"Di in a distributed manner using ADMM, while providing privacy guarantee for each data sample 2.
",2.1. Problem Formulation,[0],[0]
"1A connected network is one in which every node is reachable (via a path) from every other node.
2The proposed penalty perturbation method is not limited to classification problems.",2.1. Problem Formulation,[0],[0]
It can be applied to general ADMM-based distributed algorithms since the convergence and privacy analysis,2.1. Problem Formulation,[0],[0]
"To decentralize (1), let fi be the local classifier of each node i. To achieve consensus, i.e., f1 = f2 = · · · = fN , a set of auxiliary variables {wij |i ∈ N , j ∈ Vi} are introduced for every pair of connected nodes.",2.2. Conventional ADMM,[0],[0]
"As a result, (1) is reformulated equivalently as:
min {fi},{wij} ÕERM ({fi}Ni=1, Dall) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
",2.2. Conventional ADMM,[0],[0]
"s.t. fi = wij , wij = fj , i ∈ N ,",2.2. Conventional ADMM,[0],[0]
"j ∈ Vi
(2)
where O(fi, Di) = C
Bi
∑Bi n=1 L (y n",2.2. Conventional ADMM,[0],[0]
i f T,2.2. Conventional ADMM,[0],[0]
"i x n i ) + ρ
N R(fi).
",2.2. Conventional ADMM,[0],[0]
The objective in (2) can be solved using ADMM.,2.2. Conventional ADMM,[0],[0]
"Let {fi} be the shorthand for {fi}i∈N ; let {wij , λkij} be the shorthand for {wij , λkij}i∈N ,j∈Vi,k∈{a,b}, where λaij , λbij are dual variables corresponding to equality constraints fi = wij and wij = fj respectively.",2.2. Conventional ADMM,[0],[0]
"Then the augmented Lagrangian is as follows:
Lη({fi}, {wij , λkij}) =",2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"O(fi, Di)
+ N∑ i=1",2.2. Conventional ADMM,[0],[0]
∑ j∈Vi (λaij) T (fi − wij) +,2.2. Conventional ADMM,[0],[0]
N∑ i=1,2.2. Conventional ADMM,[0],[0]
"∑ j∈Vi (λbij) T (wij − fj) (3)
+ N∑ i=1 ∑",2.2. Conventional ADMM,[0],[0]
j∈Vi η 2 (||fi − wij ||22 + ||wij,2.2. Conventional ADMM,[0],[0]
"− fj ||22) .
",2.2. Conventional ADMM,[0],[0]
"In the (t + 1)-th iteration, the ADMM updates consist of the following:
fi(t+ 1) = argmin fi Lη({fi}, {wij(t), λkij(t)}) ; (4)
wij(t+ 1) = argmin wij Lη({fi(t+ 1)}, {wij , λkij(t)}) ; (5)
λaij(t+ 1) = λ a ij(t) + η(fi(t+",2.2. Conventional ADMM,[0],[0]
1)− wij(t+ 1)),2.2. Conventional ADMM,[0],[0]
"; (6)
λbij(t+ 1) = λ b ij(t) +",2.2. Conventional ADMM,[0],[0]
η(wij(t+ 1)− fj(t+ 1)) .,2.2. Conventional ADMM,[0],[0]
"(7)
Using Lemma 3 in (Forero et al., 2010), if dual variables λaij(t) and λ b ij(t) are initialized to zero for all node pairs (i, j), then λaij(t) = λ b ij(t) and λ k ij(t) = −λkji(t) will hold for all iterations with k ∈ {a, b}, i ∈ N , j ∈ Vi.
",2.2. Conventional ADMM,[0],[0]
Let λi(t) = ∑,2.2. Conventional ADMM,[0],[0]
"j∈Vi λ a ij(t) = ∑ j∈Vi λ b ij(t), then the ADMM iterations (4)-(7) can be simplified as:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+η ∑ j∈Vi ||1 2 (fi(t) + fj(t))− fi||22 } ; (8)
λi(t+ 1) = λi(t) + η
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .",2.2. Conventional ADMM,[0],[0]
"(9)
in Section 3 & 4 remain valid.",2.2. Conventional ADMM,[0],[0]
"Differential privacy (Dwork, 2006) can be used to measure the privacy risk of each individual sample in the dataset quantitatively.",2.3. Differential Privacy,[0],[0]
"Mathematically, a randomized algorithm A (·) taking a dataset as input satisfies ε-differential privacy if for any two datasets D, D̂ differing in at most one data point, and for any set of possible outputs S ⊆ range(A ), Pr(A (D) ∈ S) ≤",2.3. Differential Privacy,[0],[0]
exp(ε)Pr(A (D̂) ∈ S) holds.,2.3. Differential Privacy,[0],[0]
We call two datasets differing in at most one data point as neighboring datasets.,2.3. Differential Privacy,[0],[0]
"The above definition suggests that for a sufficiently small ε, an adversary will observe almost the same output regardless of the presence (or value change) of any one individual in the dataset; this is what provides privacy protection for that individual.",2.3. Differential Privacy,[0],[0]
"Two randomizations were proposed in (Zhang & Zhu, 2017): (i) dual variable perturbation, where each node i adds a random noise to its dual variable λi(t) before updating its primal variable fi(t) using (8) in each iteration; and (ii) primal variable perturbation, where after updating primal variable fi(t), each node adds a random noise to it before broadcasting to its neighbors.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
Both were evaluated for a single iteration for a fixed privacy constraint.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"As we will see later in numerical experiments, the privacy loss accumulates significantly when inspected over multiple iterations.
","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"In contrast, in this study we will explore the use of the penalty parameter η to provide privacy.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"In particular, we will allow this to be private information to every node, i.e., each decides its own η in every iteration and it is not exchanged among the nodes.","2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
Below we will begin by modifying the ADMM to accommodate private penalty terms.,"2.4. Private ADMM proposed in (Zhang & Zhu, 2017)",[0],[0]
"Conventional ADMM (Boyd et al., 2011) requires that the penalty parameter η be fixed and equal to the dual updating step size for all nodes in all iterations.",3.1. Making η a node’s private information,[0],[0]
Varying the penalty parameter to accelerate convergence in ADMM has been proposed in the literature.,3.1. Making η a node’s private information,[0],[0]
"For instance, (He et al., 2002; Magnússon et al., 2014; Aybat & Iyengar, 2015; Xu et al., 2016) vary this penalty parameter in every iteration but keep it the same for different equality constraints in (2).",3.1. Making η a node’s private information,[0],[0]
"In (Song et al., 2016; Zhang & Wang, 2017) this parameter varies in each iteration and is allowed to differ for different equality constraints.",3.1. Making η a node’s private information,[0],[0]
"However, all of these modifications are based on the original ADMM (Eqn. (4)-(7)) and not on the simplified version (Eqn. (8)-(9)); the significance of this difference is discussed below in the context of privacy requirement.",3.1. Making η a node’s private information,[0],[0]
"Moreover, we will decouple ηi(t+1) from the dual updating step size, denoted as θ below.",3.1. Making η a node’s private information,[0],[0]
"For simplicity, θ is fixed for
all nodes in our analysis, but can also be private information as we show in numerical experiments.
",3.1. Making η a node’s private information,[0],[0]
First consider replacing η with ηij(t+ 1) in Eqn.,3.1. Making η a node’s private information,[0],[0]
"(4)-(5) of the original ADMM (as is done in (Song et al., 2016; Zhang & Wang, 2017))",3.1. Making η a node’s private information,[0],[0]
"and replacing η with θ in Eqn. (6)-(7); we obtain the following:
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ ∑ j∈Vi ηij(t+ 1) + ηji(t+ 1) 2 ||1 2 (fi(t) + fj(t))− fi||22} ;
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) .
",3.1. Making η a node’s private information,[0],[0]
This however violates our requirement that ηji(t) be node j’s private information since this is needed by node i to perform the above computation.,3.1. Making η a node’s private information,[0],[0]
"To resolve this, we instead start from the simplified ADMM, modifying Eqn. (8)-(9):
fi(t+ 1) = argmin fi {O(fi, Di) + 2λi(t)T fi
+ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 } ; (10)
λi(t+ 1) = λi(t) +",3.1. Making η a node’s private information,[0],[0]
"θ
2 ∑ j∈Vi (fi(t+ 1)− fj(t+ 1)) , (11)
where ηi(t+ 1) is now node i’s private information.",3.1. Making η a node’s private information,[0],[0]
Indeed ηi(t+ 1) is no longer purely a penalty parameter related to any equality constraint in the original sense.,3.1. Making η a node’s private information,[0],[0]
We will however refer to it as the private penalty parameter for simplicity.,3.1. Making η a node’s private information,[0],[0]
The above constitutes the M-ADMM algorithm.,3.1. Making η a node’s private information,[0],[0]
We next show that the M-ADMM (Eqn. (10)-(11)) converges to the optimal solution under a set of common technical assumptions.,3.2. Convergence Analysis,[0],[0]
"Our proof is based on the method given in (Ling et al., 2016).
",3.2. Convergence Analysis,[0],[0]
"Assumption 1: Function O(fi, Di) is convex and continuously differentiable in fi, ∀i.
",3.2. Convergence Analysis,[0],[0]
Assumption 2:,3.2. Convergence Analysis,[0],[0]
"The solution set to the original ERM problem (1) is nonempty and there exists at least one bounded element.
",3.2. Convergence Analysis,[0],[0]
"The KKT optimality condition of the primal update (10) is:
0 = ∇O(fi(t+ 1), Di) + 2λi(t)",3.2. Convergence Analysis,[0],[0]
+ηi(t+ 1) ∑ j∈Vi (2fi(t+ 1)− (fi(t) + fj(t))) .,3.2. Convergence Analysis,[0],[0]
"(12)
We next rewrite (11)-(12) in matrix form.",3.2. Convergence Analysis,[0],[0]
"Define the adjacency matrix of the network A ∈ RN×N as
aij = { 1, if node i and node j are connected 0, otherwise .
",3.2. Convergence Analysis,[0],[0]
"Stack the variables fi(t), λi(t) and ∇O(fi(t), Di) for i ∈ N into matrices, i.e.,
f̂(t) =  f1(t) T f2(t) T
...",3.2. Convergence Analysis,[0],[0]
"fN (t) T
 ∈ RN×d , Λ(t) =  λ1(t) T λ2(t) T
... λN",3.2. Convergence Analysis,[0],[0]
"(t) T
 ∈ RN×d
∇Ô(f̂(t), Dall) =  ∇O(f1(t), D1)T ∇O(f2(t), D2)T
...",3.2. Convergence Analysis,[0],[0]
"∇O(fN (t), DN )T  ∈ RN×d",3.2. Convergence Analysis,[0],[0]
"Let Vi = |Vi| be the number of neighbors of node i, and define the degree matrix D = diag([V1;V2; · · · ;VN ]) ∈ RN×N .",3.2. Convergence Analysis,[0],[0]
Define for the t-th iteration a penalty-weighted matrix W (t) = diag([η1(t); η2(t); · · · ; ηN (t)]) ∈ RN×N .,3.2. Convergence Analysis,[0],[0]
"Then the matrix form of (11)-(12) are:
∇Ô(f̂(t+ 1), Dall) + 2Λ(t) + 2W (t+ 1)Df̂(t+ 1) −W (t+ 1)(D +A)f̂(t) = 0N×d ; (13)
2Λ(t+ 1) = 2Λ(t) + θ(D −A)f̂(t+ 1) .",3.2. Convergence Analysis,[0],[0]
"(14)
Note that D −A is the Laplacian matrix and D +A is the signless Laplacian matrix of the network, with the following properties if the network is connected: (i) D ±",3.2. Convergence Analysis,[0],[0]
A 0 is positive semi-definite; (ii),3.2. Convergence Analysis,[0],[0]
Null(D,3.2. Convergence Analysis,[0],[0]
"− A) = c1, i.e., every member in the null space of D −A is a scalar multiple of 1 with 1 being the vector of all 1’s (Kelner, 2007).",3.2. Convergence Analysis,[0],[0]
"Let √ X denote the square root of a symmetric positive semi-definite (PSD) matrix X that is also symmetric PSD, i.e., √ X √ X = X .",3.2. Convergence Analysis,[0],[0]
"Define matrix Y (t) such that 2Λ(t) =√
D −AY (t).",3.2. Convergence Analysis,[0],[0]
"Since Λ(0) = zeros(N, d), which is in the column space of D −A, this together with (14) imply that Λ(t) is in the column space of D − A and √ D −A.",3.2. Convergence Analysis,[0],[0]
This guarantees the existence of Y (t).,3.2. Convergence Analysis,[0],[0]
"This allows us to rewrite (13)-(14) as:
∇Ô(f̂(t+ 1), Dall) + √ D −AY (t+ 1)
+(W (t+ 1)− θI)(D −A)f̂(t+ 1) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))",3.2. Convergence Analysis,[0],[0]
"= 0N×d ; (15)
Y (t+ 1) = Y (t) + θ",3.2. Convergence Analysis,[0],[0]
√ D −Af̂(t+ 1) .,3.2. Convergence Analysis,[0],[0]
"(16)
Lemma 3.1 [First-order Optimality Condition (Ling et al., 2016)]",3.2. Convergence Analysis,[0],[0]
"Under Assumptions 1 and 2, the following two statements are equivalent:
• f̂∗ =",3.2. Convergence Analysis,[0],[0]
"[(f∗1 )T ; (f∗2 )T ; · · · ; (f∗N )T ] ∈ RN×d is consensual, i.e., f∗1 = f ∗ 2 = · · · = f∗N = f∗c where f∗c is the
optimal solution to (1).
",3.2. Convergence Analysis,[0],[0]
"• There exists a pair (f̂∗, Y ∗) with Y ∗ = √ D −AX
for some X ∈ RN×d such that
∇Ô(f̂∗, Dall) + √ D −AY ∗ = 0N×d ; (17)√ D −Af̂∗ = 0N×d .",3.2. Convergence Analysis,[0],[0]
"(18)
Lemma 3.1 shows that a pair (Y ∗, f̂∗) satisfying (17)(18) is equivalent to the optimal solution of our problem, hence the convergence of M-ADMM is proved by showing that (Y (t), f̂(t)) converges to a pair (Y ∗, f̂∗) satisfying (17)(18).
",3.2. Convergence Analysis,[0],[0]
Theorem 3.1 Consider the modified ADMM defined by (10)-(11).,3.2. Convergence Analysis,[0],[0]
"Let {Y (t), f̂(t)} be outputs in each iteration and (Y ∗, f̂∗) a pair satisfying (17)-(18).",3.2. Convergence Analysis,[0],[0]
"Denote
Z(t) =
[ Y (t)
f̂(t)
] ∈ R2N×d, Z∗ =",3.2. Convergence Analysis,[0],[0]
"[ Y ∗
f̂∗
] ∈ R2N×d
J(t)",3.2. Convergence Analysis,[0],[0]
=,3.2. Convergence Analysis,[0],[0]
"[ IN×N θ 0 0 W (t)(D +A) ] ∈ R2N×2N
Let 〈·, ·〉F be the Frobenius inner product of two matrices.",3.2. Convergence Analysis,[0],[0]
"We have
〈Z(t+ 1)−Z∗, J(t+ 1)(Z(t+ 1)−Z(t))〉F ≤ 0 .",3.2. Convergence Analysis,[0],[0]
(19),3.2. Convergence Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"To further establish the convergence rate of modified ADMM, an additional assumption is used:
Assumption 3:",3.3. Convergence Rate Analysis,[0],[0]
"For all i ∈ N , O(fi, Di) is strongly convex in fi and has Lipschitz continues gradients, i.e., for any f1i and f 2",3.3. Convergence Rate Analysis,[0],[0]
"i , we have:
(f1i −f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",3.3. Convergence Rate Analysis,[0],[0]
"≥ mi||f1i −f2i ||22
||∇O(f1i , Di)−∇O(f2i , Di)||2 ≤Mi||f1i",3.3. Convergence Rate Analysis,[0],[0]
"− f2i ||2 (20)
where mi > 0 is the strong convexity constant and 0",3.3. Convergence Rate Analysis,[0],[0]
<,3.3. Convergence Rate Analysis,[0],[0]
Mi,3.3. Convergence Rate Analysis,[0],[0]
"< +∞ is the Lipschitz constant.
",3.3. Convergence Rate Analysis,[0],[0]
Theorem 3.2 Define Dm = diag([m1;m2; · · · ;mN ]) ∈,3.3. Convergence Rate Analysis,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈ RN×N with mi > 0,3.3. Convergence Rate Analysis,[0],[0]
and 0 <,3.3. Convergence Rate Analysis,[0],[0]
Mi < +∞ as given in Assumption 3.,3.3. Convergence Rate Analysis,[0],[0]
"Denote by ||X||2J = 〈X, JX〉F the Frobenius inner product of any matrix X and JX; denote by σmin(·) and σmax(·) the smallest nonzero, and the largest, singular values of a matrix, respectively.
",3.3. Convergence Rate Analysis,[0],[0]
Let σ̃max(t) =,3.3. Convergence Rate Analysis,[0],[0]
"σmax(W (t)(D +A)), σ̄max/min(t) = σmax/min((W",3.3. Convergence Rate Analysis,[0],[0]
(t)− θI)(D −A)) and µ > 1 be an arbitrary constant.,3.3. Convergence Rate Analysis,[0],[0]
"Consider any δ(t) that satisfies (21)(22):
δ(t)µ2σ̃max(t) θσmin(D −A) ≤ 1 (21)
and
δ(t)( µσ̄max(t) 2IN + µ2DM θσmin(D",3.3. Convergence Rate Analysis,[0],[0]
−A)(µ− 1),3.3. Convergence Rate Analysis,[0],[0]
"+W (t)(D +A))
",3.3. Convergence Rate Analysis,[0],[0]
2(W (t)− θI)(D −A) + 2Dm .,3.3. Convergence Rate Analysis,[0],[0]
(22),3.3. Convergence Rate Analysis,[0],[0]
"(Y (t), f̂(t)) converges to (Y ∗, f̂∗) in the following sense:
(1 + δ(t))||Z(t)− Z∗||2J(t) ≤","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
||Z(t−,"If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"1)− Z ∗||2J(t) .
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Furthermore, a lower bound on δ(t) is:
min{θσmin(D −A) µ2σ̃max(t) , 2mo + 2σ̄min(t) µ2M2O+µσ̄max(t) 2
θσmin(D−A)(µ−1) + σ̃max(t) } (23)
where mo = mini∈N {mi} and MO = maxi∈N {Mi}.
","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Although Theorem 3.2 only gives a lower bound on the convergence rate (1 + δ(t)) of the M-ADMM, it reflects the impact of penalty {ηi(t)}Ni=1 on the convergence.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Since σ̄max(t) = σmax((W (t)− θI)(D −A)) and σ̃max(t) = σmax(W (t)(D +A)), larger penalty results in larger σ̄max(t) and σ̃max(t).","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"By (23), the first term,
θσmin(D−A) µ2σ̃max(t)
is smaller when σ̃max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"The second term is bounded by θσmin(D−A)(µ−1)(2mo+2σ̄min(t))µσ̄max(t)2 , which is smaller when σ̄max(t) is larger.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
"Therefore, the convergence rate 1 + δ(t) decreases as {ηi(t)}Ni=1 increase.","If ηi(t + 1) ≥ ηi(t) ≥ θ > 0 and ηi(t) < +∞, ∀t, i, then",[0],[0]
In this section we present a privacy preserving version of MADMM.,4. Private M-ADMM,[0],[0]
"To begin, a random noise i(t+1) with probability density proportional to exp{−αi(t + 1)|| i(t + 1)||2} is added to penalty term in the objective function of (10):
Lprivi (t+ 1) =",4. Private M-ADMM,[0],[0]
"O(fi, Di) + 2λi(t)",4. Private M-ADMM,[0],[0]
T fi +ηi(t+ 1) ∑ j∈Vi ||fi + i(t+,4. Private M-ADMM,[0],[0]
"1)− 1 2 (fi(t) + fj(t))||22
(24)
",4. Private M-ADMM,[0],[0]
"To generate this noisy vector, choose the norm from the gamma distribution with shape d and scale 1αi(t+1) and the direction uniformly, where d is the dimension of the feature space.",4. Private M-ADMM,[0],[0]
"Then node i’s local result is obtained by finding the optimal solution to the private objective function:
fi(t+ 1) = argmin fi
Lprivi (t+ 1), i ∈ N .",4. Private M-ADMM,[0],[0]
"(25)
It is equivalent to (26) below when noise ηi(t+1)Vi i(t+1)
",4. Private M-ADMM,[0],[0]
Algorithm 1 Penalty perturbation (PP) method,4. Private M-ADMM,[0],[0]
Parameter:,4. Private M-ADMM,[0],[0]
"Determine θ such that 2c1 < BiC ( ρ N + 2θVi)
holds for all i. Initialize: Generate fi(0) randomly and λi(0) = 0d×1 for every node i ∈ N , t = 0",4. Private M-ADMM,[0],[0]
"Input: {Di}Ni=1, {αi(1), · · · , αi(T )}Ni=1 for t = 0 to T − 1 do
for i = 1 to N do Generate noise i(t+ 1) ∼ exp(−αi(t+ 1)|| ||2)",4. Private M-ADMM,[0],[0]
"Perturb the penalty term according to (24) Update primal variable via (25) end for for i = 1 to N do
Broadcast fi(t+ 1) to all neighbors",4. Private M-ADMM,[0],[0]
"j ∈ Vi end for for i = 1 to N do
Update dual variable according to (11) end for
end for Output: upper bound of the total privacy loss β
is added to the dual variable λi(t):
argmin fi
L̃privi (",4. Private M-ADMM,[0],[0]
"t+ 1) = C
Bi Bi∑ n=1 L",4. Private M-ADMM,[0],[0]
(,4. Private M-ADMM,[0],[0]
yni f T i x n,4. Private M-ADMM,[0],[0]
i ),4. Private M-ADMM,[0],[0]
"+ ρ N R(fi)
",4. Private M-ADMM,[0],[0]
+2(λi(t) +,4. Private M-ADMM,[0],[0]
ηi(t+,4. Private M-ADMM,[0],[0]
1)Vi i(t+ 1)),4. Private M-ADMM,[0],[0]
"T fi +ηi(t+ 1) ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22 .
",4. Private M-ADMM,[0],[0]
"Further, if ηi(t+1) = η = θ,∀i, t, then the above is reduced to the dual variable perturbation in (Zhang & Zhu, 2017)3.
",4. Private M-ADMM,[0],[0]
"The complete procedure is shown in Algorithm 1, where the condition used to generate θ helps bound the worst-case privacy loss but is not necessary in guaranteeing convergence.
",4. Private M-ADMM,[0],[0]
"In a distributed and iterative setting, the “output” of the algorithm is not merely the end result, but includes all intermediate results generated and exchanged during the iterative process.",4. Private M-ADMM,[0],[0]
"For this reason, we formally state the differential privacy definition in this setting below.
",4. Private M-ADMM,[0],[0]
"Definition 4.1 Consider a connected network G(N ,E ) with a set of nodes N = {1, 2, · · · , N}.",4. Private M-ADMM,[0],[0]
Let f(t) =,4. Private M-ADMM,[0],[0]
{fi(t)}Ni=1 denote the information exchange of all nodes in the t-th iteration.,4. Private M-ADMM,[0],[0]
"A distributed algorithm is said to satisfy β-differential privacy during T iterations if for any two datasets Dall = ∪iDi and D̂all = ∪iD̂i, differing in at
3Only a single iteration is considered in (Zhang & Zhu, 2017) while imposing a privacy constraint.",4. Private M-ADMM,[0],[0]
"Since we consider the entire iterative process, we don’t impose per-iteration privacy constraint but calculate the total privacy loss.
",4. Private M-ADMM,[0],[0]
"most one data point, and for any set of possible outputs S during T iterations, the following holds:
Pr({f(t)}Tt=0 ∈ S|Dall)",4. Private M-ADMM,[0],[0]
Pr({f(t)}Tt=0 ∈ S|D̂all) ≤,4. Private M-ADMM,[0],[0]
"exp(β)
We now state our main result on the privacy property of the penalty perturbation algorithm using the above definition.",4. Private M-ADMM,[0],[0]
"Additional assumptions on L (·) and R(·) are used.
",4. Private M-ADMM,[0],[0]
Assumption 4: The loss function L is strictly convex and twice differentiable.,4. Private M-ADMM,[0],[0]
|L,4. Private M-ADMM,[0],[0]
"′| ≤ 1 and 0 < L ′′ ≤ c1 with c1 being a constant.
",4. Private M-ADMM,[0],[0]
"Assumption 5: The regularizer R is 1-strongly convex and twice continuously differentiable.
",4. Private M-ADMM,[0],[0]
Theorem 4.1 Normalize feature vectors in the training set such that ||xni ||2 ≤ 1 for all i ∈ N and,4. Private M-ADMM,[0],[0]
"n. Then the private M-ADMM algorithm (PP) satisfies the β-differential privacy with
β ≥ max i∈N { T∑ t=1 C(1.4c1 + αi(t)) ηi(t)ViBi } .",4. Private M-ADMM,[0],[0]
(26),4. Private M-ADMM,[0],[0]
"We use the same dataset as (Zhang & Zhu, 2017), i.e., the Adult dataset from the UCI Machine Learning Repository (Lichman, 2013).",5. Numerical Experiments,[0],[0]
"It consists of personal information of around 48,842 individuals, including age, sex, race, education, occupation, income, etc.",5. Numerical Experiments,[0],[0]
"The goal is to predict whether the annual income of an individual is above $50,000.
",5. Numerical Experiments,[0],[0]
"To preprocess the data, we (1) remove all individuals with missing values; (2) convert each categorical attribute (with m categories) to a binary vector of length m; (3) normalize columns (features) such that the maximum value of each column is 1; (4) normalize rows (individuals) such that its l2 norm is at most 1; and (5) convert labels {≥ 50k,≤ 50k} to {+1,−1}.",5. Numerical Experiments,[0],[0]
"After this preprocessing, the final data includes 45,223 individuals, each represented as a 105-dimensional vector of norm at most 1.
",5. Numerical Experiments,[0],[0]
"We will use as loss function the logistic loss L (z) = log(1 + exp(−z)), with |L ′| ≤ 1 and L ′′ ≤ c1 = 14 .",5. Numerical Experiments,[0],[0]
The regularizer is R(fi),5. Numerical Experiments,[0],[0]
= 12 ||fi|| 2 2.,5. Numerical Experiments,[0],[0]
We will measure the accuracy of the algorithm by the average loss L(t) := 1 N ∑N i=1 1,5. Numerical Experiments,[0],[0]
"Bi ∑Bi n=1 L (y n i fi(t)
",5. Numerical Experiments,[0],[0]
Txni ) over the training set.,5. Numerical Experiments,[0],[0]
"We will measure the privacy of the algorithm by the upper bound P (t) := max i∈N { ∑t r=1 C(1.4c1+αi(r)) ηi(r)ViBi
}.",5. Numerical Experiments,[0],[0]
"The smaller L(t) and P (t), the higher accuracy and stronger privacy guarantee.",5. Numerical Experiments,[0],[0]
"We consider a five-node network and assign each node the following private penalty parameters: ηi(t) = ηi(1)q t−1 i for node i, where [η1(1), · · · , η5(1)] =",5.1. Convergence of M-ADMM,[0],[0]
"[0.55, 0.65, 0.6, 0.55, 0.6] and [q1, · · · , q5] =",5.1. Convergence of M-ADMM,[0],[0]
"[1.01, 1.03, 1.1, 1.2, 1.02].
Figure 1(a) shows the convergence of M-ADMM under these parameters while using a fixed dual updating step size θ = 0.5 across all nodes (blue curve).",5.1. Convergence of M-ADMM,[0],[0]
This is consistent with Theorem 3.1.,5.1. Convergence of M-ADMM,[0],[0]
"As mentioned earlier, this step size can also be non-fixed (black) and different (red) for different nodes.",5.1. Convergence of M-ADMM,[0],[0]
"In
Figure 1(b) we let each node use the same penalty ηi(t) = η(t) = 0.5qt−11 and compare the results by increasing q1, q1 ≥ 1.",5.1. Convergence of M-ADMM,[0],[0]
"We see that increasing penalty slows down the convergence, and larger increase in q1 slows it down even more, which is consistent with Theorem 3.2.",5.1. Convergence of M-ADMM,[0],[0]
"We next inspect the accuracy and privacy of the penalty perturbation (PP) based private M-ADMM (Algorithm 1) and compare it with the dual variable perturbation (DVP) method proposed in (Zhang & Zhu, 2017).",5.2. Private M-ADMM,[0],[0]
"In this set of experiments, for simplicity of presentation we shall fix θ = 0.5, let ηi(t) = η(t) = θqt−11 , and noise αi(t) = α(t) = α(1)qt−12 for all nodes.",5.2. Private M-ADMM,[0],[0]
"We observe similar results when ηi(t) and αi(t) vary from node to node.
",5.2. Private M-ADMM,[0],[0]
"For each parameter setting, we perform 10 independent runs of the algorithm, and record both the mean and the range of their accuracy.",5.2. Private M-ADMM,[0],[0]
"Specifically, Ll(t) denotes the average loss over the training dataset in the t-th iteration of the l-th experiment (1 ≤ l ≤ 10).",5.2. Private M-ADMM,[0],[0]
The mean of average loss is then given by Lmean(t) = 110 ∑10 l=1,5.2. Private M-ADMM,[0],[0]
"L
l(t), and the range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"= max
1≤l≤10 Ll(t)",5.2. Private M-ADMM,[0],[0]
− min 1≤l≤10 Ll(t).,5.2. Private M-ADMM,[0],[0]
"The larger the
range Lrange(t)",5.2. Private M-ADMM,[0],[0]
"the less stable the algorithm, i.e., under the same parameter setting, the difference in performances (convergence curves) of every two experiments is larger.",5.2. Private M-ADMM,[0],[0]
Each parameter setting also has a corresponding upper bound on the privacy loss denoted by P (t).,5.2. Private M-ADMM,[0],[0]
Figures 2(a)2(b) show both Lmean(t) and Lrange(t),5.2. Private M-ADMM,[0],[0]
as vertical bars centered at Lmean(t),5.2. Private M-ADMM,[0],[0]
.,5.2. Private M-ADMM,[0],[0]
Their corresponding privacy upper bound is given in Figures 2(c)2(d).,5.2. Private M-ADMM,[0],[0]
"The pair 2(a)-2(c) (resp. 2(b)2(d)) is for the same parameter setting.
",5.2. Private M-ADMM,[0],[0]
"Figure 2 compares PP (blue & red, with ηi(t) increasing geometrically) with DVP (black & magenta, with ηi(t) = θ, ∀i, t).",5.2. Private M-ADMM,[0],[0]
"We see that in both cases improved accuracy comes at the expense of higher privacy loss (from magenta to black under DVP, from red to blue under PP).",5.2. Private M-ADMM,[0],[0]
"However, we also see that with suitable choices of q1, q2, PP can outperform DVP significantly both in accuracy and in privacy (e.g., red outperforms magenta in both accuracy and privacy, and blue outperforms black in both accuracy and privacy).
",5.2. Private M-ADMM,[0],[0]
We also performed experiments with the same dataset on larger networks with tens and hundreds of nodes and with samples evenly and unevenly spread across nodes.,5.2. Private M-ADMM,[0],[0]
"In both cases, convergence is attained and our algorithm continues to outperform (Zhang & Zhu, 2017) in a large network (see Figures 3 & 4).",5.2. Private M-ADMM,[0],[0]
"Since the privacy loss of the network is dominated by the node with the largest privacy loss and it increases as the number of samples in a node decreases (Theorem 4.1), the loss of privacy in a network with uneven sample size distributions is higher; note that this is a common issue with this type of analysis.",5.2. Private M-ADMM,[0],[0]
Our numerical results show that increasing the penalty {ηi(t)}Ni=1 over iterations can improve the algorithm’s accuracy and privacy simultaneously.,6. Discussion,[0],[0]
Below we provide some insight on why this is the case and discuss possible generalizations of our method.,6. Discussion,[0],[0]
"When the algorithm is perturbed by random noise, which is necessary to achieve privacy, increasing the penalty parameters over iterations makes the algorithm more noise resistant.",6.1. Higher accuracy,[0],[0]
"In particular, for the minimization in (25), larger ηi(t+ 1) results in smaller updates of variables, i.e., smaller distance between fi(t + 1) and fi(t).",6.1. Higher accuracy,[0],[0]
"In the non-private case, since fi(t) always moves toward the optimum, smaller update slows down the process.",6.1. Higher accuracy,[0],[0]
"In the private case, on the other hand, since a random noise is added to each update, fi(t) does not always move toward the optimum in each step.",6.1. Higher accuracy,[0],[0]
"When the overall perturbation has a larger variance, it is more likely that fi(t) could move further away from the optimum in some iterations.",6.1. Higher accuracy,[0],[0]
"Because larger ηi(t) leads to smaller update, it helps prevent fi(t) from moving too far away from the optimum, thus stabilizing the algorithm (smaller Lrange(t)).",6.1. Higher accuracy,[0],[0]
"First of all, more added noise means stronger privacy guarantee.",6.2. Stronger privacy,[0],[0]
"Increasing ηi(t) and αi(t) in such a way that the overall perturbation 2ηi(t)Vi i(t)T fi(t) in (26) is increasing leads to less privacy loss, as shown in Figure 2.",6.2. Stronger privacy,[0],[0]
"The noise resistance provided by an increasing ηi(t) indeed allows larger noises to be added under PP without jeopardizing convergence as observed in Section 6.1.
More interestingly, keeping ηi(t) private further strengthens privacy protection.",6.2. Stronger privacy,[0],[0]
"Consider the following threat model: An attacker knows {(xni , yni )}",6.2. Stronger privacy,[0],[0]
"Bi n=2 and {fj(t)}j∈Vi∪i for all t, i.e., all data points except for the first data point of node i, as well as all intermediate results of node i and its neighbors.",6.2. Stronger privacy,[0],[0]
"If the attacker also knows the dual updating step size θ and penalty parameter {ηi(t)}Tt=1 of node i, it can then infer the unknown data point (x1i , y 1 i ) with high confidence by combining the KKT optimality conditions from all iterations (see supplementary material for details).",6.2. Stronger privacy,[0],[0]
"However, if the penalty parameters {ηi(t)}Tt=1 are private to each node, then it is impossible for the attacker to infer the unknown data.",6.2. Stronger privacy,[0],[0]
"Even if the attacker knows the participation of an individual, it remains hard to infer its features.",6.2. Stronger privacy,[0],[0]
"The main contribution of this paper is the finding that increasing {ηi}Ni=1 improves the algorithm’s ability to resist
noise: even though we increase noise in each iteration to improve privacy, the accuracy does not degrade significantly due to this increasing robustness, which improves the privacy-utility tradeoff.",6.3. Generalization & comparison,[0],[0]
This property holds regardless of the noise distribution.,6.3. Generalization & comparison,[0],[0]
"While the present privacy analysis uses a similar framework as in (Chaudhuri et al., 2011; Zhang & Zhu, 2017) (objective perturbation with added Gamma noise), we can also use methods from other existing (centralized) ERM differentially private algorithms to every iteration in ADMM.",6.3. Generalization & comparison,[0],[0]
"For example, if we allow some probability (δ > 0) of violating -differential privacy and adopt a weaker variant ( , δ)-differential privacy, we can adopt methods from works such as (Kifer et al., 2012; Jain & Thakurta, 2014; Bassily et al., 2014), by adding Gaussian noise to achieve tighter bounds on privacy loss.",6.3. Generalization & comparison,[0],[0]
"However, as noted above, the robustness is improved as {ηi}Ni=1 increases; thus the same conclusion can be reached that both privacy and accuracy can be improved.
",6.3. Generalization & comparison,[0],[0]
This idea can also be generalized to other differentially private iterative algorithms.,6.3. Generalization & comparison,[0],[0]
A key observation of our algorithm is that the overall perturbation (2ηi(t)Vi i(t)T fi(t)) is related to the parameter that controls the updating step size (ηi(t)).,6.3. Generalization & comparison,[0],[0]
"In general, if the algorithm is perturbed in each iteration with a quantity φ( , ξ), which is a function of added noise and some parameter ξ that controls the step size, such that the resulting step size and φ( , ξ) move in opposite directions (i.e., decreasing step size increases the φ( , ξ)), then it is possible to simultaneously improve both accuracy and privacy by varying ξ to decrease the step size over time.
",6.3. Generalization & comparison,[0],[0]
"Interestingly, in a differentially private (sub)gradient-based distributed algorithm (Huang et al., 2015), the step size
and the overall perturbation move in the same direction (i.e., decreasing step size decreases perturbation).",6.3. Generalization & comparison,[0],[0]
"The reason for this difference is that under this subgradient-based algorithm, the sensitivity of the algorithm decreases with decreasing step size, which in turn leads to privacy constraint being satisfied with smaller perturbation.",6.3. Generalization & comparison,[0],[0]
"In contrast, for ADMM the sensitivity of the algorithm is independent of the step size, and the perturbation actually needs to increase to improve privacy guarantee; the decreasing step size acts to compensate for this increase in noise to maintain accuracy, as discussed in Section 6.1.
",6.3. Generalization & comparison,[0],[0]
"This issue of step size never arises in the study of (Zhang & Zhu, 2017) because the analysis is only for a single iteration; however, as we have seen doing so leads to significant total privacy loss over many iterations.",6.3. Generalization & comparison,[0],[0]
This paper presents a penalty-perturbation idea to introduce privacy preservation in iterative algorithms.,7. Conclusions,[0],[0]
We showed how to modify an ADMM-based distributed algorithm to improve privacy without compromising accuracy.,7. Conclusions,[0],[0]
The key idea is to add a perturbation correlated to the step size so that they change in opposite directions.,7. Conclusions,[0],[0]
Applying this idea to other iterative algorithms can be part of the future work.,7. Conclusions,[0],[0]
"This work is supported by the NSF under grants CNS1422211, CNS-1646019, CNS-1739517.",Acknowledgements,[0],[0]
"By KKT condition of (5), there is:
0 =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λbij(t)− λaij(t) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η(2wij(t+ 1)− fi(t+ 1)− fj(t+ 1))
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Implies:
wij(t+ 1) = 1
2η (λaij(t)− λbij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
1 2 (fi(t+ 1) + fj(t+ 1)) (27)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Plug (27) into (6)(7):
λaij(t+ 1) = 1
2 (λaij(t) + λ b ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (28)
λbij(t+ 1) = 1
2 (λbij(t) + λ a ij(t))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"+
η 2 (fi(t+ 1)− fj(t+ 1)) (29)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"If initialize λaij(0) = λ b ij(0) to be zero vectors for all node pairs (i, j), (28)(29) imply that λ a ij(t) = λ b ij(t) and λ k ji(t) = −λkij(t), k ∈ {a, b} will hold for all t. (27) becomes:
wij(t+ 1)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"= 1
2 (fi(t+ 1) + fj(t+ 1)) (30)
Let λij(t) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
λaij(t),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
= λ,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"b ij(t), (6)(7) can be simplified as:
λij(t+ 1) = λij(t) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"η
2 (fi(t+ 1)− fj(t+ 1))","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"(31)
Plug (30) into the augmented Lagrangian (3) to simplify it:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T (fi − fj)
+ N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||fi − 1 2 (fi(t) + fj(t))||22) +,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22)
(32)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Since ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi λij(t)fj = ∑N i=1 ∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi λji(t)fi and λij(t) = −λji(t), the second term in (32) can be simplified:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
T (fi − fj) = 2,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (λij(t)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi
The last term can be expressed as:
N∑ i=1","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fj ||22) =,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"j∈Vi η 2 (||1 2 (fi(t) + fj(t))− fi||22)
Therefore, (32) is simplified as:
Lη({fi}, {wij , λkij}) =","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"O(fi, Di) +","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
2 N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi λij(t) T fi + N∑ i=1,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"∑ j∈Vi η(||fi − 1 2 (fi(t) + fj(t))||22) (33)
","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
Define λi(t) = ∑ j∈Vi λij(t).,"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Based on (31)(33), the original ADMM updates (4)-(7) are simplified as:
fi(t+ 1) = argmin fi O(fi, Di) + 2λi(t)","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"T fi + η ∑ j∈Vi ||fi − 1 2 (fi(t) + fj(t))||22
λi(t+ 1) = λi(t) + η
2","A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
∑ j∈Vi (fi(t+ 1)− fj(t+ 1)),"A. Proof of Simplifying ADMM (Forero et al., 2010)",[0],[0]
"Subtract (17) from (15) and (18) from (16):
∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) + √ D −A(Y (t+ 1)− Y ∗)",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂(t+ 1)
+W (t+ 1)(D +",B. Proof of Theorem 3.1,[0],[0]
A)(f̂(t+ 1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d (34)
Y (t+ 1) = Y (t) + θ √ D −A(f̂(t+",B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗) (35)
",B. Proof of Theorem 3.1,[0],[0]
"By convexity of O(fi, Di), for any f1i and f 2 i , there is:
(f1i − f2i )T (∇O(f1i , Di)−∇O(f2i , Di))",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Let 〈·, ·〉F be frobenius inner product of two matrices, there is:
〈f̂(t+ 1)− f̂∗,∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Substitute ∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) from (34):
0 ≤ 〈f̂(t+ 1)− f̂∗,−",B. Proof of Theorem 3.1,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)〉F + 〈f̂(t+ 1)− f̂∗,−(W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F +〈f̂(t+ 1)− f̂∗,−W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))〉F",B. Proof of Theorem 3.1,[0],[0]
"(36)
Consider the right hand side of (36).",B. Proof of Theorem 3.1,[0],[0]
"Since D−A is symmetric and PSD, √ D −A is also a symmetric matrix and by (35),
〈f̂(t+ 1)− f̂∗,− √ D −A(Y (t+ 1)− Y ∗)〉F",B. Proof of Theorem 3.1,[0],[0]
= 〈− √ D −A(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
"1)− f̂∗), (Y (t+ 1)− Y ∗)〉F
= −〈1 θ
(Y (t+ 1)− Y (t)), Y (t+ 1)− Y ∗〉F",B. Proof of Theorem 3.1,[0],[0]
"(37)
Rearrange (36) and use (D −A)f̂∗ = 0N×d
0",B. Proof of Theorem 3.1,[0],[0]
"≥ 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F +",B. Proof of Theorem 3.1,[0],[0]
"〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"(38)
Suppose ηi(t) ≥ θ for all t, i, i.e., the diagonal matrix W (t)− θI 0 for all t. Since D−A 0, whose eigenvalues are all non-negative, the eigenvalues of (W (t+ 1)− θI)(D −A) are thus also non-negative, i.e., (W (t+ 1)− θI)(D −A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Then for the second term of the RHS of (38), there is:
〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)(f̂(t+ 1)− f̂∗)〉F",B. Proof of Theorem 3.1,[0],[0]
"≥ 0
Therefore, 〈Z(t+ 1)− Z∗, J(t+ 1)(Z(t+ 1)− Z(t))〉F",B. Proof of Theorem 3.1,[0],[0]
≤ 0,B. Proof of Theorem 3.1,[0],[0]
"(39)
To simplify the notation, for a matrix X , let ||X||2J = 〈X, JX〉F , then (39) can be represented as:
1 2 ||Z(t+ 1)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
+ 1 2 ||Z(t+ 1)− Z(t)||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− 1 2 ||Z(t)− Z∗||2J(t+1) ≤ 0
implies
||Z(t+ 1)− Z(t)||2J(t+1) ≤ −||Z(t+",B. Proof of Theorem 3.1,[0],[0]
1)− Z ∗||2J(t+1) + ||Z(t)− Z ∗||2J(t) + ||Z(t)− Z ∗||2J(t+1),B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t)− Z ∗||2J(t) (40)
",B. Proof of Theorem 3.1,[0],[0]
"Suppose ηi(t+ 1) ≥ ηi(t) for all t and i, i.e., the diagonal matrix W (t+ 1)−W (t) 0 for all t. Since D+A 0, implies (W (t+ 1)−W (t))(D +A) 0.",B. Proof of Theorem 3.1,[0],[0]
"Let U = sup
i,t,k |(fi(t)− f∗c )k| ∈ R be the finite upper bound of all nodes i, all iterations t
and all components k, then
||Z(t)− Z∗||2J(t+1)",B. Proof of Theorem 3.1,[0],[0]
− ||Z(t)− Z ∗||2J(t) = Tr((Z(t)− Z ∗)T,B. Proof of Theorem 3.1,[0],[0]
"(J(t+ 1)− J(t))(Z(t)− Z∗))
= Tr((f̂(t)− f̂∗)T (W (t+ 1)−W (t))(D +A)(f̂(t)− f̂∗))",B. Proof of Theorem 3.1,[0],[0]
"≤ U2(||ones(N, d)||2W (t+1)(D+A)",B. Proof of Theorem 3.1,[0],[0]
"− ones(N, d)|| 2 W (t)(D+A))
(41)
where ones(N, d) is all one’s matrix of size N × d.",B. Proof of Theorem 3.1,[0],[0]
"By (40)(41):
||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(t)− Z ∗||2J(t)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(t+ 1)− Z ∗||2J(t+1) +U2(||ones(N, d)||2W",B. Proof of Theorem 3.1,[0],[0]
"(t+1)(D+A) − ||ones(N, d)|| 2 W (t)(D+A))
",B. Proof of Theorem 3.1,[0],[0]
"(42)
Sum up (42) over t from 0 to +∞ leads to:
+∞∑ t=0 ||Z(t+ 1)− Z(t)||2J(t+1) ≤ ||Z(0)− Z ∗||2J(0)",B. Proof of Theorem 3.1,[0],[0]
"− ||Z(+∞)− Z ∗||2J(+∞)
+U2(||ones(N, d)||2W (+∞)(D+A) − ||ones(N, d)|| 2 W (0)(D+A))
(43)
Since ηi(t) <",B. Proof of Theorem 3.1,[0],[0]
"+∞, the RHS of (43) is finite, implies that limt→+∞ ||Z(t+ 1)− Z(t)||2J(t+1) = 0 must hold.
",B. Proof of Theorem 3.1,[0],[0]
"By the definition of Z(t), J(t) and ||X||2J = 〈X, JX〉F , the following must hold
lim t→+∞
||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) = 0",B. Proof of Theorem 3.1,[0],[0]
"(44)
lim t→+∞
||Y (t+ 1)− Y (t)||2F = 0 (45)
(45) shows that Y (t) converges to a stationary point Y s, along with (16) imply limt→+∞ √ D −Af̂(t + 1) = 0.",B. Proof of Theorem 3.1,[0],[0]
"Since Null( √ D −A) = c1, f̂(t+ 1) must lie in the subspace spanned by 1 as t→∞. To satisfy (44), either of the following two statements must hold:
",B. Proof of Theorem 3.1,[0],[0]
• limt→+∞(f̂(t+,B. Proof of Theorem 3.1,[0],[0]
1)− f̂(t)),B. Proof of Theorem 3.1,[0],[0]
"= 0N×d
• limt→+∞W (t+ 1)(D +A)1 = limt→+∞W (t+ 1)A1 + limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
"1)Vi = 0N×1
",B. Proof of Theorem 3.1,[0],[0]
Since ηi(t) ≥,B. Proof of Theorem 3.1,[0],[0]
θ > 0,B. Proof of Theorem 3.1,[0],[0]
"for all t, implies limt→+∞ ∑N i=1",B. Proof of Theorem 3.1,[0],[0]
ηi(t+,B. Proof of Theorem 3.1,[0],[0]
1)Vi > 0.,B. Proof of Theorem 3.1,[0],[0]
The second statement can never be true because all elements of A and W (t+ 1) are non-negative.,B. Proof of Theorem 3.1,[0],[0]
"Hence, f̂(t) should also converge to a stationary point f̂s.
",B. Proof of Theorem 3.1,[0],[0]
"Now show that the stationary point (Y s, f̂s) is (Y ∗, f̂∗).
",B. Proof of Theorem 3.1,[0],[0]
"Take limit of both sides of (15) (16), substitute f̂s, Y s yields
∇Ô(f̂s, Dall) + √ D −AY s",B. Proof of Theorem 3.1,[0],[0]
"+ (W (t+ 1)− θI)(D −A)f̂s = 0N×d (46)
",B. Proof of Theorem 3.1,[0],[0]
"√ D −Af̂s = 0N×d (47)
",B. Proof of Theorem 3.1,[0],[0]
"By (47), (46) turns into: ∇Ô(f̂s, Dall) + √ D −AY s = 0N×d",B. Proof of Theorem 3.1,[0],[0]
"(48)
Compare (47)(48) with (17)(18) in Lemma 3.1 and observe that (Y s, f̂s) satisfies the optimality condition (17)(18) and is thus the optimal point.",B. Proof of Theorem 3.1,[0],[0]
"Therefore, f(t) converges to f̂∗ and Y (t) converges to Y ∗.",B. Proof of Theorem 3.1,[0],[0]
"According to the Assumption 3 that O(fi, Di) is strongly convex and has Lipschitz continues gradients for all i ∈ N , define diagonal matrices Dm = diag([m1;m2; · · · ;mN ]) ∈",C. Proof of Theorem 3.2,[0],[0]
RN×N and DM = diag([M21 ;M22 ; · · · ;M2N ]) ∈,C. Proof of Theorem 3.2,[0],[0]
"RN×N , (20) yield:
〈f̂1 − f̂2,∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)〉F",C. Proof of Theorem 3.2,[0],[0]
"≥ 〈f̂1 − f̂2, Dm(f̂1",C. Proof of Theorem 3.2,[0],[0]
"− f̂2)〉F (49)
||∇Ô(f̂1, Dall)−∇Ô(f̂2, Dall)||2F ≤ 〈f̂1 − f̂2, DM (f̂1 − f̂2)〉F (50)
",C. Proof of Theorem 3.2,[0],[0]
"Since for any µ > 1 and any matrices C1, C2 with the same dimensions, there is:
||C1 +",C. Proof of Theorem 3.2,[0],[0]
"C2||2F ≤ µ||C1||2F + µ
µ− 1 ||C2||2F
From (34), there is:
||",C. Proof of Theorem 3.2,[0],[0]
"√ D −A(Y (t+ 1)− Y ∗)||2F ≤ µ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall) +W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F
+ µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F ≤
µ2
µ− 1 ||∇Ô(f̂(t+ 1), Dall)−∇Ô(f̂∗, Dall)||2F
+µ2||W (t+ 1)(D +A)(f̂(t+ 1)− f̂(t))||2F + µ
µ− 1 ||(W (t+ 1)− θI)(D −A)f̂(t+ 1)||2F
(51)
Let σmin(·), σmax(·) denote the smallest nonzero singular value and the largest singular value of a matrix respectively.
",C. Proof of Theorem 3.2,[0],[0]
"For any matrices C1, C2, let C1 = UΣV T be SVD of C1, there is:
||C1C2||2F ≤ σmax(C1)||C2||2CT1
σmin(C1)",C. Proof of Theorem 3.2,[0],[0]
2||C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
||C1C2||2F ≤,C. Proof of Theorem 3.2,[0],[0]
"σmax(C1)2||C2||2F
Denote σ̄max(t+ 1) = σmax((W (t+ 1)− θI)(D −A))",C. Proof of Theorem 3.2,[0],[0]
"σ̄min(t+ 1) = σmin((W (t+ 1)− θI)(D −A))
",C. Proof of Theorem 3.2,[0],[0]
"σ̃max(t+ 1) = σmax(W (t+ 1)(D +A))
",C. Proof of Theorem 3.2,[0],[0]
"Using (50) and (D −A)f̂∗ = 0, (51) is turned into:
1 θ ||Y (t+ 1)− Y ∗||2F ≤
µ2
θσmin(D −A)(µ− 1) ||f̂(t+ 1)− f̂∗||2DM
+ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A) +
µσ̄max(t+ 1) 2
θσmin(D",C. Proof of Theorem 3.2,[0],[0]
−A)(µ− 1),C. Proof of Theorem 3.2,[0],[0]
"||(f̂(t+ 1)− f̂∗)||2F
Adding ||f̂(t+ 1)− f̂∗||2W (t+1)(D+A) at both sides leads to:
||Z(t+ 1)− Z∗||2J(t+1) ≤ µ2σ̃max(t+ 1)
θσmin(D −A) ||f̂(t+ 1)− f̂(t)||2W (t+1)(D+A)
+||f̂(t+ 1)− f̂∗||2µ2DM+µσ̄max(t+1)2IN θσmin(D−A)(µ−1)",C. Proof of Theorem 3.2,[0],[0]
"+W (t+1)(D+A)
(52)
",C. Proof of Theorem 3.2,[0],[0]
"Since δ(t+ 1)µ2σ̃max(t+ 1)
θσmin(D −A) ≤ 1 (53)
and
δ(t+ 1)( µσ̄max(t+ 1) 2IN + µ2DM θσmin(D −A)(µ− 1)",C. Proof of Theorem 3.2,[0],[0]
+W (t+ 1)(D +A)),C. Proof of Theorem 3.2,[0],[0]
"2(W (t+ 1)− θI)(D −A) + 2Dm (54)
",C. Proof of Theorem 3.2,[0],[0]
"It implies from (52) that:
δ(t+ 1)||Z(t+ 1)− Z∗||2J(t+1) ≤ ||f̂(t+ 1)− f̂(t)||",C. Proof of Theorem 3.2,[0],[0]
"2 W (t+1)(D+A) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm ≤ ||Z(t+ 1)− Z(t)||2J(t+1) + ||f̂(t+ 1)− f̂ ∗||22(W (t+1)−θI)(D−A)+2Dm (55)
",C. Proof of Theorem 3.2,[0],[0]
"Substituting f̂1 with f̂(t+ 1) and f̂2 with f̂∗ and the gradient difference from (34) in (49) leads to:
〈f̂(t+ 1)− f̂∗, √ D −A(Y (t+ 1)− Y ∗)〉F",C. Proof of Theorem 3.2,[0],[0]
"+ 〈f̂(t+ 1)− f̂∗,W (t+ 1)(D +",C. Proof of Theorem 3.2,[0],[0]
"A)(f̂(t+ 1)− f̂(t))〉F
+〈f̂(t+ 1)− f̂∗, (W (t+ 1)− θI)(D −A)f̂(t+ 1)〉F ≤",C. Proof of Theorem 3.2,[0],[0]
"−〈f̂(t+ 1)− f̂∗, Dm(f̂(t+ 1)− f̂∗)〉F
Similar to the proof of Theorem 3.1, using the definition of Z(t+ 1), Z∗, J(t+ 1) and (D −A)f̂∗ = 0, there is:
||Z(t+ 1)− Z∗||2J(t+1) ≤ −||Z(t+",C. Proof of Theorem 3.2,[0],[0]
1)− Z(t)|| 2 J(t+1) + ||Z(t)− Z ∗||2J(t+1),C. Proof of Theorem 3.2,[0],[0]
"− ||f̂(t+ 1)− f̂ ∗||22Dm+2(W (t+1)−θI)(D−A)
(56)
",C. Proof of Theorem 3.2,[0],[0]
"Sum up (55) and (56) gives:
(1 + δ(t+ 1))||Z(t+ 1)− Z∗||2J(t+1) ≤ ||Z(t)−",C. Proof of Theorem 3.2,[0],[0]
"Z ∗||2J(t+1)
",C. Proof of Theorem 3.2,[0],[0]
"Let mo = mini∈N {mi}, MO = maxi∈N {Mi}.",C. Proof of Theorem 3.2,[0],[0]
"One δ(t+ 1) that satisfies (53) and (54) could be:
min{θσmin(D −A) µ2σ̃max(t+",C. Proof of Theorem 3.2,[0],[0]
"1) , 2mo + 2σ̄min(t+ 1) µ2M2O+µσ̄max(t+1) 2
θσmin(D−A)(µ−1) + σ̃max(t+ 1) }",C. Proof of Theorem 3.2,[0],[0]
"In the following proof, use the uppercase letters and lowercase letters to denote random variables and the corresponding realizations.
",D. Proof of Theorem 4.1,[0],[0]
"Since the modified ADMM is randomized, denote Fi(t) as the random variable of the result that node i broadcasts in t-th iteration, of which the realization is fi(t).",D. Proof of Theorem 4.1,[0],[0]
"Define F (t) = {Fi(t)}Ni=1 whose realization is {fi(t)}Ni=1.
",D. Proof of Theorem 4.1,[0],[0]
"Let FF (0:t)(·) be the joint probability distribution of F (0 : t) = {F (r)}tr=0, and FF (t)(·) be the distribution of F (t), by chain rule:
FF (0:T )({f(r)}Tr=0) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0:T−1)({f(r)}T−1r=0 ) ·FF (T )(f(T )|{f(r)} T−1 r=0 ) = · · ·
= FF (0)(f(0)) · T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0)
For two neighboring datasets Dall and D̂all of the network, the ratio of joint probabilities is given by:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) =",D. Proof of Theorem 4.1,[0],[0]
FF (0)(f(0)|Dall) FF (0)(f(0)|D̂all) · T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
"FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all)
(57)
Since fi(0) is randomly selected for all i, which is independent of dataset, there is FF (0)(f(0)|Dall) =",D. Proof of Theorem 4.1,[0],[0]
"FF (0)(f(0)|D̂all).
",D. Proof of Theorem 4.1,[0],[0]
"First only consider t-th iteration, since the primal variable is updated according to (25), by KKT optimality condition, ∇fiL priv i (t)|fi=fi(t) = 0, implies:
i(t) =",D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 yni L ′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i −
1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
"+ 2λi(t− 1))
",D. Proof of Theorem 4.1,[0],[0]
− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)),D. Proof of Theorem 4.1,[0],[0]
"(58)
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, Fi(t) and Ei(t) will be bijective:
• For any Fi(t) with the realization fi(t), ∃ an unique Ei(t) = i(t) having the form of (58) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"• Since the Lagrangian Lprivi (t) is strictly convex (by Assumption 4,5), its minimizer is unique, implies that for any Ei(t) with the realization i(t), ∃ an unique Fi(t) = fi(t) such that the KKT condition holds.
",D. Proof of Theorem 4.1,[0],[0]
"Since each node i generates i(t) independently, fi(t) is also independent from each other.",D. Proof of Theorem 4.1,[0],[0]
"Let FFi(t)(·) be the distribution of Fi(t), there is:
FF (t)(f(t)|{f(r)}t−1r=0, Dall) FF (t)(f(t)|{f(r)}t−1r=0, D̂all) = N∏ v=1 FFv(t)(fv(t)|{fv(r)} t−1 r=0, Dv) FFv(t)(fv(t)|{fv(r)} t−1 r=0, D̂v) = FFi(t)(fi(t)|{fi(r)}",D. Proof of Theorem 4.1,[0],[0]
"t−1 r=0, Di) FFi(t)(fi(t)|{fi(r)} t−1 r=0, D̂i)
(59)
",D. Proof of Theorem 4.1,[0],[0]
"Since two neighboring datasets Dall and D̂all only have at most one data point that is different, the second equality holds is because of the fact that this different data point could only be possessed by one node, say node i.",D. Proof of Theorem 4.1,[0],[0]
"Then there is Dj = D̂j for j 6= i.
",D. Proof of Theorem 4.1,[0],[0]
"Given {fi(r)}t−1r=0, let gt(·, Di) :",D. Proof of Theorem 4.1,[0],[0]
Rd → Rd denote the one-to-one mapping from Ei(t) to Fi(t) using dataset Di.,D. Proof of Theorem 4.1,[0],[0]
"Let FEi(t)(·) be the probability density of Ei(t), by Jacobian transformation, there is4:
FFi(t)(fi(t)|Di)",D. Proof of Theorem 4.1,[0],[0]
"= FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))| (60)
where g−1t (fi(t), Di) is the mapping from Fi(t) to Ei(t) using data Di as shown in (58) and J(g −1 t (fi(t), Di)) is the Jacobian matrix of it.
",D. Proof of Theorem 4.1,[0],[0]
"Without loss of generality, let Di and D̂i be only different in the first data point, say (x1i , y 1 i ) and (x̂ 1",D. Proof of Theorem 4.1,[0],[0]
"i , ŷ 1 i ) respectively.",D. Proof of Theorem 4.1,[0],[0]
"Then by (59)(60), (57) yields:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) = T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i)) ·",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))|
(61)
4We believe that there is a critical mistake in (Zhang & Zhu, 2017) and the original paper (Chaudhuri et al., 2011) where the objective perturbation method was proposed.",D. Proof of Theorem 4.1,[0],[0]
"A wrong mapping is used in both work:
FFi(t)(fi(t)|Di) = FEi(t)(g −1 t (fi(t), Di)) ·",D. Proof of Theorem 4.1,[0],[0]
"| det(J(g−1t (fi(t), Di)))|−1
Consider the first part, Ei(t) ∼ exp{−αi(t)|| ||}, let ̂i(t) = g−1t (fi(t), D̂i) and i(t) =",D. Proof of Theorem 4.1,[0],[0]
"g−1t (fi(t), Di)
T∏ t=1",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
= T∏ t=1,D. Proof of Theorem 4.1,[0],[0]
exp(αi(t)(||̂i(t)||,D. Proof of Theorem 4.1,[0],[0]
− || i(t)||)),D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 αi(t)||̂i(t)− i(t)||) (62)
",D. Proof of Theorem 4.1,[0],[0]
"By (58), Assumptions 4 and the facts that ||xni ||2 ≤ 1 (pre-normalization), yni ∈ {+1,−1}.
",D. Proof of Theorem 4.1,[0],[0]
"||̂i(t)− i(t)|| = 1
2ηi(t)Vi
C Bi · ||y1iL ′(y1i fi(t)Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x1i,D. Proof of Theorem 4.1,[0],[0]
− ŷ1iL ′(ŷ1i fi(t)T x̂1i ),D. Proof of Theorem 4.1,[0],[0]
"x̂1i || ≤
C
ηi(t)ViBi
(62) can be bounded: T∏ t=1 FEi(t)(g −1 t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
"FEi(t)(g −1 t (fi(t), D̂i))",D. Proof of Theorem 4.1,[0],[0]
"≤ exp( T∑ t=1 Cαi(t) ηi(t)ViBi ) (63)
Consider the second part, the Jacobian matrix J(g−1t (fi(t), Di)) is:
J(g−1t (fi(t), Di))",D. Proof of Theorem 4.1,[0],[0]
=,D. Proof of Theorem 4.1,[0],[0]
"− 1
2ηi(t)Vi
C
Bi Bi∑ n=1 L ′′(yni fi(t)",D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
i (x n i ) T,D. Proof of Theorem 4.1,[0],[0]
− 1 2ηi(t)Vi ρ N ∇2R(fi(t))−,D. Proof of Theorem 4.1,[0],[0]
"Id
Let G(t) =",D. Proof of Theorem 4.1,[0],[0]
C2ηi(t)ViBi (L ′′(ŷ1i fi(t) T x̂1i )x̂ 1,D. Proof of Theorem 4.1,[0],[0]
i (x̂ 1 i ) T −L ′′(y1i fi(t)Tx1i ),D. Proof of Theorem 4.1,[0],[0]
x1i (x1i )T ) and H(t) =,D. Proof of Theorem 4.1,[0],[0]
"−J(g −1 t (fi(t), Di)), there is:
|det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| = |det(H(t))| |det(H(t) +G(t))| =
1
|det(I +H(t)−1G(t))| =
1 | ∏r j=1(1 + λj(H(t) −1G(t)))|
where λj(H(t)−1G(t)) denotes the j-th largest eigenvalue of H(t)−1G(t).",D. Proof of Theorem 4.1,[0],[0]
"Since G(t) has rank at most 2, implies H(t)−1G(t) also has rank at most 2.
",D. Proof of Theorem 4.1,[0],[0]
"Because θ is determined such that 2c1 < BiC ( ρ N + 2θVi), and θ ≤ ηi(t) holds for all node i and iteration t, which implies:
c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
"< 1 2 (64)
",D. Proof of Theorem 4.1,[0],[0]
"By Assumptions 4 and 5, the eigenvalue of H(t) and G(t) satisfy:
λj(H(t))",D. Proof of Theorem 4.1,[0],[0]
"≥ ρ
2ηi(t)ViN + 1 > 0
",D. Proof of Theorem 4.1,[0],[0]
− Cc1 2ηi(t)ViBi ≤,D. Proof of Theorem 4.1,[0],[0]
λj(G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ Cc1 2ηi(t)ViBi
",D. Proof of Theorem 4.1,[0],[0]
"Implies:
− c1 Bi C ( ρ N + 2ηi(t)Vi)",D. Proof of Theorem 4.1,[0],[0]
≤ λj(H(t)−1G(t)),D. Proof of Theorem 4.1,[0],[0]
"≤ c1 Bi C ( ρ N + 2ηi(t)Vi)
",D. Proof of Theorem 4.1,[0],[0]
"By (64):
−1 2 ≤ λj(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 2
Since λmin(H(t)−1G(t))",D. Proof of Theorem 4.1,[0],[0]
"> −1, there is:
1 |1 + λmax(H(t)−1G(t))|2",D. Proof of Theorem 4.1,[0],[0]
"≤ 1 |det(I +H(t)−1G(t))| ≤ 1 |1 + λmin(H(t)−1G(t))|2
Therefore,
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤",D. Proof of Theorem 4.1,[0],[0]
"T∏ t=1
1
|1− c1Bi",D. Proof of Theorem 4.1,[0],[0]
"C ( ρ N +2ηi(t)Vi)
|2 = exp(− T∑ t=1 2 ln(1− c1 Bi C",D. Proof of Theorem 4.1,[0],[0]
( ρ N + 2ηi(t)Vi) )),D. Proof of Theorem 4.1,[0],[0]
"(65)
Since for any real number x ∈",D. Proof of Theorem 4.1,[0],[0]
"[0, 0.5], − ln(1 − x) < 1.4x.",D. Proof of Theorem 4.1,[0],[0]
"By condition (64), (65) can be bounded with a simper expression:
T∏ t=1 |det(J(g−1t (fi(t), Di)))| |det(J(g−1t (fi(t), D̂i)))| ≤ exp",D. Proof of Theorem 4.1,[0],[0]
( T∑ t=1 2.8c1 Bi C ( ρ N + 2ηi(t)Vi) ),D. Proof of Theorem 4.1,[0],[0]
≤ exp( T∑ t=1 1.4Cc1 ηi(t)ViBi ),D. Proof of Theorem 4.1,[0],[0]
"(66)
Combine (63)(66), (61) can be bounded:
FF (0:T )({f(r)}Tr=0|Dall) FF (0:T )({f(r)}Tr=0|D̂all) ≤ exp( T∑ t=1 ( 1.4Cc1 ηi(t)ViBi + Cαi(t) ηi(t)ViBi ))",D. Proof of Theorem 4.1,[0],[0]
"= exp( T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t)))
",D. Proof of Theorem 4.1,[0],[0]
"Therefore, the total privacy loss during T iterations can be bounded by any β:
β ≥ max i∈N { T∑ t=1
C
ηi(t)ViBi (1.4c1 + αi(t))}
E. Inference of Attackers when ηi(t) is Non-private By KKT optimality condition in each iteration, we have:
i(t) +",D. Proof of Theorem 4.1,[0],[0]
"1
2ηi(t)Vi
C Bi y1iL ′(y1i fi(t) Tx1i )",D. Proof of Theorem 4.1,[0],[0]
x 1,D. Proof of Theorem 4.1,[0],[0]
"i = −
1
2ηi(t)Vi
C
Bi",D. Proof of Theorem 4.1,[0],[0]
Bi∑ n=2 yni L ′(yni fi(t),D. Proof of Theorem 4.1,[0],[0]
Txni )x n,D. Proof of Theorem 4.1,[0],[0]
"i
− 1 2ηi(t)Vi ( ρ N ∇R(fi(t))",D. Proof of Theorem 4.1,[0],[0]
+,D. Proof of Theorem 4.1,[0],[0]
"2λi(t− 1))− 1 2Vi ∑ j∈Vi (2fi(t)− fi(t− 1)− fj(t− 1)) .
",D. Proof of Theorem 4.1,[0],[0]
In this case the attacker can compute the RHS of (67) completely.,D. Proof of Theorem 4.1,[0],[0]
"Furthermore, since Ei(t) is zero-mean, over a large number of iterations we will have 1T ∑T t=1 i(t)",D. Proof of Theorem 4.1,[0],[0]
"≈ 0 with high probability, which then allows the attacker to determine the features of the unknown individual up to a scaling factor, i.e., it can determine the second term on the LHS as a scalar multiplied with x1i .",D. Proof of Theorem 4.1,[0],[0]
"Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion.",abstractText,[0],[0]
During this iterative process the leakage of data privacy arises.,abstractText,[0],[0]
"A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process.",abstractText,[0],[0]
We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously.,abstractText,[0],[0]
The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size.,abstractText,[0],[0]
The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.,abstractText,[0],[0]
Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms ,title,[0],[0]
"Topic modeling algorithms, such as Latent Dirichlet Allocation (Blei et al., 2003) and related methods (Blei, 2012), are often used to learn a set of latent topics for a corpus, and predict the probabilities of each word in each document belonging to each topic (Teh et al., 2006; Newman et al., 2006; Toutanova and Johnson, 2008; Porteous et al., 2008; Johnson, 2010; Xie and Xing, 2013; Hingmire et al., 2013).
",1 Introduction,[0],[0]
Conventional topic modeling algorithms such as these infer document-to-topic and topic-to-word distributions from the co-occurrence of words within documents.,1 Introduction,[0],[0]
"But when the training corpus of documents is small or when the documents are short, the resulting distributions might be based on little evidence.",1 Introduction,[0],[0]
"Sahami and Heilman (2006) and Phan et al.
(2011) show that it helps to exploit external knowledge to improve the topic representations.",1 Introduction,[0],[0]
Sahami and Heilman (2006) employed web search results to improve the information in short texts.,1 Introduction,[0],[0]
"Phan et al. (2011) assumed that the small corpus is a sample of topics from a larger corpus like Wikipedia, and then use the topics discovered in the larger corpus to help shape the topic representations in the small corpus.",1 Introduction,[0],[0]
"However, if the larger corpus has many irrelevant topics, this will “use up” the topic space of the model.",1 Introduction,[0],[0]
"In addition, Petterson et al. (2010) proposed an extension of LDA that uses external information about word similarity, such as thesauri and dictionaries, to smooth the topic-to-word distribution.
",1 Introduction,[0],[0]
"Topic models have also been constructed using latent features (Salakhutdinov and Hinton, 2009; Srivastava et al., 2013; Cao et al., 2015).",1 Introduction,[0],[0]
"Latent feature (LF) vectors have been used for a wide range of NLP tasks (Glorot et al., 2011; Socher et al., 2013; Pennington et al., 2014).",1 Introduction,[0],[0]
"The combination of values permitted by latent features forms a high dimensional space which makes it is well suited to model topics of very large corpora.
",1 Introduction,[0],[0]
"Rather than relying solely on a multinomial or latent feature model, as in Salakhutdinov and Hinton (2009), Srivastava et al. (2013)",1 Introduction,[0],[0]
"and Cao et al. (2015), we explore how to take advantage of both latent feature and multinomial models by using a latent feature representation trained on a large external corpus to supplement a multinomial topic model estimated from a smaller corpus.
",1 Introduction,[0],[0]
"Our main contribution is that we propose two new latent feature topic models which integrate latent feature word representations into two Dirichlet
ar X
iv :1
81 0.
06 30
6v 1
[ cs
.C",1 Introduction,[0],[0]
"L
] 1
5 O
ct 2
multinomial topic models: a Latent Dirichlet Allocation (LDA) model (Blei et al., 2003) and a onetopic-per-document Dirichlet Multinomial Mixture (DMM) model (Nigam et al., 2000).",1 Introduction,[0],[0]
"Specifically, we replace the topic-to-word Dirichlet multinomial component which generates the words from topics in each Dirichlet multinomial topic model by a twocomponent mixture of a Dirichlet multinomial component and a latent feature component.
",1 Introduction,[0],[0]
"In addition to presenting a sampling procedure for the new models, we also compare using two different sets of pre-trained latent feature word vectors with our models.",1 Introduction,[0],[0]
"We achieve significant improvements on topic coherence evaluation, document clustering and document classification tasks, especially on corpora of short documents and corpora with few documents.",1 Introduction,[0],[0]
"The Latent Dirichlet Allocation (LDA) topic model (Blei et al., 2003) represents each document d as a probability distribution θd over topics, where each topic z is modeled by a probability distribution φz over words in a fixed vocabulary W .
",2.1 LDA model,[0],[0]
"As presented in Figure 1, where α and β are hyper-parameters and T is number of topics, the generative process for LDA is described as follows:
θd ∼ Dir(α) zdi ∼ Cat(θd) φz ∼ Dir(β) wdi ∼ Cat(φzdi )
where Dir and Cat stand for a Dirichlet distribution and a categorical distribution, and zdi is the topic indicator for the ith word wdi in document d. Here, the topic-to-word Dirichlet multinomial component generates the word wdi by drawing it from the categorical distribution Cat(φzdi ) for topic zdi .
",2.1 LDA model,[0],[0]
We follow the Gibbs sampling algorithm for estimating LDA topic models as described by Griffiths and Steyvers (2004).,2.1 LDA model,[0],[0]
"By integrating out θ and φ, the algorithm samples the topic zdi for the current i th
word wdi in document d using the conditional distribution P(zdi | Z¬di), where Z¬di denotes the topic assignments of all the other words in the document collection D, so:
P(zdi = t | Z¬di) ∝",2.1 LDA model,[0],[0]
"(N td¬i + α) N t,wdi ¬di +",2.1 LDA model,[0],[0]
"β
N t¬di + V β (",2.1 LDA model,[0],[0]
"1)
Notation: N t,wd is the rank-3 tensor that counts the number of times that word w is generated from topic t in document d by the Dirichlet multinomial component, which in section 2.1 belongs to the LDA model, while in section 2.2 belongs to the DMM model.",2.1 LDA model,[0],[0]
"When an index is omitted, it indicates summation over that index (so Nd is the number of words in document d).
",2.1 LDA model,[0],[0]
"We write the subscript ¬d for the document collection D with document d removed, and the subscript ¬di for D with just the ith word in document d removed, while the subscript d¬i represents document d without its ith word.",2.1 LDA model,[0],[0]
"For example, N t¬di is the number of words labelled a topic t, ignoring the ith word of document d. V is the size of the vocabulary, V = |W",2.1 LDA model,[0],[0]
|.,2.1 LDA model,[0],[0]
Applying topic models for short or few documents for text clustering is more challenging because of data sparsity and the limited contexts in such texts.,2.2 DMM model for short texts,[0],[0]
"One approach is to combine short texts into long pseudo-documents before training LDA (Hong and Davison, 2010; Weng et al., 2010; Mehrotra et al., 2013).",2.2 DMM model for short texts,[0],[0]
"Another approach is to assume that there is only one topic per document (Nigam et al., 2000; Zhao et al., 2011; Yin and Wang, 2014).
",2.2 DMM model for short texts,[0],[0]
"In the Dirichlet Multinomial Mixture (DMM) model (Nigam et al., 2000), each document is assumed to only have one topic.",2.2 DMM model for short texts,[0],[0]
"The process of generating a document d in the collection D, as shown in Figure 1, is to first select a topic assignment for the document, and then the topic-to-word Dirichlet multinomial component generates all the words in the document from the same selected topic:
θ ∼ Dir(α) zd ∼ Cat(θ) φz ∼ Dir(β) wdi ∼ Cat(φzd)
Yin and Wang (2014) introduced a collapsed Gibbs sampling algorithm for the DMM model in
which a topic zd is sampled for the document d using the conditional probability P(zd | Z¬d), where Z¬d denotes the topic assignments of all the other documents, so:
",2.2 DMM model for short texts,[0],[0]
P(zd = t | Z¬d) ∝,2.2 DMM model for short texts,[0],[0]
(Mt¬d + α) Γ(Nt¬d,2.2 DMM model for short texts,[0],[0]
"+ V β)
Γ(Nt¬d",2.2 DMM model for short texts,[0],[0]
"+Nd + V β) ∏ w∈W Γ(Nt,w¬d +N w d + β) Γ(Nt,w¬d + β) (2)
Notation: M t¬d is the number of documents assigned to topic t excluding the current document d; Γ is the Gamma function.",2.2 DMM model for short texts,[0],[0]
"Traditional count-based methods (Deerwester et al., 1990; Lund and Burgess, 1996; Bullinaria and Levy, 2007) for learning real-valued latent feature (LF) vectors rely on co-occurrence counts.",2.3 Latent feature vector models,[0],[0]
"Recent approaches based on deep neural networks learn vectors by predicting words given their window-based context (Collobert and Weston, 2008; Mikolov et al., 2013; Pennington et al., 2014; Liu et al., 2015).
",2.3 Latent feature vector models,[0],[0]
Mikolov et al. (2013)’s method maximizes the log likelihood of each word given its context.,2.3 Latent feature vector models,[0],[0]
Pennington et al. (2014) used back-propagation to minimize the squared error of a prediction of the logfrequency of context words within a fixed window of each word.,2.3 Latent feature vector models,[0],[0]
Word vectors can be trained directly on a new corpus.,2.3 Latent feature vector models,[0],[0]
"In our new models, however, in order to incorporate the rich information from very large datasets, we utilize pre-trained word vectors that were trained on external billion-word corpora.",2.3 Latent feature vector models,[0],[0]
"In this section, we propose two novel probabilistic topic models, which we call the LF-LDA and the LFDMM, that combine a latent feature model with either an LDA or DMM model.",3 New latent feature topic models,[0],[0]
"We also present Gibbs sampling procedures for our new models.
",3 New latent feature topic models,[0],[0]
"In general, LF-LDA and LF-DMM are formed by taking the original Dirichlet multinomial topic models LDA and DMM, and replacing their topic-to-
word Dirichlet multinomial component that generates words from topics with a two-component mixture of a topic-to-word Dirichlet multinomial component and a latent feature component.
",3 New latent feature topic models,[0],[0]
"Informally, the new models have the structure of the original Dirichlet multinomial topic models, as shown in Figure 2, with the addition of two matrices τ and ω of latent feature weights, where τ t and ωw are the latent-feature vectors associated with topic t and word w respectively.
",3 New latent feature topic models,[0],[0]
"Our latent feature model defines the probability that it generates a word given the topic as the categorical distribution CatE with:
CatE(w | τ tω>) = exp(τ t · ωw)∑
w′∈W exp(τ t · ωw′) (3)
CatE is a categorical distribution with log-space parameters, i.e. CatE(w | u) ∝ exp(uw).",3 New latent feature topic models,[0],[0]
"As τ t and ωw are (row) vectors of latent feature weights, so τ tω> is a vector of “scores” indexed by words.",3 New latent feature topic models,[0],[0]
"ω is fixed because we use pre-trained word vectors.
",3 New latent feature topic models,[0],[0]
"In the next two sections 3.1 and 3.2, we explain the generative processes of our new models LF-LDA and LF-DMM.",3 New latent feature topic models,[0],[0]
"We then present our Gibbs sampling procedures for the models LF-LDA and LF-DMM in the sections 3.3 and 3.4, respectively, and explain how we estimate τ in section 3.5.",3 New latent feature topic models,[0],[0]
"The LF-LDA model generates a document as follows: a distribution over topics θd is drawn for document d; then for each ith word wdi (in sequential order that words appear in the document), the model chooses a topic indicator zdi , a binary indicator variable sdi is sampled from a Bernoulli distribution to determine whether the word wdi is to be generated by the Dirichlet multinomial or latent feature component, and finally the word is generated from the chosen topic by the determined topic-toword model.",3.1 Generative process for the LF-LDA model,[0],[0]
"The generative process is:
θd ∼ Dir(α) zdi ∼ Cat(θd) φz ∼ Dir(β) sdi ∼ Ber(λ) wdi ∼ (1− sdi)Cat(φzdi ) + sdiCatE(τ zdi ω >)
where the hyper-parameter λ is the probability of a word being generated by the latent feature topic-toword model and Ber(λ) is a Bernoulli distribution with success probability λ.",3.1 Generative process for the LF-LDA model,[0],[0]
Our LF-DMM model uses the DMM model assumption that all the words in a document share the same topic.,3.2 Generative process for the LF-DMM model,[0],[0]
"Thus, the process of generating a document in a document collection with our LF-DMM is as follows: a distribution over topics θ is drawn for the document collection; then the model draws a topic indicator zd for the entire document d; for every ith word wdi in the document d, a binary indicator variable sdi is sampled from a Bernoulli distribution to determine whether the Dirichlet multinomial or latent feature component will be used to generate the word wdi , and finally the word is generated from the same topic zd by the determined component.",3.2 Generative process for the LF-DMM model,[0],[0]
"The generative process is summarized as:
θ ∼ Dir(α) zd ∼ Cat(θ) φz ∼ Dir(β) sdi ∼ Ber(λ) wdi ∼ (1− sdi)Cat(φzd) + sdiCatE(τ",3.2 Generative process for the LF-DMM model,[0],[0]
zd ω >),3.2 Generative process for the LF-DMM model,[0],[0]
"From the generative model of LF-LDA in Figure 2, by integrating out θ and φ, we use the Gibbs sampling algorithm (Robert and Casella, 2004) to perform inference to calculate the conditional topic assignment probabilities for each word.",3.3 Inference in LF-LDA model,[0],[0]
"The outline of the Gibbs sampling algorithm for the LF-LDA model is detailed in Algorithm 1.
",3.3 Inference in LF-LDA model,[0],[0]
"Algorithm 1: An approximate Gibbs sampling algorithm for the LF-LDA model
Initialize the word-topic variables zdi using the LDA sampling algorithm for iteration iter = 1, 2, ... do for topic t = 1, 2, ..., T do
τ",3.3 Inference in LF-LDA model,[0],[0]
"t = arg maxτ t P(τ t | Z,S) for document d = 1, 2, ..., |D| do
for word index i = 1, 2, ...,",3.3 Inference in LF-LDA model,[0],[0]
"Nd do sample zdi and sdi from P(zdi = t, sdi | Z¬di ,S¬di , τ ,ω)
Here, S denotes the distribution indicator variables for the whole document collection D. Instead of sampling τ",3.3 Inference in LF-LDA model,[0],[0]
"t from the posterior, we perform MAP estimation as described in the section 3.5.
",3.3 Inference in LF-LDA model,[0],[0]
"For sampling the topic zdi and the binary indicator variable sdi of the i
th word wdi in the document d, we integrate out sdi in order to sample zdi and then
sample sdi given zdi .",3.3 Inference in LF-LDA model,[0],[0]
"We sample the topic zdi using the conditional distribution as follows:
P(zdi = t | Z¬di , τ ,ω) ∝",3.3 Inference in LF-LDA model,[0],[0]
"(N td¬i +K
t d¬i + α)(
(1− λ) N t,wdi ¬di + β
N t¬di + V β +",3.3 Inference in LF-LDA model,[0],[0]
λCatE(wdi,3.3 Inference in LF-LDA model,[0],[0]
| τ t ω>) ),3.3 Inference in LF-LDA model,[0],[0]
"(4) Then we sample sdi conditional on zdi = t with:
P(sdi=s | zdi=t) ∝  (1− λ)N t,wdi ¬di +β Nt¬di",3.3 Inference in LF-LDA model,[0],[0]
+V β for s,3.3 Inference in LF-LDA model,[0],[0]
"= 0
λ CatE(wdi |τ t ω>)",3.3 Inference in LF-LDA model,[0],[0]
"for s = 1 (5)
Notation: Due to the new models’ mixture architecture, we separate out the counts for each of the two components of each model.",3.3 Inference in LF-LDA model,[0],[0]
"We define the rank3 tensor Kt,wd as the number of times a word w in document d is generated from topic t by the latent feature component of the generative LF-LDA or LFDMM model.
",3.3 Inference in LF-LDA model,[0],[0]
"We also extend the earlier definition of the tensor N t,wd as the number of times a word w in document d is generated from topic t by the Dirichlet multinomial component of our combined models, which in section 3.3 refers to the LF-LDA model, while in section 3.4 refers to the LF-DMM model.",3.3 Inference in LF-LDA model,[0],[0]
"For both tensors K and N , omitting an index refers to summation over that index and negation ¬ indicates exclusion as before.",3.3 Inference in LF-LDA model,[0],[0]
So Nwd +K w d is the total number of times the word type w appears in the document d.,3.3 Inference in LF-LDA model,[0],[0]
"For the LF-DMM model, we integrate out θ and φ, and then sample the topic zd and the distribution selection variables sd for document d using Gibbs sampling as outlined in Algorithm 2.
",3.4 Inference in LF-DMM model,[0],[0]
"Algorithm 2: An approximate Gibbs sampling algorithm for the LF-DMM model
Initialize the word-topic variables zdi using the DMM sampling algorithm for iteration iter = 1, 2, ... do for topic t = 1, 2, ..., T do
τ",3.4 Inference in LF-DMM model,[0],[0]
"t = arg maxτ t P(τ t | Z,S) for document d = 1, 2, ..., |D| do
sample zd and sd from P(zd = t, sd | Z¬d,S¬d, τ ,ω)
",3.4 Inference in LF-DMM model,[0],[0]
"As before in Algorithm 1, we also use MAP estimation of τ as detailed in section 3.5 rather than
sampling from the posterior.",3.4 Inference in LF-DMM model,[0],[0]
"The conditional distribution of topic variable and selection variables for document d is:
P(zd = t, sd | Z¬d,S¬d, τ ,ω)
∝",3.4 Inference in LF-DMM model,[0],[0]
"λKd (1− λ)Nd (M t¬d + α) Γ(N t¬d + V β)
Γ(N t¬d",3.4 Inference in LF-DMM model,[0],[0]
+,3.4 Inference in LF-DMM model,[0],[0]
"Nd + V β)∏ w∈W Γ(N t,w¬d +N w d + β) Γ(N t,w¬d + β) ∏ w∈W",3.4 Inference in LF-DMM model,[0],[0]
CatE(w | τ t ω>)K,3.4 Inference in LF-DMM model,[0],[0]
"w d (6)
Unfortunately the ratios of Gamma functions makes it difficult to integrate out sd in this distribution P. As zd and sd are not independent, it is computationally expensive to directly sample from this distribution, as there are 2(N w d +K w d ) different values of sd.",3.4 Inference in LF-DMM model,[0],[0]
"So we approximate P with a distribution Q that factorizes across words as follows:
Q(zd = t, sd | Z¬d,S¬d, τ ,ω) ∝",3.4 Inference in LF-DMM model,[0],[0]
"λKd (1− λ)Nd (M t¬d + α) (7)∏
w∈W
( N t,w¬d + β
N t¬d + V β )",3.4 Inference in LF-DMM model,[0],[0]
Nwd ∏,3.4 Inference in LF-DMM model,[0],[0]
w∈W CatE(w | τ t ω>)K,3.4 Inference in LF-DMM model,[0],[0]
"w d
This simpler distribution Q can be viewed as an approximation to P in which the topic-word “counts” are “frozen” within a document.",3.4 Inference in LF-DMM model,[0],[0]
This approximation is reasonably accurate for short documents.,3.4 Inference in LF-DMM model,[0],[0]
This distribution Q simplifies the coupling between zd and sd.,3.4 Inference in LF-DMM model,[0],[0]
This enables us to integrate out sd in Q.,3.4 Inference in LF-DMM model,[0],[0]
"We first sample the document topic zd for document d using Q(zd), marginalizing over sd:
Q(zd = t | Z¬d, τ ,ω)
∝",3.4 Inference in LF-DMM model,[0],[0]
(M t¬d + α),3.4 Inference in LF-DMM model,[0],[0]
∏,3.4 Inference in LF-DMM model,[0],[0]
"w∈W
( (1− λ) N t,w ¬d +β
Nt¬d+V β
+ λ",3.4 Inference in LF-DMM model,[0],[0]
"CatE(w | τ t ω>)
)(Nwd +Kwd ) (8)
Then we sample the binary indicator variable sdi for each ith word wdi in document d conditional on zd = t from the following distribution:
Q(sdi=s | zd = t) ∝
{ (1− λ)N t,wdi ¬d +β
Nt¬d+V β for s = 0
λ CatE(wdi | τ t ω>) for s = 1 (9)",3.4 Inference in LF-DMM model,[0],[0]
"To estimate the topic vectors after each Gibbs sampling iteration through the data, we apply regularized maximum likelihood estimation.",3.5 Learning latent feature vectors for topics,[0],[0]
"Applying MAP estimation to learn log-linear models for topic models is also used in SAGE (Eisenstein et al., 2011) and SPRITE (Paul and Dredze, 2015).",3.5 Learning latent feature vectors for topics,[0],[0]
"How-
ever, unlike our models, those models do not use latent feature word vectors to characterize topic-word distributions.",3.5 Learning latent feature vectors for topics,[0],[0]
The negative log likelihood of the corpus L under our model factorizes topic-wise into factors Lt for each topic.,3.5 Learning latent feature vectors for topics,[0],[0]
"With L2 regularization1 for topic t, these are:
Lt = − ∑ w∈W Kt,w ( τ t · ωw − log ( ∑ w′∈W exp(τ t · ωw′) ))
",3.5 Learning latent feature vectors for topics,[0],[0]
"+ µ ‖ τ t ‖22 (10)
",3.5 Learning latent feature vectors for topics,[0],[0]
The MAP estimate of topic vectors τ t is obtained by minimizing the regularized negative log likelihood.,3.5 Learning latent feature vectors for topics,[0],[0]
"The derivative with respect to the jth element of the vector for topic t is: ∂Lt ∂τ t,j = − ∑ w∈W Kt,w ( ωw,j − ∑ w′∈W ωw′,jCatE(w ′",3.5 Learning latent feature vectors for topics,[0],[0]
"| τ tω>)
)",3.5 Learning latent feature vectors for topics,[0],[0]
"+ 2µτ t,j (11)
",3.5 Learning latent feature vectors for topics,[0],[0]
"We used L-BFGS2(Liu and Nocedal, 1989) to find the topic vector τ t that minimizes Lt.",3.5 Learning latent feature vectors for topics,[0],[0]
"To investigate the performance of our new LF-LDA and LF-DMM models, we compared their performance against baseline LDA and DMM models on topic coherence, document clustering and document classification evaluations.",4 Experiments,[0],[0]
"The topic coherence evaluation measures the coherence of topic-word associations, i.e. it directly evaluates how coherent the assignment of words to topics is.",4 Experiments,[0],[0]
"The document clustering and document classification tasks evaluate how useful the topics assigned to documents are in clustering and classification tasks.
",4 Experiments,[0],[0]
"Because we expect our new models to perform comparatively well in situations where there is little data about topic-to-word distributions, our experiments focus on corpora with few or short documents.",4 Experiments,[0],[0]
"We also investigated which values of λ perform well, and compared the performance when using two different sets of pre-trained word vectors in these new models.",4 Experiments,[0],[0]
"We experimented with two state-of-the-art sets of pre-trained word vectors here.
",4.1.1 Distributed word representations,[0],[0]
1The L2 regularizer constant was set to µ = 0.01.,4.1.1 Distributed word representations,[0],[0]
"2We used the L-BFGS implementation from the Mallet
toolkit (McCallum, 2002).
",4.1.1 Distributed word representations,[0],[0]
Google word vectors3 are pre-trained 300- dimensional vectors for 3 million words and phrases.,4.1.1 Distributed word representations,[0],[0]
"These vectors were trained on a 100 billion word subset of the Google News corpus by using the Google Word2Vec toolkit (Mikolov et al., 2013).",4.1.1 Distributed word representations,[0],[0]
Stanford vectors4 are pre-trained 300-dimensional vectors for 2 million words.,4.1.1 Distributed word representations,[0],[0]
"These vectors were learned from 42-billion tokens of Common Crawl web data using the Stanford GloVe toolkit (Pennington et al., 2014).
",4.1.1 Distributed word representations,[0],[0]
"We refer to our LF-LDA and LF-DMM models using Google and Stanford word vectors as w2v-LDA, glove-LDA, w2v-DMM and glove-DMM.",4.1.1 Distributed word representations,[0],[0]
"We conducted experiments on the 20-Newsgroups dataset, the TagMyNews news dataset and the Sanders Twitter corpus.
",4.1.2 Experimental datasets,[0],[0]
"The 20-Newsgroups dataset5 contains about 19,000 newsgroup documents evenly grouped into 20 different categories.",4.1.2 Experimental datasets,[0],[0]
The TagMyNews news dataset6,4.1.2 Experimental datasets,[0],[0]
"(Vitale et al., 2012) consists of about 32,600 English RSS news items grouped into 7 categories, where each news document has a news title and a short description.",4.1.2 Experimental datasets,[0],[0]
"In our experiments, we also used a news title dataset which consists of just the news titles from the TagMyNews news dataset.
",4.1.2 Experimental datasets,[0],[0]
"Each dataset was down-cased, and we removed non-alphabetic characters and stop-words found in the stop-word list in the Mallet toolkit (McCallum, 2002).",4.1.2 Experimental datasets,[0],[0]
"We also removed words shorter than 3 characters and words appearing less than 10 times in the 20-Newsgroups corpus, and under 5 times in the TagMyNews news and news titles datasets.",4.1.2 Experimental datasets,[0],[0]
"In addition, words not found in both Google and Stanford vector representations were also removed.7 We refer to the cleaned 20-Newsgroups, TagMyNews news
3 Download at: https://code.google.com/p/word2vec/ 4 Download at: http://www-nlp.stanford.edu/projects/glove/ 5We used the “all-terms” version of the 20-Newsgroups dataset available at http://web.ist.utl.pt/acardoso/datasets/ (Cardoso-Cachopo, 2007).
",4.1.2 Experimental datasets,[0],[0]
"6The TagMyNews news dataset is unbalanced, where the largest category contains 8,200 news items while the smallest category contains about 1,800 items.",4.1.2 Experimental datasets,[0],[0]
"Download at: http: //acube.di.unipi.it/tmn-dataset/
71366, 27 and 12 words were correspondingly removed out of the 20-Newsgroups, TagMyNews news and news title datasets.
and news title datasets as N20, TMN and TMNtitle, respectively.
",4.1.2 Experimental datasets,[0],[0]
We also performed experiments on two subsets of the N20 dataset.,4.1.2 Experimental datasets,[0],[0]
The N20short dataset consists of all documents from the N20 dataset with less than 21 words.,4.1.2 Experimental datasets,[0],[0]
"The N20small dataset contains 400 documents consisting of 20 randomly selected documents from each group of the N20 dataset.
",4.1.2 Experimental datasets,[0],[0]
"Finally, we also experimented on the publicly available Sanders Twitter corpus.8",4.1.2 Experimental datasets,[0],[0]
"This corpus consists of 5,512 Tweets grouped into four different topics (Apple, Google, Microsoft, and Twitter).",4.1.2 Experimental datasets,[0],[0]
"Due to restrictions in Twitter’s Terms of Service, the actual Tweets need to be downloaded using 5,512 Tweet IDs.",4.1.2 Experimental datasets,[0],[0]
There are 850 Tweets not available to download.,4.1.2 Experimental datasets,[0],[0]
"After removing the non-English Tweets, 3,115 Tweets remain.",4.1.2 Experimental datasets,[0],[0]
"In addition to converting into lowercase and removing non-alphabetic characters, words were normalized by using a lexical normalization dictionary for microblogs (Han et al., 2012).",4.1.2 Experimental datasets,[0],[0]
"We then removed stop-words, words shorter than 3 characters or appearing less than 3 times in the corpus.",4.1.2 Experimental datasets,[0],[0]
"The four words apple, google, microsoft and twitter were removed as these four words occur in every Tweet in the corresponding topic.",4.1.2 Experimental datasets,[0],[0]
"Moreover, words not found in both Google and Stanford vector lists were also removed.9",4.1.2 Experimental datasets,[0],[0]
"In all our experiments, after removing words from documents, any document with a zero word count was also removed from the corpus.",4.1.2 Experimental datasets,[0],[0]
"For the Twitter corpus, this resulted in just 2,520 remaining Tweets.",4.1.2 Experimental datasets,[0],[0]
"The hyper-parameter β used in baseline LDA and DMM models was set to 0.01, as this is a common setting in the literature (Griffiths and Steyvers,
8Download at: http://www.sananalytics.com/lab/index.php 9There are 91 removed words.
2004).",4.1.3 General settings,[0],[0]
"We set the hyper-parameter α = 0.1, as this can improve performance relative to the standard setting α = 50T , as noted by Lu et al. (2011) and Yin and Wang (2014).
",4.1.3 General settings,[0],[0]
We ran each baseline model for 2000 iterations and evaluated the topics assigned to words in the last sample.,4.1.3 General settings,[0],[0]
"For our models, we ran the baseline models for 1500 iterations, then used the outputs from the last sample to initialize our models, which we ran for 500 further iterations.
",4.1.3 General settings,[0],[0]
"We report the mean and standard deviation of the results of ten repetitions of each experiment (so the standard deviation is approximately 3 standard errors, or a 99% confidence interval).",4.1.3 General settings,[0],[0]
This section examines the quality of the topic-word mappings induced by our models.,4.2 Topic coherence evaluation,[0],[0]
"In our models, topics are distributions over words.",4.2 Topic coherence evaluation,[0],[0]
"The topic coherence evaluation measures to what extent the highprobability words in each topic are semantically coherent (Chang et al., 2009; Stevens et al., 2012).",4.2 Topic coherence evaluation,[0],[0]
"Newman et al. (2010), Mimno et al. (2011) and Lau et al. (2014) describe methods for automatically evaluating the semantic coherence of sets of words.",4.2.1 Quantitative analysis,[0],[0]
The method presented in Lau et al. (2014) uses the normalized pointwise mutual information (NPMI) score and has a strong correlation with humanjudged coherence.,4.2.1 Quantitative analysis,[0],[0]
A higher NPMI score indicates that the topic distributions are semantically more coherent.,4.2.1 Quantitative analysis,[0],[0]
"Given a topic t represented by its top-N topic words w1, w2, ..., wN , the NPMI score for t is:
NPMI-Score(t) = ∑
16i<j6N
log P(wi,wj)
P(wi)P(wj)
− log P(wi, wj) (12)
where the probabilities in equation (12) are derived from a 10-word sliding window over an external corpus.
",4.2.1 Quantitative analysis,[0],[0]
The NPMI score for a topic model is the average score for all topics.,4.2.1 Quantitative analysis,[0],[0]
"We compute the NPMI score based on top-15 most probable words of each topic and use the English Wikipedia10 of 4.6 million articles as our external corpus.
Figures 3 and 4 show NPMI scores computed for the LDA, w2v-LDA and glove-LDA models on the
10We used the Wikipedia-articles dump of July 8, 2014.
N20short dataset for 20 and 40 topics.",4.2.1 Quantitative analysis,[0],[0]
We see that λ = 1.0 gives the highest NPMI score.,4.2.1 Quantitative analysis,[0],[0]
"In other words, using only the latent feature model produces the most coherent topic distributions.
",4.2.1 Quantitative analysis,[0],[0]
"Tables 2, 3 and 4 present the NPMI scores produced by the models on the other experimental datasets, where we vary11 the number of topics in steps from 4 to 80.",4.2.1 Quantitative analysis,[0],[0]
"Tables 3 and 4 show that the DMM model performs better than the LDA model on
11 We perform with T",4.2.1 Quantitative analysis,[0],[0]
"= 6 on the N20 and N20small datasets as the 20-Newsgroups dataset could be also grouped into 6 larger topics instead of 20 fine-grained categories.
",4.2.1 Quantitative analysis,[0],[0]
"the TMN, TMNtitle and Twitter datasets.",4.2.1 Quantitative analysis,[0],[0]
"These results show that our latent feature models produce significantly higher scores than the baseline models on all the experimental datasets.
",4.2.1 Quantitative analysis,[0],[0]
"Google word2vec vs. Stanford glove word vectors: In general, our latent feature models obtain competitive NPMI results in using pre-trained Google word2vec and Stanford glove word vectors for a large value of T , for example T = 80.",4.2.1 Quantitative analysis,[0],[0]
"With small values of T , for example T ≤ 7 , using Google word vectors produces better scores than using Stanford word vectors on the small N20small dataset of normal texts and on the short text TMN and TMNtitle datasets.",4.2.1 Quantitative analysis,[0],[0]
"However, the opposite pattern holds on the full N20 dataset.",4.2.1 Quantitative analysis,[0],[0]
Both sets of the pre-trained word vectors produce similar scores on the small and short Twitter dataset.,4.2.1 Quantitative analysis,[0],[0]
This section provides an example of how our models improve topic coherence.,4.2.2 Qualitative analysis,[0],[0]
"Table 5 compares the top15 words12 produced by the baseline DMM model
12In the baseline model, the top-15 topical words output from the 1500th sample are similar to top-15 words from the 2000th
and our w2v-DMM model with λ = 1.0 on the TMNtitle dataset with T = 20 topics.
",4.2.2 Qualitative analysis,[0],[0]
"In table 5, topic 1 of the DMM model consists of words related to “nuclear crisis in Japan” together with other unrelated words.",4.2.2 Qualitative analysis,[0],[0]
"The w2v-DMM model produced a purer topic 1 focused on “Japan earthquake and nuclear crisis,” presumably related to the “Fukushima Daiichi nuclear disaster.”",4.2.2 Qualitative analysis,[0],[0]
Topic 3 is about “oil prices” in both models.,4.2.2 Qualitative analysis,[0],[0]
"However, all top15 words are qualitatively more coherent in the w2vDMM model.",4.2.2 Qualitative analysis,[0],[0]
"While topic 4 of the DMM model is difficult to manually label, topic 4 of the w2v-DMM model is about the “Arab Spring” event.
",4.2.2 Qualitative analysis,[0],[0]
"Topics 5, 19 and 14 of the DMM model are not easy to label.",4.2.2 Qualitative analysis,[0],[0]
"Topic 5 relates to “entertainment”, topic 19 is generally a mixture of “entertainment” and “sport”, and topic 14 is about “sport” and “politics.”",4.2.2 Qualitative analysis,[0],[0]
"However, the w2v-DMM model more clearly distinguishes these topics: topic 5 is about “entertainment”, topic 19 is only about “sport” and topic 14 is only about “politics.”",4.2.2 Qualitative analysis,[0],[0]
We compared our models to the baseline models in a document clustering task.,4.3 Document clustering evaluation,[0],[0]
"After using a topic model to calculate the topic probabilities of a document, we assign every document the topic with the highest probability given the document (Cai et al., 2008; Lu et al., 2011; Xie and Xing, 2013; Yan et al., 2013).",4.3 Document clustering evaluation,[0],[0]
"We use two common metrics to evaluate clustering performance: Purity and normalized mutual information (NMI): see (Manning et al., 2008, Section 16.3) for details of these evaluations.",4.3 Document clustering evaluation,[0],[0]
"Purity and NMI scores always range from 0.0 to 1.0, and higher scores reflect better clustering performance.
",4.3 Document clustering evaluation,[0],[0]
"Figures 5 and 6 present Purity and NMI results obtained by the LDA, w2v-LDA and glove-LDA models on the N20short dataset with the numbers of topics T set to either 20 or 40, and the value of the mixture weight λ varied from 0.0 to 1.0.
",4.3 Document clustering evaluation,[0],[0]
"We found that setting λ to 1.0 (i.e. using only the latent features to model words), the glove-LDA produced 1%+ higher scores on both Purity and NMI results than the w2v-LDA when using 20 topics.",4.3 Document clustering evaluation,[0],[0]
"However, the two models glove-LDA and w2v-LDA returned equivalent results with 40 topics where they
sample if we do not take the order of the most probable words into account.
gain 2%+ absolute improvement13 on the two Purity and NMI against the baseline LDA model.
",4.3 Document clustering evaluation,[0],[0]
"By varying λ, as shown in Figures 5 and 6, the w2v-LDA and glove-LDA models obtain their best results at λ = 0.6 where the w2v-LDA model does slightly better than the glove-LDA.",4.3 Document clustering evaluation,[0],[0]
"Both models sig-
13Using the Student’s t-Test, the improvement is significant (p < 0.01).
nificantly outperform their baseline LDA models; for example with 40 topics, the w2v-LDA model attains 4.4% and 4.3% over the LDA model on Purity and NMI metrics, respectively.
",4.3 Document clustering evaluation,[0],[0]
"We fix the mixture weight λ at 0.6, and report experimental results based on this value for the rest of this section.",4.3 Document clustering evaluation,[0],[0]
"Tables 6, 7 and 8 show clustering results produced by our models and the baseline models on the remaining datasets with different numbers
of topics.",4.3 Document clustering evaluation,[0],[0]
"As expected, the DMM model is better than the LDA model on the short datasets of TMN, TMNtitle and Twitter.",4.3 Document clustering evaluation,[0],[0]
"For example with 80 topics on the TMNtitle dataset, the DMM achieves about 7+% higher Purity and NMI scores than LDA.
",4.3 Document clustering evaluation,[0],[0]
"New models vs. baseline models: On most tests, our models score higher than the baseline models, particularly on the small N20small dataset where we get 6.0% improvement on NMI at T = 6, and on the short text TMN and TMNtitle datasets we obtain 6.1% and 2.5% higher Purity at T = 80.",4.3 Document clustering evaluation,[0],[0]
"In addition, on the short and small Twitter dataset with T = 4, we achieve 3.9% and 5.3% improvements in Purity and NMI scores, respectively.",4.3 Document clustering evaluation,[0],[0]
"Those results show that an improved model of topic-word mappings also
improves the document-topic assignments.",4.3 Document clustering evaluation,[0],[0]
"For the small value of T ≤ 7, on the large datasets of N20, TMN and TMNtitle, our models and baseline models obtain similar clustering results.",4.3 Document clustering evaluation,[0],[0]
"However, with higher values of T , our models perform better than the baselines on the short TMN and TMNtitle datasets, while on the N20 dataset, the baseline LDA model attains a slightly higher clustering results than ours.",4.3 Document clustering evaluation,[0],[0]
"In contrast, on the short and small Twitter dataset, our models obtain considerably better clustering results than the baseline models with a small value of T .
",4.3 Document clustering evaluation,[0],[0]
"Google word2vec vs. Stanford glove word vectors: On the small N20short and N20small datasets, using the Google pre-trained word vectors produces
higher clustering scores than using Stanford pretrained word vectors.",4.3 Document clustering evaluation,[0],[0]
"However, on the large datasets N20, TMN and TMNtitle, using Stanford word vectors produces higher scores than using Google word vectors when using a smaller number of topics, for example T ≤ 20.",4.3 Document clustering evaluation,[0],[0]
"With more topics, for instance T = 80, the pre-trained Google and Stanford word vectors produce similar clustering results.",4.3 Document clustering evaluation,[0],[0]
"In addition, on the Twitter dataset, both sets of pre-trained word vectors produce similar results.",4.3 Document clustering evaluation,[0],[0]
"Unlike the document clustering task, the document classification task evaluates the distribution over topics for each document.",4.4 Document classification evaluation,[0],[0]
"Following Lacoste-Julien et al. (2009), Lu et al. (2011), Huh and Fienberg (2012) and Zhai and Boyd-graber (2013), we used Support Vector Machines (SVM) to predict the ground truth labels from the topic-proportion vector of each document.",4.4 Document classification evaluation,[0],[0]
"We used the WEKA’s implementation (Hall et al., 2009) of the fast Sequential Minimal Optimization algorithm (Platt, 1999) for learning a classifier with ten-fold cross-validation and WEKA’s default parameters.",4.4 Document classification evaluation,[0],[0]
"We present the macroaveraged F1 score (Manning et al., 2008, Section 13.6) as the evaluation metric for this task.
",4.4 Document classification evaluation,[0],[0]
"Just as in the document clustering task, the mixture weight λ = 0.6 obtains the highest classification performances on the N20short dataset.",4.4 Document classification evaluation,[0],[0]
"For example with T = 40, our w2v-LDA and gloveLDA obtain F1 scores at 40.0% and 38.9% which are 4.5% and 3.4% higher than F1 score at 35.5% obtained by the LDA model, respectively.
",4.4 Document classification evaluation,[0],[0]
"We report classification results on the remaining experimental datasets with mixture weight λ = 0.6 in tables 9, 10 and 11.",4.4 Document classification evaluation,[0],[0]
"Unlike the clustering results, the LDA model does better than the DMM model for classification on the TMN dataset.
",4.4 Document classification evaluation,[0],[0]
"New models vs. baseline models: On most eval-
uations, our models perform better than the baseline models.",4.4 Document classification evaluation,[0],[0]
"In particular, on the small N20small and Twitter datasets, when the number of topics T is equal to number of ground truth labels (i.e. 20 and 4 correspondingly), our w2v-LDA obtains 5+% higher F1 score than the LDA model.",4.4 Document classification evaluation,[0],[0]
"In addition, our w2v-DMM model achieves 5.4% and 2.9% higher F1 score than the DMM model on short TMN and TMNtitle datasets with T = 80, respectively.
",4.4 Document classification evaluation,[0],[0]
Google word2vec vs. Stanford glove word vectors: The comparison of the Google and Stanford pre-trained word vectors for classification is similar to the one for clustering.,4.4 Document classification evaluation,[0],[0]
"We found that the topic coherence evaluation produced the best results with a mixture weight λ = 1, which corresponds to using topic-word distributions defined in terms of the latent-feature word vectors.",4.5 Discussion,[0],[0]
"This is not surprising, since the topic coherence evaluation we used (Lau et al., 2014) is based on word co-occurrences in an external corpus (here, Wikipedia), and it is reasonable that the billion-word corpora used to train the latent feature word vectors are more useful for this task than the much smaller topic-modeling corpora, from which the topic-word multinomial distributions are trained.
",4.5 Discussion,[0],[0]
"On the other hand, the document clustering and document classification tasks depend more strongly on possibly idiosyncratic properties of the smaller topic-modeling corpora, since these evaluations reflect how well the document-topic assignments can group or distinguish documents within the topicmodeling corpus.",4.5 Discussion,[0],[0]
"Smaller values of λ enable the models to learn topic-word distributions that include an arbitrary multinomial topic-word distribution, enabling the models to capture idiosyncratic properties of the topic-modeling corpus.",4.5 Discussion,[0],[0]
"Even in these evaluations we found that an intermediate value of λ = 0.6 produced the best results, indicating that better word-topic distributions were produced when information from the large external corpus is combined with corpus-specific topic-word multinomials.",4.5 Discussion,[0],[0]
"We found that using the latent feature word vectors produced significant performance improvements even when the domain of the topic-modeling corpus was quite different to that of the external corpus from which the word vectors were derived, as was the case in our experiments on Twitter data.
",4.5 Discussion,[0],[0]
We found that using either the Google or the Stanford latent feature word vectors produced very similar results.,4.5 Discussion,[0],[0]
"As far as we could tell, there is no reason to prefer either one of these in our topic modeling applications.",4.5 Discussion,[0],[0]
"In this paper, we have shown that latent feature representations can be used to improve topic models.",5 Conclusion and future work,[0],[0]
"We proposed two novel latent feature topic models, namely LF-LDA and LF-DMM, that integrate a latent feature model within two topic models LDA and DMM.",5 Conclusion and future work,[0],[0]
"We compared the performance of our models LF-LDA and LF-DMM to the baseline LDA and DMM models on topic coherence, document clustering and document classification evaluations.",5 Conclusion and future work,[0],[0]
"In the topic coherence evaluation, our model outperformed the baseline models on all 6 experimental datasets, showing that our method for exploiting external information from very large corpora helps improve the topic-to-word mapping.",5 Conclusion and future work,[0],[0]
"Meanwhile, document clustering and document classification results show that our models improve the document-topic assignments compared to the baseline models, especially on datasets with few or short documents.
",5 Conclusion and future work,[0],[0]
"As an anonymous reviewer suggested, it would be interesting to identify exactly how the latent feature word vectors improve topic modeling performance.",5 Conclusion and future work,[0],[0]
"We believe that they provide useful information about word meaning extracted from the large corpora that they are trained on, but as the reviewer suggested, it is possible that the performance improvements arise because the word vectors are trained on context windows of size 5 or 10, while the LDA and DMM models view documents as bags of words, and effectively use a context window that encompasses the entire document.",5 Conclusion and future work,[0],[0]
"In preliminary experiments where we train latent feature word vectors from the topic-modeling corpus alone using context windows of size 10 we found that performance was degraded relative to the results presented here, suggesting that the use of a context window alone is not responsible for the performance improvements we reported here.",5 Conclusion and future work,[0],[0]
"Clearly it would be valuable to investigate this further.
",5 Conclusion and future work,[0],[0]
"In order to use a Gibbs sampler in section 3.4, the conditional distributions needed to be distributions we can sample from cheaply, which is not the case for the ratios of Gamma functions.",5 Conclusion and future work,[0],[0]
"While we used a simple approximation, it is worth exploring other sampling techniques that can avoid approximations, such as Metropolis-Hastings sampling (Bishop, 2006, Section 11.2.2).
",5 Conclusion and future work,[0],[0]
"In order to compare the pre-trained Google and Stanford word vectors, we excluded words that did not appear in both sets of vectors.",5 Conclusion and future work,[0],[0]
"As suggested by anonymous reviewers, it would be interesting to learn vectors for these unseen words.",5 Conclusion and future work,[0],[0]
"In addition, it is worth fine-tuning the seen-word vectors on the dataset of interest.
",5 Conclusion and future work,[0],[0]
"Although we have not evaluated our approach on very large corpora, the corpora we have evaluated on do vary in size, and we showed that the gains from our approach are greatest when the corpora are small.",5 Conclusion and future work,[0],[0]
A drawback of our approach is that it is slow on very large corpora.,5 Conclusion and future work,[0],[0]
"Variational Bayesian inference may provide an efficient solution to this problem (Jordan et al., 1999; Blei et al., 2003).",5 Conclusion and future work,[0],[0]
"This research was supported by a Google award through the Natural Language Understanding
Focused Program, and under the Australian Research Council’s Discovery Projects funding scheme (project numbers DP110102506 and DP110102593).",Acknowledgments,[0],[0]
"The authors would like to thank the three anonymous reviewers, the action editor and Dr. John Pate at the Macquarie University, Australia for helpful comments and suggestions.",Acknowledgments,[0],[0]
"Probabilistic topic models are widely used to discover latent topics in document collections, while latent feature vector representations of words have been used to obtain high performance in many NLP tasks.",abstractText,[0],[0]
"In this paper, we extend two different Dirichlet multinomial topic models by incorporating latent feature vector representations of words trained on very large corpora to improve the word-topic mapping learnt on a smaller corpus.",abstractText,[0],[0]
"Experimental results show that by using information from the external corpora, our new models produce significant improvements on topic coherence, document clustering and document classification tasks, especially on datasets with few or short documents.",abstractText,[0],[0]
Improving Topic Models with Latent Feature Word Representations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 862–868 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
862",text,[0],[0]
Building a machine translation (MT) system requires lots of bilingual data.,1 Introduction,[0],[0]
"Neural MT models (Bahdanau et al., 2015), which become the current standard, are even more difficult to train without huge bilingual supervision (Koehn and Knowles, 2017).",1 Introduction,[0],[0]
"However, bilingual resources are still limited to some of the selected language pairs—mostly from or to English.
",1 Introduction,[0],[0]
A workaround for zero-resource language pairs is translating via an intermediate (pivot) language.,1 Introduction,[0],[0]
"To do so, we need to collect parallel data and train MT models for source-to-pivot and pivot-to-target individually; it takes a double effort and the decoding is twice as slow.
",1 Introduction,[0],[0]
"Unsupervised learning is another alternative, where we can train an MT system with only monolingual corpora.",1 Introduction,[0],[0]
"Decipherment methods (Ravi and Knight, 2011; Nuhn et al., 2013) are the first work in this direction, but they often suffer from a huge latent hypothesis space (Kim et al., 2017).
",1 Introduction,[0],[0]
Recent work by Artetxe et al. (2018) and Lample et al. (2018) train sequence-to-sequence MT models of both translation directions together in an unsupervised way.,1 Introduction,[0],[0]
"They do back-translation (Sennrich et al., 2016a) back and forth for every iteration or batch, which needs an immensely long time and careful tuning of hyperparameters for massive monolingual data.
",1 Introduction,[0],[0]
"Here we suggest rather simple methods to build an unsupervised MT system quickly, based on word translation using cross-lingual word embeddings.",1 Introduction,[0],[0]
"The contributions of this paper are:
• We formulate a straightforward way to combine a language model with cross-lingual word similarities, effectively considering context in lexical choices.
",1 Introduction,[0],[0]
"• We develop a postprocessing method for word-by-word translation outputs using a denoising autoencoder, handling local reordering and multi-aligned words.
",1 Introduction,[0],[0]
"• We analyze the effect of different artificial noises for the denoising model and propose a novel noise type.
",1 Introduction,[0],[0]
"• We verify that cross-lingual embedding on subword units performs poorly in translation.
",1 Introduction,[0],[0]
"• We empirically show that cross-lingual mapping can be learned using a small vocabulary without losing the translation performance.
",1 Introduction,[0],[0]
"The proposed models can be efficiently trained with off-the-shelf softwares with little or no changes in the implementation, using only monolingual data.",1 Introduction,[0],[0]
The provided analyses help for better learning of cross-lingual word embeddings for translation purpose.,1 Introduction,[0],[0]
"Altogether, our unsupervised MT system outperforms the sequence-to-sequence neural models even without training signals from the opposite translation direction, i.e. via backtranslation.",1 Introduction,[0],[0]
"As a basic step for unsupervised MT, we learn a word translation model from monolingual corpora of each language.",2 Cross-lingual Word Embedding,[0],[0]
"In this work, we exploit crosslingual word embedding for word-by-word translation, which is state-of-the-art in terms of type translation quality (Artetxe et al., 2017; Conneau et al., 2018).
",2 Cross-lingual Word Embedding,[0],[0]
Cross-lingual word embedding is a continuous representation of words whose vector space is shared across multiple languages.,2 Cross-lingual Word Embedding,[0],[0]
"This enables distance calculation between word embeddings across languages, which is actually finding translation candidates.
",2 Cross-lingual Word Embedding,[0],[0]
"We train cross-lingual word embedding in a fully unsupervised manner:
1.",2 Cross-lingual Word Embedding,[0],[0]
Learn monolingual source and target embeddings independently.,2 Cross-lingual Word Embedding,[0],[0]
"For this, we run skipgram algorithm augmented with character ngram (Bojanowski et al., 2017).
2.",2 Cross-lingual Word Embedding,[0],[0]
"Find a linear mapping from source embedding space to target embedding space by adversarial training (Conneau et al., 2018).",2 Cross-lingual Word Embedding,[0],[0]
"We do not pre-train the discriminator with a seed dictionary, and consider only the top Vcross-train words of each language as input to the discriminator.
",2 Cross-lingual Word Embedding,[0],[0]
"Once we have the cross-lingual mapping, we can transform the embedding of a given source word and find a target word with the closest embedding, i.e. nearest neighbor search.",2 Cross-lingual Word Embedding,[0],[0]
"Here, we apply cross-domain similarity local scaling (Conneau et al., 2018) to penalize the word similarities in dense areas of the embedding distribution.
",2 Cross-lingual Word Embedding,[0],[0]
"We further refine the mapping obtained from Step 2 as follows (Artetxe et al., 2017):
3.",2 Cross-lingual Word Embedding,[0],[0]
"Build a synthetic dictionary by finding mutual nearest neighbors for both translation directions in vocabularies of Vcross-train words.
4.",2 Cross-lingual Word Embedding,[0],[0]
"Run a Procrustes problem solver with the dictionary from Step 3 to re-train the mapping (Smith et al., 2017).
5.",2 Cross-lingual Word Embedding,[0],[0]
Repeat Step 3 and 4 for a fixed number of iterations to update the mapping further.,2 Cross-lingual Word Embedding,[0],[0]
"In translating sentences, cross-lingual word embedding has several drawbacks.",3 Sentence Translation,[0],[0]
We describe each of them and our corresponding solutions.,3 Sentence Translation,[0],[0]
The word translation using nearest neighbor search does not consider context around the current word.,3.1 Context-aware Beam Search,[0],[0]
"In many cases, the correct translation is not the nearest target word but other close words with morphological variations or synonyms, depending on the context.
",3.1 Context-aware Beam Search,[0],[0]
"The reasons are in two-fold: 1) Word embedding is trained to place semantically related words nearby, even though they have opposite meanings.",3.1 Context-aware Beam Search,[0],[0]
"2) A hubness problem of high-dimensional embedding space hinders a correct search, where lots of different words happen to be close to each other (Radovanović et al., 2010).
",3.1 Context-aware Beam Search,[0],[0]
"In this paper, we integrate context information into word-by-word translation by combining a language model (LM) with cross-lingual word embedding.",3.1 Context-aware Beam Search,[0],[0]
Let f be a source word in the current position and e a possible target word.,3.1 Context-aware Beam Search,[0],[0]
"Given a history h of target words before e, the score of e to be the translation of f would be:
L(e; f, h) = λemb log q(f, e) + λLM log p(e|h)
Here, q(f, e) is a lexical score defined as:
q(f, e) = d(f, e) + 1
2
where d(f, e) ∈",3.1 Context-aware Beam Search,[0],[0]
"[−1, 1] is a cosine similarity between f and e.",3.1 Context-aware Beam Search,[0],[0]
"It is transformed to the range [0, 1] to make it similar in scale with the LM probability.",3.1 Context-aware Beam Search,[0],[0]
"In our experiments, we found that this simple linear scaling is better than sigmoid or softmax functions in the final translation performance.
",3.1 Context-aware Beam Search,[0],[0]
"Accumulating the scores per position, we perform a beam search to allow only reasonable translation hypotheses.",3.1 Context-aware Beam Search,[0],[0]
"Even when we have correctly translated words for each position, the output is still far from an acceptable translation.",3.2 Denoising,[0],[0]
"We adopt sequence denoising autoencoder (Hill et al., 2016) to improve the translation output of Section 3.1.",3.2 Denoising,[0],[0]
"The main idea is to train a sequence-to-sequence neural network model that takes a noisy sentence as input and produces a (denoised) clean sentence as output, both of which are of the same (target) language.",3.2 Denoising,[0],[0]
"The model was originally proposed to learn sentence embeddings, but here we use it directly to actually remove noise in a sentence.
",3.2 Denoising,[0],[0]
"Training label sequences for the denoising network would be target monolingual sentences, but
we do not have their noisy versions at hand.",3.2 Denoising,[0],[0]
"Given a clean target sentence, the noisy input should be ideally word-by-word translation of the corresponding source sentence.",3.2 Denoising,[0],[0]
"However, such bilingual sentence alignment is not available in our unsupervised setup.
",3.2 Denoising,[0],[0]
"Instead, we inject artificial noise into a clean sentence to simulate the noise of word-by-word translation.",3.2 Denoising,[0],[0]
We design different noise types after the following aspects of word-by-word translation.,3.2 Denoising,[0],[0]
Word-by-word translation always outputs a target word for every position.,3.2.1 Insertion,[0],[0]
"However, there are a plenty of cases that multiple source words should be translated to a single target word, or that some source words are rather not translated to any word to make a fluent output.",3.2.1 Insertion,[0],[0]
"For example, a German sentence “Ich höre zu.” would be translated to “I’m listening to.”",3.2.1 Insertion,[0],[0]
"by a word-by-word translator, but “I’m listening.” is more natural in English (Figure 1).
",3.2.1 Insertion,[0],[0]
"We pretend to have extra target words which might be translation of redundant source words, by inserting random target words to a clean sentence:
1.",3.2.1 Insertion,[0],[0]
"For each position i, sample a probability pi ∼ Uniform(0, 1).
2.",3.2.1 Insertion,[0],[0]
"If pi < pins, sample a word e from the most frequent Vins target words and insert it before position i.
We limit the inserted words by Vins because target insertion occurs mostly with common words, e.g. prepositions or articles, as the example above.",3.2.1 Insertion,[0],[0]
"We insert words only before—not after—a position, since an extra word after the ending word (usually a punctuation) is not probable.",3.2.1 Insertion,[0],[0]
"Similarly, word-by-word translation cannot handle the contrary case: when a source word should be translated into more than one target words, or a
target word should be generated from no source words for fluency.",3.2.2 Deletion,[0],[0]
"For example, a German word “im” must be “in the” in English, but word translation generates only one of the two English words.",3.2.2 Deletion,[0],[0]
"Another example is shown in Figure 2.
",3.2.2 Deletion,[0],[0]
"To simulate such situations, we drop some words randomly from a clean target sentence (Hill et al., 2016):
1.",3.2.2 Deletion,[0],[0]
"For each position i, sample a probability pi ∼ Uniform(0, 1).
2.",3.2.2 Deletion,[0],[0]
"If pi < pdel, drop the word in the position i.",3.2.2 Deletion,[0],[0]
"Also, translations generated word-by-word are not in an order of the target language.",3.2.3 Reordering,[0],[0]
"In our beam search, LM only assists in choosing the right word in context but does not modify the word order.",3.2.3 Reordering,[0],[0]
"A common reordering problem of German→English is illustrated in Figure 3.
",3.2.3 Reordering,[0],[0]
"From a clean target sentence, we corrupt its word order by random permutations.",3.2.3 Reordering,[0],[0]
"We limit the maximum distance between an original position and its new position like Lample et al. (2018):
1.",3.2.3 Reordering,[0],[0]
"For each position i, sample an integer δi from [0, dper].
2.",3.2.3 Reordering,[0],[0]
"Add δi to index i and sort the incremented indices i+ δi in an increasing order.
3.",3.2.3 Reordering,[0],[0]
"Rearrange the words to be in the new positions, to which their original indices have moved by Step 2.
",3.2.3 Reordering,[0],[0]
"This is a generalized version of swapping two neighboring words (Hill et al., 2016).",3.2.3 Reordering,[0],[0]
"Reordering is highly dependent of each language, but we found that this noise is generally close to wordby-word translation outputs.
",3.2.3 Reordering,[0],[0]
"Insertion, deletion, and reordering noises were applied to each mini-batch with different random seeds, allowing the model to see various noisy versions of the same clean sentence over the epochs.
",3.2.3 Reordering,[0],[0]
Note that the deletion and permutation noises are integrated in the neural MT training of Artetxe et al. (2018) and Lample et al. (2018) as additional training objectives.,3.2.3 Reordering,[0],[0]
Whereas we optimize an independent model solely for denoising without architecture change.,3.2.3 Reordering,[0],[0]
It allows us to easily train a larger network with a larger data.,3.2.3 Reordering,[0],[0]
"Insertion noise is of our original design, which we found to be the most effective (Section 4.1).",3.2.3 Reordering,[0],[0]
We applied the proposed methods on WMT 2016 German↔English task and WMT 2014 French↔English task.,4 Experiments,[0],[0]
"For German/English, we trained word embeddings with 100M sentences sampled from News Crawl 2014-2017 monolingual corpora.",4 Experiments,[0],[0]
"For French, we used News Crawl 2007-2014 (around 42M sentences).",4 Experiments,[0],[0]
The data was lowercased and filtered to have a maximum sentence length 100.,4 Experiments,[0],[0]
German compound words were splitted beforehand.,4 Experiments,[0],[0]
Numbers were replaced with category labels and recovered back after decoding by looking at the source sentence.,4 Experiments,[0],[0]
"Also, frequent casing was applied to the translation output.
",4 Experiments,[0],[0]
"fasttext (Bojanowski et al., 2017) was used to learn monolingual embeddings for only the words with minimum count 10.",4 Experiments,[0],[0]
"MUSE (Conneau et al., 2018) was used for cross-lingual mappings with Vcross-train = 100k and 10 refinement iterations
(Step 3-5 in Section 2).",4 Experiments,[0],[0]
Other parameters follow the values in Conneau et al. (2018).,4 Experiments,[0],[0]
"With the same data, we trained 5-gram count-based LMs using KenLM (Heafield, 2011) with its default setting.
",4 Experiments,[0],[0]
"Denoising autoencoders were trained using Sockeye (Hieber et al., 2017) on News Crawl 2016 for German/English and News Crawl 2014 for French.",4 Experiments,[0],[0]
We considered only top 50k frequent words for each language and mapped other words to <unk>.,4 Experiments,[0],[0]
"The unknowns in the denoised output were replaced with missing words from the noisy input by a simple line search.
",4 Experiments,[0],[0]
"We used 6-layer Transformer encoder/decoder (Vaswani et al., 2017) for denoisers, with embedding/hidden layer size 512, feedforward sublayer size 2048 and 8 attention heads.
",4 Experiments,[0],[0]
"As a validation set for the denoiser training, we used newstest2015 (German ↔ English) or newstest2013 (French↔ English), where the input/output sides both have the same clean target sentences, encouraging a denoiser to keep at least clean part of word-by-word translations.",4 Experiments,[0],[0]
"Here, the noisy input showed a slight degradation of performance; the model seemed to overfit to specific noises in the small validation set.
",4 Experiments,[0],[0]
"Optimization of the denoising models was done with Adam (Kingma and Ba, 2015): initial learning rate 0.0001, checkpoint frequency 4000, no learning rate warmup, multiplying 0.7 to the learning rate when the perplexity on the validation set did not improve for 3 checkpoints.",4 Experiments,[0],[0]
"We stopped the training if it was not improved for 8 checkpoints.
",4 Experiments,[0],[0]
Table 1 shows the results.,4 Experiments,[0],[0]
"LM improves wordby-word baselines consistently in all four tasks, giving at least +3% BLEU.",4 Experiments,[0],[0]
"When our denoising model is applied on top of it, we have additional gain around +3% BLEU.",4 Experiments,[0],[0]
"Note that our methods do not involve any decoding steps to generate pseudo-parallel training data, but still perform
better than unsupervised MT systems that rely on repetitive back-translations (Artetxe et al., 2018; Lample et al., 2018) by up to +3.9% BLEU.",4 Experiments,[0],[0]
The total training time of our method is only 1-2 days with a single GPU.,4 Experiments,[0],[0]
"To examine the effect of each noise type in denoising autoencoder, we tuned each parameter of the noise and combined them incrementally (Table 2).",4.1 Ablation Study: Denoising,[0],[0]
"Firstly, for permutations, a significant improvement is achieved from dper = 3, since a local reordering usually involves a sequence of 3 to 4 words.",4.1 Ablation Study: Denoising,[0],[0]
"With dper > 5, it shuffles too many consecutive words together, yielding no further improvement.",4.1 Ablation Study: Denoising,[0],[0]
"This noise cannot handle long-range reordering, which is usually a swap of words that are far from each other, keeping the words in the middle as they are.
",4.1 Ablation Study: Denoising,[0],[0]
"Secondly, we applied the deletion noise with different values of pdel. 0.1 gives +0.8% BLEU, but we immediately see a degradation with a larger value; it is hard to observe one-to-many translations more than once in each sentence pair.
",4.1 Ablation Study: Denoising,[0],[0]
"Finally, we optimized Vins for the insertion noise, fixing pins = 0.1.",4.1 Ablation Study: Denoising,[0],[0]
"Increasing Vins is generally not beneficial, since it provides too much variations in the inserted word; it might not be related to its neighboring words.",4.1 Ablation Study: Denoising,[0],[0]
"Overall, we observe the best result (+1.5% BLEU) with Vins = 50.",4.1 Ablation Study: Denoising,[0],[0]
We also examined how the translation performance varies with different vocabularies of crosslingual word embedding in Table 3.,4.2 Ablation Study: Vocabulary,[0],[0]
"The first three rows show that BPE embeddings performs worse
than word embeddings, especially with smaller vocabulary size.",4.2 Ablation Study: Vocabulary,[0],[0]
"For small BPE tokens (1-3 characters), the context they meet during the embedding training is much more various than a complete word, and a direct translation of such small token to a BPE token of another language would be very ambiguous.
",4.2 Ablation Study: Vocabulary,[0],[0]
"For word level embeddings, we compared different vocabulary sizes used for training the cross-lingual mapping (the second step in Section 2).",4.2 Ablation Study: Vocabulary,[0],[0]
"Surprisingly, cross-lingual word embedding learned only on top 20k words is comparable to that of 200k words in the translation quality.",4.2 Ablation Study: Vocabulary,[0],[0]
We also increased the search vocabulary to more than 200k but the performance only degrades.,4.2 Ablation Study: Vocabulary,[0],[0]
"This means that word-by-word translation with crosslingual embedding depends highly on the frequent word mappings, and learning the mapping between rare words does not have a positive effect.",4.2 Ablation Study: Vocabulary,[0],[0]
"In this paper, we proposed a simple pipeline to greatly improve sentence translation based on cross-lingual word embedding.",5 Conclusion,[0],[0]
"We achieved context-aware lexical choices using beam search with LM, and solved insertion/deletion/reordering problems using denoising autoencoder.",5 Conclusion,[0],[0]
Our novel insertion noise shows a promising performance even combined with other noise types.,5 Conclusion,[0],[0]
Our methods do not need back-translation steps but still outperforms costly unsupervised neural MT systems.,5 Conclusion,[0],[0]
"In addition, we proved that for general translation purpose, an effective cross-lingual mapping can be learned using only a small set of frequent words, not on subword units.",5 Conclusion,[0],[0]
"This work has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation
programme, grant agreement No. 694537 (SEQCLAS).",Acknowledgments,[0],[0]
The GPU computing cluster was partially funded by Deutsche Forschungsgemeinschaft (DFG) under grant INST 222/1168-1 FUGG.,Acknowledgments,[0],[0]
The work reflects only the authors’ views and neither ERC nor DFG is responsible for any use that may be made of the information it contains.,Acknowledgments,[0],[0]
"Unsupervised learning of cross-lingual word embedding offers elegant matching of words across languages, but has fundamental limitations in translating sentences.",abstractText,[0],[0]
"In this paper, we propose simple yet effective methods to improve word-by-word translation of crosslingual embeddings, using only monolingual corpora but without any back-translation.",abstractText,[0],[0]
"We integrate a language model for context-aware search, and use a novel denoising autoencoder to handle reordering.",abstractText,[0],[0]
Our system surpasses state-of-the-art unsupervised neural translation systems without costly iterative training.,abstractText,[0],[0]
"We also analyze the effect of vocabulary size and denoising type on the translation performance, which provides better understanding of learning the cross-lingual word embedding and its usage in translation.",abstractText,[0],[0]
Improving Unsupervised Word-by-Word Translation with Language Model and Denoising Autoencoder,title,[0],[0]
"√ logn) speedup for
the Viterbi algorithm when there are few distinct transition probabilities in the HMM.",text,[0],[0]
A Hidden Markov Model (HMM) is a simple model that describes a random process for generating a sequence of observations.,1. Introduction,[0],[0]
"A random walk is performed on an underlying graph (Markov Chain) and, at each step, an observation is drawn from a probability distribution that depends only on the current state (the node in the graph).
",1. Introduction,[0],[0]
HMMs are a fundamental statistical tool and one of the most important questions in the applications of HMMs is computing the most likely sequence of states visited by the random walk in the HMM given the sequence of observations.,1. Introduction,[0],[0]
"Andrew Viterbi proposed an algorithm (Viterbi, 1967) for this problem that computes the solution in
Authors ordered alphabetically.",1. Introduction,[0],[0]
"1MIT, US.",1. Introduction,[0],[0]
"Correspondence to: Arturs Backurs <backurs@mit.edu>, Christos Tzamos <tzamos@mit.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017.",1. Introduction,[0],[0]
"Copyright 2017 by the author(s).
",1. Introduction,[0],[0]
O(Tn2) time for any HMM with n states and an observation sequence of length T .,1. Introduction,[0],[0]
"This algorithm is known as the Viterbi algorithm and the problem of computing the most likely sequence of states is also known as the Viterbi Path problem.
",1. Introduction,[0],[0]
The Viterbi algorithm has found wide applicability in machine learning.,1. Introduction,[0],[0]
"It is an important tool for structured prediction, used e.g., for structured perceptrons (Collins, 2002).",1. Introduction,[0],[0]
"Other applications include speech recognition (Rabiner, 1989; Nefian et al., 2002; Bengio, 2003), part-of-speech tagging (Collins, 2002), action planning (Attias, 2003), emotion recognition (Cohen et al., 2000), human activity classification (Mannini & Sabatini, 2010), and waveform classification (Kim & Smyth, 2006).",1. Introduction,[0],[0]
"Furthermore, it is often combined with other methods.",1. Introduction,[0],[0]
"For example, a combination of the Viterbi algorithm and neural networks is used for speech recognition (Mohamed et al., 2012; AbdelHamid et al., 2012; Bourlard & Morgan, 2012), handwriting recognition and protein secondary structure prediction (Lin et al., 2005; Peng et al., 2009).",1. Introduction,[0],[0]
"It also can be combined with Support Vector Machines (Altun et al., 2003).",1. Introduction,[0],[0]
"Finally, the Viterbi algorithm is used as a module in Graph Transformer Networks, with applications to speech recognition (LeCun et al., 1998; Collobert, 2011).
",1. Introduction,[0],[0]
"The quadratic dependence of the algorithm’s runtime on the number of states is a long-standing bottleneck that limits its applicability to problems with large state spaces, particularly when the number of observations is large.",1. Introduction,[0],[0]
A lot of effort has been put into improving the Viterbi algorithm to lower either the time or space complexity.,1. Introduction,[0],[0]
"Many works achieve speedups by requiring structure in the input, either explicitly by considering restricted classes of HMMs (Felzenszwalb et al., 2004; Siddiqi & Moore, 2005) or implicitly by using heuristics that improve runtime in certain cases (Esposito & Radicioni, 2009; Kaji et al., 2010).",1. Introduction,[0],[0]
"For the general case, in (Lifshits et al., 2009; Mahmud & Schliep, 2011) it is shown how to speed up the Viterbi algorithm by O(log n) when the number of distinct observations is constant using the Four Russians method or similar ideas.",1. Introduction,[0],[0]
"More recently, in (Cairo et al., 2016), the same logarithmic speed-up was shown to be possible for the general case.",1. Introduction,[0],[0]
"Despite significant effort, only log-
arithmic improvements are known other than in very special cases.",1. Introduction,[0],[0]
"In contrast, the memory complexity can be reduced to almost linear in the number of states without significant overhead in the runtime (Grice et al., 1997; Tarnas & Hughey, 1998; Churbanov & Winters-Hilt, 2008).
",1. Introduction,[0],[0]
"In this work, we attempt to explain this apparent barrier for faster runtimes by giving evidence of the inherent hardness of the Viterbi Path problem.",1. Introduction,[0],[0]
"In particular, we show that getting a polynomial speedup1 would imply a breakthrough for fundamental graph problems.",1. Introduction,[0],[0]
"Our lower bounds are based on standard hardness assumptions for the All-Pairs Shortest Paths and the Min-Weight k-Clique problems and apply even in cases where the number of distinct observations is small.
",1. Introduction,[0],[0]
"Before formally stating our results, let us give some background on the Min-Weight k-Clique problem.",1. Introduction,[0],[0]
This fundamental graph problem asks to find the minimum weight k-clique in the given undirected weighted graph on n nodes and O(n2) weighted edges.,1. Introduction,[0],[0]
"This is the parameterized version of the NP-hard Min-Weight Clique problem (Karp, 1972).",1. Introduction,[0],[0]
"The Min-Weight k-Clique is amongst the most wellstudied problems in theoretical computer science, and it is the canonical intractable problem in parameterized complexity.
",1. Introduction,[0],[0]
"A naive algorithm solves the Min-Weight k-Clique in O(nk) time and the best known algorithm still runs in O(nk−o(1)) for any constant k. Obtaining a significantly faster algorithm for this problem is a longstanding open question.
",1. Introduction,[0],[0]
A conjecture in graph algorithms and parameterized complexity is that it there is no O(nk−ε) algorithm for any constant ε > 0.,1. Introduction,[0],[0]
The special case of the conjecture with k = 3 says that finding the minimum weight triangle in a weighted graph cannot be solved in O(n3−δ) time for any constant δ > 0.,1. Introduction,[0],[0]
"There are many negative results that intuitively support this conjecture: a truly sub-
1Getting an algorithm running in time, say O(Tn1.99).
cubic algorithm for Min-Weight 3-Clique implies such algorithm for the All-Pairs Shortest Paths as well (Williams & Williams, 2010).",1. Introduction,[0],[0]
"The latter is a well studied problem and no truly subcubic algorithm is known for it despite significant effort (Williams, 2014).",1. Introduction,[0],[0]
"Unconditional lower bounds for k-Clique are known for various computational models, such as Ω(nk) for monotone circuits (Alon & Boppana, 1987).",1. Introduction,[0],[0]
"The planted Clique problem has also proven to be very challenging (e.g. (Alon et al., 2007; 1998; Hazan & Krauthgamer, 2011; Jerrum, 1992)).",1. Introduction,[0],[0]
"Max-Clique is also known to be hard to efficiently approximate within nontrivial factors (Håstad, 1999).
",1. Introduction,[0],[0]
We complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM.,1. Introduction,[0],[0]
"We summarize our results in Table 1.
",1. Introduction,[0],[0]
Our results and techniques Our first lower bound shows that the Viterbi Path problem cannot be computed in time O(Tn2)1−ε for a constant ε > 0,1. Introduction,[0],[0]
unless the APSP conjecture is false.,1. Introduction,[0],[0]
The APSP conjecture states that there is no algorithm for the All-Pairs Shortest Paths problem that runs in truly subcubic2 time in the number of vertices of the graph.,1. Introduction,[0],[0]
"We obtain the following theorem:
Theorem 1.",1. Introduction,[0],[0]
"The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.
",1. Introduction,[0],[0]
The proof of the theorem gives a reduction from All-Pairs Shortest Paths to the Viterbi Path problem.,1. Introduction,[0],[0]
This is done by encoding the weights of the graph of the APSP instance as transition probabilities of the HMM or as probabilities of seeing observations from different states.,1. Introduction,[0],[0]
"The proof requires a large alphabet size, i.e. a large number of distinct observations, which can be as large as the number of total steps T .
",1. Introduction,[0],[0]
"A natural question question to ask is whether there is a faster algorithm that solves the Viterbi Path problem when
2Truly subcubic means O(n3−δ) for constant δ > 0.
",1. Introduction,[0],[0]
"the alphabet size is much smaller than T , say when T = n2 and the alphabet size is n. We observe that in such a case, the input size to the Viterbi Path problem is only O(n2): we only need to specify the transition probabilities of the HMM, the probabilities of each observation in each state and the sequence of observations.",1. Introduction,[0],[0]
The Viterbi algorithm in this setting runs in Θ(Tn2) = Θ(n4) time.,1. Introduction,[0],[0]
Showing a matching APSP based lower bound seems difficult because the runtime in this setting is quadratic in the input size while the APSP conjecture gives only N1.5 hardness for input size N .,1. Introduction,[0],[0]
"To our best knowledge, all existing reduction techniques based on the APSP conjecture do not achieve such an amplification of hardness.",1. Introduction,[0],[0]
"In order to get a lower bound for smaller alphabet sizes, we need to use a different hardness assumption.
",1. Introduction,[0],[0]
"For this purpose, we consider the k-Clique conjecture.",1. Introduction,[0],[0]
It is a popular hardness assumption which states that it is not possible to compute a minimum weight k-clique on an edge-weighted graph with n vertices in time O(nk−ε) for constant k and ε > 0.,1. Introduction,[0],[0]
"With this assumption, we are able to extend Theorem 1 and get the following lower bound for the Viterbi Path problem on very small alphabets:
Theorem 2.",1. Introduction,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.
",1. Introduction,[0],[0]
"To show the theorem, we perform a reduction from the Min-Weight k-Clique problem.",1. Introduction,[0],[0]
"Given a Min-Weight kClique instance, we create an HMM with two special nodes, a start node and an end node, and enforce the following behavior of the optimal Viterbi path: Most of the time it stays in the start or end node, except for a small number of steps, during which it traverses the rest of the graph to move from the start to the end node.",1. Introduction,[0],[0]
The time at which the traversal happens corresponds to a clique in the original graph of the Min-Weight k-Clique instance.,1. Introduction,[0],[0]
We penalize the traversal according to the weight of the corresponding k-clique and thus the optimal path will find the minimum weight k-clique.,1. Introduction,[0],[0]
Transition probabilities of the HMM and probabilities of seeing observations from different states encode edge-weights of the Min-Weight k-Clique instance.,1. Introduction,[0],[0]
"Further, we encode the weights of smaller cliques into the sequence of observations according to the binary expansion of the weights.
",1. Introduction,[0],[0]
Our results of Theorems 1 and 2 imply that the Viterbi algorithm is essentially optimal even for small alphabets.,1. Introduction,[0],[0]
We also study the extreme case of the Viterbi Path problem with unary alphabet where the only information available is the total number of steps T .,1. Introduction,[0],[0]
We show a surprising behavior: when T ≤ n,1. Introduction,[0],[0]
"the Viterbi algorithm is essentially optimal, while there is a simple much faster algorithm",1. Introduction,[0],[0]
when T > n.,1. Introduction,[0],[0]
"See Section 5 for more details.
",1. Introduction,[0],[0]
We complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM.,1. Introduction,[0],[0]
"Such a restriction is mild in applications where one can round the transition probabilities to a small number of distinct values.
",1. Introduction,[0],[0]
Theorem 3.,1. Introduction,[0],[0]
"When there are fewer than 2ε √
logn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.
",1. Introduction,[0],[0]
"We achieve this result by developing an algorithm for online (min,+) matrix-vector multiplication for the case when the matrix has few distinct values.",1. Introduction,[0],[0]
"Our algorithm is presented in Section 7 and is based on a recent result for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017).
",1. Introduction,[0],[0]
The results we presented above hold for dense HMMs.,1. Introduction,[0],[0]
"For sparse HMMs that have at most m edges out of the n2 possible ones, i.e. the transition matrix has at most m nonzero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time.",1. Introduction,[0],[0]
The lower bounds that we presented above can be adapted directly for this case to show that no faster algorithm exists that runs in timeO(Tm)1−ε.,1. Introduction,[0],[0]
See the corresponding discussion in Section 6.,1. Introduction,[0],[0]
"Notation For an integer m, we denote the set {1, 2, . . .",2. Preliminaries,[0],[0]
",m} by [m].
",2. Preliminaries,[0],[0]
Definition 1 (Hidden Markov Model).,2. Preliminaries,[0],[0]
"A Hidden Markov Model (HMM) consists of a directed graph with n distinct hidden states [n] with transition probabilities Ã(u, v) of going from state u to state v.",2. Preliminaries,[0],[0]
"In any given state, there is a probability distribution of symbols that can be observed and B̃(u, s) gives the probability of seeing symbol s on",2. Preliminaries,[0],[0]
state u.,2. Preliminaries,[0],[0]
The symbols come from an alphabet [σ] of size σ.,2. Preliminaries,[0],[0]
"An HMM can thus be represented by a tuple (Ã, B̃).",2. Preliminaries,[0],[0]
"Given an HMM and a sequence of T observations, the Viterbi algorithm (Viterbi, 1967) outputs a sequence of T states that is most likely given the T observations.",2.1. The Viterbi Path Problem,[0],[0]
"More precisely, let S = (s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ) be the given sequence of T observations where symbol st ∈",2.1. The Viterbi Path Problem,[0],[0]
"[σ] is observed at time t = 1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", T .",2.1. The Viterbi Path Problem,[0],[0]
Let ut ∈,2.1. The Viterbi Path Problem,[0],[0]
"[n] be the state of the HMM at time t = 1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", T .",2.1. The Viterbi Path Problem,[0],[0]
"The Viterbi algorithm finds a state sequence U = (u0, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ) starting at u0 = 1 that maximizes Pr[U |S].",2.1. The Viterbi Path Problem,[0],[0]
The problem of finding the sequence U is known as the Viterbi Path problem.,2.1. The Viterbi Path Problem,[0],[0]
"In particular, the Viterbi Path
problem solves the optimization problem
arg max u0=1,u1,...,uT T∏ t=1",2.1. The Viterbi Path Problem,[0],[0]
"[ Ã(ut−1, ut) · B̃(ut, st) ] .
",2.1. The Viterbi Path Problem,[0],[0]
The Viterbi algorithm solves this problem in O(Tn2) by computing for t = 1 . . .,2.1. The Viterbi Path Problem,[0],[0]
T the best sequence of length t that ends in a given state in a dynamic programming fashion.,2.1. The Viterbi Path Problem,[0],[0]
"When run in a word RAM model with O(log n) bit words, this algorithm is numerically unstable because even representing the probability of reaching a state requires linear number of bits.",2.1. The Viterbi Path Problem,[0],[0]
"Therefore, log probabilities are used for numerical stability since that allows to avoid underflows (Young et al., 1997; Amengual & Vidal, 1998; Li & Tang, 2009; Lee et al., 2007; Huang et al., 2001).",2.1. The Viterbi Path Problem,[0],[0]
"To maintain numerical stability and understand the underlying combinatorial structure of the problem, we assume that the input is given in the form of log-probabilities, i.e. the input to the problem is A(u, v) =",2.1. The Viterbi Path Problem,[0],[0]
"− log Ã(u, v) and B(u, s) =",2.1. The Viterbi Path Problem,[0],[0]
"− log B̃(u, s) and focus our attention on the Viterbi Path problem defined by matrices A and B.
Definition 2 (Viterbi Path Problem).",2.1. The Viterbi Path Problem,[0],[0]
"The VITERBI PATH problem is specified by a tuple (A,B, S) where A and B are n × n",2.1. The Viterbi Path Problem,[0],[0]
and n × σ,2.1. The Viterbi Path Problem,[0],[0]
"matrices, respectively, and S = (s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ) is a sequence of T = nΘ(1) observations s1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", sT ∈",2.1. The Viterbi Path Problem,[0],[0]
[σ] over an alphabet of size σ.,2.1. The Viterbi Path Problem,[0],[0]
"Given an instance (A,B, S) of the VITERBI PATH problem, our goal is to output a sequence of vertices u0, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ∈",2.1. The Viterbi Path Problem,[0],[0]
"[n] with u0 = 1 that solves
arg min u0=1,u1,...,uT T∑ t=1",2.1. The Viterbi Path Problem,[0],[0]
"[A(ut−1, ut) +B(ut, st)] .
We can assume that log probabilities in matrices A and B are arbitrary positive numbers without the restriction that the corresponding probabilities must sum to 1.",2.1. The Viterbi Path Problem,[0],[0]
"See Appendix C for a discussion.
",2.1. The Viterbi Path Problem,[0],[0]
"A simpler special case of the VITERBI PATH problem asks to compute the most likely path of length T without any observations.
",2.1. The Viterbi Path Problem,[0],[0]
Definition 3 (Shortest Walk Problem).,2.1. The Viterbi Path Problem,[0],[0]
"Given an integer T and a weighted directed graph (with possible self-loops) on n vertices with edge weights specified by a matrixA, the SHORTEST WALK problem asks to compute a sequence of vertices u0 = 1, u1, . . .",2.1. The Viterbi Path Problem,[0],[0]
", uT ∈",2.1. The Viterbi Path Problem,[0],[0]
"[n] that solves
arg min u0=1,u1,...,uT T∑ t=1 A(ut−1, ut).
",2.1. The Viterbi Path Problem,[0],[0]
"It is easy to see that the SHORTEST WALK problem corresponds to the VITERBI PATH problem when σ = 1 and B(u, 1) = 0 for all u ∈",2.1. The Viterbi Path Problem,[0],[0]
[n].,2.1. The Viterbi Path Problem,[0],[0]
"We use the hardness assumptions of the following problems.
",2.2. Hardness assumptions,[0],[0]
Definition 4 (ALL-PAIRS SHORTEST PATHS (APSP) problem).,2.2. Hardness assumptions,[0],[0]
"Given an undirected graph G = (V,E) with n vertices and positive integer weights on the edges, find the shortest path between u and v for every u, v ∈ V .
",2.2. Hardness assumptions,[0],[0]
"The APSP conjecture states that the ALL-PAIRS SHORTEST PATHS problem requires Ω(n3)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
Conjecture 1 (APSP conjecture).,2.2. Hardness assumptions,[0],[0]
"The ALL-PAIRS SHORTEST PATHS problem on a graph with n vertices and positive integer edge-weights bounded by nO(1) requires Ω(n3)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
"There is a long list of works showing conditional hardness for various problems based on the All-Pairs Shortest Paths conjecture (Roditty & Zwick, 2004; Williams & Williams, 2010; Abboud & Williams, 2014; Abboud et al., 2015b;c).
",2.2. Hardness assumptions,[0],[0]
Definition 5 (MIN-WEIGHT k-CLIQUE problem).,2.2. Hardness assumptions,[0],[0]
"Given a complete graphG = (V,E) with n vertices and positive integer edge-weights, output the minimum total edge-weight of a k-clique in the graph.
",2.2. Hardness assumptions,[0],[0]
"This is a very well studied computational problem and despite serious efforts, the best known algorithm for this problem still runs in time O(nk−o(1)), which matches the runtime of the trivial algorithm up to subpolynomial factors.",2.2. Hardness assumptions,[0],[0]
"The k-Clique conjecture states that this problem requires Ω(nk)1−o(1) time and it has served as a basis for showing conditional hardness results for several problems on sequences (Abboud et al., 2015a; 2014; Bringmann et al., 2016) and computational geometry (Backurs et al., 2016).
",2.2. Hardness assumptions,[0],[0]
Conjecture 2 (k-Clique conjecture).,2.2. Hardness assumptions,[0],[0]
"The MIN-WEIGHT k-CLIQUE problem on a graph with n vertices and positive integer edge-weights bounded by nO(k) requires Ω(nk)1−o(1) time in expectation.
",2.2. Hardness assumptions,[0],[0]
"For k = 3, the MIN-WEIGHT 3-CLIQUE problem asks to find the minimum weight triangle in a graph.",2.2. Hardness assumptions,[0],[0]
This problem is also known as the MINIMUM TRIANGLE problem and under the 3-Clique conjecture it requires Ω(n3)1−o(1) time.,2.2. Hardness assumptions,[0],[0]
"The latter conjecture is equivalent to the APSP conjecture (Williams & Williams, 2010).
",2.2. Hardness assumptions,[0],[0]
"We often use the following variant of the MIN-WEIGHT k-CLIQUE problem:
Definition 6 (MIN-WEIGHT k-CLIQUE problem for k-partite graphs).",2.2. Hardness assumptions,[0],[0]
Given a complete k-partite graph G = (V1 ∪ . . .,2.2. Hardness assumptions,[0],[0]
"∪ Vk, E) with |Vi| = ni and positive integer weights on the edges, output the minimum total edgeweight of a k-clique in the graph.
",2.2. Hardness assumptions,[0],[0]
"If for all i, j we have that ni = n Θ(1)",2.2. Hardness assumptions,[0],[0]
"j , it can be shown that the MIN-WEIGHT k-CLIQUE problem for k-partite graphs
requires Ω (∏k
i=1",2.2. Hardness assumptions,[0],[0]
"ni
)1−o(1) time assuming the k-Clique
conjecture.",2.2. Hardness assumptions,[0],[0]
We provide a simple proof of this statement in the appendix.,2.2. Hardness assumptions,[0],[0]
"We begin by presenting our main hardness result for the VITERBI PATH problem.
",3. Hardness of VITERBI PATH,[0],[0]
Theorem 1.,3. Hardness of VITERBI PATH,[0],[0]
"The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.
",3. Hardness of VITERBI PATH,[0],[0]
"To show APSP hardness, we will perform a reduction from the MINIMUM TRIANGLE problem (described in Section 2.2) to the VITERBI PATH problem.",3. Hardness of VITERBI PATH,[0],[0]
"In the instance of the MINIMUM TRIANGLE problem, we are given a 3- partite graph G = (V1 ∪ V2 ∪ U, E) such that |V1| = |V2| = n, |U | = m.",3. Hardness of VITERBI PATH,[0],[0]
"We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed graph G′ = ({1, 2} ∪ V1 ∪ V2, E′).",3. Hardness of VITERBI PATH,[0],[0]
"E′ contains all the edges of G between V1 and V2, directed from V1 towards V2, edges from 1 towards all nodes of V1 of weight 0 and edges from all nodes of V2 towards 2 of weight 0.",3. Hardness of VITERBI PATH,[0],[0]
"We also add a self-loops at nodes 1 and 2 of weight 0.
",3. Hardness of VITERBI PATH,[0],[0]
"We create an instance of the VITERBI PATH problem (A,B, S) as described below.",3. Hardness of VITERBI PATH,[0],[0]
"Figure 1 illustrates the construction of the instance.
",3. Hardness of VITERBI PATH,[0],[0]
"• Matrix A is the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and non-existent self-loops.
",3. Hardness of VITERBI PATH,[0],[0]
"• The alphabet of the HMM is U ∪ {⊥,⊥F } and thus matrix B has 2n + 2 rows and σ",3. Hardness of VITERBI PATH,[0],[0]
= m + 2 columns.,3. Hardness of VITERBI PATH,[0],[0]
"For all v ∈ V1 ∪V2 and u ∈ U , B(v, u) is equal to the weight of the edge (v, u) in graphG.",3. Hardness of VITERBI PATH,[0],[0]
"Moreover, for all v ∈ V1 ∪ V2, B(v,⊥)",3. Hardness of VITERBI PATH,[0],[0]
=,3. Hardness of VITERBI PATH,[0],[0]
"+∞ (or a sufficiently large number) and for all v ∈ V1 ∪ V2 ∪ {1}, B(v,⊥F )",3. Hardness of VITERBI PATH,[0],[0]
"= +∞. Finally, all remaining entries corresponding to nodes 1 and 2 are 0.
",3. Hardness of VITERBI PATH,[0],[0]
"• Sequence S of length T = 3m + 1 is generated by appending the observations u, u and ⊥ for all u ∈ U and adding a ⊥F observation at the end.
",3. Hardness of VITERBI PATH,[0],[0]
"Given the above construction, the theorem statement follows directly from the following claim.
",3. Hardness of VITERBI PATH,[0],[0]
Claim 1.,3. Hardness of VITERBI PATH,[0],[0]
"The weight of the solution to the VITERBI PATH instance is equal to the weight of the minimum triangle in the graph G.
Proof.",3. Hardness of VITERBI PATH,[0],[0]
The optimal path for the VITERBI PATH instance begins at node 1.,3. Hardness of VITERBI PATH,[0],[0]
"It must end in node 2 since otherwise when observation ⊥F arrives we collect cost +∞. Similarly, whenever an observation ⊥ arrives the path must be either on node 1 or 2.",3. Hardness of VITERBI PATH,[0],[0]
"Thus, the path first loops in node 1 and then goes from node 1 to node 2 during three consecutive observations u, u and ⊥ for some u ∈ U and stays in node 2 until the end.",3. Hardness of VITERBI PATH,[0],[0]
Let v1 ∈ V1 and v2 ∈ V2 be the two nodes visited when moving from node 1 to node 2.,3. Hardness of VITERBI PATH,[0],[0]
"The only two steps of non-zero cost are:
1.",3. Hardness of VITERBI PATH,[0],[0]
Moving from node 1 to node v1 at the first observation u.,3. Hardness of VITERBI PATH,[0],[0]
"This costs A(1, v1) +B(v1, u) = B(v1, u).
2.",3. Hardness of VITERBI PATH,[0],[0]
Moving from node v1 to node v2 at the second observation u.,3. Hardness of VITERBI PATH,[0],[0]
"This costs A(v1, v2) +B(v2, u).
",3. Hardness of VITERBI PATH,[0],[0]
"Thus, the overall cost of the path is equal to B(v1, u) + A(v1, v2) +",3. Hardness of VITERBI PATH,[0],[0]
"B(v2, u), which is equal to the weight of the triangle (v1, v2, u) in G. Minimizing the cost of the path in this instance is therefore the same as finding the minimum weight triangle in G.",3. Hardness of VITERBI PATH,[0],[0]
"The proof of Theorem 1 requires a large alphabet size, which can be as large as the number of total steps T .",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"In the appendix, we show how to get a lower bound for the VITERBI PATH problem on alphabets of small size by using a different hardness assumption.
",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
Theorem 2.,4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.",4. Hardness of VITERBI PATH with small alphabet,[0],[0]
"In this section, we focus on the extreme case of VITERBI PATH with unary alphabet.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Theorem 4.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
The VITERBI PATH problem requires Ω(Tn2)1−o(1) time when T ≤ n,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"even if the size of the alphabet is σ = 1, assuming the APSP Conjecture.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The above theorem follows from APSP-hardness of the SHORTEST WALK problem that we present next.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Theorem 5.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The SHORTEST WALK problem requires Ω(Tn2)1−o(1) time when T ≤ n, assuming the APSP Conjecture.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Proof.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We will perform a reduction from the MINIMUM TRIANGLE problem to the VITERBI PATH
problem.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"In the instance of the MINIMUM TRIANGLE problem, we are given a 3-partite undirected graph G = (V1 ∪ V2 ∪ U, E) with positive edge weights such that |V1| = |V2| = n, |U | = m.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed and acyclic graph G′ = ({1, 2} ∪ V1 ∪ V2 ∪ U ∪ U ′, E′).",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
Nodes in U ′ are in one-to-one correspondence with nodes in U and |U ′| = m. E′ is defined as follows.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We add all edges of G between nodes in U and V1 directed from U towards V1 and similarly, we add all edges of G between nodes in V1 and V2 directed from V1 towards V2.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Instead of having edges between nodes in V2 and U , we add the corresponding edges of G between nodes in V2 and U ′ directed from V2 towards U ′.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Moreover, we add additional edges of weight 0 to create a path P of m + 1 nodes, starting from node 1 and going through all nodes in U in some order.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Finally, we create another path P ′ of m + 1 nodes going through all nodes in U ′",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
in the same order as their counterparts on path P and ending at node 2.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"These edges have weight 0 apart from the last one, entering node 2, which has weight −C (a sufficiently large negative constant)3.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We create an instance of the SHORTEST WALK problem by setting T = m+ 4 and A to be the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and self-loops.
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
The optimal walk of the SHORTEST WALK instance must include the edge of weight −C entering node 2 since otherwise the cost will be non-negative.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Moreover, the walk
3Since the definition of SHORTEST WALK doesn’t allow negative weights, we can equivalently set its weight to be 0 and add C to all the other edge weights.
must reach node 2 exactly at the last step since otherwise the cost will be +∞ as there are no outgoing edges from node 2.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"By the choice of T , the walk leaves path P at some node u ∈ U , then visits nodes v1 and v2 in V1 and V2, respectively, and subsequently moves to node u′ ∈ U ′ where u′ is the counterpart of u on path P ′. The total cost of the walk is thus the weight of the triangle (u, v1, v2) in G, minus C. Therefore, the optimal walk has cost equal to the weight of the minimum triangle up to the additive constant C.
Notice that when T > n, the runtime of the Viterbi algorithm is no longer optimal.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"We now present a faster algorithm with a total running time log T · n3/2Ω( √ logn).
",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"As we show in Section 7, the general VITERBI PATH problem reduces, according to Equation 2, to computing (min,+) matrix-vector products.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"In the case of unary alphabet, it corresponds to computing (min,+) matrixvector product T times as follows: A ⊕ A ⊕ ... ⊕",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
A ⊕ z.,5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"This can be equivalently performed by first computing all (min,+) matrix-matrix products A⊕T = A⊕A⊕ ...⊕A using exponentiation with repeated squaring and then multiplying the resulting matrix with the vector z.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"This requires only O(log T ) matrix (min,+)-multiplications.",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"Using the currently best algorithm for (min,+) matrix product (Williams, 2014), we get an algorithm with total running time log T · n3/2Ω( √ logn).",5. Complexity of VITERBI PATH for unary alphabet,[0],[0]
"The VITERBI PATH lower-bounds we have provided apply to the case where the HMM has all n2 possible edges.
",6. Hardness for sparse HMMs,[0],[0]
"For sparse HMMs that have at most m edges out of the
n2 possible ones, i.e. the transition matrix has at most m non-zero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time.",6. Hardness for sparse HMMs,[0],[0]
The lower bounds that we presented in the paper can be adapted directly for this case to show that no faster algorithm exists that runs in time O(Tm)1−ε.,6. Hardness for sparse HMMs,[0],[0]
This can be easily seen via a padding argument.,6. Hardness for sparse HMMs,[0],[0]
Consider a hard instance for VITERBI PATH on a dense HMM with √ m states andm edges.,6. Hardness for sparse HMMs,[0],[0]
"Adding n− √ m additional states with self-loops, we obtain a sparse instance with n states and m + n",6. Hardness for sparse HMMs,[0],[0]
− √ m = O(m) edges.,6. Hardness for sparse HMMs,[0],[0]
"Thus, any algorithm that computes the optimal Viterbi Path in O(Tm)1−ε time for the resulting instance would solve the original instance with √ m states in O ( T ( √ m)2
)1−ε time contradicting the corresponding lower bound.
",6. Hardness for sparse HMMs,[0],[0]
"This observation directly gives the following lower bounds for VITERBI PATH problem, parametrized by the number m of edges in an HMM with n states.
",6. Hardness for sparse HMMs,[0],[0]
Theorem 6.,6. Hardness for sparse HMMs,[0],[0]
"The VITERBI PATH problem requires Ω(Tm)1−o(1) time for an HMM with m edges and n states, assuming the APSP Conjecture.
",6. Hardness for sparse HMMs,[0],[0]
Theorem 7.,6. Hardness for sparse HMMs,[0],[0]
"For any C, ε > 0, the VITERBI PATH problem on T = Θ(mC) observations from an alphabet of size Θ(mε) requires Ω(Tm)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.",6. Hardness for sparse HMMs,[0],[0]
Theorem 8.,6. Hardness for sparse HMMs,[0],[0]
The VITERBI PATH problem requires Ω(Tm)1−o(1) time when T ≤,6. Hardness for sparse HMMs,[0],[0]
√ m even if the size of the alphabet is σ,6. Hardness for sparse HMMs,[0],[0]
= 1,6. Hardness for sparse HMMs,[0],[0]
", assuming the APSP Conjecture.",6. Hardness for sparse HMMs,[0],[0]
"In this section, we present a faster algorithm for the VITERBI PATH problem, when there are only few distinct transition probabilities in the underlying HMM.",7. A faster VITERBI PATH algorithm,[0],[0]
Theorem 3.,7. A faster VITERBI PATH algorithm,[0],[0]
"When there are fewer than 2ε √
logn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.
",7. A faster VITERBI PATH algorithm,[0],[0]
The number of distinct transition probabilities is equal to the number of distinct entries in matrix Ã in Definition 1.,7. A faster VITERBI PATH algorithm,[0],[0]
"The same is true for matrix A in the additive version of VITERBI PATH, in Definition 2.",7. A faster VITERBI PATH algorithm,[0],[0]
"So, from the theorem statement we can assume that matrixA has at most 2ε √ logn different entries for some constant ε > 0.
",7. A faster VITERBI PATH algorithm,[0],[0]
"To present our algorithm, we revisit the definition of VITERBI PATH.",7. A faster VITERBI PATH algorithm,[0],[0]
"We want to compute a path u0 = 1, u1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", uT that minimizes the quantity:
min u0=1,u1,...,uT T∑ t=1",7. A faster VITERBI PATH algorithm,[0],[0]
"[A(ut−1, ut) +B(ut, st)] .",7. A faster VITERBI PATH algorithm,[0],[0]
"(1)
Defining the vectors bt = B(·, st), we note that (1) is equal
to the minimum entry in the vector obtained by a sequence of T (min,+) matrix-vector products4 as follows:
A⊕ (. . .",7. A faster VITERBI PATH algorithm,[0],[0]
(A⊕ (A⊕ (A⊕z+ b1)+ b2)+ b3) . .,7. A faster VITERBI PATH algorithm,[0],[0]
.)+,7. A faster VITERBI PATH algorithm,[0],[0]
"bT (2)
where z is a vector with entries",7. A faster VITERBI PATH algorithm,[0],[0]
z1 = 0 and zi = ∞ for all i 6= 1.,7. A faster VITERBI PATH algorithm,[0],[0]
Vector z represents the cost of being at node i at time 0.,7. A faster VITERBI PATH algorithm,[0],[0]
Vector (A ⊕ z + b1) represents the minimum cost of reaching each node at time 1 after seeing observation s1.,7. A faster VITERBI PATH algorithm,[0],[0]
"After T steps, every entry i of vector (2) represents the minimum minimum cost of a path that starts at u0 = 1 and ends at uT = i after T observations.",7. A faster VITERBI PATH algorithm,[0],[0]
"Taking the minimum of all entries gives the cost of the solution to the VITERBI PATH instance.
",7. A faster VITERBI PATH algorithm,[0],[0]
"To evaluate (2), we design an online (min,+) matrixvector multiplication algorithm.",7. A faster VITERBI PATH algorithm,[0],[0]
"In the online matrix-vector multiplication problem, we are given a matrix and a sequence of vectors in online fashion.",7. A faster VITERBI PATH algorithm,[0],[0]
We are required to output the result of every matrix-vector product before receiving the next vector.,7. A faster VITERBI PATH algorithm,[0],[0]
"Our algorithm for online (min,+) matrix-vector multiplication is based on a recent algorithm for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017):
Theorem 9 (Green Larsen and Williams (Larsen & Williams, 2017)).",7. A faster VITERBI PATH algorithm,[0],[0]
"For any matrix M ∈ {0, 1}n×n and any sequence of T = 2ω( √ logn) vectors v1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", vT ∈ {0, 1}n, online Boolean matrix-vector multiplication of M and vi can be performed in n2/2Ω( √ logn) amortized time whp.",7. A faster VITERBI PATH algorithm,[0],[0]
"No preprocessing is required.
",7. A faster VITERBI PATH algorithm,[0],[0]
"We show the following theorem for online (min,+) matrix-vector multiplication, which gives the promised runtime for the VITERBI PATH problem5 since we are interested in the case where T and n are polynomially related, i.e. T = nΘ(1).
",7. A faster VITERBI PATH algorithm,[0],[0]
Theorem 10.,7. A faster VITERBI PATH algorithm,[0],[0]
"Let A ∈ Rn×n be a matrix with at most 2ε √
logn distinct entries for a constant ε > 0.",7. A faster VITERBI PATH algorithm,[0],[0]
"For any sequence of T = 2ω( √ logn) vectors v1, . . .",7. A faster VITERBI PATH algorithm,[0],[0]
", vT ∈ Rn, online (min,+) matrix-vector multiplication of A and vi can be performed in n2/2Ω( √ logn) amortized time whp.",7. A faster VITERBI PATH algorithm,[0],[0]
"No preprocessing is required.
",7. A faster VITERBI PATH algorithm,[0],[0]
Proof.,7. A faster VITERBI PATH algorithm,[0],[0]
"We will show the theorem for the case where A ∈ {0,+∞}n×n.",7. A faster VITERBI PATH algorithm,[0],[0]
The general case where matrix A has d ≤,7. A faster VITERBI PATH algorithm,[0],[0]
2ε,7. A faster VITERBI PATH algorithm,[0],[0]
"√
logn distinct values a1, ..., ad can be handled by creating d matrices A1, ..., Ad, where each matrix Ak has entries Akij = 0",7. A faster VITERBI PATH algorithm,[0],[0]
"if Aij = a
k and +∞ otherwise.",7. A faster VITERBI PATH algorithm,[0],[0]
"Then, vector 4A (min,+) product between a matrix M and a vector v is denoted by M ⊕ v and is equal to a vector u where ui = minj(Mi,j + vj).
",7. A faster VITERBI PATH algorithm,[0],[0]
"5Even though computing all (min,+) products does not directly give a path for the VITERBI PATH problem, we can obtain one at no additional cost by storing back pointers.",7. A faster VITERBI PATH algorithm,[0],[0]
"This is standard and we omit the details.
",7. A faster VITERBI PATH algorithm,[0],[0]
r = A⊕v can be computed by computing rk =,7. A faster VITERBI PATH algorithm,[0],[0]
"Ak⊕v for every k and setting ri = mink(rki + a
k).",7. A faster VITERBI PATH algorithm,[0],[0]
"This introduces a factor of 2ε √ logn in amortized runtime but the final amortized runtime remains n2/2Ω( √
logn)",7. A faster VITERBI PATH algorithm,[0],[0]
if ε > 0 is sufficiently small.,7. A faster VITERBI PATH algorithm,[0],[0]
"From now on we assume thatA ∈ {0,+∞}n×n and define the matrix Ā ∈ {0, 1}n×n whose every entry is 1 if the corresponding entry at matrix A is 0 and 0 otherwise.
",7. A faster VITERBI PATH algorithm,[0],[0]
"For every query vector v, we perform the following:
– Sort indices i1, ..., in such that vi1 ≤ ...",7. A faster VITERBI PATH algorithm,[0],[0]
≤ vin in O(n log n) time.,7. A faster VITERBI PATH algorithm,[0],[0]
"– Partition the indices into p = 2α √
logn sets, where set Sk contains indices i(k−1)dnp e+1, ..., ikdnp e.
–",7. A faster VITERBI PATH algorithm,[0],[0]
"Set r = (⊥, ...,⊥)T , where ⊥ indicates an undefined value.
– For k = 1...p fill the entries of r as follows:
- Let ISk be the indicator vector of Sk that takes value 1 at index",7. A faster VITERBI PATH algorithm,[0],[0]
i if i ∈ Sk and 0 otherwise.,7. A faster VITERBI PATH algorithm,[0],[0]
- Compute the Boolean matrix-vector product πk = Ā,7. A faster VITERBI PATH algorithm,[0],[0]
"ISk using the algorithm from Theorem 9.
- Set rj =",7. A faster VITERBI PATH algorithm,[0],[0]
"mini∈Sk(Aj,i + vi) for all j ∈",7. A faster VITERBI PATH algorithm,[0],[0]
"[n] such that rj = ⊥ and πkj = 1.
– Return vector r.
Runtime of the algorithm per query The algorithm performs p = 2α √ logn Boolean matrix-vector multiplications, for a total amortized cost of p · n2/2Ω( √ logn) = n2/2Ω( √
logn) for a small enough constant α > 0.",7. A faster VITERBI PATH algorithm,[0],[0]
"Moreover, to fill an entry rj the algorithm requires going through all elements in some set Sk for a total runtime ofO(|Sk|) = n/2Ω( √ logn).",7. A faster VITERBI PATH algorithm,[0],[0]
"Thus, for all entries pj the total time required is n2/2Ω( √
logn).",7. A faster VITERBI PATH algorithm,[0],[0]
"The runtime of the other steps is dominated by these two operations so the algorithm takes n2/2Ω( √ logn) amortized time per query.
",7. A faster VITERBI PATH algorithm,[0],[0]
"Correctness of the algorithm To see that the algorithm correctly computes the (min,+) product A ⊕ v, observe that the algorithm fills in the entries of vector r from smallest to largest.",7. A faster VITERBI PATH algorithm,[0],[0]
"Thus, when we set a value to entry rj we never have to change it again.",7. A faster VITERBI PATH algorithm,[0],[0]
"Moreover, if the value rj gets filled at step k, it must be the case that πk ′
j = 0 for all k′",7. A faster VITERBI PATH algorithm,[0],[0]
< k.,7. A faster VITERBI PATH algorithm,[0],[0]
"This means that for all indices i ∈ S1 ∪ ... ∪ Sk−1 the corresponding entry Aj,i was always +∞.",7. A faster VITERBI PATH algorithm,[0],[0]
"We thank Piotr Indyk for many helpful discussions, for comments on an earlier version of the writeup and for suggestion on how to improve the presentation.",Acknowledgments,[0],[0]
"We also thank
the anonymous reviewers for their careful reviews.",Acknowledgments,[0],[0]
"This work was supported in part by an IBM PhD Fellowship, the NSF and the Simons Foundation.",Acknowledgments,[0],[0]
The classic algorithm of Viterbi computes the most likely path in a Hidden Markov Model (HMM) that results in a given sequence of observations.,abstractText,[0],[0]
It runs in time O(Tn) given a sequence of T observations from a HMM with n states.,abstractText,[0],[0]
"Despite significant interest in the problem and prolonged effort by different communities, no known algorithm achieves more than a polylogarithmic speedup.",abstractText,[0],[0]
"In this paper, we explain this difficulty by providing matching conditional lower bounds.",abstractText,[0],[0]
Our lower bounds are based on assumptions that the best known algorithms for the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight k-Clique problem in edge-weighted graphs are essentially tight.,abstractText,[0],[0]
"Finally, using a recent algorithm by Green Larsen and Williams for online Boolean matrix-vector multiplication, we get a 2 √ logn) speedup for the Viterbi algorithm when there are few distinct transition probabilities in the HMM.",abstractText,[0],[0]
Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 51–57 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2009",text,[0],[0]
Language identification (LID) is an essential first step for NLP on multilingual text.,1 Introduction,[0],[0]
"In global settings like Twitter, this text is written by authors from diverse linguistic backgrounds, who may communicate with regional dialects (Gonçalves and Sánchez, 2014) or even include parallel translations in the same message to address different audiences (Ling et al., 2013, 2016).",1 Introduction,[0],[0]
"Such dialectal variation is frequent in all languages and even macro-dialects such as American and British English are composed of local dialects that vary across city and socioeconomic development level (Labov, 1964; Orton et al., 1998).",1 Introduction,[0],[0]
"Yet current systems for broad-coverage LID—trained on dozens of languages—have largely leveraged Europeancentric corpora and not taken into account demo-
graphic and dialectal variation.",1 Introduction,[0],[0]
"As a result, these systems systematically misclassify texts from populations with millions of speakers whose local speech differs from the majority dialects (Hovy and Spruit, 2016; Blodgett et al., 2016).
",1 Introduction,[0],[0]
"Multiple systems have been proposed for broadcoverage LID at the global level (McCandless, 2010; Lui and Baldwin, 2012; Brown, 2014; Jaech et al., 2016).",1 Introduction,[0],[0]
"However, only a handful of techniques have addressed the challenge of linguistic variability of global data, such as the dialectal variability and multilingual text seen in Figure 1.",1 Introduction,[0],[0]
"These techniques have typically focused only on limited aspects of variability, e.g., individual dialects like African American Vernacular English (Blodgett et al., 2016), online speech (Nguyen and Doğruöz, 2013), similar languages (Bergsma et al., 2012; Zampieri et al., 2014a), or word-level code switching (Solorio et al., 2014; Rijhwani et al., 2017).
",1 Introduction,[0],[0]
"In this work, our goal is to devise a socially equitable LID, that will enable a massively multilingual, broad-coverage identification of populations speaking underrepresented dialects, multilingual messages, and other linguistic varieties.",1 Introduction,[0],[0]
We first construct a large-scale dataset of Twitter posts across the world (§2).,1 Introduction,[0],[0]
"Then, we introduce an LID system, EQUILID, that produces pertoken language assignments and obtains state-ofthe-art performance on four LID tasks (§3), outperforming broad-coverage LID benchmarks by
51
up to 300%.",1 Introduction,[0],[0]
"Finally, we present a case study on using Twitter for health monitoring and show that (1) current widely-used systems suffer from lower recall rates for texts from developing countries, and (2) our system substantially reduces this disparity and enables socially-equitable LID.",1 Introduction,[0],[0]
"Despite known linguistic variation in languages, current broad-coverage LID systems are trained primarily on European-centric sources (e.g., Lui and Baldwin, 2014), often due to data availability.",2 Curating Socially-Representative Text,[0],[0]
"Further, even when training incorporates seemingly-global texts from Wikipedia, their authors are still primarily from highly-developed countries (Graham et al., 2014).",2 Curating Socially-Representative Text,[0],[0]
"This latent bias can significantly affect downstream applications (as we later show in §4), since language ID is often assumed to be a solved problem (McNamee, 2005) and most studies employ off-the-shelf LID systems without considering how they were trained.
",2 Curating Socially-Representative Text,[0],[0]
"We aim to create a socially-representative corpus for LID that captures the variation within a language, such as orthography, dialect, formality, topic, and spelling.",2 Curating Socially-Representative Text,[0],[0]
"Motivated by the recent language survey of Twitter (Trampus, 2016), we next describe how we construct this corpus for 70 languages along three dimensions: geography, social and topical diversity, and multilinguality.",2 Curating Socially-Representative Text,[0],[0]
"Geographic Diversity We create a large-scale dataset of geographically-diverse text by bootstrapping with a people-centric approach (Bamman, 2015) that treats location and languagesspoken as demographic attributes to be inferred for authors.",2 Curating Socially-Representative Text,[0],[0]
"By inferring both for Twitter users and then collecting documents from monolingual users, we ensure that we capture regional variation in a language, rather than focusing on a particular aspect of linguistic variety.
",2 Curating Socially-Representative Text,[0],[0]
Individuals’ locations are inferred using the method of Compton et al. (2014) as implemented by Jurgens et al. (2015).,2 Curating Socially-Representative Text,[0],[0]
"The method first identifies the individuals who have reliable ground truth locations from geotagged tweets and then infers the locations of other individuals as the geographic center of their friends’ locations, iteratively applying this inference method to the whole social network.",2 Curating Socially-Representative Text,[0],[0]
"The method is accurate to within tens of kilometers on urban and rural users (Johnson et al., 2017), which is sufficient for the city-level analysis we use here.",2 Curating Socially-Representative Text,[0],[0]
"We use a network of 2.3B edges
from reciprocal mentions to locate 132M users.",2 Curating Socially-Representative Text,[0],[0]
"To identify monolingual users, we classify multiple tweets by the same individual and consider an author monolingual if they had at least 20 tweets and 95% were labeled with one language `.",2 Curating Socially-Representative Text,[0],[0]
All tweets by that author are then treated as being `.,2 Curating Socially-Representative Text,[0],[0]
"We use this relabeling process to automatically identify misclassified tweets, which when aggregated geographically, can potentially capture regional dialects and topics.1 We construct separate sets of monolinguals using langid.py and CLD2 as classifiers to mitigate the biases of each.",2 Curating Socially-Representative Text,[0],[0]
"Social and Topical Diversity Authors modulate their writing style for different social registers (Eisenstein, 2015; Tatman, 2015).",2 Curating Socially-Representative Text,[0],[0]
"Therefore, we include corpora from different levels of formality across a wide range of topics.",2 Curating Socially-Representative Text,[0],[0]
"Texts were gathered for all of the 70 languages from (1) Wikipedia articles and their more informal Talk pages, (2) Bible and Quran translations (3) JRC-Acquis (Steinberger et al., 2006), a collection of European legislation, (4) the UN Declaration of Human Rights, (5) the Watchtower online magazines, (6) the 2014 and 2015 iterations of the Distinguishing Similar Languages shared task (Zampieri et al., 2014b, 2015), and (7) the Twitter70 dataset (Trampus, 2016).",2 Curating Socially-Representative Text,[0],[0]
"We also include single-language corpora drawn from slang websites (e.g., Urban Dictionary) and the African American Vernacular English data from Blodgett et al. (2016).",2 Curating Socially-Representative Text,[0],[0]
"For all sources, we extract instances sequentially by aggregating sentences up to 140 characters.",2 Curating Socially-Representative Text,[0],[0]
"Multilingual Diversity Authors are known to generate multilingual texts on Twitter (Ling et al., 2013, 2014), with Rijhwani et al. (2017) estimating that 3.5% of tweets are code-switched.",2 Curating Socially-Representative Text,[0],[0]
"To capture the potential diversity in multilingual documents, we perform data augmentation to synthetically construct multilingual documents of tweet length by (1) sampling texts for two languages from arbitrary sources, (2) with 50% chance for each, truncating a text at the first occurrence of phrasal punctuation, and (3) concatenating the two texts together and adding it to the dataset (if ≤ 140 characters).",2 Curating Socially-Representative Text,[0],[0]
"We create only sentence-level or phrase-level code-switching rather than wordlevel switches to avoid classifier ambiguity for loan words, which is known to be a significant challenge (Çetinoğlu et al., 2016).
",2 Curating Socially-Representative Text,[0],[0]
"1A manual analysis of 500 tweets confirmed that nearly all cases (98.6%) where the classifier’s label differed from the author’s inferred language were misclassifications.
",2 Curating Socially-Representative Text,[0],[0]
Corpus Summary The geographically-diverse corpus was constructed from two Twitter datasets: 1.3B tweets drawn from a 10% sample of all tweets from March 2014 and 14.2M tweets drawn from 1% sample of all geotagged tweets from November 2016.,2 Curating Socially-Representative Text,[0],[0]
"Ultimately, we collected 97.8M tweets from 1.5M users across 197 countries and in 53 languages.",2 Curating Socially-Representative Text,[0],[0]
"After identifying monolingual authors in the dataset, 9.4% of the instances (9.1M) were labeled by CLD2 or langid.py with a different language than that spoken by its author; since nearly all are misclassifications, we view these posts as valuable data to correct systematic bias.
",2 Curating Socially-Representative Text,[0],[0]
A total of 258M instances were collected for the topically and socially-diverse corpora.,2 Curating Socially-Representative Text,[0],[0]
Multilingual instances were created by sampling text from all language pairs; a total of 3.2M synthetic instances were created.,2 Curating Socially-Representative Text,[0],[0]
Full details are reported in Supplementary Material.,2 Curating Socially-Representative Text,[0],[0]
"We introduce EQUILID, and evaluate it on monolingual and multilingual tweet-length text.",3 Equitable LID Classifier,[0],[0]
"Model Character-based neural network architectures are particularly suitable for LID, as they facilitate modeling nuanced orthographic and phonological properties of languages (Jaech et al., 2016; Samih et al., 2016), e.g., capturing regular morpheme occurrences within the words of a language.",3 Equitable LID Classifier,[0],[0]
"Further, character-based methods significantly reduce the model complexity compared to word-based methods; the latter require separate neural representations for each word form and therefore are prohibitive in multilingual environments that easily contain tens of millions of unique words.",3 Equitable LID Classifier,[0],[0]
"We use an encoder–decoder architecture (Cho et al., 2014; Sutskever et al., 2014) with an attention mechanism (Bahdanau et al., 2015).",3 Equitable LID Classifier,[0],[0]
"The encoder and the decoder are 3-layer recurrent neural networks with 512 gated recurrent units (Chung et al., 2014).",3 Equitable LID Classifier,[0],[0]
"The model is trained to tokenize character sequence input based on white space and output a sequence with each token’s language, with extra token types for punctuation, hashtags, and user mentions.",3 Equitable LID Classifier,[0],[0]
"Setup The data from our socially-representative corpus (§2) was split into training, development, and test sets (80%/10%/10%, respectively), separately partitioning the data from each source (e.g., Wikipedia).",3 Equitable LID Classifier,[0],[0]
"Due to different sizes, we imposed
a maximum of 50K instances per source and language to reduce training bias.",3 Equitable LID Classifier,[0],[0]
A total 52.3M instances were used for the final datasets.,3 Equitable LID Classifier,[0],[0]
Multilingual instances were generated from texts within their respective split to prevent test-train leakage.,3 Equitable LID Classifier,[0],[0]
"For the Twitter70 dataset, we use identical training, development, and test splits as Jaech et al. (2016).",3 Equitable LID Classifier,[0],[0]
The same trained model is used for all evaluations.,3 Equitable LID Classifier,[0],[0]
"All parameter optimization was performed on the development set using adadelta (Zeiler, 2012) with mini-batches of size 64 to train the models.",3 Equitable LID Classifier,[0],[0]
"The model was trained for 2.7M steps, which is roughly three epochs.
",3 Equitable LID Classifier,[0],[0]
"Comparison Systems We compare against two broad-coverage LID systems, langid.py (Lui and Baldwin, 2012) and CLD2 (McCandless, 2010), both of which have been widely used for Twitter within in the NLP community.",3 Equitable LID Classifier,[0],[0]
"CLD2 is trained on web page text, while langid.py was trained on newswire, JRC-Acquis, web pages, and Wikipedia.",3 Equitable LID Classifier,[0],[0]
"As neither was designed for Twitter, we preprocess text to remove user mentions, hashtags, and URLs for a more fair comparison.",3 Equitable LID Classifier,[0],[0]
"For multilingual documents, we substitute langid.py (Lui and Baldwin, 2012) with its extension, Polyglot, described in Lui et al. (2014) and designed for that particular task.
",3 Equitable LID Classifier,[0],[0]
"We also include the results reported in Jaech et al. (2016), who trained separate models for two benchmarks used here.",3 Equitable LID Classifier,[0],[0]
Their architecture uses a convolutional network to transform each input word into a vector using its characters and then feed the word vectors to an LSTM encoder that decodes to per-word soft-max distributions over languages.,3 Equitable LID Classifier,[0],[0]
These word-language distributions are averaged to identify the most-probable language for the input text.,3 Equitable LID Classifier,[0],[0]
"In contrast, our architecture uses only character-based representations and produces per-token language assignments.
",3 Equitable LID Classifier,[0],[0]
"Benchmarks We test the monolingual setting with three datasets: (1) the test portion of the geographically-diverse corpus from §2, which covers 53 languages (2) the test portion of the Twitter70 dataset, which covers 70 languages and (3) the TweetLID shared task (Zubiaga et al., 2016), which covers 6 languages.",3 Equitable LID Classifier,[0],[0]
"The TweetLID data includes Galician, which is not one of the 70 languages we include due to its relative infrequency.",3 Equitable LID Classifier,[0],[0]
"Therefore, we report results only on the non-Galician portions of the data.",3 Equitable LID Classifier,[0],[0]
"Multilingual LID is tested using the test data portion of the
synthetically-constructed multilingual data from 70 languages.",3 Equitable LID Classifier,[0],[0]
Models are evaluated using macroaveraged and micro-averaged F1.,3 Equitable LID Classifier,[0],[0]
"Macro-averaged F1 denotes the average F1 for each language, independent of how many instances were seen for that language.",3 Equitable LID Classifier,[0],[0]
Micro-averaged F1 denotes the F1 measured from all instances and is sensitive to the skew in the distribution of languages in the dataset.,3 Equitable LID Classifier,[0],[0]
Results EQUILID attains state-of-the-art performance over the other broad-coverage LID systems on all benchmarks.,3 Equitable LID Classifier,[0],[0]
"We attribute this increase to more representative training data; indeed, Jaech et al. (2016) reported langid.py obtains a substantially higher F1 of 0.879 when retrained only on Twitter70 data, underscoring the fact that broadcoverage systems are typically not trained on data as linguistically diverse as seen in social media.",3 Equitable LID Classifier,[0],[0]
"Despite being trained for general-purpose, EQUILID also outperformed the benchmark-optimized models of Jaech et al. (2016).
",3 Equitable LID Classifier,[0],[0]
"In the multilingual setting, EQUILID substantially outperforms both Polyglot and CLD2, with over a 300% increase in Macro-F1 over the former.",3 Equitable LID Classifier,[0],[0]
"Further, because our model can also identify the spans in each language, we view its performance as an important step towards an all-languages solution for detecting sentence and phrase-level switching between languages.",3 Equitable LID Classifier,[0],[0]
"Indeed, in the Twitter70 dataset, EQUILID found roughly 5% of the test data are unmarked instances of codeswitching, one of which is the third example in Figure 1.",3 Equitable LID Classifier,[0],[0]
"Error Analysis To identify main sources of classification errors, we manually analyzed the outputs of EQUILID on the test set of Twitter70.",3 Equitable LID Classifier,[0],[0]
"The dataset contains 9,572 test instances, 90.5% of which were classified correctly by our system; we discuss below sources of errors in the remaining 909 misclassified instances.
",3 Equitable LID Classifier,[0],[0]
"Classification of closely related languages with overlapping vocabularies written in a same script is the biggest source of errors (374 misclassified instances, 41.1% of all errors).",3 Equitable LID Classifier,[0],[0]
"Slavic languages
are the most challenging, with 177 Bosnian and 65 Slovenian tweets classified as Croatian.",3 Equitable LID Classifier,[0],[0]
"This is unsurprising, considering that even for a human annotator this task is challenging (or impossible).",3 Equitable LID Classifier,[0],[0]
"For example, a misclassified Bosnian tweet Sočni čokoladni biskvit recept (“juicy chocolate biscuit recipe”) would be the same in Croatian.",3 Equitable LID Classifier,[0],[0]
"IndoIranian languages contribute 39 errors, with Bengali, Marathi, Nepali, Punjabi, and Urdu tweets classified as Hindi.",3 Equitable LID Classifier,[0],[0]
"Among Germanic languages, Danish, Norwegian, and Swedish are frequently confused, contributing 22 errors.
",3 Equitable LID Classifier,[0],[0]
"Another major source of errors is due to transliteration and code switching with English: 328 messages in Hindi, Urdu, Tagalog, Telugu, and Punjabi were classified as English, contributing 36.1% of errors.",3 Equitable LID Classifier,[0],[0]
"A Hindi-labeled tweet dost tha or rahega ... dont wory ... but dherya rakhe (“he was and will remain a friend ... don’t worry ... but have faith”) is a characteristic example, misclassified by our system as English.",3 Equitable LID Classifier,[0],[0]
Reducing these types of errors is currently difficult due to the lack of transliterated examples for these languages.,3 Equitable LID Classifier,[0],[0]
"We conclude with a real-world case study on using Twitter posts as a real-time source of information for tracking health and well-being trends (Paul and Dredze, 2011; Achrekar et al., 2011; Aramaki et al., 2011).",4 Case Study: Health Monitoring,[0],[0]
This information is especially critical for regions where local authorities may not have sufficient resources to identify trends otherwise.,4 Case Study: Health Monitoring,[0],[0]
"Commonly, trend-tracking approaches first apply language identification to select language-specific content, and then apply sophisticated NLP techniques to identify content related to their target phenomena, e.g., distinguishing a flu comment from a hangover-related one.",4 Case Study: Health Monitoring,[0],[0]
"This setting is where socially-inclusive LID systems can make real, practical impact: LID systems that effectively classify languages of underrepresented dialects can substantially increase the re-
call of data for trend-tracking approaches, and thus help reveal dangerous trends in infectious diseases in the areas that need it most.
",4 Case Study: Health Monitoring,[0],[0]
"Language varieties are associated, among other factors, with social class (Labov, 1964; Ash, 2002) and ethnic identity (Rose, 2006; Mendoza-Denton, 1997; Dubois and Horvath, 1998).",4 Case Study: Health Monitoring,[0],[0]
"As a case study, we evaluate the efficacy of LID systems in identifying English tweets containing health lexicons, across regions with varying Human Development Index (HDI).2 We compare EQUILID against langid.py and CLD2.",4 Case Study: Health Monitoring,[0],[0]
"Setup A list of health-related terms was compiled from lexicons for influenza (Lamb et al., 2013); psychological well-being (Smith et al., 2016; Preoţiuc-Pietro et al., 2015); and temporal orientation lexica correlated with age, gender and personality traits (Park et al., 2016).",4 Case Study: Health Monitoring,[0],[0]
"We incorporate the 100 highest-weighted alphanumeric terms from each lexicon, for a total of 385 unique terms.
",4 Case Study: Health Monitoring,[0],[0]
"To analyze the possible effect of regional language, we selected 25 countries with Englishspeaking populations and constructed 62 bounding boxes for major cities therein for study (listed in Supplementary Material).",4 Case Study: Health Monitoring,[0],[0]
"Using the Gnip API, a total of 984K tweets were collected during January 2016 which used at least one term and were authored within one of the bounding boxes.",4 Case Study: Health Monitoring,[0],[0]
"As these tweets are required to contain domain-specific terms, the vast majority are English.3 We therefore measure each system’s performance according to what percent of these tweets they classify as English, which estimates their Recall.",4 Case Study: Health Monitoring,[0],[0]
"Results To understand how Human Development Index relates to LID performance, we train a Logit Regression to predict whether a tweet with one of the target terms will be recognized as English according to the HDI of the tweet’s origin country.",4 Case Study: Health Monitoring,[0],[0]
Figure 2 reveals increasing disparity in LID accuracy for developing countries by the two baseline models.,4 Case Study: Health Monitoring,[0],[0]
"In contrast, EQUILID outperforms both systems at all levels of HDI and provides 30% more observations for countries with the lowest development levels.",4 Case Study: Health Monitoring,[0],[0]
"This performance improvement is increasingly critical in the global environment as more English text is generated from populous developing countries such as Nigeria (HDI
2HDI is a composite of life expectancy, education, and income per capita indicators, used to rank countries into tiers of human development.
",4 Case Study: Health Monitoring,[0],[0]
"3A manual analysis of a random sample of 1000 tweets showed that 99.4% were in English.
0.527) and India (HDI 0.624), which have tens of millions of anglophones each.",4 Case Study: Health Monitoring,[0],[0]
"EQUILID provides a 23.9% and 17.4% improvement in recall of English tweets for each country, respectively.",4 Case Study: Health Monitoring,[0],[0]
This study corroborates our hypothesis that sociallyequitable training corpora are an essential first step towards socially-equitable NLP.,4 Case Study: Health Monitoring,[0],[0]
"Globally-spoken languages often vary in how they are spoken according to regional dialects, topics, or sociolinguistic factors.",5 Conclusion,[0],[0]
"However, most LID systems are not designed and trained for this linguistic diversity, which has downstream consequences for what types of text are considered a part of the language.",5 Conclusion,[0],[0]
"In this work, we introduce a sociallyequitable LID system, EQUILID, built by (1) creating a dataset representative of the types of diversity within languages and (2) explicitly modeling multilingual and codes-switched communication for arbitrary language pairs.",5 Conclusion,[0],[0]
"We demonstrate that EQUILID significantly outperforms current broad-coverage LID systems and, in a realworld case study on tracking health-related content, show that EQUILID substantially reduces the LID performance disparity between developing and developed countries.",5 Conclusion,[0],[0]
Our work continues a recent emphasis on NLP for social good by ensuring NLP tools fully represent all people.,5 Conclusion,[0],[0]
The EQUILID system is publicly available at https: //github.com/davidjurgens/equilid and data is available upon request.,5 Conclusion,[0],[0]
"We thank the anonymous reviewers, the Stanford Data Science Initiative, and Twitter and Gnip for providing access to part of data used in this study.",Acknowledgments,[0],[0]
"This work was supported by the National Science Foundation through awards IIS-1514268, IIS-1159679, and IIS-1526745.",Acknowledgments,[0],[0]
Language identification (LID) is a critical first step for processing multilingual text.,abstractText,[0],[0]
"Yet most LID systems are not designed to handle the linguistic diversity of global platforms like Twitter, where local dialects and rampant code-switching lead language classifiers to systematically miss minority dialect speakers and multilingual speakers.",abstractText,[0],[0]
We propose a new dataset and a character-based sequence-tosequence model for LID designed to support dialectal and multilingual language varieties.,abstractText,[0],[0]
Our model achieves state-of-theart performance on multiple LID benchmarks.,abstractText,[0],[0]
"Furthermore, in a case study using Twitter for health tracking, our method substantially increases the availability of texts written by underrepresented populations, enabling the development of “socially inclusive” NLP tools.",abstractText,[0],[0]
Incorporating Dialectal Variability for Socially Equitable Language Identification,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1232–1242 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1232",text,[0],[0]
"Word embedding, which is also termed distributed word representation, has been a hot topic in the area of Natural Language Processing (NLP).",1 Introduction,[0],[0]
"The derived word embeddings have been used in plenty of tasks such as text classification (Liu
∗This is the corresponding author.
",1 Introduction,[0],[0]
"et al., 2015), information retrieval (Manning et al., 2008), sentiment analysis (Shin et al., 2016), machine translation (Cho et al., 2014) and so on.",1 Introduction,[0],[0]
"Recently, some classic word embedding methods have been proposed, like Continuous Bag-ofWord (CBOW), Skip-gram (Mikolov et al., 2013a), Global Vectors (GloVe) (Pennington et al., 2014).",1 Introduction,[0],[0]
"These methods can usually capture word-level semantic information but ignore the meaningful inner structures of words like English morphemes or Chinese characters.
",1 Introduction,[0],[0]
"The effectiveness of exploiting the internal compositions of words has been validated by some previous work (Luong et al., 2013; Botha and Blunsom, 2014; Chen et al., 2015; Cotterell et al., 2016).",1 Introduction,[0],[0]
"Some of them compute the word embeddings by directly adding the representations of morphemes/characters to context words or optimizing a joint objective over distributional statistics and morphological properties (Qiu et al., 2014; Botha and Blunsom, 2014; Chen et al., 2015; Luong et al., 2013; Lazaridou et al., 2013), while others introduce some probabilistic graphical models to build relationship between words and their internal compositions.",1 Introduction,[0],[0]
"e.g., Bhatia et al. (2016) treat word embeddings as latent variables for a prior distribution, which reflects words’ morphological properties, and feed the latent variables into a neural sequence model to obtain final word embeddings.",1 Introduction,[0],[0]
"Cotterell et al. (2016) construct a Gaussian graphical model that binds the morphological analysis to pre-trained word embeddings, which can help to smooth the noisy embeddings.",1 Introduction,[0],[0]
"Besides, these two methods also have the ability to predict embeddings for unseen words.
",1 Introduction,[0],[0]
"Different from all the above models (we regard them as Explicit models in Fig. 1) where internal compositions are directly used to encode morphological regularities into words and the
composition embeddings like morpheme embeddings are generated as by-products, we explore a new way to employ the latent meanings of morphological compositions rather than the compositions themselves to train word embeddings.",1 Introduction,[0],[0]
"As shown in Fig. 1, according to the distributional semantics hypothesis (Sahlgren, 2008), incredible and unbelievable probably have similar word embeddings because they have similar context.",1 Introduction,[0],[0]
"As a matter of fact, incredible is a synonym of unbelievable and their embeddings are expected to be close enough.",1 Introduction,[0],[0]
"Since the morphemes of the two words are different, especially the roots cred and believ, the explicit models may not significantly shorten the distance between the words in the vector space.",1 Introduction,[0],[0]
"Fortunately, the latent meanings of the different morphemes are the same (e.g., the latent meanings of roots cred, believ are “believe”) as listed in the lookup table (derived from the resources provided by Michigan State University),1 which evidently implies that incredible and unbelievable share the same meanings.",1 Introduction,[0],[0]
"In addition, by replacing morphemes with their latent meanings, we can directly and simply quantize the similarities between words and their sub-compositions with the same metrics used in most NLP tasks, e.g., cosine similarity.",1 Introduction,[0],[0]
"Subsequently, the similarities are utilized to calculate the weights of latent meanings of morphemes for each word.
",1 Introduction,[0],[0]
"In this paper, we try different strategies to
1https://msu.edu/˜defores1/gre/roots/ gre_rts_afx1.htm
modify the input layer and update rules of a neural language model, e.g., CBOW, Skipgram, and propose three lightweight and efficient models, which are termed Latent Meaning Models (LMMs), to not only encode morphological properties into words but also enhance the semantic similarities among word embeddings.",1 Introduction,[0],[0]
"Usually, the vocabulary derived from the corpus contains vast majority or even all of the latent meanings.",1 Introduction,[0],[0]
"Rather than generating and training extra embeddings for latent meanings, we directly override the embeddings of the corresponding words in the vocabulary.",1 Introduction,[0],[0]
"Moreover, a word map is created to describe the relations between words and the latent meanings of their morphemes.
",1 Introduction,[0],[0]
"For comparison, our models together with the state-of-the-art baselines are tested on two basic NLP tasks, which are word similarity and syntactic analogy, and one downstream text classification task.",1 Introduction,[0],[0]
The results show that LMMs outperform the baselines and get satisfactory improvement on these tasks.,1 Introduction,[0],[0]
"In all, the main contributions of this paper are summarized as follows.
",1 Introduction,[0],[0]
"• Rather than directly incorporating the morphological compositions (surface forms) of words, we decide to employ the latent meanings of the compositions (underlying forms) to train the word embeddings.",1 Introduction,[0],[0]
"To validate the feasibility of our purpose, three specific models, named LMMs, are proposed with different strategies to incorporate the latent meanings.
",1 Introduction,[0],[0]
"• We utilize a medium-sized English corpus to train LMMs and the state-of-the-art baselines, and evaluate their performance on two basic NLP tasks, i.e., word similarity and syntactic analogy, and one downstream text classification task.",1 Introduction,[0],[0]
The results show that LMMs outperform the baselines on five word similarity datasets.,1 Introduction,[0],[0]
"On the golden standard Wordsim-353 and RG-65, LMMs approximately achieve 5% and 7% gains over CBOW, respectively.",1 Introduction,[0],[0]
"For the syntactic analogy and text classification tasks, LMMs also surpass all the baselines.
",1 Introduction,[0],[0]
"• We conduct experiments to analyze the impacts of parameter settings, and the results demonstrate that the performance of LMMs on the smallest corpus is similar to the performance of CBOW on the corpus that is five times as large, which convinces us that LMMs are of great advantages to enhance word embeddings compared with traditional methods.",1 Introduction,[0],[0]
"Considering the high efficiency of CBOW proposed by Mikolov et al. (2013a), our LMMs are built upon CBOW.",2 Background and Related Work,[0],[0]
"Here, we first review some backgrounds of CBOW, and then present some related work on recent word-level and morphology-based word embedding methods.
",2 Background and Related Work,[0],[0]
"CBOW with Negative Sampling With a sliding window, CBOW utilizes the context words in the window to predict the target word.",2 Background and Related Work,[0],[0]
"Given a sequence of tokens T = {t1, t2, · · · , tn}, where n is the size of a training corpus, the objective of CBOW is to maximize the following average log probability equation:
L = 1
n n∑ i=1",2 Background and Related Work,[0],[0]
"log p ( ti|context(ti) ) , (1)
where context(ti) represents the context words of ti in the slide window, p ( ti|context(ti) ) is derived by softmax.",2 Background and Related Work,[0],[0]
"Due to huge size of English vocabulary, p ( ti|context(ti) ) can not be calculated in a tolerable time.",2 Background and Related Work,[0],[0]
"Therefore, negative sampling and hierarchical softmax are proposed to solve this problem.",2 Background and Related Work,[0],[0]
"Owing to the efficiency of negative sampling, all our models are trained based on it.",2 Background and Related Work,[0],[0]
"In terms of negative sampling, the log
probability log p(tO|tI) is transformed as: log δ ( vec′(tO) T vec(tI) )",2 Background and Related Work,[0],[0]
"+
m∑ i=1 log [ 1− δ",2 Background and Related Work,[0],[0]
( vec′(ti) T vec(tI) ),2 Background and Related Work,[0],[0]
],2 Background and Related Work,[0],[0]
",
(2)
where m denotes the number of negative samples, and δ(·) is the sigmoid function.",2 Background and Related Work,[0],[0]
The first item of Eq.,2 Background and Related Work,[0],[0]
(2) is the probability of target word when its context is given.,2 Background and Related Work,[0],[0]
"The second item indicates the probability that negative samples do not share the same context as the target word.
",2 Background and Related Work,[0],[0]
"Word-level Word Embedding In general, word embedding models can mainly be divided into two branches.",2 Background and Related Work,[0],[0]
"One is based on neural network like the classic CBOW model (Mikolov et al., 2013a), while the other is based on matrix factorization.",2 Background and Related Work,[0],[0]
"Besides CBOW, Skip-gram (Mikolov et al., 2013a) is another widely used neuralnetwork-based model, which predicts the context by using the target word (Mikolov et al., 2013a).",2 Background and Related Work,[0],[0]
"As for matrix factorization, Dhillon et al. (2015) proposed a spectral word embedding method to measure the correlation between word information matrix and context information matrix.",2 Background and Related Work,[0],[0]
"In order to combine the advantages of models based on neural network and matrix factorization, Pennington et al. (2014) proposed a famous word embedding model named GloVe, which is reported to outperform the CBOW and Skip-gram models on some tasks.",2 Background and Related Work,[0],[0]
These models are effective to capture word-level semantic information while neglecting inner structures of words.,2 Background and Related Work,[0],[0]
"In contrast, the unheeded inner structures are utilized in both our LMMs and other morphology-based models.
",2 Background and Related Work,[0],[0]
"Morphology-based Word Embedding Recently, some more fine-grained word embedding models are proposed by exploiting the morphological compositions of words, e.g., root and affixes.",2 Background and Related Work,[0],[0]
"These morphology-based models can be divided into two main categories.
",2 Background and Related Work,[0],[0]
"The first category directly adds the representations of internal structures to word embeddings or optimizes a joint objective over distributional statistics and morphological properties (Luong et al., 2013; Qiu et al., 2014; Botha and Blunsom, 2014; Lazaridou et al., 2013; Chen et al., 2015; Kim et al., 2016; Cotterell and Schütze, 2015).",2 Background and Related Work,[0],[0]
"Chen et al. (2015) proposed a character-enhanced Chinese word embedding model, which splits a Chinese word into several characters and add the characters into the input layer of their models.
",2 Background and Related Work,[0],[0]
"Luong et al. (2013) utilized the morpheme segments produced by Morfessor (Creutz and Lagus, 2007) and constructed morpheme trees for words to learn morphologically-aware word embeddings by the recursive neural network.",2 Background and Related Work,[0],[0]
Kim et al. (2016) incorporated the convolutional character information into English words.,2 Background and Related Work,[0],[0]
"Their model can learn character-level semantic information for embeddings, which is proved to be effective for some morpheme-rich languages.",2 Background and Related Work,[0],[0]
"However, with a huge size architecture, it’s very time-consuming.",2 Background and Related Work,[0],[0]
"Cotterell et al. (2015) augmented the log linear model to make the words, which share similar morphemes, gather together in vector space.
",2 Background and Related Work,[0],[0]
"The other category tries to use probabilistic graphical models to connect words with their morphological compositions, and further learns word embeddings (Bhatia et al., 2016; Cotterell et al., 2016).",2 Background and Related Work,[0],[0]
"Bhatia et al. (2016) employed morphemes and made them as prior knowledge of the latent word embeddings, then fed the latent variables into a neural sequence model to obtain final word embeddings.",2 Background and Related Work,[0],[0]
Cotterell et al. (2016) proposed a morpheme-based post-processor for pre-trained word embeddings.,2 Background and Related Work,[0],[0]
"They constructed a Gaussian graphical model which can extrapolate continuous representations for unknown words.
",2 Background and Related Work,[0],[0]
"However, these morphology-based models directly exploit the internal compositions of words to encode morphological regularities into word embeddings, and some by-products are also produced like morpheme embeddings.",2 Background and Related Work,[0],[0]
"In contrast, we employ the latent meanings of morphological compositions to provide deeper insights for training better word embeddings.",2 Background and Related Work,[0],[0]
"Furthermore, since the latent meanings are included in the vocabulary, there is no extra embedding being generated.",2 Background and Related Work,[0],[0]
We leverage different strategies to modify the input layer and update rules of CBOW when incorporating the latent meanings of morphemes.,3 Our Latent Meaning Models,[0],[0]
"Three specific models, named Latent Meaning Model-Average (LMM-A), LMM-Similarity (LMM-S) and LMM-Max (LMM-M), are proposed.",3 Our Latent Meaning Models,[0],[0]
"It should be stated that, for now, our models mainly concern the derivational morphemes, which can be interpreted to some meaningful words or phrases (i.e., latent meanings), not the inflectional morphemes like tense, number,
gender, etc.",3 Our Latent Meaning Models,[0],[0]
LMM-A assumes that all latent meanings of morphemes of a word have equal contributions to the word.,3 Our Latent Meaning Models,[0],[0]
LMM-A is applicable to the condition where words are correctly segmented into morphemes and each morpheme is interpreted to appropriate latent meanings.,3 Our Latent Meaning Models,[0],[0]
"However, refining the latent meanings for morphemes is timeconsuming and needs vast human annotations.",3 Our Latent Meaning Models,[0],[0]
"To address this concern, LMM-S is proposed.",3 Our Latent Meaning Models,[0],[0]
"Motivated by the attention scheme, LMM-S holds the assumption that all latent meanings have different contributions, and assigns the outliers small weights to let them have little impact on the representation of the target word.",3 Our Latent Meaning Models,[0],[0]
"Furthermore, in LMM-M, we only keep the latent meanings which have the greatest contributions to the corresponding word.",3 Our Latent Meaning Models,[0],[0]
"In what follows, we are going to introduce each of our LMMs in detail.",3 Our Latent Meaning Models,[0],[0]
"At the end of this section, we will introduce the update rules of the models.",3 Our Latent Meaning Models,[0],[0]
"Given a sequence of tokens T = {t1, t2, · · · , tn}, LMM-A assumes that morphemes’ latent meanings of token ti (i ∈",3.1 LMM-A,[0],[0]
"[1, n]) have equal contributions to ti, as shown in Fig. 2.",3.1 LMM-A,[0],[0]
The item for ti in the word map is ti 7→ Mi.,3.1 LMM-A,[0],[0]
"Mi is a set of latent meanings of ti’s morphemes, and it consists of three sub-parts Pi, Ri and Si corresponding to the latent meanings of prefixes, roots and suffixes of ti, respectively.",3.1 LMM-A,[0],[0]
"Hence, at the input layer, the
modified embedding of ti can be expressed as
v̂ti = 1
2
( vti + 1
Ni ∑ w∈Mi vw ) , (3)
where vti is the original word embedding of ti, Ni denotes the length of Mi and vw indicates the embedding of latent meaning",3.1 LMM-A,[0],[0]
"w. Meanwhile, we assume the original word embedding and the average embeddings of vw (w ∈ Mi) have equal weights, i.e., 0.5.",3.1 LMM-A,[0],[0]
"Eventually, v̂ti rather than vti is utilized for training in CBOW.",3.1 LMM-A,[0],[0]
This model is proposed based on the attention scheme.,3.2 LMM-S,[0],[0]
We observe that many morphemes have more than one latent meaning.,3.2 LMM-S,[0],[0]
"For instance, prefix in- means “in” and “not”, and suffix -ible means “able” and “capable”.2 As Fig. 3 shows, for the item incredible 7→ {",3.2 LMM-S,[0],[0]
"[in, not],
[believe], [able, capable] }
in the word map, the latent meanings have different biases towards “incredible”.",3.2 LMM-S,[0],[0]
"Therefore, we assign different weights to latent meanings.",3.2 LMM-S,[0],[0]
We measure the weights of latent meanings by calculating the normalized similarities between token ti and the corresponding latent meanings.,3.2 LMM-S,[0],[0]
"For LMM-S, the modified embedding of ti can be rewritten as
v̂ti = 1
2
[ vti + ∑ w∈Mi ω<ti,w> · vw ] , (4)
where vti is the original vector of ti, and ω<ti,w> denotes the weight between ti and the latent meaning w (w ∈Mi).",3.2 LMM-S,[0],[0]
"We use cos(va, vb) to denote the
2All the latent meanings of roots and affixes are referred to the resources we mentioned before.
",3.2 LMM-S,[0],[0]
"cosine similarity between va and vb, then ω<ti,w> is expressed as follows:
ω<ti,w> = cos(vti , vw)∑
x∈Mi cos(vti , vx)
.",3.2 LMM-S,[0],[0]
(5),3.2 LMM-S,[0],[0]
"To further eliminate the impacts of some uncorrelated latent meanings to a word, in LMM-M, we only select the latent meanings that have maximum similarities to the token ti from Pi, Ri and Si.",3.3 LMM-M,[0],[0]
"As is shown in Fig. 4, the latent meaning “not” of prefix in is finally selected since the similarity between “not” and “incredible” is larger than that between “in” and “incredible”.",3.3 LMM-M,[0],[0]
"For token ti, LMM-M is mathematically defined as
v̂ti = 1
2
[ vti + ∑ w∈M imax ω<ti,w> · vw ] , (6)
where M imax = {P imax, Rimax, Simax} is the set of latent meanings with maximum similarities towards token ti, and P imax, R i max, S",3.3 LMM-M,[0],[0]
"i max are obtained by the following equations:
P imax = argmaxw cos(vti , vw), w ∈ Pi, Rimax = argmaxw cos(vti , vw),",3.3 LMM-M,[0],[0]
"w ∈ Ri, (7) Simax = argmaxw cos(vti , vw), w ∈ Si.
",3.3 LMM-M,[0],[0]
"The normalized weight ω<ti,w> (w ∈ M imax) can similarly be derived like Eq.",3.3 LMM-M,[0],[0]
(5).,3.3 LMM-M,[0],[0]
"After modifying the input layer of CBOW, Eq. (1) can be rewritten as
L̂ = 1
n n∑ i=1",3.4 Update Rules for LMMs,[0],[0]
"log p ( vti | ∑ tj∈context(ti) v̂tj ) , (8)
where v̂tj is the modified vector of vtj (tj ∈ context(ti)).",3.4 Update Rules for LMMs,[0],[0]
"Since the word map describes top-level relations between words and the latent meanings, these relations don’t change during the training period.",3.4 Update Rules for LMMs,[0],[0]
"All parameters introduced by our models can be directly derived using the word map and word vectors, thus no extra parameter needs to be trained.",3.4 Update Rules for LMMs,[0],[0]
"When the gradient is propagated back to the input layer, we update not just the word vector vtj (tj ∈ context(ti)) but the vectors of the latent meanings in the vocabulary with the same weights as they are added to the vector vtj .",3.4 Update Rules for LMMs,[0],[0]
"Before conducting experiments, some experimental settings are firstly introduced in this section.",4 Experimental Setup,[0],[0]
We utilize a medium-sized English corpus to train all word embedding models.,4.1 Corpus and Word Map,[0],[0]
"The corpus stems from the website of the 2013 ACL Workshop on Machine Translation3 and is used in (Kim et al., 2016).",4.1 Corpus and Word Map,[0],[0]
We choose the news corpus of 2009 whose size is about 1.7GB.,4.1 Corpus and Word Map,[0],[0]
"It contains approximately 500 million tokens and 600,000 words in the vocabulary.",4.1 Corpus and Word Map,[0],[0]
"To get better quality of the word embeddings, we filter all digits and some punctuation marks out of the corpus.
",4.1 Corpus and Word Map,[0],[0]
"For many languages, there exist large morphological lexicons or morphological tools that can analyze any word form (Cotterell and Schütze, 2015).",4.1 Corpus and Word Map,[0],[0]
"To create the word map, we need to obtain the morphemes of each word and interpret them with the lookup table mentioned above to get the latent meanings.",4.1 Corpus and Word Map,[0],[0]
"Usually, the lookup table can also be derived from the morphological lexicons for different languages, although it costs some time and manpower, we can create the lookup table once for all since it represents the common knowledge with respect to a certain language.",4.1 Corpus and Word Map,[0],[0]
"Specifically, we first perform an
3http://www.statmt.org/wmt13/ translation-task.html
unsupervised morpheme segmentation using Morefessor (Creutz and Lagus, 2007) for the vocabularies.",4.1 Corpus and Word Map,[0],[0]
"Then we execute matching between the segmentation results and the morphological compositions in the lookup table, and the character sequence with largest overlap ratio will be viewed as a final morpheme and further be replaced by its latent meanings.",4.1 Corpus and Word Map,[0],[0]
"Although the lookup table employed in this paper contains latent meanings for only 90 prefixes, 382 roots and 67 suffixes, we focus on validating the feasibility of enhancing word embeddings with the latent meanings of morphemes, and expending the lookup table is left as future work.",4.1 Corpus and Word Map,[0],[0]
"For comparison, we choose three word-level state-of-the-art word embedding models including CBOW, Skip-gram (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014), and we also implement an Explicitly Morpheme-related Model (EMM), which is a variant version of the previous work (Qiu et al., 2014).",4.2 Baselines,[0],[0]
"The architecture of EMM is based on our LMM-A, where latent meanings are replaced back to morphemes and the embeddings of morphemes are also learned when training word embeddings.",4.2 Baselines,[0],[0]
"This enables our evaluation to focus on the critical difference between our models and the explicit model (Bhatia et al., 2016).",4.2 Baselines,[0],[0]
We utilize the source code of word2vec4 to train CBOW and Skip-gram.,4.2 Baselines,[0],[0]
GloVe is trained based on the code5 provided by Pennington et al. (2014).,4.2 Baselines,[0],[0]
We modify the source of word2vec and train our models and EMM.,4.2 Baselines,[0],[0]
"Parameter settings have a great effect on the performance of word embeddings (Levy et al., 2015).",4.3 Parameter Settings,[0],[0]
"For fairness, all models are trained based on equal parameter settings.",4.3 Parameter Settings,[0],[0]
"In order to accelerate the training process, CBOW, Skip-gram and EMM together with our models are trained by using the negative sampling technique.",4.3 Parameter Settings,[0],[0]
"It is suggested that the number of negative samples in the range 5-20 is useful for small corpus (Mikolov et al., 2013b).",4.3 Parameter Settings,[0],[0]
"If large corpus is used, the number of negative samples can be as small as 2-5.",4.3 Parameter Settings,[0],[0]
"According to the size of corpus we used, the number of negative samples is empirically set to be 20 in this paper.
",4.3 Parameter Settings,[0],[0]
"4https://github.com/dav/word2vec 5http://nlp.stanford.edu/projects/
glove
The dimension of word embedding is set as 200 like that in (Dhillon et al., 2015).",4.3 Parameter Settings,[0],[0]
"We set the context window size as 5 which is equal to the setting in (Mikolov et al., 2013b).",4.3 Parameter Settings,[0],[0]
This experiment is conducted to evaluate the ability of word embeddings to capture semantic information from corpus.,4.4.1 Word Similarity,[0],[0]
"For English word similarity, we employ two gold standard datasets including Wordsim-353 (Finkelstein et al., 2001) and RG-65 (Rubenstein and Goodenough, 1965) as well as some other widely-used datasets including Rare-Word (Luong et al., 2013), SCWS (Huang et al., 2012), Men-3k (Bruni et al., 2014) and WS-353-Related (Agirre et al., 2009).",4.4.1 Word Similarity,[0],[0]
More details of these datasets are shown in Table 1.,4.4.1 Word Similarity,[0],[0]
Each dataset consists of three columns.,4.4.1 Word Similarity,[0],[0]
The first two columns stand for word pairs and the last column is human score.,4.4.1 Word Similarity,[0],[0]
"We utilize the cosine similarity, which is used in many previous works (Mikolov et al., 2013b; Pennington et al., 2014), as the metric to measure the distance between two words.",4.4.1 Word Similarity,[0],[0]
The Spearman’s rank correlation coefficient (ρ) is employed to evaluate the similarity between our results and human scores.,4.4.1 Word Similarity,[0],[0]
Higher ρ means better performance.,4.4.1 Word Similarity,[0],[0]
"Based on the learned word embeddings, the core task of syntactic analogy is to answer the analogy question “a is to b as c is to ”.",4.4.2 Syntactic Analogy,[0],[0]
"We utilize the Microsoft Research Syntactic Analogies dataset, which is created by Mikolov (Mikolov et al., 2013c) with size of 8000.",4.4.2 Syntactic Analogy,[0],[0]
"To answer the syntactic analogy question “a is to b as c is to d” where d is unknown, we assume that the word representations of a, b, c, d are va, vb, vc, vd, respectively.",4.4.2 Syntactic Analogy,[0],[0]
"To get d, we first calculate v̂d = vb − va + vc.",4.4.2 Syntactic Analogy,[0],[0]
"Then, we find out the word d′ whose cosine similarity to v̂d is the largest.",4.4.2 Syntactic Analogy,[0],[0]
"Finally, we set d as d′.",4.4.2 Syntactic Analogy,[0],[0]
"To further evaluate the learned word embeddings, we also conduct 4 text classification tasks using the 20 Newsgroups dataset.6",4.4.3 Text Classification,[0],[0]
"The dataset totally contains around 19000 documents of 20 different newsgroups, and each corresponding to a different topic, such as guns, motorcycles, electronics and so on.",4.4.3 Text Classification,[0],[0]
"For each task, we randomly select the documents of 10 topics and split them into training/validation/test subsets at the ratio of 6:2:2, which are emplyed to train, validate and test an L2-regularized 10-categorization logistic regression (LR) classifier.",4.4.3 Text Classification,[0],[0]
"As mentioned in (Tsvetkov et al., 2015), here we also regard the average word embedding of words (excluding stop words and out-of-vocabulary words) in each document as the feature vector (the input of the classifier) of that document.",4.4.3 Text Classification,[0],[0]
"The LR classifier is implemented with the scikit-learn toolkit (Pedregosa et al., 2011), which is an open-source Python module integrating many state-of-the-art machine learning algorithms.",4.4.3 Text Classification,[0],[0]
"Word similarity is conducted to test the semantic information which is encoded in word embeddings, and the results are listed in Table 2 (first 6 rows).",5.1 The Results on Word Similarity,[0],[0]
We observe that our models surpass the comparative baselines on five datasets.,5.1 The Results on Word Similarity,[0],[0]
"Compared with the base model CBOW, it is remarkable that our models approximately achieve improvements of more than 5% and 7%, respectively, in the performance on the golden standard Wordsim-353 and RG-65.",5.1 The Results on Word Similarity,[0],[0]
"On WS-353-REL, the difference between CBOW and LMM-S even reaches 8%.",5.1 The Results on Word Similarity,[0],[0]
The advantage demonstrates the effectiveness of our methods.,5.1 The Results on Word Similarity,[0],[0]
"Based on our strategy, more semantic information will be captured in corpus when adding more latent meanings in the context window.",5.1 The Results on Word Similarity,[0],[0]
"By incorporating mophemes, EMM also performs better than other baselines but fails to get the performance as well as ours.",5.1 The Results on Word Similarity,[0],[0]
"Actually, EMM mainly tunes the distributions of words in vector space to let the morpheme-similar words gather closer, which means it just encodes more morphological properties into word embeddings but lacks the ability to capture more semantic information.",5.1 The Results on Word Similarity,[0],[0]
"Specially, because of the medium-
6http://qwone.com/˜jason/20Newsgroups
size corpus and the experimental settings, GloVe doesn’t perform as well as that described in (Pennington et al., 2014).",5.1 The Results on Word Similarity,[0],[0]
"In (Mikolov et al., 2013c), the dataset is divided into adjectives, nouns and verbs.",5.2 The Results on Syntactic Analogy,[0],[0]
"For brevity, we only report performance on the whole dataset.",5.2 The Results on Syntactic Analogy,[0],[0]
"As the middle row of Table 2 shows, all of our models outperform the comparative baselines to a great extent.",5.2 The Results on Syntactic Analogy,[0],[0]
"Compared with CBOW, the advantage of LMM-A even reaches to 7%.",5.2 The Results on Syntactic Analogy,[0],[0]
"Besides, we observe that the suffix of “b” usually is the same as the suffix of “d” when answering question “a is to b as c is to d”.",5.2 The Results on Syntactic Analogy,[0],[0]
"Based on our strategy, morphemesimilar words will not only gather closer but have a trend to group near the latent meanings of their morphemes, which makes our embeddings have the advantage to deal with the syntactic analogy problem.",5.2 The Results on Syntactic Analogy,[0],[0]
EMM also performs well on this task but is still weaker than our models.,5.2 The Results on Syntactic Analogy,[0],[0]
"Actually, syntactic analogy is also a semantics-related task because “c” and “d” are with similar meanings.",5.2 The Results on Syntactic Analogy,[0],[0]
"Since our models are better to capture semantic information, they lead to higher performance than the explicitly morphology-based models.",5.2 The Results on Syntactic Analogy,[0],[0]
"For each one of the 4 text classification tasks, we report the classification accuracy over the test set.",5.3 The Results on Text Classification,[0],[0]
The average classification accuracy across the 4 tasks is utilized as the evaluation metric for different models.,5.3 The Results on Text Classification,[0],[0]
The results are displayed in the bottom row of Table 2.,5.3 The Results on Text Classification,[0],[0]
"Since we simply use the average embedding of words as the feature vector for 10-categorization classification, the overall classification accuracies of all models are merely aroud 80%.",5.3 The Results on Text Classification,[0],[0]
"However, the classification accuracies of our LMMs still surpass all the baselines, especailly CBOW and GloVe.
",5.3 The Results on Text Classification,[0],[0]
"Moreover, it can be found that incorporating morphological knowledge (morphemes or latent meanings of morphemes) into word embeddings can contribute to enhancing the performance of word embeddings in the downstream NLP tasks.",5.3 The Results on Text Classification,[0],[0]
Parameter settings can affect the performance of word embeddings.,5.4 The Impacts of Parameter Settings,[0],[0]
"For example, the corpus with larger corpus size (the ratio of tokens used for training) contains more semantic information, which can improve the performance on word similarity.",5.4 The Impacts of Parameter Settings,[0],[0]
We analyze the impacts of corpus size and window size on the performance of word embeddings.,5.4 The Impacts of Parameter Settings,[0],[0]
"In the analysis of corpus size, we hold the same parameter settings as before.",5.4 The Impacts of Parameter Settings,[0],[0]
"The sizes of tokens used for training are separately 1/5, 2/5, 3/5, 4/5 and 5/5 of the entire corpus mentioned above.",5.4 The Impacts of Parameter Settings,[0],[0]
We utilize the result of word similarity on Wordsim-353 as the evaluation criterion.,5.4 The Impacts of Parameter Settings,[0],[0]
"From Fig. 5, we observe several phenomena.",5.4 The Impacts of Parameter Settings,[0],[0]
"Firstly, the performance of our LMMs is better than CBOW at each corpus size.",5.4 The Impacts of Parameter Settings,[0],[0]
"Secondly, the performance of CBOW is sensitive to the corpus size.",5.4 The Impacts of Parameter Settings,[0],[0]
"In contrast, LMMs’ performance is more stable than CBOW.",5.4 The Impacts of Parameter Settings,[0],[0]
"As we analyzed in word similarity experiment, LMMs can increase the semantic information of word embeddings.",5.4 The Impacts of Parameter Settings,[0],[0]
It is worth noting that the performance of LMMs on the smallest corpus is even better than CBOW’s performance on the largest corpus.,5.4 The Impacts of Parameter Settings,[0],[0]
"In the analysis of window size, we observe that the performance of all word embeddings trained by different models has a trend to ascend with the increasing of window size as illustrated in Fig. 6.",5.4 The Impacts of Parameter Settings,[0],[0]
Our LMMs outperform CBOW under all the pre-set conditions.,5.4 The Impacts of Parameter Settings,[0],[0]
"Besides, the worst performance of LMMs is nearly equal to the best performance of CBOW.",5.4 The Impacts of Parameter Settings,[0],[0]
"To visualize the embeddings of our models, we randomly select several words from the results of LMM-A. The dimensions of the selected word embeddings are reduced from 200 to 2 using Principal Component Analysis (PCA), and the 2-D word embeddings are illustrated in Fig. 7.",5.5 Word Embedding Visualization,[0],[0]
The words with different colors reflect that they have different morphemes.,5.5 Word Embedding Visualization,[0],[0]
It is apparent that words with similar morphemes have a trend to group together and stay near the latent meanings of their morphemes.,5.5 Word Embedding Visualization,[0],[0]
"In addition, we can also find some syntactic regularities in Fig. 7, for example, “physics” is to “physicist” as “science” is to “scientist”, and “physicist” and “scientist” stay near the latent meaning, i.e., “human”, of the suffix -ist.",5.5 Word Embedding Visualization,[0],[0]
"In this paper, we explored a new direction to employ the latent meanings of morphological compositions rather than the internal compositions themselves to train word embeddings.",6 Conclusion,[0],[0]
"Three specific models named LMM-A, LMM-S and LMM-M were proposed by modifying the input layer and update rules of CBOW.",6 Conclusion,[0],[0]
"The source code of LMMs is avaliable at https: //github.com/Y-Xu/lmm.
",6 Conclusion,[0],[0]
"To test the performance of our models, we chose three word-level word embedding models and implemented an Explicitly Morpheme-related Model (EMM) as comparative baselines, and tested them on two basic NLP tasks of word similarity and syntactic analogy, and one downstream text classification task.",6 Conclusion,[0],[0]
The experimental results demonstrate that our models outperform the baselines on five word similarity datasets.,6 Conclusion,[0],[0]
"On the syntactic analogy as well as the text classification tasks, our models also surpass all the baselines including the EMM.",6 Conclusion,[0],[0]
"In the future, we intend to evaluate our models for some morpheme-rich languages like Russian, German and so on.",6 Conclusion,[0],[0]
The authors are grateful to the reviewers for constructive feedback.,Acknowledgments,[0],[0]
"This work was supported by the National Natural Science Foundation of China (No.61572456), the Anhui Province Guidance Funds for Quantum Communication and Quantum Computers and the Natural Science Foundation of Jiangsu Province of China (No.BK20151241).",Acknowledgments,[0],[0]
Traditional word embedding approaches learn semantic information at word level while ignoring the meaningful internal structures of words like morphemes.,abstractText,[0],[0]
"Furthermore, existing morphology-based models directly incorporate morphemes to train word embeddings, but still neglect the latent meanings of morphemes.",abstractText,[0],[0]
"In this paper, we explore to employ the latent meanings of morphological compositions of words to train and enhance word embeddings.",abstractText,[0],[0]
"Based on this purpose, we propose three Latent Meaning Models (LMMs), named LMM-A, LMM-S and LMM-M respectively, which adopt different strategies to incorporate the latent meanings of morphemes during the training process.",abstractText,[0],[0]
"Experiments on word similarity, syntactic analogy and text classification are conducted to validate the feasibility of our models.",abstractText,[0],[0]
The results demonstrate that our models outperform the baselines on five word similarity datasets.,abstractText,[0],[0]
"On Wordsim-353 and RG-65 datasets, our models nearly achieve 5% and 7% gains over the classic CBOW model, respectively.",abstractText,[0],[0]
"For the syntactic analogy and text classification tasks, our models also surpass all the baselines including a morphology-based model.",abstractText,[0],[0]
Incorporating Latent Meanings of Morphological Compositions to Enhance Word Embeddings,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 45–50 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-2008",text,[0],[0]
Systems for automatic assessment of spontaneous spoken language proficiency (Fig. 1) are becoming increasingly important to meet the demand for English second language learning.,1 Introduction,[0],[0]
"Such systems are able to provide throughput and consistency
which are unachievable with human examiners.",1 Introduction,[0],[0]
This is a challenging task.,1 Introduction,[0],[0]
"There is a large vari-
ation in the quality of spoken English across all proficiency levels.",1 Introduction,[0],[0]
"In addition, candidates of the same skill level will have different accents, voices, mispronunciations, and sentence construction errors.",1 Introduction,[0],[0]
All of which are heavily influenced by the candidate’s L1 language and compounded by ASR errors.,1 Introduction,[0],[0]
It is therefore impossible in practice to observe all these variants in training.,1 Introduction,[0],[0]
"At test time, the predicted grade’s validity will decrease the more the candidate is mismatched to the data used to train the system.",1 Introduction,[0],[0]
For deployment of these systems to high-stakes tests the performance on all candidates needs to be consistent and highly correlated with human graders.,1 Introduction,[0],[0]
"To achieve this it is important that these systems can detect outlier speakers who need to be examined by, for example, human graders.
",1 Introduction,[0],[0]
"Previously, separate models were used to filter out ”non-scorable” candidates (Yoon and Xie, 2014; Zechner et al., 2009; Higgins et al., 2011; Xie et al., 2012).",1 Introduction,[0],[0]
"However, such models reject candidates based on whether they can be scored at all, rather than an automatic grader’s uncertainty 1 in its predictions.",1 Introduction,[0],[0]
"It was shown by van Dalen et al. (2015) that Gaussian Process (GP) graders give
1Uncertainty is used in the sense of the inverse of confidence to be consistent with Gal and Ghahramani (2016) and van Dalen et al. (2015).
45
state-of-the-art performance for automatic assessment and yield meaningful uncertainty estimates for rejection of candidates.",1 Introduction,[0],[0]
"There are, however, computational constraints on training set sizes for GPs.",1 Introduction,[0],[0]
"In contrast, Deep Neural Networks (DNNs) are able to scale to large data sets, but lack a native measure of uncertainty.",1 Introduction,[0],[0]
"However, Gal and Ghahramani (2016) have shown that Monte-Carlo Dropout (MCD) can be used to derive an uncertainty estimate for a DNN.
",1 Introduction,[0],[0]
"Alternatively, a Deep Density Network (DDN), which is a Mixture Density Network (Bishop, 1994) with only one mixture component, may be used to yield a mean and variance corresponding to the predicted grade and the uncertainty in the prediction.",1 Introduction,[0],[0]
"Similar to GP and DNNs with MCD, a standard DDN provides an implicit modelling of uncertainty in its prediction.",1 Introduction,[0],[0]
This implicit model may not be optimal for the task at hand.,1 Introduction,[0],[0]
"Hence, a novel approach to explicitly model uncertainty is proposed in which the DDN is trained in a multitask fashion to model a low variance real data distribution and a high variance artificial data distribution which represents candidates with unseen characteristics.",1 Introduction,[0],[0]
"The principled method for dealing with uncertainty in statistical modelling is the Bayesian approach, where a conditional posterior distribution over grades, g, given inputs, x, and training data D = {ĝ, x̂} is computed by marginalizing over all models:
p(g|x, D) = ∫ p(g|x,M)p(M|D)dM (1)
where p(M|D) is a prior over a model given the data.",2 Prediction Uncertainty,[0],[0]
"Given the posterior, the predictive mean and the variance (uncertainty) can be computed using:
µg(x) =
∫ p(g|x, D)gdg
σ2g(x) = ∫ p(g|x, D)g2dg − µ2g(x)
(2)
(3)",2 Prediction Uncertainty,[0],[0]
"Eq. 2, 3 can be analytically solved for a class of models called Gaussian Processes (GP) (Rasmussen and Williams, 2006), a powerful nonparametric model for regression.",2.1 Gaussian Processes,[0],[0]
"The GP induces
a conditional posterior in the form of a normal distribution over grades g given an input x and training data D:
p(g|x; D) = N",2.1 Gaussian Processes,[0],[0]
"(g; µg(x|D), σ2g(x|D))",2.1 Gaussian Processes,[0],[0]
"(4)
With mean function µg(x|D) and variance function σ2g(x|D), which is a function of the similarity of an input x to the training data inputs x̂, where the similarity metric is defined by a covariance function k(., .).",2.1 Gaussian Processes,[0],[0]
"The nature of GP variance means that the model is uncertain in predictions for inputs far away from the training data, given appropriate choice of k(., .).",2.1 Gaussian Processes,[0],[0]
"Unfortunately, without sparsification approaches, the computational and memory requirements of GPs become prohibitively expensive for large data sets.",2.1 Gaussian Processes,[0],[0]
"Furthermore, GPs are known to scale poorly to higher dimensional features (Rasmussen and Williams, 2006).",2.1 Gaussian Processes,[0],[0]
"Alternatively, a grader can be constructed using Deep Neural Networks (DNNs) which have a very flexible architecture and scale well to large data sets.",2.2 Monte-Carlo Dropout,[0],[0]
"DNNs, however, lack a native measure of uncertainty.",2.2 Monte-Carlo Dropout,[0],[0]
"Uncertainty estimates for DNNs can be computed using a Monte-Carlo ensemble approximation to Eq. 2, 3:
µ̂g(x) = 1
N
N∑
i=1
f(x;M(i))
σ̂2g(x) = 1
N
N∑
i=1
( f(x; M(i)) )",2.2 Monte-Carlo Dropout,[0],[0]
"2 − µ̂2g(x)
(5)
(6)
where there are N DNN models in the ensemble, M(i) is a DNN with a particular architecture and parameters sampled from p(M|D) using Monte Carlo Dropout (MCD) (Srivastava et al., 2014), and f(x; M(i)) are the DNN predictions.",2.2 Monte-Carlo Dropout,[0],[0]
"Recent work by Gal and Ghahramani (2016) showed that MCD is equivalent to approximate variational inference in GPs, and can be used to yield meaningful uncertainty estimates for DNNs.",2.2 Monte-Carlo Dropout,[0],[0]
"Furthermore, Gal and Ghahramani (2016) show that different choices of DNN activation functions correspond to different GP covariance functions.",2.2 Monte-Carlo Dropout,[0],[0]
"MCD uncertainty assumes that for inputs further from the training data, different subnets will produce increasingly differing outputs, leading to larger variances.",2.2 Monte-Carlo Dropout,[0],[0]
"Unfortunately, it is difficult to know beforehand which activation functions accomplish this in practice.",2.2 Monte-Carlo Dropout,[0],[0]
"Instead of relying on a Monte Carlo approximation to Eq. 1, a DNN can be modified to produce a prediction of both a mean and a variance:
µg(x) = fµ(x; M) σ2g(x) = fσ2(x; M)
(7)
(8)
parametrising a normal distribution over grades conditioned on the input, similar to a GP.",3 Deep Density Networks,[0],[0]
"This architecture is a Deep Density Network (DDN), which is a Mixture Density Network (MDN) (Bishop, 1994) with only one mixture component.",3 Deep Density Networks,[0],[0]
DDNs are trained by maximizing the likelihood of the training data.,3 Deep Density Networks,[0],[0]
The variance of the DDN represents the natural spread of grades at a given input.,3 Deep Density Networks,[0],[0]
"This is an implicit measure of uncertainty, like GP and MCD variance, because it is learned automatically as part of the model.",3 Deep Density Networks,[0],[0]
"However, this doesn’t enforce higher variance further away from training points in DDNs.",3 Deep Density Networks,[0],[0]
"It is possible to explic-
itly teach a DDN to predict a high or low variance for inputs which are unlike or similar to the training data, respectively (Fig. 2).",3 Deep Density Networks,[0],[0]
This requires a novel training procedure.,3 Deep Density Networks,[0],[0]
"Two normal distributions are constructed: a low-variance real (training) data distribution pD and a high-variance artificial data distribution pN, which models data outside the real training data region.",3 Deep Density Networks,[0],[0]
The DDN needs to model both distributions in a multi-task (MT) fashion.,3 Deep Density Networks,[0],[0]
"The loss function for training the DDN with explicitly specified uncertainty is the expectation over the training data of the KL divergence between the distribution it parametrizes and both the real and artificial data distributions:
L = Ex̂[KL(pD||p(g|x̂; M)]",3 Deep Density Networks,[0],[0]
"+ α · Ex̃[KL(pN||p(g|x̃; M)]
(9)
where α is the multi-task weight.",3 Deep Density Networks,[0],[0]
The DDN with explicit uncertainty is trained in a two stage fashion.,3 Deep Density Networks,[0],[0]
"First, a standard DDN M0
is trained, then a DDN M is instantiated using the parameters of M0 and trained in a multi-task fashion.",3 Deep Density Networks,[0],[0]
"The real data distribution pD is defined by M0 (Eq. 7, 8).",3 Deep Density Networks,[0],[0]
"The artificial data distribution pN is constructed by generating artificial inputs x̃ and the associated mean and variance targets µ(x̃), σ2(x̃):
pN = N (g; fµ(x̃; M0), σ2(x̃)) (10)
",3 Deep Density Networks,[0],[0]
The predictions of M0 are used as the targets for µ(x̃).,3 Deep Density Networks,[0],[0]
The target variance σ2(x̃) should depend on the similarity of x̃ to the training data.,3 Deep Density Networks,[0],[0]
"Here, this variance is modelled by the squared normalized Euclidean distance from the mean of x̂, with a diagonal covariance matrix, scaled by a hyperparameter λ.",3 Deep Density Networks,[0],[0]
"The artificial inputs x̃ need to be different to, but related to the real data x̂. Ideally, they should represent candidates with unseen characteristics, such as L1, accent and proficiency.",3 Deep Density Networks,[0],[0]
"A simple approach to generating x̃ is to use a Factor Analysis (FA) (Murphy, 2012) model trained on x̂.",3 Deep Density Networks,[0],[0]
"The generative model of FA is:
x̃ ∼ N",3 Deep Density Networks,[0],[0]
"(Wz + µ, γΨ), z ∼ N (0, γI) (11)
where W is the loading matrix, Ψ the diagonal residual noise variance, µ the mean, all derived from x̂, and γ is used to control the distance of the generated data from the real training data region.",3 Deep Density Networks,[0],[0]
During training the artificial inputs are sampled from the FA model.,3 Deep Density Networks,[0],[0]
"AUCRR = AUCvar
AUCmax (12)
As previously stated, the operating scenario is to use a model’s estimate of the uncertainty in
its prediction to reject candidates to be assessed by human graders for high-stakes tests, maximizing the increase in performance while rejecting the least number of candidates.",4 Experimental Results,[0],[0]
The rejection process is illustrated using a rejection plot (Fig. 3).,4 Experimental Results,[0],[0]
"As the rejection fraction is increased, model predictions are replaced with human scores in some particular order, increasing overall correlation with human graders.",4 Experimental Results,[0],[0]
"Fig. 3 has 3 curves representing different orderings: expected random rejection, optimal rejection and model rejection.",4 Experimental Results,[0],[0]
"The expected random performance curve is a straight line from the base predictive performance to 1.0, representing rejection in a random order.",4 Experimental Results,[0],[0]
The optimal rejection curve is constructed by rejecting predictions in order of decreasing mean square error relative to human graders.,4 Experimental Results,[0],[0]
A rejection curve derived from a model should sit between the random and optimal curves.,4 Experimental Results,[0],[0]
"In this work, model rejection is in order of decreasing predicted variance.
",4 Experimental Results,[0],[0]
"The following metrics are used to assess and compare models: Pearson Correlation Coefficient (PCC) with human graders, the standard performance metric in assessment (Zechner et al., 2009; Higgins et al., 2011); 10% rejection PCC, which illustrates the predictive performance at a partic-
ular operating point, i.e. rejecting 10% of candidates; and Area under a model’s rejection curve (AUC) (Fig 3).",4 Experimental Results,[0],[0]
"However, AUC is influenced by the base PCC of a model, making it difficult to compare the rejection performance.",4 Experimental Results,[0],[0]
"Thus, a metric independent of predictive performance is needed.",4 Experimental Results,[0],[0]
"The proposed metric, AUCRR (Eq. 12), is the ratio of the areas under the actual (AUCvar) and optimal (AUCmax) rejection curves relative to the random rejection curve.",4 Experimental Results,[0],[0]
"Ratios of 1.0 and 0.0 correspond to perfect and random rejection, respectively.
",4 Experimental Results,[0],[0]
"All experiments were done using 33- dimensional pronunciation, fluency and acoustic features derived from audio and ASR transcriptions of responses to questions from the BULATS exam (Chambers and Ingham, 2011).",4 Experimental Results,[0],[0]
The ASR system has a WER of 32% on a development set.,4 Experimental Results,[0],[0]
"The training and test sets have 4300 and 224 candidates, respectively.",4 Experimental Results,[0],[0]
"Each candidate provided a response to 21 questions, and the features used are aggregated over all 21 questions into a single feature vector.",4 Experimental Results,[0],[0]
The test data was graded by expert graders at Cambridge English.,4 Experimental Results,[0],[0]
These experts have inter-grader PCCs in the range 0.95-0.97.,4 Experimental Results,[0],[0]
"Candidates are equally distributed across CEFR grade levels (Europe, 2001).
",4 Experimental Results,[0],[0]
The input features where whitened by subtracting the mean and dividing by the standard deviation for each dimension computed on all training speakers.,4 Experimental Results,[0],[0]
"The Adam optimizer (Kingma and Ba, 2015), dropout (Srivastava et al., 2014) regularization with a dropout keep probability of 0.6 and an exponentially decaying learning rate are used with decay factor of 0.86 per epoch, batch size 50.",4 Experimental Results,[0],[0]
All networks have 2 hidden layers with 180 rectified linear units (ReLU) in each layer.,4 Experimental Results,[0],[0]
"DNN and DDN models were implemented in Tensorflow (Abadi et al., 2015).",4 Experimental Results,[0],[0]
"Models were initialized using the Xavier Initializer (Glorot and Bengio, 2010).",4 Experimental Results,[0],[0]
A validation set of 100 candidates was selected from the training data to tune the model and hyperparameters.,4 Experimental Results,[0],[0]
"GPs were run using Scikit-Learn (Pedregosa et al., 2011) using a squared exponential covariance function.
",4 Experimental Results,[0],[0]
"The Gaussian Process grader, GP, is a competitive baseline (Tab. 1).",4 Experimental Results,[0],[0]
GP variance clearly yields uncertainty which is useful for rejection.,4 Experimental Results,[0],[0]
"A DNN with ReLU activation, MCD, achieves grading performance similar to the GP.",4 Experimental Results,[0],[0]
"However, MCD fails to yield an informative uncertainty for rejection, with performance barely above random.",4 Experimental Results,[0],[0]
"If the tanh activation function, MCDtanh, is used instead, then a DNN is able to provide a meaningful measure of uncertainty using MCD, at the cost of grading performance.",4 Experimental Results,[0],[0]
"It is likely that ReLU activations correspond to a GP covariance function which is not suited for rejection on this data.
",4 Experimental Results,[0],[0]
The standard DDN has comparable grading performance to the GP and DNNs.,4 Experimental Results,[0],[0]
"AUCRR of the DDN is on par with the GP, but the 10% rejection PCC is lower, indicating that the DDN is not as effective at rejecting the worst outlier candidates.",4 Experimental Results,[0],[0]
"The approach proposed in this work, a DDN trained in a multi-task fashion (DDN+MT), achieves significantly higher rejection performance, resulting in the best AUCRR and 10% rejection PCC, showing its better capability to detect outlier candidates.",4 Experimental Results,[0],[0]
"Note, AUC reflects similar trends to AUCRR, but not
as clearly, which is demonstrated by Fig. 4.",4 Experimental Results,[0],[0]
"The model was found to be insensitive to the choice of hyper-parameters α and γ, but λ needed to be set to produce target noise variances σ2(x̃) larger than data variances σ2(x̂).",4 Experimental Results,[0],[0]
A novel method for explicitly training DDNs to yield uncertainty estimates is proposed.,5 Conclusions and Future Work,[0],[0]
A DDN is a density estimator which is trained to model two distributions in a multi-task fashion (1) the low variance (uncertainty) true data distribution and (2) a generated high variance artificial data distribution.,5 Conclusions and Future Work,[0],[0]
The model is trained by minimizing the KL divergence between the DDN and the true data distribution (1) and between the DDN and the artificial data distribution (2).,5 Conclusions and Future Work,[0],[0]
The DDN should assign its prediction of low or high variance (uncertainty) if the input is similar or dissimilar to the true data respectively.,5 Conclusions and Future Work,[0],[0]
The artificial data distribution is given by a factor analysis model trained on the real data.,5 Conclusions and Future Work,[0],[0]
"During training the artificial data is sampled from this distribution.
",5 Conclusions and Future Work,[0],[0]
This method outperforms GPs and Monte-Carlo Dropout in uncertainty based rejection for automatic assessment.,5 Conclusions and Future Work,[0],[0]
"However, the effect of the nature of artificial data on rejection performance should be further investigated and other data generation methods, such as Variational AutoEncoders (Kingma and Welling, 2014), and metrics to assess similarity between artificial and real training data should be examined.",5 Conclusions and Future Work,[0],[0]
The proposed approach must also be assessed on other tasks and datasets.,5 Conclusions and Future Work,[0],[0]
"This research was funded under the ALTA Institute, University of Cambridge as well as the Engineering and Physical Sciences Research Council.",Acknowledgments,[0],[0]
"Thanks to Cambridge English, University of Cambridge, for support and access to the BULATS data.",Acknowledgments,[0],[0]
There is a growing demand for automatic assessment of spoken English proficiency.,abstractText,[0],[0]
"These systems need to handle large variations in input data owing to the wide range of candidate skill levels and L1s, and errors from ASR.",abstractText,[0],[0]
"Some candidates will be a poor match to the training data set, undermining the validity of the predicted grade.",abstractText,[0],[0]
"For high stakes tests it is essential for such systems not only to grade well, but also to provide a measure of their uncertainty in their predictions, enabling rejection to human graders.",abstractText,[0],[0]
"Previous work examined Gaussian Process (GP) graders which, though successful, do not scale well with large data sets.",abstractText,[0],[0]
Deep Neural Networks (DNN) may also be used to provide uncertainty using Monte-Carlo Dropout (MCD).,abstractText,[0],[0]
This paper proposes a novel method to yield uncertainty and compares it to GPs and DNNs with MCD.,abstractText,[0],[0]
The proposed approach explicitly teaches a DNN to have low uncertainty on training data and high uncertainty on generated artificial data.,abstractText,[0],[0]
"On experiments conducted on data from the Business Language Testing Service (BULATS), the proposed approach is found to outperform GPs and DNNs with MCD in uncertainty-based rejection whilst achieving comparable grading performance.",abstractText,[0],[0]
Incorporating Uncertainty into Deep Learning for Spoken Language Assessment,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 1833–1843 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Temporal information extraction is becoming an active research field in natural language processing (NLP) due to the rapidly growing need for NLP applications such as timeline generation and question answering (Llorens et al., 2015; Meng et al., 2017).",1 Introduction,[0],[0]
It has great potential to create many practical applications.,1 Introduction,[0],[0]
"For example, SemEval2015 Task 4 (Minard et al., 2015) collects news articles about a target entity and the task required participants automatically ordering the events in-
volving that entity in a timeline.",1 Introduction,[0],[0]
The timeline representation of news can help people more easily comprehend a mass of information.,1 Introduction,[0],[0]
"This work aims to contribute to such timeline applications by extracting temporal information in specific domains like news articles.
",1 Introduction,[0],[0]
"TimeBank1 (Pustejovsky et al., 2003) is the first widely used corpus with temporal information annotated in the NLP community.",1 Introduction,[0],[0]
"It contains 183 news articles that have been annotated with events, time expressions and temporal relations between events and time expressions.",1 Introduction,[0],[0]
"The annotation follows the TimeML2 specification (Saurı et al., 2006).",1 Introduction,[0],[0]
"Along with the TimeBank and other temporal information corpora, a series of competitions on temporal information extraction (TempEval-1,2,3) (Verhagen et al., 2009, 2010; UzZaman et al., 2012) are attracting growing research efforts.
",1 Introduction,[0],[0]
A majority of temporal information corpora adopt temporal links (TLINKs) to encode temporal information in documents.,1 Introduction,[0],[0]
"A TLINK denotes a temporal relation between mentions, i.e., events, time expressions and document creation time (DCT) (Setzer, 2002).",1 Introduction,[0],[0]
"However, annotating TLINKs is a painful work, because annotation candidates are quadratic to the number of mentions in a document.",1 Introduction,[0],[0]
"The original TimeBank only annotated those “salient” mention pairs judged by annotators, while the definition of “salient” is not necessarily clear.",1 Introduction,[0],[0]
"Annotators had to face a complicated task; identify “salient” mention pairs, and label temporal relations.",1 Introduction,[0],[0]
"For solving this, many dense annotation schemata are proposed to force annotators to annotate more or even complete graph pairs.",1 Introduction,[0],[0]
"However, dense annotation is time-consuming and unstable human judgments
1https://catalog.ldc.upenn.edu/LDC2006T08 2http://www.timeml.org/
1833
on “salient” pairs are not improved at all.",1 Introduction,[0],[0]
"As a consequence, a high proportion of “vague” or “nolink” pairs appears in these dense corpora such as TimeBank-Dense (Cassidy et al., 2014).
",1 Introduction,[0],[0]
"In this work, we propose a new approach to obtain temporal relations from time anchors, i.e. absolute time value, of all mentions.",1 Introduction,[0],[0]
We assume that a temporal relation can be induced by comparing the relative temporal order of two time anchors (e.g. YYYY-MM-DD) in a time axis.,1 Introduction,[0],[0]
"We use pre-defined rules (Section 3) to generate temporal order (TORDER) relations (e.g. BEFORE, AFTER, SAME DAY, etc.) by taking two annotated time anchors as input.",1 Introduction,[0],[0]
"This proposal requires the annotation of time anchors, of which the annotation effort is linear with the number of mentions.",1 Introduction,[0],[0]
"This is the first work to obtain temporal relations shifted from the annotation of individual mentions, which is distinguished from most annotation work of manually annotating mention pairs.
",1 Introduction,[0],[0]
This approach brings several advantages over the current temporal relation annotation.,1 Introduction,[0],[0]
"First, as long as time anchors of all mentions in a document are given, our pre-defined rules can induce the temporal relations for all the quadratic pairs.",1 Introduction,[0],[0]
This skips the step of identifying “salient” pairs.,1 Introduction,[0],[0]
"Second, annotating the time anchors is relatively easy, as the annotation work is linear to the number of mentions.",1 Introduction,[0],[0]
"Third, the automatic generation rules can provide flexible relation types based on our definition and this increased informativeness might contribute positively to downstream tasks.
",1 Introduction,[0],[0]
"In our first evaluation (Section 4), we compare the correspondence and difference between the new TORDERs and conventional TLINKs.",1 Introduction,[0],[0]
"The comparison of empirical statistics shows the new data is label balanced, contains informative relations and reduces “vague” relations.",1 Introduction,[0],[0]
"Besides, the classification performance suggests the new data achieve reasonable accuracy, although accuracy numbers are not directly comparable.
",1 Introduction,[0],[0]
Many text processing tasks are often requiring to know time anchors when events occurred in a timeline.,1 Introduction,[0],[0]
"In Section 5, we evaluate the data in a downstream time anchor prediction task (Reimers et al., 2016) by using the temporal relation recognizers separately trained with TORDERs or TLINKs.",1 Introduction,[0],[0]
The main results show that the recognizer trained with our TORDERs significantly outperforms the recognizer trained with the TLINKs by 14.1 point exact match accuracy.,1 Introduction,[0],[0]
TimeBank started a wave of data-driven temporal information extraction research in the NLP community.,2.1 Temporal Relation Annotation,[0],[0]
The original TimeBank only annotated relations judged to be salient by annotators and resulted in sparse annotations.,2.1 Temporal Relation Annotation,[0],[0]
"Subsequent TempEval-1,2,3 competitions (Verhagen et al., 2009, 2010; UzZaman et al., 2012) mostly relied on TimeBank, but also aimed to improve coverage by annotating relations between all events and time expressions in the same sentence.",2.1 Temporal Relation Annotation,[0],[0]
"However, most missing relations between mentions in different sentences are not considered.
",2.1 Temporal Relation Annotation,[0],[0]
"In order to solve the sparsity issue, researchers started the work towards denser annotation schema.",2.1 Temporal Relation Annotation,[0],[0]
Bramsen et al. (2006) annotated multi-sentence segments of text to build directed acyclic graphs.,2.1 Temporal Relation Annotation,[0],[0]
"Kolomiyets et al. (2012) annotated temporal dependency structures, though they only focused on relations between pairs of events.",2.1 Temporal Relation Annotation,[0],[0]
Do et al. (2012) produced the densest annotation and the annotator was required to annotate pairs “as many as possible”.,2.1 Temporal Relation Annotation,[0],[0]
Cassidy et al. (2014) proposed a compulsory mechanism to force annotators to label every pair in a given sentence window.,2.1 Temporal Relation Annotation,[0],[0]
"They performed the annotation (TimeBankDense) on a subset (36 documents) of TimeBank, which achieved a denser corpus with 6.3 TLINKs per event and time expression, comparing to 0.7 in the original TimeBank corpus.",2.1 Temporal Relation Annotation,[0],[0]
"However, it raises the issue that hand-labeling all dense TLINKs is extremely time-consuming and the unclear definition of “salient” is not improved at all.",2.1 Temporal Relation Annotation,[0],[0]
The majority of the temporal relation classifiers focus on exploiting a variety of features to improve the performance in TimeBank.,2.2 Temporal Relation Classification,[0],[0]
Laokulrat et al. (2013) extracted lexical and morphological features derived from WordNet synsets.,2.2 Temporal Relation Classification,[0],[0]
"Mani et al. (2006); D’Souza and Ng (2013) incorporated semantic relations between verbs from VerbOcean.
",2.2 Temporal Relation Classification,[0],[0]
"Recently, more researchers move on to diverse approaches on the TimeBank-Dense corpus.",2.2 Temporal Relation Classification,[0],[0]
Chambers et al. (2014) proposed a multi-sieve classifier composed of several rule-based and machine learning based sieves ranked by their precision.,2.2 Temporal Relation Classification,[0],[0]
"Mirza and Tonelli (2016) started to mine the value of low-dimensional word embeddings by concatenating them with traditional sparse feature
vectors to improve their classifier.",2.2 Temporal Relation Classification,[0],[0]
"Inspired by the success of the deep learning work in the similar task: relation extraction, Cheng and Miyao (2017) proposed the shortest dependency path based Bi-directional Long short-term memory (Hochreiter and Schmidhuber, 1997)",2.2 Temporal Relation Classification,[0],[0]
"(Bi-LSTM) to achieve state-of-the-art performance in the TimeBank-Dense corpus, which is adopted for the experiments in this paper.",2.2 Temporal Relation Classification,[0],[0]
There are two reasons to use this classifier: 1) intersentence temporal relations are well treated.,2.2 Temporal Relation Classification,[0],[0]
"2) only word, part-of-speech and dependency relation embeddings are required as input.",2.2 Temporal Relation Classification,[0],[0]
"A related task: Cross-Document Event Ordering (Minard et al., 2015) aims to order the events involving a target entity in a timeline given written news in English.",2.3 Time Anchor Annotation,[0],[0]
"Compared to traditional TLINKs, annotating time anchors of events is intuitively more straightforward in such tasks.
",2.3 Time Anchor Annotation,[0],[0]
"Reimers et al. (2016) proposed an annotation scheme, which requires annotators to infer the exact time of each individual event.",2.3 Time Anchor Annotation,[0],[0]
They distinguished events that occur at a Single-Day from that span over Multi-Day by setting the granularity as one day.,2.3 Time Anchor Annotation,[0],[0]
"For Single-Day events, the event time is written in the format ‘YYYY-MM-DD’ when the precise event time can be determined.",2.3 Time Anchor Annotation,[0],[0]
"Otherwise, they required annotators to narrow down the possible time as precisely as possible.",2.3 Time Anchor Annotation,[0],[0]
"An imprecise Single-Day event can be annotated as a tuple (after, before), e.g. ‘(after 1998-10-02, )’, ‘(, before 2000-01-31)’ or ‘(after 1998-10-02, before 2000- 01-31)’.",2.3 Time Anchor Annotation,[0],[0]
"In the case of Multi-Day, an event is annotated as a tuple (begin, end), where begin and end are represented with Single-Day.",2.3 Time Anchor Annotation,[0],[0]
"For instance of a sentence:
The economy created jobs at a surprisingly robust pace in January, the government reported on Friday, evidence that America’s economic stamina has withstood any disruption caused so far by the financial tumult in Asia.
",2.3 Time Anchor Annotation,[0],[0]
"The Multi-Day event created is annotated as (begin=1998-01-01, end=1998-01-31).",2.3 Time Anchor Annotation,[0],[0]
The Single-Day event reported is annotated as the same day as DCT (1998-02-06).,2.3 Time Anchor Annotation,[0],[0]
"The imprecise Multi-Day event disruption is annotated as (begin=(, before1998-02-06), end=(, before1998-0206))",2.3 Time Anchor Annotation,[0],[0]
"as the event must have occurred before the
time of this news, but the precise begin and end dates cannot be inferred from the text.",2.3 Time Anchor Annotation,[0],[0]
Time anchors have the capability of anchoring all the events from a document into the same timeline as shown in Figure 1.,2.3 Time Anchor Annotation,[0],[0]
"They annotated the time anchors of total 1,498 events from 36 documents of TimeBank-Dense.
",2.3 Time Anchor Annotation,[0],[0]
"In temporal information retrieval, Berberich et al. (2010) proposed a four-tuple representation (‘earliest begin’, ‘latest begin’, ‘earliest end’, ‘latest end’) for uncertain time expression (e.g. ‘1990s’) in order to integrate such temporal information into language model.",2.3 Time Anchor Annotation,[0],[0]
"In the time anchor annotation, an event ‘in 1990s’ will be annotated as a Multi-Day event with imprecise begin and end points, i.e. (begin=(after 1990-01-01, before199912-31), end=(after 1990-01-01, before1999-1231)), which is quite similar to their four-tuple representation.",2.3 Time Anchor Annotation,[0],[0]
"TimeML states that TLINKs present a temporal relation between event to event, event to time expression, and event to DCT.",3 Automatic generation of TORDERs,[0],[0]
The sparse TLINK coverage in the majority of temporal information corpora is attributed to the unstable identification of “salient” pairs by human annotators.,3 Automatic generation of TORDERs,[0],[0]
"Denser annotation schemata somehow improved sparseness, but the annotation work became very timeconsuming.",3 Automatic generation of TORDERs,[0],[0]
"These issues plague the development of temporal information extraction work.
",3 Automatic generation of TORDERs,[0],[0]
Our temporal order (TORDER) proposal is designed with the goal of solving unstable recognition of “salient” pairs and reducing annotation effort.,3 Automatic generation of TORDERs,[0],[0]
We hypothesize that a temporal relation can be automatically computed by comparing the relative temporal order between two time anchors (e.g. YYYY-MM-DD) in a time axis.,3 Automatic generation of TORDERs,[0],[0]
"We propose a set of pre-defined generation rules, which have the capability to rigorously induce a TORDER by taking the two annotated time anchors as input.",3 Automatic generation of TORDERs,[0],[0]
"Annotat-
ing time anchors of individual mentions extremely reduces annotation effort, as it is linear with mention numbers.",3 Automatic generation of TORDERs,[0],[0]
"As long as time anchors are given, our pre-defined rules can induce the temporal relations for all the quadratic pairs, which skips the step of identifying “salient” pairs.
",3 Automatic generation of TORDERs,[0],[0]
"TimeBank contains the normalized date ‘YYYYMM-DD’ of time expressions and DCT, but does not include events’ time.",3 Automatic generation of TORDERs,[0],[0]
Our proposal of inducing a TORDER by comparing two time anchors requires the time anchor annotation of events in the same granularity as time expressions and DCT.,3 Automatic generation of TORDERs,[0],[0]
"Therefore, annotating the events with ‘YYYY-MMDD’ is a reasonable setting and one day is used as the minimal granularity of annotation.",3 Automatic generation of TORDERs,[0],[0]
"We choose the annotation (Reimers et al., 2016) of the daylevel time anchors of events as the source of our automatic TORDER generator.",3 Automatic generation of TORDERs,[0],[0]
"In the case that a corpus can provide more specific time information ‘YYYY-MM-DD, hh-mm-ss’ (e.g. this morning, three o’clock in the afternoon), our TORDER generator can be flexible to handle this information as long as the time anchors of all mentions are annotated in the same granularity.
",3 Automatic generation of TORDERs,[0],[0]
"For the clear demonstration of the definition of the auto-generated temporal order, we separately describe the generation of the pairs with two Single-Day mentions, and the pairs involving Multi-Day mentions.",3 Automatic generation of TORDERs,[0],[0]
"In this paper, TORDER labels are written in the upper-case bold font to be distinguished from TLINK labels written in the lower-case italic font.",3 Automatic generation of TORDERs,[0],[0]
Table 1 introduces the definition of temporal orders between two Single-Day pairs S1 and S2.,3 Automatic generation of TORDERs,[0],[0]
PVAGUE (i.e. partially vague) denotes that two imprecise time anchors are equivalent.,3 Automatic generation of TORDERs,[0],[0]
"For instance, we cannot induce a clear temporal relation between two events both occur-
ring on (,before1998-02-06), but nevertheless both events provide partially equivalent date information ‘1998-02-06’.",3 Automatic generation of TORDERs,[0],[0]
It can possibly provide useful information for the future processes of classification or time inference.,3 Automatic generation of TORDERs,[0],[0]
"PVAGUE in the Multi-Day definition takes the same consideration.
",3 Automatic generation of TORDERs,[0],[0]
"In order to introduce the temporal orders involving Multi-Day events, a Multi-Day event M is denoted as a tuple of two Single-Day dates (begin, end).",3 Automatic generation of TORDERs,[0],[0]
"A temporal order between a SingleDay S1 and Multi-Day M2 (begin2, end2) can be derived by computing the temporal order of two Single-Day S1 and begin2, or S1 and end2 first.",3 Automatic generation of TORDERs,[0],[0]
All the types of temporal orders involving MultiDay events are defined in Table 2.,3 Automatic generation of TORDERs,[0],[0]
"One additional INCLUDES relation that Multi-Day event includes a Single-Day event can be obtained by reversing the symmetric IS INCLUDED.
",3 Automatic generation of TORDERs,[0],[0]
The example of automatically computing temporal orders can be demonstrated by using the events in Figure 1.,3 Automatic generation of TORDERs,[0],[0]
"Both Multi-Day created and disruption are clearly BEFORE the Single-Day reported, because reported is AFTER the end dates of created and disruption.",3 Automatic generation of TORDERs,[0],[0]
"The relation between created and disruption is induced as VAGUE, as the imprecise begin, end of disruption cannot be determined with a relation to created.
",3 Automatic generation of TORDERs,[0],[0]
"In this paper, the definition adopts a similar relation set to TLINK for the purpose that we can perform fair comparison and evaluation in the next two sections.",3 Automatic generation of TORDERs,[0],[0]
"However, our inducing proposal can be very scalable to introduce more temporal relations.",3 Automatic generation of TORDERs,[0],[0]
"For instance, Allen’s interval algebra (Allen, 1990) defines ‘starts’, ‘finish’ relations, which are not included in our current defini-
tion.",3 Automatic generation of TORDERs,[0],[0]
"We can easily extend our definition by detecting whether two time anchors have the equivalent begin or end points.
",3 Automatic generation of TORDERs,[0],[0]
Our inducing proposal takes human annotated time expressions and normalized values as inputs to generate TORDER relations as the training data of the next processes (e.g. classification).,3 Automatic generation of TORDERs,[0],[0]
"In the case of processing raw texts, we can perform detection and normalization of time expressions by using existing temporal taggers, e.g. HeidelTime (Strötgen and Gertz, 2015), SUTime (Chang and Manning, 2012), etc.",3 Automatic generation of TORDERs,[0],[0]
Fairly evaluating the TORDER’s capability of encoding temporal order information compared to the existing data is difficult but necessary work.,4 Comparison of TORDERs and TLINKs,[0],[0]
"This section provides empirical statistics of TORDER and TLINK annotations, and compare the performance of automatic recognition.",4 Comparison of TORDERs and TLINKs,[0],[0]
"Additionally, we evaluate these two frameworks in a downstream task performance in Section 5.",4 Comparison of TORDERs and TLINKs,[0],[0]
"Our new TORDERs are formally similar to the conventional TLINKs, as both state a temporal relation between two mentions.",4.1 Correspondences and Differences,[0],[0]
"BEFORE and AFTER represent that one mention occurs before or after in a timeline, which is close to before and after.",4.1 Correspondences and Differences,[0],[0]
"INCLUDES and IS INCLUDED are more clearly conditioned as a Single-Day or MultiDay mention occurs during the other Multi-Day mention, compared to includes and is included.",4.1 Correspondences and Differences,[0],[0]
SAME DAY and SAME SPAN are designed for the one-day minimal granularity.,4.1 Correspondences and Differences,[0],[0]
"Ideally, these two relations will include simultaneous and other TLINKs with two mentions occurring in the same day.",4.1 Correspondences and Differences,[0],[0]
"VAGUE and PVAGUE state that our generation rules cannot induce the relations, similar to vague (i.e. annotators cannot judge the relations).
",4.1 Correspondences and Differences,[0],[0]
The one-day minimal granularity is the main reason causing the difference between TORDER and TLINK types.,4.1 Correspondences and Differences,[0],[0]
"For a sentence:
I went to sleep after taking a bath.
",4.1 Correspondences and Differences,[0],[0]
"According to the TimeML specification, sleep is obviously after bath.",4.1 Correspondences and Differences,[0],[0]
"But in the one-day granularity, the relation is shifted to SAME DAY.",4.1 Correspondences and Differences,[0],[0]
"This brings the obstacle that we cannot measure whether the temporal information encoded in
TORDERs is more informative than TLINKs by directly comparing the classification results.
",4.1 Correspondences and Differences,[0],[0]
Our TORDER definition shows the capability of capturing some relations which cannot be encoded by TLINK.,4.1 Correspondences and Differences,[0],[0]
"For instance:
Stocks rose, pushing the Dow Jones industrial average up 72.24 points, to 8,189.49, leaving the index within 70 points of its record.
",4.1 Correspondences and Differences,[0],[0]
"These TLINKs among the three events are annotated as vague in TimeBank-Dense, as the annotators cannot state their temporal orders.",4.1 Correspondences and Differences,[0],[0]
"However, we can easily obtain SAME DAY relations, since their day-level time anchors are the same.
",4.1 Correspondences and Differences,[0],[0]
Imprecisely represented time anchors (e.g. after YYYY-MM-DD) are the major drawback of losing temporal order information.,4.1 Correspondences and Differences,[0],[0]
"For instance:
America’s economic stamina has withstood any disruption...
The TLINK between withstood and disruption is annotated as after.",4.1 Correspondences and Differences,[0],[0]
"While both of them were annotated as the same time anchor (begin=before 1998- 02-06, end= before 1998-02-06), our TORDER generator induced a PVAGUE relation and temporal order information is lost.
",4.1 Correspondences and Differences,[0],[0]
The hypothesis that our proposal skipping the unstable manual identification of “salient” pairs can reduce the VAGUE relations in the new data.,4.1 Correspondences and Differences,[0],[0]
This can be measured by comparing the numbers of the TORDER and TLINK relations on the same mention pairs.,4.1 Correspondences and Differences,[0],[0]
"If the observation of a part of vague TLINKs induced as non-VAGUE TORDERs in the new data can be found, it will be the evidence.
",4.1 Correspondences and Differences,[0],[0]
"Depending on the text domain, TLINKs or TORDERs can be advantageous in different scenarios.",4.1 Correspondences and Differences,[0],[0]
"TLINKs can capture the temporal ordering information between events, when time expressions are often absent in the documents such as novels and narratives.",4.1 Correspondences and Differences,[0],[0]
But the annotation work is time consuming and a part of relations will be neglected by the unstable human identification of “salient” pairs.,4.1 Correspondences and Differences,[0],[0]
TORDERs have the capability of capturing more informative relations by skipping the “salient” pairs recognition and need less annotation effort.,4.1 Correspondences and Differences,[0],[0]
But they require that the events can be anchored in a timeline from a document (e.g. often the case of news articles) and imprecise time anchors cause some information loss.,4.1 Correspondences and Differences,[0],[0]
Investigating the quality of auto-generated TORDERs is important to demonstrate the value of this research.,4.2 Empirical Comparison,[0],[0]
"In this section, we empirically compare the statistics of the auto-generated TORDERs and human-annotated TLINKs.",4.2 Empirical Comparison,[0],[0]
"Theoretically, a TORDER between two mentions with any distance in a document can be automatically computed.",4.2 Empirical Comparison,[0],[0]
"However, it is important to make the new data in a comparable manner to the existing data.",4.2 Empirical Comparison,[0],[0]
"In this paper, we follow the process of TimeBank-Dense (Cassidy et al., 2014) to generate the complete graph of the 10,007 mention pairs in the same and adjacent sentences.",4.2 Empirical Comparison,[0],[0]
"The TORDER data used in this paper are publicly available3 and our scalable generation method can be easily applied for inducing relations of longer distance pairs.
",4.2 Empirical Comparison,[0],[0]
Table 3 shows the comparison between the numbers of the TimeBank-Dense TLINKs and the new TORDERs.,4.2 Empirical Comparison,[0],[0]
"One observation as we expected is that our approach captures new relations for a considerable part of the mention pairs that were judged as v (vague) in the human-annotated
3https://github.com/racerandom/temporalorder
TLINKs.",4.2 Empirical Comparison,[0],[0]
"542 vague relations are induced as AFTER in the new TORDERs, as well as other relation types.",4.2 Empirical Comparison,[0],[0]
"However, a part of non-vague TLINKs are shifted to VAGUE TORDERs.",4.2 Empirical Comparison,[0],[0]
This matches our description of the imprecise time anchor issue.,4.2 Empirical Comparison,[0],[0]
It is a trade-off between the part of mention pairs obtaining richer temporal information and the part of pairs losing information.,4.2 Empirical Comparison,[0],[0]
That is the reason why we need a downstream task (i.e. Time Anchors Prediction in Section 5) to measure how much temporal order information is encoded in TORDERs and TLINKs.,4.2 Empirical Comparison,[0],[0]
"The shift of TLINK relations to SAME DAY due to the one-day minimal granularity setting can also be clearly observed.
",4.2 Empirical Comparison,[0],[0]
Figure 2 shows the label distributions of the auto-generated TORDERs and the TimeBankDense TLINKs.,4.2 Empirical Comparison,[0],[0]
"We investigate the statistics of Event-Event, Event-Time, and Event-DCT pairs.",4.2 Empirical Comparison,[0],[0]
The TimeBank-Dense corpus is obviously sparser due to the high proportion of vague in all three types of pairs.,4.2 Empirical Comparison,[0],[0]
"Our TORDERs show a more balanced distribution of labels, which suggests that this method possibly encodes more informative temporal orders compared to the traditional TLINKs.",4.2 Empirical Comparison,[0],[0]
"In particular, TORDERs show extremely rare VAGUE labels in Event-DCT pairs.",4.2 Empirical Comparison,[0],[0]
"When given the precise Single-Day DCT of a document, our proposal to compare the temporal order between the time anchor of a event and the DCT manages to avoid the most unstable judgments made by the human annotators in the EventDCT pairs.",4.2 Empirical Comparison,[0],[0]
"Although the different definition of TORDERs from TLINKs makes direct comparison difficult, the more balanced distribution of TORDERs can possibly provide more informative classification results to benefit the downstream tasks.",4.2 Empirical Comparison,[0],[0]
"Although the classification results of TORDERs and TLINKs are not directly comparable, they can show some evidence whether TORDERs is functional to provide temporal order information.",4.3 Classification Results,[0],[0]
"Table 4 shows the Bi-LSTM classification results with the data split4(Chambers et al., 2014) (27 training/validation documents, 9 testing documents).
",4.3 Classification Results,[0],[0]
"The classification system achieves fairly high F1 0.631 in Event-DCT and 0.485 in Event-Time on the SAME DAY temporal orders, which are the main information source to predict the precise time of events.",4.3 Classification Results,[0],[0]
"The performance on AFTER, BEFORE temporal orders are close to the TLINKs in number, but not meaningfully comparable.",4.3 Classification Results,[0],[0]
The high proportion of vague in the TLINKs results in biased predictions.,4.3 Classification Results,[0],[0]
"When we use a more meaningful evaluation ‘Non-vague’ overall, the TLINKs performance drops sharply.",4.3 Classification Results,[0],[0]
"Generally, the classification results suggest that our proposal of autogenerated TORDERs has sufficient capability to encode temporal information, which can be well
4https://github.com/nchambers/caevo/blob/master/src/mai n/java/caevo/Evaluate.java
classified from the textual inputs.",4.3 Classification Results,[0],[0]
"In this section, we describe a two-step system trained with the existing TLINKs and our data to challenge a downstream time anchor prediction task.",5 Evaluation in Time Anchor Prediction,[0],[0]
The different performance can be seen as the evidence whether our auto-generated TORDERs can capture comparable temporal information to the human-annotated TLINKs.,5 Evaluation in Time Anchor Prediction,[0],[0]
"Predicting the time of events from the news articles is an attractive goal, which is a necessary step towards automatic event timeline extraction.",5.1 Task Definition,[0],[0]
"Reimers et al. (2016) bring the task of time anchor prediction, which aims to predict the time anchor of each Single-Day event given a document.",5.1 Task Definition,[0],[0]
They use a general two-step process to determine the event anchors as shown in Figure 3.,5.1 Task Definition,[0],[0]
"Given a set of documents with events and time expressions already annotated, the system first obtains a list of possible times for each event.",5.1 Task Definition,[0],[0]
"Then, the most precise time is selected for each event.
",5.1 Task Definition,[0],[0]
A serious issue is that their baseline system still depends on the TimeBank-Dense TLINK classifier and the time anchor annotation is only used for the final evaluation.,5.1 Task Definition,[0],[0]
That leaves the space to consider a new method without relying on the human-annotated TLINKs.,5.1 Task Definition,[0],[0]
"Our auto-generated TORDERs are a natural alternative to TLINKs to provide the similar temporal order information of mention pairs, but with less annotation efforts.",5.1 Task Definition,[0],[0]
The second-step selection rules just need a slight modification to replace the previous TLINK types with the new TORDER types.,5.1 Task Definition,[0],[0]
"In this work, we adopt a similar two-step architecture.",5.2 The Two-step System in Experiments,[0],[0]
"The first-step temporal order classifier is designed to provide the temporal relations of the mention pairs in a document.
",5.2 The Two-step System in Experiments,[0],[0]
The second-step selects the most precise time by taking all Event-Time and Event-DCT relations of a target event as input.,5.2 The Two-step System in Experiments,[0],[0]
"For instance in Figure 3, the second-step received a set of relations e.g. (is included,DCT ), (is included, Friday) and (vague, January) of reported.",5.2 The Two-step System in Experiments,[0],[0]
"For the system trained with the TimeBank-Dense TLINKs, we adopt the same selection algorithm as described in (Reimers et al., 2016).",5.2 The Two-step System in Experiments,[0],[0]
"When the system is trained
with the TORDERs, we slightly modified the algorithm by replacing the TLINK relations with similar TORDER relations.",5.2 The Two-step System in Experiments,[0],[0]
"SAME DAY replaces simultaneous to predict precise dates, although their definition is quite different.",5.2 The Two-step System in Experiments,[0],[0]
We perform a 6-fold cross-validation strategy to predict all the TORDERs and TLINKs of the mention pairs in the 36 documents of the TimeBankDense corpus.,5.3 Experiment Settings,[0],[0]
"In each run, we split 30 documents for training and validation to predict the other 6 test documents.
",5.3 Experiment Settings,[0],[0]
"We define two evaluation metrics, i.e. Exact Match accuracy and Partial Match accuracy to measure the performance in this task as follows:
exact match = #Number of the exact match predictions
#Total number of the test samples
partial match = #Number of the partial match predictions
#Total number of the test samples
We define two partial match cases: 1) a precise (1998-02-06) is partial match with an imprecise (after 1998-02-06), if the date values are the same.",5.3 Experiment Settings,[0],[0]
"2) (after 1998-02-06) is partial match with (after 1998-02-06, before 1998-02-21), if one is a part of the other.",5.3 Experiment Settings,[0],[0]
Table 5 summarizes the main results of the twostep time anchor prediction system trained with TORDER and TLINK data.,5.4 Main Results,[0],[0]
"‘Precise’, ‘Imprecise’ and ‘Overall’ denote the results of predicting time anchors of precise events, imprecise events, and overall performance.",5.4 Main Results,[0],[0]
"‘Event-DCT’ or ‘EventTime’ denotes the second-step selection takes only Event-DCT or Event-Time pairs as input, which helps us to investigate how much information is provided by the different types of pairs for predicting the final time anchors.",5.4 Main Results,[0],[0]
"The new TORDERs show significantly superior out-performance in all three settings (i.e. only Event-DCT pairs, only Event-Time pairs, or Event-DCT +",5.4 Main Results,[0],[0]
"Event-Time), compared to the TLINKs.",5.4 Main Results,[0],[0]
"With both Event-DCT and Event-Time temporal order information, the system achieves the highest overall exact match and partial match accuracy.
",5.4 Main Results,[0],[0]
"The Event-DCT, Event-Time pairs are the source of temporal information for predicting time anchors.",5.4 Main Results,[0],[0]
"The system only using the Event-DCT achieves surprisingly high accuracy, particularly on the TORDER partial match accuracy of the
precise events.",5.4 Main Results,[0],[0]
The reason is that most events reported in news articles usually occur in precisely the same day as DCT.,5.4 Main Results,[0],[0]
"Therefore, the TORDER Event-DCT is benefited from the low proportion of vague relations, which sharply outperforms the TLINK Event-DCT by 16.3% overall exact match.",5.4 Main Results,[0],[0]
"However, the contribution of the EventTime to the overall might be underestimated in this task somehow.",5.4 Main Results,[0],[0]
The TORDER Event-Time still beats the TLINKs by 11% overall exact match and 16.4% overall partial match.,5.4 Main Results,[0],[0]
"Furthermore, the Event-Time encoding the temporal information within 1-sentence window in our experiments can be easily strengthen by our TORDER proposal to introduce more inter-sentence pairs.",5.4 Main Results,[0],[0]
"In this section, we perform an additional experiment to make a comparison to a system with the first-step replaced by a state-of-the-art dense TLINK classifier CAEVO (Chambers et al., 2014).",5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
"We adopt the data split setting in Section 4.3 for three classifiers: CAEVO, Bi-LSTM classifier trained with TLINKs and Bi-LSTM classifier trained with TORDERs.
",5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
The results are summarized in Table 6.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
CAEVO achieves the exact match accuracy slightly better than the Bi-LSTM model trained with the TLINKs.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
The Bi-LSTM model trained with the TORDERs sharply outperforms the other two systems by approximate 14% exact match accuracy and approximate 26% in partial match accuracy.,5.5 Comparison to a state-of-the-art dense TLINK classifier,[0],[0]
"In this paper, we propose a new approach to obtain temporal relations based on time anchors (i.e. absolute time value) of mentions in news articles.",6 Conclusion,[0],[0]
Our pre-defined generation rules can automatically induce TORDER relations by comparing the temporal order of two time anchors in a timeline.,6 Conclusion,[0],[0]
"The requirement of our proposal for annotating time anchors is much easier compared to conventional methods, as the annotation effort is linear
with the number of mentions.",6 Conclusion,[0],[0]
The TORDER data used in this paper are publicly available.,6 Conclusion,[0],[0]
"The analysis, empirical comparison and classification results of the new TORDERs and the TimeBankDense TLINKs show our new data achieve the low VAGUE proportion, the informative relation types and the balanced label distribution.",6 Conclusion,[0],[0]
We perform the second evaluation of using the temporal relation classifier to complete the downstream task of time anchor prediction in news articles.,6 Conclusion,[0],[0]
"The main results show our TORDERs significantly outperform the TLINKs in this task, which suggests our proposal has the capability to encode informative temporal order information with less annotation effort.
",6 Conclusion,[0],[0]
The main limitation of TORDER is that events are required to be anchored in a timeline.,6 Conclusion,[0],[0]
Strötgen and Gertz (2016) introduce the highly different characteristics of time expressions in four domains of text.,6 Conclusion,[0],[0]
It suggests that our proposal is difficult to be applied in some domains.,6 Conclusion,[0],[0]
"One possible solution is to adopt a hybrid annotation method to annotate a target event towards the most relevant event (TLINK-style), when temporal information is absent in its context.",6 Conclusion,[0],[0]
"Although this work is motivated for contributing to timeline applications, evaluating this proposal in the temporal question answering is also valuable.",6 Conclusion,[0],[0]
SAME DAY could be harmful because this task possibly requires to know the exact order between two events occurring on the same day.,6 Conclusion,[0],[0]
It is worth conceiving a more general solution to improve the limitations of TORDER in the future work.,6 Conclusion,[0],[0]
We would like to thank the anonymous reviewers for their valuable comments and thank Jason Bennett for useful discussions and proofreading.,Acknowledgments,[0],[0]
Recognizing temporal relations among events and time expressions has been an essential but challenging task in natural language processing.,abstractText,[0],[0]
Conventional annotation of judging temporal relations puts a heavy load on annotators.,abstractText,[0],[0]
"In reality, the existing annotated corpora include annotations on only ”salient” event pairs, or on pairs in a fixed window of sentences.",abstractText,[0],[0]
"In this paper, we propose a new approach to obtain temporal relations from absolute time value (a.k.a. time anchors), which is suitable for texts containing rich temporal information such as news articles.",abstractText,[0],[0]
"We start from time anchors for events and time expressions, and temporal relation annotations are induced automatically by computing relative order of two time anchors.",abstractText,[0],[0]
"This proposal shows several advantages over the current methods for temporal relation annotation: it requires less annotation effort, can induce inter-sentence relations easily, and increases informativeness of temporal relations.",abstractText,[0],[0]
We compare the empirical statistics and automatic recognition results with our data against a previous temporal relation corpus.,abstractText,[0],[0]
"We also reveal that our data contributes to a significant improvement of the downstream time anchor prediction task, demonstrating 14.1 point increase in overall accuracy.",abstractText,[0],[0]
Inducing Temporal Relations from Time Anchor Annotation,title,[0],[0]
"The past decade has witnessed advances of deep learning in a broad range of application areas such as game playing (Silver et al., 2016), natural language processing (Sutskever et al., 2014), image processing and computer vision (He et al., 2016).",1. Introduction,[0],[0]
"Its effectiveness is often attributed to the automated learning of latent representations, in that salient and discriminative features are highly beneficial for the overall learning task.",1. Introduction,[0],[0]
"With abstract and semantic features synthesized, the predictive relations between observations can be captured with more ease despite the possible complications in the correlation.",1. Introduction,[0],[0]
"In unsupervised learning, latent models have been widely used for clustering (Banerjee et al., 2005), dimensionality reduction (Lawrence, 2005), and transformation-invariant visual data analysis (Ranzato et al., 2012).
1Department of Computer Science, University of Illinois at Chicago, USA 2School of Computer Science, University of Waterloo, Canada.",1. Introduction,[0],[0]
Correspondence to:,1. Introduction,[0],[0]
"Xinhua Zhang <zhangx@uic.edu>.
Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
"The focus of this paper is conditional modeling for supervised learning, where latent variables are learned in the context of output information, so that accurate reconstruction of outputs can be facilitated through predictive intervening features.",1. Introduction,[0],[0]
"Such features can characterize latent clusters (Tishby et al., 1999), sparse coding (Elad & Aharon, 2006), invariant representation (Rifai et al., 2011), amongst others.
",1. Introduction,[0],[0]
"Despite their advantages in modeling and success in applications, latent models remain hard to train.",1. Introduction,[0],[0]
"The key challenge originates from the coupling of model parameter learning and latent variable inference, which in general leads to a nonconvex optimization problem.",1. Introduction,[0],[0]
"Although empirical performance has been the major focus of deep learning, recently substantial progress has been made towards the analysis of global training and the structure of the optimization problem.",1. Introduction,[0],[0]
"For example, Choromanska et al. (2014) and Dauphin et al. (2014) showed that the lowest critical values of the random loss function are close to the global minimum, and Kawaguchi (2016) showed, under certain assumptions, that every local minimum is a global minimum for an expected loss function of a deep nonlinear neural network.",1. Introduction,[0],[0]
"Similar global trainability results have been derived for gradient descent on two-node ReLU networks (Tian, 2017), quadratic activations (Soltanolkotabi et al., 2017), and one-hidden-layer non-overlapping convolution nets (Brutzkus & Globerson, 2017).",1. Introduction,[0],[0]
"The global minima in over-parameterized settings were characterized on deep and wide nets and convolutional nets (Nguyen & Hein, 2017a;b).",1. Introduction,[0],[0]
"However most analyses are still limited, especially with assumptions on the model and data distribution that are hard to verify in practice.
",1. Introduction,[0],[0]
"Along a different line of methodology, reformulations of latent models have been studied which admit tractable global solutions.",1. Introduction,[0],[0]
"Examples include boosting (Bengio et al., 2005), spectral methods (Anandkumar et al., 2014; Zhong et al., 2017), kernel methods (Zhang et al., 2016; 2017), polynomial networks and sum-product networks (Livni et al., 2014; Gens & Domingos, 2012), and semidefinite relaxations (Fogel et al., 2015).",1. Introduction,[0],[0]
"Unfortunately, they either impose restrictions on the model space (e.g. polynomial network, recursive inverse kernels), or require tractability of underlying oracles, or rely on realizability assumptions.
",1. Introduction,[0],[0]
"A framework based on reformulation that accommodates more general latent variable structures was proposed by Aslan et al. (2013; 2014), where each pair of adjacent layers are conjoined through a prediction loss that favors nonlinear connections.",1. Introduction,[0],[0]
"A similar approach was designed by Carreira-Perpinnan & Wang (2014), which introduced “auxiliary coordinates” to allow deviation from layer-wise outputs with a penalty.",1. Introduction,[0],[0]
"In order to achieve a convex model, Aslan et al. (2013; 2014) further represent each layer’s output as a kernel matrix, and the loss over adjacent kernels is relaxed in a jointly convex fashion, retaining nonlinear transformations that allow a rich set of salient latent features to be captured.
",1. Introduction,[0],[0]
"However, these models assume that all latent layers behave as a multi-label classifier, and the latent kernels are learned nonparametrically, i.e. there is no explicit parametric transfer function and nonlinear relations are introduced only through the loss functions between layers.",1. Introduction,[0],[0]
"This is more restrictive than state-of-the-art deep learners where the activation functions are parametric and continuously valued, with popular choices such as ReLU.",1. Introduction,[0],[0]
"As a result the model is restricted to a transductive setting, in that training examples are required to establish the data-dependent context of nonparametric kernel learning.",1. Introduction,[0],[0]
"This restriction significantly slows down predictions at test time, which is more important than the training cost.
",1. Introduction,[0],[0]
"Such a challenge in efficiency is exacerbated as the kernelbased learning leads to an expensive semi-definite programming (SDP), whose computational cost limited their experiments to only 200 examples.
",1. Introduction,[0],[0]
"The goal of this paper, therefore, is to develop an inductive and efficient learning strategy for two-layer conditional models with global optimality guarantees.",1. Introduction,[0],[0]
"This allows predictions to be made as efficiently as a feedforward neural network (FFNN) does, obviating retraining at test time.",1. Introduction,[0],[0]
It is achieved by directly constructing a convex relaxation based on a parametric transfer function (e.g. ReLU) specified a priori.,1. Introduction,[0],[0]
"In particular, we first make a new observation that no inter-layer loss satisfying nonlinear recovery and grounding can be jointly convex (§2).",1. Introduction,[0],[0]
"However by using the matching loss, the non-convexity can be encapsulated entirely by a bilinear term, facilitating a convex relaxation for ReLU based on completely positive (CP) cones (§3).",1. Introduction,[0],[0]
"The result provides a direct initialization of FFNN for finer tuning, which yields, inductively, more accurate predictions than baseline training methods (§5).",1. Introduction,[0],[0]
"Different from the SDP used by Aslan et al. (2013; 2014), our CP-based model allowed us to develop a new efficient algorithm using low-rank approximation, scaling up the size of solvable problems by an order of magnitude (§4).",1. Introduction,[0],[0]
A new constant approximation guarantee is also proved.,1. Introduction,[0],[0]
Two-layer neural networks are composed of two nonlinear conditional models.,2. Matching Loss for Transfer Functions,[0],[0]
The latent layer is characterized by a nonlinear transfer function f :,2. Matching Loss for Transfer Functions,[0],[0]
"Rh → Rh, which converts the linear transformation Wx into φ = f(Wx).",2. Matching Loss for Transfer Functions,[0],[0]
"Here x ∈ Rn is the raw input feature, and W ∈ Rh×n is the hidden layer weights.",2. Matching Loss for Transfer Functions,[0],[0]
"We use regular lowercase letters for scalar, bold lowercase letters for vector, and capital letters for matrix.",2. Matching Loss for Transfer Functions,[0],[0]
"The resulting φ is further multiplied with the output layer weights U ∈ Rh×m, and the product is measured against the given label y ∈ Rm via a loss function `(U ′φ,y).",2. Matching Loss for Transfer Functions,[0],[0]
Here U ′ is the transpose of U .,2. Matching Loss for Transfer Functions,[0],[0]
"Typical losses include binary hinge loss `(z, y) =",2. Matching Loss for Transfer Functions,[0],[0]
"[1− yz]+ with m = 1, where y ∈ {−1, 1} and [z]+ := max{0, z}.",2. Matching Loss for Transfer Functions,[0],[0]
"For multiclass problems with C classes, y encodes a class c with the canonical vector ec.",2. Matching Loss for Transfer Functions,[0],[0]
"Then m = C and the hinge loss `(z,y) =",2. Matching Loss for Transfer Functions,[0],[0]
max{1 − y + z,2. Matching Loss for Transfer Functions,[0],[0]
"− (y′z)1}, where 1 is a vector of all one’s.",2. Matching Loss for Transfer Functions,[0],[0]
"The logistic loss is −z′y + log ∑ c exp(zc).
",2. Matching Loss for Transfer Functions,[0],[0]
There are several popularly used transfer functions.,2. Matching Loss for Transfer Functions,[0],[0]
"The simplest options are elementwise, i.e. f(z) = (f(z1), . . .",2. Matching Loss for Transfer Functions,[0],[0]
", f(zh))
′, where all zi are applied separately to the same function f : R → R. ReLU uses fr(z) =",2. Matching Loss for Transfer Functions,[0],[0]
"[z]+, and variants include the leaky rectifier which uses fl(z) = max{z, az} where a > 0 is a small positive number, and the bounded hard tanh which uses fh(z) = max{−1,min{z, 1}}.",2. Matching Loss for Transfer Functions,[0],[0]
"Transfers that are not piecewise linear are also available, e.g. the sigmoid fs(z) =",2. Matching Loss for Transfer Functions,[0],[0]
(1 + e−z)−1.,2. Matching Loss for Transfer Functions,[0],[0]
These transfers are illustrated in Figure 1.,2. Matching Loss for Transfer Functions,[0],[0]
"Nonelementwise transfers are also available, e.g. the soft-max function with f(z) = (ez1 , . . .",2. Matching Loss for Transfer Functions,[0],[0]
", ezh)′/ ∑h k=1 e zk .
",2. Matching Loss for Transfer Functions,[0],[0]
A major source of non-convexity in neural network is the nonlinear transfer function.,2. Matching Loss for Transfer Functions,[0],[0]
"To cope with it, a natural approach is to replace the exact connection of φ = f(z) by a loss function that penalizes the deviation between φ and f(z).",2. Matching Loss for Transfer Functions,[0],[0]
"Formally, it attempts to construct a loss L(φ, z) that would (ideally) satisfy three conditions:
• Unique recovery: arg minφ L(φ, z) = f(z) for all z, with the arg min attained uniquely.
",2. Matching Loss for Transfer Functions,[0],[0]
• Joint convexity: L is jointly convex over φ and z.,2. Matching Loss for Transfer Functions,[0],[0]
"This is required if we choose to build a jointly convex deep model by directly usingL to connect the input and output of adjacent layers.
",2. Matching Loss for Transfer Functions,[0],[0]
•,2. Matching Loss for Transfer Functions,[0],[0]
"Grounding: minφ L(φ, z) = 0 for all z, so that there is no bias towards any value of z.
Unfortunately, it can be shown that such a loss does not exist, unless f is affine (see the proof in Appendix A):
Theorem 1.",2. Matching Loss for Transfer Functions,[0],[0]
"There exists a loss L that satisfies all the three conditions if, and only if, f is affine.
",2. Matching Loss for Transfer Functions,[0],[0]
This result motivates us to resort to weaker versions of loss.,2. Matching Loss for Transfer Functions,[0],[0]
"Interestingly, the matching loss (Auer et al., 1996) meets
the first and third conditions, and satisfies a weakened version of convexity by imposing a very mild condition on f .",2. Matching Loss for Transfer Functions,[0],[0]
"In particular, we assume that the transfer function is the gradient of a strictly convex function F : f = ∇F , with F : Rh → R. If f is elementwise, this just means the constituent f is continuous and strictly increasing.",2. Matching Loss for Transfer Functions,[0],[0]
"As a result, the inverse of f also exists, and it is well known that f−1 = ∇F ∗, where F ∗ is the Fenchel conjugate of F .
",2. Matching Loss for Transfer Functions,[0],[0]
"Although the ReLU fr(z) is not strictly increasing in the negative hallf line, it can be approximated arbitrarily closely via max{ z, z} for infinitesimally small > 0.",2. Matching Loss for Transfer Functions,[0],[0]
Similar alterations can be applied to hard tanh fh(z) by allowing a tiny slope for |z| ≥ 1.,2. Matching Loss for Transfer Functions,[0],[0]
"The F corresponding to the abovementioned transfers f are also shown in Figure 1.
",2. Matching Loss for Transfer Functions,[0],[0]
"In the case that f is not elementwise, this assumption of F implies: 1) f is strictly increasing in the vector sense: (x − y)′(f(x)",2. Matching Loss for Transfer Functions,[0],[0]
"− f(y)) > 0, and 2) The Jabobian of f is symmetric (as the Hessian of F ):",2. Matching Loss for Transfer Functions,[0],[0]
"Jf = (Jf)′, provided f is differentiable.",2. Matching Loss for Transfer Functions,[0],[0]
"Under this assumption, we adopt the following loss function based on Bregman divergence:
L(φ, z) = DF∗(φ, f(z))",2. Matching Loss for Transfer Functions,[0],[0]
"= F ∗(φ) + F (z)− φ′z, (1) whereDF∗ is the Bregman divergence induced by F ∗.",2. Matching Loss for Transfer Functions,[0],[0]
"Obviously L meets the conditions of recovery and grounding, but is not jointly convex.",2. Matching Loss for Transfer Functions,[0],[0]
"However, the only nonconvex part is the bilinear term φ′z, while both F ∗ and F are convex.",2. Matching Loss for Transfer Functions,[0],[0]
Such a decoupling of nonconvex terms from the transfer functions is the key enabler for our convex reformulation.,2. Matching Loss for Transfer Functions,[0],[0]
"Suppose we have t training pairs {(xj ,yj)}tj=1, stacked in two matrices X = (x1, . . .",3. Convex Two-layer Modeling,[0],[0]
",xt) ∈ Rn×t and Y = (y1, . . .",3. Convex Two-layer Modeling,[0],[0]
",yt) ∈Rm×t.",3. Convex Two-layer Modeling,[0],[0]
"The corresponding set of latent layer outputs are stacked into Φ = (φ1, . . .",3. Convex Two-layer Modeling,[0],[0]
",φt) ∈ Rh×t.",3. Convex Two-layer Modeling,[0],[0]
"The regularized risk minimization objective can be written as
min W,Φ U,b t∑ j=1 DF∗(φj , f(Wxj))",3. Convex Two-layer Modeling,[0],[0]
"+ `(U ′φj+b,yj)+ ‖W‖2+‖U‖2 2
= min W,U,b,Φ t∑ j=1 {F ∗(φj)−",3. Convex Two-layer Modeling,[0],[0]
φ′jWxj,3. Convex Two-layer Modeling,[0],[0]
+,3. Convex Two-layer Modeling,[0],[0]
"F (Wxj) (2)
+ `j(U ′φj + b)}+ 12 ‖W‖ 2 + 12 ‖U‖ 2 ,
where `j(U ′φj + b) := `(U ′φj + b,yj).",3. Convex Two-layer Modeling,[0],[0]
We introduced regularizations via Frobenius norms.,3. Convex Two-layer Modeling,[0],[0]
"The weight of both regularization terms can be tuned by any model selection method, e.g. cross validation, and here we put 1 to simplify the presentation.",3. Convex Two-layer Modeling,[0],[0]
We also assume that dom `j is the entire space.,3. Convex Two-layer Modeling,[0],[0]
"To keep our notation neat we write vector-input functions on matrices, representing the sum of the function values applied to each column, e.g. F ∗(Φ) = ∑ j F ∗(φj).",3. Convex Two-layer Modeling,[0],[0]
"Now we can rewrite the objective compactly as
min Φ,W,U,b
F ∗(Φ)− tr(Φ′WX) + F (WX) + `(U ′Φ + b1′)
+ 12 ‖W‖ 2 + 12 ‖U‖ 2 .",3. Convex Two-layer Modeling,[0],[0]
"(3)
It is bi-convex in two groups of variables (Φ,b) and (W,U), i.e. fixing one group it is convex in the other.",3. Convex Two-layer Modeling,[0],[0]
"In order to derive a jointly convex reformulation, we first note that `(U ′Φ + b1′) = maxR{tr(R′(U ′Φ + b1′))",3. Convex Two-layer Modeling,[0],[0]
"− `∗(R)}, where `∗ is the Fenchel conjugate of `, and R ∈ Rm×t.",3. Convex Two-layer Modeling,[0],[0]
"For binary hinge loss, `∗(r) =",3. Convex Two-layer Modeling,[0],[0]
yr over r ∈,3. Convex Two-layer Modeling,[0],[0]
"[min{0,−y},max{0,−y}], and ∞ else.",3. Convex Two-layer Modeling,[0],[0]
"For multiclass hinge loss, `∗(r) = y′r",3. Convex Two-layer Modeling,[0],[0]
if r + y ∈,3. Convex Two-layer Modeling,[0],[0]
∆m,3. Convex Two-layer Modeling,[0],[0]
":= {x ∈ Rm+ : 1′x = 1}, and ∞ else.",3. Convex Two-layer Modeling,[0],[0]
"For multiclass logistic loss, `∗(r) = ∑ i(ri + yi) log(ri + yi) if r + y ∈ ∆m, and∞ else.",3. Convex Two-layer Modeling,[0],[0]
"Similarly, F (WX) = maxΛ{tr(Λ′WX)",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ)}.,3. Convex Two-layer Modeling,[0],[0]
"So we can rewrite (2) into
min W,U,b,Φ max R,Λ
F ∗(Φ)− tr(Φ′WX) + tr(Λ′WX)
",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ) + tr(R′(U ′Φ + b1′))− `∗(R) + ‖W‖,3. Convex Two-layer Modeling,[0],[0]
"2+‖U‖2 2
=",3. Convex Two-layer Modeling,[0],[0]
"min Φ max R,Λ min W,U,b
F ∗(Φ)− tr(Φ′WX) + tr(Λ′WX)
",3. Convex Two-layer Modeling,[0],[0]
− F ∗(Λ) + tr(R′(U ′Φ + b1′))− `∗(R) + ‖W‖,3. Convex Two-layer Modeling,[0],[0]
"2+‖U‖2 2
=",3. Convex Two-layer Modeling,[0],[0]
"min Φ max R1=0,Λ
F ∗(Φ)− 12 ‖(Φ− Λ)X ′‖2",3. Convex Two-layer Modeling,[0],[0]
"− 12 ‖ΦR ′‖2
− F ∗(Λ)− `∗(R).",3. Convex Two-layer Modeling,[0],[0]
"(4)
The optimal W and U for the last equality is W = (Φ + Λ)X ′",3. Convex Two-layer Modeling,[0],[0]
and U = −ΦR′.,3. Convex Two-layer Modeling,[0],[0]
"The first equality swaps minW,U,b with maxR,Λ. Such a strong duality is indeed not trivial because the celebrated Sion’s minimax lemma requires that the domain of (W,U) be compact, which is not assumed here.",3. Convex Two-layer Modeling,[0],[0]
"However the conclusion is still correct as we formalize here.
",3. Convex Two-layer Modeling,[0],[0]
Theorem 2.,3. Convex Two-layer Modeling,[0],[0]
"For any W,U,b, denote L(Φ, R) = F ∗(Φ)− tr(Φ′WX) + tr(R′(U ′Φ + b1′))− `∗(R).",3. Convex Two-layer Modeling,[0],[0]
"Then
min Φ max R L(Φ, R) = max R min Φ L(Φ, R).
",3. Convex Two-layer Modeling,[0],[0]
"To prove it, just use Proposition 2.2 (p173) of (Ekeland & Témam, 1999).",3. Convex Two-layer Modeling,[0],[0]
"There, take R = Λ = 0",3. Convex Two-layer Modeling,[0],[0]
"(i.e. p0 = 0), and then L diverges when (W,U) diverges.",3. Convex Two-layer Modeling,[0],[0]
Note b disappears as R = 0.,3. Convex Two-layer Modeling,[0],[0]
We now derive a convex relaxation for (4).,3.1. Convex relaxation,[0],[0]
"To be concrete, consider the ReLU transfer with Fr(Z)",3.1. Convex relaxation,[0],[0]
"= 12 ‖[Z]+‖
2.",3.1. Convex relaxation,[0],[0]
"Its Fenchel dual is F ∗r (Φ) = 1 2 ‖Φ‖
2 for Φ ≥ 0",3.1. Convex relaxation,[0],[0]
"(elementwise), and +∞ otherwise.",3.1. Convex relaxation,[0],[0]
"Therefore (4) can be specialized into
min Φ≥0 max R1=0,Λ≥0
1 2 ‖Φ‖ 2 − 12 ‖(Φ− Λ)X ′‖2 (5)
",3.1. Convex relaxation,[0],[0]
"− 12 ‖ΦR ′‖2 − 12 ‖Λ‖ 2 − `∗(R).
",3.1. Convex relaxation,[0],[0]
"Notice that both Φ and Λ are constrained to the positive orthant, and they are both sized h×t.",3.1. Convex relaxation,[0],[0]
"Since t h in general, their ranks are h and their column spaces have full rank.",3.1. Convex relaxation,[0],[0]
"As a result, we may perform change of variable via Λ = ΦA, where A ∈ Rt×t+ and is not necessarily symmetric.",3.1. Convex relaxation,[0],[0]
"So we can rewrite (5) as min Φ≥0 max R1=0,A≥0 1 2 ‖Φ‖ 2 − 12 tr(Φ ′Φ(I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
"− 12 tr(Φ ′ΦR′R)− 12 tr(Φ ′ΦAA′)− `∗(R).
",3.1. Convex relaxation,[0],[0]
"Although this is still not convex, all occurrences of Φ are now in the form of Φ′Φ, leading to the natural idea of optimizing over Φ′Φ directly.",3.1. Convex relaxation,[0],[0]
"Denote T := Φ′Φ ∈ Rt×t, and then we finally arrive at
min T∈Th max R1=0,A≥0
1 2 tr(T )",3.1. Convex relaxation,[0],[0]
"− 1 2 tr(T (I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
"− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R),
where Th := { Φ′Φ : Φ ∈ Rh×t+ } ⊆ { T ∈ Rt×t+ : T 0 } .",3.1. Convex relaxation,[0],[0]
T 0 means T is positive semi-definite (PSD).,3.1. Convex relaxation,[0],[0]
"Now given T , the maximization over R and A is concave because T 0.",3.1. Convex relaxation,[0],[0]
"Indeed A and R are decoupled, making the inner optimization efficient.",3.1. Convex relaxation,[0],[0]
"The objective function is also convex in T , because maximization over linear terms gives a convex function.",3.1. Convex relaxation,[0],[0]
"The only challenge left is the nonconvexity of Th.
",3.1. Convex relaxation,[0],[0]
The set Th is obviously a cone.,3.1. Convex relaxation,[0],[0]
"In fact, if we relax the fixed value of h, then T∞ is the well-known completely positive (CP) matrix cone (Berman & Shaked-Monderer, 2003).",3.1. Convex relaxation,[0],[0]
"More interestingly, it is not hard to show that T∞ is the tightest convex relaxation of Th, i.e. the convex hull of Th for any h. Letting T := T∞ yields our final objective
min T∈T max R1=0,A≥0
1 2 tr(T )",3.1. Convex relaxation,[0],[0]
"− 1 2 tr(T (I −A)X ′X(I −A′))
",3.1. Convex relaxation,[0],[0]
− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R).,3.1. Convex relaxation,[0],[0]
"(6)
It turns out that the convex relaxation does not require prespecifying the number of hidden nodes; h can be figured out automatically through the rank of the optimal T .",3.1. Convex relaxation,[0],[0]
"We will see in the sequel that the formulation does implicitly favor a low-rank solution through a gauge regularizer (Lemma 1), although a manual assignment of h can always be incorporated through truncation after optimization.
",3.1. Convex relaxation,[0],[0]
Generality of the convexification scheme.,3.1. Convex relaxation,[0],[0]
"We note in passing that the above technique is general, and can be extended beyond ReLU.",3.1. Convex relaxation,[0],[0]
"For example, when using the hard tanh transfer, we have F ∗h (Φ) = 1 2 ‖Φ‖
2 if the L∞ norm ‖Φ‖∞",3.1. Convex relaxation,[0],[0]
":= maxij |Φij | ≤ 1, and∞ otherwise.",3.1. Convex relaxation,[0],[0]
"Then we get the same objective function as in (6), only with Th changed into {Φ′Φ : ‖Φ‖∞ ≤ 1} and the domain of A changed into {A : ∑",3.1. Convex relaxation,[0],[0]
i |Aij,3.1. Convex relaxation,[0],[0]
"| ≤ 1, ∀ j}.
",3.1. Convex relaxation,[0],[0]
Even more general extensions to non-elementwise transfer functions can also be developed in our framework.,3.1. Convex relaxation,[0],[0]
"The details on convexifying the soft-max transfer (and hard tanh) are deferred to Appendix B, and the space saved will be devoted to the more important issue of efficiently optimizing the model, hence overcoming the key bottleneck that has much confined the applicability of (Aslan et al., 2014).",3.1. Convex relaxation,[0],[0]
"Although the problem (6) is convex, the set T lacks a compact characterization in terms of linear/quadratic, PSD, or second-order conic constraints.",4. Optimization,[0],[0]
"Optimization over completely positive matrices is known hard (Berman & ShakedMonderer, 2003), and even projection to T is NP-hard (Dickinson & Gijben, 2014).1 Therefore we resort to conditional gradient (Frank-Wolfe) methods that are free of projection (CG, Jaggi, 2013; Harchaoui et al., 2015).",4. Optimization,[0],[0]
The key benefit of CG lies in the efficiency of optimizing a linear function over T (a.k.a.,4. Optimization,[0],[0]
"the polar operator), robustness in its inaccuracy (Freund & Grigas, 2016), and the low rank of intermediate solutions due to its greedy and progressive nature (hence efficient intermediate updates).
",4. Optimization,[0],[0]
"In practice, however, CG still suffers from slow convergence, and its linearly-converging variants are typically subject to a large condition number (Lacoste-Julien & Jaggi, 2015).",4. Optimization,[0],[0]
"This is partly because at each step only the weights on the existing bases are optimized, while the bases themselves are not.",4. Optimization,[0],[0]
"To alleviate this problem, Zhang et al. (2012) proposed the Generalized Conditional Gradient algorithm (GCG) which simultaneously optimizes the bases.",4. Optimization,[0],[0]
"Despite the lack of theoretical proof, it is much faster in practice.",4. Optimization,[0],[0]
"Furthermore, GCG is robust to inexactness in polar operators, and one of our key contributions below is to
1In spite of the “convexity”, a convex function may itself be NP-hard to evaluate, or it can be NP-hard to project to a convex set, or optimize a linear function over it.
show that it can efficiently solve (6) with a multiplicative approximation bound of 14 .
",4. Optimization,[0],[0]
"Since GCG operates on gauge regularized objectives, our first step is to take a nontrivial path of rewriting (6).",4. Optimization,[0],[0]
"Recall that given a convex bounded set C containing the origin, the gauge function induced by C evaluated at T is defined as γC(T )",4. Optimization,[0],[0]
":= min{γ ≥ 0 : γX = T, X ∈ C}.",4. Optimization,[0],[0]
"If no such (γ,X) meets the condition, then γC(T )",4. Optimization,[0],[0]
":= ∞. Since (6) does not contain a gauge function induced by a bounded set (T is unbounded), we first recast it into this framework.
",4. Optimization,[0],[0]
"The simplest way to add bound to T is via the trace norm, which is exactly tr(T ) since T 0:
S := T ∩ {T : tr(T ) ≤ 1} (7) = convT1 ∩ {T : tr(T ) ≤ 1}",4. Optimization,[0],[0]
"(8) = conv { xx′ : x ∈ Rt+, ‖x‖ ≤ 1 } .",4. Optimization,[0],[0]
"(9)
Our key observation is the following lemma which allows us to rewrite the problem in terms of gauge regularized objective.",4. Optimization,[0],[0]
"In particular, the domain of the gauge implicitly enforces the constraint on T .
",4. Optimization,[0],[0]
Lemma 1.,4. Optimization,[0],[0]
"S is convex, bounded, and closed.",4. Optimization,[0],[0]
"In addition
γS(T ) =",4. Optimization,[0],[0]
{ tr(T ) T ∈ T +∞ otherwise .,4. Optimization,[0],[0]
"(10)
",4. Optimization,[0],[0]
The proof is relegated to Appendix A.,4. Optimization,[0],[0]
"In fact, it is easy to show that for any convex cone C, the gauge function of its intersection with a half-space tr(A′T )",4. Optimization,[0],[0]
≤ 1 is exactly tr(A′T ) overC.,4. Optimization,[0],[0]
The significance of Lemma 1 is that it provides the cornerstone for solving the problem (6) by GCG.,4. Optimization,[0],[0]
"Indeed, (6) can be equivalently rewritten as
min T
J(T )",4. Optimization,[0],[0]
:= 12γS(T ) + g(T ),4. Optimization,[0],[0]
"where (11)
g(T )",4. Optimization,[0],[0]
":= max R1=0,A≥0
− 12 tr(T (I −A)X ′X(I −A′)) (12)
− 12 tr(TR ′R)− 12 tr(TAA ′)− `∗(R).
",4. Optimization,[0],[0]
"This objective finally falls into the framework of GCG sketched in Algorithm 1 (Zhang et al., 2012; Harchaoui et al., 2015).",4. Optimization,[0],[0]
GCG proceeds in iterations and at each step it seeks the steepest descent extreme point T new (a.k.a. basis) of the set S with respect to the objective gradient (steps 3-4).,4. Optimization,[0],[0]
"After finding the optimal conic combination with the existing solution (step 5), it directly optimizes the underlying factor Φ, initialized by the value that corresponds to the current solution T (step 6).",4. Optimization,[0],[0]
"Although this last step is not convex (hence called “local optimization”), it offers significant practical efficiency because it allows all existing bases to be optimized along with their weights.
",4. Optimization,[0],[0]
"We next provide details on the efficient computational strategies for the above operations in our problem.
",4. Optimization,[0],[0]
Algorithm 1: General GCG algorithm 1 Randomly sample Φ1 ∈,4. Optimization,[0],[0]
"[0, 1]t, and set T1 = Φ′1Φ1.",4. Optimization,[0],[0]
"2 while k = 1, 2, . .",4. Optimization,[0],[0]
.,4. Optimization,[0],[0]
"do 3 Find ∇g(Tk) with Tk = Φ′kΦk by solving the inner
maximization problem in g(Tk) of (12).",4. Optimization,[0],[0]
"4 Polar operator: find a new basis via T new = arg maxT∈S 〈T,−∇g(Tk)〉.",4. Optimization,[0],[0]
"5 Compute the optimal combination weight
(α, β) := arg minα≥0,β≥0 J(αTk + βT",4. Optimization,[0],[0]
"new).
6 Locally optimize T : Φk+1 =arg minΦ≥0 J(Φ′Φ) with Φ initialized by the value corresponding to Φ′Φ",4. Optimization,[0],[0]
"= αTk + βT
new (see Section 4.1).",4. Optimization,[0],[0]
7 Return Tk+1,4. Optimization,[0],[0]
"Given the negative gradient G = −∇g(Tk) ∈ Rt×t, the polar operator of S tries to solve the following optimization problem by using the characterization of S in (9):
max T∈S tr(G′T ) ⇐⇒ max x∈Rt+, ‖x‖≤1 tr(x′Gx).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"(13) Unfortunately, this problem is NP-hard.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"If this were solvable for any G, then we could use it to answer whether minx≥0 x
′(−G)x ≥ 0.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"But the latter is to check the copositivity of −G, which is known to be co-NP-complete (Murty & Kabadi, 1987).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Usually problems like (13) are approached by semi-definite relaxations (SDP), and Nemirovski et al. (1999) showed that it can be approximately solved with a multiplicative bound of O(1/ log t).
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"As one of our major contributions, we next show that when G 0, this bound can be tightened into constant for (13) with a computational procedure that is much more efficient than SDP.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Furthermore, our problem does satisfy G 0.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Before proceeding, we first recall the definition of a multiplicative α-approximate solution.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Definition 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Let α ∈ (0, 1] and assume an optimization problem maxx∈X f(x) has nonnegative optimal value.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
A solution x∗ ∈ X is called α-approximate if f(x∗) ≥ αmaxx∈X f(x) ≥ 0.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Similarly, the condition becomes 0 ≤ f(x∗) ≤",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
1α minx∈X f(x) for minimization problems.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Theorem 3.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Assume G 0.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Then a 14 -approximate solution to (13) can be found in O(t2) time.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Proof.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Since G 0, it can be decomposed into G = H ′H and the problem (13) becomes maxx∈Rt+,‖x‖≤1 ‖Hx‖
2.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Let v be top eigenvector ofG that corresponds to the greatest eigenvalue.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Then v maximizes ‖Hx‖ over ‖x‖ ≤ 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Decompose v = v+ − v−, where v+ =",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"[v]+ collects the nonnegative components, and v− collects the negative components.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Apparently we have ‖v+‖ ≤ 1 and ‖v−‖ ≤ 1.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Without loss of generality assume ‖Hv+‖2 ≥ ‖Hv−‖2 and consequently let us use v+ as an approximate minimizer, which we demonstrate is 14 -approximate:
maxx∈Rt+,‖x‖≤1‖Hx‖ 2≤ ‖Hv‖2",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"= ‖Hv+ −Hv−‖2
≤ 2(‖Hv+‖2+‖Hv−‖2) ≤4 ‖Hv+‖2.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Obviously v+‖v+‖ is an even better solution, which can also be used as an initializer for further local optimization.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"The computational bottleneck lies in the top eigenvector v of G, which costs O(t2).
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"In the case that G is not PSD, it turns out very hard to extend this technique while retaining a constant bound.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"However the SDP-based technique in (Nemirovski et al., 1999) still applies, and the bound remains 1/ log t.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"In hindsight, our choice of the adding Frobenius norm constraint on Φ when defining S in (7) is not arbitrary.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
It constitutes the most straightforward path that allows the polar operator to be approximated in a tractable fashion.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Other choices, such as structured Frobenius norms, could be possible if we would like to enforce structured decompositions in the hidden representation.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"We leave the extension of tractable approximation for future exploration.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Finally, although our algorithm for the polar operator requires G be positive semi-definite—which is not satisfied in general—it happens to be fulfilled by our particular problem (11).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"Notice the gradient of g is simply
− 12 (I −A)X ′X(I −A′)−",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
12R ′R−,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"12AA ′, (14)
where the R and A are the optimal solution to the inner maximization.",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"This is obviously negative semi-definite, providing the key cornerstone for the constant approximation bound of our approach.
",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Optimality of GCG and rates of convergence We finally translate the bound on the polar operator to that of the original objective (11).,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"As shown by Theorem 1 of (Cheng et al., 2016), any α-approximate polar operator allows GCG to converge to an α-approximate solution to the original problem, and the convergence rate is O(1/ ).",4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
Hence we are guaranteed to find a 14 -approximate solution to (11).,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
The overall method is summarized in Algorithm 2.,4.1. Polar operator and constant multiplicative approximation guarantee,[0],[0]
"The computational bottleneck of applying GCG to our problem (11) is the step of local optimization: minΦ J(Φ
′Φ) over Φ ∈ Rh×t+ .",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Owing to the Φ′Φ term, this objective is not convex.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"However, it is often observed in practice that the overall optimization can be much accelerated if we solve it just locally (e.g. by BFGS), with Φ initialized based on the value of the convex optimization variable T (step 6 of Algorithm 1 or step 11 of Algorithm 2).
",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Unfortunately, since g defined in (12) employs a nested maximization, we are now faced with a min-max problem.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"Different from min-min optimizations minx miny f(x, y)
Algorithm 2: Solve (6) for T by the GCG algorithm 1 Randomly sample Φ1 ∈",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"[0, 1]t, and set T1 = Φ′1Φ1.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"2 while k = 1, 2, . .",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
.,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"do 3 if k = 1 then 4 (Uk,bk) = optimal U and b in (15) for Φ1.",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
5 Mk = optimal M in (15) for Φ1.,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
6 Recover the optimal R: Rk=∇`(U ′kΦk+bk1′).,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
7 Recover the optimal A by (17).,4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"8 Compute the gradient Gk of gµ at Tk = Φ′kΦk via
(14), with R and A served by Rk and Ak, resp 9 Compute a new basis xk by approximately solving
arg maxx∈Rt+,‖x‖≤1 x ′(−Gk)x (c.f. Theorem 3).",4.2. Accelerating local optimization by converting min-max into min-min,[0],[0]
"(α, β) := arg minα≥0,β≥0 J(αTk + βxkx ′ k).
11 Set Φtmp = ( √ αΦ′k, √ βxk)
′. 12 Local search: (Φk+1, Uk+1,bk+1,Mk+1) := Local Opt(Φtmp, Uk,bk,Mk) by Algorithm 3.",10 Line search:,[0],[0]
"13 Return Tk+1
Algorithm 3: Local optimization used by GCG 1 Require (Φtmp, Uk,bk,Mk) from the current step 2 Initialize : Φ = Φtmp, U = Uk, b = bk, M = Mk. 3 for t = 1, 2, . . .",10 Line search:,[0],[0]
"do // till the change is small 4 (U,b) = arg minU,b{`(U ′Φ + b1′) + 12 ‖U‖
2}.",10 Line search:,[0],[0]
"5 M = arg minM≥0 h(M,Φ).",10 Line search:,[0],[0]
6,10 Line search:,[0],[0]
"Φ = arg minΦ≥0 {`(U ′Φ + b1′) + h(M,Φ)}.",10 Line search:,[0],[0]
"7 Return (Φ, U,b,M).
",10 Line search:,[0],[0]
"which can be solved very efficiently by alternating between optimizing x and y, a min-max problem like minx maxy f(x, y) cannot be solved by alternating: fixing x solve y, and fixing y solve x. Instead, one needs to treat the objective as a function of x, and for each x solve the inner maximization in y exactly, before obtaining a gradient in x that is supplied to standard solvers such as BFGS.",10 Line search:,[0],[0]
"This is often much slower than alternating.
",10 Line search:,[0],[0]
"To enable an efficient solution by alternating, we next develop a novel reformulation of g as a minimization, such that minimizing g becomes a min-min problem:
g(Φ′Φ) = max R1=0 { − 12 ‖ΦR ′‖2 − `∗(R) }
+ max A≥0
{ − 12 ‖Φ(I −A)X ′‖2",10 Line search:,[0],[0]
"− 12 ‖ΦA‖ 2 }
= max R min b
{ b′R1−`∗(R)−max
U − tr(U ′ΦR′)− ‖U‖
2
2 } + max
A min M≥0
{ −‖Φ(I−A)X
′‖2 2 − ‖ΦA‖2 2 + tr(M ′A) }",10 Line search:,[0],[0]
"= min
U,b
{ `(U ′Φ + b1′) + 12 ‖U‖ 2 }
+",10 Line search:,[0],[0]
"min M≥0 h(M,Φ), (15)
where h(M,Φ) := max",10 Line search:,[0],[0]
"A
{ − 12 ‖Φ(I −A)X ′‖2 (16)
− 12 ‖ΦA‖ 2
+ tr(M ′A) } .
",10 Line search:,[0],[0]
"As the key advantage achieved here, the local optimization minΦ≥0 J(Φ ′Φ) = minΦ≥0 1 2 ‖Φ‖ 2 + g(Φ′Φ) can now be solved by alternating between (U,b), M , and Φ. The details are shown in Algorithm 3.",10 Line search:,[0],[0]
"The optimization over (U,b) is the standard supervised learning.",10 Line search:,[0],[0]
"However, the optimization over M and Φ is trickier because they require evaluating h which in turn involves a nested optimization on A.",10 Line search:,[0],[0]
"Fortunately h is quadratic in A, which allows us to design an efficient closed-form scheme by leveraging the celebrated Woodbury formula (Woodbury, 1950).
",10 Line search:,[0],[0]
"Given (M,Φ), the optimal A can be found by setting its gradient to zero: Φ′ΦA(X",10 Line search:,[0],[0]
′X,10 Line search:,[0],[0]
+ I) = M + Φ′ΦX ′X .,10 Line search:,[0],[0]
"Unfortunately, the rank of Φ′ΦA (hence the left-hand side) is at most h < t.",10 Line search:,[0],[0]
"So noA can satisfy the equality if the rank of the right-hand side is greater than h, and hence h(M,Φ) is finite only if the column space of (M + Φ′ΦX ′X)(X ′X+ I)−1 is contained in that of Φ′. Such an implicit constraint between variables precludes the application of alternating.
",10 Line search:,[0],[0]
"To address this problem, we introduce a small strongly convex regularizer on A in the definition of h(M,Φ) in (16), akin to the standard smoothing technique (Nesterov, 2005):
hµ(M,Φ) := max A
{ − 12 ‖Φ(I −A)X ′‖2 − 12 ‖ΦA‖ 2
+ tr(M ′A)− µ2 tr(A(X ′X + I)A′)
} ,
where µ > 0 is small.",10 Line search:,[0],[0]
"The new term µ2 tr(A(X ′X + I)A′) also needs to be added to the definition of g in (12), which we will denote as gµ. Then the optimal A can be found by setting the gradient to zero: A = (Φ′Φ + µI)−1(M + Φ′ΦX ′X)(X ′X +",10 Line search:,[0],[0]
I)−1.,10 Line search:,[0],[0]
"(17)
To efficiently computeA, we apply the Woodbury formula: µA",10 Line search:,[0],[0]
= (M + Φ′ΦX ′X)(X ′X +,10 Line search:,[0],[0]
"I)−1
− Φ′(µI + ΦΦ′)−1Φ(M + Φ′ΦX ′X)(X ′X+I)−1.
",10 Line search:,[0],[0]
Computational complexity.,10 Line search:,[0],[0]
Here (µI + ΦΦ′)−1 ∈ Rh×h can be computed efficiently as h is not large (it is exactly the iteration index k in GCG Algorithm 2).,10 Line search:,[0],[0]
Then the second line can be computed inO(ht2) time as we can precompute (X ′X + I)−1.,10 Line search:,[0],[0]
"So the only challenge in computing A is the term M(X ′X+ I)−1, which costs O(t3) time.",10 Line search:,[0],[0]
"However, if n t, then we may again save computations by applying the Woodbury formula: M(X ′X + I)−1 = M −MX ′(I +XX ′)−1X, which costs O(nt2) time.
",10 Line search:,[0],[0]
"Overall, the complexity is 1 ·nt 2 multiplied with: i) #round of alternating in Algorithm 3, and ii) #iteration of LBFGS in steps 4-6.",10 Line search:,[0],[0]
"In practice, with warm start these two numbers are about 10 before the relative change becomes small.",10 Line search:,[0],[0]
"We evaluated the proposed inductive training of convexified two-layer model (CVX-IN) by comparing the generalization accuracy with 4 other baselines: FFNN: a two-layer
feedforward neural network; Ker-CVX: the kernel-based convex model proposed by Aslan et al. (2014); LOCAL: a model obtained by alternative minimization of the twolayer objective (3); and CVX-TR: our model learned transductively (see below).",5. Experiment,[0],[0]
"SVM was not included since it was already shown inferior to Ker-CVX by Aslan et al. (2014).
",5. Experiment,[0],[0]
Inductive learning.,5. Experiment,[0],[0]
"A key advantage of our method is the purely inductive setting, which obviates any retraining during test time, as opposed to a transductive setting.",5. Experiment,[0],[0]
"After completing the GCG optimization, CVX-IN directly obtains the optimal U and b thanks to the local minimization in Algorithm 3.",5. Experiment,[0],[0]
"The optimal W can be recovered by solving (3) with fixed (Φ, U,b), and it is a simple convex problem.",5. Experiment,[0],[0]
"With this initialization, we finely tuned all parameters by backpropagation.
",5. Experiment,[0],[0]
Transductive learning.,5. Experiment,[0],[0]
"As Ker-CVX is transductive, we also considered the following transductive variant of CVXIN.",5. Experiment,[0],[0]
"The objective (11) was first trained with X being the combination of (Xtrain, Xtest), and accordingly the intermediate representation Φ (along with the corresponding T ) also consisted of the combination of (Φtrain,Φtest).",5. Experiment,[0],[0]
"Since only Ytrain was available for training, the loss function `(U ′Φ + b1′) was applied only to the training data.",5. Experiment,[0],[0]
"As a result, Φtest was learned largely from the matching loss in the latent layer given by (16).",5. Experiment,[0],[0]
"After recovering the optimal U and b by local minimization (same as in CVX-IN), test data were labeled by Ŷtest = U ′Φtest +b1′. Although CVX-TR bypasses the recovery of W , optimization has to be redone from scratch when new test data arrives.
",5. Experiment,[0],[0]
Comparison on smaller datasets.,5. Experiment,[0],[0]
"To enable comparison with Ker-CVX which is highly expensive in computation, we first used smaller datasets including a synthetic XOR dataset and three “real world” datasets for binary classification: Letter (Lichman, 2013), CIFAR-SM, a binary classification dataset from (Aslan et al., 2013) based on CIFAR100 (Krizhevsky & Hinton, 2009), and G241N (Chapelle).
",5. Experiment,[0],[0]
"All methods were applied to two different sizes of training and test data (Xtrain and Xtest): 100/100 and 200/200, and the resulting test error, averaged over 10 trials, were presented in Table 1 and 2 respectively.",5. Experiment,[0],[0]
"CVX-IN outperforms FFNN on G241N, Letter, and CIFAR-SM, and they both delivered perfect classification on XOR.",5. Experiment,[0],[0]
"This corroborates the advantage of convex models, suggesting that predictive structures are preserved by the relaxation.",5. Experiment,[0],[0]
"CVX-IN also marginally outperforms or is comparable to CVX-TR on all the datasets, confirming that inductive learning saves computation at test time without sacrificing the accuracy.",5. Experiment,[0],[0]
"Consistently poor performance is observed on the LOCAL method (used in a transductive fashion), and it does not work even for XOR.",5. Experiment,[0],[0]
This implies that it does suffer seriously from local optimality.,5. Experiment,[0],[0]
"Ker-CVX (transductive only) performs competitively on 200 examples especially on the Letter dataset, but its error on 100 examples is significantly
higher than CVX-IN and CVX-TR.",5. Experiment,[0],[0]
"It ran into computational issues on G241N, hence marked by N/A.
On the CIFAR-SM dataset all methods produced a slightly higher error with 200 training examples than 100 examples, probably due to the small size of training set and high variance.",5. Experiment,[0],[0]
"However the comparative results between algorithms remain similar to other datasets.
",5. Experiment,[0],[0]
Comparison on larger datasets.,5. Experiment,[0],[0]
"Thanks to the fast local optimization enabled by the new min-min alternating (§4.2), our model enjoys significant speedup compared with Aslan et al. (2013; 2014).",5. Experiment,[0],[0]
"To demonstrate this, we applied CVX-IN to Letter, XOR, and CIFAR-10 (Krizhevsky & Hinton, 2009) with 1000/1000 and 2000/2000 train/test examples, and to G241N with 1000/500 examples (the entire dataset only has 1500 examples).",5. Experiment,[0],[0]
"Details on data preprocessing are available in Appendix C.
As Table 3 and 4 show, CVX-IN again achieves significantly lower test error on these larger datasets over FFNN, CVX-TR, and LOCAL.",5. Experiment,[0],[0]
"The training time of CVX-IN is summarized in Table 6, and it took 2.5 hours on CIFAR-10 with 2000 examples and 256 features.",5. Experiment,[0],[0]
"Although still expensive, it is substantially faster than Ker-CVX which is completely incapable of scaling here (hence omitted).",5. Experiment,[0],[0]
"In contrast, the run time of FFNN and LOCAL is much lower.",5. Experiment,[0],[0]
"These are shown for comparison in Appendix D. Overall CVX-IN scales quadratically in #examples (t), which is consistent with our analysis in §4.2.
",5. Experiment,[0],[0]
Intermediate representation.,5. Experiment,[0],[0]
One of the key merits of our two-layer model is that the relaxation retains the necessary structure in the input data to make accurate predictions.,5. Experiment,[0],[0]
"To test this feature, we tried to visualize the latent representation learned by our CVX-IN.",5. Experiment,[0],[0]
"Figure 2 demonstrates the original features in the input data Xtrain and the learned intermediate representation Φtrain, for two datasets Box and XOR which both employ a rich latent structure.",5. Experiment,[0],[0]
Clearly the convex relaxation was able to separate the two classes and preserve sufficient structures that allows it to outperform single-layer models.,5. Experiment,[0],[0]
We developed a convex relaxation for parametric transfer functions such as ReLU based on matching loss.,6. Conclusions and Future Work,[0],[0]
An efficient optimization method was designed with a constant approximation bound.,6. Conclusions and Future Work,[0],[0]
For future work we will explore other transfer functions and their influence.,6. Conclusions and Future Work,[0],[0]
"To the best of our knowledge, no nontrivial recovery properties are known about nonlinear CP or SDP relaxation.",6. Conclusions and Future Work,[0],[0]
"Although our empirical results demonstrate compelling promise, it will be interesting to rigorously establish its theoretical guarantees.",6. Conclusions and Future Work,[0],[0]
"Latent prediction models, exemplified by multilayer networks, employ hidden variables that automate abstract feature discovery.",abstractText,[0],[0]
"They typically pose nonconvex optimization problems and effective semi-definite programming (SDP) relaxations have been developed to enable global solutions (Aslan et al., 2014).",abstractText,[0],[0]
"However, these models rely on nonparametric training of layer-wise kernel representations, and are therefore restricted to transductive learning which slows down test prediction.",abstractText,[0],[0]
"In this paper, we develop a new inductive learning framework for parametric transfer functions using matching losses.",abstractText,[0],[0]
"The result for ReLU utilizes completely positive matrices, and the inductive learner not only delivers superior accuracy but also offers an order of magnitude speedup over SDP with constant approximation guarantees.",abstractText,[0],[0]
Inductive Two-layer Modeling with Parametric Bregman Transfer,title,[0],[0]
"In this paper, we analyze inference suboptimality: the mismatch between the true and approximate posterior.",1. Introduction,[0],[0]
"More specifically, we are interested in understanding what factors cause the gap between the marginal log-likelihood and the evidence lower bound (ELBO) in variational autoencoders (VAEs, Kingma & Welling (2014); Rezende et al. (2014)).",1. Introduction,[1.0],"['More specifically, we are interested in understanding what factors cause the gap between the marginal log-likelihood and the evidence lower bound (ELBO) in variational autoencoders (VAEs, Kingma & Welling (2014); Rezende et al. (2014)).']"
We refer to this as the inference gap.,1. Introduction,[1.0],['We refer to this as the inference gap.']
"Moreover, we break down the inference gap into two components: the approximation gap and the amortization gap.",1. Introduction,[1.0],"['Moreover, we break down the inference gap into two components: the approximation gap and the amortization gap.']"
The approximation gap comes from the inability of the variational distribution family to exactly match the true posterior.,1. Introduction,[1.0],['The approximation gap comes from the inability of the variational distribution family to exactly match the true posterior.']
"The amortization gap refers to the difference caused by amortizing the variational parameters over the entire training set, instead of optimizing for each training example individually.",1. Introduction,[1.0],"['The amortization gap refers to the difference caused by amortizing the variational parameters over the entire training set, instead of optimizing for each training example individually.']"
"We refer the reader to Table 1 for the definitions of the gaps and to
1Department of Computer Science, University of Toronto, Toronto, Canada.",1. Introduction,[0],[0]
"Correspondence to: Chris Cremer <ccremer@cs.toronto.edu>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
Fig. 1 for a simple illustration of the gaps.,1. Introduction,[0],[0]
"In Fig. 1, L[q] refers to the ELBO evaluated using an amortized distribution q, as is typical of VAE training.",1. Introduction,[0],[0]
"In contrast, L[q⇤] is the ELBO evaluated using the optimal approximation within its variational family.
",1. Introduction,[0],[0]
"There has been significant work on improving variational inference in VAEs through the development of expressive approximate posteriors (Rezende & Mohamed, 2015; Kingma et al., 2016; Ranganath et al., 2016; Tomczak & Welling, 2016; 2017).",1. Introduction,[0],[0]
"These works have shown that with more expressive approximate posteriors, the model learns a better distribution over the data.",1. Introduction,[0],[0]
"Our study aims to gain a better understanding of the relationship between expressive approximations and improved generative models.
",1. Introduction,[0],[0]
"Our experiments investigate how the choice of encoder, posterior approximation, decoder, and optimization affect the approximation and amortization gaps.",1. Introduction,[0],[0]
"We train VAE models in a number of settings on the MNIST (LeCun et al., 1998), Fashion-MNIST (Xiao et al., 2017), and CIFAR-10 (Krizhevsky & Hinton, 2009) datasets.
",1. Introduction,[0],[0]
"Our contributions are: a) we investigate inference suboptimality in terms of the approximation and amortization gaps, providing insight to guide future improvements in VAE inference, b) we quantitatively demonstrate that the learned generative model accommodates the choice of approximation, and c) we demonstrate that parameterized functions that improve the expressiveness of the approximation play a significant role in reducing amortization error.",1. Introduction,[0],[0]
"Let x be the observed variable, z the latent variable, and p(x, z) be their joint distribution.",2.1. Inference in Variational Autoencoders,[0],[0]
"Given a dataset X = {x1, x2, ..., xN}, we would like to maximize the marginal log-likelihood with respect to the model parameters ✓:
log p✓(X) = NX
i=1
log p✓(xi) = NX
i=1
log Z p✓(xi, zi)dzi.
",2.1. Inference in Variational Autoencoders,[0],[0]
"In practice, the marginal log-likelihood is computationally intractable due to the integration over the latent variable z. Instead, VAEs introduce an inference network q (z|x) to approximate the true posterior p(z|x) and optimize the ELBO with respect to model parameters ✓ and inference network parameters (parameterization subscripts omitted for brevity): log p(x) = Eq(z|x)  log ✓ p(x, z)
q(z|x)
◆ + KL (q(z|x)||p(z|x))
(1)
Eq(z|x)  ",2.1. Inference in Variational Autoencoders,[0],[0]
"log ✓ p(x, z)
q(z|x)
◆ = LVAE[q].",2.1. Inference in Variational Autoencoders,[0],[0]
"(2)
From the above equation, we see that the ELBO is tight when q(z|x) = p(z|x).",2.1. Inference in Variational Autoencoders,[0],[0]
The choice of q(z|x) is often a factorized Gaussian distribution for its simplicity and efficiency.,2.1. Inference in Variational Autoencoders,[0],[0]
"By utilizing the inference network (also referred to as encoder or recognition network), VAEs amortize inference over the entire dataset.",2.1. Inference in Variational Autoencoders,[0],[0]
"Furthermore, the overall model is trained by stochastically optimizing the ELBO using the reparametrization trick (Kingma & Welling, 2014).",2.1. Inference in Variational Autoencoders,[0],[0]
"There are a number of strategies for increasing the expressiveness of approximate posteriors, going beyond the original factorized-Gaussian.",2.2. Expressive Approximate Posteriors,[0],[0]
We briefly summarize normalizing flows and auxiliary variables.,2.2. Expressive Approximate Posteriors,[0],[0]
"Normalizing flow (Rezende & Mohamed, 2015) is a change of variables procedure for constructing complex distributions by transforming probability densities through a series of invertible mappings.",2.2.1. NORMALIZING FLOWS,[0],[0]
"Specifically, if we transform
a random variable z0 with distribution q0(z), the resulting random variable zT = T (z0) has a distribution:
qT (zT ) = q0(z0) det @zT @z0
1
.",2.2.1. NORMALIZING FLOWS,[0],[0]
"(3)
By successively applying these transformations, we can build arbitrarily complex distributions.",2.2.1. NORMALIZING FLOWS,[0],[0]
Stacking these transformations remains tractable due to the determinant being decomposable: det(AB) = det(A)det(B).,2.2.1. NORMALIZING FLOWS,[0],[0]
"An important property of these transformations is that we can take expectations with respect to the transformed density qT (zT ) without explicitly knowing its formula due to the law of the unconscious statistician (LOTUS):
EqT",2.2.1. NORMALIZING FLOWS,[0],[0]
[h(zT )],2.2.1. NORMALIZING FLOWS,[0],[0]
= Eq0,2.2.1. NORMALIZING FLOWS,[0],[0]
[h(fT (fT 1(...f1(z0))))].,2.2.1. NORMALIZING FLOWS,[0],[0]
"(4)
Using equations (3) and (4), the lower bound with the transformed approximation can be written as:
Ez0⇠q0(z|x)
2
64log
0
B@ p(x, zT )
q0(z0|x) QT
t=1 det @zt@zt 1 1
1
CA
3
75 .
(5)
",2.2.1. NORMALIZING FLOWS,[0],[0]
The main constraint on these transformations is that the determinant of their Jacobian needs to be easily computable.,2.2.1. NORMALIZING FLOWS,[0],[0]
Deep generative models can be extended with auxiliary variables which leave the generative model unchanged but make the variational distribution more expressive.,2.2.2. AUXILIARY VARIABLES,[1.0],['Deep generative models can be extended with auxiliary variables which leave the generative model unchanged but make the variational distribution more expressive.']
"Just as hierarchical Bayesian models induce dependencies between data, hierarchical variational models can induce dependencies between latent variables.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"The addition of the auxiliary variable changes the lower bound to:
Ez,v⇠q(z,v|x)  log ✓ p(x, z)r(v|x, z)
q(z, v|x)
◆ (6)
= Eq(z|x)  log ✓ p(x, z)
q(z|x)
◆ KL ⇣ q(v|z, x)kr(v|x, z) ⌘
(7)
where r(v|x, z) is called the reverse model.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"From Eqn. 7, we see that this bound is looser than the regular ELBO,
however the extra flexibility provided by the auxiliary variable can result in a higher lower bound.",2.2.2. AUXILIARY VARIABLES,[0],[0]
"This idea has been employed in works such as auxiliary deep generative models (ADGM, (Maaløe et al., 2016)), hierarchical variational models (HVM, (Ranganath et al., 2016)) and Hamiltonian variational inference (HVI, (Salimans et al., 2015)).",2.2.2. AUXILIARY VARIABLES,[1.0],"['This idea has been employed in works such as auxiliary deep generative models (ADGM, (Maaløe et al., 2016)), hierarchical variational models (HVM, (Ranganath et al., 2016)) and Hamiltonian variational inference (HVI, (Salimans et al., 2015)).']"
The inference gap G is the difference between the marginal log-likelihood log p(x) and a lower bound L[q].,3.1. Approximation and Amortization Gaps,[0],[0]
"Given the distribution in the family that maximizes the bound, q⇤(z|x) = argmaxq2Q",3.1. Approximation and Amortization Gaps,[0],[0]
"L[q], the inference gap decomposes as the sum of approximation and amortization gaps:
G = log p(x) L[q] = log p(x) L[q⇤]| {z } Approximation +L[q⇤] L[q]| {z } Amortization .
",3.1. Approximation and Amortization Gaps,[0],[0]
"For VAEs, we can translate the gaps to KL divergences by rearranging Eqn.",3.1. Approximation and Amortization Gaps,[0],[0]
"(1):
GVAE = KL q⇤(z|x)||p(z|x)
",3.1. Approximation and Amortization Gaps,[0],[0]
"| {z }
Approximation
+ KL q(z|x)||p(z|x)
KL q⇤(z|x)||p(z|x)
| {z }
Amortization
.
(8)",3.1. Approximation and Amortization Gaps,[0],[0]
Our experiments involve expressive approximations which use flow transformations and auxiliary variables.,3.2. Flexible Approximate Posteriors,[0],[0]
"The flow transformation that we employ is of the same type as the transformations of Real NVP (Dinh et al., 2017).",3.2. Flexible Approximate Posteriors,[0],[0]
"We partition the latent variable z into two, z1 and z2, then perform the following transformations:
z01 = z1 1(z2) + µ1(z2) (9) z02 = z2 2(z01) + µ2(z01) (10)
where 1, 2, µ1, µ2 : Rn !",3.2. Flexible Approximate Posteriors,[0],[0]
Rn are differentiable mappings parameterized by neural nets and takes the Hadamard or element-wise product.,3.2. Flexible Approximate Posteriors,[0],[0]
We partition the latent variable by simply indexing the elements of the first half and the second half.,3.2. Flexible Approximate Posteriors,[0],[0]
"The determinant of the combined transformation’s Jacobian, det ⇣ @z0
@z ⌘ , can be easily evaluated.",3.2. Flexible Approximate Posteriors,[0],[0]
See section 7.3 of the Supplementary material for a derivation.,3.2. Flexible Approximate Posteriors,[0],[0]
The lower bound of this approximation is the same as Eqn.,3.2. Flexible Approximate Posteriors,[0],[0]
(5).,3.2. Flexible Approximate Posteriors,[0],[0]
"We refer to this approximation as qFlow.
",3.2. Flexible Approximate Posteriors,[1.0000000101167288],['We refer to this approximation as qFlow.']
We also experiment with an approximation that combines flow transformations and auxiliary variables.,3.2. Flexible Approximate Posteriors,[0],[0]
Let z 2 Rn be the variable of interest and v 2 Rn the auxiliary variable.,3.2. Flexible Approximate Posteriors,[0],[0]
"The flow is the same as equations (9) and (10), where z1 is
replaced with z and z2 with v.",3.2. Flexible Approximate Posteriors,[0],[0]
"We refer to this approximate distribution as qAF , where AF stands for auxiliary flow.",3.2. Flexible Approximate Posteriors,[0],[0]
"We train this model by optimizing the following bound:
Eq0(z,v|x)
2
64log
0
B@ p(x, zT )",3.2. Flexible Approximate Posteriors,[0],[0]
"r(vT |x, zT )
qT (zT , vT |x)",3.2. Flexible Approximate Posteriors,[0],[0]
"det
⇣ @ztvt
@zt 1vt 1
⌘ 1
1
CA
3
75
= L[qAF ].",3.2. Flexible Approximate Posteriors,[0],[0]
"(11)
Note that this lower bound is looser as explained in Section 2.2.2.",3.2. Flexible Approximate Posteriors,[0],[0]
We refer readers to Section 7.0.2 in the Supplementary material for specific details of the flow configuration adopted in the experiments.,3.2. Flexible Approximate Posteriors,[0],[0]
"In this section, we describe the estimates we use to compute the bounds of the inference gaps: log p(x), L[q⇤], and L[q].",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"We use two bounds to estimate the marginal log-likelihood, log p(x): IWAE (Burda et al., 2016) and AIS (Neal, 2001).
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
The IWAE bound takes multiple importance weighted samples from the variational q distribution resulting in a tighter lower bound than the VAE bound.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"The IWAE bound is computed as:
log p(x) Ez1...zk⇠q(z|x)
"" log 1
k
kX
i=1
p(x, zi) q(zi|x)
!",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"# (12)
= LIWAE[q].
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"As the number of importance samples approaches infinity, the bound approaches the marginal log-likelihood.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"It is often used as an evaluation metric for generative models (Burda et al., 2016; Kingma et al., 2016).",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
AIS is potentially an even tighter lower bound.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
AIS weights samples from distributions which are sequentially annealed from an initial proposal distribution to the true posterior.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
See Section 7.4 in the Supplementary material for further details regarding AIS.,3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"To compute the AIS bound, we use 100 chains, each with 10000 intermediate distributions, where each transition consists of one HMC trajectory with 10 leapfrog steps.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"The initial distribution for AIS is the prior, so that it is encoderindependent.
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"We estimate the marginal log-likelihood by independently computing our tightest lower bounds then take the maximum of the two:
log p̂(x) = max(LAIS,LIWAE).
",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0.999999987735609],"['We estimate the marginal log-likelihood by independently computing our tightest lower bounds then take the maximum of the two: log p̂(x) = max(LAIS,LIWAE).']"
"The L[q⇤] and L[q] bounds are the standard ELBOs, LVAE, from Eqn.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"(2), computed with either the amortized q or the optimal q⇤ (see below).",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"When computing LVAE and LIWAE, we use 5000 samples.",3.3. Marginal Log-Likelihood Estimation and Evidence Lower Bounds,[0],[0]
"To compute LVAE[q⇤], we optimize the parameters of the variational distribution for every datapoint.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
"For the local optimization of qFFG, we initialize the mean and variance as the prior, i.e. N (0, I).",3.4. Local Optimization of the Approximate Distribution,[0],[0]
We optimize the mean and variance using the Adam optimizer with a learning rate of 10 3.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
"To determine convergence, after every 100 optimization steps, we compute the average of the previous 100 ELBO values and compare it to the best achieved average.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
If it does not improve for 10 consecutive iterations then the optimization is terminated.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
"For qFlow and qAF , the same process is used to optimize all of its parameters.",3.4. Local Optimization of the Approximate Distribution,[0],[0]
"All neural nets for the flow were initialized with a variant of the Xavier initilization (Glorot & Bengio, 2010).",3.4. Local Optimization of the Approximate Distribution,[0],[0]
We use 100 Monte Carlo samples to compute the ELBO to reduce variance.,3.4. Local Optimization of the Approximate Distribution,[0],[0]
The soundness of our empirical analysis depends on the reliability of the marginal log-likelihood estimator.,3.5. Validation of Bounds,[0],[0]
"For general importance sampling based estimators, the sample variance of the normalized importance weights can serve as an indicator of accuracy (Geweke, 1989; Neal, 2001).",3.5. Validation of Bounds,[0],[0]
"This quantitative measure, however, can also be unreliable, e.g. when the proposal misses an important mode of the target distribution (Neal, 2001).
",3.5. Validation of Bounds,[0],[0]
"In this work, we follow (Wu et al., 2017) to empirically validate our AIS estimates with Bidirectional Monte Carlo (BDMC, Grosse et al. (2015; 2016)).",3.5. Validation of Bounds,[0],[0]
"In addition to a lower bound provided by AIS, BDMC runs AIS chains backward from exact posterior samples to obtain an upper bound on the marginal log-likelihood.",3.5. Validation of Bounds,[0],[0]
It should be noted that BDMC relies on the assumption that the distribution of the simulated data from the model roughly matches that of the real data.,3.5. Validation of Bounds,[0],[0]
"This is due to the backward chain initializes from exact posterior samples (Grosse et al., 2015).
",3.5. Validation of Bounds,[0],[0]
"For the MNIST and Fashion datasets, BDMC gives a gap within 0.1 nat for a linear schedule AIS with 104 intermediate distributions and 100 importance samples on 103 simulated datapoints.",3.5. Validation of Bounds,[0],[0]
"For 3-BIT CIFAR, the same AIS setting gives a gap within 1 nat with the sigmoidial annealing schedule (Grosse et al., 2015) on 100 simulated datapoints.",3.5. Validation of Bounds,[0],[0]
"Loosely speaking, this should give us confidence in how well our AIS lower bounds reflect the marginal loglikelihood computed on the real data.",3.5. Validation of Bounds,[0],[0]
"Much of the earlier work on variational inference focused on optimizing the variational parameters locally for each datapoint, e.g. the original Stochastic Variational Inference scheme (SVI, Hoffman et al. (2013)).",4. Related Work,[0],[0]
"To scale inference to large datasets, most related works utilize inference networks to amortize the cost of inference over the entire dataset.
",4. Related Work,[0],[0]
"Our work analyses the error that these inference networks introduce.
",4. Related Work,[0],[0]
"Most relevant to our work is the recent work of Krishnan et al. (2017), which explicitly remarks on two sources of error in variational learning with inference networks, and proposes to optimize approximate inference locally from an initialization output by the inference network.",4. Related Work,[0],[0]
"They show improved training on high-dimensional, sparse data with the hybrid method, claiming that local optimization reduces the negative effects of random initialization in the inference network early on in training.",4. Related Work,[0],[0]
Thus their work focuses on reducing the amortization gap early on in training.,4. Related Work,[0],[0]
"Similar to this idea, Hoffman (2017) proposes to perform approximate inference during model training with MCMC at an initialization given by a variational distribution.",4. Related Work,[0],[0]
Our work provides a means of explaining these improvements in terms of the sources of inference suboptimality that they reduce.,4. Related Work,[0],[0]
"To begin, we would like to gain an intuitive visualization of the gaps presented in Section 3.1.",5.1. Intuition through Visualization,[0],[0]
"To this end, we trained a VAE with a two-dimensional latent space on MNIST and in Fig. 2 we show contour plots of various distributions in the latent space.",5.1. Intuition through Visualization,[0],[0]
The first row contains contour plots of the true posteriors p(z|x) for four different training datapoints (columns).,5.1. Intuition through Visualization,[0],[0]
We have selected these four examples to highlight different inference phenomena.,5.1. Intuition through Visualization,[0],[0]
"The amortized fully-factorized Gaussian (FFG) row refers to the output of the recognition net, in this case, a FFG approximation.",5.1. Intuition through Visualization,[0],[0]
Optimal FFG is the FFG that best fits the posterior of the datapoint.,5.1. Intuition through Visualization,[0],[0]
"Optimal Flow is the optimal fit of a flexible distribution to the same posterior, where the flexible distribution we use is described in Section 3.2.
",5.1. Intuition through Visualization,[0],[0]
Posterior A is an example of a distribution where a FFG can fit relatively well.,5.1. Intuition through Visualization,[0],[0]
"Posterior B is an example of a posterior with dependence between dimensions, demonstrating the
limitation of having a factorized approximation.",5.1. Intuition through Visualization,[0],[0]
"Posterior C highlights a shortcoming of performing amortization with a limited-capacity recognition network, where the amortized FFG shares little support with the true posterior.",5.1. Intuition through Visualization,[0],[0]
"Posterior D is a bi-modal distribution which demonstrates the ability of the flexible approximation to fit to complex distributions, in contrast to the simple FFG approximation.",5.1. Intuition through Visualization,[0],[0]
"These observations raise the following question: in more typical VAEs, is the amortization of inference the leading cause of the distribution mismatch, or is it the limited expressiveness of the approximation?",5.1. Intuition through Visualization,[0],[0]
"In this section, we compare how much the approximation and amortization gaps each contribute to the total inference gap.",5.2. Amortization vs Approximation Gap,[1.0],"['In this section, we compare how much the approximation and amortization gaps each contribute to the total inference gap.']"
"Table 2 are results of inference on the training set of MNIST, Fashion-MNIST and 3-BIT CIFAR (a binarized version of CIFAR-10, see Section 7.0.3 for details).",5.2. Amortization vs Approximation Gap,[0],[0]
"For each dataset, we trained models with two different approximate posterior distributions: a fully-factorized Gaussian, qFFG, and the flexible distribution, qAF .",5.2. Amortization vs Approximation Gap,[0],[0]
"Due to the computational cost of optimizing the local parameters for each datapoint, our evaluation is performed on a subset of 1000 datapoints for MNIST and Fashion-MNIST and a subset of 100 datapoints for 3-BIT CIFAR.
",5.2. Amortization vs Approximation Gap,[0],[0]
"For MNIST, we see that the amortization and approximation gaps each account for nearly half of the inference gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"On the more difficult Fashion-MNIST dataset, the amortization gap is larger than the approximation gap.",5.2. Amortization vs Approximation Gap,[1.0],"['On the more difficult Fashion-MNIST dataset, the amortization gap is larger than the approximation gap.']"
"For CIFAR, we see that the amortization gap is much more significant compared to the approximation gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"Thus, for the three datasets and model architectures that we consider, the amortization gap is likely to be the more prominent cause of inference suboptimality, especially when the dataset becomes more challenging to model.",5.2. Amortization vs Approximation Gap,[0],[0]
"This indicates that improvements in inference will likely be a result of reducing amortization error, rather than approximation errors.
",5.2. Amortization vs Approximation Gap,[0],[0]
"With these results in mind, would simply increasing the capacity of the encoder improve the amortization gap?",5.2. Amortization vs Approximation Gap,[1.0],"['With these results in mind, would simply increasing the capacity of the encoder improve the amortization gap?']"
"We
examined this by training the MNIST and Fashion-MNIST models from above but with larger encoders.",5.2. Amortization vs Approximation Gap,[0],[0]
See Section 7.0.2 for implementation details.,5.2. Amortization vs Approximation Gap,[0],[0]
Table 3 (left) are the results of this experiment.,5.2. Amortization vs Approximation Gap,[1.0],['Table 3 (left) are the results of this experiment.']
"Comparing to Table 2, we see that, for both datasets and both variational distributions, using a larger encoder results in the inference gap decreasing and the decrease is mainly due to a reduction in the amortization gap.",5.2. Amortization vs Approximation Gap,[0],[0]
"The common reasoning for increasing the expressiveness of the approximate posterior is to minimize the difference between the true and approximate distributions, i.e. reduce the approximation gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"However, given that the expressive approximation is often accompanied by many additional parameters, we would like to know how much influence it has on the amortization error.
",5.3. Influence of Flows on the Amortization Gap,[1.00000008537459],"['However, given that the expressive approximation is often accompanied by many additional parameters, we would like to know how much influence it has on the amortization error.']"
"To investigate this, we trained a VAE on MNIST, discarded the encoder, then retrained encoders with different approximate distributions on the fixed decoder.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
We fixed the decoder so that the true posterior is constant for all the retrained encoders.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
The initial encoder was a two-layer MLP with a factorized Gaussian distribution.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"In order to emphasize a large amortization gap, the retrained encoders had no hidden layers (ie. just linear transformations).",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"For the retraiend encoders, we tested three approximate distributions: fully factorized Gaussian (qFFG), auxiliary flow (qAV ), and Flow (qFlow).",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"See Section 3.2 for the details of these distributions.
",5.3. Influence of Flows on the Amortization Gap,[0],[0]
The inference gaps of the retrained encoders on the training set are shown in Table 4.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"As expected, we observe that the small encoder with qFFG has a very large amortization gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"However, when we use qAF or qFlow as the approximate distribution, we see the approximation gap decrease, but more importantly, there is a significant decrease in the amortization gap.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"This indicates that the parameters used for increasing the complexity of the approximation also play a large role in diminishing the amortization error.
",5.3. Influence of Flows on the Amortization Gap,[0],[0]
"These results are expected given that the parameterization of the Flow distribution can be interpreted as an instance of the RevNet (Gomez et al., 2017) which has demonstrated that Real-NVP transformations (Dinh et al., 2017) can model complex functions similar to typical MLPs.",5.3. Influence of Flows on the Amortization Gap,[0],[0]
Thus the flow transformations we employ should also be expected to increase the expressiveness while also increasing the capacity of the encoder.,5.3. Influence of Flows on the Amortization Gap,[0],[0]
"The implication of this observation is that models which improve the flexibility of their variational approximation, and attribute their improved results to the increased expressiveness, may have actually been due to the reduction in amortization error.",5.3. Influence of Flows on the Amortization Gap,[1.0],"['The implication of this observation is that models which improve the flexibility of their variational approximation, and attribute their improved results to the increased expressiveness, may have actually been due to the reduction in amortization error.']"
To what extent does the posterior approximation affect the learned model?,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
Turner & Sahani (2011) studied the biases in parameter learning induced by the variational approximation when learning via variational Expectation-Maximization.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Similarly, we ask whether a factorized Gaussian approximation causes the true posterior to be more like a factorized Gaussian?",5.4. Influence of Approximate Posterior on True Posterior,[1.0],"['Similarly, we ask whether a factorized Gaussian approximation causes the true posterior to be more like a factorized Gaussian?']"
"Burda et al. (2016) visually demonstrate that when trained with an importance-weighted approximate posterior, the resulting true posterior is more complex than those trained with factorized Gaussian approximations.",5.4. Influence of Approximate Posterior on True Posterior,[1.0],"['Burda et al. (2016) visually demonstrate that when trained with an importance-weighted approximate posterior, the resulting true posterior is more complex than those trained with factorized Gaussian approximations.']"
"Just as it is hard to evaluate a generative model by visually inspecting samples, it is hard to judge how “Gaussian” the true posterior is by visual inspection.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"We can quantitatively determine
how close the posterior is to a fully-factorized Gaussian (FFG) by comparing the marginal log-likelihood estimate log p̂(x) and the Optimal FFG bound LVAE[q⇤FFG].",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This is equivalent to estimating the KL divergence between the optimal Gaussian and the true posterior, KL (q⇤(z|x)||p(z|x)).
",5.4. Influence of Approximate Posterior on True Posterior,[1.0000000071730109],"['This is equivalent to estimating the KL divergence between the optimal Gaussian and the true posterior, KL (q⇤(z|x)||p(z|x)).']"
"In Table 2 on MNIST, for the FFG trained model, KL (q⇤(z|x)||p(z|x)) is nearly the same for both q⇤FFG and q⇤AF .",5.4. Influence of Approximate Posterior on True Posterior,[1.0],"['In Table 2 on MNIST, for the FFG trained model, KL (q⇤(z|x)||p(z|x)) is nearly the same for both q⇤FFG and q⇤AF .']"
"In contrast, on the model trained with qAF , KL (q⇤(z|x)||p(z|x)) is much larger for q⇤FFG than q⇤AF .",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
This suggests that the true posterior of a FFG-trained model is closer to FFG than the true posterior of the Flow-trained model.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
The same observation can be made on the FashionMNIST dataset.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This implies that the decoder can learn to have a true posterior that fits better to the approximation.
",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
These observations justify our results of Section 5.2.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
which showed that the amortization error is often the main cause of inference suboptimality.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"One reason for this is that the generator accommodates the choice of approximation, thus reducing the approximation error.
",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"Given that we have seen that the generator can accommodate the choice of approximation, our next question is whether a generator with more capacity increases its ability to fit to the approximation.",5.4. Influence of Approximate Posterior on True Posterior,[1.0],"['Given that we have seen that the generator can accommodate the choice of approximation, our next question is whether a generator with more capacity increases its ability to fit to the approximation.']"
"To this end, we trained VAEs with decoders of different sizes and measured the approximation gaps on
the training set.",5.4. Influence of Approximate Posterior on True Posterior,[1.0000001138679797],"['To this end, we trained VAEs with decoders of different sizes and measured the approximation gaps on the training set.']"
"Specifically, we trained decoders with 0, 2, and 4 hidden layers on MNIST.",5.4. Influence of Approximate Posterior on True Posterior,[1.0],"['Specifically, we trained decoders with 0, 2, and 4 hidden layers on MNIST.']"
See Table 5 for the results.,5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"We see that as the capacity of the decoder increases, the approximation gap decreases.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
"This result implies that the more flexible the generator is, the less flexible the approximate distribution needs to be to ensure accurate inference.",5.4. Influence of Approximate Posterior on True Posterior,[0],[0]
How well does amortized inference generalize at test time?,5.5. Inference Generalization,[0],[0]
We address this question by visualizing the gaps on training and validation datapoints across the training epochs.,5.5. Inference Generalization,[0],[0]
"In Fig. 3, the models are trained on 50000 binarized FashionMNIST datapoints and the gaps are computed on a subset of a 100 training and validation datapoints.",5.5. Inference Generalization,[0],[0]
The top and bottom boundaries of the blue region represent log p̂(x) and L[q⇤].,5.5. Inference Generalization,[0],[0]
The bottom boundary of the orange region represents L[q].,5.5. Inference Generalization,[0],[0]
"In other words, the blue region is the approximation gap and the orange is the amortization gap.
",5.5. Inference Generalization,[0],[0]
"In Fig. 3, the Standard model (top left) refers to a VAE of latent size 20 trained with a factorized Gaussian approximate posterior.",5.5. Inference Generalization,[0],[0]
"In this case, the encoder and decoder both have two hidden layers each consisting of 200 hidden units.",5.5. Inference Generalization,[0],[0]
The Flow model (top right) augments the Standard model with a qFlow variational distribution.,5.5. Inference Generalization,[0],[0]
"Larger Decoder and Larger Encoder models have factorized Gaussian distributions and increase the number of hidden layers to three and the number of units in each layer to 500.
",5.5. Inference Generalization,[0],[0]
"Firstly, we observe that for all models, the approximation gap on the training and validation sets are roughly equivalent.",5.5. Inference Generalization,[1.0],"['Firstly, we observe that for all models, the approximation gap on the training and validation sets are roughly equivalent.']"
This indicates that the true posteriors of the held-out data are similar to that of the training data.,5.5. Inference Generalization,[1.0],['This indicates that the true posteriors of the held-out data are similar to that of the training data.']
"Secondly, we note that for all models, the encoder overfits more than the decoder.
",5.5. Inference Generalization,[0],[0]
"These observations resonate with the encoder overfitting findings by Wu et al. (2017).
",5.5. Inference Generalization,[0],[0]
How does increasing decoder capacity affect inference on held-out data?,5.5. Inference Generalization,[1.0],['How does increasing decoder capacity affect inference on held-out data?']
We know from Section 5.4 that increasing generator capacity results in a posterior that better fits the approximation making posterior inference easier.,5.5. Inference Generalization,[0],[0]
"Furthermore, the Larger Decoder plot of Fig. 3 shows that increasing generator capacity causes the model to be more prone to overfitting.",5.5. Inference Generalization,[0],[0]
"Thus, there is a tradeoff between ease of inference and decoder overfitting.",5.5. Inference Generalization,[0],[0]
We have seen in Sections 5.2 and 5.3 that expressive approximations as well as increasing encoder capacity can lead to a reduction in the amortization gap.,5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
This leads us to the following question: when should we increase encoder capacity versus increasing the expressiveness of the approximation?,5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"We answer this question in terms of how well each model can generalize its efficient inference (recognition network and variational distribution) to held-out data.
",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"In Fig. 3, we see that the Flow model and the Larger Encoder model achieve similar log p̂(x) on the validation set at the end of training.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"However, we see that the L[q] bound of the Larger Encoder model is significantly lower than the L[q] bound of the Flow model due to the encoder overfitting to the training data.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Although they both model the data nearly equally well, the recognition net of the Larger Encoder model is no longer suitable to perform inference on the held-out data due to overfitting.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Thus a potential rational for utilizing expressive approximations is that they improve generalization to held-out data in comparison to increasing the encoder capacity.
",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"We highlight that, in many scenarios, efficient test time inference is not required and consequently, encoder overfitting is not an issue, since we can use non-efficient encoderindependent methods to estimate log p(x), such as AIS, IWAE with local optimization, or potentially retraining the encoder on the held-out data.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"In contrast, when efficient test time inference is required, encoder generalization is important and expressive approximations are likely advantageous.",5.5.1. ENCODER CAPACITY AND APPROXIMATION EXPRESSIVENESS,[0],[0]
"Typical warm-up (Bowman et al., 2015; Sønderby et al., 2016) refers to annealing the KL (q(z|x)||p(z)) term during training.",5.6. Annealing the Entropy,[0],[0]
This can also be interpreted as performing maximum likelihood estimation (MLE) early on during training.,5.6. Annealing the Entropy,[0],[0]
"This optimization technique is known to help prevent the latent variable from degrading to the prior (Burda et al., 2016; Sønderby et al., 2016).",5.6. Annealing the Entropy,[0],[0]
"We employ a similar annealing scheme during training by annealing the entropy of the
approximate distribution:
Ez⇠q(z|x) [log p(x, z) log q(z|x)] ,
where is annealed from 0 to 1 over training.",5.6. Annealing the Entropy,[0],[0]
"This can be interpreted as maximum a posteriori (MAP) in the initial phase of training.
",5.6. Annealing the Entropy,[0],[0]
"We find that warm-up techniques, such as annealing the entropy, are important for allowing the true posterior to be more complex.",5.6. Annealing the Entropy,[0],[0]
Table 3 (right) are results from a model trained without the entropy annealing schedule.,5.6. Annealing the Entropy,[0],[0]
"Comparing these results to Table 2, we observe that the difference between LVAE[q⇤FFG] and LVAE[q⇤AF ] is significantly smaller without entropy annealing.",5.6. Annealing the Entropy,[0],[0]
This indicates that the true posterior is more Gaussian when entropy annealing is not used.,5.6. Annealing the Entropy,[0],[0]
"This suggests that, in addition to preventing the latent variable from degrading to the prior, entropy annealing allows the true posterior to better utilize the flexibility of the expressive approximation.",5.6. Annealing the Entropy,[0],[0]
"In this paper, we investigated how encoder capacity, approximation choice, decoder capacity, and model optimization influence inference suboptimality in terms of the approximation and amortization gaps.",6. Conclusion,[1.0],"['In this paper, we investigated how encoder capacity, approximation choice, decoder capacity, and model optimization influence inference suboptimality in terms of the approximation and amortization gaps.']"
We discovered that the amortization gap can be a leading source to inference suboptimality and that the generator can reduce the approximation gap by learning a true posterior that fits to the choice of approximation.,6. Conclusion,[0],[0]
We showed that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.,6. Conclusion,[0],[0]
We confirmed that increasing the capacity of the encoder reduces the amortization error.,6. Conclusion,[1.0],['We confirmed that increasing the capacity of the encoder reduces the amortization error.']
"Additionally, we demonstrated that optimization techniques, such as entropy annealing, help the generative model to better utilize the flexibility of expressive variational distributions.",6. Conclusion,[1.0],"['Additionally, we demonstrated that optimization techniques, such as entropy annealing, help the generative model to better utilize the flexibility of expressive variational distributions.']"
Analyzing these gaps can be useful for guiding improvements in VAEs.,6. Conclusion,[1.0],['Analyzing these gaps can be useful for guiding improvements in VAEs.']
"Future work includes evaluating other types of expressive approximations, more complex likelihood functions, and datasets.",6. Conclusion,[1.0],"['Future work includes evaluating other types of expressive approximations, more complex likelihood functions, and datasets.']"
Amortized inference allows latent-variable models trained via variational learning to scale to large datasets.,abstractText,[0],[0]
The quality of approximate inference is determined by two factors: a) the capacity of the variational distribution to match the true posterior and b) the ability of the recognition network to produce good variational parameters for each datapoint.,abstractText,[0],[0]
We examine approximate inference in variational autoencoders in terms of these factors.,abstractText,[0],[0]
"We find that divergence from the true posterior is often due to imperfect recognition networks, rather than the limited complexity of the approximating distribution.",abstractText,[0],[0]
We show that this is due partly to the generator learning to accommodate the choice of approximation.,abstractText,[0],[0]
"Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.",abstractText,[0],[0]
Inference Suboptimality in Variational Autoencoders,title,[0],[0]

0,1,label2,summary_sentences
Neural networks trained through stochastic gradient descent (SGD) can memorize their training data.,1. Introduction,[0],[0]
"Although practitioners have long been aware of this phenomenon, Zhang et al. (2017) recently brought attention to it by showing that standard SGD-based training on AlexNet gets close to zero training error on a modification of the ImageNet dataset even when the labels are randomly permuted.",1. Introduction,[0],[0]
"This leads to an interesting question: If neural nets have sufficient capacity to memorize random training sets why do
1Two Sigma, New York, NY, USA.",1. Introduction,[0],[0]
"Correspondence to: Satrajit Chatterjee <satrajit.chatterjee@twosigma.com>.
",1. Introduction,[0],[0]
"Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018.",1. Introduction,[0],[0]
"Copyright 2018 by the author(s).
",1. Introduction,[0],[0]
they generalize on real data?,1. Introduction,[0],[0]
A natural hypothesis is that nets behave differently on real data than on random data.,1. Introduction,[0],[0]
Arpit et al. (2017) study this question experimentally and show that there are apparent differences in behavior.,1. Introduction,[0],[0]
"They conclude that generalization and memorization depend not just on the network architecture and optimization procedure but on the dataset itself.
",1. Introduction,[0],[0]
"But what if networks fundamentally do not behave differently on real data than on random data, and, in both cases, are simply memorizing?",1. Introduction,[0],[0]
This is a difficult question to explore for two reasons.,1. Introduction,[0],[0]
"First, it is hard to provide a direct answer.",1. Introduction,[0],[0]
Whereas it is easy to tell when a net is memorizing random data (the training error goes to zero!),1. Introduction,[0],[0]
", there is no easy way to tell when a network is memorizing real data as opposed to “learning”.",1. Introduction,[0],[0]
"Second, and perhaps more importantly, it contradicts the intuitive notion—inherent in the preceding discussion—that memorization and generalization are at odds.",1. Introduction,[0],[0]
This work attempts to shed light on this second difficulty by investigating the following: How much can you learn if memorization is all you can do?,1. Introduction,[0],[0]
"Is generalization even possible in this setting?
",1. Introduction,[0],[0]
"At first, generalization in such a setting of pure memorization may seem hopeless: the simplest way to memorize would be to build a lookup table from the training data.",1. Introduction,[0.9504211665608168],"['In this section, we propose a mechanism to reduce the large number of entities/relationships over which attention has to be generated in the knowledge graph.']"
"Although this approach works for special cases where the input population is finite and small, it fails in general since the examples seen during training are unlikely to match test examples.",1. Introduction,[0.9514853271595735],"['Further, it is not possible for a model to learn all such correlations from just the labeled training data available for the task.']"
One way to get around this limitation is to use k-Nearest Neighbors (k-NN) or any of its variants at test time.,1. Introduction,[0],[0]
"While k-NNs work well on many problems, they fail on problems where it is not easy to construct a semantically meaningful distance function on the input space.",1. Introduction,[0],[0]
"In such cases, the obvious syntactic distance functions (e.g., say Euclidean distance between images viewed as vectors in Rd) do not work well.",1. Introduction,[0],[0]
"Indeed some of the most interesting results from deep learning have been the discovery—through learning—of semantically meaningful distance functions (via embeddings).
",1. Introduction,[0],[0]
"Therefore, in this work we do not allow ourselves a distance function.",1. Introduction,[0],[0]
"Instead, we get around the problem by applying the notion of depth, which has been wildly successful in improving the performance of neural networks, to direct memorization.",1. Introduction,[0],[0]
"We build a network of lookup tables (also
called “luts”) where the luts are arranged in successive layers much like a neural network.",1. Introduction,[0],[0]
"However, unlike a neural network, training happens through memorization and does not involve backpropagation, gradient descent, or any explicit search.",1. Introduction,[0],[0]
"Now, since in contrast to a neuron, the function implemented by a lut can be arbitrarily complex, without some means to control the complexity, the notion of depth is vacuous.",1. Introduction,[0.956874846927794],"['This result is very promising, to reduce the large labeled training data requirement of large deep learning models, which is hard to come by.']"
We control the complexity of a function learned by a lut in the simplest possible way: we limit the support (and thereby the size) of the lut.,1. Introduction,[0],[0]
"Each lut in a layer receives inputs from only a few luts in the previous layer, which are picked at random when the network is constructed.",1. Introduction,[0],[0]
This kind of restriction on local function complexity is similar to what is found to work well in deep neural networks.,1. Introduction,[0],[0]
"For example, a convolutional filter is obviously support-limited, and a fully connected layer although not support-limited is nevertheless limited in expressivity.",1. Introduction,[0],[0]
"Furthermore, the learned weight matrices in neural networks are often sparse or can be made so with no loss in accuracy (Han et al., 2015).
",1. Introduction,[0],[0]
We need two restrictions before we can proceed to an algorithm.,1. Introduction,[0],[0]
"First, for simplicity, we focus our attention on binary classification problems.",1. Introduction,[0],[0]
"Second, because lookup tables work naturally with discrete inputs, in this work we limit ourselves to discrete signals.",1. Introduction,[0],[0]
"In fact, the inputs and all intermediate signals in the network of lookup tables are binary.",1. Introduction,[0],[0]
The restriction is not as extreme as it may appear.,1. Introduction,[0],[0]
"There are a number of results in quantized and binary neural networks showing that limited precision is often sufficient (e.g. Rastegari et al., 2016).",1. Introduction,[0],[0]
"Furthermore, even in real-valued neural networks, we need mechanisms such as convolution and pooling to ensure that certain types of small changes in the inputs (e.g., a small displacement) do not lead to large changes in output.",1. Introduction,[0],[0]
"In principle, similar mechanisms could be used in a fully discrete setting to handle real-valued quantities.
",1. Introduction,[0],[0]
"With these restrictions in place, we are now ready to proceed.",1. Introduction,[0],[0]
"Let B = {0, 1} and consider the problem of learning a function f :",2. A Single Lookup Table,[0],[0]
"Bk → B from a list of training examples where each example is an (x, y) pair.",2. A Single Lookup Table,[0],[0]
"Since we want to learn by memorizing, we construct a lookup table with 2k rows (one for each possible bit pattern p ∈",2. A Single Lookup Table,[0],[0]
Bk that can appear at the input) and two columns y0 and y1.,2. A Single Lookup Table,[0],[0]
"The y0 entry for the row corresponding to pattern p (denoted by cp0) counts how many times p is associated with output 0 in the training set, i.e., the number of occurrences of (p, 0) in the training set.",2. A Single Lookup Table,[0],[0]
"Similarly, the y1 entry for row p (denoted by cp1) counts how many times the pattern p is associated with the output 1 in the training set, i.e., the number of occurrences of (p, 1)
in the training set.",2. A Single Lookup Table,[0],[0]
"Note that for a pattern p it is possible for both cp0 and cp1 to be greater than zero since due to Bayes error both (p, 0) and (p, 1) may be present in the training examples.",2. A Single Lookup Table,[0],[0]
It is also possible for both cp0 and cp1 to be zero if the input p never appears in the training examples.,2. A Single Lookup Table,[0],[0]
"We call such a lookup table a k-input lookup table or a k-lut since the inputs are bit vectors of length k.1
Next, we associate a boolean function f̂ : Bk → B with the lookup table in the following manner:
f̂(p) =  1 if cp1 > cp0,0 if cp1 < cp0, b if cp1 = cp0
where b ∈ B is picked uniformly at random when fixing f̂ in order to break ties.",2. A Single Lookup Table,[0],[0]
"In other words, f̂ maps an input p to the output that is most often associated with it in the training set (breaking ties randomly).",2. A Single Lookup Table,[0],[0]
"We say that f̂ is the function learned by the lookup table.
",2. A Single Lookup Table,[0],[0]
Example 1.,2. A Single Lookup Table,[0],[0]
Let k = 3 and consider learning a function f : B3 → B from 7 examples shown on the left below.,2. A Single Lookup Table,[0],[0]
"The lookup table that we learn is shown in the middle, and the truth table of the learned function f̂ is shown on the right.",2. A Single Lookup Table,[0],[0]
"The entries in the truth table which have been picked randomly to break ties are indicated by an asterisk.
",2. A Single Lookup Table,[0],[0]
"x x0x1x2
y
000 0 000 1 000 1 001 1 100 0 110 0 110 1
p x0x1x2
y0 y1
000 1 2 001 0 1 010 0 0 011 0 0 100 1 0 101 0 0 110 1 1 111 0 0
p f̂
000 1 001 1 010 0∗ 011 1∗ 100 0 101 1∗ 110 1∗ 111 0∗
Note that f̂ gets all training examples correct except for the first and sixth.",2. A Single Lookup Table,[0],[0]
"This is the best we can do on this set of training examples because the Bayes error rate is non-zero.
",2. A Single Lookup Table,[0],[0]
"If we measure training error as the average 0–1 loss on the training set, this procedure to learn f̂ has the following properties:
1.",2. A Single Lookup Table,[0],[0]
Optimality.,2. A Single Lookup Table,[0],[0]
"The learned function f̂ is Bayes-optimal on the training set, i.e., there is no function g :",2. A Single Lookup Table,[0],[0]
Bk → B with training error strictly less than that of f̂ .,2. A Single Lookup Table,[0],[0]
"In particular, the training error is zero iff the training set has zero Bayes error.
2.",2. A Single Lookup Table,[0],[0]
Monotonicity.,2. A Single Lookup Table,[0],[0]
"If we have more information for each x in the training set, i.e., we augment each training
1 Typically k is small (less than 10) and so the the table can be stored explicitly.",2. A Single Lookup Table,[0],[0]
"The input bit vector (viewed as an integer) can be used to directly index into the table.
example with m extra bits of information (keeping the labels fixed) and use the above procedure to now learn a new function ĝ : Bk+m → B, then the training error of ĝ is no more than that of f̂ .
",2. A Single Lookup Table,[0],[0]
Proof Sketch.,2. A Single Lookup Table,[0],[0]
Optimality is easy to see since the total training error is the sum of the training error for each possible pattern p which is minimized by choosing the majority class for each p.,2. A Single Lookup Table,[0],[0]
"Monotonicity holds since if not, then we can compose the obvious projection Bk+m",2. A Single Lookup Table,[0],[0]
"→ Bk with f̂ to get a contradiction with the optimality of ĝ.
Note that monotonicity implies in particular that the training accuracy at the output of a lut is no worse than that at any of its inputs.",2. A Single Lookup Table,[0],[0]
"Furthermore, as we make the luts larger, the training error cannot increase but only decrease.",2. A Single Lookup Table,[0],[0]
This is interesting since there are no restrictions on the m extra bits: they could be completely non-informative.,2. A Single Lookup Table,[0],[0]
"These properties will prove useful in the next section as we consider networks of luts.
",2. A Single Lookup Table,[0],[0]
"To summarize, the procedure described to learn a single lookup table in this section is essentially memorization in the presence of Bayes error, where the idea is to simply remember the output that is most commonly associated with an input in the training set.",2. A Single Lookup Table,[0],[0]
"Now consider a binary classification task on MNIST (LeCun & Cortes, 2010) of separating the digits ‘0’ through ‘4’ (we map these to the 0 class) from the digits ‘5’ through ‘9’ (the 1 class) where the pixels are 1-bit quantized.",3. A Network of Lookup Tables,[0],[0]
"Thus the task is to learn a function f : B28×28 → B. We call this the Binary-MNIST task (overloading binary here to mean both binary classification and binary inputs).
",3. A Network of Lookup Tables,[0],[0]
"In principle, we could use the procedure in Section 2 to learn this function.",3. A Network of Lookup Tables,[0],[0]
"However, since we have only 60,000 training examples in MNIST, most of the 228×28 rows in the lookup table would have 0 entries in both columns, and hence the function learned would be mostly random and have very poor generalization to inputs outside the training set.
",3. A Network of Lookup Tables,[0],[0]
"As discussed in the introduction, we get around this problem by introducing depth.",3. A Network of Lookup Tables,[0],[0]
"Instead of learning a giant lookup table with 228×28 entries, we learn a network of (much) smaller lookup tables.",3. A Network of Lookup Tables,[0],[0]
The network consists of d layers with each layer l (1 ≤ l ≤ d) having nl k-input lookup tables.,3. A Network of Lookup Tables,[0],[0]
Each lut in first layer (l = 1) receives its inputs from a krandom subset of the network inputs.,3. A Network of Lookup Tables,[0],[0]
A lut in a layer,3. A Network of Lookup Tables,[0],[0]
l > 1 receives inputs from a k-random subset of the luts in layer l − 1.,3. A Network of Lookup Tables,[0],[0]
The connectivity is fixed at network creation time and does not change during training or inference.,3. A Network of Lookup Tables,[0],[0]
"The final layer of the network has a single lookup table (i.e., nd = 1) which is the output of the network.",3. A Network of Lookup Tables,[0],[0]
"By analogy with neural
networks, we call the final layer the output layer and the other layers hidden layers.
",3. A Network of Lookup Tables,[0],[0]
"We train the lookup tables layer by layer, where the target of each lookup table is the final output.",3. A Network of Lookup Tables,[0],[0]
We start from the first layer and work our way to the output.,3. A Network of Lookup Tables,[0],[0]
"Once a layer has been learned, we use the functions associated with its luts (the f̂s of Section 2) to map its inputs to outputs.",3. A Network of Lookup Tables,[0],[0]
"These outputs serve as the inputs for the next layer, which is learned next.",3. A Network of Lookup Tables,[0],[0]
"Continuing our analogy with neural networks, we call the output values of a layer activations.
",3. A Network of Lookup Tables,[0],[0]
"Inference is similar to training: We start from the inputs and evaluate each layer in order using the functions learned at each lut to map inputs to outputs.
",3. A Network of Lookup Tables,[0],[0]
Example 2.,3. A Network of Lookup Tables,[0],[0]
We modify Example 1.,3. A Network of Lookup Tables,[0],[0]
"Instead of learning a single lut with k = 3 inputs, we learn a network of k = 2 luts.",3. A Network of Lookup Tables,[0],[0]
The network shown in Figure 1 has d = 2 layers.,3. A Network of Lookup Tables,[0],[0]
"The first layer has 2 luts (i.e., n1 = 2) which are connected to inputs x0 and x1 of the network.",3. A Network of Lookup Tables,[0],[0]
"The second layer (which is also the output layer) has 1 lut (i.e., n2 = 1) which is connected to the outputs of the two luts in the first layer.",3. A Network of Lookup Tables,[0],[0]
(The connections were made randomly when the network was created.),3. A Network of Lookup Tables,[0],[0]
"Using the procedure in Section 2, the two lookup tables learned in the first layer (using y as the target) along with their corresponding functions f̂10 and f̂11 are:
p x0x1
y0 y1 f̂10
00 1 3 1 01 0 0 1∗ 10 1 0 0 11 1 1 1∗
p x0x2
y0 y1 f̂11
00 1 2 1 01 0 1 1 10 2 1 0 11 0 0 1∗
Let the output of the luts in the first layer be w10 and w11, i.e., w10 = f̂10(x0x1) and w11 = f̂11(x0x2).",3. A Network of Lookup Tables,[0],[0]
The learning problem for the lut in the second layer is shown in the tables below.,3. A Network of Lookup Tables,[0],[0]
"For convenience, on the left we show the primary inputs x0, x1 and x2, the first layer activations w10 and w11 (which are the inputs of the lut), and the target output y.",3. A Network of Lookup Tables,[0],[0]
"On the right we show the table and the learned function f̂20:
x x0x1x2
w10w11 y
000 11 0 000 11 1 000 11 1 001 11 1 100 00 0 110 10 0 110 10 1
p w10w11
y0 y1 f̂20
00 1 0 0 01 0 0 1∗ 10 1 1 0∗ 11 1 3 1
In this case the function implemented by the network of 2-luts has the same performance on the training set as the function learned by the 3-lut in Example 1.",3. A Network of Lookup Tables,[0],[0]
"Since there are fewer possible patterns in the case of smaller luts, we expect better pattern coverage during training and hence better generalization.
",3. A Network of Lookup Tables,[0],[0]
Implementation.,3. A Network of Lookup Tables,[0],[0]
"The memorization procedure described here is linear in the size of the training data, requiring two passes over the training set.",3. A Network of Lookup Tables,[0],[0]
It is computationally efficient since it only involves counting and dense table lookups and does not require floating point.,3. A Network of Lookup Tables,[0],[0]
"It is also easy to parallelize since each lut in a given layer is independent, and the counts can be computed on disjoint subsets of the training data and then combined (using, for example, a reduction tree).",3. A Network of Lookup Tables,[0],[0]
Note that using this property it is possible to execute the algorithm on extremely large datasets where all the training examples may not fit on a single machine with only the summary statistics of the data (the counts in the lookup tables) being exchanged across machines.,3. A Network of Lookup Tables,[0],[0]
Experiment 1.,4. Experiments,[0],[0]
"In the first experiment, we apply the above procedure to the Binary-MNIST task (as defined in Section 3) to see if this approach to memorization can generalize.",4. Experiments,[0],[0]
"For this experiment, we construct a network with 5 hidden layers of 1024 luts and 1 lut in the output layer.",4. Experiments,[0],[0]
"We set k = 8, i.e., each lut in the network takes 8 inputs.
",4. Experiments,[0],[0]
"The network achieves a training accuracy of 0.89 on this task, which is perhaps not so surprising since we are memorizing the training data after all.",4. Experiments,[0],[0]
"But what is surprising is that the network achieves an accuracy of 0.87 on a heldout set (the 10,000 test images in MNIST) which indicates generalization.
",4. Experiments,[0],[0]
"This result is not state-of-the-art on this variant of MNIST (see Experiment 4), but that is not the point.",4. Experiments,[0],[0]
"It is significantly above the 0.5 accuracy that would be expected by chance, and this is achieved by an algorithm that only memorizes and performs no explicit search.
",4. Experiments,[0],[0]
The training and test accuracies are stable: there is very little variation from run to run.,4. Experiments,[0],[0]
"In other words, very little depends on the actual random choices made when deciding the topology of the network.",4. Experiments,[0],[0]
"To understand why this is
the case, we look at training accuracies of the luts in the network.",4. Experiments,[0],[0]
"Since the target for each lut in the network is the final classification target, we can examine the accuracy of a lut as a function of its layer.
",4. Experiments,[0],[0]
Table 1 shows the summary statistics for the accuracies of luts in each layer.,4. Experiments,[0],[0]
We observe that as depth increases the average accuracy of the luts in a layer goes up.,4. Experiments,[0],[0]
"In other words, depth helps.",4. Experiments,[0],[0]
"Some intuition for this is provided by the monotonicity property of the luts: the output of a lut cannot have lower accuracy than any of its inputs (Section 2).
",4. Experiments,[0],[0]
"Furthermore, we observe in Table 1 the dispersion in accuracy across the luts (measured either by standard deviation (std) or the difference between max and min) goes down.",4. Experiments,[0],[0]
"Therefore, as depth increases the specifics of the connectivity matters less and the network automatically becomes more stable with respect to the random choices made during construction.",4. Experiments,[0.9568116479671417],"['While training the classification and retrieval module together, the model tends to ignore the KG part and gradient propagates only through the classification module.']"
"Indeed we can say something stronger: we have seen in our experiments (not shown in Table 1) that as depth increases the activations of the luts in a layer become more correlated with each other, and hence become more interchangeable.",4. Experiments,[0],[0]
"While this correlation is good for stability with respect to connectivity, it causes diminishing returns with additional depth.
",4. Experiments,[0],[0]
Remark.,4. Experiments,[0],[0]
The perceptive reader looking at Table 1 will also notice that we are wasting computation: the single output lut in layer 6 receives input from only 8 of the 1024 luts in layer 5 and these in turn can at most receive inputs from 64 luts from layer 4.,4. Experiments,[0],[0]
"Although a different topology would be more computationally efficient, this specific choice allows us to compare the different layers more easily.",4. Experiments,[0],[0]
"We have not optimized this aspect since it typically takes less than 30 seconds using a single threaded unoptimized implementation (Python with NumPy) to run an experiment.
",4. Experiments,[0],[0]
Experiment 2.,4. Experiments,[0],[0]
"As discussed in the introduction and in Section 3, we do not expect unbridled memorization in the form of a large lookup table (say k = 28 × 28 in the case of Binary-MNIST) to generalize at all.",4. Experiments,[0],[0]
"This motivated our
exploration of a network of smaller lookup tables parameterized by k (the number of inputs of each lut).",4. Experiments,[0],[0]
We now vary k to see if we can control the amount of memorization and to see the effect it has on generalization.,4. Experiments,[0],[0]
"To avoid changing too much at once, we keep the number of layers and the number of luts per layer the same as in Experiment 1.
",4. Experiments,[0],[0]
The results are shown in the first 3 columns of Table 2.,4. Experiments,[0],[0]
"With small values of k, the network finds it difficult to memorize the training data.",4. Experiments,[0],[0]
"As intuitively expected (see also the monotonicity property in Section 2), as k increases the training accuracy goes up with perfect memorization at k = 14, i.e., long before 28×28.",4. Experiments,[0],[0]
"However, larger luts generalize less well, and the best test accuracy of 0.90 is achieved at k = 12 though with substantially good memorization of the training data (0.99).",4. Experiments,[0],[0]
"Interestingly, there is a clear monotonic increase in the generalization gap measured as the difference between training and test accuracy with increasing k.
Experiment 3.",4. Experiments,[0],[0]
In this experiment—along the lines of those performed in Zhang et al. (2017)—we randomly permute the labels in the training set and repeat Experiment 2 on this “random” dataset.,4. Experiments,[0],[0]
The results are shown in columns 4 and 5 of Table 2.,4. Experiments,[0],[0]
"As expected, with increasing k the network gets better at memorizing the training data, and the test accuracy hovers around chance (0.5) though with significant variation (± 0.05).",4. Experiments,[0],[0]
"This may be viewed as empirical evidence that the Rademacher complexity goes up with k.
However, and this may be surprising for a pure memorization algorithm, memorizing random data turns out to be harder than memorizing real data (columns 2 and 3 of Table 2) in the sense that a larger k is required to get the same accuracy with random data than with real data.",4. Experiments,[0],[0]
"For example, it takes until k = 12 to get comparable training accuracy on random data as k = 4 gets on real data.",4. Experiments,[0],[0]
"This result corroborates the findings in Arpit et al. (2017, §3 and §4) that real data is easier to fit than random data.",4. Experiments,[0],[0]
But it also means that we cannot conclude that any such difference observed in neural networks is because they do not use brute force memorization on real data.,4. Experiments,[0],[0]
"As this experiment shows, such
differences can appear even with brute force memorization.
",4. Experiments,[0],[0]
"Finally, at k = 12 we have a network that is able to memorize random data (random training accuracy of 0.82) and yet generalizes to test data when trained on real data (real test accuracy of 0.90).",4. Experiments,[0],[0]
This is very similar to findings of Zhang et al. (2017) in the context of neural networks.,4. Experiments,[0.9501886913019965],"['DKRL (Xie et al., 2016) is a KG representation technique which also takes into account the descriptive nature of text keeping the simple structure of TransE model.']"
"Kawaguchi et al. (2017, §3) argue that this phenomenon is universal and our result may be viewed as further empirical evidence for their claim showing that this phenomenon can happen even in the simplified setting of just memorization.
",4. Experiments,[0],[0]
Experiment 4.,4. Experiments,[0],[0]
"For completeness, we compare memorization with several standard methods and the results are shown in Table 3.",4. Experiments,[0],[0]
We have not specifically tuned the other methods since our goal is not to beat the state-of-the-art but to get a sense of how memorization alone does when compared to the standard methods.,4. Experiments,[0],[0]
"The best performance is obtained by a LENET-style convolutional network with 2 convolutions (64 and 32 filters respectively) each followed by a corresponding max pool layer, and 3 fully connected layers (256, 128 and 2 units respectively) with softmax output.",4. Experiments,[0],[0]
"The net is trained for 6 epochs with stochastic gradient descent and dropout.
",4. Experiments,[0],[0]
"Once again, compared to random guessing which has 0.50 test accuracy, memorization does quite well with a test accuracy of 0.90 (using the k = 12 configuration from Experiment 2) and beats logistic regression and naı̈ve Bayes.",4. Experiments,[0],[0]
"Interestingly, 1- and 5-Nearest Neighbors do well too (test accuracy of 0.97) though recall that they are provided with a distance function which memorization does not have access to and must in a sense discover.
",4. Experiments,[0],[0]
Experiment 5.,4. Experiments,[0],[0]
"We now consider the task of separating the i-th digit in MNIST from the j-th digit, which gives us( 10 2 ) = 45 binary classification tasks, which we collectively call Pairwise-MNIST.",4. Experiments,[0],[0]
"The images are binarized as before.
",4. Experiments,[0],[0]
"Figure 2 shows the training accuracy and the test accuracy for each of those 45 experiments for 8 different values of k.
As in Experiment 2, we find that as k increases, the training accuracy increases (reaching 1.0), but the test accuracy falls off.",4. Experiments,[0],[0]
"If we look at the best test accuracies for a given task (across k), on 31 out of the 45 tasks, we do better than 0.98.",4. Experiments,[0],[0]
The worst of these is 0.95 which is the best memorization can do for separating ‘4’ and ‘9’.,4. Experiments,[0],[0]
This is still significantly better than the 0.5 we would expect by chance.,4. Experiments,[0],[0]
"Typically the best test accuracies are achieved at k = 6 and k = 8.
",4. Experiments,[0],[0]
Experiment 6.,4. Experiments,[0],[0]
In Experiment 5 we notice that the variation is quite high for k = 2.,4. Experiments,[0],[0]
This indicates that the depth of the network is insufficient for proper mixing.,4. Experiments,[0],[0]
"To investigate this further, we keep k = 2 and vary the number of hidden layers from 20 to 25.",4. Experiments,[0],[0]
Each hidden layer still has 1024 luts.,4. Experiments,[0],[0]
Figure 3 shows how the training and test accuracies vary with the depth of the network.,4. Experiments,[0],[0]
"It is interesting to note that the test accuracy continues to improve even for relatively deep networks (16 or 32 hidden layers), and we get very high test accuracies even with such small lookup tables.",4. Experiments,[0],[0]
"Furthermore, we note that the variation in the generalization error (difference between training and test accuracies) decreases with increasing depth.
",4. Experiments,[0],[0]
Experiment 7.,4. Experiments,[0],[0]
Next we look at memorization on CIFAR-10 which is a collection of 32 pixel by 32 pixel color images belonging to 10 classes.,4. Experiments,[0],[0]
"As with Binary-MNIST, we quantize each color channel to 1 bit and try to separate the classes 0 through 4 from classes 5 through 9.",4. Experiments,[0],[0]
"This gives us the Binary-CIFAR-10 task where we have to learn a function f : B3×32×32 → B from 50,000 images.",4. Experiments,[0],[0]
"Incidentally, the quantization of each color channel to 1-bit significantly degrades the signal making it a difficult task for humans.
",4. Experiments,[0],[0]
"For this task, we construct a network with 5 hidden layers each with 1024 luts and one output layer with 1 output.",4. Experiments,[0],[0]
We set k = 10 for the luts.,4. Experiments,[0],[0]
This network is able to achieve a training accuracy of 0.79 and a test accuracy of 0.63.,4. Experiments,[0],[0]
"Although not as impressive in absolute terms as the memoriza-
tion result on Binary-MNIST, it is still significantly above chance (0.50).",4. Experiments,[0],[0]
"Furthermore, as before, the result is very stable and does not depend on a specific random topology chosen when the network is constructed.
",4. Experiments,[0],[0]
We compare memorization with several standard methods in Table 4.,4. Experiments,[0],[0]
By comparing Table 4 with Table 3 it is clear that Binary-CIFAR-10 is a harder task than Binary-MNIST since all the methods perform significantly worse on it.,4. Experiments,[0],[0]
"The best test accuracy of 0.71 is again from a LENET-style network similar to the one used in Experiment 4, but with 40 epochs of training.",4. Experiments,[0],[0]
"We believe a ResNet-style architecture (He et al., 2016) may potentially do better here but since our goal is not to achieve state-of-the-art but see how memorization does, we leave this to future work.",4. Experiments,[0],[0]
"For the same reason we don’t explore data augmentation here which is a standard technique for CIFAR-10.
Once again, memorization compares favorably on test accuracy with the other methods, and compared to Binary-MNIST it does relatively better here since it ties with the nearest neighbor searches.
",4. Experiments,[0],[0]
Experiment 8.,4. Experiments,[0],[0]
"In this experiment, we consider the Pairwise-CIFAR-10 tasks which are defined analogously to Pairwise-MNIST.",4. Experiments,[0],[0]
We use the same network architecture as in Experiment 7 instead of optimizing specifically for these tasks.,4. Experiments,[0],[0]
Training accuracies are generally 0.95 and above whereas the test accuracies range from 0.61 (CAT v/s DOG) to 0.85,4. Experiments,[0],[0]
"(FROG v/s SHIP) with an average test accuracy of 0.76 which is significantly above chance.
",4. Experiments,[0],[0]
Experiment 9.,4. Experiments,[0],[0]
"To get qualitative insight into the decision boundaries learned with different levels of memorization, we classify points in the region [−2, 2] ×",4. Experiments,[0],[0]
"[−2, 2] ∈ R2 as being inside or outside the circle",4. Experiments,[0],[0]
x2,4. Experiments,[0],[0]
+,4. Experiments,[0],[0]
y2 ≤ 1.62.,4. Experiments,[0],[0]
"Our dataset consists of points on a 100 × 100 grid in this region which has been partitioned into equal test and training sets (Figure 4, leftmost column).",4. Experiments,[0],[0]
To make this a hard problem we encode each point as pair of 10-bit fixed-point numbers.,4. Experiments,[0],[0]
"We learn this function f : B20 → B using networks with 32 layers each with 2048 luts and vary k. With k = 10 (rightmost column), the training set is memorized perfectly but (as seen on test)",4. Experiments,[0],[0]
the concept is not learned.,4. Experiments,[0],[0]
"However, memorizing with k = 2, we learn a simpler concept that is not faithful around the “corners” (as can be seen by zooming in) but one that generalizes almost perfectly to test.",4. Experiments,[0],[0]
"Finally, k = 6 provides a satisfactory compromise between the two extremes.",4. Experiments,[0],[0]
"Thus, once again, we see that memorization if done carefully can lead to good generalization.",4. Experiments,[0],[0]
"It is instructive to compare our memorization procedure with a few commonly used procedures for learning.
",5. Comparison with Other Methods,[0],[0]
k-Nearest Neighbors.,5. Comparison with Other Methods,[0],[0]
"The key difference, as noted in the introduction, is that k-NNs require a user-specified distance function which is often syntactic notion of distance such that induced by treating an image as a vector in Rd.",5. Comparison with Other Methods,[0],[0]
These syntactic notions of distance do not work well on more challenging tasks and one may view such a learning problem as essentially that of discovering a semantically meaningful distance function.,5. Comparison with Other Methods,[0],[0]
"We see this in our experiments: the
tr ai
ni ng
−2.0 −1.5",5. Comparison with Other Methods,[0],[0]
−1.0,5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
te st
−2.0 −1.5",5. Comparison with Other Methods,[0],[0]
−1.0,5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
"−0.5 0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2.0 −1.5 −1.0",5. Comparison with Other Methods,[0],[0]
−0.5,5. Comparison with Other Methods,[0],[0]
"0.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
ground truth k = 2 k = 6 k = 10
Figure 4.",5. Comparison with Other Methods,[0],[0]
"The decision boundaries learned in Experiment 9.
distance function helps more with Binary-MNIST (Experiment 4) than it does with Binary-CIFAR-10 (Experiment 7).",5. Comparison with Other Methods,[0],[0]
"Furthermore, in a separate experiment we found that augmenting the table lookup with 1-NN search at test time did not significantly improve test accuracy for Binary-CIFAR-10 where memorization was already tied with k-NNs.
Additionally, k-NN requires storing the entire training set and is typically computationally more expensive at test time.",5. Comparison with Other Methods,[0],[0]
"For example, on Binary-MNIST the standard k-NN implementation in scikit-learn (Pedregosa et al., 2011) took more than an hour to evaluate performance on the training and test sets (as opposed to seconds with memorization).",5. Comparison with Other Methods,[0],[0]
"There has been work on speeding up nearest neighbor search by using locality sensitive hashing (Indyk & Motwani, 1998) and, more recently, with random projections (Li & Malik, 2016).",5. Comparison with Other Methods,[0],[0]
"In that context, one may view each lookup table as implementing a trivial locality sensitive hash function where the distance metric arises from exact equality, and the network as an ensemble through cascading of such nearest neighbors classifiers.
",5. Comparison with Other Methods,[0],[0]
Neural Networks.,5. Comparison with Other Methods,[0],[0]
"The initial motivation for this work was to understand neural networks better; particularly to explore with a model the idea that perhaps SGD is a sophisticated way to memorize training data in a manner that generalizes and that perhaps there are simpler ways to memorize data
as well that may yet generalize.",5. Comparison with Other Methods,[0.9526114803693997],"['Here, for a learning model to infer B from A, it should have access to the common knowledge that “The man and woman and The couple means the same” since this information may not be specific for a particular inference.']"
"However, a key difference is that gradient descent-based training can learn useful intermediate representations or targets for hidden layers.",5. Comparison with Other Methods,[0],[0]
"In this work we have side stepped that question, by simply setting the intermediate target to be the final output.",5. Comparison with Other Methods,[0],[0]
It is an interesting line of research to see if we can find a way to learn useful intermediate signals in this setting perhaps by purely combinatorial methods.,5. Comparison with Other Methods,[0],[0]
"Practically, that would give us a method to learn purely binary neural networks without using floating point at all, which is useful in resource constrained environments.
",5. Comparison with Other Methods,[0],[0]
Random Forests.,5. Comparison with Other Methods,[0],[0]
"Trees in a random forest are constructed over a subset of the data by iteratively evaluating different input variables to optimize purity after splitting on the variable (Breiman, 2001).",5. Comparison with Other Methods,[0],[0]
"In contrast, memorization uses the whole dataset and does not solve any optimization problem (which makes it more computationally efficient).",5. Comparison with Other Methods,[0],[0]
"Furthermore, random forests combine the tree predictions using voting whereas memorization uses cascading.
",5. Comparison with Other Methods,[0],[0]
Cascading and Stacked Generalization.,5. Comparison with Other Methods,[0],[0]
"A recent extension of random forests are Deep Forests (Zhi-Hua Zhou, 2017) where multiple random forests are constructed at each level and then cascaded using the idea of stacked generalization (Wolpert, 1992) which is a generalization of cross-validation.",5. Comparison with Other Methods,[0],[0]
"In contrast, layers of luts are far simpler, and memorization propagates outputs based on what has been memorized over the entire training data.",5. Comparison with Other Methods,[0],[0]
"Due to the manner in which we construct the lookup tables and the corresponding functions (using the counts of the patterns) it is not clear to us that stacked generalization will help.
",5. Comparison with Other Methods,[0],[0]
Spectral Methods.,5. Comparison with Other Methods,[0],[0]
"There is a rich literature on the theory of learning boolean functions (f : Bk → B in our notation) (Mansour, 1994) which looks at theoretical learning guarantees under assumptions on the input distribution (typically uniform) and on the spectrum of the function (e.g. f can be approximated by a sparse and low degree polynomial in the boolean fourier basis).",5. Comparison with Other Methods,[0],[0]
"Recently, Hazan et al. (2017) have used these techniques in hyperparameter optimization where they find them to be practically useful (the distributional assumption is not fatal for this application).",5. Comparison with Other Methods,[0],[0]
"This line of work does not deal with depth, but only linear combinations of the basis functions.",5. Comparison with Other Methods,[0],[0]
"However, there is similarity in having a low degree in the fourier basis and our notion of support-limited memorization.",5. Comparison with Other Methods,[0],[0]
"These are similar structural priors and our results and those of Hazan et al. may be viewed as evidence that real world functions satisfy these priors.
",5. Comparison with Other Methods,[0],[0]
Learning Boolean Circuits.,5. Comparison with Other Methods,[0],[0]
"There is relatively little prior work in directly learning boolean circuits (Oliveira & Sangiovanni-Vincentelli, 1994; Tapp, 2014).",5. Comparison with Other Methods,[0],[0]
"However, it is interesting to note that the memorization algorithm in Section 3 although developed independently and from different
considerations is similar to the greedy algorithm described by Tapp.2",5. Comparison with Other Methods,[0],[0]
"An important difference is that instead of learning a single tree, we learn a network which makes learning more stable (as seen in Experiment 1).",5. Comparison with Other Methods,[0],[0]
"The experiments of Zhang et al. (2017) and Arpit et al. (2017) on training with random data lead naturally to the question that if neural networks can memorize random data and yet generalize on real data, are they perhaps doing something different in the two cases.",6. Conclusion,[0],[0]
This work started with the opposite thought: What if in both cases they are simply memorizing?,6. Conclusion,[0],[0]
"This, in turn, leads to the question of whether it is even possible to generalize from pure memorization.",6. Conclusion,[0],[0]
Naı̈ve memorization with a lookup table is too simplistic a model,6. Conclusion,[0],[0]
"but, as we saw, a slightly more complex model in the form of a network of support-limited lookup tables does significantly better than chance and is closer to the standard algorithms on a number of binary classification problems from MNIST and CIFAR-10.",6. Conclusion,[0],[0]
"(To investigate if this result holds on other datasets is an important area of future work.)
",6. Conclusion,[0],[0]
"Furthermore, this model replicates some of the key observations with neural networks: the performance of a network improves with depth; it memorizes random data and yet generalizes on real data; and memorizing random data is harder than real data.",6. Conclusion,[0],[0]
"In particular, the last observation implies that we cannot rule out memorization based on differences in the hardness of learning between real and random data.
",6. Conclusion,[0],[0]
"For future work, we would like to understand why memorization generalizes.",6. Conclusion,[0],[0]
"Now, since the size of the hypothesis space is bounded by 2n2 k
(where n is the number of k-luts in the network), we can use results from PAC-learning to bound the generalization gap, but these bounds are typically weak or vacuous.3 Rademacher complexity may be useful for small k (say 2), but for moderate k—where the Rademacher complexity is high yet there is generalization— we would need a different approach, perhaps one based on stability (Bousquet & Elisseeff, 2002).",6. Conclusion,[0],[0]
"In this connection, we expect the results in Devroye & Wagner (1979) to apply to a single lut, but extensions are needed to handle networks of luts, i.e., depth.",6. Conclusion,[0],[0]
"Furthermore, these would have to incorporate details of the construction since not every network of luts generalizes (even for k = 2).
",6. Conclusion,[0],[0]
"Finally, given the computational efficiency of memorization, we would like to extend it to a practically useful algorithm for learning, but that would likely involve introducing some form of explicit optimization or search.
",6. Conclusion,[0],[0]
2We thank David Krueger for noticing the connection.,6. Conclusion,[0],[0]
3,6. Conclusion,[0],[0]
"For example, using Theorem 2.2 in Mohri et al. (2012) for the experiments in Table 2 (with δ = 0.01 for concreteness) bounds the gap to 0.34 for k = 2.",6. Conclusion,[0],[0]
The bound doubles as k increases by 2.,6. Conclusion,[0],[0]
"I thank Ben Rossi, Vinod Valsalam, Rhys Ulerich, and Eric Allen for many useful discussions and Larry Rudolph and Steve Heller for their feedback on the paper.",Acknowledgments,[0],[0]
"In the machine learning research community, it is generally believed that there is a tension between memorization and generalization.",abstractText,[0],[0]
"In this work, we examine to what extent this tension exists, by exploring if it is possible to generalize by memorizing alone.",abstractText,[0],[0]
"Although direct memorization with a lookup table obviously does not generalize, we find that introducing depth in the form of a network of support-limited lookup tables leads to generalization that is significantly above chance and closer to those obtained by standard learning algorithms on several tasks derived from MNIST and CIFAR-10.",abstractText,[0],[0]
"Furthermore, we demonstrate through a series of empirical results that our approach allows for a smooth tradeoff between memorization and generalization and exhibits some of the most salient characteristics of neural networks: depth improves performance; random data can be memorized and yet there is generalization on real data; and memorizing random data is harder in a certain sense than memorizing real data.",abstractText,[0],[0]
The extreme simplicity of the algorithm and potential connections with generalization theory point to several interesting directions for future research.,abstractText,[0],[0]
Learning and Memorization,title,[0],[0]
"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 332–344 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics
https://doi.org/10.18653/v1/P17-1031",text,[0],[0]
"There is a growing interest in automated processing of historical documents, as evidenced by the growing field of digital humanities and the increasing number of digitally available collections of historical documents.",1 Introduction,[0],[0]
"A common approach to deal with the high amount of variance often found in this type of data is to perform spelling normalization (Piotrowski, 2012), which is the mapping of historical spelling variants to standardized/modernized forms (e.g. vnd→ und ‘and’).
",1 Introduction,[0],[0]
"Training data for supervised learning of historical text normalization is typically scarce, making it a challenging task for neural architectures, which typically require large amounts of labeled data.",1 Introduction,[0],[0]
"Nevertheless, we explore framing the
spelling normalization task as a character-based sequence-to-sequence transduction problem, and use encoder–decoder recurrent neural networks (RNNs) to induce our transduction models.",1 Introduction,[0],[0]
"This is similar to models that have been proposed for neural machine translation (e.g., Cho et al. (2014)), so essentially, our approach could also be considered a specific case of character-based neural machine translation.
",1 Introduction,[0],[0]
"By basing our model on individual characters as input, we keep the vocabulary size small, which in turn reduces the model’s complexity and the amount of data required to train it effectively.",1 Introduction,[0],[0]
Using an encoder–decoder architecture removes the need for an explicit character alignment between historical and modern wordforms.,1 Introduction,[0],[0]
"Furthermore, we explore using an auxiliary task for which data is more readily available, namely grapheme-tophoneme mapping (word pronunciation), to regularize the induction of the normalization models.
",1 Introduction,[0],[0]
"We propose several architectures, including multi-task learning architectures taking advantage of the auxiliary data, and evaluate them across 44 small datasets from Early New High German.
",1 Introduction,[0],[0]
Contributions,1 Introduction,[0],[0]
"Our contributions are as follows:
• We are, to the best of our knowledge, the first to propose and evaluate encoder-decoder architectures for historical text normalization.
",1 Introduction,[0],[0]
"• We evaluate several such architectures across 44 datasets of Early New High German.
",1 Introduction,[0],[0]
"• We show that such architectures benefit from bidirectional encoding, beam search, and attention.
",1 Introduction,[0],[0]
"• We also show that MTL with pronunciation as an auxiliary task improves the performance of architectures without attention.
",1 Introduction,[0],[0]
"332
• We analyze the above architectures and show that the MTL architecture learns attention from the auxiliary task, making the attention mechanism largely redundant.
",1 Introduction,[0],[0]
"• We make our implementation publicly available at https://bitbucket.org/ mbollmann/acl2017.
",1 Introduction,[0],[0]
"In sum, we both push the state-of-the-art in historical text normalization and present an analysis that, we believe, brings us a step further in understanding the benefits of multi-task learning.",1 Introduction,[0],[0]
"Normalization For the normalization task, we use a total of 44 texts from the Anselm corpus (Dipper and Schultz-Balluff, 2013) of Early New High German.1",2 Datasets,[0],[0]
"The corpus is a collection of manuscripts and prints of the same core text, a religious treatise.",2 Datasets,[0],[0]
"Although the texts are semi-parallel and share some vocabulary, they were written in different time periods (between the 14th and 16th century) as well as different dialectal regions, and show quite diverse spelling characteristics.",2 Datasets,[0],[0]
"For example, the modern German word Frau ‘woman’ can be spelled as fraw/vraw (Me), frawe (N2), frauwe (St), fraüwe (B2), frow (Stu), vrowe (Ka), vorwe (Sa), or vrouwe (B), among others.2
All texts in the Anselm corpus are manually annotated with gold-standard normalizations following guidelines described in Krasselt et al. (2015).",2 Datasets,[0],[0]
"For our experiments, we excluded texts from the corpus that are shorter than 4,000 tokens, as well as a few for which annotations were not yet available at the time of writing (mostly Low German and Dutch versions).",2 Datasets,[0],[0]
"Nonetheless, the remaining 44 texts are still quite short for machine-learning standards, ranging from about 4,200 to 13,200 tokens, with an average length of 7,350 tokens.
",2 Datasets,[0],[0]
"For all texts, we removed tokens that consisted solely of punctuation characters.",2 Datasets,[0],[0]
"We also lowercase all characters, since it helps keep the size of the vocabulary low, and uppercasing of words is usually not very consistent in historical texts.",2 Datasets,[0],[0]
"Tokenization was not an issue for pre-processing these texts, since modern token boundaries have already been marked by the transcribers.
",2 Datasets,[0],[0]
"1https://www.linguistics.rub.de/ anselm/
2We refer to individual texts using the same internal IDs that are found in the Anselm corpus (cf.",2 Datasets,[0],[0]
"the website).
",2 Datasets,[0],[0]
Grapheme-to-phoneme mappings We use learning to pronounce as our auxiliary task.,2 Datasets,[0],[0]
This task consists of learning mappings from sequences of graphemes to the corresponding sequences of phonemes.,2 Datasets,[0],[0]
"We use the German part of the CELEX lexical database (Baayen et al., 1995), particularly the database of phonetic transcriptions of German wordforms.",2 Datasets,[0.9615861736800541],"['Variants of the TransE (Bordes et al., 2013) model uses translation of the entity vectors over relation specific subspaces.']"
"The database contains a total of 365,530 wordforms with transcriptions in DISC format, which assigns one character to each distinct phonological segment (including affricates and diphthongs).",2 Datasets,[0],[0]
"For example, the word Jungfrau ‘virgin’ is represented as ’jUN-frB.",2 Datasets,[0],[0]
"We propose several architectures that are extensions of a base neural network architecture, closely following the sequence-to-sequence model proposed by Sutskever et al. (2014).",3.1 Base model,[0],[0]
"It consists of the following:
• an embedding layer that maps one-hot input vectors to dense vectors;
• an encoder RNN that transforms the input sequence to an intermediate vector of fixed dimensionality;
• a decoder RNN whose hidden state is initialized with the intermediate vector, and which is fed the output prediction of one timestep as the input for the next one; and
• a final dense layer with a softmax activation which takes the decoder’s output and generates a probability distribution over the output classes at each timestep.
",3.1 Base model,[0],[0]
"For the encoder/decoder RNNs, we use long short-term memory units (LSTM) (Hochreiter and Schmidhuber, 1997).",3.1 Base model,[0],[0]
"LSTMs are designed to allow recurrent networks to better learn long-term dependencies, and have proven advantageous to standard RNNs on many tasks.",3.1 Base model,[0],[0]
"We found no significant advantage from stacking multiple LSTM layers for our task, so we use the simplest competitive model with only a single LSTM unit for both encoder and decoder.
",3.1 Base model,[0],[0]
"By using this encoder–decoder model, we avoid the need to generate explicit alignments between the input and output sequences, which would bring up the question of how to deal with input/output
pairs of different lengths.",3.1 Base model,[0],[0]
"Another important property is that the model does not start to generate any output until it has seen the full input sequence, which in theory allows it to learn from any part of the input, without being restricted to fixed context windows.",3.1 Base model,[0],[0]
An example illustration of the unrolled network is shown in Fig. 1.,3.1 Base model,[0],[0]
"During training, the encoder inputs are the historical wordforms, while the decoder inputs correspond to the correct modern target wordforms.",3.2 Training,[0],[0]
"We then train each model by minimizing the crossentropy loss across all output characters; i.e., if y = (y1, ..., yn) is the correct output word (as a list of one-hot vectors of output characters) and ŷ",3.2 Training,[0],[0]
"= (ŷ1, ..., ŷn) is the model’s output, we minimize the mean loss−∑ni=1 yi log ŷi over all training samples.",3.2 Training,[0],[0]
"For the optimization, we use the Adam algorithm (Kingma and Ba, 2015) with a learning rate of 0.003.
",3.2 Training,[0],[0]
"To reduce computational complexity, we also set a maximum word length of 14, and filter all training samples where either the input or output word is longer than 14 characters.",3.2 Training,[0],[0]
"This only affects 172 samples across the whole dataset, and is only done during training.",3.2 Training,[0],[0]
"In other words, we evaluate our models across all the test examples.",3.2 Training,[0],[0]
"For prediction, our base model generates output character sequences in a greedy fashion, selecting the character with the highest probability at each timestep.",3.3 Decoding,[0],[0]
"This works fairly well, but the greedy approach can yield suboptimal global picks, in which each individual character is sensibly derived from the input, but the overall word is non-
sensical.",3.3 Decoding,[0],[0]
"We therefore also experiment with beam search decoding, setting the beam size to 5.
",3.3 Decoding,[0],[0]
"Finally, we also experiment with using a lexical filter during the decoding step.",3.3 Decoding,[0],[0]
"Here, before picking the next 5 most likely characters during beam search, we remove all characters that would lead to a string not covered by the lexicon.",3.3 Decoding,[0],[0]
This is again intended to reduce the occurrence of nonsensical outputs.,3.3 Decoding,[0],[0]
"For the lexicon, we use all word forms from CELEX (cf. Sec. 2) plus the target word forms from the training set.3",3.3 Decoding,[0],[0]
"In our base architecture, we assume that we can decode from a single vector encoding of the input sequence.",3.4 Attention,[0],[0]
"This is a strong assumption, especially with long input sequences.",3.4 Attention,[0],[0]
Attention mechanisms give us more flexibility.,3.4 Attention,[0],[0]
"The idea is that instead of encoding the entire input sequence into a fixedlength vector, we allow the decoder to “attend” to different parts of the input character sequence at each time step of the output generation.",3.4 Attention,[0],[0]
"Importantly, we let the model learn what to attend to based on the input sequence and what it has produced so far.
",3.4 Attention,[0],[0]
Our implementation is identical to the decoder with soft attention described by Xu et al. (2015).,3.4 Attention,[0],[0]
"If a = (a1, ..., an) is the encoder’s output and ht is the decoder’s hidden state at timestep t, we first calculate a context vector ẑt as a weighted combination of the output vectors ai:
ẑt =
n∑
i=1
αiai (1)
3We observe that due to this filtering, we cannot reach 2.25% of the targets in our test set, most of which are Latin word forms.
",3.4 Attention,[0],[0]
"The weights αi are derived by feeding the encoder’s output and the decoder’s hidden state from the previous timestep into a multilayer perceptron, called the attention model (fatt):
α = softmax(fatt(a, ht−1))",3.4 Attention,[0],[0]
"(2)
We then modify the decoder by conditioning its internal states not only on the previous hidden state ht−1 and the previously predicted output character yt−1, but also on the context vector ẑt:
it = σ(Wi[ht−1, yt−1, ẑt]",3.4 Attention,[0],[0]
"+ bi)
ft = σ(Wf [ht−1, yt−1, ẑt]",3.4 Attention,[0],[0]
"+ bf )
ot = σ(Wo[ht−1, yt−1, ẑt]",3.4 Attention,[0],[0]
"+ bo)
gt = tanh(Wg[ht−1, yt−1, ẑt] + bg)
ct = ft ct−1",3.4 Attention,[0],[0]
"+ it gt ht = ot tanh(ct)
(3)
",3.4 Attention,[0],[0]
"In Eq. 3, we follow the traditional LSTM description consisting of input gate it, forget gate ft, output gate ot, cell state ct and hidden state ht, where W and b are trainable parameters.
",3.4 Attention,[0],[0]
"For all experiments including an attentional decoder, we use a bi-directional encoder, comprised of one LSTM layer that reads the input sequence normally and another LSTM layer that reads it backwards, and attend over the concatenated outputs of these two layers.
",3.4 Attention,[0],[0]
"While a precise alignment of input and output sequences is sometimes difficult, most of the time the sequences align in a sequential order, which can be exploited by an attentional component.",3.4 Attention,[0],[0]
"Finally, we introduce a variant of the base architecture, with or without beam search, that does multi-task learning (Caruana, 1993).",3.5 Multi-task learning,[0],[0]
"The multitask architecture only differs from the base architecture in having two classifier functions at the outer layer, one for each of our two tasks.",3.5 Multi-task learning,[0],[0]
Our auxiliary task is to predict a sequence of phonemes as the correct pronunciation of an input sequence of graphemes.,3.5 Multi-task learning,[0],[0]
"This choice is motivated by the relationship between phonology and orthography, in particular the observation that spelling variation often stems from phonological variation.
",3.5 Multi-task learning,[0],[0]
"We train our multi-task learning architecture by alternating between the two tasks, sampling one instance of the auxiliary task for each training sample of the main task.",3.5 Multi-task learning,[0],[0]
"We use the encoderdecoder to generate a corresponding output se-
quence, whether a modern word form or a pronunciation.",3.5 Multi-task learning,[0],[0]
"Doing so, we suffer a loss with respect to the true output sequence and update the model parameters.",3.5 Multi-task learning,[0],[0]
"The update for a sample from a specific task affects the parameters of corresponding classifier function, as well as all the parameters of the shared hidden layers.",3.5 Multi-task learning,[0],[0]
We used a single manuscript (B) for manually evaluating and setting the hyperparameters.,3.6 Hyperparameters,[0],[0]
This manuscript is left out of the averages reported below.,3.6 Hyperparameters,[0],[0]
"We believe that using a single manuscript for development, and using the same hyperparameters across all manuscripts, is more realistic, as we often do not have enough data in historical text normalization to reliably tune hyperparameters.
",3.6 Hyperparameters,[0],[0]
"For the final evaluation, we set the size of the embedding and the recurrent LSTM layers to 128, applied a dropout of 0.3 to the input of each recurrent layer, and trained the model on mini-batches with 50 samples each for a total of 50 epochs (in the multi-task learning setup, mini-batches contain 50 samples of each task, and epochs are counted by the size of the training set for the main task only).",3.6 Hyperparameters,[0],[0]
All these parameters were set on the B manuscript alone.,3.6 Hyperparameters,[0],[0]
"We implemented all of the models in Keras (Chollet, 2015).",3.7 Implementation,[0],[0]
Any parameters not explicitly described here were left at their default values in Keras v1.0.8.,3.7 Implementation,[0],[0]
"We split up each text into three parts, using 1,000 tokens each for a test set and a development set (that is not currently used), and the remainder of the text (between 2,000 and 11,000 tokens) for training.",4 Evaluation,[0],[0]
"We then train and evaluate on each of the 43 texts (excluding the B text that was used for hyper-parameter tuning) individually.
",4 Evaluation,[0],[0]
Baselines We compare our architectures to several competitive baselines.,4 Evaluation,[0],[0]
"Our first baseline is an averaged perceptron model trained to predict output character n-grams for each input character, after using Levenshtein alignment with generated segment distances (Wieling et al., 2009, Sec. 3.3) to align input and output characters.",4 Evaluation,[0],[0]
"Our second baseline uses the same alignment, but trains a
deep bi-LSTM sequential tagger, following Bollmann and Søgaard (2016).",4 Evaluation,[0],[0]
We evaluate this tagger using both standard and multi-task learning.,4 Evaluation,[0],[0]
"Finally, we compare our model to the rule-based and Levenshtein-based algorithms provided by the Norma tool (Bollmann, 2012).4",4 Evaluation,[0],[0]
We use word-level accuracy as our evaluation metric.,4.1 Word accuracy,[0],[0]
"While we also measure character-level metrics, minor differences on character level can cause large differences in downstream applications, so we believe that perfectly matching the output sequences is more useful.",4.1 Word accuracy,[0],[0]
"Average scores across all 43 texts are presented in Table 1 (see Appendix A for individual scores).
",4.1 Word accuracy,[0],[0]
We first see that almost all our encoder-decoder architectures perform significantly better than the four state-of-the-art baselines.,4.1 Word accuracy,[0],[0]
"All our architectures perform better than Norma and the averaged perceptron, and all the MTL architectures outperform Bollmann and Søgaard (2016).
",4.1 Word accuracy,[0],[0]
"We also see that beam search, filtering, and attention lead to cumulative gains in the context of the single-task architecture – with the best architecture outperforming the state-of-the-art by almost 3% in absolute terms.
",4.1 Word accuracy,[0],[0]
"For our multi-task architecture, we also observe gains when we add beam search and filtering, but
4https://github.com/comphist/norma
importantly, adding attention does not help.",4.1 Word accuracy,[0],[0]
"In fact, attention hurts the performance of our multitask architecture quite significantly.",4.1 Word accuracy,[0],[0]
"Also note that the multi-task architecture without attention performs on-par with the single-task architecture with attention.
",4.1 Word accuracy,[0],[0]
"We hypothesize that the reason for this pattern, which is not only observed in the average scores in Table 1, but also quite consistent across the individual results in Appendix A, is that our multi-task learning already learns how to focus attention.
",4.1 Word accuracy,[0],[0]
"This is the hypothesis that we will try to validate in Sec. 5: That multi-task learning can induce strategies for focusing attention comparable to attention strategies for recurrent neural networks.
",4.1 Word accuracy,[0],[0]
Sample predictions A small selection of predictions from our models is shown in Table 2.,4.1 Word accuracy,[0],[0]
"They serve to illustrate the effects of the various settings; e.g., the base model with greedy search tends to produce more nonsense words (ters, ünsget) than the others.",4.1 Word accuracy,[0],[0]
"Using a lexical filter helps the most in this regard: the base model with filtering correctly normalizes ergieng to erging ‘(he) fared’, while decoding without a filter produces the non-word erbiggen.",4.1 Word accuracy,[0],[0]
"Even for herczenlichen (modern herzlichen ‘heartfelt’), where no model finds the correct target form, only the model with filtering produces a somewhat reasonable alternative (herzgeliebtes ‘heartily loved’).
",4.1 Word accuracy,[0],[0]
"In some cases (such as gewarnet ‘warned’),
only the models with attention or multi-task learning produce the correct normalization, but even when they are wrong, they often agree on the prediction (e.g. dicke, herzel).",4.1 Word accuracy,[0],[0]
We will investigate this property further in Sec. 5.,4.1 Word accuracy,[0],[0]
"To gain further insights into our model, we created t-SNE projections (Maaten and Hinton, 2008) of vector representations learned on the M4 text.
",4.2 Learned vector representations,[0],[0]
Fig. 2 shows the learned character embeddings.,4.2 Learned vector representations,[0],[0]
"In the representations from the base model (Fig. 2a), characters that are often normalized to the same target character are indeed grouped closely together: e.g., historical <v> and <u> (and, to a smaller extent, <f>) are often used interchangeably in the M4 text.",4.2 Learned vector representations,[0],[0]
Note the wide separation of <n>,4.2 Learned vector representations,[0],[0]
"and <m>, which is a feature of M4 that does not hold true for all of the texts, as these do not always display a clear distinction between nasals.",4.2 Learned vector representations,[0],[0]
"On the other hand, the MTL model shows a better generalization of the training data (Fig. 2b): here, <u> is grouped closer to other vowel characters and far away from <v>/<f>.",4.2 Learned vector representations,[0],[0]
"Also, <n> and <m> are now in close proximity.
",4.2 Learned vector representations,[0],[0]
We can also visualize the internal word representations that are produced by the encoder (Fig. 3).,4.2 Learned vector representations,[0],[0]
"Here, we chose words that demonstrate the interchangeable use of <u> and <v>.",4.2 Learned vector representations,[0],[0]
"Historical vnd, vns, vmb become modern und, uns, um, changing the <v> to <u>.",4.2 Learned vector representations,[0],[0]
"However, the representation of vmb learned by the base model is closer to forms like von, vor, uor, all starting with <v> in the target normalization.",4.2 Learned vector representations,[0],[0]
"In the MTL model, however, these examples are indeed clustered together.",4.2 Learned vector representations,[0],[0]
Table 1 shows that models which employ either an attention mechanism or multi-task learning obtain similar improvements in word accuracy.,5 Analysis: Multi-task learning helps focus attention,[0],[0]
"However, we observe a decline in word accuracy for models that combine multi-task learning with attention.
",5 Analysis: Multi-task learning helps focus attention,[0],[0]
"A possible interpretation of this counterintuitive pattern might be that attention and MTL, to some degree, learn similar functions of the input data, a conjecture by Caruana (1998).",5 Analysis: Multi-task learning helps focus attention,[0],[0]
We put this hypothesis to the test by closely investigating properties of the individual models below.,5 Analysis: Multi-task learning helps focus attention,[0],[0]
"First, we are interested in the weight parameters of the final layer that transforms the decoder output to class probabilities.",5.1 Model parameters,[0],[0]
"We consider these parameters for our standard encoder-decoder model and compare them to the weights that are learned by the attention and multi-task models, respectively.5
Note that hidden layer parameters are not necessarily comparable across models, but with a fixed seed, differences in parameters over a reference model may be (and are, in our case).",5.1 Model parameters,[0],[0]
"With a fixed seed, and iterating over data points in the same order, it is conceivable the two non-baselines end up in roughly the same alternative local optimum (or at least take comparable routes).
",5.1 Model parameters,[0],[0]
"We observe that the weight differences between the standard and the attention model correlate with the differences between the standard and multitask model by a Pearson’s r of 0.346, averaged across datasets, with a standard deviation of 0.315; on individual datasets, correlation coefficient is as
5For the multi-task models, this analysis disregards those dimensions that do not correspond to classes in the main task.
high as 96.",5.1 Model parameters,[0],[0]
Figure 4 illustrates these highly parallel weight changes for the different models when trained on the N4 dataset.,5.1 Model parameters,[0],[0]
"Next, we compare the effect that employing either an attention mechanism or multi-task learning has on the actual output of our system.",5.2 Final output,[0],[0]
"We find that out of the 210.9 word errors that the base model produces on average across all test sets (comprising 1,000 tokens each), attention resolves 47.7, while multi-task learning resolves an average of 45.4 errors.",5.2 Final output,[0],[0]
"Crucially, the overlap of errors that are resolved by both the attention and the MTL model amounts to 27.7 on average.
",5.2 Final output,[0],[0]
"Attention and multi-task also introduce new errors compared to the base model (26.6 and 29.5 per test set, respectively), and again we can observe a relatively high agreement of the models (11.8 word errors are introduced by both models).
",5.2 Final output,[0.9519657295542354],"['Conventional supervised learning models with parameters Θ, given training data x and label y, tries to maximize the following function max Θ P (y|x,Θ) The optimized parameters Θ are given as, Θ = argmax Θ logP (y|x,Θ) In this work, we propose to augment the supervised learning process by incorporation of world knowledge features xw.']"
"Finally, the attention and multi-task models display a word-level agreement of κ=0.834 (Cohen’s kappa), while either of these models is less strongly correlated with the base model (κ=0.817 for attention and κ=0.814 for multi-task learning).",5.2 Final output,[0],[0]
Our last analysis regards the saliency of the input timesteps with respect to the predictions of our models.,5.3 Saliency analysis,[0],[0]
We follow Li et al. (2016) in calculating first-derivative saliency for given input/output pairs and compare the scores from the different models.,5.3 Saliency analysis,[0],[0]
"The higher the saliency of an input timestep, the more important it is in determining the model’s prediction at a given output timestep.",5.3 Saliency analysis,[0],[0]
"Therefore, if two models produce similar saliency
matrices for a given input/output pair, they have learned to focus on similar parts of the input during the prediction.",5.3 Saliency analysis,[0],[0]
"Our hypothesis is that the attentional and the multi-task learning model should be more similar in terms of saliency scores than either of them compared to the base model.
",5.3 Saliency analysis,[0],[0]
Figure 5 shows a plot of the saliency matrices generated from the word pair czeychen – zeichen ‘sign’.,5.3 Saliency analysis,[0],[0]
"Here, the scores for the attentional and the MTL model indeed correlate by ρ = 0.615, while those for the base model do not correlate with either of them.",5.3 Saliency analysis,[0],[0]
"A systematic analysis across 19,000 word pairs (where all models agree on the output) shows that this effect only holds for longer input sequences (≥ 7 characters), with a mean ρ = 0.303 (±0.177) for attentional vs. MTL model, while the base model correlates with either of them by ρ < 0.21.",5.3 Saliency analysis,[0],[0]
"Many traditional approaches to spelling normalization of historical texts use edit distances or some form of character-level rewrite rules, handcrafted (Baron and Rayson, 2008) or learned automatically (Bollmann, 2013; Porta et al., 2013).
",6 Related Work,[0],[0]
"A more recent approach is based on characterbased statistical machine translation applied to historical text (Pettersson et al., 2013; SánchezMartínez et al., 2013; Scherrer and Erjavec, 2013; Ljubešić et al., 2016) or dialectal data (Scherrer and Ljubešić, 2016).",6 Related Work,[0],[0]
"This is conceptually very similar to our approach, except that we substitute the classical SMT algorithms for neural networks.",6 Related Work,[0],[0]
"Indeed, our models can be seen as a form of character-based neural MT (Cho et al., 2014).
",6 Related Work,[0],[0]
"Neural networks have rarely been applied to
historical spelling normalization so far.",6 Related Work,[0],[0]
Azawi et al. (2013) normalize old Bible text using bidirectional LSTMs with a layer that performs alignment between input and output wordforms.,6 Related Work,[0],[0]
"Bollmann and Søgaard (2016) also use bi-LSTMs to frame spelling normalization as a characterbased sequence labelling task, performing character alignment as a preprocessing step.
",6 Related Work,[0],[0]
"Multi-task learning was shown to be effective for a variety of NLP tasks, such as POS tagging, chunking, named entity recognition (Collobert et al., 2011) or sentence compression (Klerke et al., 2016).",6 Related Work,[0],[0]
"It has also been used in encoderdecoder architectures, typically for machine translation (Dong et al., 2015; Luong et al., 2016), though so far not with attentional decoders.",6 Related Work,[0],[0]
"We presented an approach to historical spelling normalization using neural networks with an encoder-decoder architecture, and showed that it consistently outperforms several existing baselines.",7 Conclusion and Future Work,[0],[0]
"Encouragingly, our work proves to be fully competitive with the sequence-labeling approach by Bollmann and Søgaard (2016), without requiring a prior character alignment.
",7 Conclusion and Future Work,[0],[0]
"Specifically, we demonstrated the aptitude of multi-task learning to mitigate the shortage of training data for the named task.",7 Conclusion and Future Work,[0],[0]
We included a multifaceted analysis of the effects that MTL introduces to our models and the resemblance that it bears to attention mechanisms.,7 Conclusion and Future Work,[0],[0]
"We believe that this analysis is a valuable contribution to the understanding of MTL approaches also beyond spelling normalization, and we are confident that our observations will stimulate further research into the relationship between MTL and attention.
",7 Conclusion and Future Work,[0],[0]
"Finally, many improvements to the presented approach are conceivable, most notably introducing some form of token context to the model.",7 Conclusion and Future Work,[0],[0]
"Currently, we only consider word forms in isolation, which is problematic for ambiguous cases (such as jn, which can normalize to in ‘in’ or ihn ‘him’) and conceivably makes the task harder for others.",7 Conclusion and Future Work,[0],[0]
Reranking the predictions with a language model could be one possible way to improve on this.,7 Conclusion and Future Work,[0],[0]
Ljubešić,7 Conclusion and Future Work,[0],[0]
"et al. (2016), for example, experiment with segment-based normalization, using a character-based SMT model with character input derived from segments (essentially, token ngrams) instead of single tokens, which also intro-
duces context.",7 Conclusion and Future Work,[0],[0]
"Such an approach could also deal with the issue of tokenization differences between the historical and the modern text, which is another challenge often found in datasets of historical text.",7 Conclusion and Future Work,[0],[0]
"Marcel Bollmann was supported by Deutsche Forschungsgemeinschaft (DFG), Grant DI 1558/4.",Acknowledgments,[0],[0]
This research is further supported by ERC Starting Grant LOWLANDS,Acknowledgments,[0],[0]
"No. 313695, as well as by Trygfonden.",Acknowledgments,[0],[0]
"For interested parties, we provide our full evaluation results for each single text in our dataset.",A Supplementary Material,[0],[0]
"Table 3 shows token counts, a rough classification of each text’s dialectal region, and the results for the baseline methods.",A Supplementary Material,[0],[0]
Table 4 presents the full results for our encoder-decoder models.,A Supplementary Material,[0],[0]
Automated processing of historical texts often relies on pre-normalization to modern word forms.,abstractText,[0],[0]
"Training encoder-decoder architectures to solve such problems typically requires a lot of training data, which is not available for the named task.",abstractText,[0],[0]
"We address this problem by using several novel encoder-decoder architectures, including a multi-task learning (MTL) architecture using a grapheme-to-phoneme dictionary as auxiliary data, pushing the state-of-theart by an absolute 2% increase in performance.",abstractText,[0],[0]
We analyze the induced models across 44 different texts from Early New High German.,abstractText,[0],[0]
"Interestingly, we observe that, as previously conjectured, multi-task learning can learn to focus attention during decoding, in ways remarkably similar to recently proposed attention mechanisms.",abstractText,[0],[0]
"This, we believe, is an important step toward understanding how MTL works.",abstractText,[0],[0]
Learning attention for historical text normalization by learning to pronounce,title,[0],[0]
"Proceedings of NAACL-HLT 2018, pages 313–322 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics",text,[0],[0]
"Today, machine learning is centered around algorithms that can be trained on available taskspecific labeled and unlabeled training samples.",1 Introduction,[0],[0]
"Although learning paradigms like Transfer Learning (Pan and Yang, 2010) attempt to incorporate
∗equal contribution †Main work done during internship at Accenture Technol-
ogy Labs
knowledge from one task into another, these techniques are limited in scalability and are specific to the task at hand.",1 Introduction,[0],[0]
"On the other hand, humans have the intrinsic ability to elicit required past knowledge from the world on demand and infuse it with newly learned concepts to solve problems.
",1 Introduction,[0],[0]
"The question that we address in this paper is the following: Is it possible to develop learning models that can be trained in a way that it is able to infuse a general body of world knowledge for prediction apart from learning based on training data?
",1 Introduction,[0.950263880750406],['Our experiments were designed to analyze whether a deep learning model is being improved when it has access to KG facts from a relevant source.']
"By world knowledge, we mean structured general purpose knowledge that need not be domain specific.",1 Introduction,[0],[0]
"Knowledge Graphs (Nickel et al., 2016a) are a popular source of such structured world knowledge.",1 Introduction,[0],[0]
"Knowledge Graphs represent information in the form of fact triplets, consisting of a subject entity, relation and object entity (example: <Italy, capital, Rome>).",1 Introduction,[0],[0]
The entities represent the nodes of the graph and their relations act as edges.,1 Introduction,[0],[0]
"A fact triple (subject entity, relation, object relation) is represented as (h, r, t).",1 Introduction,[0],[0]
"Practical knowledge bases congregate information from secondary databases or extract facts from unstructured text using various statistical learning mechanisms, examples of such systems are NELL (Mitchell et al., 2015) and DeepDive (Niu
313
et al., 2012).",1 Introduction,[0],[0]
"There are human created knowledge bases as well, like Freebase (FB15k) (Bollacker et al., 2008) and WordNet (Miller et al., 1990).",1 Introduction,[0.9700174110984899],"['Similar work utilizing only the structure of the graph include ManifoldE (Xiao et al., 2015b), TransG (Xiao et al., 2015a), TransD (Ji et al., 2015), TransM (Fan et al., 2014), HolE (Nickel et al., 2016b) and ProjE (Shi and Weninger, 2017).']"
"The knowledge present in these knowledge bases includes common knowledge and partially covers common-sense knowledge and domain knowledge (Song and Roth, 2017).",1 Introduction,[0],[0]
"Knowledge Graphs and Knowledge Bases are conceptually equivalent for our purpose and we will use the name interchangeably in this paper.
",1 Introduction,[0],[0]
We illustrate the significance of world knowledge using a few examples.,1 Introduction,[0],[0]
"For the example of a Natural Language Inference (NLI) problem (MacCartney, 2009), consider the two following statements, A: The couple is walking on the sea shore and B: The man and woman are wide awake.",1 Introduction,[1.0],"['For the example of a Natural Language Inference (NLI) problem (MacCartney, 2009), consider the two following statements, A: The couple is walking on the sea shore and B: The man and woman are wide awake.']"
"Here, for a learning model to infer B from A, it should have access to the common knowledge that “The man and woman and The couple means the same” since this information may not be specific for a particular inference.",1 Introduction,[0],[0]
"Further, it is not possible for a model to learn all such correlations from just the labeled training data available for the task.
",1 Introduction,[0],[0]
"Consider another example of classifying the news snippet, Donald Trump offered his condolences towards the hurricane victims and their families in Texas.",1 Introduction,[0],[0]
"We cannot classify it as a political news unless we know the facts <Donald Trump, president, United States> and <Texas, state, United States>.",1 Introduction,[1.0],"['We cannot classify it as a political news unless we know the facts <Donald Trump, president, United States> and <Texas, state, United States>.']"
"We posit that machine learning models, apart from training them on data with the ground-truth can also be trained to fetch relevant information from structured knowledge bases in order to enhance their performance.
",1 Introduction,[0.999999974473635],"['We posit that machine learning models, apart from training them on data with the ground-truth can also be trained to fetch relevant information from structured knowledge bases in order to enhance their performance.']"
"In this work, we propose a deep learning model that can extract relevant support facts on demand from a knowledge base (Mitchell et al., 2015) and incorporate it in the feature space along with the features learned from the training data (shown in Figure 1).",1 Introduction,[1.0],"['In this work, we propose a deep learning model that can extract relevant support facts on demand from a knowledge base (Mitchell et al., 2015) and incorporate it in the feature space along with the features learned from the training data (shown in Figure 1).']"
"This is a challenging task, as knowledge bases typically have millions of fact triples.",1 Introduction,[0],[0]
Our proposed model involves a deep learning mechanism to jointly model this look-up scheme along with the task specific training of the model.,1 Introduction,[0],[0]
The look-up mechanism and model is generic enough so that it can be augmented to any task specific learning model to boost the learning performance.,1 Introduction,[0],[0]
"In this paper, we have established superior performance of the proposed KG-augmented models
over vanilla model on text classification and natural language inference.
",1 Introduction,[0],[0]
"Although there is a plethora of work on knowledge graph representation (Nickel et al., 2016a)",1 Introduction,[0],[0]
"(Mitchell et al., 2015) (Niu et al., 2012) from natural language text, no attempt to augment learning models with knowledge graph information have been done.",1 Introduction,[0],[0]
To the best of our knowledge this is the first attempt to incorporate world knowledge from a knowledge base for learning models.,1 Introduction,[0],[0]
Knowledge Graph entities/relations need to be encoded into a numerical representation for processing.,2 Knowledge Graph Representations,[0],[0]
"Before describing the model, we provide a brief overview of graph encoding techniques.",2 Knowledge Graph Representations,[0],[0]
"Various KG embedding techniques can be classified at a high level into: Structure-based embeddings and Semantically-enriched embeddings.
",2 Knowledge Graph Representations,[0],[0]
"Structure-based embeddings: TransE (Bordes et al., 2013) is the introductory work on knowledge graph representation, which translated subject entity to object entity using one-dimensional relation vector (h + r = t).",2 Knowledge Graph Representations,[0],[0]
"Variants of the TransE (Bordes et al., 2013) model uses translation of the entity vectors over relation specific subspaces.",2 Knowledge Graph Representations,[0],[0]
"TransH (Wang et al., 2014b) introduced the relation-specific hyperplane to translate the entities.",2 Knowledge Graph Representations,[0],[0]
Similar work utilizing only the structure of the graph include ManifoldE,2 Knowledge Graph Representations,[0],[0]
"(Xiao et al., 2015b), TransG (Xiao et al., 2015a), TransD",2 Knowledge Graph Representations,[0],[0]
"(Ji et al., 2015), TransM (Fan et al., 2014), HolE (Nickel et al., 2016b) and ProjE (Shi and Weninger, 2017).
",2 Knowledge Graph Representations,[0],[0]
Semantically-enriched embeddings: These embedding techniques learn to represent entities/relations of the KG along with its semantic information.,2 Knowledge Graph Representations,[0],[0]
"Neural Tensor Network(NTN) (Socher et al., 2013) was the pioneering work in this field which initialized entity vectors with the average word embeddings followed by tensor-based operations.",2 Knowledge Graph Representations,[0],[0]
"Recent works involving this idea are “Joint Alignment” (Zhong et al., 2015) and SSP (Xiao et al., 2017).",2 Knowledge Graph Representations,[0],[0]
"DKRL (Xie et al., 2016) is a KG representation technique which also takes into account the descriptive nature of text keeping the simple structure of TransE model.",2 Knowledge Graph Representations,[0],[0]
Pretrained word2vec,2 Knowledge Graph Representations,[0],[0]
"(Mikolov et al., 2013) is used to form the entity representation by passing through a Convolutional Neural Network (CNN) (Kim, 2014) architecture constraining the relationships to hold.
",2 Knowledge Graph Representations,[0.9999999460183145],"['Pretrained word2vec (Mikolov et al., 2013) is used to form the entity representation by passing through a Convolutional Neural Network (CNN) (Kim, 2014) architecture constraining the relationships to hold.']"
"In our experiments we have used the DKRL (Xie et al., 2016) encoding scheme as it emphasizes on the semantic description of the text.",2 Knowledge Graph Representations,[1.0],"['In our experiments we have used the DKRL (Xie et al., 2016) encoding scheme as it emphasizes on the semantic description of the text.']"
"Moreover, DKRL fundamentally uses TransE (Bordes et al., 2013) method for encoding structural information.",2 Knowledge Graph Representations,[0],[0]
"Therefore, we can retrieve relevant entities & relation and obtain the complete the fact using t = h+",2 Knowledge Graph Representations,[0],[0]
r.,2 Knowledge Graph Representations,[0],[0]
"This reduces the complexity of fact retrieval as the number of entities/relations is much less compared to the number of facts, thus making the retrieval process faster.",2 Knowledge Graph Representations,[0],[0]
"Conventional supervised learning models with parameters Θ, given training data x and label y, tries to maximize the following function
max Θ
P (y|x,Θ)
The optimized parameters Θ are given as,
Θ = argmax Θ
logP (y|x,Θ)
",3 The Proposed Model,[0],[0]
"In this work, we propose to augment the supervised learning process by incorporation of world knowledge features xw.",3 The Proposed Model,[0],[0]
"The world knowledge features are retrieved using the data x, using a separate model where, xw = F (x,Θ(2)).",3 The Proposed Model,[0],[0]
"Thus, our modified objective function can be expressed as
max Θ
P (y|x, xw,Θ(1))
where, Θ = {Θ(1),Θ(2)}.",3 The Proposed Model,[0],[0]
"The optimized parameters can be obtained using the equation
Θ = argmax Θ
logP (y|x, F (x,Θ(2)),Θ(1))
",3 The Proposed Model,[0],[0]
The subsequent sections focus on the formulation of the function F which is responsible for fact triple retrieval using the data sample x.,3 The Proposed Model,[0],[0]
"Here it is important to note that, we are not assuming any structural form for P based on F .",3 The Proposed Model,[0],[0]
"So the method is generic and applicable to augment any supervised learning setting with any form for P , only constraint being P should be such that the error gradient can be computed with respect to F .",3 The Proposed Model,[0],[0]
"In the experiments we have used softmax using the LSTM (Greff et al., 2015) encodings of the input as the form for P .",3 The Proposed Model,[0],[0]
"As for F , we use soft attention (Luong et al., 2015; Bahdanau et al., 2014) using the LSTM encodings of the input and appropriate representations of the fact(s).",3 The Proposed Model,[0],[0]
"Based on the
representation used for the facts, we propose two models (a) Vanilla Model (b) Convolution-based entity/relation cluster representation, for fact retrieval in the subsequent sections.",3 The Proposed Model,[0],[0]
"The entities and relationships of KG are encoded using DKRL, explained earlier.",3.1 Vanilla Model,[0],[0]
Let ei ∈ Rm stand for the encoding of the entity i and rj ∈ Rm stands for jth relationship in the KG.,3.1 Vanilla Model,[0],[0]
"The input text in the form of concatenated word vectors, x = (x1, x2, . . .",3.1 Vanilla Model,[0],[0]
", xT ) is first encoded using an LSTM (Greff et al., 2015) module as follows,
ht = f(xt, ht−1)
and
o = 1
T
T∑
t=1
ht,
ht ∈",3.1 Vanilla Model,[0],[0]
"Rn is the hidden state of the LSTM at time t, f is a non-linear function and T is the sequence length.",3.1 Vanilla Model,[0],[0]
"Then a context vector is formed from o as follows,
C = ReLU(oTW ),
where, W ∈ Rn×m represent the weight parameters.",3.1 Vanilla Model,[0],[0]
"The same procedure is duplicated with separate LSTMs to form two seperate context vectors, one for entity retrieval (CE) and one for relationship retrieval (CR).
",3.1 Vanilla Model,[0],[0]
"As the number of fact triples in a KG is in the order of millions in the vanilla model, we resort to generating attention over the entity and relation space separately.",3.1 Vanilla Model,[0],[0]
The fact is then formed using the retrieved entity and relation.,3.1 Vanilla Model,[0],[0]
"The attention for the entity, ei using entity context vector is given by
αei = exp(CTEei)",3.1 Vanilla Model,[0],[0]
|E|∑ j=0,3.1 Vanilla Model,[0],[0]
"exp(CTEej)
where |E| is the number of entities in the KG.",3.1 Vanilla Model,[0],[0]
"Similarly the attention for a relation vector ri is computed as
αri = exp(CTRri) |R|∑ j=0 exp(CTRrj)
where |R| is the number of relations in the KG.",3.1 Vanilla Model,[0],[0]
"The final entity and relation vector retrieval is computed by the weighted sum with the attention
values of individual retrieved entity/relation vectors.
",3.1 Vanilla Model,[0],[0]
"e =
|E|∑
i=0
αeiei r =
|R|∑
i=0
αriri
Figure 2 shows the schematic diagram for entity/relation retrieval.",3.1 Vanilla Model,[0],[0]
"After the final entity and relation vectors are computed, we look forward to completion of the fact triple.",3.1 Vanilla Model,[0],[0]
The KG embedding technique used for the experiment is DKRL which inherently uses the TransE model assumption (h+r ≈ t).,3.1 Vanilla Model,[0],[0]
"Therefore, using the subject entity and relation we form the object entity as t = e+r.",3.1 Vanilla Model,[0],[0]
Thus the fact triplet retrieved is F =,3.1 Vanilla Model,[0],[0]
"[e, r, e + r], where F ∈ R3m. This retrieved fact information is concatenated along with the context vector (C) of input x obtained using LSTM module.",3.1 Vanilla Model,[0],[0]
"The final classification label y is computed as follows,
F ′ = ReLU(FTV )
y = softmax([F ′",3.1 Vanilla Model,[0],[0]
": C]TU) where, V ∈ R3m×u and U ∈ R2u×u are model parameters to be learned.",3.1 Vanilla Model,[0],[0]
y is used to compute the cross entropy loss.,3.1 Vanilla Model,[0],[0]
"We minimize this loss averaged across the training samples, to learn the various model parameters using stochastic gradient descent (Bottou, 2012).",3.1 Vanilla Model,[0],[0]
"The final prediction y, now includes information from both dataset specific samples and world knowledge to aid in en-
hanced performance.",3.1 Vanilla Model,[0],[0]
While jointly training the attention mechanism tunes itself to retrieve relevant facts that are required to do the final classification.,3.1 Vanilla Model,[1.0],['While jointly training the attention mechanism tunes itself to retrieve relevant facts that are required to do the final classification.']
The vanilla model attends over the entire entity/relation space which is not a good approach as we observe that the gradient for each attention value gets saturated easily.,3.2 Pre-training KG Retrieval,[1.0],['The vanilla model attends over the entire entity/relation space which is not a good approach as we observe that the gradient for each attention value gets saturated easily.']
"While training the classification and retrieval module together, the model tends to ignore the KG part and gradient propagates only through the classification module.",3.2 Pre-training KG Retrieval,[0],[0]
"This is expected to an extent as the most pertinent information for the task at hand comes from the training samples, only background aiding information comes from KG.",3.2 Pre-training KG Retrieval,[0],[0]
"After few epochs of training, the KG retrieved fact always converged to a fixed vector.",3.2 Pre-training KG Retrieval,[0],[0]
"To overcome this problem, we attempted pretraining KG retrieval part separately.",3.2 Pre-training KG Retrieval,[0],[0]
"A pre-trained KG model is used to retrieve the facts and then concatenate with the classification module, while we allow error to be propagate through the pretrained model, at the time of joint training.",3.2 Pre-training KG Retrieval,[0],[0]
We infer that KG doesn’t return noise and has essential information for the task as the separate KG part alone shows significant performance (59% for News20 & 66% for SNLI).,3.2 Pre-training KG Retrieval,[0],[0]
Figure 3 depicts the entire training scheme.,3.2 Pre-training KG Retrieval,[0],[0]
"This procedure solved the issue of gradient saturation in the KG retrieval part
at the time of joint training.",3.2 Pre-training KG Retrieval,[0],[0]
"However, the key problem of attention mechanism having to cover a large span of entities/relation, remained.",3.2 Pre-training KG Retrieval,[0],[0]
"In this section, we propose a mechanism to reduce the large number of entities/relationships over which attention has to be generated in the knowledge graph.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"We propose to reduce the attention space by learning the representation of similar entity/relation vectors and attending over them.
",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"In order to cluster similar entity/relation vectors, we used k-means clustering (Bishop, 2006) and formed l clusters with equal number of entity/relation vectors in each cluster.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
Each of the clusters were then encoded using convolutional filters.,3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"The output of the k-means clustering is a sequence of entity/relation vectors {eT1 , eT2 , · · · , eTq }, where ei ∈ Rm.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"For each cluster these vectors were stacked to form E as the 2- D input to the CNN encoder, where E ∈ Rm×q.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"During experimentation for finding a suitable fil-
ter shape, it was observed that using 2-D filters the model failed to converge at all.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"Therefore, we inferred that the latent representation of two different indices in the vector ei, should not be tampered using convolution.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"We then resorted to use 1-D convolution filters which slide along only the columns of E , as shown Figure 4.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
The stride length along y-axis is the window length k.,3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"The output of the convolution layer is expressed as,
E ′(i, j) = W T",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"[ei,j , ei+1,j , . . .",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
", ei+k−1,j ]T
where, E ′(i, j) is the (i, j)th element of the output matrix E ′ and W ∈",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
Rk is the convolution weight filter.,3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"A pooling layer followed the convolution layer in order to reduce the parameter space, we used 1-D window only along the y-axis similar to the convolutional kernel mentioned above.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"We used a two layered convolution network with the stride length k & max-pool windows n is adjusted to obtain output Ei ∈ Rm, where i is the cluster index.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
Similar procedure of clustering followed by the encoding of the cluster entities is done for relations as well.,3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"Thus both the entity and relation space were reduced to contain fewer elements, one each for each cluster.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"After the compact entity space E and relation space R is formed, we followed the same steps as earlier for forming the attention, but now the training was more effective as the gradient was propagating effectively and was not choked by the large space.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"As the convolution architecture is also simultaneously trained, attention mechanism was not burdened as before, to learn over the large space of entities and relations.
",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"Another point that needs to be mentioned here is regarding ranking/ordering items in the clusters, we have done experiments to verify the ordering does not affect the final result.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"We have verified this by randomly shuffling the entities/relationships in every clusters and the ac-
curacy output remained within an error bound of ±0.5%.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"In various permutations, the representations learned by the convolution operator for clusters varies, but it does not affect the overall results.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"Regarding the interpretation of what convolution operator learns, the operator is applied along each dimension of the entity/relationship vector, to learn a representation of the clusters.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"This representation includes information from relevant entities in the cluster, as the relevant entities varies across tasks, the representation learned using convolution also adapts accordingly.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
"It is analogous to learning relevant features from an image, in our case the convolution layer learns the features focusing on relevant entities/relations in a cluster pertaining to the task.",3.3 Convolution-based Entity and Relation Cluster Representation,[0],[0]
Our experiments were designed to analyze whether a deep learning model is being improved when it has access to KG facts from a relevant source.,4 Experiments and Evaluations,[0],[0]
"The selection of knowledge graph has to be pertinent to the task at hand, as currently there is no single knowledge base that contains multiple kinds of information and can cater to all tasks.",4 Experiments and Evaluations,[0],[0]
We illustrate with results that the performance of a deep learning model improves when it has access to relevant facts.,4 Experiments and Evaluations,[0],[0]
"We also illustrate that as the model learns faster with access to knowledge bases, we can train deep learning models with substantially less training data, without compromising on the accuracy.",4 Experiments and Evaluations,[0],[0]
"In the subsequent section we briefly describe the datasets and associated Knowledge Bases used.
Datasets and Relevant Knowledge Graphs
In our experiments, we have mainly used the popular text classification dataset 20Newsgroups (Lichman, 2013) and the Natural Language Inference dataset, Stanford Natural Language Inference (SNLI) corpus (Bowman et al., 2015).",4 Experiments and Evaluations,[0.9809788861326849],"['Datasets and Relevant Knowledge Graphs In our experiments, we have mainly used the popular text classification dataset 20Newsgroups (Lichman, 2013) and the Natural Language Inference dataset, Stanford Natural Language Inference (SNLI) corpus (Bowman et al., 2015).']"
"We have also done experiments on DBPedia ontology classification dataset1, with a very strong baseline.",4 Experiments and Evaluations,[0],[0]
"These datasets are chosen as they share domain knowledge with two most popular knowledge bases, Freebase (FB15k) (Bollacker et al., 2008) and WordNet (WN18) (Bordes et al., 2013).",4 Experiments and Evaluations,[1.0],"['These datasets are chosen as they share domain knowledge with two most popular knowledge bases, Freebase (FB15k) (Bollacker et al., 2008) and WordNet (WN18) (Bordes et al., 2013).']"
"The training and test size of the datasets are mentioned in Table 1.
1http://wiki.dbpedia.org/ services-resources/dbpedia-data-set-2014
Freebase (FB15k) (Bollacker et al., 2008) contains facts about people, places and things (contains 14904 entities, 1345 relations & 4.9M fact triples), which is useful for text classification in 20Newsgroups (Lichman, 2013) dataset.",4 Experiments and Evaluations,[0.9601363686116294],"['Freebase (FB15k) (Bollacker et al., 2008) contains facts about people, places and things (contains 14904 entities, 1345 relations & 4.9M fact triples), which is useful for text classification in 20Newsgroups (Lichman, 2013) dataset.']"
"On the other hand, WordNet (WN18) (Bordes et al., 2013) (has 40943 entities, 18 relations & 1.5M fact triples) contains facts about common day-to-day things (example: furniture includes bed), which can help in inference tasks like SNLI.",4 Experiments and Evaluations,[0],[0]
"Both the knowledge bases are directed graphs, due to fewer number of relations WN18 the entities are more likely to be connected using the same type of relations.",4 Experiments and Evaluations,[0],[0]
For experiments relating to both the datasets 20Newsgroups & SNLI we used the standard LSTM as the classification module.,4 Experiments and Evaluations,[0],[0]
"As iterated earlier, our KG based fact retrieval is independent of the base model used.",4 Experiments and Evaluations,[0],[0]
We show improvement in performance using the proposed models by KG fact retrieval.,4 Experiments and Evaluations,[0],[0]
We use classification accuracy of the test set as our evaluation metric.,4 Experiments and Evaluations,[0],[0]
All experiments were carried on a Dell Precision Tower 7910 server with Quadro M5000 GPU with 8 GB of memory.,4.1 Experimental Setup,[0],[0]
"The models were trained using the Adam’s Optimizer (Kingma and Ba, 2014) in a stochastic gradient descent (Bottou, 2012) fashion.",4.1 Experimental Setup,[0],[0]
"The models were implemented using TensorFlow (Abadi et al., 2015).",4.1 Experimental Setup,[1.0],"['The models were implemented using TensorFlow (Abadi et al., 2015).']"
The relevant hyperparameters are listed in Table 2.,4.1 Experimental Setup,[0],[0]
"The word embeddings for the experiments were obtained using the pre-trained GloVe (Pennington et al., 2014)2 vectors.",4.1 Experimental Setup,[0],[0]
"For words missing in the pre-trained vectors, the local GloVe vectors which was trained on the corresponding dataset was used.",4.1 Experimental Setup,[0],[0]
Table 3 shows the results of test accuracy of the various methods proposed on the datasets News20 & SNLI.,4.2 Results & Discussion,[0],[0]
"We observe that incorporation of KG facts using the basic vanilla model improves the performance slightly, as the retrieval model was
2http://nlp.stanford.edu/data/glove.840B.300d.zip
not getting trained effectively.",4.2 Results & Discussion,[0],[0]
The convolutionbased model shows significant improvement over the normal LSTM classification.,4.2 Results & Discussion,[0],[0]
While tuning the parameters of the convolution for clustered entities/relations it was observed that smaller stride length and longer max-pool window improved performance.,4.2 Results & Discussion,[0],[0]
"For News20 dataset we show an improvement of almost 3% and for SNLI an improvement of almost 5%.
",4.2 Results & Discussion,[0],[0]
The work is motivated more from the perspective of whether incorporation of world knowledge will improve any deep learning model rather than beating the state-of-the-art performance.,4.2 Results & Discussion,[0],[0]
"Although LSTM is used to encode the input for the model as well as the retrieval vector, as mentioned earlier, these two modules need not be same.",4.2 Results & Discussion,[0],[0]
For encoding the input any complex state-of-the-art model can be used.,4.2 Results & Discussion,[0],[0]
LSTM has also been used to generate the retrieval vector.,4.2 Results & Discussion,[0],[0]
"For DBPedia ontology classification dataset, we have used a strong baseline of 98.6%, and after augmenting it with KG (Freebase) using convolution based model we saw an improvement of ∼0.2%.",4.2 Results & Discussion,[0],[0]
"As the baseline is stronger, the improvement quantum has decreased.",4.2 Results & Discussion,[0],[0]
This is quite intuitive as complex models are selfsufficient in learning from the data by itself and therefore the room available for further improvement is relatively less.,4.2 Results & Discussion,[1.0],['This is quite intuitive as complex models are selfsufficient in learning from the data by itself and therefore the room available for further improvement is relatively less.']
"The improvement as observed in the experiments is significant in weaker learning models, however it is also capable of improving stronger baselines as is evident from the results of DBPedia dataset.",4.2 Results & Discussion,[1.0],"['The improvement as observed in the experiments is significant in weaker learning models, however it is also capable of improving stronger baselines as is evident from the results of DBPedia dataset.']"
"We hypothesized that as Knowledge Graph is feeding more information to the model, we can achieve better performance with less training data.
",4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
To verify this we have performed experiments on varying dataset fractions for 20Newsgroups dataset as shown in Figure 5.,4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
"From the plot, we observe that KG augmented LSTM with 70% data outperforms the baseline model with full dataset support, thereby reducing the dependency on labeled data by 30%.
",4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0.999999995888955],"['From the plot, we observe that KG augmented LSTM with 70% data outperforms the baseline model with full dataset support, thereby reducing the dependency on labeled data by 30%.']"
We also designed an experiment to compare the accuracy of the baseline model trained on full training data and compared it with the accuracy of the KG augmented model trained with just 70% of the training data for 20Newsgroups and SNLI datasets.,4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0.9607102682765328],"['Even with just 70% of the data, KG augmented model is able to achieve better accuracy compared to the vanilla LSTM model trained on the full data.']"
The accuracy and training loss plots across training epochs is given in Figure 6.,4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
"Even with just 70% of the data, KG augmented model is able to achieve better accuracy compared to the vanilla LSTM model trained on the full data.",4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
This clearly indicates that relevant information pertaining to the task is retrieved from the knowledge graph and the training loss reduction is not due to lesser data only.,4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
Also note that training loss is substantially less for KG LSTM compared to normal LSTM when the dataset size is reduced.,4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[1.0],['Also note that training loss is substantially less for KG LSTM compared to normal LSTM when the dataset size is reduced.']
"This result is very promising, to reduce the large labeled training data requirement of large deep learning
models, which is hard to come by.",4.3 Reducing Dataset Size Requirements for Training Deep Learning Models,[0],[0]
"The basic idea of infusing general world knowledge for learning tasks, especially for natural language processing, has not been attempted before.",5 Relevant Previous Work,[0],[0]
"For multi-label image classification, the use of KGs has been pursued recently by (Marino et al., 2016).",5 Relevant Previous Work,[0],[0]
"In this work, they first obtain labels of the input data (using a different model), use these labels to populate features from the KG and in turn use these features back for the final classification.",5 Relevant Previous Work,[1.0],"['In this work, they first obtain labels of the input data (using a different model), use these labels to populate features from the KG and in turn use these features back for the final classification.']"
"For NLP tasks the information needed may not necessarily depend on the final class, and we are directly using all the information available in the input for populating the relevant information from the knowledge graphs.",5 Relevant Previous Work,[0],[0]
"Our attempt is very different from Transfer Learning (Pan and Yang, 2010).
",5 Relevant Previous Work,[0],[0]
In Transfer Learning the focus is on training the model for one task and tuning the trained model to use it for another task.,5 Relevant Previous Work,[0],[0]
This is heavily dependent on the alignment between source task and destination task and transferred information is in the model.,5 Relevant Previous Work,[0],[0]
"In our case, general world knowledge is being infused into the learning model for any given task.",5 Relevant Previous Work,[0],[0]
"By the same logic, our work is different from domain adaptation (Glorot et al., 2011) as well.",5 Relevant Previous Work,[0],[0]
"There has been attempts to use world knowledge (Song and Roth, 2017) for creating more labeled training data and providing distant supervision etc.",5 Relevant Previous Work,[0],[0]
"Incorporating Inductive Biases (Ridgeway, 2016) based on the known information about a domain onto the structure of the learned models, is an active area of research.",5 Relevant Previous Work,[0],[0]
However our motivation and approach is fundamentally different from these works.,5 Relevant Previous Work,[0],[0]
In this work we have illustrated the need for incorporating world knowledge in training task specific models.,6 Conclusion & Future Work,[0],[0]
We presented a novel convolutionbased architecture to reduce the attention space over entities and relations that outperformed other models.,6 Conclusion & Future Work,[0],[0]
"With significant improvements over the vanilla baselines for two well known datasets, we have illustrated the efficacy of our proposed methods in enhancing the performance of deep learning models.",6 Conclusion & Future Work,[0],[0]
We showcased that the proposed method can be used to reduce labeled training data requirements of deep learning models.,6 Conclusion & Future Work,[0],[0]
"Although in this work we focused only on NLP tasks and using LSTM as the baseline model, the proposed approach is applicable for other domain tasks as well, with more complicated deep learning models as baseline.",6 Conclusion & Future Work,[0],[0]
To the best of our knowledge this is the first attempt at infusing general world knowledge for task specific training of deep learning models.,6 Conclusion & Future Work,[0],[0]
"Being the first work of its kind, there is a lot of scope for improvement.",6 Conclusion & Future Work,[0],[0]
A more sophisticated model which is able to retrieve facts more efficiently from millions of entries can be formulated.,6 Conclusion & Future Work,[0],[0]
"Currently we have focused only on a flat attention structure, a hierarchical attention mechanism would be more suitable.",6 Conclusion & Future Work,[0],[0]
The model uses soft attention to enable training by simple stochastic gradient descent.,6 Conclusion & Future Work,[0],[0]
Hard attention over facts using reinforcement learning can be pursued further.,6 Conclusion & Future Work,[0],[0]
"This will further help in selection of multifacts, that are not of similar type but relevant to the task.",6 Conclusion & Future Work,[0],[0]
"The convolution based model, helped to reduce the space over entities and relationships over which attention had to be generated.",6 Conclusion & Future Work,[0],[0]
"However more sophisticated techniques using similarity based search (Wang et al., 2014a; Mu and Liu, 2017) can be pursued towards this purpose.",6 Conclusion & Future Work,[0],[0]
"The results from the initial experiments illustrates the effectiveness of our proposed approach, advocating further investigations in these directions.",6 Conclusion & Future Work,[0],[0]
"Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data.",abstractText,[0],[0]
"Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand.",abstractText,[0],[0]
"In this work, we propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks.",abstractText,[0],[0]
Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism.,abstractText,[0],[0]
We introduce a convolutionbased model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space.,abstractText,[0],[0]
We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task.,abstractText,[0],[0]
"Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset.",abstractText,[0],[0]
"We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base.",abstractText,[0],[0]
Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing,title,[0],[0]

1	48	First and foremost, implementation errors can be extremely difficult to detect—let alone to localize and address—since there are many other potential causes of undesired behavior in a machine learning system.
4	42	As a result, actual implementation errors can persist Standard methodology: test it empirically Program Debug Test Our methodology: verify it mathematically indefinitely without detection.1 Errors are even more difficult to detect in stochastic programs, since some errors may only distort the distributions of random variables and may require writing custom statistical tests to detect.
16	71	Proving correctness of machine learning systems requires building on the tools and insights from two distinct fields: program verification (Leroy, 2009; Klein et al., 2009; Chlipala, 2013; Chen et al., 2015), which has aimed to prove properties of computer programs, and formal mathematics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al., 2013; Hales et al., 2015), which has aimed to formally represent and generate machine-checkable proofs of mathematical theorems.
37	18	To develop software systems with no implementation errors, we need a way to write computer programs, mathematical theorems, and mathematical proofs all in the same language.
38	18	All three capabilities are provided by the new interactive proof assistant Lean (de Moura et al., 2015).
42	39	We can write standard functional programs in Lean, such as softplus: def splus (x : R) : R := log (1 + exp x) We can also represent more abstract operations such as integrals and gradients:∫ (f : R→ R) : R ∇ (f : R→ R) (θ : R) : R Here the intended meaning of ∫ f is the integral of the function f over all of R, while the intended meaning of ∇ f θ is the gradient (i.e. the derivative) of the function f at the point θ.
45	20	For example, we can use the following predicate to state that a particular function f is differentiable at a point θ: is_diff (f : R→ R) (θ : R) : Prop The fact that the return type of is_diff is Prop indicates that it is not a computer program to be executed but rather that it represents a mathematical theorem.
46	41	We can also state and assume basic properties about the gradient, such as linearity: ∀ (f g : R→ R) (θ : R), is_diff f θ ∧ is_diff g θ→ ∇ (f + g) θ =∇ f θ +∇ g θ Returning to our running example, we can state the theorem that a particular function f computes the gradient of the softplus function: def gsplus_spec (f : R→ R) : Prop := ∀ x, f x =∇ splus x Suppose we try to write a program to compute the gradient of the softplus function as follows: def gsplus (x : R) : R := 1 / (1 + exp x) The application gsplus_spec gsplus represents the proposition that our implementation gsplus is correct, i.e. that it indeed computes the gradient of the softplus function for all inputs.
47	31	We can try to formally prove theorems in Lean interactively: theorem gsplus_correct : gsplus_spec gsplus := lean: ` gsplus_spec gsplus user: expand_def gsplus_spec, lean: ` ∀ x, gsplus x =∇ splus x user: introduce x, lean: x : R ` gsplus x =∇ splus x user: expand_defs [gsplus, splus], lean: x : R ` 1 / (1 + exp x) =∇ (λ x, log (1 + exp x)) x user: simplify_grad, lean: x : R ` 1 / (1 + exp x) = exp x / (1 + exp x) The lines beginning with lean show the current state of the proof as displayed by Lean, which at any time consists of a collection of goals of the form assumptions ` conclusion.
49	22	Here the simplify_grad tactic rewrites exhaustively with known gradient rules—in this case it uses the rules for log, exp, addition, constants, and the identity function.
51	41	Luckily the goal tells us exactly what gsplus x needs to return: gsplus x = exp x / (1 + exp x).
57	30	Stochastic computation graphs are directed acyclic graphs in which each node represents a specific computational operation that may be deterministic or stochastic (Schulman et al., 2015).
58	38	The loss function for a graph is defined to be the expected value of the sum of the leaf nodes over the stochastic choices.
61	38	The main purpose of the system is to take a program describing a stochastic computation graph and to run a randomized algorithm (stochastic backpropagation) that, in expectation, provably generates unbiased samples of the gradients of the loss function with respect to the parameters.
62	24	We now briefly describe the components of Certigrad, some of which have no analogues in traditional software systems.4 Mathematics libraries.
98	52	For mathematics, we define a Func n to be a functional that takes a realvalued function on Rn to a scalar: def Func (n : N) : Type := ∀ (f : Rn→ R), R The intended semantics is that if p : Func n represents a distribution on Rn, then p f is the expected value of f over p, i.e. Ex∼p[f(x)].
112	73	While conventional wisdom is that one would write their program before trying to prove it correct, the interactive proof process provides so much helpful information about what the system needs to do that we began working on the proof immediately after drafting the specification.
115	32	Second, we implemented a more performant version (that computed the gradient for multiple parameters simultaneously using memoization) and proved it equivalent to the first one.
116	42	For the first step, we started with a placeholder implementation that immediately returned zero and let the interactive proof process guide the implementation.
117	86	Whenever the proof seemed to require induction on a particular data structure, we extended the program to recurse on that data structure; whenever the proof showed that a branch of the program needed to return a value with a given expectation, we worked backwards from that to determine what value to return.
118	29	Proving the first step also exposed errors in our specification in the form of missing preconditions.
123	28	Luckily the process of proving necessarily exposes all implementation errors, and in this case made it clear how to fix both of them.
126	17	When we made our axioms sound and propagated the changes we found that our specification required two additional preconditions: that all functions that are integrated over in the theorem statement are indeed integrable (IntegralsExist g θ), and that the many preconditions needed for pushing the gradient over each integral in the expected loss are satisfied (CanDiffUnderInts g θ).
137	119	Even though we proved that bprop satisfies its formal specification (bprop_spec), we cannot be sure that it will compute the correct gradients for a particular model unless we prove that the model satisfies the preconditions of the specification.
138	37	Although some of the preconditions are technically undecidable, in practice most machine learning models will satisfy them all for simple reasons.
145	49	As an experiment, we trained an AEVB model with a 2-layer encoding network and a 2- layer decoding network on MNIST using the optimization procedure ADAM (Kingma & Ba, 2014), and compared both the expected loss and the running time of our system at each iteration against the same model and optimization procedure in TensorFlow, both running on 2 CPU cores.
149	20	Not only were we able to synthesize some fragments of the system (§4.5), we were able to achieve extremely high confidence that our system was bug-free without needing to think about how all the pieces of the system fit together.
153	123	For example, specifications need not cover functional correctness, not all theorems need to be proved, unsound axioms can be used that omit certain preconditions, and more traditional code can be wrapped and axiomatized (as we did with Eigen).
154	50	When developing Certigrad we pursued the ideal of a complete, machinecheckable proof of functional correctness, and achieved an extremely high level of confidence that the system was correct.
157	19	While a pure version of our methodology may already be cost-effective for high-assurance applications, we expect that pragmatic use of our methodology could yield many of the benefits for relatively little cost and could be useful for developing a wide range of machine learning systems to varying standards of correctness.

0	44	Real-time captioning provides deaf or hard of hearing people access to speech in mainstream classrooms, at public events, and on live television.
3	20	Unfortunately, professional captionists are quite expensive ($150 per hour), must be recruited in blocks of an hour or more, and are difficult to schedule on short notice.
5	69	However, the accuracy of ASR quickly plummets to below 30% when used on an untrained speaker’s voice, in a new environment, or in the absence of a high quality microphone (Wald, 2006b).
7	21	In this approach, multiple non-expert human workers transcribe an audio stream containing speech in real-time, and their partial input is combined to produce a final transcript (see Figure 1).
8	19	This approach has been shown to dramatically outperform ASR in terms of both accuracy and Word Error Rate (WER), even when using captionists drawn from Amazon’s Mechanical Turk.
9	58	Furthermore, recall approached and even exceeded that of a trained expert stenographer with seven workers contributing, suggesting that the information is present to meet the performance of a stenographer.
10	20	However, combining these captions i volves real-time alignment of partial captions that may be incomplete and that often have spelling errors and inconsistent timestamps.
13	27	Although word error rate (WER) is commonly used in speech recognition, it considers accuracy and completeness, not readability.
27	49	The problem of aligning and combining multiple transcripts can be mapped to the well-studied Multiple Sequence Alignment (MSA) problem (Edgar and Batzoglou, 2006).
30	20	The pairwise alignment problem can be solved efficiently using dynamic programming inO(N2) time and space, whereN is the sequence length.
33	68	Most MSA algorithms for biological sequences follow a progressive alignment strategy that first performs pairwise alignment among the sequences, and then builds a guide tree based on the pairwise similarity between these sequences (Edgar, 2004; Do et al., 2005; Thompson et al., 1994).
42	18	, SK ,K ≥ 2, be theK sequences over an alphabetΣ, and having length N1, .
47	52	Our goal is to find the optimum alignment matrixAOPT that minimizes the sum of pairs (SOP) cost function: c(A) = ∑ 1≤i≤j≤K c(Aij) (1) wherec(Aij) is the cost of the pairwise alignment betweenSi and Sj according toA.
62	36	Assuming the sequences have roughly same lengthN , the size of the dynamic programming matrix isO(NK).
68	22	The A∗ search can find the shortest path using a greedy Best First Search according to an evaluation function f(n), which is the summation of the cost func- tionsg(n) and the heuristic functionh(n) for node n. The cost functiong(n) denotes the cost of the shortest path from the sources to the current node n. The heuristic functionh(n) is the approximate estimated cost of the shortest path fromn to the destination t. At each step of the A∗ search algorithm, we extract the node with the smallestf(n) value from the priority queueQ and expand it by one edge.
71	100	One commonly used admissible heuristic function ishpair(n): hpair(n) = L(n→ t) = ∑ 1≤i<j≤K c(A∗p(σ n i , σ n j )) (2) whereL(n → t) denotes the lower bound on the cost of the shortest path fromn to destinationt, A∗p is the optimal pairwise alignment, andσni is the suffix of noden in the i-th sequence.
74	20	It may appear that we need to estimate the optimal pairwise alignment for all the pairs of suffix sequences at every node.
79	23	We modify the evaluation functionf(n) = g(n)+hpair(n) to a weighted evaluation functionf ′(n) = g(n) + whpair(n), where w ≥ 1 is a weight parameter.
96	27	For each node in the priority queue, for each of the O(2K) successor states, the objective function and heuristic estimation requiresO(K2) operations and each priority queue insertion requiresO(log(NbK)) i.e. O(logN + K log b) operations.
104	27	To filter out such spurious words, we apply a voting threshold (tv) during majority voting and filter out words having less thantv votes.
136	23	Each group was assigned two of the four audio clips, and each person evaluated all four captions for both clips.
138	89	Finally, we estimated the correlation coefficients (both Spearman and Pearson) for the three metrics discussed above with respect to the average score assigned by the human participants.
146	55	Each audio clip is transcribed by ten non-expert human workers in real-time.
147	58	We then combine these inputs using our MSA-A∗ algorithm, and also compare with the existing graph-based system and mul- 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.58 0.60 0.36 0.47 0.54 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.60 0.63 0.40 0.49 0.41 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.53 0.55 0.35 0.45 0.42 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.49 0.51 0.26 0.36 0.30 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.53 0.55 0.44 0.39 0.37 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.56 0.56 0.45 0.39 0.19 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.43 0.44 0.41 0.35 0.23 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.43 0.46 0.36 0.29 0.09 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.62 0.64 0.53 0.47 0.55 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.63 0.63 0.53 0.45 0.44 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.52 0.54 0.49 0.43 0.39 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.53 0.56 0.46 0.38 0.35 (1.0-WER) BLEU Score F-Measure D a ta S e t 1 D a ta S e t 2 D a ta S e t 3 D a ta S e t 4 A*-10-t (c=10 sec, threshold=2) A*-15-t (c=15 sec, threshold=2) A*-15 (c=15 sec, no threshold) Graphbased MUSCLE Figure 4: Evaluation of different systems on using three different automated metrics for measuring transcription quality: 1- Word Error Rate (WER), BLEU, and Fmeasure on the four audio clips.
149	31	As explained earlier, we vary the four key parameters of the algorithm: the chunk size (c), the heuristic weight (w), the voting threshold (tv), and the beam size (b).
150	182	The heuristic weight and chunk size parameters help us to trade-off between speed versus accuracy; the voting thresholdtv helps improve precision by pruning words having less than tv votes, and beam size reduces the search space by restricting states to be inside a time window/beam.
155	41	Out of the five systems in Figure 4, the first three are different versions of our A∗ search based MSA algorithm with different parameter settings: 1) A∗10-t system (c = 10 seconds,tv = 2), 2) A∗-15-t (c = 15 seconds,tv = 2), and 3) A∗-15 (c = 15 seconds,tv = 1 i.e. no pruning while voting).
156	29	For all three systems, the heuristic weight parameterw is set to 2.5 and beam sizeb = 20 seconds.
165	42	The average time to align each 15 second chunk with 10 input captions is∼400 milliseconds.
169	30	This could explain why language model did not improve accuracy, as it does for speech recognition.

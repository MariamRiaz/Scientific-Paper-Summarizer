20	31	Using our estimates of the error probabilities in weighted majority votes, we also provide strategies to estimate ground-truth labels of the tasks.
22	66	We first describe a general model for crowdsourcing with non-adaptive workers and binary classification tasks: there are n workers w1, .
25	21	If wj is presented with xi, that is gij = 1, wj provides an estimate wj(xi) ∈ {−1,+1} of the ground-truth label yi.
26	13	Let A ∈ {−1, 0,+1}m×n be a matrix that stores all the responses collected from the workers: Aij = wj(xi) if gij = 1 and Aij = 0 if gij = 0.
29	33	Let εwj (x, y) ∈ [0, 1] be the conditional error probability that, given x and y, wj(x) does not equal y, that is εwj (x, y) := Prwj |(x,y)[wj(x) 6= y | (x, y)].
31	22	Now one may study the following questions: (i) Given only the matrix A, how can we estimate the ground-truth labels y1, .
35	46	With this paper we initiate the study of a significant extension of the one-coin model.
36	43	We will allow almost half of the workers to deviate from the one-coin model and for such a worker wj , the conditional error probability εwj (x, y) to be a completely arbitrary random variable.
41	12	In this section we want to present the general outline of our approach.
46	33	(3) This suggests to solve the system of equations 1− εj − εk + 2εjεk + 2cjk = pjk, 1 ≤ j < k ≤ n, (4) in the unknowns εl, l ∈ [n], and cjk, 1 ≤ j < k ≤ n, in order to obtain estimates of the workers’ unconditional error probabilities εw1 , .
48	18	We will assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities smaller than one half.
67	12	For example, if pjk = 1 for all 1 ≤ j < k ≤ n, there are the two solutions εl = 0, l ∈ [n], and εl = 1, l ∈ [n], corresponding to either all perfect or all completely erroneous workers.
68	16	On the other hand, the system (7) is identifiable if we assume that on average workers are better than random guessing, that is 1 n ∑n j=1 εwj < 1 2 , and there are at least three informative workers with εwj 6= 12 (Bonald & Combes, 2017).
79	13	Hence, a necessary condition for a solution to correspond to actual workers is that |cjk| ≤ (εj−ε 2j )1/2(εk−ε 2k )1/2 (in addition to εl ∈ [0, 1]).
81	13	From now on we assume that at least n2 + 2 workers follow the one-coin model and have error probabilities smaller than one half:2 Assumption A.
82	22	There exists L ⊆ [n] with |L| ≥ n/2 + 2 such that for all j ∈ L, the worker wj follows the one-coin model with error probability εwj < 1/2.
84	17	The system (4) together with (6) is identifiable: Proposition 1.
92	42	Our goal is then to find a solution of (4) that satisfies (6) approximately and to show that our approximate solution has to be close to εw1 , .
94	32	If there exist two solutions (εSil )l∈[n], (c Si jk )1≤j<k≤n, i ∈ {1, 2}, of system (4) (where pjk ∈ [0, 1]) with the property that εSil ∈ [0, 1], l ∈ [n], and ∃Li ⊆ [n] with |Li| ≥ n/2 + 2 such that ∀j ∈ Li : ( εSij ≤ γ ∧ [ ∀k 6= j : |c Sijk | ≤ ν ]) , (8) then∣∣εS1l − εS2l ∣∣ ≤ G(γ, ν)√ν, ∣∣c S1jk − c S2jk ∣∣ ≤ 3G(γ, ν)√ν for l ∈ [n], j < k, where G(γ, ν)→ G(γ) > 0 as ν → 0.
97	19	In this case, assuming that estimates pjk are close to true agreement probabilities, we can construct a solution of (4) that is guaranteed to be close to the true error probabilities and covariances (and hence approximately satisfies (6)).
103	36	(11) If all expressions are defined (i.e., B > 0, B + 4C ≥ 0 and εSi2 6= 1 2 ), then (ε S l )l∈[n], (c S jk)1≤j<k≤n is a solution of (4) with pjk as right-hand side.
125	31	We set Qp = [n] unless γ as specified in (13) is smaller than one, in which case we set Qp = {l ∈ [n] : εSl (p) ≤ γ} and discard any solution (εSl (p))l∈[n], (c S jk(p))1≤j<k≤n for which |Qp| < n2 + 2.
155	18	If the number of workers n is small, this is the best one can do.
166	55	On both synthetic and real data, we compared our proposed Algorithm 1 to straightforward majority voting for predicting labels (referred to as Maj) and the following methods from the literature: the spectral algorithms by Ghosh et al. (2011) (GKM), Dalvi et al. (2013) (RoE and EoR) and Karger et al. (2013) (KOS), the two-stage procedure by Algorithm 1 Input: crowdsourced labels stored in A ∈ {−1, 0,+1}m×n, upper bound 0 < γTR < 12 on the error probabilities of dn2 + 2e workers that follow the one-coin model, confidence parameter 0 < δ < 1 Output: estimates (εFl )l∈[n], (c Fjk )j<k, (ŷi)i∈[m] of error probabilities, covariances and ground-truth labels I Estimating agreement probabilities set gij = 1{Aij 6= 0}, i ∈ [m], j ∈ [n] set qjk = ∑m i=1 gijgik, j, k ∈ [n] set pjk as in (3), j, k ∈ [n] (pjk = NaN if qjk = 0) I Estimating error probabilities and covariances set β = [ ln(2n2/δ)/ ( 2 minj,k∈[n] qjk )]1/2 ∈ (0,+Inf ] set γ as in (13) if γ /∈ [0, 1] then set γ = 1 end if set P = { (i1, i2, i3) : i1, i2, i3 ∈ [n] pairwise different and qjk ≥ 10, j, k ∈ {i1, i2, i3}, and qi2j ≥ 3, j 6= i2 } set νold = Inf, (εFl )l∈[n] = 0, (c F jk )1≤j<k≤n = 0, L = ∅ for (i1, i2, i3) ∈ P do if not all expressions in (10) or (11) are defined then break end if compute (εSl )l∈[n], (c S jk)1≤j<k≤n as in (10) and (11) set Q = {l ∈ [n] : εSl ≤ γ} set ν = dn2 + 2e-th smallest element of {maxk∈[n]\{l} |c Slk | : l ∈ Q} (ν = NaN ifQ = ∅) if |Q| ≥ n2 + 2 AND ν < νold then set (εFl )l∈[n] = (ε S l )l∈[n], (c F jk )j<k = (c S jk)j<k set L = {l ∈ Q : maxk∈[n]\{l} |c Slk | ≤ ν} set νold = ν end if end for I Estimating ground-truth labels set f(ε̂wl) = ln ((1− ε̂wl)/ε̂wl) ∈ [−Inf,+Inf], l ∈ L, and f(ε̂wl) = 0, l ∈ [n] \ L (alternatively set f(ε̂wl) = 1− 2ε̂wl , l ∈ [n]) set ŷi as in (16), i ∈ [m] Zhang et al. (2016) (S-EM1 and S-EM10, where we run one or ten iterations of the EM algorithm) and the recent method by Bonald & Combes (2017) (TE).
172	13	In the following, all results are average results obtained from running an experiment for 100 times.
173	35	In our first experiment, we consider n = 50 workers and m = 5000 tasks with balanced ground-truth labels.
217	14	Our Algorithm 1 can compete with the other methods, and on four out of the six data sets, the prediction error of Alt-Alg.
228	52	It would also be interesting to see whether our approach can be extended to multiclass classification problems.
229	21	Another direction concerns improving the sufficient rate m ∼ ρ−8 , which we obtained for our algorithm for recovering worker qualities up to error ρ.
230	20	In the absence of adversaries one can achieve a rate m ∼ ρ−2, and we would like to understand whether this gap is inherent or an artifact of our algorithm/proof.

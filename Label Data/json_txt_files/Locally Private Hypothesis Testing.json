{"sections": [{"heading": "1. Introduction", "text": "Differential privacy is a mathematically rigorous notion of privacy that has become the de-facto gold-standard of privacy preserving data analysis. Informally, -differential privacy bounds the affect of a single datapoint on any result of the computation by . In recent years the subject of private hypothesis testing has been receiving increasing attention (see Related Work below). However, by and large, the focus of private hypothesis testing is in the centralized model (or the curated model), where a single trusted entity holds the sensitive details of n users and runs the private hypothesis tester on the actual data.\n1Dept. of Computing Science, University of Alberta.. Correspondence to: Or Sheffet <osheffet@ualberta.ca>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nIn contrast, the subject of this work is private hypothesis testing in the local-model (or the distributed model), where a -differentially private mechanism is applied independently to each datum. This model, which alleviates trust (each user can run the mechanism independently on her own and release the noisy signal from the mechanism), has gained much popularity in recent years, especially since it was adopted by Google\u2019s Rappor (Erlingsson et al., 2014) and Apple (Apple, 2017). And yet, despite its popularity, and the fact that recent works (Bassily & Smith, 2015; Bassily et al., 2017) have shown the space of possible locally-private mechanism is richer than what was originally thought, little is known about private hypothesis testing in the local-model."}, {"heading": "1.1. Background: Local Differential Privacy", "text": "We view the local differentially private model as a signaling scheme. Each datum / user has a type x taken from a predefined and publicly known set of possible types X whose size is T = |X |. The differentially private mechanism is merely a randomized function M : ([n],X ) \u2192 S, mapping each possible type X of the i-th datum to some set of possible signals S, which we assume to be -differentially private: for any index i, any pair of types x, x\u2032 \u2208 X and any signal s \u2208 S it holds that Pr[M(i, x) = s] \u2264 e Pr[M(i, x\u2032) = s].1 In our most general results (Theorems 1 and 9), we ignore the fact thatM is -differentially private, and just refer to any signaling scheme that transforms one domain (namely, X ) into another (S). For example, a surveyer might unify rarely occurring types under the category of \u201cother\u201d, or perhaps users report their types over noisy channels, etc.\nWe differentiate between two types of signaling schemes: the symmetric (or index-oblivious) variety, and the nonsymmetric (index-aware) type. A local signaling mechanism is called symmetric if it is independent of the index of the datum. Namely, if for any i 6= j we have that M(i, x) = M(j, x) def= M(x). A classic exam-\n1For simplicity, we assume S, the set of possible signals, is discrete. Note that this doesn\u2019t exclude mechanisms such as adding Gaussian/Gamma noise to a point in Rd \u2014 such mechanisms require X to be some bounded subset of Rd and use the bound to set the noise appropriately. Therefore, the standard approach of discretizing X and projecting the noisy point to the closest point in the grid yields a finite set of signals S.\nple of such a mechanism is randomized-response \u2014 that actually dates back to before differential privacy was defined (Warner, 1965) and was first put to use in differential privacy in (Kasiviswanathan et al., 2008) \u2014 where each user / datum x draws her own signal from the set S = X skewing the probability ever-so-slightly in favor of the original type. I.e. if the user\u2019s type is x then\nM(x) =\n{ x, w.p. e\nT\u22121+e\nx\u2032, for any other x\u2032 w.p. 1T\u22121+e .\nThe utility of the above-mentioned symmetric mechanism scales polynomially with T (or rather, with |S|), which motivated the question of designing local mechanisms with error scaling logarithmically in T . This question was recently answered in the affirmative by the works of Bassily and Smith (2015) and Bassily et al (2017), whose mechanisms are not symmetric. In fact, both of them work by presenting each user i with a mapping fi : X \u2192 S (the mapping itself is chosen randomly, but it is public, so we treat it as a given), and the user then runs the standard randomized response mechanism on the signals using fi(x) as the more-likely signal. (In fact, in both schemes, S = {1,\u22121}: in (Bassily & Smith, 2015) fi is merely the j-th coordinate of a hashing of the types where j and the hashing function are publicly known, and in (Bassily et al., 2017) fi maps a u.a.r chosen subset of X to 1 and its complementary to \u22121.2) So given fi, the user then tosses her own private random coins to determine what signal she broadcasts. Therefore, each user\u2019s mechanism can be summarized in a |S| \u00d7 |X |-matrix, where Mi(s, x) is the probability a user of type x sends the signal s. For example, using the mechanism of (Bassily et al., 2017), each user whose type maps to 1 sends \u201csignal 1\u201d with probability e\n1+e and \u201csignal \u22121\u201d with probability 1 1+e . Namely, Mi(fi(x), x) = e 1+e andMi(\u2212fi(x), x) = 1\n1+e , where fi is the mapping X \u2192 {1,\u22121} set for user i."}, {"heading": "1.2. Our Contribution and Organization", "text": "This work initiates (to the best of our knowledge) the theory of differentially private hypothesis testing in the local model. First we survey related work and preliminaries. Then, in Section 3, we examine the symmetric case and show that any mechanism (not necessarily a differentially private one) yields a distribution on the signals for which finding a maximum-likelihood hypothesis is feasible, assuming the set of possible hypotheses is convex. Then, focusing on the classic randomized-response mechanism, we show that the problem of maximizing the likelihood of the observed signals is strongly-convex and thus simpler than the original problem. More importantly, in essence\n2In both works, much effort is put to first reducing T to the most frequent \u221a n types, and then run the counting algorithm. Regardless, the end-counts / collection of users\u2019 signals are the ones we care for the sake of hypothesis testing.\nwe give a characterization of hypothesis testing under randomized response: the symmetric locally-private mechanism translates the original null hypothesis H0 (and the alternative H1) by a known affine translation into a different set \u03d5(H0) (and resp. \u03d5(H1)). Hence, hypothesis testing under randomized-response boils to discerning between two different (and considerably closer in total-variation distance) sets, but in the exact same model as in standard hypothesis testing as all signals were drawn from the same hypothesis in \u03d5(H0). As an immediate corollary we give bounds on identity-testing (Corollary 5) and independencetesting (Theorem 6) under randomized-response. (The latter requires some manipulations and far less straightforward than the former.) The sample complexity (under certain simplifying assumptions) of both problems is proportional to T 2.5.\nIn Section 4 we move to the non-symmetric local-model. Again, we start with a general result showing that in this case too, finding an hypothesis that maximizes the likelihood of the observed signals is feasible when the hypothesis-set is convex. We then focus on the mechanism of Bassily et al (2017) and show that it also makes the problem of finding a maximum-likelihood hypothesis strongly-convex. We then give a simple identity tester under this scheme whose sample complexity is proportional to T 2, and is thus more efficient than any tester under standard randomized-response. Similarly, we also give an independence-tester with a similar sample complexity. In Section 4.2 we empirically investigate alternative identitytesting and independence-testing based on Pearson\u2019s \u03c72test in this non-symmetric scheme, and identify a couple of open problems in this regime."}, {"heading": "1.3. Related Work", "text": "Several works have looked at the intersection of differential privacy and statistics (Dwork & Lei, 2009; Smith, 2011; Chaudhuri & Hsu, 2012; Duchi et al., 2013a; Dwork et al., 2015) mostly focusing on robust statistics; but only a handful of works study rigorously the significance and power of hypotheses testing under differential privacy. Vu and Slavkovic (2009) looked at the sample size for privately testing the bias of a coin. Johnson and Shmatikov (2013), Uhler et al (2013) and Yu et al (2014) focused on the Pearson \u03c72-test (the simplest goodness of fit test), showing that the noise added by differential privacy vanishes asymptotically as the number of datapoints goes to infinity, and propose a private \u03c72-based test which they study empirically. Wang et al (2015) and Gaboardi et al (2016) who have noticed the issues with both of these approaches, have revised the statistical tests themselves to incorporate also the added noise in the private computation. Cai et al (2017) give a private identity tester based on noisy \u03c72-test over large bins, Sheffet (2017) studies private Ordinary Least Squares using the JL transform, and Karwa and Vadhan (2018) give\nmatching upper- and lower-bounds on the confidence intervals for the mean of a population. All of these works however deal with the centralized-model of differential privacy.\nPerhaps the closest to our work are the works of Duchi et al (2013a; 2013b) who give matching upper- and lowerbound on robust estimators in the local model. And while their lower bounds do inform as to the sample complexity\u2019s dependency on \u22122, they do not ascertain the sample complexity dependency on the size of the domain (T ) we get in Section 3. Moreover, these works disregard independence testing (and in fact (Duchi et al., 2013b) focus on mean estimation so they apply randomized-response to each feature independently generating a product-distribution even when the input isn\u2019t sampled from a product-distribution). And so, to the best of our knowledge, no work has focused on hypothesis testing in the local model, let alone in the (relatively new) non-symmetric local model. Lastly, developed concurrently to our work, Gaboardi and Rogers (2018) study the asymptotic power of a variety chi-squared based hypothesis testing in the local model."}, {"heading": "2. Preliminaries, Notation and Background", "text": "Notation. We user lower-case letters to denote scalars, bold characters to denote vectors and CAPITAL letters to denote matrices. So 1 denotes the number, 1 denotes the all-1 vector, and 1X\u00d7X denotes the all-1 matrix over a domain X . We use ex to denote the standard basis vector with a single 1 in coordinate corresponding to x. To denote the x-coordinate of a vector v we use v(x), and to denote the (x, x\u2032)-coordinate of a matrix M we use M(x, x\u2032). For a given vector v , we use diag(v) to denote the matrix whose diagonal entries are the coordinates of v . For any natural n, we use [n] to denote the set {1, 2, ..., n}.\nDistances and norms. Unless specified otherwise \u2016v\u2016 refers to the L2-norm of v , whereas \u2016v\u20161 refers to the L1-\nnorm. We also denote \u2016v\u2016 2 3\n= (\u2211\ni |vi| 2 3\n) 3 2\n. For a matrix, \u2016M\u20161 denotes (as usual) the maximum absolute column sum. We identify a distribution p over a domain X as a T -dimensional vector with non-negative entries that sum to 1. This defines the total variation distance between two distributions: dTV(p,q) = 12\u2016p \u2212 q\u20161. (On occasion, we will apply dTV to vectors that aren\u2019t distributions, but rather nearby estimations; in those cases we use the same definition: the half of the L1-norm.) It is known that the TV-distance is a metric overs distributions. We also use the \u03c72-divergence to measure difference between two distributions: d\u03c72(p,q) = \u2211 x (p(x)\u2212q(x))2 p(x) = (\u2211 x (q(x))2 p(x) ) \u2212 1. The \u03c72-divergence is not symmetric and can be infinite, however it is non-negative and zeros only when p = q . We refer the reader to (Sason & Verdu\u0301, 2016) for more properties of the total-variance distance the \u03c72-divergence.\nDifferential Privacy. An algorithm A is called - differentially private, if for any two datasets D and D\u2032 that differ only on the details of a single user and any set of outputsO, we have that Pr[A(D) \u2208 O] \u2264 e Pr[A(D\u2032) \u2208 O]. The unacquainted reader is referred to the Dwork-Roth monograph (Dwork & Roth, 2014) as an introduction to the rapidly-growing field of differential privacy.\nHypothesis testing. The problem of hypothesis testing is to test whether a given set of samples was drawn from a distribution satisfying the null-hypothesis or the alternativehypothesis. Thus, the null-hypothesis is merely a set of possible distributions H0 and the alternative is disjoint set H1. Hypothesis tests boils down to estimating a teststatistic \u03b8 whose distribution has been estimated under the null-hypothesis. We can thus reject the null-hypothesis if the value of \u03b8 is highly unlikely, or accept the nullhypothesis otherwise. We call an algorithm a tester if the acceptance (in the completeness case) or rejection (in the soundness case) happen with probability \u2265 2/3. Standard amplification techniques (return the median of independent tests) reduce the error probability from 1/3 to any \u03b2 > 0 at the expense of increasing the sample complexity by a factor of O(log(1/\u03b2)); hence we focus on achieving a constant error probability. One of the most prevalent and basic tests is the identity-testing, where the null-hypothesis is composed of a single distribution H0 = {p} and our goal is to accept if the samples are drawn from p and reject if they were drawn from any other \u03b1-far (in dTV) distribution. Another extremely common tester is for independence when X is composed of several features (i.e., X = X 1 \u00d7X 2 \u00d7 ...\u00d7X d) and the null-hypothesis is composed of all product distributions H0 = {p1 \u00d7 ... \u00d7 pd} where each pj is a distribution on the jth feature X j .\nMiscellaneous. We use M 0 to denote that M is a positive semi-definite (PSD) matrix, and M N to denote that (M \u2212 N) 0. We use M\u2020 to denote M \u2019s pseudoinverse. We emphasize that we made no effort to minimize constants in our proofs, and only strived to obtain asymptotic bounds (O(\u00b7),\u2126(\u00b7))."}, {"heading": "3. Symmetric Signaling Scheme", "text": "Recall, in the symmetric signaling scheme, each user\u2019s type is mapped through a random functionM into a set of signals S. This mapping is index-oblivious \u2014 each user of type x \u2208 X , sends the signal s with the same probability Pr[M(x) = s]. We denote the matrixG as the (|S|\u00d7|X |)- matrix whose entries are Pr[M(x) = s], and its sth-row by gs. Note that all entries of G are non negative and that for each x we have \u2016Gex\u20161 = 1. By garbling each datum i.i.d, we observe the new dataset (y1, y2, ..., yn) \u2208 Sn.\nTheorem 1. For any convex setH of hypotheses, the problem of finding the max-likelihood p \u2208 H generating the observed signals (y1, .., yn) is poly-time solvable.\nProof. Since G(s, x) describes the probability that a user of type x sends the signal s, any distribution p \u2208 H over the types in X yields a distribution on S where Pr[user sends s] = \u2211 x\u2208X G(s, x) \u00b7 p(x) = gTsp. Therefore, given signals (y1, ..., yn) summarized as a signalshistogram \u3008ns\u3009s\u2208S , the likelihood of these signals is given by: L(p; y1, ..., yn) = \u220f i g T yip = \u220f s\u2208S(g T s p) ns =\nexp (\u2211 s ns log(g T sp) ) . Thus, the gradient of the negative\nlog-loss function is\u2207f = \u2212 1n \u2211 s\u2208S ns gTsp \u00b7gs, and its Hes-\nsian is given by the matrix 1n \u2211 s\u2208S ns (gTsp) 2gsg T s . Clearly, as a non-negative sum of rank-1 matrices, the Hessian is a PSD matrix.so our loss-function is convex. Known polytime algorithms for minimizing a convex function over a convex set (e.g. (Zinkevich, 2003)) conclude the proof.\nUnfortunately, in general the solution to this problem has no closed form (to the best of our knowledge). However, we can find a close-form solution under the assumption that G isn\u2019t just any linear transformation but rather one that induces probability distribution over S, the assumption that |S| \u2264 |X | (in all applications we are aware of use fewer signals than user-types) and one extra-condition.\nCorollary 2. Let q\u2217 be the |S|-dimensional vector given by \u3008nsn \u3009. Given that |S| \u2264 |X |, that G is a full-rank matrix satisfying \u2016G\u20161 = 1 and assuming that ( G\u2020q\u2217+ker(G) ) \u2229 H 6= \u2205, then any vector inH of the form p\u2217+u where p\u2217 = G\u2020q\u2217 and u \u2208 ker(G) is an hypothesis that maximizes the likelihood of the given signals (y1, ..., yn). Proof deferred to the supplementary material, Section B."}, {"heading": "3.1. Hypothesis Testing under Randomized-Response", "text": "We now aim to check the affect of a particular G, the one given by the randomized-response mechanism. In this case S = X and we denote G as the matrix whose entries are\nG(x, x\u2032) = { \u03c1+ \u03b3 , if x\u2032 = x \u03c1 , otherwise where \u03c1 def= 1T\u22121+e\nand \u03b3 def= e \u22121\nT\u22121+e . We get that G = \u03c1 \u00b7 1X\u00d7X + \u03b3I (where 1X\u00d7X is the all-1 matrix). In particular, all vectors gs = gx, which correspond to the rows of G, are of the form: gx = \u03c11 + \u03b3ex. It follows that for any probability distribution p \u2208 H we have that Pr[seeing signal x] = gTxp = \u03c1+ \u03b3p(x). We have therefore translated any p \u2208 H (over X ) to an hypothesis q over S (which in this case S = X ), using the affine transformation \u03d5(p) = \u03c11 +\u03b3p = T\u03c1uX +\u03b3p when uX denotes the uniform distribution over X . (Indeed, \u03b3 = 1 \u2212 T\u03c1, an identity we will often apply.) At the risk of overburdening notation, we use \u03d5 to denote the same transformation over scalars, vectors and even sets (applying \u03d5 to each vector in the set). Since \u03d5 is injective, we have therefore discovered the following theorem.\nTheorem 3. Under the classic randomized response mechanism, testing for any hypothesis H0 (or for comparing H0 against the alternative H1) of the original distribution,\ntranslates into testing for hypothesis \u03d5(H0) (or \u03d5(H0) against \u03d5(H1)) for generating the signals y1, ..., yn. Theorem 3 seems very natural and simple, and yet (to the best of our knowledge) it was never put to words.\nMoreover, it is simple to see that under standardrandomized response, our log-loss function is in fact strongly-convex, and therefore finding p\u2217 becomes drastically more efficient (see, for example (Hazan et al., 2006)).\nClaim 4. Given signals y1, ..., yn generated using standard randomized response with parameter < 1, we have that our log-loss function is \u0398( 2 \u00b7 minx{nx}n )-strongly convex. Note that in expectation nx \u2265 \u03c1n, hence with overwhelming probability we have minx nx \u2265 n/(2T ). The proof is fairly straight-forward and is deferred to the supplementary material, Section B.\nA variety of corollaries follow from Theorem 3. In particular, a variety of detailing matching sample complexity upper- and lower-bounds translate automatically into the realm of making such hypothesis-tests over the outcomes of the randomized-response mechanism. We focus here on two of the most prevalent tests: identity testing and independence testing.\nIdentity Testing. Perhaps the simplest of the all hypothesis testing is to test whether a given sample was generated according to a given distribution or not. Namely, the null hypothesis is a single hypothesis H0 = {p}, and the alternative is H1 = {q : dTV(p,q) \u2265 \u03b1} for a given parameter \u03b1. The seminal work of Valiant and Valiant (2014) discerns that (roughly) \u0398(\u2016p\u2016 2\n3 /\u03b12) samples are sufficient\nand are necessary for correctly rejecting or accepting the null-hypothesis w.p.\u2265 2/3.3\nHere, the problem of identity testing under standard randomized response reduces to the problem of hypothesis testing between \u03d5(H0) = {\u03c11 + \u03b3p : p \u2208 H0} and \u03d5(H1) = {\u03d5(q) : q satisfying dTV(p,q) \u2265 \u03b1}. Corollary 5. In order to do identity testing under standard randomized response with confidence and power \u2265 2/3, it is necessary and sufficient that we get \u0398( T 2.5\n2\u03b12 ) samples. The proof uses the results of (Valiant & Valiant, 2014) as a black-box and is mainly composed of calculations, so it is deferred to supplementary material, Section B.\nIndependence Testing. Another prevalent hypothesis testing over a domain X where each type is composed of multiple feature is independence testing. Denoting X = X 1 \u00d7 X 2 \u00d7 ... \u00d7 X d as a domain with d possible features (hence T = |X | = \u220f j |X j | def = \u220f j T\nj), our goal is to discern whether an observed sample is drawn from a product distribution or a distribution \u03b1-far from any product distri-\n3For the sake of brevity, we ignore pathological examples where by removing \u03b1 probability mass from p we obtain a vector of significantly smaller 2\n3 -norm.\nbution. In particular, the null-hypothesis in this case is a complex one: H0 = {p\u0304 = p1\u00d7p2\u00d7 ...\u00d7pd} and the alternative is H1 = {q : minp\u0304\u2208H0 dTV(q, p\u0304) \u2265 \u03b1}. To the best of our knowledge, the (current) tester with smallest sample complexity is of Acharya et al (2015), which requires \u2126 ( ( \u221a T + \u2211 j T j)/\u03b12 ) iid samples.\nWe now consider the problem of testing for independence under standard randomized response. Our goal is to prove the following theorem. Theorem 6. There exists an algorithm that takes n =\n\u2126\u0303( T 2\n\u03b12 2\n( d2(max\nj {T j})2 +\n\u221a T ) ) signals generated by\napplying standard randomized response (with < 1) on n samples drawn from a distribution p and with probability \u2265 2/3 accepts if p \u2208 H0, or rejects if p \u2208 H1. Moreover, no algorithm can achieve such guarantee using n = o(T 5/2/(\u03b12 2)) signals. Note there are at least two types per feature, so d \u2264 log2(T ). Should all T\njs be equal we have (T j)2 \u2264 T 2d , making T 2.5/(\u03b12 2) the leading term in the above bound.\nProof. Theorem 3 implies we are comparing \u03d5(H0) = {\u03c11X+\u03b3(p1\u00d7...\u00d7pd)} to \u03d5(H1) = {\u03c11X+\u03b3q : q \u2208 H1}. Note that \u03d5(H0) is not a subset of product-distributions over X but rather a convex combination (with publicly known weights) of the uniform distribution and H0; so we cannot run the independence tester of Acharya et al on the signals as a black-box. Luckily it holds that \u03d5(H1) is far from all distributions in \u03d5(H0): for each q \u2208 H1 and p\u0304 \u2208 H0 we have dTV(\u03d5(q), \u03d5(p\u0304)) \u2265 \u03b3dTV(q, p\u0304) \u2265 \u03b3\u03b1. And so we leverage on the main result of Acharya et al ((2015), Theorem 2): we first find a distribution \u03c11 + \u03b3z\u0304 \u2208 \u03d5(H0) such that if the signals were generated by some \u03c11X + \u03b3p\u0304 \u2208 \u03d5(H0) then d\u03c72(\u03d5(z\u0304), \u03d5(p\u0304)) \u2264 \u03b32\u03b12/500, and then test if indeed the signals are likely to be generated by a distribution close to \u03d5(z\u0304) using Acharya et al\u2019s algorithm. We now give our procedure for finding the product-distribution z\u0304 .\nPer feature j, given the jth feature of the signals yj1, ..., y j n where each xj \u2208 X j appears nxj times, our procedure for finding zj is as follows.\n0. (Preprocessing:) Denote \u03c4 = \u03b1/(10d \u00b7 T j). We call any type xj where nxjn \u2264 1\u2212\u03b3 T j + \u03b3\u03c4 as small and\notherwise we say type xj is large. Ignore all small types, and learn zj only over large types. (For brevity, we refer to n as the number of signals on large types and T j as the number of large types.)\n1. Set the distribution z\u0303j as the \u201cadd-1\u201d estimator of Kamath et al (2015) for the signals: z\u0303j(xj) = 1+nxjT j+n .\n2. Compute zj = 1\u03b3 ( I \u2212 1\u2212\u03b3T j 1X j ) z\u0303j .\nOnce zj is found for each feature j, set z\u0304 = z1 \u00d7 ... \u00d7 zd run the test of Acharya et al (2015) (Theorem 2) with \u03d5(z\u0304) looking only at the large types from each feature, setting\nthe distance parameter to \u03b1\u03b32 and confidence 1 9 , to decide whether to accept or reject.\nIn order to successfully apply the Acharya et al\u2019s test, a few conditions need to hold. First, the provided distribution \u03d5(z\u0304) should be close to \u03d5(H0). This however hold trivially, as z\u0304 is a product-distribution. Secondly, we need that \u03d5(z\u0304) and \u03d5(p\u0304) to be close in \u03c72-divergence, as we argue next.\nLemma 7. Suppose that n, the number of signals, is at least \u2126( d 2\n\u03b12\u03b32 maxj{T j}). Then the above procedure cre-\nates distributions zj such that the product distribution z\u0304 = z1\u00d7z2\u00d7 ...\u00d7zd satisfies the following property. If the signals y1, ..., yn were generated by \u03d5(p\u0304) for some productdistribution p\u0304 = p1 \u00d7 ... \u00d7 pd, then w.p. \u2265 8/9 we have that d\u03c72(\u03d5(z\u0304), \u03d5(p\u0304)) \u2264 \u03b32\u03b12/1000. We table the proof of Lemma 7 to Section B in the supplementary material. Next, either completeness or soundness must happen: either the signals were taken from randomized-response on a product distribution, or they were generated by a distribution \u03b3\u03b1/2-far from \u03d5(H0). If no type of any feature was deemed as \u201csmall\u201d, this condition clearly holds; but we need to argue this continues to hold even when we run our tester on a strict subset of X composed only of large types in each feature. Completeness is straight-forward: since we remove types feature by feature, the types now come from a product distribution p\u0304large = p 1 large \u00d7 ... \u00d7 pdlarge where each pjlarge is a restriction of p j to the large types of feature j. Soundness however is more intricate. We partition X into two subsets: AllLarge = {(x1, x2, ..., xd) \u2208 X : \u2200j, xj is large} and Rest = X \\AllLarge; and break q into q = \u03b7qRest + (1\u2212 \u03b7)qAllLarge, with \u03b7 = Prq [Rest]. Claim 8 (proof deferred to the supplementary material) argues that \u03b7 < \u03b12 . Therefore, dTV(q, qAllLarge) \u2264 \u03b1 2 , implying that dTV(\u03d5(qAllLarge), \u03d5(H0)) > \u03b1 \u00b7 \u03b3\u2212 \u03b1\u03b32 = \u03b1\u03b3 2 . Claim 8. Assume the underlying distribution of the samples is q and that the number of signals is at least n = \u2126( d2(maxj T j)2\n\u03b12\u03b32 log(dmaxj T j)). Then w.p. \u2265 8/9 our\npreprocessing step marks certain types each feature as \u201csmall\u201d such that the probability (under q) of sampling a type (x1, x2, ..., xd) such that \u2203j, xj is small is \u2264 \u03b1/2. So, given that both Lemma 7 and Claim 8 hold, we can use the test of Acharya et al, which requires a sample of size n = \u2126( \u221a T/(\u03b1\u03b3)2). Recall that < 1 so \u03b3 = \u0398( /T ), and we get that the sample size required for the last test is n = \u2126( T 2.5\n\u03b12 2 ). Moreover, for this last part, the lower bound in Acharya et al (2015) still holds (for the same reason it holds in the identity-testing case): the lower bound is derived from the counter example of testing whether the signals were generated from the uniform distribution (which clearly lies in \u03d5(H0)) or any distribution from a collection of perturbations which all belong to \u03d5(H1) (See (Paninski, 2008) for more details). Each of distribution is thus \u03b3\u03b1-far from \u03d5(H0) and so any tester for this particular construc-\ntion requires \u221a T/(\u03b1\u03b3)2-many samples. This proves both the upper- and lower-bounds of Theorem 6."}, {"heading": "4. Non-Symmetric Signaling Schemes", "text": "Let us recall the non-symmetric signaling schemes in (Bassily & Smith, 2015; Bassily et al., 2017). Each user, with true type x \u2208 X , is assigned her own mapping (the mapping is broadcast and publicly known) fi : X \u2192 S . This sets her inherent signal to fi(x), and then she runs standard (symmetric) randomized response on the signals, making the probability of sending her true signal fi(x) to be e -times greater than any other signal s 6= fi(x).\nIn fact, let us allow an even broader look. Each user is given a mapping fi : X \u2192 S, and denoting (like before) T = |X | and S = |S|, we identify this mapping with a (S \u00d7 T )-matrix Gi. The column gxi = Giex is the probability distribution that a user of type x is going to use to pick which signal she broadcasts. (And so the guarantee of differential privacy is that for any signal s \u2208 S and any two types x 6= x\u2032 we have that gxi (s) \u2264 e gx \u2032\ni (s).) Therefore, all entries in Gi are non-negative and \u2016Gi\u20161 = 1 for all is.\nSimilarly to the symmetric case, we first exhibit the feasibility of finding a maximum-likelihood hypothesis given the signals from the non-symmetric scheme. Since we view which signal in S was sent, our likelihood mainly depends on the row vectors gsi . We prove the following theorem, proof deferred to Section C in the supplementary material.\nTheorem 9. For any convex set H , the problem of finding the max-likelihood p \u2208 H generating the observed nonsymmetric signals (y1, .., yn) is poly-time solvable."}, {"heading": "4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms", "text": "Let us recap the differentially private scheme of Bassily et al (2017). It this scheme, the mechanism uses solely two signals S = {1,\u22121} (so S = 2). For every i the mechanism sets Gi by picking u.a.r for each x \u2208 X which of the two signals in S is more likely; the chosen signal gets a probability mass of e\n1+e and the other get probability mass of 11+e . We denote \u03b7 as the constant such that 1 2 + \u03b7 = e\n1+e and 1 2 \u2212 \u03b7 = 1 1+e ; namely \u03b7 = e \u22121 2(e +1) =\n\u0398( ) when < 1. Thus, for every s \u2208 {1,\u22121} the row vector gsi is chosen such that each coordinate is chosen iid and uniformly from { 12 + \u03b7, 1 2 \u2212 \u03b7}. (Obviously, there\u2019s dependence between g1i and g \u22121 i , as g 1 i + g \u22121 i = 1, but the distribution of g1i is identical to the one of g \u22121 i .)\nFirst we argue that for any distribution p, if n is sufficiently large then w.h.p over the generation of theGis and over the signals we view from each user, then finding p\u0302 which maximizes the likelihood of the observed signals yields a good approximation to p. To that end, it suffices to argue that the function we optimize is Lipfshitz and strongly-convex.\nLemma 10. Fix \u03b4 > 0 and assume that the number of signals we observe is n = \u2126(T 3 log(1/\u03b4)). Then w.p.\u2265 1\u2212 \u03b4 it holds that the function f(p) we optimize (as given in\nEquation (1)) is ( 3 \u221a T ) -Lipfshitz and ( \u03b72\n2\n) -strongly con-\nvex over the subspace {x : xT1 = 0} (all vectors orthogonal to the all-1 vector). The proof of Lemma 10 \u2014 which (in part) is hairy due to the dependency between the matrix Gi and the signal yi \u2014 is deferred to Section C in the supplementary material.\nIdentity Testing. Designing an Identity Test based solely on the maximum-likelihood is feasible, due to results like Cesa-Binachi et al (2002) which allow us to compare between the risk of the result p\u0303 of a online gradient descent algorithm to the original distribution p which generated the signals. Through some manipulations one can (eventually) infer that |f(p) \u2212 f(p\u0303)| = O(1/ \u221a n). However, since strong-convexity refers to the L2-norm squared of \u2016p \u2212 p\u0303\u2016, we derive the resulting bound is \u2016p \u2212 p\u0303\u201621 \u2264 T\u2016p \u2212 p\u0303\u201622 = O( 1\u03b72\u221an ), which leads to a sample complexity bound proportional to T 3/(\u03b1\u03b7)4. This bound is worse than the bounds in Section 3.\nWe therefore design a different, simple, identity tester in the local non-symmetric scheme, based on the estimator given in (Bassily et al., 2017). The tester itself \u2014 which takes as input a given distribution p, a distance parameter \u03b1 > 0 and the n signals \u2014 is quite simple.\n1. Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator \u03b8 = 1n \u2211 i 1 \u03b7 ( gyii \u2212 121 ) .\n2. If dTV( 12\u03b7\u03b8,p) \u2264 \u03b1 2 then accept, else reject. Theorem 11. Assume < 1. If we observe n = \u2126( ( T \u03b1 )2 ) signals generated by a distribution q then w.p. \u2265 2/3 over the matrices Gi we generate and the signals we observe, it holds that dTV( 12\u03b7\u03b8,q) \u2264 \u03b1/2. The correctness of the tester now follows from checking for the two cases where either p = q or dTV(p,q) > \u03b1.\nProof. In the first part of the proof we assume the types of the n users were already drawn and are now fixed. We denote xi as the type of user i. We denote the frequency vector f = \u3008nxn \u3009x\u2208X , generated by counting the number of users of type x and normalizing it by n.\nGiven f , we examine the estimator \u03b8. For each user i we have that 1\u03b7 (g yi i \u2212 121) \u2208 {\u22121, 1}\nT . Because xi, the type of user i, is fixed, then for each coordinate x\u2032 6= xi, the signal yi is independent of the x\u2032-column in Gi (yi depends solely on the entries in the xi-column). We thus have that gyii (x\n\u2032) is distributed uniformly among { 12 \u00b1 \u03b7} and so E[ 1 \u03b7 (g yi i (x\n\u2032) \u2212 12 )] = 0. In contrast, Pr[ 1\u03b7 (g yi i (xi) \u2212 12 ) = 1 ]\n= \u2211 s\u2208{\u22121,1} Pr[ 1 \u03b7 (g s i (xi) \u2212 12 ) = 1 and yi = s] = 2 \u00b7 12 \u00b7 ( 1 2 + \u03b7) = 1 2 +\u03b7. Therefore, E[ 1 \u03b7 (g yi i (xi)\u2212 12 )] =\n( 12 + \u03b7)\u2212 ( 1 2 \u2212 \u03b7) = 2\u03b7. It follows that E[ 1 \u03b7 (g yi i \u2212 121)] = 2\u03b7exi and so E[\u03b8] = 2\u03b7f .\nNext we examine the variance of \u03b8 , and argue the following (proof deferred to supplementary material).\nProposition 12. E[(\u03b8 \u2212 2\u03b7f )(\u03b8 \u2212 2\u03b7f )T] 1nI So as a result, the expectedL2-difference E[\u2016\u03b8 \u2212 2\u03b7f \u20162] = E[trace((\u03b8 \u2212 2\u03b7f )(\u03b8 \u2212 2\u03b7f )T)] = trace(E[(\u03b8 \u2212 2\u03b7f )(\u03b8 \u2212 2\u03b7f )T]) \u2264 Tn . Chesbyshev\u2019s inequality assures us that therefore Pr[ 12\u03b7\u2016\u03b8 \u2212 2\u03b7f \u2016 > \u221a 6T 2\u03b7 \u221a n ] \u2264 T/n6T/n = 1 6 .\nSo far we have assumed f is fixed, and only looked at the event that the coin-tosses of the mechanism yielded an estimator far from its expected value. We now turn to bounding the distance between f and its expected value q (the distribution that generated the types). Indeed, it is clear to see that the expected value of f = 1n \u2211 i exi is E[f ] = q . Moreover, it isn\u2019t hard (and has been computed before many times, e.g. Agresti (2003)) to see that E[(f \u2212 q)(f \u2212 q)T] = 1n ( diag(q)\u2212 qqT ) . Thus\nE[\u2016f \u2212q\u20162] = trace( 1n ( diag(q)\u2212 qqT ) ) = 1n (1\u2212\u2016q\u2016\n2). Therefore, applying Chebyshev again, we get that w.p. at most 1/6 over the choice of types by q , we have that Pr[\u2016f \u2212 q\u2016 > \u221a 6/n] \u2264 1/n6/n = 1 6 .\nCombining both results we get that w.p. \u2265 2/3 we have that \u2016 12\u03b7\u03b8 \u2212 q\u20161 \u2264 \u221a T\u2016 12\u03b7\u03b8 \u2212 q\u2016 \u2264\u221a\nT ( \u2016 12\u03b7\u03b8 \u2212 f \u2016+ \u2016f \u2212 q\u2016 ) \u2264 \u221a 6T 2 4\u03b72n+ \u221a 6T n \u2264 \u03b1 since\nwe have n = \u2126( T 2\n\u03b72\u03b12 ). Recall that \u03b7 = \u0398( ) and that dTV(x,y) = 1 2\u2016x\u2212y\u20161, and the bound of \u03b1 2 is proven.\nIndependence Testing. Similarly to the identity tester, we propose a similar tester for independence. Recall that in this case, X is composed of d features, hence X = X 1 \u00d7 X 2 \u00d7 ... \u00d7 X d, with our notation of T j = |X j | for each j. Our tester should accept when the underlying distribution over the types is some product distribution p, and should reject when the underlying distribution over the types is \u03b1-far from any product distribution. The tester, whose input is the n signals and a distance parameter \u03b1 > 0, is as follows.\n1. Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator \u03b8 = 1n \u2211 i 1 \u03b7 ( gyii \u2212 121 ) .\n2. For each feature j compute \u03b8j \u2014 the jth marginal of 1 2\u03b7\u03b8 (namely, for each x\nj \u2208 X j sum all types whose jth feature is xj). Denote \u03b8\u0304 = \u03b81 \u00d7 ...\u00d7 \u03b8d.\n3. If dTV( 12\u03b7\u03b8, \u03b8\u0304) \u2264 \u03b1 2 then accept, else reject.\nTheorem 13. Assume < 1. Given n = \u2126( T\u03b12 2 ( T + d2 \u2211 j T j )\n) iid drawn signals from the nonsymmetric locally-private mechanism under a dataset whose types were drawn iid from some distribution q , then\nw.p. \u2265 2/3 over the matrices Gi we generate and the types in the dataset we have the following guarantee. If q is a product distribution, then dTV( 12\u03b7\u03b8, \u03b8\u0304) \u2264 \u03b1 2 , and if q is \u03b1far from any product distribution then dTV( 12\u03b7\u03b8, \u03b8\u0304) > \u03b1 2 . (Proof deferred to the supplementary material, Section C.)\nOpen Problems. (1) Is there a tester with a better sample complexity? The experiment in Section 4.2 leads us to conjecture that there exists a tester with sample complexity of T 1.5/(\u03b7\u03b1)2. There could exist better testers, of smaller sample complexity, which leads to the second question. (2) Can one derive lower bounds for identity/independence testing in this model, where each sample has its own distribution, related to the original distribution over types? In Section D in the supplementary material we give more details as to possible venues to tackle both problems, relating them to the problem of learning a mixture-model of product distributions."}, {"heading": "4.2. Experiment: Proposed \u03c72-Based Testers", "text": "Following the derivations in the proof of Theorem 11, we can see that Var(\u03b8) = 1n ( I \u2212 4\u03b72diag(f 2) ) . As ever, we assume is a small constant and as a result the variance in 2\u03b7f (which is approximately 4\u03b7 2\nn diag(p)) is significantly smaller than the variance of \u03b8. This allows us to use the handwavey approximation f \u2248 p, and argue that we have the approximation Var(\u03b8) \u2248 1 n ( I \u2212 4\u03b72diag(p2) ) def = 1nM . Central Limit Theorem thus give that \u221a nM\u22121/2(\u03b8 \u2212 2\u03b7p) n\u2192\u221e\u2192 N (0, I). Therefore, it stands to reason that the norm of the LHS is distributed like a \u03c72-distribution, namely,\nP (\u03b8) def = n \u2211 x\u2208X (\u03b8(x)\u2212 2\u03b7 \u00b7 p(x))2 1\u2212 4\u03b72p(x)2 n\u2192\u221e\u2192 \u03c72T\nOur experiment is aimed at determining whether P (\u03b8) can serve as a test statistic and assessing its sample complexity.\nSetting and Default Values. We set a true ground distribution on T possible types, p. We then pick a distribution q which is \u03b1-far from p using the counter example of Paninski (2008): we pair the types and randomly move 2\u03b1T probability mess between each pair of matched types. We then generate n samples according to q , and apply the nonsymmetric -differentially private mechanism of (Bassily et al., 2017). Finally, we aggregate the suitable vectors to obtain our estimator \u03b8 and compute P (\u03b8). If we decide to accept/reject we do so based on comparison of P to the 23 -quantile of the \u03c7 2 T -distribution, so that in the limit we reject only w.p. 1/3 under the null-hypothesis. We repeat this entire process t times. We have set the default values T = 10, p = uT (uniform on [T ]), \u03b1 = 0.2, n = 1000, = 0.25 and therefore \u03b7 = 12 e \u22121 e +1 , and t = 10000.\nExperiment 1: Convergence to the \u03c72-distribution in the null case. First we ask ourself whether our approximation, denoting P (\u03b8) \u2248 \u03c72T is correct when indeed p is\nthe distribution generating the signals. To that end, we set \u03b1 = 0 (so the types are distributed according to p) and plot the t empirical values of P we in our experiment, varying both the sample size n \u2208 {10, 100, 1000, 10000} and the domain size T \u2208 {10, 25, 50, 100}. The results are consistent \u2014 P is distributed like a \u03c72T - distribution. Indeed, the mean of the t sample points is\u2248 T (the mean of a \u03c72T -distribution). The results themselves appear in Figure 2 in the supplementary material, Section D.\nExperiment 2: Divergence from the \u03c72-distribution in the alternate case. Secondly, we asked whether P can serve as a good way to differentiate between the null hypothesis (the distribution over the types is derived from p) and the alternative hypothesis (the distribution over the types if \u2265 \u03b1-far from p). We therefore ran our experiment while varying \u03b1 (between 0.25 and 0.05) and increasing n. Again, the results show that the distribution does shift towards higher values as n increases. The results are given in\nFigure 3 in the supplementary material, Section D.\nExperiment 3: Sample Complexity. Next, we set to find the required sample complexity for rejection. We fix the \u03b1-far distribution from p, and first do binary search to hone on an interval [nL, nU ] where the empirical rejection probability is between 30% \u2212 35%; then we equipartition this interval and return the n for which the empirical rejection probability is the closest to 33%. We repeat this experiment multiple times, each time varying just one of the 3 most important parameters, T , \u03b1 and . We maintain two parameters at default values, and vary just one parameter: T \u2208 {5, 10, 15, .., 100}, \u03b1 \u2208 {0.05, 0.1, 0.15, ..., 0.5}, \u2208 {0.05, 0.1, 0.15, ..., 0.5}. The results are shown in Figure 1, where next to each curve we plot the curve of our conjecture in a dotted line.4 We conjecture initially that n \u221d T cT \u00b7 \u03b1c\u03b1 \u00b7 c . And so, for any parameter \u03be \u2208 {T, \u03b1, }, if we compare two experiments i, j that differ only on the value of this parameter and resulted in two empirical estimations Ni, Nj of the sample complexity, then we get that c\u03be \u2248 log(Ni/Nj)log(\u03bei/\u03bej) . And so for any \u03be \u2208 {T, \u03b1, } we take the median over of all pairs of i and j and we get the empirical estimations of c = \u22121.900793, c\u03b1 = \u22121.930947 and cT = 1.486957. This leads us to the conjecture that the actual sample complexity according to this test is T 1.5\n\u03b12 2 .\nOpen Problem. Perhaps even more interesting, is the experiment we wish we could have run: a \u03c72-based independence testing. Assuming the distribution of the type is a product distribution p\u0304 = p1 \u00d7 ... \u00d7 pd, the proof of Theorem 13 shows that for each feature j we have Var(\u03b8j \u2212 pj) \u2248 14\u03b72n T T j IX j . Thus 4\u03b7 2nT j T \u2016\u03b8 j \u2212 pj\u20162 n\u2192\u221e\u2192 \u03c72T j . However, the d estimators \u03b8j are not independent, so it is\n4We plot the dependency on \u03b1 and on the same plot, as both took the same empirical values.\nnot true that \u2211 j 4\u03b7 2nT j T \u2016\u03b8 j \u2212 pj\u20162 n\u2192\u221e\u2192 \u03c72\u2211 j T j . Moreover, even if the estimators of the marginals were independent,5 we are still unable to determine the asymptotic distribution of \u2016\u03b8\u0304\u2212p\u0304\u20162 (only a bound, scaled byO(maxj Tj), using Proposition 17 in the supplementary material), let alone the asymptotic distribution of \u2016 12\u03b7\u03b8 \u2212 \u03b8\u0304\u2016 2.\nNonetheless, we did empirically measure the quantity\nQ(\u03b8) def = n \u2211 x ( 1 2\u03b7 \u03b8(x)\u2212\u03b8\u0304(x)) 2 \u03b8\u0304(x) under the null (\u03b1 = 0) and the alternative (\u03b1 = 0.25) hypothesis with n = 25, 000 samples in each experiment. The results (given in Figure 4 in the supplementary material) show that the distribution of Q \u2014 albeit not resembling a \u03c72-distribution \u2014 is different under the null- and the alternative-hypothesis, so we suspect that there\u2019s merit to using this quantity as a tester. We thus leave the design of a \u03c72-based statistics for independence in this model as an open problem.\n5E.g. by assigning each example i to one of the d estimators, costing only d = log(T ) factor in sample complexity"}, {"heading": "Acknowledgments", "text": "This work was supported by the Natural Sciences and Engineering Council of Canada, Grant #2017-06701. The author is also an unpaid collaborator on NSF grant 1565387. The authors thanks the anonymous reviewers for many helpful suggestions and ideas, as well as Marco Gaboardi and Ryan Rogers for helpful discussions illustrating the similarities and differences between our two papers."}], "year": 2018, "references": [{"title": "Optimal testing for properties of distributions", "authors": ["J. Acharya", "C. Daskalakis", "G. Kamath"], "venue": "In NIPS,", "year": 2015}, {"title": "Categorical Data Analysis. Wiley Series in Probability and Statistics", "authors": ["A. Agresti"], "year": 2003}, {"title": "Learning with privacy at scale", "authors": ["D.P.T. Apple"], "venue": "Apple Machine Learning Journal,", "year": 2017}, {"title": "Local, private, efficient protocols for succinct histograms", "authors": ["R. Bassily", "A.D. Smith"], "venue": "In STOC, pp", "year": 2015}, {"title": "Practical locally private heavy hitters", "authors": ["R. Bassily", "K. Nissim", "U. Stemmer", "A.G. Thakurta"], "venue": "In NIPS,", "year": 2017}, {"title": "Priv\u2019it: Private and sample efficient identity testing", "authors": ["B. Cai", "C. Daskalakis", "G. Kamath"], "venue": "In ICML,", "year": 2017}, {"title": "On the generalization ability of on-line learning algorithms", "authors": ["N. Cesa-bianchi", "A. Conconi", "C. Gentile"], "venue": "In NIPS, pp", "year": 2002}, {"title": "Convergence rates for differentially private statistical estimation", "authors": ["K. Chaudhuri", "D. Hsu"], "venue": "In ICML,", "year": 2012}, {"title": "Local privacy and statistical minimax rates", "authors": ["J. Duchi", "M. Jordan", "M. Wainwright"], "venue": "In FOCS,", "year": 2013}, {"title": "Local privacy and minimax bounds: Sharp rates for probability estimation", "authors": ["J.C. Duchi", "M.I. Jordan", "M.J. Wainwright"], "venue": "In NIPS,", "year": 2013}, {"title": "Differential privacy and robust statistics", "authors": ["C. Dwork", "J. Lei"], "venue": "In STOC,", "year": 2009}, {"title": "The Algorithmic Foundations of Differential Privacy", "authors": ["C. Dwork", "A. Roth"], "venue": "Foundations and Trends in Theoretical Computer Science, NOW Publishers,", "year": 2014}, {"title": "Private false discovery rate control", "authors": ["C. Dwork", "W. Su", "L. Zhang"], "venue": "CoRR, abs/1511.03803,", "year": 2015}, {"title": "Rappor: Randomized aggregatable privacy-preserving ordinal response", "authors": ["\u00da. Erlingsson", "V. Pihur", "A. Korolova"], "venue": "In CCS,", "year": 2014}, {"title": "Local private hypothesis testing: Chi-square tests", "authors": ["M. Gaboardi", "R.M. Rogers"], "venue": "In ICML (to appear),", "year": 2018}, {"title": "Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing", "authors": ["M. Gaboardi", "H.W. Lim", "R. Rogers", "S.P. Vadhan"], "venue": "In ICML,", "year": 2016}, {"title": "Logarithmic regret algorithms for online convex optimization", "authors": ["E. Hazan", "A. Kalai", "S. Kale", "A. Agarwal"], "venue": "In COLT, pp", "year": 2006}, {"title": "Privacy-preserving data exploration in genome-wide association studies", "authors": ["A. Johnson", "V. Shmatikov"], "venue": "In KDD, pp", "year": 2013}, {"title": "On learning distributions from their samples", "authors": ["S. Kamath", "A. Orlitsky", "D. Pichapati", "A.T. Suresh"], "venue": "In COLT, pp", "year": 2015}, {"title": "Finite sample differentially private confidence intervals, 2018", "authors": ["V. Karwa", "S. Vadhan"], "year": 2018}, {"title": "What can we learn privately", "authors": ["S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith"], "venue": "In FOCS,", "year": 2008}, {"title": "A coincidence-based test for uniformity given very sparsely sampled discrete data", "authors": ["L. Paninski"], "venue": "IEEE Trans. Information Theory,", "year": 2008}, {"title": "Approximate distributions of order statistics: with applications to nonparametric statistics. Springer series in statistics", "authors": ["R. Reiss"], "year": 1989}, {"title": "f-divergence inequalities", "authors": ["I. Sason", "S. Verd\u00fa"], "venue": "IEEE Trans. Information Theory,", "year": 2016}, {"title": "Differentially private ordinary least squares", "authors": ["O. Sheffet"], "venue": "In ICML,", "year": 2017}, {"title": "Privacy-preserving statistical estimation with optimal convergence rates", "authors": ["A. Smith"], "venue": "In STOC,", "year": 2011}, {"title": "Privacypreserving data sharing for genome-wide association studies", "authors": ["C. Uhler", "A.B. Slavkovic", "S.E. Fienberg"], "venue": "Journal of Privacy and Confidentiality,", "year": 2013}, {"title": "An automatic inequality prover and instance optimal identity testing", "authors": ["G. Valiant", "P. Valiant"], "venue": "In FOCS, pp. 51\u2013", "year": 2014}, {"title": "URL http://arxiv", "authors": ["Vershynin", "R. Introduction to the non-asymptotic analysis of random matrices."], "venue": "org/abs/1011.3027.", "year": 2010}, {"title": "Differential privacy for clinical trial data: Preliminary evaluations", "authors": ["D. Vu", "A. Slavkovic"], "venue": "In ICDM,", "year": 2009}, {"title": "Differentially private hypothesis testing, revisited", "authors": ["Y. Wang", "J. Lee", "D. Kifer"], "venue": "CoRR, abs/1511.03376,", "year": 2015}, {"title": "Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias", "authors": ["S. Warner"], "venue": "Journal of the American Statistical Association,", "year": 1965}, {"title": "Scalable privacy-preserving data sharing methodology for genome-wide association studies", "authors": ["F. Yu", "S. Fienberg", "A. Slavkovic", "C. Uhler"], "venue": "Journal of Biomedical Informatics,", "year": 2014}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "authors": ["M. Zinkevich"], "venue": "In ICML,", "year": 2003}], "id": "SP:897cfd9b46c65d95147f94d26d3626fe098d9b3c", "authors": [{"name": "Or Sheffet", "affiliations": []}], "abstractText": "We initiate the study of differentially private hypothesis testing in the local-model, under both the standard (symmetric) randomized-response mechanism (Warner, 1965; Kasiviswanathan et al., 2008) and the newer (non-symmetric) mechanisms (Bassily & Smith, 2015; Bassily et al., 2017). First, we study the general framework of mapping each user\u2019s type into a signal and show that the problem of finding the maximum-likelihood distribution over the signals is feasible. Then we discuss the randomizedresponse mechanism and show that, in essence, it maps the nulland alternative-hypotheses onto new sets, an affine translation of the original sets. We then give sample complexity bounds for identity and independence testing under randomizedresponse. We then move to the newer nonsymmetric mechanisms and show that there too the problem of finding the maximum-likelihood distribution is feasible. Under the mechanism of Bassily et al (2017) we give identity and independence testers with better sample complexity than the testers in the symmetric case, and we also propose a \u03c7-based identity tester which we investigate empirically.", "title": "Locally Private Hypothesis Testing"}
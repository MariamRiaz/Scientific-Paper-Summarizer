1	10	Typically taking the form of a lower bound on the intractable model evidence, they provide surrogate targets that are more amenable to optimization.
2	42	In general, this optimization requires the generation of approximate posterior samples during the model training and so a number of methods simultaneously learn an inference network alongside the target generative network.
3	51	As well as assisting the training process, this inference network is often also of direct interest itself.
6	14	The performance of variational approaches depends upon the choice of evidence lower bound (ELBO) and the formulation of the inference network, with the two often intricately linked to one another; if the inference network formulation is not sufficiently expressive, this can have a knock-on effect on the generative network (Burda et al., 2016).
9	26	Remarkably, we find that it is possible to simultaneously tighten the bound, reduce the variance of the gradient updates, and arbitrarily deteriorate the training of the inference network.
10	17	Specifically, we present theoretical and empirical evidence that increasing the number of importance sampling particles, K, to tighten the bound in the importance-weighted autoencoder (IWAE) (Burda et al., 2016), degrades the signal-tonoise ratio (SNR) of the gradient estimates for the inference network, inevitably deteriorating the overall learning process.
38	32	As estimating the ELBO requires a Monte Carlo estimation of an expectation over z, we have two sample sizes to tune for the estimate: the number of samples M used for Monte Carlo estimation of the ELBO and the number of importance samples K used in the bound construction.
39	25	Here M does not change the true value of∇θ,φ ELBO, only our variance in estimating it, while changing K changes the ELBO itself, with larger K leading to tighter bounds (Burda et al., 2016).
40	31	Presuming that reparameterization is possible, we can express our gradient estimate in the general form ∆M,K := 1 M ∑M m=1 ∇θ,φ log 1 K ∑K k=1 wm,k, (3) where wm,k = pθ(zm,k, x) qφ(zm,k|x) and zm,k i.i.d.∼ qφ(zm,k|x).
44	15	To see why, consider the marginal likelihood estimates Ẑm,K = ∑K k=1 wm,k.
52	16	Assume that when M = K = 1, the expected gradients; the variances of the gradients; and the first four moments of w1,1,∇θw1,1, and∇φw1,1 are all finite and the variances are also non-zero.
55	18	The effect of M on the SNR follows from using the law of large numbers on the random variable∇θ,φ log Ẑm,K .
56	20	Namely, the overall expectation is independent of M and the variance reduces at a rate O(1/M).
61	20	We emphasize that this means the SNR for the IWAE inference network gets worse as we increase K: this is not just an opportunity cost from the fact that we could have increased M instead, increasing the total number of samples used in the estimator actually worsens the SNR!
63	9	Namely, because we have as an intermediary result from deriving the SNRs that E [∆M,K(φ)] = − ∇φVar [w1,1] ( 1 K2 ) , (7) we see that expected gradient points in the direction of −∇φVar [w1,1] as K → ∞.
85	16	In all cases we calculated 104 such estimates and used these samples to provide empirical estimates for, amongst other things, the mean and standard deviation of the estimator, and thereby an empirical estimate for the SNR.
87	15	This shows histograms of the IWAE gradient estimators for a single parameter of the inference network (left) and generative network (right).
97	20	Consequently, while the magnitude of this bias remains large compared to E[∆M,∞(µ)], it is the predominant component in the true gradient and we see similar SNR behavior as in the inference network.
129	14	When this happens, the VAE component should “take-over” and alleviate SNR issues: the asymptotic SNR of ∆CK,β for φ is O( √ MK) because the VAE component has non-zero expectation in the limit K →∞.
130	9	Our results suggest that what is good for the generative network, in terms of setting K, is often detrimental for the inference network.
131	38	It is therefore natural to question whether it is sensible to always use the same target for both the inference and generative networks.
142	13	All reported metrics are evaluated on the test data.
143	21	The motivation for the ELBOIWAE with K = 64 metric, denoted as IWAE-64, is that this is the target used for training the IWAE and so if another method does better on this metric than the IWAE, this is a clear indicator that SNR issues of the IWAE estimator have degraded its performance.
145	9	The second metric, ELBOIWAE with K = 5000, denoted log p̂(x), is used as a surrogate for estimating the log marginal likelihood and thus provides an indicator for fidelity of the learned generative model.
157	9	We note here that the KL is not an exact measure of the inference network performance as it also depends on the generative model.
175	19	We have provided theoretical and empirical evidence that algorithmic approaches to increasing the tightness of the ELBO independently to the expressiveness of the inference network can be detrimental to learning by reducing the signal-to-noise ratio of the inference network gradients.
177	13	We then exploited these insights to introduce three estimators, PIWAE, MIWAE, and CIWAE and showed that each can deliver improvements over IWAE, even when the metric used for this assessment is the IWAE target itself.
178	14	In particular, each was able to deliver improvement in the training of the inference network, without any reduction in the quality of the learned generative network.
179	12	Whereas MIWAE and CIWAE mostly allow for balancing the requirements of the inference and generative networks, PIWAE appears to be able to offer simultaneous improvements to both, with the improved training of the inference network having a knock-on effect on the generative network.
180	32	Key to achieving this is, is its use of separate targets for the two networks, opening up interesting avenues for future work.

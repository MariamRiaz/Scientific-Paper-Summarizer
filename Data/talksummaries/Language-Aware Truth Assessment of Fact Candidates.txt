15	47	The believability score reflects the likelihood that a given statement is true.
17	29	Prior truth-finding methods are mostly based on iterative voting, where votes are propagated from sources to fact candidates and then back to sources (Yin et al., 2007; Galland et al., 2010; Pasternack and Roth, 2010; Li et al., 2011; Yin and Tan, 2011).
18	51	At the core of iterative voting is the assumption that candidates mentioned by many sources are more likely to be true.
19	34	However, additional aspects of a source influence its trustworthiness, besides external votes.
21	20	A Mechanical Turk study we carried out revealed that there is a significant correlation between objectivity of language and trustworthiness of sources.
22	25	Objectivity of language refers to the use of neutral, impartial language, which is not personal, judgmental, or emotional.
49	44	That is, we assess truthfulness of factual statements and not opinions whose truthfulness is often both T and F to some degree.
78	22	While prior methods assume the alternatives are known apriori, we developed a method for generating alternative fact candidates.
80	44	The fixed argument is the argument of the SVO which when fixed, requires finding the fewest number of alternative candidates.
85	35	In our example, alternatives are possible places, other than Princeton, where Einstein could have died.
89	21	We use the fixed argument to define a topic as the fixed argument plus the verb.
91	28	To locate alternatives, we use the topic (Argfixed + V ) as a query.
106	22	S is subjective, expressing the opinion of the author.
119	20	For this task, annotators were asked to judge if a given article is objective or subjective.
128	33	These results indicate a non-trivial positive correlation between objectivity and trustworthiness.
139	55	Features 1-3 refer to lexicons developed by prior methods on subjectivity (Wiebe et al., 2004), sentiment analysis (Liu et al., 2005) and bias detection (Recasens et al., 2013).
151	26	Given a fact candidate fi, mentioned in a set of documents Di, where each document d ∈ Di has objectivity O(d), fi’s objectivity score is defined as follows: Definition 3 (Objectivity Score) O(fi) = log|Di|.
156	29	The co-mention score aims to ensure that fact candidates mentioned in similar sources have similar believability scores.
181	25	Let τ(fi) ∈ {T, F} be the truthfulness of a fact candidate fi, accuracy is defined as: Algorithm 1 FactChecker Input: A set F of fact candidates Input: KB K, SVO corpus C, WebW Output: A set L of rankings ∀fi ∈ F L = ∅ while F 6= ∅ do pick fi from F A= getAlternatives(fi,K,C,W) PriorityQueue Li = ∅ for all alternative fact candidates f ′j ∈ A do β(f ′j) = getBelievabilityScore(f ′j) Li.insert(f ′j , β(f ′ j)) end for β(f i) = getBelievabilityScore(fi) Li.insert(fi, β(fi)) L ∪ Li Remove fi from F end while return L Acc = ∑ (τ(fi)=T :τ(fj)=F ) (β(fi) > β(fj)) |{∀(fi, fj) : τ(fi) = T ∧ τ(fj) = F}| Datasets.
182	89	We evaluated FactChecker on three datasets: i) KB Fact Candidates: The first dataset consists of fact candidates taken from the fact extraction pipeline of a state-of-the-art knowledge base, NELL (Carlson et al., 2010).
183	59	The fact candidates span four different relation types: company acquisitions, book authors, movie directors and athlete teams.
190	50	First, we extracted fact candidates from the infoboxes of the Wikipedia pages of the entities.
191	39	Second, we applied our alternative candidate generation method to discover alternatives from the Web, SVO corpus, and NELL.
192	21	Details of the resulting dataset are shown in the row “WKP Politicians” in Table 3. iii) General Knowledge Quiz: The third dataset consists of questions from a general knowledge quiz 4.
193	24	We selected questions from the inventions category.
194	36	Questions are multiple choice, with 4 options per question.
195	52	Thus, from each question, we created one fact candidate and 3 alternative candidates.
196	50	Details of the resulting dataset are shown in the row “KWP Quiz” in Table 3.
201	43	A source gets a vote of trust from each candidate it “invests” in, but the vote is weighted by the proportion of trust the source previously “invested” in the candidate relative to other investors.
202	57	Implemented as described in (Pasternack and Roth, 2010).

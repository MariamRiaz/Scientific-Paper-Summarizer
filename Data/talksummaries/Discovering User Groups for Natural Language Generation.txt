8	14	At training time, we probabilistically assign users to groups and learn the language preferences for each group.
9	25	At evaluation time, we assume that our system has a chance to interact with each new user repeatedly – e.g., in the context of a dialogue system.
12	15	First, we predict the use of spatial relations in humanlike REs in the GRE3D domain (Viethen and Dale, 2010) using a log-linear production model in the spirit of Ferreira and Paraboni (2014).
14	44	In both cases, we show that our model discovers user groups in the training data and infers the group of unseen users with high confidence after only a few interactions during testing.
15	63	In the GRE3D domain, our system outperformed a strong baseline which used demographic information for the users.
32	25	We start with a basic model of the way in which people produce and comprehend language.
33	27	In order to generalize over production and comprehension, we will simply say that a human language user exhibits a certain behavior b among a range of possible behaviors, in response to a stimulus s. The behavior of a speaker is the utterance b they produce in order to achieve a communicative goal s; the behavior of a listener is the meaning b which they assign to the utterance s they hear.
34	21	Given this terminology, we define a basic loglinear model (Berger et al., 1996) of language use as follows: P (b|s; ρ) = exp(ρ · φ(b, s))∑ b′ exp(ρ · φ(b′, s)) (1) where ρ is a real-valued parameter vector of length n and φ(b, s) is a vector of real-valued feature functions f1, ..., fn over behaviors and stimuli.
58	23	The generative story we use is illustrated in Fig.
61	27	We assume that each user belongs to a group g ∈ {1, .
63	30	A group g is assigned to u at random from the distribution P (g|π) = exp(πg)∑K g′=1 exp(πg′) (2) Here π ∈ RK is a vector of weights, which defines how probable each group is a-priori.
82	18	Before the first interaction with u, it has no specific information about u and models u’s behavior based on (6).
84	69	This allows it to calculate an increasingly accurate posterior Pu(g) = P ( g|D(u); θ ) of u’s group membership, and thus generate utterances which are more and more suitable to u using (8).
91	18	Gradient descent based methods (Nocedal and Wright, 2006) exist for finding the parameter settings which maximize the likelihood for log-linear models, under the conditions that all relevant variables are observed in the training data.
107	14	This can be achieved with gradient based methods such as L-BFGS (Nocedal and Wright, 2006).
123	22	Even if we just took a single L-BFGS step in each iteration, we would still obtain a correct algorithm (Neal and Hinton, 1999) and this has the advantage that we do not spend time trying to find a θ(i) which is a good fit for the likely poor group assignments P ( g|D(u); θ(i−1) ) we obtain from early parameter estimates.
124	14	Our model can be used in any component of a dialog system for which a prediction of the user’s behavior is needed.
132	16	More specifically, we focus on predicting whether the speaker will use a spatial relation to another object (“landmark”).
134	35	Data We use the GRE3D3 dataset of humanproduced REs (Viethen and Dale, 2010), which contains 630 descriptions for 10 scenes collected from 63 users, each describing the same target object in each scene.
143	31	We compare these baselines to our Group model for values of K between 1 and 10, using the exact same features as Basic.
172	17	We use those features for our Group model as well, and evaluate for K between 1 and 10.
177	21	Since our model relies completely on observable behavior, it also relies on the ability of the features to make relevant distinctions between users.
178	28	Results on synthetic data In order to test this hypothesis, we made a synthetic dataset based on the GIVE datasets with 1000 instances from 100 users, in the following way: for each user, we randomly selected 10 scenes from GIVE-2, and replaced the target the user selected, so that half of the users always select the target with the highest visual salience, and the other half always select the one with the lowest.
182	39	All models for K > 1 clearly outperform the baseline model: the 2-group model gets 62.3% vs 28.6% averaged over all test examples, while adding more than two groups does not further improve the accuracy.
184	22	In the same figure, the entropy of the posterior distribution over groups (see production experiment) falls towards zero as D(u) grows.
185	16	These results show that our model is capable of correctly assigning a user to the group they belong to, once the features are adequate for distinguishing between different user behaviors.
187	31	In particular, if all listeners are influenced in a similar way by e.g. the visual salience of an object, then the group model cannot learn different weights for the visual salience feature; if this happens for all available features, there are effectively no groups for our model to discover.
191	25	We showed for two separate NLG-related tasks, RE production and RE comprehension, how our model, after being trained with data that is not annotated with user groups, can quickly adapt to unseen users as it gets more observations from them in the course of a dialog and makes increasingly accurate predictions about their behavior.
192	69	Although in this work we apply our model to tasks related to NLG, nothing hinges on this choice; it can also be applied to any other dialog-related prediction task where user variation plays a role.
193	39	In the future, we will also try to apply the basic principles of our user group approach to more sophisticated underlying models, such as neural networks.

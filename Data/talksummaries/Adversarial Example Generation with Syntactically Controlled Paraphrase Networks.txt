7	17	We introduce the first learning approach for this problem, building on the generality of neural encoder-decoder models to support a wide range of transformations.
8	24	In doing 1875 so, we face two new challenges: (1) obtaining a large amount of paraphrase pairs for training, and (2) defining syntactic transformations with which to label these pairs.
12	31	Our focus is on syntactic transformations, which we define using templates derived from linearized constituency parses (§2).
13	26	Given such parallel data, we can easily train an encoder-decoder model that takes a sentence and target syntactic template as input, and produces the desired paraphrase.1 A combination of automated and human evaluations show that the generated paraphrases almost always follow their target specifications, while paraphrase quality does not significantly deteriorate compared to vanilla neural backtranslation (§4).
14	110	Our model, the syntactically controlled paraphrase network (SCPN), is capable of generating adversarial examples for sentiment analysis and textual entailment datasets that significantly impact the performance of pretrained models (Figure 1).
16	15	Together these results not only establish the first general purpose syntactically controlled paraphrase approach, but also suggest that this general paradigm could be used for controlling many other aspects of the target text.
22	40	This corpus consists of over 50 million paraphrases obtained by backtranslating the Czech side of the CzEng (Bojar et al., 2016) parallel corpus.
23	32	The pretrained Czech-English model used for translation came from the Nematus NMT system (Sennrich et al., 2017).
25	20	The CzEng corpus is the largest of these four and was found to have significantly more syntactic diversity than the other data sources (Wieting and Gimpel, 2017).2
28	30	Our key insight is that target transformations can be detected (with some noise) simply by parsing these pairs.3 Specifically, we parse the backtranslated paraphrases using the Stanford parser (Manning et al., 2014),4 which yields a pair of constituency parses 〈p1, p2〉 for each sentence pair 〈s1, s2〉, where s1 is the reference English sentence in the CzEng corpus and s2 is its backtranslated counterpart.
40	27	We incorporate the target syntax p2 into the generation process by modifying the inputs to the decoder.
47	20	This attention mechanism is conditioned on the decoder’s previous hidden state ht−1.
49	30	Preliminary experiments show that SCPN struggles to maintain the semantics of the input sentence when we replace the full target parse with templates, and frequently generates short, formulaic sentences.
56	36	At test time, a user only has to specify an input sentence and target template; the template is fed through the parse generator, and its predicted target parse is in turn sent to SCPN for paraphrase generation (see Figure 2).
65	37	To measure paraphrase quality and grammaticality, we perform a crowdsourced experiment in which workers are asked to rate a paraphrase pair 〈s, g〉 on the three-point scale of Kok and Brockett (2010), where s is the source sentence and g is the generated sentence.
76	41	The NMT-BT system produces paraphrases that tend to be syntactically very similar to the input sentences: 28.7% of these paraphrases have the same template as that of the input sentence s1, while only 11.1% have the same template as the ground-truth target s2.
77	27	Even though we train SCPN on data generated by NMT backtranslation, we avoid this issue by incorporating syntax into our learning process.
78	41	The intrinsic evaluations show that SCPN produces paraphrases of comparable quality to the uncontrolled NMT-BT system while also adhering to the specified target specifications.
82	26	Our results demonstrate that controlled paraphrase generation with appropriate template selection produces far more valid adversarial examples than backtranslation on sentiment analysis and entailment tasks.
83	26	We evaluate our syntactically adversarial paraphrases on the Stanford Sentiment Treebank (Socher et al., 2013, SST) and SICK entailment detection (Marelli et al., 2014).
84	18	While both are relatively small datasets, we select them because they offer different experimental conditions: SST contains complicated sentences with high syntactic variance, while SICK almost exclusively consists of short, simple sentences.
85	14	As a baseline, we compare the ten most probable beams from NMT-BT to controlled paraphrases generated by SCPN using ten templates randomly sampled from the template set described in Section 3.3.9 We also need pretrained models for which to generate adversarial examples; we use the bidirectional LSTM baseline for both SST and SICK outlined in Tai et al. (2015) since it is a relatively simple architecture that has proven to work well for a variety of problems.10 Since the SICK task involves characterizing the relationship between two sentences, for simplicity we only generate adversarial examples for the first sentence and keep the second sentence fixed to the ground truth.
86	37	For each dataset, we generate paraphrases for held-out examples and then run a pretrained model over them.11 We consider a development example x broken if the original prediction yx is correct, but the prediction yx′ for at least one paraphrase x′ is incorrect.
87	43	For SST, we evaluate on the binary sentiment classification task and ignore all phrase-level labels (because our paraphrase models are trained on only sentences).
88	17	Table 4 shows that for both datasets, SCPN breaks many more examples than NMT-BT.
94	22	For both models, we randomly select 100 adversarial examples and have three workers annotate each one.
96	76	If we additionally augment the training data of both tasks with controlled paraphrases, we can increase a downstream model’s robustness to adversarial examples in the development set.
111	98	Ebrahimi et al. (2017) observe a similar phenomenon with HotFlip, their gradient-based substitution method for generating adversarial examples.
112	70	While NMT-BT does not receive signal from the downstream task like HotFlip, it also does not require external constraints to maintain grammaticality and limit semantic divergence.
115	21	The first two examples in Table 6 demonstrate issues with the templated approach.

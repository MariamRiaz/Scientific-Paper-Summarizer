0,1,label2,summary_sentences
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 78–88 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
"Word Sense Disambiguation (WSD) is a key task in computational lexical semantics, inasmuch as it addresses the lexical ambiguity of text by making explicit the meaning of words occurring in a given context (Navigli, 2009).",1 Introduction,[0],[0]
"Anyone who has struggled with frustratingly unintelligible translations from an automatic system, or with the meaning bias of search engines, can understand the importance for an intelligent system to go beyond the surface appearance of text.
",1 Introduction,[0],[0]
There are two mainstream lines of research in WSD: supervised and knowledge-based WSD.,1 Introduction,[0],[0]
"Supervised WSD frames the problem as a classical machine learning task in which, first a training phase occurs aimed at learning a classification model from sentences annotated with word senses and, second the model is applied to previouslyunseen sentences focused on a target word.",1 Introduction,[0],[0]
"A key
difference from many other problems, however, is that the classes to choose from (i.e., the senses of a target word) vary for each word, therefore requiring a separate training process to be performed on a word by word basis.",1 Introduction,[0],[0]
"As a result, hundreds of training instances are needed for each ambiguous word in the vocabulary.",1 Introduction,[0],[0]
"This would necessitate a million-item training set to be manually created for each language of interest, an endeavour that is currently beyond reach even in resource-rich languages like English.
",1 Introduction,[0],[0]
"The second paradigm, i.e., knowledge-based WSD, takes a radically different approach: the idea is to exploit a general-purpose knowledge resource like WordNet (Fellbaum, 1998) to develop an algorithm which can take advantage of the structural and lexical-semantic information in the resource to choose among the possible senses of a target word occurring in context.",1 Introduction,[0],[0]
"For example, a PageRank-based algorithm can be developed to determine the probability of a given sense being reached starting from the senses of its context words.",1 Introduction,[0],[0]
"Recent approaches of this kind have been shown to obtain competitive results (Agirre et al., 2014; Moro et al., 2014).",1 Introduction,[0],[0]
"However, due to its inherent nature, knowledge-based WSD tends to adopt bag-of-word approaches which do not exploit the local lexical context of a target word, including function and collocation words, which limits this approach in some cases.
",1 Introduction,[0],[0]
"In this paper we get the best of both worlds and present Train-O-Matic, a novel method for generating huge high-quality training sets for all the words in a language’s vocabulary.",1 Introduction,[0],[0]
"The approach is language-independent, thanks to its use of a multilingual knowledge resource, BabelNet (Navigli and Ponzetto, 2012), and it can be applied to any kind of corpus.",1 Introduction,[0],[0]
"The training sets produced with Train-O-Matic are shown to provide competitive performance with those of manually and semi-
78
automatically tagged corpora.",1 Introduction,[0],[0]
"Moreover, state-ofthe-art performance is also reported for low resourced languages (i.e., Italian and Spanish) and domains, where manual training data is not available.",1 Introduction,[0],[0]
"In this Section we present Train-O-Matic, a language-independent approach to the automatic construction of a sense-tagged training set.",2 Building a Training Set from Scratch,[0],[0]
"TrainO-Matic takes as input a corpus C (e.g., Wikipedia) and a semantic network G = (V,E).",2 Building a Training Set from Scratch,[0],[0]
"We assume a WordNet-like structure of G, i.e., V is the set of concepts (i.e., synsets) such that, for each word w in the vocabulary, Senses(w) is the set of vertices in V that are expressed by w, e.g., the WordNet synsets that include w as one of their senses.
",2 Building a Training Set from Scratch,[0],[0]
"Train-O-Matic consists of three steps:
• Lexical profiling: for each vertex in the semantic network, we compute its Personalized PageRank vector, which provides its lexicalsemantic profile (Section 2.1).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence scoring: For each sentence containing a word w, we compute a probability distribution over all the senses of w based on its context (Section 2.2).
",2 Building a Training Set from Scratch,[0],[0]
"• Sentence ranking and selection: for each sense s of a word w in the vocabulary, we select those sentences that are most likely to use w in the sense of s (Section 2.3).",2 Building a Training Set from Scratch,[0],[0]
In terms of semantic networks the probability of reaching a node v′ starting from v can be interpreted as a measure of relatedness between the synsets v,2.1 Lexical profiling,[0],[0]
and v′.,2.1 Lexical profiling,[0],[0]
"Thus we define the lexical profile of a vertex v in a graph G = (V,E) as the probability distribution over all the vertices v′ in the graph.",2.1 Lexical profiling,[0],[0]
"Such distribution is computed by applying the Personalized PagaRank algorithm, a variant of the traditional PageRank (Brin and Page, 1998).",2.1 Lexical profiling,[0],[0]
"While the latter is equivalent to performing random walks with uniform restart probability on every vertex at each step, PPR, on the other hand, makes the restart probability non-uniform, thereby concentrating more probability mass in the surroundings of those vertices having higher restart
probability.",2.1 Lexical profiling,[0],[0]
"Formally, (P)PR is computed as follows:
v(t+1) =",2.1 Lexical profiling,[0],[0]
"(1− α)v(0) + αMv(t) (1)
where M is the row-normalized adjacency matrix of the semantic network, the restart probability distribution is encoded by vector v(0), and α is the well-known damping factor usually set to 0.85 (Brin and Page, 1998).",2.1 Lexical profiling,[0],[0]
"If we set v(0) to a unit probability vector (0, . . .",2.1 Lexical profiling,[0],[0]
", 0, 1, 0, . . .",2.1 Lexical profiling,[0],[0]
", 0), i.e., restart is always on a given vertex, PPR outputs the probability of reaching every vertex starting from the restart vertex after a certain number of steps.",2.1 Lexical profiling,[0],[0]
"This approach has been used in the literature to create semantic signatures (i.e., profiles) of individual concepts, i.e., vertices of the semantic network (Pilehvar et al., 2013), and then to determine the semantic similarity of concepts.",2.1 Lexical profiling,[0],[0]
"As also done by Pilehvar and Collier (2016), we instead use the PPR vector as an estimate of the conditional probability of a word w′",2.1 Lexical profiling,[0],[0]
"given the target sense1 s ∈ V of word w:
P (w′|s, w) = maxs′∈Senses(w′) vs(s ′)
Z (2)
where Z = ∑
w” P (w”|s, w) is a normalization constant, vs is the vector resulting from an adequate number of random walks used to calculate PPR, and vs(s′) is the vector component corresponding to sense s′.",2.1 Lexical profiling,[0],[0]
"To fix the number of iterations needed to have a sufficiently accurate vector, we follow Lofgren et al. (2014) and set the error δ = 0.00001 and the number of iterations to 1 δ = 100, 000.
",2.1 Lexical profiling,[0],[0]
As a result of this lexical profiling step we have a probability distribution over vocabulary words for each given word sense of interest.,2.1 Lexical profiling,[0],[0]
The objective of the second step is to score the importance of word senses for each of the corpus sentences which contain the word of interest.,2.2 Sentence scoring,[0.9695674467399219],['The persona corresponding to the response is extracted using one of the methods of Section 3.2.']
Given a sentence σ =,2.2 Sentence scoring,[0],[0]
"w1, w2, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn, for a given target wordw in the sentence (w ∈ σ), and for each of its senses s ∈ Senses(w), we compute the probability P (s|σ,w).",2.2 Sentence scoring,[0],[0]
"Thanks to Bayes’ theorem we can determine the probability of sense s of w given the
1Note that we use senses and concepts (synsets) interchangeably, because – given a word – a word sense unambiguously determines a concept (i.e., the synset it is contained in) and vice versa.
sentence as follows:
P (s|σ,w) =",2.2 Sentence scoring,[0],[0]
"P (σ|s, w)P (s|w) P (σ|w) (3)
= P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) P (w1, . . .",2.2 Sentence scoring,[0],[0]
", wn|w) ∝",2.2 Sentence scoring,[0],[0]
"P (w1, . .",2.2 Sentence scoring,[0],[0]
.,2.2 Sentence scoring,[0],[0]
", wn|s, w)P (s|w) (4) ≈ P (w1|s, w) . . .",2.2 Sentence scoring,[0],[0]
"P (wn|s, w)P (s|w)
(5)
where Formula 4 is proportional to the original probability (due to removing the constant in the denominator) and is approximated with Formula 5 due to the assumption of independence of the words in the sentence.",2.2 Sentence scoring,[0],[0]
"P (wi|s, w) is calculated as in Formula 2 and P (s|w) is set to 1/|Senses(w)| (recall that s is a sense of w).",2.2 Sentence scoring,[0],[0]
"For example, given the sentence σ =",2.2 Sentence scoring,[0],[0]
"“A match is a tool for starting a fire”, the target word w = match and its set of senses Smatch = {s1match, s2match}, where s1match is the sense of lighter and s2match is the sense of game match, we want to calculate the probability of each simatch ∈ Smatch of being the correct sense of match in the sentence σ.",2.2 Sentence scoring,[0],[0]
"Following Formula 5 we have:
P (s1match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s1match,match) · P (start|s1match,match) · P (fire|s1match,match) · P (s1match|match) = 2.1 · 10−4 · 2 · 10−3 · 10−2 · 5 · 10−1 = 2.1 · 10−9
P (s2match|σ,match)",2.2 Sentence scoring,[0],[0]
"≈ P (tool|s2match,match) ·",2.2 Sentence scoring,[0],[0]
"P (start|s2match,match) · P (fire|s2match,match) · P (s2match|match) = 10−5 · 2.9 · 10−4 · 10−6 · 5 · 10−1 = 1.45 · 10−15
As can be seen, the first sense of match has a much higher probability due to its stronger relatedness to the other words in the context (i.e. start, fire and tool).",2.2 Sentence scoring,[0],[0]
Note also that all the probabilities for the second sense are at least one magnitude less than the probability of the first sense.,2.2 Sentence scoring,[0],[0]
"Finally, for a given word w and a given sense s1 ∈ Senses(w), we score each sentence σ in which w appears and s1 is its most likely sense according to a formula that takes into account the difference between the first (i.e., s1) and the second most likely sense of w in σ:
∆s1(σ)",2.3 Sense-based sentence ranking and selection,[0],[0]
"= P (s1|σ,w)− P (s2|σ,w) (6) where s1 = arg maxs∈Senses(w) P (s|σ,w), and s2 = arg maxs∈Senses(w)\{s1} P (s|σ,w).",2.3 Sense-based sentence ranking and selection,[0],[0]
We then sort all sentences based on ∆s1(·) and return a ranked list of sentences where word w is most likely to be sense-annotated with s1.,2.3 Sense-based sentence ranking and selection,[0],[0]
"Although we recognize that other scoring strategies could have been used, this was experimentally the most effective one when compared to alternative strategies, i.e., the sense probability, the number of words related to the target word w, the sentence length or a combination thereof.",2.3 Sense-based sentence ranking and selection,[0],[0]
"In the previous Section we assumed that WordNet was our semantic network, with synsets as vertices and edges represented by its semantic relations.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"However, while its lexical coverage is high, with a rich set of fine-grained synsets, at the relation level WordNet provides mainly paradigmatic information, i.e., relations like hypernymy (is-a) and meronymy (part-of).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"It lacks, on the other hand, syntagmatic relations, such as those that connect verb synsets to their arguments (e.g., the appropriate senses of eatv and foodn), or pairs of noun synsets (e.g., the appropriate senses of busn and drivern).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Intuitively, Train-O-Matic would suffer from such a lack of syntagmatic relations, as the relevance of a sense for a given word in a sentence depends directly on the possibility of visiting senses of the other words in the same sentence (cf.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Formula 5) via random walks as calculated with Formula 1.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
Such reachability depends on the connections available between synsets.,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because syntagmatic relations are sparse in WordNet, if it was used on its own, we would end up with a poor ranking of sentences for any given word sense.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Moreover, even though the methodology presented in Section 2 is languageindependent, Train-O-Matic would lack informa-
tion (e.g. senses for a word in an arbitrary vocabulary) for languages other than English.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"To cope with these issues, we exploit BabelNet,2 a huge multilingual semantic network obtained from the automatic integration of WordNet, Wikipedia, Wiktionary and other resources (Navigli and Ponzetto, 2012), and create the BabelNet subgraph induced by the WordNet vertices.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
The result is a graph whose vertices are BabelNet synsets that contain at least one WordNet synset and whose edge set includes all those relations in BabelNet coming either from WordNet itself or from links in other resources mapped to WordNet (such as hyperlinks in a Wikipedia article connecting it to other articles).,3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"The greatest contribution of syntagmatic relations comes, indeed, from Wikipedia, as its articles are linked to related articles (e.g., the English Wikipedia Bus article3 is linked to Passenger, Tourism, Bus lane, Timetable, School, and many more).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because not all Wikipedia (and other resources’) pages are connected with the same degree of relatedness (e.g., countries are often linked, but they are not necessarily closely related to the source article in which the link occurs), we apply the following weighting strategy to each edge (s, s′) ∈ E of our WordNet-induced subgraph of BabelNet G = (V,E):
w(s, s′) =",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"{ 1 (s, s′) ∈ E(WordNet)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"WO(s, s′)",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"otherwise
(7) where E(WordNet) is the edge set of the original WordNet graph andWO(s, s′) is the weighted
2http://babelnet.org 3Retrieved on February 3rd, 2017.
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"overlap measure which calculates the similarity between two synsets:
WO(s, s′) = ∑|S|",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i=1(r 1 i + r
2 i ) −1∑|S|
i=1(2i)−1
where r1i and r 2",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"i are the rankings of the i-th synsets in the set S of the components in common between the vectors associated with s and s′, respectively.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Because at this stage we still have to calculate our synset vector representation, we use the precomputed NASARI vectors (Camacho-Collados et al., 2015) to calculate WO.",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"This choice is due to WO’s higher performance over cosine similarity for vectors with explicit dimensions (Pilehvar et al., 2013).
",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"As a result, each row of the original adjacency matrix M of G will be replaced with the weights calculated in Formula 7 and then normalized in order to be ready for PPR calculation (see Formula 1).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"An idea of why a denser semantic network has more useful connections and thus leads to better results is provided by the example in
iment for the animal, and operating system and Windows for the device sense, among others).",3 Creating a Denser and Multilingual Semantic Network,[0],[0]
"Corpora for sense annotation We used two different corpora to extract sentences: Wikipedia and the United Nations Parallel Corpus (Ziemski et al., 2016).",4 Experimental Setup,[0],[0]
"The first is the largest and most up-to-date encyclopedic resource, containing definitional information, the second, on the other hand, is a public collection of parliamentary documents of the United Nations.",4 Experimental Setup,[0],[0]
"The application of TrainO-Matic to the two corpora produced two senseannotated datasets, which we named T-O-MWiki and T-O-MUN , respectively.
",4 Experimental Setup,[0],[0]
"Semantic Network We created sense-annotated corpora with Train-O-Matic both when using PPR vectors computed from vanilla WordNet and when using WordNetBN , our denser network obtained from the WordNet-induced subgraph of BabelNet (see Section 3).
",4 Experimental Setup,[0],[0]
"Gold standard datasets We performed our evaluations using the framework made available by Raganato et al. (2017a) on five different allwords datasets, namely: the Senseval-2 (Edmonds and Cotton, 2001), Senseval-3 (Snyder and Palmer, 2004), SemEval-2007 (Pradhan et al., 2007), SemEval-2013 (Navigli et al., 2013) and SemEval-2015 (Moro and Navigli, 2015)",4 Experimental Setup,[0],[0]
WSD datasets.,4 Experimental Setup,[0],[0]
"We focused on nouns only, given the fact that Wikipedia provides connections between nominal synsets only, and therefore contributes mainly to syntagmatic relations between nouns.
",4 Experimental Setup,[0],[0]
"Comparison sense-annotated corpora To show the impact of our T-O-M corpora in WSD, we compared its performance on the above gold standard datasets, against training with:
• SemCor (Miller et al., 1993), a corpus containing about 226,000 words annotated manually with WordNet senses.
",4 Experimental Setup,[0],[0]
"• One Million Sense-Tagged Instances (Taghipour and Ng, 2015, OMSTI), a sense-annotated dataset obtained via a semi-automatic approach based on the disambiguation of a parallel corpus, i.e., the United Nations Parallel Corpus, performed by exploiting manually translated word senses.",4 Experimental Setup,[0],[0]
"Because OMSTI integrates SemCor
to increase coverage, to keep a level playing field we excluded the latter from the corpus.
",4 Experimental Setup,[0],[0]
"We note that T-O-M, instead, is fully automatic and does not require any WSD-specific human intervention nor any aligned corpus.
Reference system In all our experiments, we used It Makes Sense (Zhong and Ng, 2010, IMS), a state-of-the-art WSD system based on linear Support Vector Machines, as our reference system for comparing its performance when trained on TO-M, against the same WSD system trained on other sense-annotated corpora (i.e., SemCor and OMSTI).",4 Experimental Setup,[0],[0]
"Following the WSD literature, unless stated otherwise, we report performance in terms of F1, i.e., the harmonic mean of precision and recall.
",4 Experimental Setup,[0],[0]
"We note that it is not the purpose of this paper to show that T-O-M, when integrated into IMS, beats all other configurations or alternative systems, but rather to fully automatize the WSD pipeline with performances which are competitive with the state of the art.
",4 Experimental Setup,[0],[0]
Baseline,4 Experimental Setup,[0],[0]
"As a traditional baseline in WSD, we used the Most Frequent Sense (MFS) baseline given by the first sense in WordNet.",4 Experimental Setup,[0],[0]
"The MFS is a very competitive baseline, due to the sense skewness phenomenon in language (Navigli, 2009).
",4 Experimental Setup,[0],[0]
"Number of training sentences per sense Given a target word w, we sorted its senses Senses(w) following the WordNet ordering and selected the top ki training sentences for the i-th sense according to Formula 6, where:
ki = 1 iz ∗K",4 Experimental Setup,[0],[0]
"(8)
with K = 500 and z = 2 which were tuned on a separate small in-house development dataset5.",4 Experimental Setup,[0],[0]
The first result we report regards the impact of vanilla WordNet vs. our WordNet-induced subgraph of BabelNet (WordNetBN ) when calculating PPR vectors.,5.1 Impact of syntagmatic relations,[0],[0]
"As can be seen from Table 2 – which shows the performance of the T-O-MWiki corpora generated with the two semantic networks – using WordNet for PPR computation decreases
550 word-sense pairs annotated manually.
",5.1 Impact of syntagmatic relations,[0],[0]
"the overall performance of IMS from 0.5 to around 4 points across the five datasets, with an overall loss of 1.6 F1 points.",5.1 Impact of syntagmatic relations,[0],[0]
Similar performance losses were observed when using T-O-MUN (see Table 3).,5.1 Impact of syntagmatic relations,[0],[0]
This corroborates our hunch discussed in Section 3 that a resource like BabelNet can contribute important syntagmatic relations that are beneficial for identifying (and ranking high) sentences which are semantically relevant for the target word sense.,5.1 Impact of syntagmatic relations,[0],[0]
"In the following experiments, we report only results using WordNetBN .",5.1 Impact of syntagmatic relations,[0],[0]
"We now move to comparing the performance of T-O-M, which is fully automatic, against corpora which are annotated manually (SemCor) and semi-automatically (OMSTI).",5.2 Comparison against sense-annotated corpora,[0],[0]
"In Table 3 we show the F1-score of IMS on each gold standard dataset in the evaluation framework and on all datasets merged together (last row), when it is trained with the various corpora described above.
",5.2 Comparison against sense-annotated corpora,[0],[0]
"As can be seen, T-O-MWiki and T-O-MUN obtain higher performance than OMSTI (up to 5.5 points above) on 3 out of 5 datasets, and, overall, T-O-MWiki scores 1 point above OMSTI.",5.2 Comparison against sense-annotated corpora,[0],[0]
"The MFS is in the same ballpark as T-O-MWiki, performing better on some datasets and worse on others.",5.2 Comparison against sense-annotated corpora,[0],[0]
We note that IMS trained on T-O-MWiki succeeds in surpassing or obtaining the same results as IMS trained on SemCor on SemEval15 and SemEval-13.,5.2 Comparison against sense-annotated corpora,[0],[0]
"We view this as a significant achievement given the total absence of manual effort involved in T-O-M. Because overall T-O-MWiki outperforms T-O-MUN , in what follows we report all the results with T-O-MWiki, except for the domain-oriented evaluation (see Section 5.4).",5.2 Comparison against sense-annotated corpora,[0],[0]
"IMS uses the MFS as a backoff strategy when no sense can be output for a target word in context (Zhong and Ng, 2010).",5.3 Performance without backoff strategy,[0],[0]
"Consequently, the performance of the MFS is mixed up with that of the SVM classifier.",5.3 Performance without backoff strategy,[0],[0]
"As shown in Table 4, OMSTI is able to provide annotated sentences for roughly half of the tokens in the datasets.",5.3 Performance without backoff strategy,[0],[0]
"Train-O-Matic, on the other hand, is able to cover almost all words in each dataset with at least one training sentence.",5.3 Performance without backoff strategy,[0],[0]
"This means that in around 50% of cases OMSTI gives an answer based on the IMS backoff strategy.
",5.3 Performance without backoff strategy,[0],[0]
"To determine the real impact of the different training data, we therefore decided to perform an additional analysis of the IMS performance when the MFS backoff strategy is disabled.",5.3 Performance without backoff strategy,[0],[0]
"Because we suspected the system would not always return a sense for each target word, in this experiment we measured precision, recall and their harmonic mean, i.e., F1.",5.3 Performance without backoff strategy,[0],[0]
"The results in Table 5 confirm our hunch, showing that OMSTI’s recall drops heavily, thereby affecting F1 considerably.",5.3 Performance without backoff strategy,[0],[0]
"T-O-M performances, instead, remain high in terms of precision, recall and F1.",5.3 Performance without backoff strategy,[0],[0]
"This confirms that OMSTI relies heavily on data (those obtained for the MFS and from SemCor) that are produced manually, rather than semi-automatically.",5.3 Performance without backoff strategy,[0],[0]
"To further inspect the ability of T-O-M to enable disambiguation in different domains, we decided to evaluate on specific documents from the various gold standard datasets which could be clearly assigned a domain label.",5.4 Domain-oriented WSD,[0],[0]
"Specifically, we tested on 13 SemEval-13 documents from various domains6 and 2 SemEval-15 documents (namely, maths & computers, and biomedicine) and carried out two separate tests and evaluations of T-O-M on each domain: once using the MFS backoff strategy, and once not using it.",5.4 Domain-oriented WSD,[0],[0]
"In Tables 6 and 7 we report the results of both T-O-MWiki and T-O-MUN to determine the impact of the corpus type.
",5.4 Domain-oriented WSD,[0],[0]
"As can be seen in the tables, T-O-MWiki systematically attains higher scores than OMSTI (except for the biology domain), and, in most cases, attains higher scores than MFS when the backoff is used, with a drastic, systematic increase over OMSTI with both Train-O-Matic configurations
6Namely biology, climate, finance, health care, politics, social issues and sport.
in recall and F1 when the backoff strategy is disabled.",5.4 Domain-oriented WSD,[0],[0]
"This demonstrates the usefulness of the corpora annotated by Train-O-Matic not only on open text, but also on specific domains.",5.4 Domain-oriented WSD,[0],[0]
"We note that T-O-MUN obtains the best results in the politics domain, which is the closest domain to the UN corpus from which its training sentences are obtained.",5.4 Domain-oriented WSD,[0],[0]
"Experimental Setup In this section we investigate the ability of Train-O-Matic to scale to lowresourced languages, such as Italian and Spanish, for which training data for WSD is not available.
",6 Scaling up to Multiple Languages,[0],[0]
"Thanks to BabelNet, in fact, Train-O-Matic can
be used to generate sense-annotated data for any language supported by the knowledge base.",6 Scaling up to Multiple Languages,[0],[0]
"Thus, in order to build new training datasets for the two languages, we ran Train-O-Matic on their corresponding versions of Wikipedia, then we tuned the two parameters K and z on an in-house development dataset7.",6 Scaling up to Multiple Languages,[0],[0]
"In contrast to the English setting, in order to calculate Formula 8 we sorted the senses of each word by vertex degree.",6 Scaling up to Multiple Languages,[0],[0]
"Finally we used the output data to train IMS.
Results To perform our evaluation we chose the most recent multilingual task (SemEval 2015 task 13) which includes gold data for Italian and Spanish.",6 Scaling up to Multiple Languages,[0],[0]
"As can be seen from Table 8 TrainO-Matic enabled IMS to perform better than the best participating system (Manion and Sainudiin, 2014, SUDOKU) in all three settings (All domains, Maths & Computer and Biomedicine).",6 Scaling up to Multiple Languages,[0],[0]
"Its performance was in fact, 1 to 3 points higher, with a 6-point peak on Maths & Computer in Spanish and on Biomedicine in Italian.",6 Scaling up to Multiple Languages,[0],[0]
This demonstrates the ability of Train-O-Matic to enable supervised WSD systems to surpass state-of-theart knowledge-based WSD approaches in lowresourced languages without relying on manually curated data for training.,6 Scaling up to Multiple Languages,[0],[0]
There are two mainstream approaches to Word Sense Disambiguation: supervised and knowledge-based approaches.,7 Related Work,[0],[0]
"Both suffer in different ways from the so-called knowledge acquisition bottleneck, that is, the difficulty in obtaining an adequate amount of lexical-semantic data: for training in the case of supervised systems, and for enriching semantic networks in the case of knowledge-based ones (Pilehvar and
7We set K = 100 and z",7 Related Work,[0],[0]
"= 2.3 for Spanish and K = 100 and z = 2.5 for Italian.
Navigli, 2014; Navigli, 2009).
",7 Related Work,[0],[0]
"State-of-the-art supervised systems include Support Vector Machines such as IMS (Zhong and Ng, 2010) and, more recently, LSTM neural networks with attention and multitask learning (Raganato et al., 2017b) as well as LSTMs paired with nearest neighbours classification (Melamud et al., 2016; Yuan et al., 2016).",7 Related Work,[0],[0]
The latter also integrates a label propagation algorithm in order to enrich the sense annotated dataset.,7 Related Work,[0],[0]
"The main difference from our approach is its need for a manually annotated dataset to start the label propagation algorithm, whereas Train-O-Matic is fully automatic.",7 Related Work,[0],[0]
"An evaluation against this system would have been interesting, but neither the proprietary training data nor the code are available at the time of writing.
",7 Related Work,[0],[0]
"In order to generalize effectively, these supervised systems require large numbers of training in-
stances annotated with senses for each target word occurrence.",7 Related Work,[0],[0]
"Overall, this amounts to millions of training instances for each language of interest, a number that is not within reach for any language.",7 Related Work,[0],[0]
"In fact, no supervised system has been submitted in major multilingual WSD competitions for languages other than English (Navigli et al., 2013; Moro and Navigli, 2015).",7 Related Work,[0],[0]
"To overcome this problem, new methodologies have recently been developed which aim to create sense-tagged corpora automatically.",7 Related Work,[0],[0]
Raganato et al. (2016) developed 7 heuristics to grow the number of hyperlinks in Wikipedia pages.,7 Related Work,[0],[0]
"Otegi et al. (2016) applied a different disambiguation pipeline for each language to parallel text in Europarl (Koehn, 2005) and QTLeap (Agirre et al., 2015) in order to enrich them with semantic annotations.",7 Related Work,[0],[0]
"Taghipour and Ng (2015), the work closest to ours, exploits the alignment from English to Chinese sentences of
the United Nation Parallel Corpus (Ziemski et al., 2016) to reduce the ambiguity of English words and sense-tag English sentences.",7 Related Work,[0],[0]
The assumption is that the second language is less ambiguous than the first one and that hand-made translations of senses are available for each WordNet synset.,7 Related Work,[0],[0]
"This approach is, therefore, semi-automatic and relies on certain assumptions, in contrast to TrainO-Matic which is, instead, fully automatic and can be applied to any kind of corpus (and language) depending on the specific need.",7 Related Work,[0],[0]
Earlier attempts at the automatic extraction of training samples were made by Agirre and De Lacalle (2004) and Fernández et al. (2004).,7 Related Work,[0],[0]
"Both exploited the monosemous relatives method (Leacock et al., 1998) in order to retrieve sentences from the Web which contained a given monosemous noun or a relative monosemous word (e.g., a synonym, a hypernym, etc.).",7 Related Work,[0],[0]
"As can be seen in (Fernández et al., 2004)",7 Related Work,[0],[0]
"this approach can lead to the retrieval of very accurate examples, but its main drawback lies in the number of senses covered.",7 Related Work,[0],[0]
"In fact, for all those synsets that do not have any monosemous relative, the system is unable to retrieve examples, thus heavily affecting the performance in terms of recall and F1.",7 Related Work,[0],[0]
"Knowledge-based WSD, instead, bypasses the heavy requirement of sense-annotated corpora by applying algorithms that exploit a general-purpose semantic network, such as WordNet, which encodes the relational information that interconnects synsets via different kinds of relation.",7 Related Work,[0],[0]
"Approaches include variants of Personalized PageRank (Agirre et al., 2014) and densest subgraph approximation algorithms (Moro et al., 2014) which, thanks to the availability of multilingual resources such as BabelNet, can easily be extended to perform WSD in arbitrary languages.",7 Related Work,[0],[0]
Other approaches to knowledge-based WSD exploit the definitional knowledge contained in a dictionary.,7 Related Work,[0],[0]
"The Lesk algorithm (Lesk, 1986) and its variants (Banerjee and Pedersen, 2002; Kilgarriff and Rosenzweig, 2000; Vasilescu et al., 2004) aim to determine the correct sense of a word by comparing each wordsense definition with the context in which the target word appears.",7 Related Work,[0],[0]
"The limit of knowledge-based WSD, however, lies in the absence of mechanisms that can take into account the very local context of a target word occurrence, including non-content words such as prepositions and articles.",7 Related Work,[0],[0]
"Furthermore, recent studies seem to suggest that such
approaches are barely able to surpass supervised WSD systems when they enrich their networks starting from a comparable amount of annotated data (Pilehvar and Navigli, 2014).",7 Related Work,[0],[0]
"With T-O-M, rather than further enriching an existing semantic network, we exploit the information available in the network to annotate raw sentences with sense information and train a state-of-the-art supervised WSD system without task-specific human annotations.",7 Related Work,[0],[0]
"In this paper we presented Train-O-Matic, a novel approach to the automatic construction of large training sets for supervised WSD in an arbitrary language.",8 Conclusion,[0],[0]
"Train-O-Matic removes the burden of manual intervention by leveraging the structural semantic information available in the WordNet graph enriched with additional relational information from BabelNet, and achieves performance competitive to that of semi-automatic approaches and, in some cases, of manually-curated training data.",8 Conclusion,[0],[0]
"T-O-M was shown to provide training data for virtually all the target ambiguous nouns, in marked contrast to alternatives like OMSTI, which covers in many cases around half of the tokens, resorting to the MFS otherwise.",8 Conclusion,[0],[0]
"Moreover Train-O-Matic has proven to scale well to lowresourced languages, for which no manually annotated dataset exists, surpassing the current state of the art of knowledge-based systems.
",8 Conclusion,[0],[0]
"We believe that the ability of T-O-M to overcome the current paucity of annotated data for WSD, coupled with video games with a purpose for validation purposes (Jurgens and Navigli, 2014; Vannella et al., 2014), paves the way for high-quality multilingual supervised WSD.",8 Conclusion,[0],[0]
"All the training corpora, including approximately one million sentences which cover English, Italian and Spanish, are made available to the community at http://trainomatic.org.
",8 Conclusion,[0],[0]
"As future work we plan to extend our approach to verbs, adjectives and adverbs.",8 Conclusion,[0],[0]
Following Bennett et al. (2016) we will also experiment on more realistic estimates of P (s|w) in Formula 5 as well as other assumptions made in our work.,8 Conclusion,[0],[0]
The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE,Acknowledgments,[0],[0]
No.,Acknowledgments,[0],[0]
726487.,Acknowledgments,[0],[0]
Annotating large numbers of sentences with senses is the heaviest requirement of current Word Sense Disambiguation.,abstractText,[0],[0]
"We present Train-O-Matic, a languageindependent method for generating millions of sense-annotated training instances for virtually all meanings of words in a language’s vocabulary.",abstractText,[0],[0]
The approach is fully automatic: no human intervention is required and the only type of human knowledge used is a WordNet-like resource.,abstractText,[0],[0]
"Train-O-Matic achieves consistently state-of-the-art performance across gold standard datasets and languages, while at the same time removing the burden of manual annotation.",abstractText,[0],[0]
All the training data is available for research purposes at http://trainomatic.org.,abstractText,[0],[0]
Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data,title,[0],[0]
"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1968–1978 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics",text,[0],[0]
Neural machine translation has recently become a method of choice in machine translation research.,1 Introduction,[0],[0]
"Besides its success in traditional settings of machine translation, that is one-to-one translation between two languages, (Sennrich et al., 2016; Chung et al., 2016), neural machine translation has ventured into more sophisticated settings of machine translation.",1 Introduction,[0],[0]
"For instance, neural machine translation has successfully proven itself to be capable of
handling subword-level representation of sentences (Lee et al., 2016; Luong and Manning, 2016; Sennrich et al., 2015; Costa-Jussa and Fonollosa, 2016; Ling et al., 2015).",1 Introduction,[0],[0]
"Furthermore, several research groups have shown its potential in seamlessly handling multiple languages (Dong et al., 2015; Luong et al., 2015a; Firat et al., 2016a,b; Lee et al., 2016; Ha et al., 2016; Viégas et al., 2016).
",1 Introduction,[0],[0]
A typical scenario of neural machine translation starts with training a model to maximize its log-likelihood.,1 Introduction,[0],[0]
"That is, we often train a model to maximize the conditional probability of a reference translation given a source sentence over a large parallel corpus.",1 Introduction,[0],[0]
"Once the model is trained in this way, it defines the conditional distribution over all possible translations given a source sentence, and the task of translation becomes equivalent to finding a translation to which the model assigns the highest conditional probability.",1 Introduction,[0.9594381066649355],"['But only on weekends.” The persona is a set of sentences representing the personality of the responding agent, the context is the utterance that it responds to, and the response is the answer to be predicted.']"
"Since it is computationally intractable to do so exactly, it is a usual practice to resort to approximate search/decoding algorithms such as greedy decoding or beam search.",1 Introduction,[0],[0]
"In this scenario, we have identified two points where improvements could be made.",1 Introduction,[0],[0]
"They are (1) training (including the selection of a model architecture) and (2) decoding.
",1 Introduction,[0],[0]
"Much of the research on neural machine translation has focused solely on the former, that is, on improving the model architecture.",1 Introduction,[0],[0]
"Neural machine translation started with with a simple encoderdecoder architecture in which a source sentence is encoded into a single, fixed-size vector (Cho et al., 2014; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013).",1 Introduction,[0],[0]
"It soon evolved with the attention mechanism (Bahdanau et al., 2014).",1 Introduction,[0],[0]
"A few variants of the attention mechanism, or its regularization, have been proposed recently to improve both the translation quality as well as the computational efficiency (Luong et al., 2015b; Cohn et al., 2016; Tu et al., 2016b).",1 Introduction,[0],[0]
"More recently, convolutional net-
1968
works have been adopted either as a replacement of or a complement to a recurrent network in order to efficiently utilize parallel computing (Kalchbrenner et al., 2016; Lee et al., 2016; Gehring et al., 2016).
",1 Introduction,[0],[0]
"On the aspect of decoding, only a few research groups have tackled this problem by incorporating a target decoding algorithm into training.",1 Introduction,[0],[0]
Wiseman and Rush (2016) and Shen et al. (2015) proposed a learning algorithm tailored for beam search.,1 Introduction,[0],[0]
"Ranzato et al. (2015) and (Bahdanau et al., 2016) suggested to use a reinforcement learning algorithm by viewing a neural machine translation model as a policy function.",1 Introduction,[0],[0]
"Investigation on decoding alone has, however, been limited.",1 Introduction,[0],[0]
Cho (2016) showed the limitation of greedy decoding by simply injecting unstructured noise into the hidden state of the neural machine translation system.,1 Introduction,[0],[0]
"Tu et al. (2016a) similarly showed that the exactness of beam search does not correlate well with actual translation quality, and proposed to augment the learning cost function with reconstruction to alleviate this problem.",1 Introduction,[0],[0]
"Li et al. (2016) proposed a modification to the existing beam search algorithm to improve its exploration of the translation space.
",1 Introduction,[0],[0]
"In this paper, we tackle the problem of decoding in neural machine translation by introducing a concept of trainable greedy decoding.",1 Introduction,[0],[0]
"Instead of manually designing a new decoding algorithm suitable for neural machine translation, we propose to learn a decoding algorithm with an arbitrary decoding objective.",1 Introduction,[0],[0]
"More specifically, we introduce a neural-network-based decoding algorithm that works on an already-trained neural machine translation system by observing and manipulating its hidden state.",1 Introduction,[0],[0]
"We treat such a neural network as an agent with a deterministic, continuous action and train it with a variant of the deterministic policy gradient algorithm (Silver et al., 2014).
",1 Introduction,[0],[0]
"We extensively evaluate the proposed trainable greedy decoding on four language pairs (En-Cs, En-De, En-Ru and En-Fi; in both directions) with two different decoding objectives; sentence-level BLEU and negative perplexity.",1 Introduction,[0],[0]
"By training such trainable greedy decoding using deterministic policy gradient with the proposed critic-aware actor learning, we observe that we can improve decoding performance with minimal computational overhead.",1 Introduction,[0],[0]
"Furthermore, the trained actors are found to improve beam search as well, suggesting a future research direction in extending the proposed idea of trainable decoding for more sophisticated
underlying decoding algorithms.",1 Introduction,[0],[0]
"Neural machine translation is a special case of conditional recurrent language modeling, where the source and target are natural language sentences.",2.1 Neural Machine Translation,[0],[0]
"Let us use X = {x1, . . .",2.1 Neural Machine Translation,[0],[0]
", xTs} and Y = {y1, . . .",2.1 Neural Machine Translation,[0],[0]
", yT } to denote source and target sentences, respectively.",2.1 Neural Machine Translation,[0],[0]
"Neural machine translation then models the target sentence given the source sentence as: p(Y |X) = ∏Tt=1 p(yt|y<t, X).",2.1 Neural Machine Translation,[0],[0]
Each term on the r.h.s.,2.1 Neural Machine Translation,[0],[0]
"of the equation above is modelled as a composite of two parametric functions:
p(yt|y<t, X) ∝",2.1 Neural Machine Translation,[0],[0]
"exp (g (yt, zt; θg)) ,
where zt = f(zt−1, yt−1, et(X; θe); θf ).",2.1 Neural Machine Translation,[0],[0]
"g is a read-out function that transforms the hidden state zt into the distribution over all possible symbols, and f is a recurrent function that compresses all the previous target words y<t and the time-dependent representation et(X; θe) of the source sentence X .",2.1 Neural Machine Translation,[0],[0]
"This time-dependent representation et is often implemented as a recurrent network encoder of the source sentence coupled with an attention mechanism (Bahdanau et al., 2014).
",2.1 Neural Machine Translation,[0],[0]
"Maximum Likelihood Learning We train a neural machine translation model, or equivalently estimate the parameters θg, θf and θe, by maximizing the log-probability of a reference translation Ŷ = {ŷ1, ..., ŷT } given a source sentence.",2.1 Neural Machine Translation,[0],[0]
"That is, we maximize the log-likelihood function:
JML(θg, θf , θe) = 1 N N∑ n=1",2.1 Neural Machine Translation,[0],[0]
"Tn∑ t=1 log pθ(ŷnt |ŷn<t, Xn),
given a training set consisting of N source-target sentence pairs.",2.1 Neural Machine Translation,[0],[0]
It is important to note that this maximum likelihood learning does not take into account how a trained model would be used.,2.1 Neural Machine Translation,[0],[0]
"Rather, it is only concerned with learning a distribution over all possible translations.",2.1 Neural Machine Translation,[0],[0]
"Once the model is trained, either by maximum likelihood learning or by any other recently proposed algorithms (Wiseman and Rush, 2016; Shen et al., 2015; Bahdanau et al., 2016; Ranzato et al., 2015), we can let the model translate a given sentence by
finding a translation that maximizes
Ŷ = arg max Y
log pθ(Y |X),
where θ = (θg, θf , θe).",2.2 Decoding,[0],[0]
"This is, however, computationally intractable, and it is a usual practice to resort to approximate decoding algorithms.
",2.2 Decoding,[0],[0]
Greedy Decoding One such approximate decoding algorithm is greedy decoding.,2.2 Decoding,[0],[0]
"In greedy decoding, we follow the conditional dependency path and pick the symbol with the highest conditional probability so far at each node.",2.2 Decoding,[0],[0]
This is equivalent to picking the best symbol one at a time from left to right in conditional language modelling.,2.2 Decoding,[0],[0]
"A decoded translation of greedy decoding is Ŷ = (ŷ1, . . .",2.2 Decoding,[0],[0]
", ŷT ), where
ŷt = arg max y∈V
log pθ(y|ŷ<t, X).",2.2 Decoding,[0],[0]
"(1)
Despite its preferable computational complexity O(|V | × T ), greedy decoding has been over time found to be undesirably sub-optimal.
",2.2 Decoding,[0],[0]
"Beam Search Beam search keeps K > 1 hypotheses, unlike greedy decoding which keeps only a single hypothesis during decoding.",2.2 Decoding,[0],[0]
"At each time step t, beam search picks K hypotheses with the highest scores ( ∏t t′=1 p(yt|y<t, X)).",2.2 Decoding,[0],[0]
"When all the hypotheses terminate (outputting the end-of-thesentence symbol), it returns the hypothesis with the highest log-probability.",2.2 Decoding,[0],[0]
"Despite its superior performance compared to greedy decoding, the computational complexity grows linearly w.r.t.",2.2 Decoding,[0],[0]
"the size of beam K, which makes it less preferable especially in the production environment.",2.2 Decoding,[0],[0]
"Although we have described decoding in neural machine translation as a maximum-a-posteriori estimation in log p(Y |X), this is not necessarily the only nor the desirable decoding objective.
",3.1 Many Decoding Objectives,[0],[0]
"First, each potential scenario in which neural machine translation is used calls for a unique decoding objective.",3.1 Many Decoding Objectives,[0],[0]
"In simultaneous translation/interpretation, which has recently been studied in the context of neural machine translation (Gu et al., 2016), the decoding objective is formulated as a trade-off between the translation quality and delay.",3.1 Many Decoding Objectives,[0],[0]
"On the other hand, when a machine translation system is used as a part of a larger information
extraction system, it is more important to correctly translate named entities and events than to translate syntactic function words.",3.1 Many Decoding Objectives,[0],[0]
"The decoding objective in this case must account for how the translation is used in subsequent modules in a larger system.
",3.1 Many Decoding Objectives,[0],[0]
"Second, the conditional probability assigned by a trained neural machine translation model does not necessarily reflect our perception of translation quality.",3.1 Many Decoding Objectives,[0],[0]
"Although Cho (2016) provided empirical evidence of high correlation between the logprobability and BLEU, a de facto standard metric in machine translation, there have also been reports on large mismatch between the log-probability and BLEU.",3.1 Many Decoding Objectives,[0],[0]
"For instance, Tu et al. (2016a) showed that beam search with a very large beam, which is supposed to find translations with better logprobabilities, suffers from pathological translations of very short length, resulting in low translation quality.",3.1 Many Decoding Objectives,[0],[0]
"This calls for a way to design or learn a decoding algorithm with an objective that is more directly correlated to translation quality.
",3.1 Many Decoding Objectives,[0],[0]
"In short, there is a significant need for designing multiple decoding algorithms for neural machine translation, regardless of how it was trained.",3.1 Many Decoding Objectives,[0],[0]
It is however non-trivial to manually design a new decoding algorithm with an arbitrary objective.,3.1 Many Decoding Objectives,[0],[0]
"This is especially true with neural machine translation, as the underlying structure of the decoding/search process – the high-dimensional hidden state of a recurrent network – is accessible but not interpretable.",3.1 Many Decoding Objectives,[0],[0]
"Instead, in the remainder of this section, we propose our approach of trainable greedy decoding.",3.1 Many Decoding Objectives,[0],[0]
"We start from the noisy, parallel approximate decoding (NPAD) algorithm proposed in (Cho, 2016).",3.2 Trainable Greedy Decoding,[0],[0]
The main idea behind NPAD algorithm is that a better translation with a higher log-probability may be found by injecting unstructured noise in the transition function of a recurrent network.,3.2 Trainable Greedy Decoding,[0],[0]
"That is,
zt = f(zt−1 + t, yt−1, et(X; θe); θf ),
where t ∼ N (0, (σ0/t)2).",3.2 Trainable Greedy Decoding,[0],[0]
NPAD avoids potential degradation of translation quality by running such a noisy greedy decoding process multiple times in parallel.,3.2 Trainable Greedy Decoding,[0],[0]
"An important lesson of NPAD algorithm is that there exists a decoding strategy with the asymptotically same computational complexity that results in a better translation quality, and that such a better translation can be found by manipulating the hidden state of the recurrent network.
",3.2 Trainable Greedy Decoding,[0],[0]
"In this work, we propose to significantly extend NPAD by replacing the unstructured noise t with a parametric function approximator, or an agent, πφ.",3.2 Trainable Greedy Decoding,[0],[0]
"This agent takes as input the previous hidden state zt−1, previously decoded word ŷt−1 and the time-dependent context vector et(X; θe) and outputs a real-valued vectorial action at ∈ Rdim(zt).",3.2 Trainable Greedy Decoding,[0],[0]
"Such an agent is trained such that greedy decoding with the agent finds a translation that maximizes any predefined, arbitrary decoding objective, while the underlying neural machine translation model is pretrained and fixed.",3.2 Trainable Greedy Decoding,[0],[0]
"Once the agent is trained, we generate a translation given a source sentence by greedy decoding however augmented with this agent.",3.2 Trainable Greedy Decoding,[0],[0]
"We call this decoding strategy trainable greedy decoding.
",3.2 Trainable Greedy Decoding,[0],[0]
Related Work:,3.2 Trainable Greedy Decoding,[0],[0]
"Soothsayer prediction function Independently from and concurrently with our work here, Li et al. (2017) proposed, just two weeks earlier, to train a neural network that predicts an arbitrary decoding objective given a source sentence and a partial hypothesis, or a prefix of translation, and to use it as an auxiliary score in beam search.",3.2 Trainable Greedy Decoding,[0],[0]
"For training such a network, referred to as a Q network in their paper, they generate each training example by either running beam search or using a ground-truth translation (when appropriate) for each source sentence.",3.2 Trainable Greedy Decoding,[0],[0]
"This approach allows one to use an arbitrary decoding objective, but it still re-
lies heavily on the log-probability of the underlying neural translation system in actual decoding.",3.2 Trainable Greedy Decoding,[0],[0]
We expect a combination of these and our approaches may further improve decoding for neural machine translation in the future.,3.2 Trainable Greedy Decoding,[0],[0]
"While all the parameters—θg, θf and θe— of the underlying neural translation model are fixed, we only update the parameters φ of the agent π.",3.3 Learning and Challenges,[0],[0]
"This ensures the generality of the pretrained translation model, and allows us to train multiple trainable greedy decoding agents with different decoding objectives, maximizing the utility of a single trained translation model.
",3.3 Learning and Challenges,[0],[0]
Let us denote by R our arbitrary decoding objective as a function that scores a translation generated from trainable greedy decoding.,3.3 Learning and Challenges,[0],[0]
"Then, our learning objective for trainable greedy decoding is
JA(φ) = EŶ=Gπ(X)X∼D",3.3 Learning and Challenges,[0],[0]
"[ R(Ŷ ) ] ,
where we used Gπ(X) as a shorthand for trainable greedy decoding with an agent π.
",3.3 Learning and Challenges,[0],[0]
There are two major challenges in learning an agent with such an objective.,3.3 Learning and Challenges,[0],[0]
"First, the decoding objective R may not be differentiable with respect to the agent.",3.3 Learning and Challenges,[0],[0]
"Especially because our goal is to accommodate an arbitrary decoding objective, this becomes a problem.",3.3 Learning and Challenges,[0],[0]
"For instance, BLEU, a standard
quality metric in machine translation, is a piecewise linear function with zero derivatives almost everywhere.",3.3 Learning and Challenges,[0],[0]
"Second, the agent here is a real-valued, deterministic policy with a very high-dimensional action space (1000s of dimensions), which is well known to be difficult.",3.3 Learning and Challenges,[0],[0]
"In order to alleviate these difficulties, we propose to use a variant of the deterministic policy gradient algorithm (Silver et al., 2014; Lillicrap et al., 2015).",3.3 Learning and Challenges,[0],[0]
"It is highly unlikely for us to have access to the gradient of an arbitrary decoding objective R with respect to the agent π, or its parameters φ.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Furthermore, we cannot estimate it stochastically because our policy π is defined to be deterministic without a predefined nor learned distribution over the action.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Instead, following (Silver et al., 2014; Lillicrap et al., 2015), we use a parametric, differentiable approximator, called a critic Rc, for the non-differentiable objective R. We train the critic by minimizing
JC(ψ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D [ Rcψ(z1:T )−R(Ŷ ),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"]2 .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"The critic observes the state-action sequence of the agent π via the modified hidden states (z1, . . .",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
", zT )",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"of the recurrent network, and predicts the associated decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"By minimizing the mean squared error above, we effectively encourage the critic to approximate the non-differentiable objective as closely as possible in the vicinity of the state-action sequence visited by the agent.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We implement the critic Rc as a recurrent network, similarly to the underlying neural machine translation system.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"This implies that we can compute the derivative of the predicted decoding objective with respect to the input, that is, the state-action sequence z1:T , which allows us to update the actor π, or equivalently its parameters φ, to maximize the predicted decoding objective.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Effectively we avoid the issue of non-differentiability of the original decoding objective by working with its proxy.
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"With the critic, the learning objective of the actor is now to maximize not the original decoding objective R but its proxy RC such that
ĴA(φ)",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
= EŶ=Gπ(X)X∼D,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"[ RC(Ŷ ) ] .
",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Algorithm 1 Trainable Greedy Decoding Require: NMT θ, actor φ, critic ψ, Nc, Na, Sc, Sa, τ
1: Train θ using MLE on training set D; 2: Initialize φ and ψ; 3:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Shuffle D twice into Dφ and Dψ 4: while stopping criterion is not met do 5: for t = 1 :,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Nc do 6: Draw a translation pair: (X,Y ) ∼ Dψ; 7: r, rc = DECODE(Sc, X, Y, 1) 8:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Update ψ using∇ψ ∑ k (r c,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
k,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"− rk)2/(Sc + 1)
9: for t = 1 : Na do 10: Draw a translation pair: (X,Y ) ∼ Dφ; 11: r, rc = DECODE(Sa, X, Y, 0) 12: Compute wk = exp
(− (rck − rk)2 /τ) 13: Compute w̃k = wk/ ∑ k wk
14: Update φ using −∑k",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
(w̃k · ∇φrck),4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Function: DECODE(S,X, Y, c)
1: Ys = {}, Zs = {}, r = {}, rc = {}; 2: for k = 1 : S do 3: Sample noise ∼ N (0, σ2) for each action; 4: Greedy decoding Ŷ k = Gθ,φ(X) with ; 5: Collect hidden states zk1:T given X , Ŷ , θ, φ 6: Ys ← Ys ∪ {Y k} 7:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {zk1:T } 8: if c = 1 then 9: Collect hidden states z1:T given X , Y , θ
10: Ys ← Ys ∪ {Y } 11:",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Zs ← Zs ∪ {z1:T } 12: for Ŷ , Z ∈ Ys, Zs do 13: Compute the critic output rc ← Rcψ(Z, Ŷ ) 14: Compute true reward r ← R(Y, Ŷ ) 15: return r, rc
Unlike the original objective, this objective function is fully differentiable with respect to the agent π.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"We thus use a usual stochastic gradient descent algorithm to train the agent, while simultaneously training the critic.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
We do so by alternating between training the actor and critic.,4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
"Note that we maximize the return of a full episode rather than the Q value, unlike usual approaches in reinforcement learning.",4.1 Deterministic Policy Gradient for Trainable Greedy Decoding,[0],[0]
Challenges The most apparent challenge for training such a deterministic actor with a large action space is that most of action configurations will lead to zero return.,4.2 Critic-Aware Actor Learning,[0],[0]
It is also not trivial to devise an efficient exploration strategy with a deterministic actor with real-valued actions.,4.2 Critic-Aware Actor Learning,[0],[0]
"This issue has however turned out to be less of a problem than in a usual reinforcement learning setting, as the state and action spaces are well structured thanks to pretraining by maximum likelihood learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"As observed by Cho (2016), any reasonable perturbation to the hidden state of the recurrent network generates a reasonable translation which would re-
ceive again a reasonable return.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Although this property of dense reward makes the problem of trainable greedy decoding more manageable, we have observed other issues during our preliminary experiment with the vanilla deterministic policy gradient.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid these issues that caused instability, we propose the following modifications to the vanilla algorithm.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-Aware Actor Learning A major goal of the critic is not to estimate the return of a given episode, but to estimate the gradient of the return evaluated given an episode.",4.2 Critic-Aware Actor Learning,[0],[0]
"In order to do so, the critic must be trained, or presented, with stateaction sequences z1:T ′ similar though not identical to the state-action sequence generated by the current actor π.",4.2 Critic-Aware Actor Learning,[0],[0]
"This is achieved, in our case, by injecting unstructured noise to the action at each
time step, similar to (Heess et al., 2015):
ãt = φ(zt, at−1) + σ · , (2)
where is a zero-mean, unit-variance normal variable.",4.2 Critic-Aware Actor Learning,[0],[0]
"This noise injection procedure is mainly used when training the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
We have however observed that the quality of the reward and its gradient estimate of the critic is very noisy even when the critic was trained with this kind of noisy actor.,4.2 Critic-Aware Actor Learning,[0],[0]
This imperfection of the critic often led to the instability in training the actor in our preliminary experiments.,4.2 Critic-Aware Actor Learning,[0],[0]
"In order to avoid this, we describe here a technique which we refer to as critic-aware actor gradient estimation.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Instead of using the point estimate ∂R c
∂φ of the gradient of the predicted objective with respect to the actor’s parameters φ, we propose to use the expected gradient of the predicted objective with
respect to the critic-aware distribution Q.",4.2 Critic-Aware Actor Learning,[0],[0]
"That is,
EQ [ ∂Rcψ ∂φ ] , (3)
where we define the critic-aware distribution Q as
Q( ) ∝",4.2 Critic-Aware Actor Learning,[0],[0]
exp(−(Rcψ −R)2/τ︸,4.2 Critic-Aware Actor Learning,[0],[0]
︷︷ ︸,4.2 Critic-Aware Actor Learning,[0],[0]
"Critic-awareness
) exp(− 2
2σ2︸ ︷︷ ︸ Locality ).",4.2 Critic-Aware Actor Learning,[0],[0]
"(4)
",4.2 Critic-Aware Actor Learning,[0],[0]
"This expectation allows us to incorporate the noisy, non-uniform nature of the critic’s approximation of the objective by up-weighting the gradient computed at a point with a higher critic quality and down-weighting the gradient computed at a point with a lower critic quality.",4.2 Critic-Aware Actor Learning,[0],[0]
"The first term in Q reflects this, while the second term ensures that our estimation is based on a small region around the state-action sequence generated by the current, noise-free actor π.
",4.2 Critic-Aware Actor Learning,[0],[0]
Since it is intractable to compute Eq.,4.2 Critic-Aware Actor Learning,[0],[0]
"(3) exactly, we resort to importance sampling with the proposed distribution equal to the second term in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
(4).,4.2 Critic-Aware Actor Learning,[0],[0]
"Then, our gradient estimate for the actor becomes the sum of the gradients from multiple realizations of the noisy actor in Eq.",4.2 Critic-Aware Actor Learning,[0],[0]
"(2), where each gradient is weighted by the quality of the critic exp(−(Rcφ − R)2/τ).",4.2 Critic-Aware Actor Learning,[0],[0]
τ is a hyperparameter that controls the smoothness of the weights.,4.2 Critic-Aware Actor Learning,[0],[0]
"We observed in our preliminary experiment that the use of this criticaware actor learning significantly stabilizes general learning of both the actor and critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"Reference Translations for Training the Critic In our setting of neural machine translation, we have access to a reference translation for each source sentence X , unlike in a usual setting of reinforcement learning.",4.2 Critic-Aware Actor Learning,[0],[0]
"By force-feeding the reference translation into the underlying neural machine translation system (rather than feeding the decoded symbols), we can generate the reference state-action sequence.",4.2 Critic-Aware Actor Learning,[0],[0]
"This sequence is much less correlated with those sequences generated by the actor, and facilitates computing a better estimate of the gradient w.r.t.",4.2 Critic-Aware Actor Learning,[0],[0]
"the critic.
",4.2 Critic-Aware Actor Learning,[0],[0]
"In Alg. 1, we present the complete algorithm.",4.2 Critic-Aware Actor Learning,[0],[0]
"To make the description less cluttered, we only show the version of minibatch size = 1 which can be naturally extended.",4.2 Critic-Aware Actor Learning,[0],[0]
We also illustrate the proposed trainable greedy decoding and the proposed learning strategy in Fig. 1.,4.2 Critic-Aware Actor Learning,[0],[0]
"We empirically evaluate the proposed trainable greedy decoding on four language pairs – EnDe, En-Ru, En-Cs and En-Fi – using a standard attention-based neural machine translation system (Bahdanau et al., 2014).",5 Experimental Settings,[0],[0]
We train underlying neural translation systems using the parallel corpora made available from WMT’15.1 The same set of corpora are used for trainable greedy decoding as well.,5 Experimental Settings,[0],[0]
"All the corpora are tokenized and segmented into subword symbols using byte-pair encoding (BPE) (Sennrich et al., 2015).",5 Experimental Settings,[0],[0]
We use sentences of length up to 50 subword symbols for MLE training and 200 symbols for trainable decoding.,5 Experimental Settings,[0],[0]
"For validation and testing, we use newstest-2013 and newstest-2015, respectively.",5 Experimental Settings,[0],[0]
"Underlying NMT Model For each language pair, we implement an attention-based neural machine translation model whose encoder and decoder recurrent networks have 1,028 gated recurrent units (GRU, Cho et al., 2014) each.",5.1 Model Architectures and Learning,[0],[0]
Source and target symbols are projected into 512-dimensional embedding vectors.,5.1 Model Architectures and Learning,[0],[0]
"We trained each model for approximately 1.5 weeks using Adadelta (Zeiler, 2012).
",5.1 Model Architectures and Learning,[0],[0]
Actor π,5.1 Model Architectures and Learning,[0],[0]
We use a feedforward network with a single hidden layer as the actor.,5.1 Model Architectures and Learning,[0],[0]
"The input is a 2,056-dimensional vector which is the concatenation of the decoder hidden state and the timedependent context vector from the attention mech-
1http://www.statmt.org/wmt15/
anism, and it outputs a 1,028-dimensional action vector for the decoder.",5.1 Model Architectures and Learning,[0],[0]
"We use 32 units for the hidden layer with tanh activations.
",5.1 Model Architectures and Learning,[0],[0]
Critic Rc The critic is implemented as a variant of an attention-based neural machine translation model that takes a reference translation as a source sentence and a state-action sequence from the actor as a target sentence.,5.1 Model Architectures and Learning,[0],[0]
Both the size of GRU units and embedding vectors are the same with the underlying model.,5.1 Model Architectures and Learning,[0],[0]
"Unlike a usual neural machine translation system, the critic does not language-model the target sentence but simply outputs a scalar value to predict the true return.",5.1 Model Architectures and Learning,[0],[0]
"When we predict a bounded return, such as sentence BLEU, we use a sigmoid activation at the output.",5.1 Model Architectures and Learning,[0],[0]
"For other unbounded return like perplexity, we use a linear activation.
",5.1 Model Architectures and Learning,[0],[0]
Learning We train the actor and critic simultaneously by alternating between updating the actor and critic.,5.1 Model Architectures and Learning,[0],[0]
"As the quality of the critic’s approximation of the decoding objective has direct influence on the actor’s learning, we make ten updates to the critic before each time we update the actor once.",5.1 Model Architectures and Learning,[0],[0]
"We use RMSProp (Tieleman and Hinton, 2012) with the initial learning rates of 2× 10−6 and 2× 10−4, respectively, for the actor and critic.
",5.1 Model Architectures and Learning,[0],[0]
We monitor the progress of learning by measuring the decoding objective on the validation set.,5.1 Model Architectures and Learning,[0],[0]
"After training, we pick the actor that results in the best decoding objective on the validation set, and test it on the test set.
",5.1 Model Architectures and Learning,[0],[0]
"Decoding Objectives For each neural machine translation model, pretrained using maximum likelihood criterion, we train two trainable greedy decoding actors.",5.1 Model Architectures and Learning,[0],[0]
"One actor is trained to maximize BLEU (or its smoothed version for sentence-level
scoring (Lin and Och, 2004))",5.1 Model Architectures and Learning,[0],[0]
"as its decoding objective, and the other to minimize perplexity (or equivalently the negative log-probability normalized by the length.)
",5.1 Model Architectures and Learning,[0],[0]
We have chosen the first two decoding objectives for two purposes.,5.1 Model Architectures and Learning,[0],[0]
"First, we demonstrate that it is possible to build multiple trainable decoders with a single underlying model trained using maximum likelihood learning.",5.1 Model Architectures and Learning,[0],[0]
"Second, the comparison between these two objectives provides a glimpse into the relationship between BLEU (the most widely used automatic metric for evaluating translation systems) and log-likelihood (the most widely used learning criterion for neural machine translation).
",5.1 Model Architectures and Learning,[0],[0]
Evaluation We test the trainable greedy decoder with both greedy decoding and beam search.,5.1 Model Architectures and Learning,[0],[0]
"Although our decoder is always trained with greedy decoding, beam search in practice can be used together with the actor of the trainable greedy decoder.",5.1 Model Architectures and Learning,[0],[0]
Beam search is expected to work better especially when our training of the trainable greedy decoder is unlikely to be optimal.,5.1 Model Architectures and Learning,[0],[0]
"In both cases, we report both the perplexity and BLEU.",5.1 Model Architectures and Learning,[0],[0]
We present the improvements of BLEU and perplexity (or its negation) in Fig. 2 for all the language pair-directions.,5.2 Results and Analysis,[0],[0]
It is clear from these plots that the best result is achieved when the trainable greedy decoder was trained to maximize the target decoding objective.,5.2 Results and Analysis,[0],[0]
"When the decoder was trained to maximize sentence-level BLEU, we see the improvement in BLEU but often the degradation in the perplexity (see the left plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"On the other hand, when the actor was trained to minimize the perplexity, we only see the improvement in per-
plexity (see the right plots in Fig. 2.)",5.2 Results and Analysis,[0],[0]
"This confirms our earlier claim that it is necessary and desirable to tune for the target decoding objective regardless of what the underlying translation system was trained for, and strongly supports the proposed idea of trainable decoding.
",5.2 Results and Analysis,[0],[0]
"The improvement from using the proposed trainable greedy decoding is smaller when used together with beam search, as seen in Fig. 2 (b).",5.2 Results and Analysis,[0],[0]
"However, we still observe statistically significant improvement in terms of BLEU (marked with red stars.)",5.2 Results and Analysis,[0],[0]
"This suggests a future direction in which we extend the proposed trainable greedy decoding to directly incorporate beam search into its training procedure to further improve the translation quality.
",5.2 Results and Analysis,[0],[0]
It is worthwhile to note that we achieved all of these improvements with negligible computational overhead.,5.2 Results and Analysis,[0],[0]
"This is due to the fact that our actor is a very small, shallow neural network, and that the more complicated critic is thrown away after training.",5.2 Results and Analysis,[0],[0]
We suspect the effectiveness of such a small actor is due to the well-structured hidden state space of the underlying neural machine translation model which was trained with a large amount of parallel corpus.,5.2 Results and Analysis,[0],[0]
"We believe this favourable computational complexity makes the proposed method suitable for production-grade neural machine translation (Wu et al., 2016; Crego et al., 2016).
",5.2 Results and Analysis,[0],[0]
"Importance of Critic-Aware Actor Learning In Fig. 3, we show sample learning curves with and without the proposed critic-aware actor learning.",5.2 Results and Analysis,[0],[0]
Both curves were from the models trained under the same condition.,5.2 Results and Analysis,[0],[0]
"Despite a slower start in the early stage of learning, we see that the critic-aware actor learning has greatly stabilized the learning progress.",5.2 Results and Analysis,[0],[0]
"We emphasize that we would not have been able to train all these 16 actors without the proposed critic-aware actor learning.
",5.2 Results and Analysis,[0],[0]
"Examples In Fig. 4, we present three examples from Ru-En.",5.2 Results and Analysis,[0],[0]
"We defined the influence as the KL divergence between the conditional distributions without the trainable greedy decoding and with the trainable greedy decoding, assuming the fixed previous hidden state and target symbol.",5.2 Results and Analysis,[0.9569232757297591],['We also encode all candidate responses and compute the dot-product between all those candidate representations and the joint representation of the context and the persona.']
"We colored a target word with magenta, when the influence of the trainable greedy decoding is large (> 0.001).",5.2 Results and Analysis,[0],[0]
Manual inspection of these examples as well as others has revealed that the trainable greedy decoder focuses on fixing prepositions and removing any unnecessary symbol generation.,5.2 Results and Analysis,[0],[0]
"More in-depth
analysis is however left as future work.",5.2 Results and Analysis,[0],[0]
We proposed trainable greedy decoding as a way to learn a decoding algorithm for neural machine translation with an arbitrary decoding objective.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoder observes and manipulates the hidden state of a trained neural translation system, and is trained by a novel variant of deterministic policy gradient, called critic-aware actor learning.",6 Conclusion,[0],[0]
Our extensive experiments on eight language pair-directions and two objectives confirmed its validity and usefulness.,6 Conclusion,[0],[0]
"The proposed trainable greedy decoding is a generic idea that can be applied to any recurrent language modeling, and we anticipate future research both on the fundamentals of the trainable decoding as well as on the applications to more diverse tasks such as image caption generating and dialogue modeling.",6 Conclusion,[0],[0]
"KC thanks the support by TenCent, eBay, Facebook, Google (Google Faculty Award 2016) and NVidia.",Acknowledgement,[0],[0]
This work was partly supported by Samsung Advanced Institute of Technology (Next Generation Deep Learning: from pattern recognition to AI).,Acknowledgement,[0],[0]
"We sincerely thank Martin Arjovsky, Zihang Dai, Graham Neubig, Pengcheng Yin and Chunting Zhou for helpful discussions and insightful feedbacks.",Acknowledgement,[0],[0]
Recent research in neural machine translation has largely focused on two aspects; neural network architectures and end-toend learning algorithms.,abstractText,[0],[0]
"The problem of decoding, however, has received relatively little attention from the research community.",abstractText,[0],[0]
"In this paper, we solely focus on the problem of decoding given a trained neural machine translation model.",abstractText,[0],[0]
"Instead of trying to build a new decoding algorithm for any specific decoding objective, we propose the idea of trainable decoding algorithm in which we train a decoding algorithm to find a translation that maximizes an arbitrary decoding objective.",abstractText,[0],[0]
"More specifically, we design an actor that observes and manipulates the hidden state of the neural machine translation decoder and propose to train it using a variant of deterministic policy gradient.",abstractText,[0],[0]
"We extensively evaluate the proposed algorithm using four language pairs and two decoding objectives, and show that we can indeed train a trainable greedy decoder that generates a better translation (in terms of a target decoding objective) with minimal computational overhead.",abstractText,[0],[0]
Trainable Greedy Decoding for Neural Machine Translation,title,[0],[0]
"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1884–1895 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics
1884",text,[0],[0]
"The standard protocol for obtaining a labeled dataset is to have a human annotator view each example, assess its relevance, and provide a label (e.g., positive or negative for binary classification).",1 Introduction,[0],[0]
"However, this only provides one bit of information per example.",1 Introduction,[0],[0]
"This invites the question: how can we get more information per example, given that the annotator has already spent the effort reading and understanding an example?
",1 Introduction,[0],[0]
"Previous works have relied on identifying relevant parts of the input such as labeling features (Druck et al., 2009; Raghavan et al., 2005; Liang et al., 2009), highlighting rationale phrases in
text (Zaidan and Eisner, 2008; Arora and Nyberg, 2009), or marking relevant regions in images (Ahn et al., 2006).",1 Introduction,[0],[0]
"But there are certain types of information which cannot be easily reduced to annotating a portion of the input, such as the absence of a certain word, or the presence of at least two words.",1 Introduction,[0],[0]
"In this work, we tap into the power of natural language and allow annotators to provide supervision to a classifier via natural language explanations.
",1 Introduction,[0],[0]
"Specifically, we propose a framework in which annotators provide a natural language explanation for each label they assign to an example (see Figure 1).",1 Introduction,[0],[0]
"These explanations are parsed into logical forms representing labeling functions (LFs), functions that heuristically map examples to labels (Ratner et al., 2016).",1 Introduction,[0],[0]
"The labeling functions are
then executed on many unlabeled examples, resulting in a large, weakly-supervised training set that is then used to train a classifier.
",1 Introduction,[0],[0]
"Semantic parsing of natural language into logical forms is recognized as a challenging problem and has been studied extensively (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011; Liang, 2016).",1 Introduction,[0],[0]
"One of our major findings is that in our setting, even a simple rule-based semantic parser suffices for three reasons: First, we find that the majority of incorrect LFs can be automatically filtered out either semantically (e.g., is it consistent with the associated example?) or pragmatically (e.g., does it avoid assigning the same label to the entire training set?).",1 Introduction,[0],[0]
"Second, LFs near the gold LF in the space of logical forms are often just as accurate (and sometimes even more accurate).",1 Introduction,[0],[0]
"Third, techniques for combining weak supervision sources are built to tolerate some noise (Alfonseca et al., 2012; Takamatsu et al., 2012; Ratner et al., 2018).",1 Introduction,[0],[0]
The significance of this is that we can deploy the same semantic parser across tasks without task-specific training.,1 Introduction,[0],[0]
"We show how we can tackle a real-world biomedical application with the same semantic parser used to extract instances of spouses.
",1 Introduction,[0],[0]
"Our work is most similar to that of Srivastava et al. (2017), who also use natural language explanations to train a classifier, but with two important differences.",1 Introduction,[0],[0]
"First, they jointly train a task-specific semantic parser and classifier, whereas we use a
simple rule-based parser.",1 Introduction,[0],[0]
"In Section 4, we find that in our weak supervision framework, the rule-based semantic parser and the perfect parser yield nearly identical downstream performance.",1 Introduction,[0],[0]
"Second, while they use the logical forms of explanations to produce features that are fed directly to a classifier, we use them as functions for labeling a much larger training set.",1 Introduction,[0],[0]
"In Section 4, we show that using functions yields a 9.5 F1 improvement (26% relative improvement) over features, and that the F1 score scales with the amount of available unlabeled data.
",1 Introduction,[0],[0]
We validate our approach on two existing datasets from the literature (extracting spouses from news articles and disease-causing chemicals from biomedical abstracts) and one real-world use case with our biomedical collaborators at OccamzRazor to extract protein-kinase interactions related to Parkinson’s disease from text.,1 Introduction,[0],[0]
We find empirically that users are able to train classifiers with comparable F1 scores up to two orders of magnitude faster when they provide natural language explanations instead of individual labels.,1 Introduction,[0],[0]
"Our code and data can be found at https:// github.com/HazyResearch/babble.
2",1 Introduction,[0],[0]
"The BabbleLabble Framework
The BabbleLabble framework converts natural language explanations and unlabeled data into a noisily-labeled training set (see Figure 2).",1 Introduction,[0],[0]
"There are three key components: a semantic parser, a filter bank, and a label aggregator.",1 Introduction,[0],[0]
"The semantic
parser converts natural language explanations into a set of logical forms representing labeling functions (LFs).",1 Introduction,[0],[0]
The filter bank removes as many incorrect LFs as possible without requiring ground truth labels.,1 Introduction,[0],[0]
The remaining LFs are applied to unlabeled examples to produce a matrix of labels.,1 Introduction,[0],[0]
"This label matrix is passed into the label aggregator, which combines these potentially conflicting and overlapping labels into one label for each example.",1 Introduction,[0],[0]
The resulting labeled examples are then used to train an arbitrary discriminative model.,1 Introduction,[0],[0]
"To create the input explanations, the user views a subset S of an unlabeled dataset D (where |S| |D|) and provides for each input xi ∈ S a label yi and a natural language explanation ei, a sentence explaining why the example should receive that label.",2.1 Explanations,[0],[0]
"The explanation ei generally refers to specific aspects of the example (e.g., in Figure 2, the location of a specific string “his wife”).",2.1 Explanations,[0],[0]
"The semantic parser takes a natural language explanation ei and returns a set of LFs (logical forms or labeling functions) {f1, . . .",2.2 Semantic Parser,[0],[0]
", fk} of the form fi : X → {−1, 0, 1} in a binary classification setting, with 0 representing abstention.",2.2 Semantic Parser,[0],[0]
"We emphasize that the goal of this semantic parser is not to generate the single correct parse, but rather to have coverage over many potentially useful LFs.1
1Indeed, we find empirically that an incorrect LF nearby the correct one in the space of logical forms actually has higher end-task accuracy 57% of the time (see Section 4.2).
",2.2 Semantic Parser,[0],[0]
We choose a simple rule-based semantic parser that can be used without any training.,2.2 Semantic Parser,[0],[0]
"Formally, the parser uses a set of rules of the form α → β, where α can be replaced by the token(s) in β (see Figure 3 for example rules).",2.2 Semantic Parser,[0],[0]
"To identify candidate LFs, we recursively construct a set of valid parses for each span of the explanation, based on the substitutions defined by the grammar rules.",2.2 Semantic Parser,[0],[0]
"At the end, the parser returns all valid parses (LFs in our case) corresponding to the entire explanation.
",2.2 Semantic Parser,[0],[0]
We also allow an arbitrary number of tokens in a given span to be ignored when looking for a matching rule.,2.2 Semantic Parser,[0],[0]
"This improves the ability of the parser to handle unexpected input, such as unknown words or typos, since the portions of the input that are parseable can still result in a valid parse.",2.2 Semantic Parser,[0],[0]
"For example, in Figure 3, the word “person” is ignored.
",2.2 Semantic Parser,[0],[0]
"All predicates included in our grammar (summarized in Table 1) are provided to annotators, with minimal examples of each in use (Appendix A).",2.2 Semantic Parser,[0],[0]
"Importantly, all rules are domain independent (e.g., all three relation extraction tasks that we tested used the same grammar), making the semantic parser easily transferrable to new domains.",2.2 Semantic Parser,[0],[0]
"Additionally, while this paper focuses on the task of relation extraction, in principle the BabbleLabble framework can be applied to other tasks or settings by extending the grammar with the necessary primitives (e.g., adding primitives for rows and columns to enable explanations about the alignments of words in tables).",2.2 Semantic Parser,[0],[0]
"To guide the construction of the grammar, we collected 500 explanations for the Spouse domain from workers
on Amazon Mechanical Turk and added support for the most commonly used predicates.",2.2 Semantic Parser,[0],[0]
These were added before the experiments described in Section 4.,2.2 Semantic Parser,[0],[0]
Altogether the grammar contains 200 rule templates.,2.2 Semantic Parser,[0],[0]
The input to the filter bank is a set of candidate LFs produced by the semantic parser.,2.3 Filter Bank,[0],[0]
The purpose of the filter bank is to discard as many incorrect LFs as possible without requiring additional labels.,2.3 Filter Bank,[0],[0]
"It consists of two classes of filters: semantic and pragmatic.
",2.3 Filter Bank,[0],[0]
"Recall that each explanation ei is collected in the context of a specific labeled example (xi, yi).",2.3 Filter Bank,[0],[0]
"The semantic filter checks for LFs that are inconsistent with their corresponding example; formally, any LF f for which f(xi) 6=",2.3 Filter Bank,[0],[0]
yi is discarded.,2.3 Filter Bank,[0],[0]
"For example, in the first explanation in Figure 2, the word “right” can be interpreted as either “immediately” (as in “right before”) or simply “to the
right.”",2.3 Filter Bank,[0],[0]
"The latter interpretation results in a function that is inconsistent with the associated example (since “his wife” is actually to the left of person 2), so it can be safely removed.
",2.3 Filter Bank,[0],[0]
"The pragmatic filters removes LFs that are constant, redundant, or correlated.",2.3 Filter Bank,[0],[0]
"For example, in Figure 2, LF 2a is constant, as it labels every example positively (since all examples contain two people from the same sentence).",2.3 Filter Bank,[0],[0]
"LF 3b is redundant, since even though it has a different syntax tree from LF 3a, it labels the training set identically and therefore provides no new signal.
",2.3 Filter Bank,[0],[0]
"Finally, out of all LFs from the same explanation that pass all the other filters, we keep only the most specific (lowest coverage) LF.",2.3 Filter Bank,[0],[0]
"This prevents multiple correlated LFs from a single example from dominating.
",2.3 Filter Bank,[0],[0]
"As we show in Section 4, over three tasks, the filter bank removes 86% of incorrect parses, and the incorrect ones that remain have average endtask accuracy within 2.5% of the corresponding correct parses.",2.3 Filter Bank,[0],[0]
The label aggregator combines multiple (potentially conflicting) suggested labels from the LFs and combines them into a single probabilistic label per example.,2.4 Label Aggregator,[0],[0]
"Concretely, if m LFs pass the filter bank and are applied to n examples, the label aggregator implements a function f : {−1, 0, 1}m×n",2.4 Label Aggregator,[0],[0]
"→ [0, 1]n.
",2.4 Label Aggregator,[0],[0]
"A naive solution would be to use a simple majority vote, but this fails to account for the fact that LFs can vary widely in accuracy and coverage.",2.4 Label Aggregator,[0],[0]
"Instead, we use data programming (Ratner et al., 2016), which models the relationship between the true labels and the output of the labeling functions as a factor graph.",2.4 Label Aggregator,[0],[0]
"More specifically, given the true labels Y ∈ {−1, 1}n (latent) and label matrix Λ ∈ {−1, 0, 1}m×n (observed) where Λi,j = LFi(xj), we define two types of factors representing labeling propensity and accuracy:
φLabi,j (Λ, Y ) = 1{Λi,j 6= 0} (1) φAcci,j (Λ, Y ) = 1{Λi,j = yj}.",2.4 Label Aggregator,[0],[0]
"(2)
Denoting the vector of factors pertaining to a given data point xj as φj(Λ, Y ) ∈ Rm, define the model:
pw(Λ, Y )",2.4 Label Aggregator,[0],[0]
= Z −1 w exp,2.4 Label Aggregator,[0],[0]
"( n∑ j=1 w · φj(Λ, Y ) )",2.4 Label Aggregator,[0],[0]
", (3)
where w ∈ R2m is the weight vector and Zw is the normalization constant.",2.4 Label Aggregator,[0],[0]
"To learn this model without knowing the true labels Y , we minimize the negative log marginal likelihood given the observed labels Λ:
ŵ = arg min w − log ∑ Y pw(Λ, Y ) (4)
using SGD and Gibbs sampling for inference, and then use the marginals pŵ(Y | Λ) as probabilistic training labels.
",2.4 Label Aggregator,[0],[0]
"Intuitively, we infer accuracies of the LFs based on the way they overlap and conflict with one another.",2.4 Label Aggregator,[0],[0]
"Since noisier LFs are more likely to have high conflict rates with others, their corresponding accuracy weights in w will be smaller, reducing their influence on the aggregated labels.",2.4 Label Aggregator,[0],[0]
The noisily-labeled training set that the label aggregator outputs is used to train an arbitrary discriminative model.,2.5 Discriminative Model,[0],[0]
One advantage of training a discriminative model on the task instead of using the label aggregator as a classifier directly is that the label aggregator only takes into account those signals included in the LFs.,2.5 Discriminative Model,[0],[0]
"A discriminative model, on the other hand, can incorporate features that were not identified by the user but are nevertheless informative.2 Consequently, even examples for which all LFs abstained can still be classified correctly.",2.5 Discriminative Model,[0],[0]
"On the three tasks we evaluate, using the discriminative model averages 4.3 F1 points higher than using the label aggregator directly.
",2.5 Discriminative Model,[0],[0]
"For the results reported in this paper, our discriminative model is a simple logistic regression classifier with generic features defined over dependency paths.3 These features include unigrams,
2We give an example of two such features in Section 4.3.",2.5 Discriminative Model,[0],[0]
"3https://github.com/HazyResearch/treedlib
bigrams, and trigrams of lemmas, dependency labels, and part of speech tags found in the siblings, parents, and nodes between the entities in the dependency parse of the sentence.",2.5 Discriminative Model,[0],[0]
"We found this to perform better on average than a biLSTM, particularly for the traditional supervision baselines with small training set sizes; it also provided easily interpretable features for analysis.",2.5 Discriminative Model,[0],[0]
"We evaluate the accuracy of BabbleLabble on three relation extraction tasks, which we refer to as Spouse, Disease, and Protein.",3 Experimental Setup,[0],[0]
"The goal of each task is to train a classifier for predicting whether the two entities in an example are participating in the relationship of interest, as described below.",3 Experimental Setup,[0],[0]
"Statistics for each dataset are reported in Table 2, with one example and one explanation for each given in Figure 4 and additional explanations shown in Appendix B.
In the Spouse task, annotators were shown a sentence with two highlighted names and asked to label whether the sentence suggests that the two people are spouses.",3.1 Datasets,[0],[0]
"Sentences were pulled from the Signal Media dataset of news articles (Corney
et al., 2016).",3.1 Datasets,[0],[0]
"Ground truth data was collected from Amazon Mechanical Turk workers, accepting the majority label over three annotations.",3.1 Datasets,[0],[0]
"The 30 explanations we report on were sampled randomly from a pool of 200 that were generated by 10 graduate students unfamiliar with BabbleLabble.
",3.1 Datasets,[0],[0]
"In the Disease task, annotators were shown a sentence with highlighted names of a chemical and a disease and asked to label whether the sentence suggests that the chemical causes the disease.",3.1 Datasets,[0],[0]
"Sentences and ground truth labels came from a portion of the 2015 BioCreative chemical-disease relation dataset (Wei et al., 2015), which contains abstracts from PubMed.",3.1 Datasets,[0],[0]
"Because this task requires specialized domain expertise, we obtained explanations by having someone unfamiliar with BabbleLabble translate from Python to natural language labeling functions from an existing publication that explored applying weak supervision to this task (Ratner et al., 2018).
",3.1 Datasets,[0],[0]
"The Protein task was completed in conjunction with OccamzRazor, a neuroscience company targeting biological pathways of Parkinson’s disease.",3.1 Datasets,[0],[0]
"For this task, annotators were shown a sentence from the relevant biomedical literature with highlighted names of a protein and a kinase and asked to label whether or not the kinase influences the protein in terms of a physical interaction or phosphorylation.",3.1 Datasets,[0],[0]
"The annotators had domain expertise but minimal programming experience, making BabbleLabble a natural fit for their use case.",3.1 Datasets,[0],[0]
Text documents are tokenized with spaCy.4,3.2 Experimental Settings,[0],[0]
"The semantic parser is built on top of the Python-based
4https://github.com/explosion/spaCy
implementation SippyCup.5 On a single core, parsing 360 explanations takes approximately two seconds.",3.2 Experimental Settings,[0],[0]
"We use existing implementations of the label aggregator, feature library, and discriminative classifier described in Sections 2.4–2.5 provided by the open-source project Snorkel (Ratner et al., 2018).
",3.2 Experimental Settings,[0],[0]
Hyperparameters for all methods we report were selected via random search over thirty configurations on the same held-out development set.,3.2 Experimental Settings,[0],[0]
"We searched over learning rate, batch size, L2 regularization, and the subsampling rate (for improving balance between classes).6 All reported F1 scores are the average value of 40 runs with random seeds and otherwise identical settings.",3.2 Experimental Settings,[0],[0]
"We evaluate the performance of BabbleLabble with respect to its rate of improvement by number of user inputs, its dependence on correctly parsed logical forms, and the mechanism by which it utilizes logical forms.",4 Experimental Results,[0],[0]
In Table 3 we report the average F1 score of a classifier trained with BabbleLabble using 30 explanations or traditional supervision with the indicated number of labels.,4.1 High Bandwidth Supervision,[0],[0]
"On average, it took the same amount of time to collect 30 explanations as 60 labels.7 We observe that in all three tasks, BabbleLabble achieves a given F1 score with far fewer user inputs than traditional supervision, by
5https://github.com/wcmac/sippycup 6Hyperparameter ranges: learning rate (1e-2 to 1e-4), batch size (32 to 128), L2 regularization (0 to 100), subsampling rate (0 to 0.5)
7Zaidan and Eisner (2008) also found that collecting annotator rationales in the form of highlighted substrings from the sentence only doubled annotation time.
as much as 100 times in the case of the Spouse task.",4.1 High Bandwidth Supervision,[0],[0]
"Because explanations are applied to many unlabeled examples, each individual input from the user can implicitly contribute many (noisy) labels to the learning algorithm.
",4.1 High Bandwidth Supervision,[0],[0]
"We also observe, however, that once the number of labeled examples is sufficiently large, traditional supervision once again dominates, since ground truth labels are preferable to noisy ones generated by labeling functions.",4.1 High Bandwidth Supervision,[0],[0]
"However, in domains where there is much more unlabeled data available than labeled data (which in our experience is most domains), we can gain in supervision efficiency from using BabbleLabble.
",4.1 High Bandwidth Supervision,[0],[0]
"Of those explanations that did not produce a correct LF, 4% were caused by the explanation referring to unsupported concepts (e.g., one explanation referred to “the subject of the sentence,” which our simple parser doesn’t support).",4.1 High Bandwidth Supervision,[0],[0]
Another 2% were caused by human errors (the correct LF for the explanation was inconsistent with the example).,4.1 High Bandwidth Supervision,[0],[0]
"The remainder were due to unrecognized paraphrases (e.g., the explanation said “the order of appearance is X, Y” instead of a supported phrasing like “X comes before Y”).",4.1 High Bandwidth Supervision,[0],[0]
"In Table 4, we report LF summary statistics before and after filtering.",4.2 Utility of Incorrect Parses,[0],[0]
LF correctness is based on exact match with a manually generated parse for each explanation.,4.2 Utility of Incorrect Parses,[0],[0]
"Surprisingly, the simple heuristic-based filter bank successfully removes over 95% of incorrect LFs in all three tasks, resulting in final LF sets that are 86% correct on average.",4.2 Utility of Incorrect Parses,[0],[0]
"Furthermore, among those LFs that pass through the filter bank, we found that the average difference in end-task accuracy between correct and incorrect parses is less than 2.5%.",4.2 Utility of Incorrect Parses,[0],[0]
"Intuitively, the filters are effective because it is quite difficult for an LF to be parsed from the explana-
tion, label its own example correctly (passing the semantic filter), and not label all examples in the training set with the same label or identically to another LF (passing the pragmatic filter).
",4.2 Utility of Incorrect Parses,[0],[0]
"We went one step further: using the LFs that would be produced by a perfect semantic parser as starting points, we searched for “nearby” LFs (LFs differing by only one predicate) with higher endtask accuracy on the test set and succeeded 57% of the time (see Figure 5 for an example).",4.2 Utility of Incorrect Parses,[0],[0]
"In other words, when users provide explanations, the signals they describe provide good starting points, but they are actually unlikely to be optimal.",4.2 Utility of Incorrect Parses,[0],[0]
"This observation is further supported by Table 5, which shows that the filter bank is necessary to remove clearly irrelevant LFs, but with that in place, the simple rule-based semantic parser and a perfect parser have nearly identical average F1 scores.",4.2 Utility of Incorrect Parses,[0],[0]
"Once we have relevant logical forms from userprovided explanations, we have multiple options for how to use them.",4.3 Using LFs as Functions or Features,[0],[0]
Srivastava et al. (2017) propose using these logical forms as features in a linear classifier.,4.3 Using LFs as Functions or Features,[0],[0]
"We choose instead to use them as functions for weakly supervising the creation of a larger training set via data programming (Ratner et al., 2016).",4.3 Using LFs as Functions or Features,[0],[0]
"In Table 6, we compare the two approaches directly, finding that the the data programming approach outperforms a feature-based one by 9.5 F1 points with the rule-based parser, and by 4.5 points with a perfect parser.
",4.3 Using LFs as Functions or Features,[0],[0]
We attribute this difference primarily to the ability of data programming to utilize unlabeled data.,4.3 Using LFs as Functions or Features,[0],[0]
"In Figure 6, we show how the data programming approach improves with the number of unlabeled examples, even as the number of LFs remains constant.",4.3 Using LFs as Functions or Features,[0],[0]
We also observe qualitatively that data programming exposes the classifier to additional patterns that are correlated with our explanations but not mentioned directly.,4.3 Using LFs as Functions or Features,[0],[0]
"For example, in the Disease task, two of the features weighted most
highly by the discriminative model were the presence of the trigrams “could produce a” or “support diagnosis of” between the chemical and disease, despite none of these words occurring in the explanations for that task.",4.3 Using LFs as Functions or Features,[0],[0]
In Table 6 we see a 4.3 F1 point improvement (10%) when we use the discriminative model that can take advantage of these features rather than applying the LFs directly to the test set and making predictions based on the output of the label aggregator.,4.3 Using LFs as Functions or Features,[0],[0]
Our work has two themes: modeling natural language explanations/instructions and learning from weak supervision.,5 Related Work and Discussion,[0],[0]
The closest body of work is on “learning from natural language.”,5 Related Work and Discussion,[0],[0]
"As mentioned earlier, Srivastava et al. (2017) convert natural language explanations into classifier features (whereas we convert them into labeling functions).",5 Related Work and Discussion,[0],[0]
"Goldwasser and Roth (2011) convert natural lan-
guage into concepts (e.g., the rules of a card game).",5 Related Work and Discussion,[0],[0]
Ling and Fidler (2017) use natural language explanations to assist in supervising an image captioning model.,5 Related Work and Discussion,[0],[0]
Weston (2016); Li et al. (2016) learn from natural language feedback in a dialogue.,5 Related Work and Discussion,[0],[0]
"Wang et al. (2017) convert natural language definitions to rules in a semantic parser to build up progressively higher-level concepts.
",5 Related Work and Discussion,[0],[0]
"We lean on the formalism of semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang, 2016).",5 Related Work and Discussion,[0],[0]
"One notable trend is to learn semantic parsers from weak supervision (Clarke et al., 2010; Liang et al., 2011), whereas our goal is to obtain weak supervision signal from semantic parsers.
",5 Related Work and Discussion,[0],[0]
The broader topic of weak supervision has received much attention; we mention some works most related to relation extraction.,5 Related Work and Discussion,[0],[0]
"In distant supervision (Craven et al., 1999; Mintz et al., 2009) and multi-instance learning (Riedel et al., 2010; Hoffmann et al., 2011), an existing knowledge base is used to (probabilistically) impute a training set.",5 Related Work and Discussion,[0],[0]
"Various extensions have focused on aggregating a variety of supervision sources by learning generative models from noisy labels (Alfonseca et al., 2012; Takamatsu et al., 2012; Roth and Klakow, 2013; Ratner et al., 2016; Varma et al., 2017).
",5 Related Work and Discussion,[0],[0]
"Finally, while we have used natural language explanations as input to train models, they can also be output to interpret models (Krening et al., 2017; Lei et al., 2016).",5 Related Work and Discussion,[0],[0]
"More generally, from a machine learning perspective, labels are the primary asset, but they are a low bandwidth signal between annotators and the learning algorithm.",5 Related Work and Discussion,[0],[0]
Natural language opens up a much higher-bandwidth communication channel.,5 Related Work and Discussion,[0],[0]
"We have shown promising results in relation extraction (where one explanation can be “worth” 100 labels), and it would be interesting to extend our framework to other tasks and more interactive settings.",5 Related Work and Discussion,[0],[0]
"The code, data, and experiments for this paper are available on the CodaLab platform at https: //worksheets.codalab.org/worksheets/ 0x900e7e41deaa4ec5b2fe41dc50594548/.",Reproducibility,[0],[0]
We gratefully acknowledge the support of the following organizations: DARPA under No.,Acknowledgments,[0],[0]
"N66001-15-C-4043 (SIMPLEX), No. FA8750-17-2-0095 (D3M), No. FA8750-122-0335 (XDATA), and No. FA8750-13-2-0039 (DEFT), DOE under No. 108845, NIH under No. U54EB020405 (Mobilize), ONR under No. N000141712266 and No. N000141310129, AFOSR under No. 580K753, the Intel/NSF CPS Security grant No. 1505728, the Michael J. Fox Foundation for Parkinsons Research under Grant No. 14672, the Secure Internet of Things Project, Qualcomm, Ericsson, Analog Devices, the Moore Foundation, the Okawa Research Grant, American Family Insurance, Accenture, Toshiba, the National Science Foundation Graduate Research Fellowship under Grant No.",Acknowledgments,[0],[0]
"DGE-114747, the Stanford Finch Family Fellowship, the Joseph W. and Hon Mai Goodman Stanford Graduate Fellowship, an NSF CAREER Award IIS-1552635, and the members of the Stanford DAWN project: Facebook, Google, Intel, Microsoft, NEC, Teradata, and VMware.
",Acknowledgments,[0],[0]
"We thank Alex Ratner and the developers of Snorkel for their assistance with data programming, as well as the many members of the Hazy Research group and Stanford NLP group who provided feedback and tested early prototyptes.",Acknowledgments,[0],[0]
"Thanks as well to the OccamzRazor team: Tarik Koc, Benjamin Angulo, Katharina S. Volz, and Charlotte Brzozowski.
",Acknowledgments,[0],[0]
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.,Acknowledgments,[0],[0]
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, DOE, NIH, ONR, AFOSR, NSF, or the U.S. Government.",Acknowledgments,[0],[0]
"Below are the predicates in the rule-based semantic parser grammar, each of which may have many supported paraphrases, only one of which is listed here in a minimal example.",A Predicate Examples,[0],[0]
and: X is true and Y is true or: X is true or Y is true not: X is not true any: Any of X or Y or Z is true all: All of X and Y and Z are true none:,Logic,[0],[0]
None of X or Y or Z is true,Logic,[0],[0]
=: X is equal to Y 6=: X is not Y <: X is smaller than Y ≤: X is no more than Y >: X is larger than Y ≥: X is at least Y,Comparison,[0],[0]
"lower: X is lowercase upper: X is upper case capital: X is capitalized all caps: X is in all caps starts with: X starts with ""cardio"" ends with: X ends with ""itis"" substring: X contains ""-induced""",Syntax,[0],[0]
person:,Named-entity Tags,[0],[0]
A person is between X and Y location: A place is within two words of X date: A date is between X and Y number: There are three numbers in the sentence organization: An organization is right after X,Named-entity Tags,[0],[0]
"list: (X, Y) is in Z set: X, Y, and Z are true count:",Lists,[0],[0]
There is one word between X and Y contains: X is in Y intersection: At least two of X are in Y map: X is at the start of a word in Y filter: There are three capitalized words to the left of X alias: A spouse word is in the sentence (“spouse” is a predefined list from the user),Lists,[0],[0]
word distance: X is two words before Y char distance: X is twenty characters after Y left: X is before Y right: X is after Y between: X is between Y and Z within: X is within five words of Y,Position,[0],[0]
The following are a sample of the explanations provided by users for each task.,B Sample Explanations,[0],[0]
"Users referred to the first person in the sentence as “X” and the second as “Y”.
",Spouse,[0],[0]
"Label true because ""and"" occurs between X and Y and ""marriage"" occurs one word after person1.
",Spouse,[0],[0]
"Label true because person Y is preceded by ‘beau’.
",Spouse,[0],[0]
"Label false because the words ""married"", ""spouse"", ""husband"", and ""wife"" do not occur in the sentence.
",Spouse,[0],[0]
"Label false because there are more than 2 people in the sentence and ""actor"" or ""actress"" is left of person1 or person2.",Spouse,[0],[0]
"Label true because the disease is immediately after the chemical and ’induc’ or ’assoc’ is in the chemical name.
",Disease,[0],[0]
"Label true because a word containing ’develop’ appears somewhere before the chemical, and the word ’following’ is between the disease and the chemical.
",Disease,[0],[0]
"Label true because ""induced by"", ""caused by"", or ""due to"" appears between the chemical and the disease.",Disease,[0],[0]
"""
Label false because ""none"", ""not"", or ""no"" is within 30 characters to the left of the disease.",Disease,[0],[0]
"Label true because ""Ser"" or ""Tyr"" are within 10 characters of the protein.
",Protein,[0],[0]
"Label true because the words ""by"" or ""with"" are between the protein and kinase and the words ""no"", ""not"" or ""none"" are not in between the protein and kinase and the total number of words between them is smaller than 10.
",Protein,[0],[0]
"Label false because the sentence contains ""mRNA"", ""DNA"", or ""RNA"".
",Protein,[0],[0]
"Label false because there are two "","" between the protein and the kinase with less than 30 characters between them.",Protein,[0],[0]
"Training accurate classifiers requires many labels, but each label provides only limited information (one bit for binary classification).",abstractText,[0],[0]
"In this work, we propose BabbleLabble, a framework for training classifiers in which an annotator provides a natural language explanation for each labeling decision.",abstractText,[0],[0]
"A semantic parser converts these explanations into programmatic labeling functions that generate noisy labels for an arbitrary amount of unlabeled data, which is used to train a classifier.",abstractText,[0],[0]
"On three relation extraction tasks, we find that users are able to train classifiers with comparable F1 scores from 5–100 faster by providing explanations instead of just labels.",abstractText,[0],[0]
"Furthermore, given the inherent imperfection of labeling functions, we find that a simple rule-based semantic parser suffices.",abstractText,[0],[0]
Training Classifiers with Natural Language Explanations,title,[0],[0]
"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775–2779 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics
2775",text,[0],[0]
"End-to-end dialogue systems, based on neural architectures like bidirectional LSTMs or Memory Networks (Sukhbaatar et al., 2015) trained directly by gradient descent on dialogue logs, have been showing promising performance in multiple contexts (Wen et al., 2016; Serban et al., 2016; Bordes et al., 2016).",1 Introduction,[0],[0]
One of their main advantages is that they can rely on large data sources of existing dialogues to learn to cover various domains without requiring any expert knowledge.,1 Introduction,[0],[0]
"However, the flip side is that they also exhibit limited engagement, especially in chit-chat settings: they lack consistency and do not leverage proactive engagement strategies as (even partially) scripted chatbots do.
Zhang et al. (2018) introduced the PERSONACHAT dataset as a solution to cope with this issue.",1 Introduction,[0],[0]
"This dataset consists of dialogues between pairs of agents with text profiles, or personas, attached to
each of them.",1 Introduction,[0],[0]
"As shown in their paper, conditioning an end-to-end system on a given persona improves the engagement of a dialogue agent.",1 Introduction,[0],[0]
"This paves the way to potentially end-to-end personalized chatbots because the personas of the bots, by being short texts, could be easily edited by most users.",1 Introduction,[0],[0]
"However, the PERSONA-CHAT dataset was created using an artificial data collection mechanism based on Mechanical Turk.",1 Introduction,[0],[0]
"As a result, neither dialogs nor personas can be fully representative of real user-bot interactions and the dataset coverage remains limited, containing a bit more than 1k different personas.
",1 Introduction,[0],[0]
"In this paper, we build a very large-scale persona-based dialogue dataset using conversations previously extracted from REDDIT1.",1 Introduction,[0],[0]
"With simple heuristics, we create a corpus of over 5 million personas spanning more than 700 million conversations.",1 Introduction,[0],[0]
We train persona-based end-to-end dialogue models on this dataset.,1 Introduction,[1.0],['We train persona-based end-to-end dialogue models on this dataset.']
"These models outperform their counterparts that do not have access to personas, confirming results of Zhang et al. (2018).",1 Introduction,[1.0],"['These models outperform their counterparts that do not have access to personas, confirming results of Zhang et al. (2018).']"
"In addition, the coverage of our dataset seems very good since pre-training on it also leads to state-of-the-art results on the PERSONA-CHAT dataset.",1 Introduction,[1.0],"['In addition, the coverage of our dataset seems very good since pre-training on it also leads to state-of-the-art results on the PERSONA-CHAT dataset.']"
"With the rise of end-to-end dialogue systems, personalized trained systems have started to appear.",2 Related work,[0],[0]
Li et al. (2016) proposed to learn latent variables representing each speaker’s bias/personality in a dialogue model.,2 Related work,[0],[0]
"Other classic strategies include extracting explicit variables from structured knowledge bases or other symbolic sources as in (Ghazvininejad et al., 2017; Joshi et al., 2017; Young et al., 2017).",2 Related work,[0],[0]
"Still, in the context of per-
1https://www.reddit.com/r/datasets/ comments/3bxlg7/
sonal chatbots, it might be more desirable to condition on data that can be generated and interpreted by the user itself such as text rather than relying on some knowledge base facts that might not exist for everyone or a great variety of situations.",2 Related work,[0.9547717226995781],"['There may not always be such an obvious relationship between the two: the discussion topic may not be covered by the persona, a single user may write contradictory statements, and due to errors in the extraction process, some persona sentences may not represent a general trait of the user (e.g. I am feeling happy today).']"
"PERSONA-CHAT (Zhang et al., 2018) recently introduced a dataset of conversations revolving around human habits and preferences.",2 Related work,[0],[0]
"In their experiments, they showed that conditioning on a text description of each speaker’s habits, their persona, improved dialogue modeling.
",2 Related work,[0],[0]
"In this paper, we use a pre-existing REDDIT data dump as data source.",2 Related work,[0],[0]
REDDIT is a massive online message board.,2 Related work,[0],[0]
Dodge et al. (2015) used it to assess chit-chat qualities of generic dialogue models.,2 Related work,[0],[0]
Yang et al. (2018) used response prediction on REDDIT as an auxiliary task in order to improve prediction performance on natural language inference problems.,2 Related work,[0],[0]
Our goal is to learn to predict responses based on a persona for a large variety of personas.,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"To that end, we build a dataset of examples of the following form using data from REDDIT:
• Persona:",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"[“I like sport”, “I work a lot”] • Context: “I love running.”",3 Building a dataset of millions of persona-based dialogues,[0],[0]
• Response: “Me too!,3 Building a dataset of millions of persona-based dialogues,[0],[0]
"But only on weekends.”
",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"The persona is a set of sentences representing the personality of the responding agent, the context is the utterance that it responds to, and the response is the answer to be predicted.",3 Building a dataset of millions of persona-based dialogues,[0],[0]
"As in (Dodge et al., 2015), we use a preexisting dump of REDDIT that consists of 1.7 billion comments.",3.1 Preprocessing,[1.0],"['As in (Dodge et al., 2015), we use a preexisting dump of REDDIT that consists of 1.7 billion comments.']"
We tokenize sentences by padding all special characters with a space and splitting on whitespace characters.,3.1 Preprocessing,[1.0],['We tokenize sentences by padding all special characters with a space and splitting on whitespace characters.']
We create a dictionary containing the 250k most frequent tokens.,3.1 Preprocessing,[1.0],['We create a dictionary containing the 250k most frequent tokens.']
We truncate comments that are longer than 100 tokens.,3.1 Preprocessing,[1.0],['We truncate comments that are longer than 100 tokens.']
"We construct the persona of a user by gathering all the comments they wrote, splitting them into sentences, and selecting the sentences that satisfy the following rules: (i) each sentence must contain between 4 and 20 words or punctuation marks, (ii) it contains either the word I or my, (iii) at least
one verb, and (iv) at least one noun, pronoun or adjective.
",3.2 Persona extraction,[0.9999999811132797],"['We construct the persona of a user by gathering all the comments they wrote, splitting them into sentences, and selecting the sentences that satisfy the following rules: (i) each sentence must contain between 4 and 20 words or punctuation marks, (ii) it contains either the word I or my, (iii) at least one verb, and (iv) at least one noun, pronoun or adjective.']"
"To handle the quantity of data involved, we limit the size of a persona to N sentences for each user.",3.2 Persona extraction,[1.0],"['To handle the quantity of data involved, we limit the size of a persona to N sentences for each user.']"
We compare four different setups for persona creation.,3.2 Persona extraction,[1.0],['We compare four different setups for persona creation.']
"In the rules setup, we select up to N random sentences that satisfy the rules above.",3.2 Persona extraction,[1.0],"['In the rules setup, we select up to N random sentences that satisfy the rules above.']"
"In the rules + classifier setup, we filter with the rules then score the resulting sentences using a bag-of-words classifier that is trained to discriminate PERSONACHAT persona sentences from random comments.",3.2 Persona extraction,[0],[0]
We manually tune a threshold on the score in order to select sentences.,3.2 Persona extraction,[0],[0]
"If there are more than N eligible persona sentences for a given user, we keep the highest-scored ones.",3.2 Persona extraction,[1.0],"['If there are more than N eligible persona sentences for a given user, we keep the highest-scored ones.']"
"In the random from user setup, we randomly select sentences uttered by the user while keeping the sentence length requirement above (we ignore the other rules).",3.2 Persona extraction,[0],[0]
The random from dataset baseline refers to random sentences from the dataset.,3.2 Persona extraction,[1.0],['The random from dataset baseline refers to random sentences from the dataset.']
They do not necessarily come from the same user.,3.2 Persona extraction,[1.0],['They do not necessarily come from the same user.']
"This last setup serves as a control mechanism to verify that the gains in prediction accuracy are due to the user-specific information contained in personas.
",3.2 Persona extraction,[0.9999999177272406],['This last setup serves as a control mechanism to verify that the gains in prediction accuracy are due to the user-specific information contained in personas.']
"In the example at the beginning of this section, the response is clearly consistent with the persona.",3.2 Persona extraction,[1.0],"['In the example at the beginning of this section, the response is clearly consistent with the persona.']"
"There may not always be such an obvious relationship between the two: the discussion topic may not be covered by the persona, a single user may write contradictory statements, and due to errors in the extraction process, some persona sentences may not represent a general trait of the user (e.g. I am feeling happy today).",3.2 Persona extraction,[0],[0]
We take each pair of successive comments in a thread to form the context and response of an example.,3.3 Dataset creation,[0],[0]
The persona corresponding to the response is extracted using one of the methods of Section 3.2.,3.3 Dataset creation,[0],[0]
"We split the dataset randomly between training, validation and test.",3.3 Dataset creation,[0],[0]
Validation and test sets contain 50k examples each.,3.3 Dataset creation,[0],[0]
"We extract personas using training data only: test set responses cannot be contained explicitly in the persona.
",3.3 Dataset creation,[1.0000000012507986],['We extract personas using training data only: test set responses cannot be contained explicitly in the persona.']
"In total, we select personas covering 4.6m users in the rule-based setups and 7.2m users in the random setups.",3.3 Dataset creation,[1.0],"['In total, we select personas covering 4.6m users in the rule-based setups and 7.2m users in the random setups.']"
"This is a sizable fraction of the total 13.2m users of the dataset; depending on the persona selection setup, between 97 and 99.4 % of the training set examples are linked to a persona.",3.3 Dataset creation,[0],[0]
"We model dialogue by next utterance retrieval (Lowe et al., 2016), where a response is picked among a set of candidates and not generated.",4 End-to-end dialogue models,[1.0],"['We model dialogue by next utterance retrieval (Lowe et al., 2016), where a response is picked among a set of candidates and not generated.']"
The overall architecture is depicted in Fig. 1.,4.1 Architecture,[0],[0]
We encode the persona and the context using separate modules.,4.1 Architecture,[0],[0]
"As in Zhang et al. (2018), we combine the encoded context and persona using a 1-hop memory network with a residual connection, using the context as query and the set of persona sentences as memory.",4.1 Architecture,[0],[0]
We also encode all candidate responses and compute the dot-product between all those candidate representations and the joint representation of the context and the persona.,4.1 Architecture,[0],[0]
"The predicted response is the candidate that maximizes the dot product.
",4.1 Architecture,[0],[0]
We train by passing all the dot products through a softmax and maximizing the log-likelihood of the correct responses.,4.1 Architecture,[0],[0]
"We use mini-batches of training examples and, for each example therein, all the responses of the other examples of the same batch are used as negative responses.",4.1 Architecture,[0],[0]
Both context and response encoders share the same architecture and word embeddings but have different weights in the subsequent layers.,4.2 Context and response encoders,[0],[0]
"We train three different encoder architectures.
",4.2 Context and response encoders,[0],[0]
Bag-of-words applies two linear projections separated by a tanh non-linearity to the word embeddings.,4.2 Context and response encoders,[0],[0]
"We then sum the resulting sentence representation across all positions in the sentence and divide the result by √ n where n is the length of the sequence.
",4.2 Context and response encoders,[0],[0]
LSTM applies a 2-layer bidirectional LSTM.,4.2 Context and response encoders,[0],[0]
"We use the last hidden state as encoded sentence.
",4.2 Context and response encoders,[0],[0]
"Transformer is a variation of an End-to-end Memory Network (Sukhbaatar et al., 2015) introduced by Vaswani et al. (2017).",4.2 Context and response encoders,[0],[0]
"Based solely on attention mechanisms, it exhibited state-of-the-art performance on next utterance retrieval tasks in dialogues (Yang et al., 2018).",4.2 Context and response encoders,[0],[0]
Here we use only its encoding module.,4.2 Context and response encoders,[0],[0]
"We subsequently average the resulting representation across all positions in the sentence, yielding a fixed-size representation.",4.2 Context and response encoders,[0],[0]
The persona encoder encodes each persona sentence separately.,4.3 Persona encoder,[0],[0]
It relies on the same word embeddings as the context encoder and applies a linear layer on top of them.,4.3 Persona encoder,[0],[0]
"We then sum the representations across the sentence.
",4.3 Persona encoder,[0],[0]
We deliberately choose a simpler architecture than the other encoders for performance reasons as the number of personas encoded for each batch is an order of magnitude greater than the number of training examples.,4.3 Persona encoder,[0],[0]
Most personas are short sentences; we therefore expect a bag-of-words representation to encode them well.,4.3 Persona encoder,[0],[0]
We train models on the persona-based dialogue dataset described in Section 3.3 and we evaluate its accuracy both on the original task and when transferring onto PERSONA-CHAT.,5 Experiments,[0],[0]
We optimize network parameters using Adamax with a learning rate of 8e−4 on mini-batches of size 512.,5.1 Experimental details,[0],[0]
"We initialize embeddings with FastText word vectors and optimize them during learning.
",5.1 Experimental details,[0],[0]
"REDDIT LSTMs use a hidden size of 150; we concatenate the last hidden states for both directions and layers, resulting in a final representation of size 600.",5.1 Experimental details,[0],[0]
"Transformer architectures on reddit use 4 layers with a hidden size of 300 and 6 attention heads, resulting in a final representation of size 300.",5.1 Experimental details,[0],[0]
We use Spacy for part-of-speech tagging in order to verify the persona extraction rules.,5.1 Experimental details,[0],[0]
"We distribute the training by splitting each batch across 8 GPUs; we stop training after 1 full epoch, which takes about 3 days.
",5.1 Experimental details,[0],[0]
"PERSONA-CHAT We used the revised version of the dataset where the personas have been rephrased, making it a harder task.",5.1 Experimental details,[0],[0]
"The dataset being only a few thousands samples, we had to reduce the architecture to avoid overfitting for the models trained purely on PERSONA-CHAT.",5.1 Experimental details,[0],[0]
"2 layers, 2 attention heads, a dropout of 0.2 and keeping the size of the word embeddings to 300 units yield the highest accuracy on the validation set.
",5.1 Experimental details,[0],[0]
IR Baseline,5.1 Experimental details,[0],[0]
"As basic baseline, we use an information retrieval (IR) system that ranks candidate responses according to a TF-IDF weighted exactmatch similarity with the context alone.",5.1 Experimental details,[0],[0]
Impact of personas We report the accuracy of the different architectures on the reddit task in Table 1.,5.2 Results,[0],[0]
Conditioning on personas improves the prediction performance regardless of the encoder architecture.,5.2 Results,[0],[0]
"Table 2 gives some examples of how the persona affects the predicted answer.
",5.2 Results,[0],[0]
"Influence of the persona extraction In Table 3, we report precision results for several persona extraction setups.",5.2 Results,[0],[0]
"The rules setup improves the results somewhat, however adding the persona classifier actually degrades the results.",5.2 Results,[0],[0]
"A possible interpretation is that the persona classifier is trained only on the PERSONA-CHAT revised personas, and that this selection might be too narrow and lack di-
versity.",5.2 Results,[0],[0]
"Increasing the maximum persona size also improves the prediction performance.
",5.2 Results,[0],[0]
Transfer learning,5.2 Results,[0],[0]
We compare the performance of transformer models trained on REDDIT and on PERSONA-CHAT on both datasets.,5.2 Results,[0],[0]
We report results in Table 4.,5.2 Results,[0],[0]
"This architecture provides a strong improvement over the results of (Zhang et al., 2018), jumping from 35.4% hits@1 to 42.1%.",5.2 Results,[0],[0]
"Pretraining the model on REDDIT and then fine-tuning on PERSONA-CHAT pushes this score to 60.7%, largely improving the state of the art.",5.2 Results,[0],[0]
"As expected, fine-tuning on PERSONA-CHAT reduces the performance on REDDIT.",5.2 Results,[0],[0]
"However, directly testing on PERSONA-CHAT the model trained on REDDIT without fine-tuning yields a very low result.",5.2 Results,[0],[0]
"This could be a consequence of a discrepancy
between the style of personas of the two datasets.",5.2 Results,[0],[0]
This paper shows how to create a very large dataset for persona-based dialogue.,6 Conclusion,[0],[0]
We show that training models to align answers both with the persona of their author and the context improves the predicting performance.,6 Conclusion,[0],[0]
The trained models show promising coverage as exhibited by the stateof-the-art transfer results on the PERSONA-CHAT dataset.,6 Conclusion,[0],[0]
"As pretraining leads to a considerable improvement in performance, future work could be done fine-tuning this model for various dialog systems.",6 Conclusion,[0],[0]
Future work may also entail building more advanced strategies to select a limited number of personas for each user while maximizing the prediction performance.,6 Conclusion,[0],[0]
"Current dialogue systems are not very engaging for users, especially when trained end-toend without relying on proactive reengaging scripted strategies.",abstractText,[0],[0]
Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model.,abstractText,[0],[0]
"However, the dataset used in (Zhang et al., 2018) is synthetic and of limited size as it contains around 1k different personas.",abstractText,[0],[0]
In this paper we introduce a new dataset providing 5 million personas and 700 million persona-based dialogues.,abstractText,[0],[0]
"Our experiments show that, at this scale, training using personas still improves the performance of end-to-end systems.",abstractText,[0],[0]
"In addition, we show that other tasks benefit from the wide coverage of our dataset by fine-tuning our model on the data from (Zhang et al., 2018) and achieving state-of-the-art results.",abstractText,[0],[0]
Training Millions of Personalized Dialogue Agents,title,[0],[0]

2	22	Most work leverages multiple sources of information, such as search query history, Twitter feeds, Facebook likes, social network links, and user profiles.
3	41	However, in many situations, little of this information is available.
5	54	In this work, we look specifically at classifying gender and language based only on the username.
7	20	The connections to ethnicity motivate the exploration of language identification.
9	31	Unfortunately, the requirement that each username be unique precludes use of given names alone.
10	23	Instead, usernames are typically a combination of component words, names and numbers.
11	13	For example, the Twitter name @taylorswift13 might decompose into “taylor”, “swift” and “13”.
14	19	We use the Morfessor algorithm (Creutz and Lagus, 2006; Virpioja et al., 2013) for unsupervised morphology induction to learn the decomposition of the usernames into sub-units.
32	13	A umorph is added to the lexicon when it increases the weighted likelihood of the data by more than the cost of increasing the size of the lexicon.
40	31	If a username u has decomposition m1, .
42	23	The choice of smoothing algorithm can be important in such cases, since minority classes have much less training data for estimating the language model and benefit from having more probability mass assigned to unseen words.
57	13	The EM algorithm used the corrected probabilities for each bin for the unlabeled data during the maximization step.
59	13	Data was collected from the OkCupid dating site by downloading up to 1,000 profiles from 27 cities in the United States, first for men seeking women and again for women seeking men to obtain a balanced set of 44,000 usernames.
60	14	The data is partitioned into three sets with 80% assigned to training and 10% each to validation and test.
64	20	The u-morphs clearly carry semantic meaning, and the trigram features appear to be substrings of the top u-morph features.
68	30	Many other tokens suffer from this problem, e.g. “miss” is in “mission”.
76	25	The semi-supervised u-morph features obtain an error rate of 25.8%, which represents a 10% relative reduction over the baseline character n-gram results.
79	35	The language labels are noisy, so we remove approximately 35% of the tweets where the Twitter API does not agree with the langid.py classifier (Lui and Baldwin, 2012).
83	12	Semi-supervised methods are not used because of the abundant labeled data.
84	15	For each language, we train a one-vs.all classifier.
87	38	The results in Tables 3 and 4 contrast systems using 4-grams, u-morphs, and a combination model, showing precision-recall trade-offs for all users together and F1 scores broken down by specific languages, respectively.
89	15	While the overall F1 scores are similar for the 4-gram and u-morph systems, their precision and recall trade-offs are quite different, making them effective in combination.
90	36	The 4-gram system has higher recall, and the u-morph system has higher precision.
92	46	Looking at performance on the different languages, we find that the F1 score for the combination model is higher than the 4-gram for every language, with precision always improving.
101	19	Other features may simply reflect cultural norms.
102	15	For example, having an underscore in the username makes it five percent less likely to observe an English tweet.
104	64	It is hard for the fixed-length n-grams to capture this information as well as the morphemes do.
122	51	In summary, this paper has introduced the use of unsupervised morphological analysis of usernames to extract features (u-morphs) for identifying user demographics, particularly gender and language.
123	19	The experimental results demonstrate that usernames contain useful personal information, and that the u-morphs provide a more efficient and complementary representation than character n-grams.2 The result for language identification is particularly remarkable because it comes close to matching the performance achieved by using the full text of a tweet.
125	63	The methods proposed here could be extended in different directions.

0	8	Medical classification, also called medical coding, plays a vital role for healthcare providers.
1	57	Medical coding is the process of assigning ICD-10 codes (2018) to a patient’s visit in a healthcare facility.
6	25	In the inpatient case the ICD-10 codes split into the Clinical Modification Coding System ICD-10-CM for diagnosis coding and the Procedure Coding System ICD-10-PCS for procedure coding.
7	56	As of January 2018, there are 71704 ICD-10-CM codes and 78705 ICD-10-PCS codes (ICD-10, 2018).
10	26	The EMRs may be composed out of discharge summaries, emergency room notes, imaging diagnoses, anesthesia process notes, laboratory reports, etcetera.
13	32	Some of the EMRs may be composed out of free form written text whereas others contain dictated text, tables or a mixture of tables and text.
15	12	To reduce the complexity of the medical coding task Computer Assisted Coding (CAC) was introduced.
19	29	Instead CAC is typically designed to assist the medical coder by providing a list of most probable codes.
28	9	Section 5 provides experiments and results, and Section 6 closes with the conclusions.
30	12	Typically, there are several ICD-10-CM codes which apply to an encounter making ICD-10-CM code prediction a multi-label classification task (Zhang and Zhou, 2014).
31	15	Ultimately, the task consists in mapping a patient’s encounter to all or a subset of the 71704 possible ICD-10-CM codes.
34	69	Yet, this advantage is dearly bought by a lack of scalability and the need for linguistic expert knowledge which results in an expensive development phase and high maintenance costs.
35	12	The work on hand investigates the use of statistical methods for the CAC task.
37	58	This can be leveraged to scale and improve the system over time which are important features in the dynamic environment healthcare providers are faced with.
38	60	The data used for this work stems from ten healthcare providers and covers 17 months of data.
39	31	For the analysis of scalability aspects, the data was split into two partitions.
40	102	Partition A covers 6 months of data and partition B covers additional 10 months of data.
42	31	For both partitions, 5% of the data was segregated and used as development (dev) set.
43	15	The dev set is meant for threshold tuning, the generation of early stopping metrics and the estimation of interpolation weights.
44	22	Table 1 provides some key statistics of the data.
45	271	One peculiarity of the data are encounters which are quite long, see Figure 1.
47	7	In addition, the encounter length distribution exhibits a long tail.
48	15	At the upper end there are 1422 encounters (0.63%) with more than 100k tokens and the maximum encounter length reaches 857k tokens.
49	52	Figure 2 shows the ranked frequency distribution over the target codes.
50	92	From Figure 2 it is apparent that out of the 18846 codes seen in the data about two-thirds appear less than ten times.
51	36	This code sparsity issue had a direct impact on the system design as many of the codes can hardly be modeled.
53	44	After concatenating all EHRs of one encounter into one document lowercasing was applied.
55	63	Finally, after applying some shallow normalization (hyphens, underscores) tokenization was done using whitespace as token separators.
58	139	To address this issue, we followed a system combination strategy combining a set of Logistic Regression (LR) classifiers, with a Convolutional Neural Network (CNN).
60	137	In case of LR this modeling strategy was strict, meaning that one LR model was built per target code.

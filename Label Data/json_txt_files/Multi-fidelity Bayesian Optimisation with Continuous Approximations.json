{"sections": [{"heading": "1. Introduction", "text": "Many tasks in scientific and engineering applications can be framed as bandit optimisation problems, where we need to sequentially evaluate a noisy black-box function f : X \u2192 R with the goal of finding its optimum. Some applications include hyper-parameter tuning in machine learning (Hutter et al., 2011; Snoek et al., 2012), optimal policy search (Lizotte et al., 2007; Martinez-Cantin et al., 2007) and scientific experiments (Gonzalez et al., 2014; Parkinson et al., 2006).\n*Equal contribution 1Carnegie Mellon University, Pittsburgh PA, USA 2Rice University, Houston TX, USA. Correspondence to: Kirthevasan Kandasamy <kandasamy@cmu.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nTypically, in such applications, each function evaluation is expensive, and conventionally, the bandit literature has focused on developing methods for finding the optimum while keeping the number of evaluations to f at a minimum.\nHowever, with increasingly expensive function evaluations, conventional methods have become infeasible as a significant cost needs to be expended before we can learn anything about f . As a result, multi-fidelity optimisation methods have recently gained attention (Cutler et al., 2014; Kandasamy et al., 2016a; Li et al., 2016). As the name suggests, these methods assume that we have access to lower fidelity approximations to f which can be evaluated instead of f . The lower the fidelity, the cheaper the evaluation, but it provides less accurate information about f . For example, when optimising the configuration of an expensive real world robot, its performance can be approximated using cheaper computer simulations. The goal is to use the cheap approximations to guide search for the optimum of f , and reduce the overall cost of optimisation. However, most multi-fidelity work assume only a finite number of approximations. In this paper, we study multi-fidelity optimisation when there is access to a continuous spectrum of approximations.\nTo motivate this set up, consider tuning a classification algorithm over a space of hyper-parameters X by maximising a validation set accuracy. The algorithm is to be trained using N\u2022 data points via an iterative algorithm for T\u2022 iterations. However, we wish to use fewer training points N < N\u2022 and/or fewer iterations T < T\u2022 to approximate the validation accuracy. We can view validation accuracy as a function g : [1, N\u2022] \u00d7 [1, T\u2022] \u00d7 X \u2192 R where evaluating g(N,T, x) requires training the algorithm with N points for T iterations with the hyper-parameters x. If the training complexity of the algorithm is quadratic in data size and linear in the number of iterations, then the cost of this evaluation is \u03bb(N,T ) = O(N2T ). Our goal is to find the optimum when N = N\u2022, and T = T\u2022, i.e. we wish to maximise f(x) = g(N\u2022, T\u2022, x).\nIn this setting, while N,T are technically discrete choices, they are more naturally viewed as coming from a continuous 2 dimensional fidelity space, [1, N\u2022] \u00d7 [1, T\u2022]. One might hope that cheaper queries to g(N,T, \u00b7) with N,T less than N\u2022, T\u2022 can be used to learn about g(N\u2022, T\u2022, \u00b7) and consequently optimise it using less overall cost. Indeed, this\nis the case with many machine learning algorithms where cross validation performance tends to vary smoothly with data set size and number of iterations. Therefore, one may use cheap low fidelity experiments with small (N,T ) to discard bad hyper-parameters and deploy expensive high fidelity experiments with large (N,T ) only in a small but promising region. The main theoretical result of this paper (Theorem 1) shows that our proposed algorithm, BOCA, exhibits precisely this behaviour.\nContinuous approximations also arise in simulation studies: where simulations can be carried out at varying levels of granularity, on-line advertising: where an ad can be controlled by continuous parameters such as display time or target audience, and several other experiment design tasks. In fact, in many multi-fidelity papers, the finite approximations were obtained by discretising a continuous space (Huang et al., 2006; Kandasamy et al., 2016a). Here, we study a Bayesian optimisation technique that is directly designed for continuous fidelity spaces and is potentially applicable to more general spaces. Our main contributions are,\n1. A novel setting and model for multi-fidelity optimisation with continuous approximations using Gaussian process (GP) assumptions. We develop a novel algorithm, BOCA, for this setting.\n2. A theoretical analysis characterising the behaviour and regret bound for BOCA. 3. An empirical study which demonstrates that BOCA outperforms alternatives, both multi-fidelity and otherwise, on a series of synthetic problems and real examples in hyper-parameter tuning and astrophysics.\nRelated Work Bayesian optimisation (BO), refers to a suite of techniques for bandit optimisation which use a prior belief distribution for f . While there are several techniques for BO (de Freitas et al., 2012; Herna\u0301ndez-Lobato et al., 2014; Jones et al., 1998; Mockus, 1994; Thompson, 1933), our work will build on the Gaussian process upper confidence bound (GP-UCB) algorithm of Srinivas et al. (2010). GP-UCB models f as a GP and uses upper confidence bound (UCB) (Auer, 2003) techniques to determine the next point for evaluation.\nBO techniques have been used in developing multi-fidelity optimisation methods in various applications such as hyperparameter tuning and industrial design (Forrester et al., 2007; Huang et al., 2006; Klein et al., 2015; Lam et al., 2015; Poloczek et al., 2016; Swersky et al., 2013). However, these methods are either problem specific and/or only use a finite number of fidelities. Further, none of them come with theoretical underpinnings. Recent work has studied multi-fidelity methods for specific problems such as hyperparameter tuning, active learning and reinforcement learning (Agarwal et al., 2011; Cutler et al., 2014; Li et al., 2016; Sabharwal et al., 2015; Zhang & Chaudhuri, 2015). While\nsome of the above tasks can be framed as optimisation problems, the methods themselves are specific to the problem considered. Our method is more general as it applies to any bandit optimisation task.\nPerhaps the closest work to us is that of Kandasamy et al. (2016a;b;c) who developed MF-GP-UCB assuming a finite number of approximations to f . While this line of work was the first to provide theoretical guarantees for multifidelity optimisation, it has two important shortcomings. First, they make strong assumptions, particularly a uniform bound on the difference between the expensive function and an approximation. This does not allow for instances where an approximation might be good at certain regions but not at the other. In contrast, our probabilistic treatment between fidelities is is robust to such cases. Second, their model does not allow sharing information between fidelities; each approximation is treated independently. Not only is this wasteful as lower fidelities can provide useful information about higher fidelities, it also means that the algorithm might perform poorly if the fidelities are not designed properly. We demonstrate this with an experiment in Section 4. On the other hand, our model allows sharing information across the fidelity space in a natural way. In addition, we can also handle continuous approximations whereas their method is strictly for a finite number of approximations. That said, BOCA inherits a key intuition from MF-GP-UCB, which is to choose a fidelity only if we have sufficiently reduced the uncertainty at all lower fidelities. Besides this, there are considerable differences in the mechanics of the algorithm and proof techniques. As we proceed, we will draw further comparisons to Kandasamy et al. (2016a)."}, {"heading": "2. Preliminaries", "text": ""}, {"heading": "2.1. Some Background Material", "text": "Gaussian processes: A GP over a space X is a random process from X to R. GPs are typically used as a prior for functions in Bayesian nonparametrics. It is characterised by a mean function \u00b5 : X \u2192 R and a covariance function (or kernel) \u03ba : X 2 \u2192 R. If f \u223c GP(\u00b5, \u03ba), then f(x) is distributed normally N (\u00b5(x), \u03ba(x, x)) for all x \u2208 X . Suppose that we are given n observations Dn = {(xi, yi)}ni=1 from this GP, where xi \u2208 X , yi = f(xi) + i \u2208 R and i \u223c N (0, \u03b72). Then the posterior process f |Dn is also a GP with mean \u00b5n and covariance \u03ban given by\n\u00b5n(x) = k >(K + \u03b72I)\u22121Y, (1)\n\u03ban(x, x \u2032) = \u03ba(x, x\u2032)\u2212 k>(K + \u03b72I)\u22121k\u2032.\nHere Y \u2208 Rn is a vector with Yi = yi, and k, k\u2032 \u2208 Rn are such that ki = \u03ba(x, xi), k\u2032i = \u03ba(x\n\u2032, xi). The matrix K \u2208 Rn\u00d7n is given by Ki,j = \u03ba(xi, xj). We refer the reader to chapter 2 of Rasmussen & Williams (2006) for more on the basics of GPs and their use in regression.\nRadial kernels: The prior covariance functions of GPs are typically taken to be radial kernels; some examples are the squared exponential (SE) and Mate\u0301rn kernels. Using a radial kernel means that the prior covariance can be written as \u03ba(x, x\u2032) = \u03ba0\u03c6(\u2016x\u2212x\u2032\u2016) and depends only on the distance between x and x\u2032. Here, the scale parameter \u03ba0 captures the magnitude f could deviate from \u00b5. The function \u03c6 : R+ \u2192 R+ is a decreasing function with \u2016\u03c6\u2016\u221e = \u03c6(0) = 1. In this paper, we will use the SE kernel in a running example to convey the intuitions in our methods. For the SE kernel, \u03c6(r) = \u03c6h(r) = exp(\u2212r2/(2h2)), where h \u2208 R+, called the bandwidth of the kernel, controls the smoothness of the GP. When h is large, the samples drawn from the GP tend to be smoother as illustrated in Fig. 1. We will reference this observation frequently in the text.\nGP-UCB: The Gaussian Process Upper Confidence Bound (GP-UCB) algorithm of Srinivas et al. (2010) is a method for bandit optimisation, which, like many other BO methods, models f as a sample from a Gaussian process. At time t, the next point xt for evaluating f is chosen via the following procedure. First, we construct an upper confidence bound \u03d5t(x) = \u00b5t\u22121(x) + \u03b2 1/2 t \u03c3t\u22121(x) for the GP. \u00b5t\u22121 is the posterior mean of the GP conditioned on the previous t\u2212 1 evaluations and \u03c3t\u22121 is the posterior standard deviation. Following other UCB algorithms (Auer, 2003), the next point is chosen by maximising \u03d5t, i.e. xt = argmaxx\u2208X \u03d5t(x). The \u00b5t\u22121 term encourages an exploitative strategy \u2013 in that we want to query regions where we already believe f is high \u2013 and \u03c3t\u22121 encourages an exploratory strategy \u2013 in that we want to query where we are uncertain about f so that we do not miss regions which have not been queried yet. \u03b2t, which is typically increasing with t, controls the trade-off between exploration and exploitation. We have provided a brief review of GP-UCB in Appendix A.1."}, {"heading": "2.2. Problem Set Up", "text": "Our goal in bandit optimisation is to maximise a function f : X \u2192 R, over a domain X . When we evaluate f at x \u2208 X we observe y = f(x) + where E[ ] = 0. Let x? \u2208 argmaxx\u2208X f(x) be a maximiser of f and f? = f(x?) be the maximum value. An algorithm for bandit optimisation is a sequence of points {xt}t\u22650, where, at time t, the algorithm chooses to evaluate f at xt based on previous queries and\nobservations {(xi, yi)}t\u22121i=1 . After n queries to f , its goal is to achieve small simple regret Sn, as defined below.\nSn = min t=1,...,n\nf? \u2212 f(xt). (2)\nContinuous Approximations: In this work, we will let f be a slice of a function g that lies in a larger space. Precisely, we will assume the existence of a fidelity space Z and a function g : Z\u00d7X \u2192 R defined on the product space of the fidelity space and domain. The function f which we wish to maximise is related to g via f(\u00b7) = g(z\u2022, \u00b7), where z\u2022 \u2208 Z . For instance, in the hyper-parameter tuning example from Section 1, Z = [1, N\u2022] \u00d7 [1, T\u2022] and z\u2022 = [N\u2022, T\u2022]. Our goal is to find a maximiser x? \u2208 argmaxx f(x) = argmaxx g(z\u2022, x). We have illustrated this setup in Fig. 2. In the rest of the manuscript, the term \u201cfidelities\u201d will refer to points z in the fidelity space Z .\nThe multi-fidelity framework is attractive when the following two conditions are true about the problem.\n1. There exist fidelities z \u2208 Z where evaluating g is cheaper than evaluating at z\u2022. To this end, we will associate a known cost function \u03bb : Z \u2192 R+. In the hyper-parameter tuning example, \u03bb(z) = \u03bb(N,T ) = O(N2T ). It is helpful to think of z\u2022 as being the most expensive fidelity, i.e. maximiser of \u03bb, and that \u03bb(z) decreases as we move away from z\u2022. However, this notion is strictly not necessary for our algorithm or results.\n2. The cheap g(z, \u00b7) evaluation gives us information about g(z\u2022, \u00b7). This is true if g is smooth across the fidelity space as illustrated in Fig. 2. As we will describe shortly, this smoothness can be achieved by modelling g as a GP with an appropriate kernel for the fidelity space Z .\nIn the above setup, a multi-fidelity algorithm is a sequence of query-fidelity pairs {(zt, xt)}t\u22650 where, at time t, the algorithm chooses zt \u2208 Z and xt \u2208 X , and observes yt =\ng(zt, xt) + where E[ ] = 0. The choice of (zt, xt) can of course depend on the previous fidelity-query-observation triples {(zi, xi, yi)}t\u22121i=1 .\nMulti-fidelity Simple Regret: We provide bounds on the simple regret S(\u039b) of a multi-fidelity optimisation method after it has spent capital \u039b of a resource. Following Kandasamy et al. (2016a); Srinivas et al. (2010), we will aim to provide any capital bounds, meaning that an algorithm would be expected to do well for all values of (sufficiently large) \u039b. Say we have made N queries to g within capital \u039b, i.e. N is the random quantity such that N = max{n \u2265 1 : \u2211n t=1 \u03bb(zt) \u2264 \u039b}. While the cheap evaluations at z 6= z\u2022 are useful in guiding search for the optimum of g(z\u2022, \u00b7), there is no reward for optimising a cheaper g(z, \u00b7). Accordingly, we define the simple regret after capital \u039b as,\nS(\u039b) =  min t\u2208{1,...,N} s.t zt=z\u2022 f? \u2212 f(xt) if we have queried at z\u2022,\n+\u221e otherwise.\nThis definition reduces to the single fidelity definition (2) when we only query g at z\u2022. It is also similar to the definition in Kandasamy et al. (2016a), but unlike them, we do not impose additional boundedness constraints on f or g.\nBefore we proceed, we note that it is customary in the bandit literature to analyse cumulative regret. However, the definition of cumulative regret depends on the application at hand (Kandasamy et al., 2016c) and the results in this paper can be extended to to many sensible notions of cumulative regret. However, both to simplify exposition and since our focus in this paper is optimisation, we stick to simple regret.\nAssumptions: As we will be primarily focusing on continuous and compact domains and fidelity spaces, going forward we will assume, without any loss of generality, that X = [0, 1]d and Z = [0, 1]p. We discuss non-continuous settings briefly at the end of Section 3. In keeping with similar work in the Bayesian optimisation literature, we will assume g \u223c GP(0, \u03ba) and upon querying at (z, x) we observe y = g(z, x) + where \u223c N (0, \u03b72). \u03ba : (Z \u00d7 X )2 \u2192 R is the prior covariance defined on the product space. In this work, we will study exclusively \u03ba of the following form,\n\u03ba([z, x], [z\u2032, x\u2032]) = \u03ba0 \u03c6Z(\u2016z \u2212 z\u2032\u2016)\u03c6X (\u2016x\u2212 x\u2032\u2016). (3)\nHere, \u03ba0 \u2208 R+ is the scale parameter and \u03c6Z , \u03c6X are radial kernels defined on Z,X respectively. The fidelity space kernel \u03c6Z is an important component in this work. It controls the smoothness of g across the fidelity space and hence determines how much information the lower fidelities provide about g(z\u2022, \u00b7). For example, suppose that \u03c6Z was a SE kernel. A favourable setting for a multi-fidelity method would be for \u03c6Z to have a large bandwidth hZ as that would imply\nthat g is very smooth across Z . We will see that hZ determines the behaviour and theoretical guarantees of BOCA in a natural way when \u03c6Z is the SE kernel. To formalise this notion, we will define the following function \u03be : Z \u2192 [0, 1].\n\u03be(z) = \u221a 1\u2212 \u03c6Z(\u2016z \u2212 z\u2022\u2016)2 (4)\nOne interpretation of \u03be(z) is that it measures the gap in information about g(z\u2022, \u00b7) when we query at z 6= z\u2022. That is, it is the price we have to pay, in information, for querying at a cheap fidelity. Observe that \u03be increases when we move away from z\u2022 in the fidelity space. For the SE kernel, it can be shown1 \u03be(z) \u2248 \u2016z\u2212z\u2022\u2016hZ . For large hZ , g is smoother across Z and we can expect the lower fidelities to be more informative about f ; as expected the information gap \u03be is small for large hZ . If hZ is small and g is not smooth, the gap \u03be is large and lower fidelities are not as informative.\nBefore we present our algorithm for the above setup, we will introduce notation for the posterior GPs for g and f . Let Dn = {(zi, xi, yi)}ni=1 be n fidelity, query, observation values from the GP g, where yi was observed when evaluating g(zi, xi). We will denote the posterior mean and standard deviation of g conditioned on Dn by \u03bdn and \u03c4n respectively (\u03bdn, \u03c4n can be computed from (1) by replacing x\u2190 [z, x]). Therefore g(z, x)|Dn \u223c N (\u03bdn(z, x), \u03c42n(z, x)) for all (z, x) \u2208 Z \u00d7 X . We will further denote\n\u00b5n(\u00b7) = \u03bdn(z\u2022, \u00b7), \u03c3n(\u00b7) = \u03c4n(z\u2022, \u00b7), (5)\nto be the posterior mean and standard deviation of g(z\u2022, \u00b7) = f(\u00b7). It follows that f |Dn is also a GP and satisfies f(x)|Dn \u223c N (\u00b5n(x), \u03c32n(x)) for all x \u2208 X .\n3. BOCA: Bayesian Optimisation with Continuous Approximations\nBOCA is a sequential strategy to select a domain point xt \u2208 X and fidelity zt \u2208 Z at time t based on previous observations. At time t, we will first construct an upper confidence bound \u03d5t for the function f we wish to optimise. It takes the form,\n\u03d5t(x) = \u00b5t\u22121(x) + \u03b2 1/2 t \u03c3t\u22121(x). (6)\nRecall from (5) that \u00b5t\u22121 and \u03c3t\u22121 are the posterior mean and standard deviation of f using the observations from the previous t\u22121 time steps at all fidelities, i.e. the entireZ\u00d7X space. We will specify \u03b2t in Theorems 1, 8. Following other UCB algorithms, our next point xt in the domain X for evaluating g is a maximiser of \u03d5t, i.e. xt \u2208 argmaxx\u2208X \u03d5t(x).\nNext, we need to determine the fidelity zt \u2208 Z to query g. 1Strictly, \u03be(z) \u2264 \u2016z\u2212 z\u2022\u2016/hZ , but the inequality is tighter for larger hZ . In any case, \u03be is strictly decreasing with hZ .\nFor this we will first select a subset Zt(xt) of Z as follows,\nZt(xt) = { z \u2208 Z : \u03bb(z) < \u03bb(z\u2022), \u03c4t\u22121(z, xt) > \u03b3(z),\n\u03be(z) > \u03b2 \u22121/2 t \u2016\u03be\u2016\u221e } , (7)\nwhere \u03b3(z) = \u221a \u03ba0 \u03be(z)\n( \u03bb(z)\n\u03bb(z\u2022)\n)q .\nHere, \u03be is the information gap function in (4) and \u03c4t\u22121 is the posterior standard deviation of g, and p, d are the dimensionalities of Z,X . The exponent q depends on the kernel used for \u03c6Z . For e.g., for the SE kernel, q = 1/(p+ d + 2). We filter out the fidelities we consider at time t using three conditions as specified above. We elaborate on these conditions in more detail in Section 3.1. If Zt is not empty, we choose the cheapest fidelity in this set, i.e. zt \u2208 argminz\u2208Zt \u03bb(z). If Zt is empty, we choose zt = z\u2022.\nWe have summarised the resulting procedure below in Algorithm 1. An important advantage of BOCA is that it only requires specifying the GP hyper-parameters for g such as the kernel \u03ba. In practice, this can be achieved by various effective heuristics such as maximising the GP marginal likelihood or cross validation which are standard in most BO methods. In contrast, MF-GP-UCB of Kandasamy et al. (2016a) requires tuning several other hyper-parameters.\nAlgorithm 1 BOCA Input: kernel \u03ba. \u2022 Set \u03bd0(\u00b7)\u2190 0, \u03c40(\u00b7)\u2190 \u03ba(\u00b7, \u00b7)1/2, D0 \u2190 \u2205. \u2022 for t = 1, 2, . . .\n1. xt \u2190 argmaxx\u2208X \u03d5t(x). See (6) 2. zt \u2190 argminz\u2208Zt(xt)\u222a{z\u2022} \u03bb(z). See (7) 3. yt \u2190 Query g at (zt, xt). 4. Dt \u2190 Dt\u22121 \u222a {(zt, xt, yt)}. Update posterior mean \u03bdt, and standard deviation \u03c4t for g conditioned on Dt."}, {"heading": "3.1. Fidelity Selection Criterion", "text": "We will now provide an intuitive justification for the three conditions in the selection criterion for zt, i.e., equation (7). The first condition, \u03bb(z) < \u03bb(z\u2022) is fairly obvious; since we wish to optimise g(z\u2022, \u00b7) and since we are not rewarded for queries at other fidelities, there is no reason to consider fidelities that are more expensive than z\u2022.\nThe second condition, \u03c4t\u22121(z, xt) > \u03b3(z) says that we will only consider fidelities where the posterior variance is larger than a threshold \u03b3(z) = \u221a \u03ba0\u03be(z)(\u03bb(z)/\u03bb(z\u2022))\nq , which depends critically on two quantities, the cost function \u03bb and the information gap \u03be. As a first step towards parsing this condition, observe that a reasonable multi-fidelity strategy should be inclined to query cheap fidelities and learn about\ng before querying expensive fidelities. As \u03b3(z) is monotonically increasing in \u03bb(z), it becomes easier for a cheap z to satisfy \u03c4t\u22121(z, xt) > \u03b3(z) and be included in Zt at time t. Moreover, since we choose zt to be the minimiser of \u03bb in Zt, a cheaper fidelity will always be chosen over expensive ones if included in Zt. Second, if a particular fidelity z is far away from z\u2022, it probably contains less information about g(z\u2022, \u00b7). Again, a reasonable multi-fidelity strategy should be discouraged from making such queries. This is precisely the role of the information gap \u03be which is increasing with \u2016z \u2212 z\u2022\u2016. As z moves away from z\u2022, \u03b3(z) increases and it becomes harder to satisfy \u03c4t\u22121(z, xt) > \u03b3(z). Therefore, such a z is less likely to be included in Zt(xt) and be considered for evaluation. Our analysis reveals that setting \u03b3 as in (7) is a reasonable trade off between cost and information in the approximations available to us; cheaper fidelities cost less, but provide less accurate information about the function f we wish to optimise. It is worth noting that the second condition is similar in spirit to Kandasamy et al. (2016a) who proceed from a lower to higher fidelity only when the lower fidelity variance is smaller than a threshold. However, while they treat the threshold as a hyper-parameter, we are able to explicitly specify theoretically motivated values.\nThe third condition in (7) is \u03be(z) > \u2016\u03be\u2016\u221e/\u03b21/2t . Since \u03be is increasing as we move away from z\u2022, it says we should exclude fidelities inside a (small) neighbourhood of z\u2022. Recall that if Zt is empty, BOCA will choose z\u2022 by default. But when it is not empty, we want to prevent situations where we get arbitrarily close to z\u2022 but not actually query at z\u2022. Such pathologies can occur when we are dealing with a continuum of fidelities and this condition forces BOCA to pick z\u2022 instead of querying very close to it. Observe that since \u03b2t is increasing with t, this neighborhood is shrinking with time and therefore the algorithm will eventually have the opportunity to evaluate fidelities close to z\u2022."}, {"heading": "3.2. Theoretical Results", "text": "We now present our main theoretical contributions. In order to simplify the exposition and convey the gist of our results, we will only present a simplified version of our theorems. We will suppress constants, polylog terms, and other technical details that arise due to a covering argument in our proofs. A rigorous treatment is available in Appendix B.\nMaximum Information Gain: Up until this point, we have not discussed much about the kernel \u03c6X of the domain X . Since we are optimising f over X , it is natural to expect that this will appear in the bounds. Srinivas et al. (2010) showed that the statistical difficulty of GP bandits is determined by the Maximum Information Gain (MIG) which measures the maximum information a subset of observations have about f . We denote it by \u03a8n(A) where A is a subset of X and n is the number of queries to f . We refer the reader\nto Appendix B for a formal definition of MIG. For the current exposition however, it suffices to know that for radial kernels, \u03a8n(A) increases with n and the volume vol(A) of A. For instance, when we use an SE kernel for \u03c6X , we have \u03a8n(A) \u221d vol(A) log(n)d+1and for a Mate\u0301rn kernel with smoothness parameter \u03bd, \u03a8n(A) \u221d vol(A)n1\u2212 \u03bd 2\u03bd+d(d+1) . (Srinivas et al., 2010). Let n\u039b = b\u039b/\u03bb(z\u2022)c denote the number of queries by a single fidelity algorithm within capital \u039b. Srinivas et al. (2010) showed that the simple regret S(\u039b) for GP-UCB after capital \u039b can be bounded by,\nSimple Regret for GP-UCB: S(\u039b) . \u221a \u03a8n\u039b(X ) n\u039b . (8)\nIn our analysis of BOCA we show that most queries to g at fidelity z\u2022 will be confined to a small subset of X which contains the optimum x?. Precisely, after capital \u039b, for any \u03b1 \u2208 (0, 1), we show there exists \u03c1 > 0 such that the number of queries outside the following set X\u03c1 is less than n\u03b1\u039b.\nX\u03c1 = { x \u2208 X : f? \u2212 f(x) \u2264 2\u03c1 \u221a \u03ba0 \u2016\u03be\u2016\u221e } . (9)\nHere, \u03be is from (4). While it is true that any optimisation algorithm would eventually query extensively in a neighbourhood around the optimum, a strong result of the above form is not always possible. For instance, for GP-UCB, the best achievable bound on the number of queries in any set that does not contain x? is n 1/2 \u039b . The fact that X\u03c1 exists relies crucially on the multi-fidelity assumptions and that our algorithm leverages information from lower fidelities when querying at z\u2022. As \u03be is small when g is smooth across Z , the set X\u03c1 will be small when the approximations are highly informative about g(z\u2022, \u00b7). For e.g., when \u03c6Z is a SE kernel, we haveX\u03c1 \u2248 {x \u2208 X : f?\u2212f(x) \u2264 2\u03c1 \u221a \u03ba0p/hZ}. When hZ is large and g is smooth across Z , X\u03c1 is small as the right side of the inequality is smaller. As BOCA confines most of its evaluations to this small set containing x?, we will be able to achieve much better regret than GP-UCB. When hZ is small and g is not smooth across Z , the set X\u03c1 becomes large and the advantage of multi-fidelity optimisation diminishes. One can similarly argue that for the Mate\u0301rn kernel, as the parameter \u03bd increases, g will be smoother across Z , and X\u03c1 becomes smaller yielding better bounds on the regret. Below, we provide an informal statement of our main theoretical result. ., will denote inequality and equality ignoring constant and polylog terms.\nTheorem 1 (Informal, Regret of BOCA). Let g \u223c GP(0, \u03ba) where \u03ba satisfies (3). Choose \u03b2t d log(t/\u03b4). Then, for sufficiently large \u039b and for all \u03b1 \u2208 (0, 1), there exists \u03c1 depending on \u03b1 such that the following bound holds with probability at least 1\u2212 \u03b4.\nS(\u039b) . \u221a \u03a8n\u039b(X\u03c1) n\u039b + \u221a \u03a8n\u03b1\u039b(X ) n2\u2212\u03b1\u039b\nIn the above bound, the latter term vanishes fast due to the n\u2212(1\u2212\u03b1/2)\u039b dependence. When comparing this with (8), we see that we outperform GP-UCB by a factor of \u221a \u03a8n\u039b(X\u03c1)/\u03a8n\u039b(X ) \u221a\nvol(X\u03c1)/vol(X ) asymptotically. If g is smooth across the fidelity space, X\u03c1 is small and the gains over GP-UCB are significant. If g becomes less smooth across Z , the bound decays gracefully, but we are never worse than GP-UCB up to constant factors.\nTheorem 1 also has similarities to the bounds of Kandasamy et al. (2016a) who also demonstrate better regret than GPUCB by showing that it is dominated by queries inside a set X \u2032 which contains the optimum. However, their bounds depend critically on certain threshold hyper-parameters which determine the volume of X \u2032 among other terms in their regret. The authors of that paper note that their bounds will suffer if these hyper-parameters are not chosen appropriately, but do not provide theoretically justified methods to make this choice. In contrast, many of the design choices for BOCA fall out naturally of our modeling assumptions. Beyond this analogue, our results are not comparable to Kandasamy et al. (2016a) as the assumptions are different.\nExtensions: While we have focused on continuousZ , many of the ideas here can be extended to other settings. If Z is a discrete subset of [0, 1]p our work extends straightforwardly. We reiterate that this will not be the same as the finite fidelity MF-GP-UCB algorithm as the assumptions are different. In particular, Kandasamy et al. (2016a) are not able to effectively share information across fidelities as we do. We also believe that Algorithm 1 can be extended to arbitrary fidelity spaces Z provided that a kernel can be defined on Z . Our results can also be extended to discrete domains X and various other kernels for \u03c6X by adopting techniques from Srinivas et al. (2010)."}, {"heading": "4. Experiments", "text": "We compare BOCA to the following four baselines: (i) GPUCB, (ii) the GP-EI criterion in BO (Jones et al., 1998), (iii) MF-GP-UCB (Kandasamy et al., 2016a) and (iv) MF-SKO, the multi-fidelity sequential kriging optimisation method from Huang et al. (2006). All methods are based on GPs and we use the SE kernel for both the fidelity space and domain. The first two are not multi-fidelity methods, while the last two are finite multi-fidelity methods2. Kandasamy et al. (2016a) also study some naive multi-fidelity algorithms and demonstrate that they do not perform well; as such we will not consider such alternatives here. In all our experiments, the fidelity space was designed to be Z = [0, 1]p with z\u2022 = 1p = [1, . . . , 1] \u2208 Rp being the most expensive fi-\n2To our knowledge, the only other work that applies to continuous approximations is Klein et al. (2015) which was developed specifically for hyper-parameter tuning. Further, their implementation is not made available and is not straightforward to implement.\ndelity. For MF-GP-UCB and MF-SKO, we used 3 fidelities (2 approximations) where the approximations were obtained at z = 0.3331p and z = 0.6671p in Z . Empirically, we found that both algorithms did reasonably well with 1-3 approximations, but did not perform well with a large number of approximations (> 5); even the original papers restrict experiments to 1-3 approximations. Implementation details for all methods are given in Appendix C.1."}, {"heading": "4.1. Synthetic Experiments", "text": "The results for the first set of synthetic experiments are given in Fig. 3. The title of each figure states the function used, and the dimensionalities p, d of the fidelity space and domain. To reflect the setting in our theory, we add Gaussian noise to the function value when observing g at any (z, x). This makes the problem more challenging than standard global optimisation problems where function evaluations are not noisy. The functions g, the cost functions \u03bb and the noise variances \u03b72 are given in Appendix C.2.\nThe first two panels in Fig. 3 are simple sanity checks. In both cases, Z = [0, 1], X = [0, 1] and the functions were sampled from GPs. The GP was made known to all methods, i.e. all methods used the true GP in picking the next point. In the first panel, we used an SE kernel with bandwidth 0.1 for \u03c6X and 1.0 for \u03c6Z . g is smooth across Z in this setting, and BOCA outperforms other baselines. The curve starts mid-way as BOCA is yet to query at z\u2022 up until that point. The second panel uses the same set up as the first except\nwe used bandwidth 0.01 for \u03c6Z . Even though g is highly un-smooth across Z , BOCA does not perform poorly. This corroborates a claim that we made earlier that BOCA can naturally adapt to the smoothness of the approximations. The other multi-fidelity methods suffer in this setting.\nIn the remaining experiments, we use some standard benchmarks for global optimisation. We modify them to obtain g and add noise to the observations. As the kernel and other GP hyper-parameters are unknown, we learn them by maximising the marginal likelihood every 25 iterations. We outperform all methods on all problems except in the case of the Borehole function where MF-GP-UCB does better. The last synthetic experiment is the Branin function given in Fig. 4(a). We used the same set up as above, but use 10 fidelities for MF-GP-UCB and MF-SKO where the kth fidelity is obtained at z = k101p in the fidelity space. Notice that the performance of finite fidelity methods deteriorate. In particular, as MF-GP-UCB does not share information across fidelities, the approximations need to be designed carefully for the algorithm to work well. Our more natural modelling assumptions prevent such pitfalls. We next present two real examples in astrophysics and hyper-parameter tuning. We do not add noise to the observations, but treat it as optimisation tasks, where the goal is to maximise the function."}, {"heading": "4.2. Astrophysical Maximum Likelihood Inference", "text": "We use data on TypeIa supernova for maximum likelihood inference on 3 cosmological parameters, the Hubble con-\nstant H0 \u2208 (60, 80), the dark matter fraction \u2126M \u2208 (0, 1) and dark energy fraction \u2126\u039b \u2208 (0, 1); hence d = 3. The likelihood is given by the Robertson-Walker metric, the computation of which requires a one dimensional numerical integration for each point in the dataset. Unlike typical maximum likelihood problems, here the likelihood is only accessible via point evaluations. We use the dataset from Davis et al (2007) which has data on 192 supernovae. We construct a p = 2 dimensional multi-fidelity problem where we can choose between data set size N \u2208 [50, 192] and perform the integration on grids of size G \u2208 [102, 106] via the trapezoidal rule. As the cost function for fidelity selection, we used \u03bb(N,G) = NG as the computation time is linear in both parameters. Our goal is to maximise the average log likelihood at z\u2022 = [192, 106]. For the finite fidelity methods we use three fidelities with the approximations available at z = [97, 2.15\u00d7 103] and z = [145, 4.64\u00d7 104] (which correspond to 0.3331p and 0.6671p after rescaling as in Section 4.1). The results are given in Fig. 4(b) where we plot the maximum average log likelihood against wall clock time as that is the cost in this experiment. The plot includes the time taken by each method to tune the GPs and determine the next points/fidelities for evaluation."}, {"heading": "4.3. Support Vector Classification with 20 news groups", "text": "We use the 20 news groups dataset (Joachims, 1996) in a text classification task. We obtain the bag of words representation for each document, convert them to tf-idf features and feed them to a support vector classifier. The goal is to tune the regularisation penalty and the temperature of the rbf kernel both in the range [10\u22122, 103]; hence d = 2. The support vector implementation was taken from scikit-learn. We set this up as a 2 dimensional multi-fidelity problem where we can choose a dataset size N \u2208 [5000, 15000] and the number of training iterations T \u2208 [20, 100]. Each evaluation takes the given dataset of size N and splits it up into 5 to perform 5-fold cross validation. As the cost function for fidelity selection, we used \u03bb(N,T ) = NT as\nthe training/validation complexity is linear in both parameters. Our goal is to maximise the cross validation accuracy at z\u2022 = [15000, 100]. For the finite fidelity methods we use three fidelities with the approximations available at z = [8333, 47] and z = [11667, 73]. The results are given in Fig. 4(c) where we plot the average cross validation accuracy against wall clock time."}, {"heading": "5. Conclusion", "text": "We studied Bayesian optimisation with continuous approximations, by treating the approximations as arising out of a continuous fidelity space. While previous multi-fidelity literature has predominantly focused on a finite number of approximations, BOCA applies to continuous fidelity spaces and can potentially be extended to arbitrary spaces. We bound the simple regret for BOCA and demonstrate that it is better than methods such as GP-UCB which ignore the approximations and that the gains are determined by the smoothness of the fidelity space. When compared to existing multi-fidelity methods, BOCA is able to share information across fidelities effectively, has more natural modelling assumptions and has fewer hyper-parameters to tune. Empirically, we demonstrate that BOCA is competitive with other baselines in synthetic and real problems. Another nice feature of using continuous approximations is that it relieves the practitioner from having to design the approximations; she/he can specify the available approximations and let the algorithm decide how to choose them.\nGoing forward, we wish to extend our theoretical results to more general settings. For instance, we believe a stronger bound on the regret might be possible if \u03c6Z is a finite dimensional kernel. Since finite dimensional kernels are typically not radial (Sriperumbudur et al., 2016), our analysis techniques will not carry over straightforwardly. Another line of work that we have alluded to is to study more general fidelity spaces with an appropriately defined kernel \u03c6Z ."}, {"heading": "Acknowledgements", "text": "We would like to thank Renato Negrinho for reviewing an initial draft of this paper. This research is supported in part by DOE grant DESC0011114 and NSF grant IIS1563887. KK is supported by a Facebook Ph.D. fellowship."}], "year": 2017, "references": [{"title": "Oracle inequalities for computationally budgeted model selection", "authors": ["Agarwal", "Alekh", "Duchi", "John C", "Bartlett", "Peter L", "Levrard", "Clement"], "venue": "In COLT,", "year": 2011}, {"title": "Using Confidence Bounds for Exploitationexploration Trade-offs", "authors": ["Auer", "Peter"], "venue": "J. Mach. Learn. Res.,", "year": 2003}, {"title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical RL", "authors": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "year": 2010}, {"title": "Reinforcement Learning with Multi-Fidelity Simulators", "authors": ["Cutler", "Mark", "Walsh", "Thomas J", "How", "Jonathan P"], "venue": "In ICRA,", "year": 2014}, {"title": "Scrutinizing Exotic Cosmological Models Using ESSENCE Supernova Data Combined with Other Cosmological Probes", "authors": ["T.M. Davis et al"], "venue": "Astrophysical Journal,", "year": 2007}, {"title": "Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations", "authors": ["de Freitas", "Nando", "Smola", "Alex J", "Zoghi", "Masrour"], "venue": "In ICML,", "year": 2012}, {"title": "Multi-fidelity optimization via surrogate modelling", "authors": ["Forrester", "Alexander I. J", "S\u00f3bester", "Andr\u00e1s", "Keane", "Andy J"], "venue": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science,", "year": 2007}, {"title": "Posterior consistency of Gaussian process prior for nonparametric binary regression", "authors": ["Ghosal", "Subhashis", "Roy", "Anindya"], "venue": "Annals of Statistics,", "year": 2006}, {"title": "Bayesian Optimization for Synthetic Gene Design", "authors": ["J. Gonzalez", "J. Longworth", "D. James", "N. Lawrence"], "venue": "In BayesOpt,", "year": 2014}, {"title": "Predictive Entropy Search for Efficient Global Optimization of Black-box Functions", "authors": ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", "Hoffman", "Matthew W", "Ghahramani", "Zoubin"], "venue": "In NIPS,", "year": 2014}, {"title": "Sequential kriging optimization using multiple-fidelity evaluations", "authors": ["D. Huang", "T.T. Allen", "W.I. Notz", "R.A. Miller"], "venue": "Structural and Multidisciplinary Optimization,", "year": 2006}, {"title": "Sequential Model-based Optimization for General Algorithm Configuration", "authors": ["Hutter", "Frank", "Hoos", "Holger H", "Leyton-Brown", "Kevin"], "venue": "In LION,", "year": 2011}, {"title": "A probabilistic analysis of the rocchio algorithm with tfidf for text categorization", "authors": ["Joachims", "Thorsten"], "venue": "Technical report, DTIC Document,", "year": 1996}, {"title": "Lipschitzian Optimization Without the Lipschitz Constant", "authors": ["D.R. Jones", "C.D. Perttunen", "B.E. Stuckman"], "venue": "J. Optim. Theory Appl.,", "year": 1993}, {"title": "Efficient global optimization of expensive black-box functions", "authors": ["Jones", "Donald R", "Schonlau", "Matthias", "Welch", "William J"], "venue": "J. of Global Optimization,", "year": 1998}, {"title": "High Dimensional Bayesian Optimisation and Bandits via Additive Models", "authors": ["Kandasamy", "Kirthevasan", "Schenider", "Jeff", "P\u00f3czos", "Barnab\u00e1s"], "venue": "In International Conference on Machine Learning,", "year": 2015}, {"title": "Gaussian Process Bandit Optimisation with Multi-fidelity Evaluations", "authors": ["Kandasamy", "Kirthevasan", "Dasarathy", "Gautam", "Oliva", "Junier", "Schenider", "Jeff", "P\u00f3czos", "Barnab\u00e1s"], "venue": "In Advances in Neural Information Processing Systems,", "year": 2016}, {"title": "Multifidelity gaussian process bandit optimisation", "authors": ["Kandasamy", "Kirthevasan", "Dasarathy", "Gautam", "Oliva", "Junier B", "Schneider", "Jeff", "Poczos", "Barnabas"], "venue": "arXiv preprint arXiv:1603.06288,", "year": 2016}, {"title": "The Multi-fidelity Multiarmed Bandit", "authors": ["Kandasamy", "Kirthevasan", "Dasarathy", "Gautam", "Schneider", "Jeff", "Poczos", "Barnabas"], "venue": "In NIPS,", "year": 2016}, {"title": "Towards efficient Bayesian Optimization for Big Data", "authors": ["A. Klein", "S. Bartels", "S. Falkner", "P. Hennig", "F. Hutter"], "venue": "In BayesOpt,", "year": 2015}, {"title": "Multifidelity optimization using statistical surrogate modeling for non-hierarchical information sources", "authors": ["Lam", "R\u00e9mi", "Allaire", "Douglas L", "Willcox", "Karen E"], "venue": "In 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference,", "year": 2015}, {"title": "Hyperband: A novel bandit-based approach to hyperparameter optimization", "authors": ["Li", "Lisha", "Jamieson", "Kevin", "DeSalvo", "Giulia", "Rostamizadeh", "Afshin", "Talwalkar", "Ameet"], "venue": "arXiv preprint arXiv:1603.06560,", "year": 2016}, {"title": "Automatic gait optimization with gaussian process regression", "authors": ["Lizotte", "Daniel", "Wang", "Tao", "Bowling", "Michael", "Schuurmans", "Dale"], "venue": "In IJCAI,", "year": 2007}, {"title": "Active Policy Learning for Robot Planning and Exploration under Uncertainty", "authors": ["R. Martinez-Cantin", "N. de Freitas", "A. Doucet", "J. Castellanos"], "venue": "In Proceedings of Robotics: Science and Systems,", "year": 2007}, {"title": "Application of Bayesian approach to numerical methods of global and stochastic optimization", "authors": ["Mockus", "Jonas"], "venue": "Journal of Global Optimization,", "year": 1994}, {"title": "A Bayesian model selection analysis of WMAP3", "authors": ["D. Parkinson", "P. Mukherjee", "Liddle", "A.. R"], "venue": "Physical Review,", "year": 2006}, {"title": "Multi-information source optimization", "authors": ["Poloczek", "Matthias", "Wang", "Jialei", "Frazier", "Peter I"], "venue": "arXiv preprint arXiv:1603.00389,", "year": 2016}, {"title": "Gaussian Processes for Machine Learning", "authors": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": "UPG Ltd,", "year": 2006}, {"title": "Selecting near-optimal learners via incremental data allocation", "authors": ["A Sabharwal", "H Samulowitz", "G. Tesauro"], "venue": "In AAAI,", "year": 2015}, {"title": "Information Consistency of Nonparametric Gaussian Process Methods", "authors": ["Seeger", "MW", "Kakade", "SM", "Foster", "DP"], "venue": "IEEE Transactions on Information Theory,", "year": 2008}, {"title": "Practical Bayesian Optimization of Machine Learning Algorithms", "authors": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "In NIPS,", "year": 2012}, {"title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "authors": ["Srinivas", "Niranjan", "Krause", "Andreas", "Kakade", "Sham", "Seeger", "Matthias"], "venue": "In ICML,", "year": 2010}, {"title": "On the optimal estimation of probability measures in weak and strong", "authors": ["Sriperumbudur", "Bharath"], "venue": "topologies. Bernoulli,", "year": 2016}, {"title": "Multitask bayesian optimization", "authors": ["Swersky", "Kevin", "Snoek", "Jasper", "Adams", "Ryan P"], "venue": "In NIPS,", "year": 2013}, {"title": "On the Likelihood that one Unknown Probability Exceeds", "authors": ["W.R. Thompson"], "venue": "Another in View of the Evidence of Two Samples. Biometrika,", "year": 1933}, {"title": "Sequential design and analysis of high-accuracy and lowaccuracy computer", "authors": ["Xiong", "Shifeng", "Qian", "Peter Z. G", "Wu", "C.F. Jeff"], "venue": "codes. Technometrics,", "year": 2013}, {"title": "Active Learning from Weak and Strong Labelers", "authors": ["C. Zhang", "K. Chaudhuri"], "venue": "In NIPS,", "year": 2015}], "id": "SP:bcb1e7703999c7cec367bdf5634334cb96ff8946", "authors": [{"name": "Kirthevasan Kandasamy", "affiliations": []}, {"name": "Gautam Dasarathy", "affiliations": []}, {"name": "Jeff Schneider", "affiliations": []}, {"name": "Barnab\u00e1s P\u00f3czos", "affiliations": []}], "abstractText": "Bandit methods for black-box optimisation, such as Bayesian optimisation, are used in a variety of applications including hyper-parameter tuning and experiment design. Recently, multifidelity methods have garnered considerable attention since function evaluations have become increasingly expensive in such applications. Multifidelity methods use cheap approximations to the function of interest to speed up the overall optimisation process. However, most multi-fidelity methods assume only a finite number of approximations. On the other hand, in many practical applications, a continuous spectrum of approximations might be available. For instance, when tuning an expensive neural network, one might choose to approximate the cross validation performance using less data N and/or few training iterations T . Here, the approximations are best viewed as arising out of a continuous two dimensional space (N,T ). In this work, we develop a Bayesian optimisation method, BOCA, for this setting. We characterise its theoretical properties and show that it achieves better regret than than strategies which ignore the approximations. BOCA outperforms several other baselines in synthetic and real experiments.", "title": "Multi-fidelity Bayesian Optimisation with Continuous Approximations"}
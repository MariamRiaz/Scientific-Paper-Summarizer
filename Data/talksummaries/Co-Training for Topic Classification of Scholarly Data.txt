0	27	As science advances, scientists around the world continue to produce a large number of research articles, which provide the technological basis for worldwide dissemination of scientific discoveries.
1	32	Online digital libraries such as Google Scholar, CiteSeerx, and PubMed store and index millions of such research articles and their metadata, and make it easier for researchers to search for scientific information.
5	29	In this paper, we explore a semi-supervised approach that can exploit large amounts of unlabeled data together with small amounts of labeled data for accurate topic classification of research articles, while minimizing the human effort required for data labeling.
6	36	In the scholarly domain, research articles (or papers) are highly interconnected in giant citation networks, in which papers cite or are cited by other papers.
53	27	The dataset consists of 3186 labeled papers, with each paper being categorized into one of six classes: Agents, Artificial Intelligence (AI), Information Retrieval (IR), Machine Learning (ML), HumanComputer Interaction (HCI) and Databases (DB).
57	38	For each paper in the dataset, we have at least one cited or one citing context.
66	46	For all experiments, our labeled dataset is split in train, validation and test sets.
69	31	The remaining 786 papers are used as labeled training data.
71	31	Blum and Mitchell (1998) proposed the cotraining algorithm in the context of webpage classification.
72	32	In co-training, the idea is that two classifiers trained on two different views of the data teach one another by re-training each classifier on the data enriched with predicted examples that the other classifier is most confident about.
74	71	Algorithm 1 Co-Training Input: L, U , ‘s’ L1 ← L, L2 ← L while U 6= ∅ do Train classifier C1 on L1 Train classifier C2 on L2 S ← ∅ Move ‘s’ examples from U to S U ← U\S S1, S2 ← GetMostConfidentExamples(S, C1, C2) L1 ← L1 ∪ S1, L2 ← L2 ∪ S2 U ← U ∪ [S\(S1 ∪ S2)] end while Ouput: The combined classifier C of C1 and C2 In this paper, we study the applicability and extension of the co-training algorithm to the task of topic classification of research papers, which are embedded in large citation networks.
75	38	Here, in addition to the information contained in a paper itself, citing and cited papers capture different aspects (e.g., topicality, domain of study, algorithms used) about the target paper (Teufel et al., 2006), with citation contexts playing an instrumental role.
76	27	We conjecture that citation contexts, which act as brief summaries about a cited paper, provide important clues in predicting the topicality of a target paper.
78	41	In our model, we use the content of a paper as one view and the citation contexts as another view of our data.
82	32	The fractions of the training set are obtained from the 786 papers by selecting k% random examples from each class.
134	43	In early fusion, the feature vectors of the two views are concatenated, creating a single representation of the data.
135	31	In contrast, late fusion trains two separate classifiers and then combines them by taking the label with the highest confidence.
136	39	Figure 3 shows this comparison over different training sizes.
140	29	The reported results are statistically significant at p value of 0.05, when the training percentage is between 5 and 35.
156	43	However, the co-training method falls short when using 5% of the training instances, where EM Content and EM Citations methods are achieving higher F1-score values.
161	34	One frequently encountered example includes newly published research papers that have no cited contexts.
163	27	Figure 6 shows the difference in performance when using: (1) only cited contexts, (2) only citing contexts, and (3) both context types.
167	43	The fact that the citing contexts achieve higher F1-score than cited contexts is consistent with the intuition that when citing a paper y, an author generally summarizes the main ideas from y using important words from a target paper x, making the citing contexts to have higher overlap with words from x.
168	55	In turn, a paper z that cites x may use paraphrasing to summarize ideas from x with words more similar to those from the content of z.
180	30	For example, words like learning, multi-agent or interface are more important in the content view.
191	34	Late Fusion outperforms Early Fusion, i.e., 0.738 vs. 0.714, both obtaining lower results than co-training, while using significantly more labeled data.
194	49	Nonetheless, co-training obtains higher results than both fully supervised approaches, while using only 30% of the labeled data.
199	37	We showed that document content and citation contexts unified under the same algorithm can dramatically decrease the annotation costs as well.
200	43	In the future, we plan to extend co-training to include active learning for more robust classification.
201	62	Moreover, it would be interesting to extend the co-training approach to multi-views that could potentially handle more than two feature spaces, e.g., it could include topics by Latent Dirichlet Allocation (Blei et al., 2003) as an additional view.

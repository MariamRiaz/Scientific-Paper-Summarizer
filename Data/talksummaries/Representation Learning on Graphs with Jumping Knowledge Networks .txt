0	13	Graphs are a ubiquitous structure that widely occurs in data analysis problems.
1	36	Real-world graphs such as social networks, financial networks, biological networks and citation networks represent important rich information which is not seen from the individual entities alone, for example, the communities a person is in, the functional role of a molecule, and the sensitivity of the assets of an enterprise to external shocks.
2	27	Therefore, representation learning of nodes in graphs aims to extract high-level features from a node as well as its neighborhood, and has proved extremely useful for many applications, such as node classification, clustering, and link prediction (Perozzi et al., 2014; Monti et al., 2017; Grover & Leskovec, 2016; Tang et al., 2015).
4	47	Many of these approaches broadly follow a neighborhood aggregation (or “message passing” scheme), and those have been very promising (Kipf & Welling, 2017; Hamilton et al., 2017; Gilmer et al., 2017; Veličković et al., 2018; Kearnes et al., 2016).
5	55	These models learn to iteratively aggregate the hidden features of every node in the graph with its adjacent nodes’ as its new hidden features, where an iteration is parametrized by a layer of the neural network.
20	17	In particular, we will see that this influence is heavily affected by the graph structure, raising the question whether “one size fits all”, in particular in graphs whose subgraphs have varying properties (such as more tree-like or more expander-like).
24	44	In biological and citation networks, the majority of the nodes have few connections, whereas some nodes (hubs) are connected to many other nodes.
74	27	We measure the sensitivity of node x to node y, or the influence of y on x, by measuring how much a change in the input feature of y affects the representation of x in the last layer.
80	18	Later, we will see connections of influence distributions with random walks.
92	15	Then the influence distribution Ix for any node x ∈ V is equivalent, in expectation, to the k-step random walk distribution on G̃ starting at node x.
99	19	Empirically, we observe that, despite somewhat simplifying assumptions, our theory is close to what happens in practice.
103	21	To show the effect of skip connections, Figure 3 visualizes the analogous heat maps for one example—GCN with residual connections.
104	21	Indeed, we observe that the influence distributions of networks with residual connections approximately correspond to lazy random walks: each step has a higher probability of staying at the current node.
108	70	Random walks starting inside an expander converge rapidly in O(log |V |) steps to an almost-uniform distribution (Hoory et al., 2006).
113	35	The above observations raise the question whether the fixed but structure-dependent influence radius size induced by common aggregation schemes really achieves the best representations for all nodes and tasks.
114	26	Large radii may lead to too much averaging, while small radii may lead to instabilities or insufficient information aggregation.
118	21	If this is done independently for each node, then the model can adapt the effective neighborhood size for each node as needed, resulting in exactly the desired adaptivity.
121	23	Let h (1) v , ..., h (k) v be the jumping representations of node v (from k layers) that are to be aggregated.
127	15	For example, feature coordinates that represent more local properties can use the feature coordinates learned from the close neighbors and those representing global status would favor features from the higher-up layers.
142	14	Contrasting this result with the influence distributions of other aggregation mechanisms, we see that JK-networks indeed differ in their node-wise adaptivity of neighborhood ranges.
143	35	Figure 5 illustrates how a 6-layer JK-Net with max-pooling aggregation learns to adapt to different subgraph structures on a citation network.
144	16	Within a tree-like structure, the influence stays in the “small community” the node belongs to.
146	24	For a node affiliated to a “hub”, which presumably plays the role of connecting different types of nodes, JK-Net learns to put most influence on the node itself and otherwise spreads out the influence.
153	27	Viewing the DenseNet setting (images) from a graph-theoretic perspective, images correspond to regular, in fact, near-planar graphs.
154	52	Such graphs are far from being expanders, and do not pose the challenges of graphs with varying subgraph structures.
155	130	Indeed, as we shall see, models with concatenation aggregation perform well on graphs with more regular structures such as images and well-structured communities.
156	48	As a more general framework, JK-Net admits general layerwise aggregation models and enables better structure-aware representations on graphs with complex structures.
160	49	We evaluate JK-Nets on four benchmark datasets.
161	33	(I) The task on citation networks (Citeseer, Cora) (Sen et al., 2008) is to classify academic papers into different subjects.
167	19	(III) For protein-protein interaction networks (PPI) (Hamilton et al., 2017), the task is to classify protein functions.

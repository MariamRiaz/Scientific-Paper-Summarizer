{"sections": [{"heading": "1. Introduction", "text": "Let f : X \u2192 R be a black-box function defined on a hypercube X = \u220fD d=1[ad, bd] where D \u2265 2. Without loss of generality we assume that 0 \u2208 X . The objective is to find a global minimizer\nx\u2217 = argmin x\u2208X f(x). (1)\nWe assume, as in Preferential Bayesian Optimization (PBO, Gonza\u0301lez et al., 2017), that f is not directly accessible. In PBO, queries to f can done in pairs of points x,x\u2032 \u2208 X , and the binary feedback indicates whether f(x) > f(x\u2032). In contrast, in our work we assume that queries to f are be done\n1Helsinki Institute for Information Technology HIIT, Department of Computer Science, Aalto University, Espoo, Finland 2Department of Applied Physics, Aalto University, Espoo, Finland 3The University of Manchester, UK. Correspondence to: Petrus Mikkola <petrus.mikkola@aalto.fi>, Samuel Kaski <samuel.kaski@aalto.fi>.\nProceedings of the 37 th International Conference on Machine Learning, Online, PMLR 119, 2020. Copyright 2020 by the author(s).\nFigure 1. An illustration of a projective preferential query on molecular properties: in which rotation is the molecule most likely to bind to the surface. Here, x \u2208 X describes the location and orientation of a molecule as a vector x = (X,Y, Z, a, b, c). In the figure, the projective preferential query (\u03be,x) finds the optimal rotation along the horizontal plane, defined by the coordinate b. This corresponds to setting \u03bei = 0 to all coordinates i except the one corresponding to b, and by rotating the molecule the expert then gives the optimal value \u03b1\u2217 that corresponds to the optimal value for coordinate b. The other coordinates are kept fixed (these are determined by x).\nover the projection onto a projection vector \u03be \u2208 \u039e \u2282 X . The feedback is the optimal scalar projection, that is, the length \u03b1\u2217 of the projection in the direction \u03be. We assume that there are zero coordinates in \u03be, and these coordinates are set to fixed values described by a reference vector x \u2208 X . Formally, given a query (\u03be,x), the feedback is obtained as a minimizer over the possible scalar projections,\n\u03b1\u2217 = argmin \u03b1\u2208I\u03be f(\u03b1\u03be + x), (2)\nwhere I\u03be \u2261 {\u03b1 \u2208 R|\u03b1\u03be + x \u2208 X}.\nWhat are then natural use cases for such projective preferential queries? The main motivation comes from humans serving as the oracles. The form of the query enables efficient learning of user preferences over choice sets in which each choice has multiple attributes, and in particular over continuous choice sets. An important application is knowledge elicitation from trained professionals (doctors, physi-\nar X\niv :2\n00 2.\n03 11\n3v 4\n[ st\nat .M\nL ]\n1 4\nA ug\n2 02\n0\ncists, etc.). For example, we may learn a material scientists preferences, that is, insight based on prior knowledge and experience, over molecular translations and orientations as a molecule adsorbs to a surface. In this case, a projective preferential query could correspond to finding an optimal rotation (see Figure 1), which the scientists can easily give by rotating the molecule in a visual interface.\nProbabilistic preference learning is a relatively new topic in machine learning research but has a longer history in econometrics and psychometrics (McFadden, 1981; 2001; Stern, 1990; Thurstone, 1927). A wide range of applications of these models exists, for instance in computer graphics (Brochu et al., 2010), expert knowledge elicitation (Soufiani et al., 2013), revenue management systems of airlines (Carrier & Weatherford, 2015), rating systems, and almost any application that contains users\u2019 preference modeling. An established probabilistic model is Thurstone-Mosteller (TM) model that measures a process of pairwise comparisons (Thurstone, 1927; Mosteller, 1951). In the preference learning context, the models based on the TM-model can be applied to learning preferences from pairwise comparison feedback (e.g. Chu & Ghahramani, 2005). An extension of this research into the interactive learning setting is studied by, among others, Brochu et al. (2008) and Gonza\u0301lez et al. (2017). All these approaches resort to pairwise feedbacks. Koyama et al. (2017) proposed an extension of Bayesian optimization for learning optimal parameter values for visual design tasks by letting a user give feedback as a slider manipulation. They considered only two pairwise comparisons per slider since they tested to \u201cincluded more sampling points\u201d but they \u201cdid not observe any significant improvement in the optimization behavior\u201d.\nA drawback of most preference learning frameworks is their incapability to handle high-dimensional input spaces. The underlying reason is a combinatorial explosion in the number of possible comparisons with respect to the number of dimensions D, O(K2D), given K grid-points per dimension. This implies that a single pairwise comparison has low information content in high-dimensional spaces. This problem was mitigated by Gonza\u0301lez et al. (2017) by capturing the correlations among pairs of queries (duels). However, it is still difficult to scale that method to high-dimensional spaces, say higher than 2-dimensional (see Section 4). Furthermore, the numerical computations become infeasible in a high-dimensional setting, especially the optimization of an acquisition function or finding a Condorcet winner.\nIn this paper, we introduce a Bayesian framework, which we call Projective Preferential Bayesian Optimization (PPBO), that scales to high-dimensional input spaces. A main reason is that the information content of a projective preferential query is much higher than that of a pairwise preferential query. A projective preferential query is equiv-\nalent to infinite pairwise comparisons along a projection. An important consequence is that with projective preferential queries, the user\u2019s workload in answering the queries will be considerably reduced. Source code is available at https://github.com/AaltoPML/PPBO."}, {"heading": "2. Learning preferences from projective preferential feedback", "text": "In this section we introduce a Bayesian framework capable of dealing with projective preferential data. A central idea is to model the user\u2019s utility function, that is f , as a Gaussian process as first proposed by Chu & Ghahramani (2005). We extend this line of study to allow projective preferential queries, by deriving a tractable likelihood, proposing a method to approximate it, and introducing four acquisition criteria for enabling interactive learning in this setting.\nIn this paper, for convenience, we will formulate the method for maximization instead of minimization as in (2), without loss of generality."}, {"heading": "2.1. Likelihood", "text": "Our probabilistic model of user preferences is built upon the Thurstone\u2019s law of comparative judgement (Thurstone, 1927). A straightforward way to formalize this would be to assume pairwise comparisons are corrupted by Gaussian noise: x x\u2032, if and only if f(x) + \u03b5 > f(x\u2032) + \u03b5\u2032, where the latent function f is a utility function that characterizes user preferences described by the preference relation . The standard assumption is that \u03b5 and \u03b5\u2032 are identically and independently distributed Gaussians. Here, we deviate slightly from this assumption: Given two alternatives (\u03b1\u03be + x), (\u03b2\u03be+x) \u2208 X , we assume that \u03b1\u03be+x \u03b2\u03be+x, if and only if f(\u03b1\u03be + x) +W (\u03b1) > f(\u03b2\u03be + x) +W (\u03b2), where W is a Gaussian white noise process with zeromean and autocorrelation E(W (t)W (t+ \u03c4)) = \u03c32 if \u03c4 = 0, and zero otherwise.\nWe would like to find the likelihood for an observation (\u03b1, (\u03be,x)) that corresponds to uncountably infinite pairwise comparisons: \u03b1\u03be+x \u03b2\u03be+x for \u03b2 6= \u03b1. For each comparison we condition on W (\u03b1) (more details in Supplementary material),\nP (\u03b1\u03be + x \u03b2\u03be + x |W (\u03b1) = w) = 1\u2212 \u03a6 ( f(\u03b2\u03be + x)\u2212 f(\u03b1\u03be + x)\u2212 w\n\u03c3\n) ,\nwhere \u03a6 is the cumulative distribution function of the standard normal distribution. For a single comparison we have\nP (\u03b1\u03be + x \u03b2\u03be + x) = 1\u2212 [\u03a6 \u2217 \u03c6] ( f(\u03b2\u03be + x)\u2212 f(\u03b1\u03be + x)\n\u03c3\n) ,\nwhere \u03c6 is the probability density of the standard normal distribution and \u2217 is the convolution operator. For infinite comparisons, we first consider a finite number of comparisons m. By their independence, we have\nP (\u03b1\u03be + x \u03b21\u03be + x, ..., \u03b1\u03be + x \u03b2m\u03be + x)\n= m\u220f j=1 ( 1\u2212 [\u03a6 \u2217 \u03c6] ( f(\u03b2j\u03be + x)\u2212 f(\u03b1\u03be + x) \u03c3 )) .\nBy letting the number of points m in an increasing sequence \u03b21, ..., \u03b2m of the partition of the interval I\u03be\\{\u03b1} to approach infinity, we can interpret this as a Volterra (product) integral\nexp ( \u2212 \u222b I\u03be [\u03a6 \u2217 \u03c6] (f(\u03b2\u03be + x)\u2212 f(\u03b1\u03be + x) \u03c3 ) d\u03b2 ) .\nThe joint log-likelihood of a dataset D, denoted as L(D|f), takes the form\n\u2212 N\u2211 i=1 \u222b I\u03bei [\u03a6 \u2217 \u03c6] (f(\u03b2\u03bei + xi)\u2212 f(\u03b1i\u03bei + xi) \u03c3 ) d\u03b2."}, {"heading": "2.2. Prior", "text": "First, we introduce notation. Assume that N projective preferential queries have been performed and gathered into a dataset D = {(\u03b1i, (\u03bei,xi))}Ni=1. For every data instance (\u03b1i, (\u03bei,xi)), we also consider a sequence of pseudoobservations {(\u03b2ij\u03be\ni,xi)}mj=1. Technically, the pseudoobservations are Monte-Carlo samples needed for integrating the likelihood. The latent function values evaluated on those points are gathered into a vector,\nf (i) \u2261 ( f(\u03b1i\u03bei + xi), {f(\u03b2ij\u03be i + xi)}mj=1 ) .\nThe latent function vector over all points is formed by concatenating over f \u2261 (f (i))Ni=1.\nThe user\u2019s utility function f is modelled as a Gaussian process (Rasmussen & Williams, 2005). GP model fits ideally to this objective, since it is flexible (non-parametric) and can conveniently handle uncertainty (predictive distributions can be derived analytically). In particular, it allows us to have insight into those regions of the space X in which either we are uncertain about user preferences due to lack of data, or because the user gives inconsistent feedback. A possible reason for the latter is that one of the preference axioms, transitivity or completeness, is violated in those regions. A weak preference relation is complete if for all x,y \u2208 X , either x y or y x holds. That is, a user is able to reveal their preferences over all possible pairwise comparisons. Similarly, is transitive if for any x,y, z \u2208 X the following holds: (x y and y z) implies that x z. That is, a user has consistent preferences. This together\nwith the continuity of guarantees the existence of a realvalued continuous utility function that represents (Debreu, 1954).\nThus, we assume as Chu & Ghahramani (2005), that the prior of the utility function follows a zero-mean Gaussian process,\np(f) = 1\n(2\u03c0) N 2 |\u03a3| 12 exp(\u22121 2 f>\u03a3\u22121f),\nwhere the ijth-element of the covariance matrix is determined by a kernel k as \u03a3ij = k(xi,xj). Throughout the paper, we assume the squared exponential kernel k(x,x) = \u03c32f exp( 1 \u22122l \u2016x\u2212 x\n\u2032\u20162), where the \u03c3f and l are hyperparameters."}, {"heading": "2.3. Posterior", "text": "For the sake of simplicity, we use the Laplace approximation for the posterior distribution. A maximum a posteriori (MAP) estimate is needed for that,\nargmax f P(f |D) = argmax f (P(f)L(D|f)) = argmax f T (f),\nwhere we denote the functional (log-scaled posterior)\nT (f) \u2261 \u22121 2 f>\u03a3\u22121f\n\u2212 N\u2211 i=1 \u222b I\u03bei [\u03a6 \u2217 \u03c6] (f(\u03b2\u03bei + xi)\u2212 f(\u03b1i\u03bei + xi) \u03c3 ) d\u03b2.\nThe convolution \u03a6 \u2217 \u03c6 can be efficiently approximated by Gauss-Hermite quadrature. The outer integral is approximated as a Monte-Carlo integral,\u222b I\u03be [\u03a6 \u2217 \u03c6] (f(\u03b2\u03be + x)\u2212 f(\u03b1\u03be + x) \u03c3 ) d\u03b2\n\u2248 `(I\u03be) m m\u2211 j=1 [\u03a6 \u2217 \u03c6] (f(\u03b2j\u03be + x)\u2212 f(\u03b1\u03be + x) \u03c3 ) ,\nwhere the pseudo-observations (\u03b2j\u03be)mj for j = 1, ...,m are sampled from a suitable distribution. Our choice is to use a family of truncated generalized normal (TGN) distributions, since it provides a continuous transformation from the uniform distribution to the truncated normal distribution, such that the locations of distributions can be specified. The idea is to concentrate pseudo-observations more densely around the optimal value \u03b1\u03be as the number of queries increases. For more details, see Supplementary material.\nFor notational convenience, define\n\u2206i,j(f) \u2261 f(\u03b2ij\u03be i + xi)\u2212 f(\u03b1i\u03bei + xi) \u03c3 .\nIf the domain is normalized to X = \u220fD d=1[0, 1], and the projections are normalized to \u03be = \u03be\u2016\u03be\u2016\u221e , then `(I\u03be) = 1. Hence, under this normalization, the functional T can be approximated as\nT (f) \u2248 \u22121 2 f>\u03a3\u22121f \u2212 1 m N\u2211 i=1 m\u2211 j=1 [\u03a6 \u2217 \u03c6] ( \u2206i,j(f) ) .\nThe MAP estimate can be efficiently solved by a secondorder iterative optimization algorithm, since the gradient and the Hessian can be easily derived for T .\nThe Laplace approximation of the posterior amounts to the second-order Taylor approximation of the log posterior around the MAP estimate. In the ordinary (non-log) scale, this reads P(f |D) \u2248 P(fMAP|D) exp ( \u2212 1\n2 (f \u2212 fMAP)>H(f \u2212 fMAP)\n) ,\nwhere the matrix H is the negative Hessian of the log-posterior at the MAP estimate, H \u2261 \u2212\u2207\u2207 log P(f |D)|f=fMAP = \u03a3\u22121 + \u039b.1 In other words, the posterior distribution is approximated as a multivariate normal distribution with mean fMAP and the covariance matrix (\u03a3\u22121 + \u039b)\u22121."}, {"heading": "2.4. Predictive distribution", "text": "Based on the well-known properties of the multivariate Gaussian distribution, the predictive distribution of f is also Gaussian. Given test locations (y(1), ...,y(M)), consider the N by M matrix K \u2261 [k(y(j),x(i))]ij . The predictive mean and the predictive covariance at test locations are (for more details see (Rasmussen & Williams, 2005) or (Chu & Ghahramani, 2005))\n\u00b5pred = K >\u03a3\u22121fMAP \u03a3pred = \u03a3 \u2032 \u2212K>(\u03a3 + \u039b\u22121)\u22121K,\nwhere \u03a3\u2032 is the covariance matrix of the test locations."}, {"heading": "3. Sequential learning by projective preferential query", "text": "In this section, we discuss how to select the next projective preferential query (\u03be,x). We will choose the next query as a maximizer of an acquisition function \u03b1(\u03be,x), for instance, we will consider a modified version of the expected\n1We denote the partial derivatives matrix evaluated at MAP estimate as\n\u039b \u2261 \u2202 2 \u2202f\u2202f> 1 m N\u2211 i=1 m\u2211 j=1 [\u03a6 \u2217 \u03c6] ( \u2206i,j(f) )\u2223\u2223\u2223\u2223 f=fMAP .\nimprovement acquisition function (Jones et al., 1998). The optimization (\u03be,x)next = argmax(\u03be,x) \u03b1(\u03be,x) is carried out by using Bayesian optimization (more details in Supplementary material).\nIf the oracle is a human, this allows us to learn user preferences in an iterative loop, making PPBO interactive. However, this interesting special case, where f is a utility function of a human, also brings forth issues due to bounded rationality. We apply here the following narrow definition of this more general concept (see Simon, 1990): Bounded rationality is the idea that users give feedback that reflects their preferences, but within the limits of the information available to them and their mental capabilities."}, {"heading": "3.1. The effects of bounded rationality on the optimal next query", "text": "If the oracle is a human, it is important to realize that the optimal next (\u03be,x) is not solely the one which optimally balances the exploration-exploitation trade-off \u2013 as it is for a perfect oracle \u2013 but the optimal (\u03be,x) takes also into account human cognitive capabilities and limitations. For instance, the more there are non-zero coordinates in \u03be, the greater the \u201ccognitive burden\u201d to a human user, and the harder it becomes to give useful feedback. Thus, if there is a human in the loop, the choice of \u03be should take into account both the optimization needs and what types of queries are convenient for the user.\nThe projective preferential feedback (2) may not be singlevalued or even well-defined for all \u03be \u2208 \u039e, if the oracle is a human. For instance, the user may not be able to explicate their preferences with respect to the dth attribute, that is, the preferences do not satisfy the completeness axiom. Formally, this means that if \u03be = ed (the dth-standard unit vector), then for some x \u2208 X it holds that argmax\u03b1\u2208I\u03be f(\u03b1\u03be + x) is multi-valued, a random variable or not well-defined \u2013 depending on how we interpret the scenario in which the user should say \u201cI do not know\u201d but instead gives an arbitrary feedback. Fortunately, this incompleteness can be easily handled when a GP is used for modelling f ; it just implies that the posterior variance is high along the dimension d.\nA possible solution would be to allow the answer \u201cI do not know\u201d, and to design an acquisition function that is capable of discovering and avoiding those regions in the space X where the user gives inconsistent feedback due to any source of bounded rationality. This challenge is left for future research. It is noteworthy that the acquisition function we introduce next, performed well in the user experiment covered in Section 5."}, {"heading": "3.2. Expected improvement by projective preferential query", "text": "We define the expected improvement by projective preferential query at the nth-iteration by\nEIn(\u03be,x) \u2261 En ( max {\nmax \u03b1\u2208I\u03be\nf(\u03b1\u03be + x)\u2212 \u00b5\u2217n, 0 }) , (3)\nwhere \u00b5\u2217n denotes the highest value of the predictive posterior mean, and the expectation is conditioned on the data up to the nth-iteration. The maximum over \u03b1 models the anticipated feedback.\nEIn can be approximated as a Monte-Carlo integral (up to a multiplicative constant that does not depend on (\u03be,x)),\n1\nK K\u2211 k=1 max { max \u03b1\u2208I\u03be f\u0303k(\u03b1\u03be + x)\u2212 \u00b5\u2217n, 0 } , (4)\nwhere max\u03b1\u2208I\u03be f\u0303k(\u03b1\u03be + x) is approximated by using discrete2 Thompson sampling as described in (Herna\u0301ndezLobato et al., 2014). Discrete Thompson sampling draws a finite sample from the GP posterior distribution, and then returns the maximum over the sample. The steps needed to approximate EIn are summarized in Algorithm 1.\nAlgorithm 1 Approximate EIn(\u03be,x) input (\u03be,x) and K \u2265 1, J \u2265 1\n1. Compute (\u03a3 + \u039b\u22121)\u22121 for k = 1, 2, ...,K do 2. Draw (\u03b2j)Jj=1 3. Draw ( f\u0303(\u03b2j\u03be +x) )J j=1\nfrom the predictive distribution N ( \u00b5pred,\u03a3pred ) 4. zk \u2190 maxj {( f\u0303(\u03b2j\u03be + x) )J j=1\n} end for\noutput 1K \u2211K k=1 max { zk \u2212 \u00b5\u2217n, 0 } The bottlenecks are the first and the third steps. In the third step, a predictive covariance matrix of size J\u00d7J needs to be computed, and then a sample from the multivariate normal distribution needs to be drawn. Hence, the time complexity of Algorithm 1 is O(N3m3 +KN2m2J +KNmJ2 + KJ3), where the terms come from a matrix inversion (the first step), two matrix multiplications, and a Cholesky decomposition, respectively. Recall that N,m,K and J refer to the number of observations, pseudo-observations, MonteCarlo samples, and grid points, respectively.\n2Another alternative is to consider continuous Thompson sampling to draw a continuous sample path from the GP model, and then maximize it. The method is based on Bochner\u2019s theorem and the equivalence between a Bayesian linear model with random features and a Gaussian process. For more details see (Herna\u0301ndezLobato et al., 2014)."}, {"heading": "3.3. Pure exploitation and exploration", "text": "In the experiments we use pure exploration and exploitation as baselines. A natural interpretation of pure exploitation in our context is to select the next query (\u03be,x) such that \u03be + x = x\u2217 \u2261 argmaxx\u2032\u2208X \u00b5n(x\u2032), where \u00b5n(x\u2032) is the posterior mean of the GP model at location x\u2032, given all the data so far Dn.\nWe interpret pure exploration as maximization of the GP variance on a query (\u03be,x) given the anticipated feedback. That is, the pure explorative acquisition strategy maximizes the following acquisition function\nExplore(\u03be,x) \u2261 Vn (\nmax \u03b1\u2208I\u03be\nf(\u03b1\u03be + x) ) . (5)\nIn practice, (5) is approximated by Monte-Carlo integration and discrete Thompson sampling in the same vein as in Algorithm 1."}, {"heading": "3.4. Preferential coordinate descent (PCD)", "text": "The fourth acquisition strategy corresponds to the interesting special case where \u03be = ed (the dth-standard unit vector), and the coordinates d are rotated in a cyclical order for each query. The reference vector x = (x1, ..., xd\u22121, 0, xd+1, ..., xD) can be chosen in several ways, but it is natural to consider an exploitative strategy in which x is set to x\u2217 except for the dth-coordinate which is set to zero. We call this acquisition strategy Preferential Coordinate Descent (PCD), since PPBO with PCD acquisition is closely related to a coordinate descent algorithm that successively minimizes an objective function along coordinate directions. The PPBO method with PCD acquisition (PPBO-PCD) differs from the classical coordinate descent in two ways: First, PPBO-PCD assumes that direct function evaluations are not possible but instead projective preferential queries are. Second, it models the black-box function f (as a GP) whereas the classical coordinate descent does not. This makes PPBO-PCD able to take advantage of past queries from every one-dimensional optimization.\nWhen comparing to other acquisition strategies, we show that PCD performs well in numerical experiments (when f is not a utility function but a numerical test function). This agrees with the results in the optimization literature; for instance: if f is pseudoconvex with continuous gradient, and X is compact and convex with \u201cnice boundary\u201d, then the coordinate descent algorithm converges to a global minimum (Spall, 2012, Corollary 3.1). However, PCD may not perform so well in high-dimensional spaces, since it cannot query in between the dimensions. For instance, the expected improvement by projective preferential query outperformed PCD on a 20D test function (see Section 4), since it allows to query arbitrary projections."}, {"heading": "4. Numerical experiments", "text": "In this section we demonstrate the efficiency of the PPBO method in high-dimensional spaces, and experiment with various acquisition strategies in numerical experiments on simulated functions.\nThe goal is to find a global minimum of a black-box function f by querying it either through (i) pairwise comparisons or (ii) projective preferential queries. For (i) we use the PBO method of Gonza\u0301lez et al. (2017), which is state of the art among Gaussian process preference learning frameworks that are based on pairwise comparisons. For (ii) we use the PPBO method as introduced in this paper. The four different acquisition strategies introduced in Section 3 are compared against the baseline that samples a random (\u03be,x). For the PBO method, we consider a random and a duelingThompson sampling acquisition strategies. In total seven different methods are compared: the expected improvement by projective preferential query (PPBO-EI), pure exploitation (PPBO-EXT), pure exploration (PPBO-EXR), preferential coordinate descent (PPBO-PCD), random (PPBO-RAND), and for the PBO; random (PBO-RAND) and a variant of dueling-Thompson sampling (PBO-DTS). For more details, see Supplementary material.\nFor f we consider four different test functions: Six-humpcamel2D, Hartmann6D, Levy10D and Ackley20D.3 We add a small Gaussian error term to the test function outputs. There are as many initial queries as there are dimensions in a test function. The ith-initial query corresponds to \u03be = ei, that is, to the ith-coordinate projection, and the reference vector x is uniformly random. We consider a total budget of 100 queries. The results are depicted in Figure 2.4\nPPBO-PCD obtained the best performance on three of the four test functions. On the high-dimensional test function Ackley20D, PPBO-EI performed best. Unsurprisingly, all PPBO variants clearly outperformed all PBO variants. Since the performance gap between PPBO-RAND and PBO-RAND is so high, we conclude that from the optimization perspective; whenever a projective preferential query is possible, a PPBO-type of approach should be preferred to an approach that is based on pairwise comparisons. However, we note that it is better to think of PPBO as a complement, not as a substitute for PBO. In the applications, pairwise comparisons may be preferred, for instance, if they are more convenient to a user, and the underlying choice space is low-dimensional.\nTo illustrate the low information content of pairwise comparisons, we ran a test on the Six-hump-camel2D function.\n3https://www.sfu.ca/\u223cssurjano/optimization.html 4All experiments of each test function were run on a computing infrastructure of 24x Xeon Gold 6148 2.40GHz cores and 72GB RAM. The longest experiment (Ackley20D) took in total 24h.\nWe trained a GP classifier with 2000 random queries (duels), and found a Condorcet winner (see Gonza\u0301lez et al., 2017) by maximizing the soft-Copeland score (33 \u00d7 33 MC-samples used for the integration) by using Bayesian optimization (500 iterations with 10 optimization restarts). This took 41 minutes on the 8th-gen Intel i5-CPU, and the distance to a true global minimizer was \u2016xc \u2212 xtrue\u2016 = \u2016(0.1770,\u22120.0488)\u2212 (0.0898,\u22120.7126)\u2016 \u2248 0.67, and the corresponding function value was 0.1052 compared to a true global minimum value \u22121.0316. In contrast, PPBORAND reached this level of accuracy at the first queries, as seen from Figure 2."}, {"heading": "5. User experiment", "text": "In this section we demonstrate the capability of PPBO to correctly and efficiently encode user preferences from projective preferential feedback.\nWe consider a material science problem of a single organic molecule adsorbing to an inorganic surface. This is a key step in understanding the structure at the interface between organic and inorganic films inside electronic devices, coatings, solar cells and other materials of technological relevance. The molecule can bind in different adsorption configurations, altering the electronic properties at the interface and affecting device performance. Exploring the structure and property phase space of materials with accurate but costly computer simulations is a difficult task. Our objective is to find the most stable surface adsorption configuration through human intuition and subsequent computer simulations. The optimal configuration is the one that minimises the computed adsorption energy.\nOur test case is the adsorption of a non-symmetric, bulky molecule camphor on the flat surface of (111)-plane terminated Cu slab. Some understanding of chemical bonding is required to infer correct adsorption configurations. The user is asked to consider the adsorption structure as a function of molecular orientation and translation near the surface. These are represented with 6 physical variables: angles \u03b1, \u03b2, \u03b3 of molecular rotation around the X, Y, Z Cartesian axes (in the range [0, 360] deg.), and distances x, y, z of translation above the surface (with lattice vectors following the translational symmetry of the surface). The internal structures of the molecule and surface were kept fixed since little structural deformation is expected with adsorption. A similar organic/inorganic model system and experiment scenario was previously employed to detect the most stable surface structures with autonomous BO, given the energies of sampled configurations (Todorovic\u0301 et al., 2019).\nIn this interactive experiment, the users encode their preferred adsorption geometry as a location in the 6- dimensional phase space. We employ the quantum-\nmechanical atomistic simulation code FHI-aims (Blum et al., 2009) to i) compute the adsorption energy E of this preferred choice, and ii) optimise the structure from this initial position to find the nearest local energy minimum in phase space, E*. We also consider the number of optimization steps N needed to reach the nearest minimum as a measure of quality of the initial location.\nThere are four different test users: two materials science experts (human: a PhD student and an experienced researcher, both of them know the optimal solution), a non-expert (human), and a random bot (computer). The hypothesis is that: the materials science experts should obtain structures associated with lower energy minimum points. We consider only coordinate projections, that is \u03be \u2208 {e1, ..., e6}. In other words, we let the user choose the optimal value for one dimension at a time.\nThe total number of queries was 24, of which 6 were initial queries. The ith-initial query corresponded to \u03be = ei, that is, to the ith-coordinate projection. The initial values for the reference coordinate vector x were fixed to the same value across all user sessions. For acquisition, we used the expected improvement by projective preferential query. Since we allowed only coordinate projections for \u03be, we first selected \u03ben+1 = argmax\u03be\u2208{e1,...,e6} \u222b EIn(\u03be,x)dx,\nand then, either xn+1 = argmaxx \u00b5n(x) (EI-EXT), or the next xn+1 was drawn uniformly at random (EI-RAND). The computer bot gave random values to the queries; to provide some consistency to the bot, xn+1 was selected by maximizing a standard expected improvement function (EI-EI). The results are summarized in Table 1.\nOur first observation is that PPBO can distinguish between the choices made by a human and a computer bot. Human choices pinpoint atomic arrangements that are close to nearby local minima (small N), while the random bot\u2019s choices are far less reasonable and require much subsequent computation to optimise structures. For all human users, the preferred molecular structures were placed somewhat high above the surface, which led to relatively high E values. With this query arrangement, it appears the z variable was the most difficult one to estimate visually. Human-preferred molecular orientations were favourable, so the structures were optimised quickly (few N steps).\nThe quality of user preference is best judged by the depth of the nearest energy basin, denoted by E*. It describes the energy of the structure preferred by a user. Here, there is a marked divide by expertise. The structures refined from the choices of the bot and non-expert are local minima of adsorption, characterised by weak dispersive interactions.\nThe expert\u2019s choice led to two low-energy structure types that compete for the global minimum, and feature strong chemical bonding of the O atom to the Cu surface. Thus, the data (Table 1, column E*: rows 1-4 versus rows 5-10) supports our hypothesis: the materials science experts do obtain structures associated with lower energy minimum points.\nThe findings above demonstrate that the PPBO framework was able to encode the expert knowledge described via preferences. However, since there are only 10 samples, further work will be needed to validate the results."}, {"heading": "6. Conclusions", "text": "In this paper we have introduced a new Bayesian framework, PPBO, for learning user preferences from a special kind of feedback, which we call projective preferential feedback. The feedback is equivalent to a minimizer along a projection. Its form is especially applicable in a human-in-the-loop context. We demonstrated this in a user experiment in which the user gives the feedback as an optimal position or orientation of a molecule adsorbing to a surface. PPBO was capable of encoding user preferences in this case.\nWe demonstrated that PPBO can deal with high-dimensional spaces where existing preferential Bayesian optimization frameworks that are based on pairwise comparisons, such as IBO (Brochu, 2010) or PBO (Gonza\u0301lez et al., 2017), have difficulties to operate. In the numerical experiments, the performance gap between PPBO and PBO was so high that we conclude: whenever a projective preferential query is possible, a PPBO-type of approach is preferable from the optimization perspective. However, we note that it is better to think of PPBO as a complement, not as a substitute for\nPBO. In the applications, pairwise comparisons may be preferred, for instance, if they are more convenient to a user.\nIn summary, if it is possible to query a projective preferential query, then PPBO provides an efficient way for preference learning in high-dimensional problems. In particular, PPBO can be used for efficient expert knowledge elicitation in highdimensional settings which are important in many fields."}, {"heading": "Acknowledgements", "text": "This research was supported by the Academy of Finland (Flagship programme: Finnish Center for Artificial Intelligence FCAI; and grants 320181, 319264, 313195, 292334 and 316601). Computational resources were provided by the CSC IT Center for Science, and the Aalto Science-IT Project."}], "year": 2020, "references": [{"title": "Ab initio molecular simulations with numeric atom-centered orbitals", "authors": ["V. Blum", "R. Gehrke", "F. Hanke", "P. Havu", "V. Havu", "X. Ren", "K. Reuter", "M. Scheffler"], "venue": "Computer Physics Communications,", "year": 2009}, {"title": "Interactive Bayesian optimization: learning user preferences for graphics and animation", "authors": ["E. Brochu"], "venue": "PhD thesis, University of British Columbia,", "year": 2010}, {"title": "Active preference learning with discrete choice data", "authors": ["E. Brochu", "N.D.F. Brochu", "A. Ghosh"], "venue": "Advances in Neural Information Processing Systems", "year": 2008}, {"title": "A Bayesian interactive optimization approach to procedural animation design", "authors": ["E. Brochu", "T. Brochu", "N. de Freitas"], "venue": "In Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation,", "year": 2010}, {"title": "Implementation of MNL choice models in the passenger origin-destination simulator (PODS)", "authors": ["E. Carrier", "L. Weatherford"], "venue": "Journal of Revenue and Pricing Management,", "year": 2015}, {"title": "Preference learning with gaussian processes", "authors": ["W. Chu", "Z. Ghahramani"], "venue": "In Proceedings of the 22nd International Conference on Machine Learning,", "year": 2005}, {"title": "Representation of a preference ordering by a numerical function", "authors": ["G. Debreu"], "venue": "Decision Process,", "year": 1954}, {"title": "Efficient global optimization of expensive black-box functions", "authors": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "year": 1998}, {"title": "Sequential line search for efficient visual design optimization by crowds", "authors": ["Y. Koyama", "I. Sato", "D. Sakamoto", "T. Igarashi"], "venue": "ACM Transactions on Graphics,", "year": 2017}, {"title": "Econometric models of probabilistic choice. Structural analysis of discrete data with econometric applications", "authors": ["D. McFadden"], "year": 1981}, {"title": "Remarks on the method of paired comparisons: The least squares solution assuming equal standard deviations and equal correlations", "authors": ["F. Mosteller"], "year": 1951}, {"title": "Gaussian Processes for Machine Learning", "authors": ["C.E. Rasmussen", "C.K.I. Williams"], "year": 2005}, {"title": "Reason in human affairs", "authors": ["H. Simon"], "year": 1990}, {"title": "Preference elicitation for general random utility models", "authors": ["H.A. Soufiani", "D.C. Parkes", "L. Xia"], "venue": "In Proceedings of the 29th Conference on Uncertainty in Artificial Intelligence,", "year": 2013}, {"title": "Cyclic seesaw process for optimization and identification", "authors": ["J.C. Spall"], "venue": "Journal of Optimization Theory and Applications,", "year": 2012}, {"title": "A continuum of paired comparisons", "authors": ["H. Stern"], "venue": "models. Biometrika,", "year": 1990}, {"title": "A law of comparative judgment", "authors": ["L.L. Thurstone"], "venue": "Psychological Review,", "year": 1927}, {"title": "Bayesian inference of atomistic structure in functional materials", "authors": ["M. Todorovi\u0107", "M. Gutmann", "J. Corander", "P. Rinke"], "venue": "In npj Computational Materials,", "year": 2019}], "id": "SP:07370c27d1b1a653131a00580ce415d061969c01", "authors": [{"name": "Petrus Mikkola", "affiliations": []}, {"name": "Milica Todorovi\u0107", "affiliations": []}, {"name": "Jari J\u00e4rvi", "affiliations": []}, {"name": "Patrick Rinke", "affiliations": []}, {"name": "Samuel Kaski", "affiliations": []}], "abstractText": "Bayesian optimization is an effective method for finding extrema of a black-box function. We propose a new type of Bayesian optimization for learning user preferences in high-dimensional spaces. The central assumption is that the underlying objective function cannot be evaluated directly, but instead a minimizer along a projection can be queried, which we call a projective preferential query. The form of the query allows for feedback that is natural for a human to give, and which enables interaction. This is demonstrated in a user experiment in which the user feedback comes in the form of optimal position and orientation of a molecule adsorbing to a surface. We demonstrate that our framework is able to find a global minimum of a high-dimensional black-box function, which is an infeasible task for existing preferential Bayesian optimization frameworks that are based on pairwise comparisons.", "title": "Projective Preferential Bayesian Optimization"}
1	41	A common approach for QA is to prefer answers that are closely related to the question, where relatedness is often determined using lexical semantic models such as word embeddings (Yih et al., 2013; Jansen et al., 2014; Fried et al., 2015).
2	29	While appealing for its robustness to natural language variation, this onesize-fits-all approach does not take into account the wide range of distinct question types that can appear in any given question set, and that are best addressed individually (Chu-Carroll et al., 2004; Ferrucci et al., 2010; Clark et al., 2013).
3	80	Given the variety of question types, we suggest that a better approach is to look for answers that are related to the question through the appropriate relation, e.g., a causal question should have a causeeffect relation with its answer.
4	52	If we adopt this view, and continue to work with embeddings as a mechanism for assessing relationship, this raises a key question: how do we train and use task-specific embeddings cost-effectively?
15	22	We evaluate our causal models both directly, in terms of measuring their capacity to rank causally-related word pairs over word pairs of other relations, as well as indirectly in the downstream causal QA task.
51	85	First, we identify potential participants in causal relations, i.e., the potential causes and effects, which we term causal mentions (CM).
59	46	(2) CM identification: We extract causal mentions (which are able to serve as arguments in our causal patterns) using a set of rules designed to be robust to the variety that exists in natural language.
60	41	Namely, to find CMs that are noun phrases, we first find words that are tagged as nouns, then follow outgoing dependency links for modifiers and attached prepo- sitional phrases2, to a maximum depth of two links.
68	22	As bootstrapping methods are typically noisy, we manually evaluated the quality of approximately 250 of these pairs selected at random.
70	37	For example, from the sentence Except for Springer’s show, which still relies heavily on confrontational topics that lead to fistfights virtually every day..., while ideally we would only extract (confrontational topics → fistfights), instead we extract the tuple (show which still relies heavily on confrontational topics → fistfights virtually every day), which contains a large amount of noise: show, relies, heavily, etc.
73	21	Causal Embedding Model (cEmbed): The first distributional similarity model we use is based on the skip-gram word-embedding algorithm of Mikolov et al. (2013), which has been shown to improve a variety of language processing tasks including QA (Yih et al., 2013; Fried et al., 2015).
74	32	In particular, we use the variant implemented by Levy and Goldberg (2014) which modifies the original algorithm to use an arbitrary, rather than linear, context.
92	32	We train the network using a binary cross entropy objective function and the Adam optimizer (Kingma and Ba, 2014), using the Keras library (Chollet, 2015) operating over Theano (Theano Development Team, 2016), a popular deep-learning framework.6 Noise-aware Causal Embedding Model (cEmbedNoise): We designed a variant of our cEmbed approach to address the potential impact of the noise introduced by our bootstrapping method.
94	21	For this, we first score the tuples by their causal PMI and then scale these scores by the overall frequency of the tuple (Riloff, 1996), to account for the PMI bias toward low-frequency items.
96	22	We begin the assessment of our models with a direct evaluation to determine whether or not the proposed approaches capture causality better than generalpurpose word embeddings and whether their robustness improves upon a simple database look-up.
105	21	We used a total of 1730 nominal pairs, 865 of which were from the Cause-Effect relation (e.g., (dancing → happiness)) and an equal number which were randomly selected from the other eight relations (e.g., (juice → grapefruit), from the Entity-Origin relation).
109	44	Random: pairs were randomly shuffled.
111	57	As expected, the causal models are better able to rank causal pairs than the vanilla embedding baseline (vEmbed), which, in turn, outperforms the random baseline.
113	53	Some models perform better on the low-recall portion of the curve (e.g., the look-up baseline and cCNN), while the embedding and alignment models have a higher and more consistent performance across the PR curve.
117	46	To examine this, we analyzed its top-ranked 15% of SemEval pairs, and found that incorrectly ranked pairs were not found in the database of causal tuples.
118	23	Instead, these incorrect rankings were largely driven by low frequency words whose embeddings could not be robustly estimated due to lack of direct evidence.
119	103	Because this sparsity is partially driven by directionality, we implemented a bidirectional embedding model (cEmbedBi) that (a) trains a second embedding model by reversing the input (effects as targets, causes as contexts), and (b) ranks pairs by the average of the scores returned by these two unidirectional causal embedding models.
122	30	All in all, the best overall model is cEmbedBiNoise, which is both bidirectional and incorporates the noise handling approach from Section 5.
135	32	The features11 we use for the various models are: Embedding model features: For both our vanilla and causal embedding models, we use the same set of features as Fried et al. (2015): the maximum, minimum, and average pairwise cosine similarity between question and answer words, as well as the overall similarity between the composite question and answer vectors.
137	30	For example, in a question such as ”What causes X?”, since X is the effect, all cosine similarities would be found using the effect vectors for the question words and the cause vectors for the answer candidate words.
148	22	Individually, the cEmbedBi model is the best performing of the causal models.
149	26	While the performance of cAlign in the direct evaluation was comparable to that of cEmbedBi, here it performs far worse (line 6 vs 8), suggesting that the robustness of embeddings is helpful in QA.
165	41	This indicates that even in causal question answering, the overall topical similarity between question and answer is still useful and complementary to the causal similarity features.
177	108	Extending this work beyond causality, we hypothesize that additional embedding spaces customized to the different information needs of questions would allow for robust performance over a larger variety of questions, and that these customized embedding models should be evaluated both directly and indirectly to accurately characterize their performance.
178	57	Resources All code and resources needed to reproduce this work are available at http://clulab.cs.

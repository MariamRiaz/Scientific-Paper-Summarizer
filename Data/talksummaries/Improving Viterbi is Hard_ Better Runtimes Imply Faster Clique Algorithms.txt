0	63	A Hidden Markov Model (HMM) is a simple model that describes a random process for generating a sequence of observations.
1	19	A random walk is performed on an underlying graph (Markov Chain) and, at each step, an observation is drawn from a probability distribution that depends only on the current state (the node in the graph).
2	15	HMMs are a fundamental statistical tool and one of the most important questions in the applications of HMMs is computing the most likely sequence of states visited by the random walk in the HMM given the sequence of observations.
3	14	Andrew Viterbi proposed an algorithm (Viterbi, 1967) for this problem that computes the solution in Authors ordered alphabetically.
4	47	O(Tn2) time for any HMM with n states and an observation sequence of length T .
5	23	This algorithm is known as the Viterbi algorithm and the problem of computing the most likely sequence of states is also known as the Viterbi Path problem.
7	2	It is an important tool for structured prediction, used e.g., for structured perceptrons (Collins, 2002).
8	15	Other applications include speech recognition (Rabiner, 1989; Nefian et al., 2002; Bengio, 2003), part-of-speech tagging (Collins, 2002), action planning (Attias, 2003), emotion recognition (Cohen et al., 2000), human activity classification (Mannini & Sabatini, 2010), and waveform classification (Kim & Smyth, 2006).
10	4	For example, a combination of the Viterbi algorithm and neural networks is used for speech recognition (Mohamed et al., 2012; AbdelHamid et al., 2012; Bourlard & Morgan, 2012), handwriting recognition and protein secondary structure prediction (Lin et al., 2005; Peng et al., 2009).
11	6	It also can be combined with Support Vector Machines (Altun et al., 2003).
13	18	The quadratic dependence of the algorithm’s runtime on the number of states is a long-standing bottleneck that limits its applicability to problems with large state spaces, particularly when the number of observations is large.
14	54	A lot of effort has been put into improving the Viterbi algorithm to lower either the time or space complexity.
15	29	Many works achieve speedups by requiring structure in the input, either explicitly by considering restricted classes of HMMs (Felzenszwalb et al., 2004; Siddiqi & Moore, 2005) or implicitly by using heuristics that improve runtime in certain cases (Esposito & Radicioni, 2009; Kaji et al., 2010).
16	11	For the general case, in (Lifshits et al., 2009; Mahmud & Schliep, 2011) it is shown how to speed up the Viterbi algorithm by O(log n) when the number of distinct observations is constant using the Four Russians method or similar ideas.
17	22	More recently, in (Cairo et al., 2016), the same logarithmic speed-up was shown to be possible for the general case.
18	8	Despite significant effort, only log- arithmic improvements are known other than in very special cases.
19	12	In contrast, the memory complexity can be reduced to almost linear in the number of states without significant overhead in the runtime (Grice et al., 1997; Tarnas & Hughey, 1998; Churbanov & Winters-Hilt, 2008).
20	18	In this work, we attempt to explain this apparent barrier for faster runtimes by giving evidence of the inherent hardness of the Viterbi Path problem.
21	13	In particular, we show that getting a polynomial speedup1 would imply a breakthrough for fundamental graph problems.
22	47	Our lower bounds are based on standard hardness assumptions for the All-Pairs Shortest Paths and the Min-Weight k-Clique problems and apply even in cases where the number of distinct observations is small.
23	8	Before formally stating our results, let us give some background on the Min-Weight k-Clique problem.
27	65	A naive algorithm solves the Min-Weight k-Clique in O(nk) time and the best known algorithm still runs in O(nk−o(1)) for any constant k. Obtaining a significantly faster algorithm for this problem is a longstanding open question.
29	16	The special case of the conjecture with k = 3 says that finding the minimum weight triangle in a weighted graph cannot be solved in O(n3−δ) time for any constant δ > 0.
30	8	There are many negative results that intuitively support this conjecture: a truly sub- cubic algorithm for Min-Weight 3-Clique implies such algorithm for the All-Pairs Shortest Paths as well (Williams & Williams, 2010).
34	11	Max-Clique is also known to be hard to efficiently approximate within nontrivial factors (Håstad, 1999).
35	6	We complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM.
41	9	The proof of the theorem gives a reduction from All-Pairs Shortest Paths to the Viterbi Path problem.
42	9	This is done by encoding the weights of the graph of the APSP instance as transition probabilities of the HMM or as probabilities of seeing observations from different states.
43	38	The proof requires a large alphabet size, i.e. a large number of distinct observations, which can be as large as the number of total steps T .
44	97	A natural question question to ask is whether there is a faster algorithm that solves the Viterbi Path problem when the alphabet size is much smaller than T , say when T = n2 and the alphabet size is n. We observe that in such a case, the input size to the Viterbi Path problem is only O(n2): we only need to specify the transition probabilities of the HMM, the probabilities of each observation in each state and the sequence of observations.

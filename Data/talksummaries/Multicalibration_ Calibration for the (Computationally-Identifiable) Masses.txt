2	10	Indeed, examples of such unintended but harmful discrimination have been well-documented across many learning tasks including image classification (Buolamwini & Gebru, 2018) and natural language tasks (Bolukbasi et al., 2016).
6	15	Second, the analysis of the training data may inadvertently introduce biases that are not borne out in the data.
7	17	In this work, we focus on the latter concern.
8	73	Indeed, even given accurate ground-truth training data, the typical approach to supervised learning – choosing a model that minimizes the expected loss on the training data – runs the risk of choosing a prediction model that is good for the majority population, but overlooks the minority populations.
10	47	If on average, the individuals from S are financially disadvantaged compared to the majority population, the model may assign a fixed, low probability to all i ∈ S, while still achieving good empirical loss by predicting very accurately in the majority population.
12	10	Focusing on such concerns, we develop a theoretical framework that aims to mitigate such risks of algorithmic discrimination, in the context of prediction tasks.
13	19	Specifically, we focus on a setting where a learner has access to a small sample of ground truth data D from some domain of individuals X .
17	10	We say a predictor f : X → [0, 1] is a map from individuals i ∈ X to an estimate of the true parameters.
18	18	Next, we discuss desirable properties of predictors that motivate our new perspective on fairness.
19	13	Calibration and Multicalibration.
35	18	To answer these questions, we take the following perspective: on the one hand, we can only expect a learner to produce a predictor that is calibrated on sets that could have been identified efficiently from the data at hand; on the other hand, we expect the learner to produce a predictor that is calibrated on every efficiently-identifiable subset.
36	92	This motivates our definition of multicalibration, which loosely says: “A predictor f is multicalibrated with respect to a family of subpopulations C if it is calibrated with respect to every S ∈ C.” In a nutshell, multicalibration guarantees highly-accurate predictions for every subpopulation of individuals identified by a specified collection C of subpopulations of individuals.
37	47	While our results can be applied to any set system C, typically, we will think of C as a collection of subsets where set membership can be determined efficiently – for instance, subpopulations defined by the conjunctions of a small number of boolean features or by small decision trees.
38	38	In this sense, we can take C to be sets identified by a class of bounded computations.
39	22	As we increase the expressiveness of C, the fairness guarantee becomes stronger; no subpopulation that can be identified within the class will be overlooked.
41	27	We investigate the new notion of multicalibration from an algorithmic and complexity theoretic perspective.
43	29	A number of subtleties arise when learning a multicalibrated predictor due to the fact that the calibration constraints change based on the current set of predictions made by the predictor.
44	87	To guarantee generalization from a small sample of training examples, we leverage results from a new line of work connecting differential privacy to robust adaptive data analysis (Dwork et al., 2015a;b;c; Bassily et al., 2016).
48	27	As a corollary, the learned predictor is efficient in both space to represent and time to evaluate.
49	81	We also study the computational complexity of learning multicalibrated predictors for structured classes C. We show a strong connection between the complexity of learning a multicalibrated predictor and agnostic learning (Haussler, 1992; Kearns et al., 1994).
50	46	In the positive direction, if there is an efficient (weak) agnostic learner (Kalai et al., 2008; Feldman, 2010) for a class C, then we can achieve similarly efficient multicalibration over C. In the other direction, we show that learning a multicalibrated predictor on all sets defined by C is as hard as weak agnostic learning C. In this sense, the complexity of learning a multicalibrated predictor with respect to a class C is equivalent to the complexity of weak agnostic learning C. Finally, we demonstrate that the goal of multicalbration is aligned with the goal of achieving high-utility predictions.
51	98	In particular, given any predictor h, we can post-process h to obtain a multicalibrated predictor f whose squared error is no worse than that of h. The complexity of evaluating the predictor f is only slightly larger than that of h. In this sense, unlike many fairness notions, multicalibration is not at odds with predictive power and can be paired with any predictive model at essentially no cost to its accuracy.
52	45	Let X denote the domain of (feature vectors of) individuals; we wish to predict whether some event will occur for each individual.
55	33	Let D denote the distribution over individuals, supported on X ; for S ⊆ X , let i ∼ S denote a sample drawn from D conditioned on membership in S.1 In our learning setting, the algorithm has access to a small number of labeled individuals D ⊆ X , where for each i ∈ D, the label is the outcome oi ∼ Ber(p∗i ) of an independent Bernoulli trial.
57	123	The most basic property we might hope for from a predictor is unbiasedness, i.e. that the predictions are accurate in expectation.
58	15	Definition (Accuracy in expectation).
60	34	(1) While this condition is necessary to achieve unbiased predictions, it is not sufficient to prevent all forms of discrimination; in particular, a predictor can be unbiased on a set S while introducing variance that is not borne out in the data, artificially treating similar individuals differently.
61	65	Calibration mitigates this form of discrimination by considering the expected values over categories Sv = {i : fi = v} defined by the predictor f .
62	63	Specifically, α-calibration with respect to S requires that for all but an α-fraction of a set S, the average of the true probabilities of the individuals receiving prediction v is α-close to v. Definition (Calibration).
63	37	For any v ∈ [0, 1], S ⊆ X , and predictor f , let Sv = {i : fi = v}.
